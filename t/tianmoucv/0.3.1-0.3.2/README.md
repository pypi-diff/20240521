# Comparing `tmp/tianmoucv-0.3.1-py3-none-any.whl.zip` & `tmp/tianmoucv-0.3.2-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,51 +1,51 @@
-Zip file size: 86215 bytes, number of entries: 49
--rw-r--r--  2.0 unx      308 b- defN 24-May-06 08:38 tianmoucv/__init__.py
--rw-r--r--  2.0 unx      994 b- defN 24-May-06 08:38 tianmoucv/tools.py
--rw-r--r--  2.0 unx       99 b- defN 24-May-06 08:38 tianmoucv/data/__init__.py
--rw-r--r--  2.0 unx    12911 b- defN 24-May-06 08:38 tianmoucv/data/tianmoucData.py
--rw-r--r--  2.0 unx    25238 b- defN 24-May-06 08:38 tianmoucv/data/tianmoucData_basic.py
--rw-r--r--  2.0 unx    25949 b- defN 24-May-06 08:38 tianmoucv/data/tianmoucData_pcie.py
--rw-r--r--  2.0 unx       49 b- defN 24-May-06 08:38 tianmoucv/isp/__init__.py
--rw-r--r--  2.0 unx    15704 b- defN 24-May-06 08:38 tianmoucv/isp/isp_basic.py
--rw-r--r--  2.0 unx     5569 b- defN 24-May-06 08:38 tianmoucv/isp/transform.py
--rw-r--r--  2.0 unx       96 b- defN 24-May-06 08:38 tianmoucv/nn/__init__.py
--rw-r--r--  2.0 unx       44 b- defN 24-May-06 08:38 tianmoucv/nn/unet_modules.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-06 08:38 tianmoucv/proc/__init__.py
--rw-r--r--  2.0 unx      100 b- defN 24-May-06 08:38 tianmoucv/proc/features/__init__.py
--rw-r--r--  2.0 unx    12268 b- defN 24-May-06 08:38 tianmoucv/proc/features/diff.py
--rw-r--r--  2.0 unx       48 b- defN 24-May-06 08:38 tianmoucv/proc/nn/__init__.py
--rw-r--r--  2.0 unx     5473 b- defN 24-May-06 08:38 tianmoucv/proc/nn/spy_modules.py
--rw-r--r--  2.0 unx     6552 b- defN 24-May-06 08:38 tianmoucv/proc/nn/unet_modules.py
--rw-r--r--  2.0 unx     9995 b- defN 24-May-06 08:38 tianmoucv/proc/nn/utils.py
--rw-r--r--  2.0 unx      177 b- defN 24-May-06 08:38 tianmoucv/proc/opticalflow/__init__.py
--rw-r--r--  2.0 unx     8974 b- defN 24-May-06 08:38 tianmoucv/proc/opticalflow/basic.py
--rw-r--r--  2.0 unx     6043 b- defN 24-May-06 08:38 tianmoucv/proc/opticalflow/estimator.py
--rw-r--r--  2.0 unx     3206 b- defN 24-May-06 08:38 tianmoucv/proc/opticalflow/spy_net.py
--rw-r--r--  2.0 unx      226 b- defN 24-May-06 08:38 tianmoucv/proc/reconstruct/__init__.py
--rw-r--r--  2.0 unx     6884 b- defN 24-May-06 08:38 tianmoucv/proc/reconstruct/basic.py
--rw-r--r--  2.0 unx     2505 b- defN 24-May-06 08:38 tianmoucv/proc/reconstruct/integration.py
--rw-r--r--  2.0 unx     5093 b- defN 24-May-06 08:38 tianmoucv/proc/reconstruct/tiny_unet.py
--rw-r--r--  2.0 unx       80 b- defN 24-May-06 08:38 tianmoucv/proc/tracking/__init__.py
--rw-r--r--  2.0 unx     3078 b- defN 24-May-06 08:38 tianmoucv/proc/tracking/feature_tracker.py
--rw-r--r--  2.0 unx      150 b- defN 24-May-06 08:38 tianmoucv/rdp_pcie/CMakeLists.txt
--rw-r--r--  2.0 unx      283 b- defN 24-May-06 08:38 tianmoucv/rdp_pcie/ReadMe.md
--rw-r--r--  2.0 unx        0 b- defN 24-May-06 08:38 tianmoucv/rdp_pcie/__init__.py
--rw-r--r--  2.0 unx      818 b- defN 24-May-06 08:38 tianmoucv/rdp_pcie/compile_pybind.bat
--rwxr-xr-x  2.0 unx      427 b- defN 24-May-06 08:38 tianmoucv/rdp_pcie/compile_pybind.sh
--rw-r--r--  2.0 unx     2081 b- defN 24-May-06 08:38 tianmoucv/rdp_pcie/lyncam_compact_data.cpp
--rw-r--r--  2.0 unx     2081 b- defN 24-May-06 08:38 tianmoucv/rdp_pcie/rod_compress.cpp
--rw-r--r--  2.0 unx    31884 b- defN 24-May-06 08:38 tianmoucv/rdp_pcie/rod_decoder_py.cpp
--rw-r--r--  2.0 unx      150 b- defN 24-May-06 08:38 tianmoucv/rdp_usb/CMakeLists.txt
--rw-r--r--  2.0 unx      283 b- defN 24-May-06 08:38 tianmoucv/rdp_usb/ReadMe.md
--rw-r--r--  2.0 unx        0 b- defN 24-May-06 08:38 tianmoucv/rdp_usb/__init__.py
--rw-r--r--  2.0 unx      818 b- defN 24-May-06 08:38 tianmoucv/rdp_usb/compile_pybind.bat
--rwxr-xr-x  2.0 unx      427 b- defN 24-May-06 08:38 tianmoucv/rdp_usb/compile_pybind.sh
--rw-r--r--  2.0 unx    72985 b- defN 24-May-06 08:38 tianmoucv/rdp_usb/rod_decoder_py.cpp
--rw-r--r--  2.0 unx      677 b- defN 24-May-06 08:38 tianmoucv/rdp_usb/try_pcie2usb_conv.py
--rw-r--r--  2.0 unx     2505 b- defN 24-May-06 08:38 tianmoucv/rdp_usb/try_usb_data.py
--rw-r--r--  2.0 unx    35149 b- defN 24-May-06 08:40 tianmoucv-0.3.1.dist-info/LICENSE
--rw-r--r--  2.0 unx     2891 b- defN 24-May-06 08:40 tianmoucv-0.3.1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-May-06 08:40 tianmoucv-0.3.1.dist-info/WHEEL
--rw-r--r--  2.0 unx       10 b- defN 24-May-06 08:40 tianmoucv-0.3.1.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     4307 b- defN 24-May-06 08:40 tianmoucv-0.3.1.dist-info/RECORD
-49 files, 315681 bytes uncompressed, 79271 bytes compressed:  74.9%
+Zip file size: 87630 bytes, number of entries: 49
+-rw-r--r--  2.0 unx      355 b- defN 24-May-21 10:56 tianmoucv/__init__.py
+-rw-r--r--  2.0 unx      994 b- defN 24-May-21 10:56 tianmoucv/tools.py
+-rw-r--r--  2.0 unx       99 b- defN 24-May-21 10:56 tianmoucv/data/__init__.py
+-rw-r--r--  2.0 unx    13039 b- defN 24-May-21 10:56 tianmoucv/data/tianmoucData.py
+-rw-r--r--  2.0 unx    26412 b- defN 24-May-21 10:56 tianmoucv/data/tianmoucData_basic.py
+-rw-r--r--  2.0 unx    25949 b- defN 24-May-21 10:56 tianmoucv/data/tianmoucData_pcie.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-21 10:56 tianmoucv/data/blc/__init__.py
+-rw-r--r--  2.0 unx       49 b- defN 24-May-21 10:56 tianmoucv/isp/__init__.py
+-rw-r--r--  2.0 unx     5803 b- defN 24-May-21 10:56 tianmoucv/isp/awb.py
+-rw-r--r--  2.0 unx    15724 b- defN 24-May-21 10:56 tianmoucv/isp/isp_basic.py
+-rw-r--r--  2.0 unx     5569 b- defN 24-May-21 10:56 tianmoucv/isp/transform.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-21 10:56 tianmoucv/proc/__init__.py
+-rw-r--r--  2.0 unx      100 b- defN 24-May-21 10:56 tianmoucv/proc/features/__init__.py
+-rw-r--r--  2.0 unx    12268 b- defN 24-May-21 10:56 tianmoucv/proc/features/diff.py
+-rw-r--r--  2.0 unx       48 b- defN 24-May-21 10:56 tianmoucv/proc/nn/__init__.py
+-rw-r--r--  2.0 unx     5473 b- defN 24-May-21 10:56 tianmoucv/proc/nn/spy_modules.py
+-rw-r--r--  2.0 unx     6550 b- defN 24-May-21 10:56 tianmoucv/proc/nn/unet_modules.py
+-rw-r--r--  2.0 unx    10067 b- defN 24-May-21 10:56 tianmoucv/proc/nn/utils.py
+-rw-r--r--  2.0 unx      154 b- defN 24-May-21 10:56 tianmoucv/proc/opticalflow/__init__.py
+-rw-r--r--  2.0 unx     6140 b- defN 24-May-21 10:56 tianmoucv/proc/opticalflow/basic.py
+-rw-r--r--  2.0 unx     6043 b- defN 24-May-21 10:56 tianmoucv/proc/opticalflow/estimator.py
+-rw-r--r--  2.0 unx     3206 b- defN 24-May-21 10:56 tianmoucv/proc/opticalflow/spy_net.py
+-rw-r--r--  2.0 unx      226 b- defN 24-May-21 10:56 tianmoucv/proc/reconstruct/__init__.py
+-rw-r--r--  2.0 unx     7180 b- defN 24-May-21 10:56 tianmoucv/proc/reconstruct/basic.py
+-rw-r--r--  2.0 unx     2505 b- defN 24-May-21 10:56 tianmoucv/proc/reconstruct/integration.py
+-rw-r--r--  2.0 unx     4942 b- defN 24-May-21 10:56 tianmoucv/proc/reconstruct/tiny_unet.py
+-rw-r--r--  2.0 unx       80 b- defN 24-May-21 10:56 tianmoucv/proc/tracking/__init__.py
+-rw-r--r--  2.0 unx     3078 b- defN 24-May-21 10:56 tianmoucv/proc/tracking/feature_tracker.py
+-rw-r--r--  2.0 unx      150 b- defN 24-May-21 10:56 tianmoucv/rdp_pcie/CMakeLists.txt
+-rw-r--r--  2.0 unx      283 b- defN 24-May-21 10:56 tianmoucv/rdp_pcie/ReadMe.md
+-rw-r--r--  2.0 unx        0 b- defN 24-May-21 10:56 tianmoucv/rdp_pcie/__init__.py
+-rw-r--r--  2.0 unx      818 b- defN 24-May-21 10:56 tianmoucv/rdp_pcie/compile_pybind.bat
+-rwxr-xr-x  2.0 unx      427 b- defN 24-May-21 10:56 tianmoucv/rdp_pcie/compile_pybind.sh
+-rw-r--r--  2.0 unx     2081 b- defN 24-May-21 10:56 tianmoucv/rdp_pcie/lyncam_compact_data.cpp
+-rw-r--r--  2.0 unx     2081 b- defN 24-May-21 10:56 tianmoucv/rdp_pcie/rod_compress.cpp
+-rw-r--r--  2.0 unx    31884 b- defN 24-May-21 10:56 tianmoucv/rdp_pcie/rod_decoder_py.cpp
+-rw-r--r--  2.0 unx      150 b- defN 24-May-21 10:56 tianmoucv/rdp_usb/CMakeLists.txt
+-rw-r--r--  2.0 unx      283 b- defN 24-May-21 10:56 tianmoucv/rdp_usb/ReadMe.md
+-rw-r--r--  2.0 unx        0 b- defN 24-May-21 10:56 tianmoucv/rdp_usb/__init__.py
+-rw-r--r--  2.0 unx      818 b- defN 24-May-21 10:56 tianmoucv/rdp_usb/compile_pybind.bat
+-rwxr-xr-x  2.0 unx      427 b- defN 24-May-21 10:56 tianmoucv/rdp_usb/compile_pybind.sh
+-rw-r--r--  2.0 unx    72985 b- defN 24-May-21 10:56 tianmoucv/rdp_usb/rod_decoder_py.cpp
+-rw-r--r--  2.0 unx      677 b- defN 24-May-21 10:56 tianmoucv/rdp_usb/try_pcie2usb_conv.py
+-rw-r--r--  2.0 unx     2505 b- defN 24-May-21 10:56 tianmoucv/rdp_usb/try_usb_data.py
+-rw-r--r--  2.0 unx    35149 b- defN 24-May-21 10:58 tianmoucv-0.3.2.dist-info/LICENSE
+-rw-r--r--  2.0 unx     2891 b- defN 24-May-21 10:58 tianmoucv-0.3.2.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-May-21 10:58 tianmoucv-0.3.2.dist-info/WHEEL
+-rw-r--r--  2.0 unx       10 b- defN 24-May-21 10:58 tianmoucv-0.3.2.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     4307 b- defN 24-May-21 10:58 tianmoucv-0.3.2.dist-info/RECORD
+49 files, 320071 bytes uncompressed, 80690 bytes compressed:  74.8%
```

## zipnote {}

```diff
@@ -12,27 +12,27 @@
 
 Filename: tianmoucv/data/tianmoucData_basic.py
 Comment: 
 
 Filename: tianmoucv/data/tianmoucData_pcie.py
 Comment: 
 
-Filename: tianmoucv/isp/__init__.py
+Filename: tianmoucv/data/blc/__init__.py
 Comment: 
 
-Filename: tianmoucv/isp/isp_basic.py
+Filename: tianmoucv/isp/__init__.py
 Comment: 
 
-Filename: tianmoucv/isp/transform.py
+Filename: tianmoucv/isp/awb.py
 Comment: 
 
-Filename: tianmoucv/nn/__init__.py
+Filename: tianmoucv/isp/isp_basic.py
 Comment: 
 
-Filename: tianmoucv/nn/unet_modules.py
+Filename: tianmoucv/isp/transform.py
 Comment: 
 
 Filename: tianmoucv/proc/__init__.py
 Comment: 
 
 Filename: tianmoucv/proc/features/__init__.py
 Comment: 
@@ -126,23 +126,23 @@
 
 Filename: tianmoucv/rdp_usb/try_pcie2usb_conv.py
 Comment: 
 
 Filename: tianmoucv/rdp_usb/try_usb_data.py
 Comment: 
 
-Filename: tianmoucv-0.3.1.dist-info/LICENSE
+Filename: tianmoucv-0.3.2.dist-info/LICENSE
 Comment: 
 
-Filename: tianmoucv-0.3.1.dist-info/METADATA
+Filename: tianmoucv-0.3.2.dist-info/METADATA
 Comment: 
 
-Filename: tianmoucv-0.3.1.dist-info/WHEEL
+Filename: tianmoucv-0.3.2.dist-info/WHEEL
 Comment: 
 
-Filename: tianmoucv-0.3.1.dist-info/top_level.txt
+Filename: tianmoucv-0.3.2.dist-info/top_level.txt
 Comment: 
 
-Filename: tianmoucv-0.3.1.dist-info/RECORD
+Filename: tianmoucv-0.3.2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## tianmoucv/__init__.py

```diff
@@ -9,8 +9,8 @@
 
 # __init__.py
 __all__ = ['random', 'cv2', 'math', 'torch','os','sys']
 __author__ = 'Y. Lin'
 __contributor__ = 'T. Wang, Y. Chen'
 __authorEmail__ = '532109881@qq.com'
 
-print('TianMouCV™ 0.3.5, via',__author__,)
+print('TianMouCV™ 0.3.2, via',__author__,' updated on 2024-05-21, new NN ckpts, new isp')
```

## tianmoucv/data/tianmoucData.py

```diff
@@ -22,43 +22,47 @@
 #用于重建
 from tianmoucv.proc.reconstruct import laplacian_blending
 from tianmoucv.isp import default_rgb_isp
 from .tianmoucData_basic import TianmoucDataReader_basic
 
 class TianmoucDataReader(TianmoucDataReader_basic):
     '''
-    - **TianmoucDataReader(0.3.3)**
-        - ## [输入]
+    - TianmoucDataReader注释(0.3.5版本)
+        
+        **输入**
+        
         - 输入dataPath：该路径下应当包含1个或多个子目录，每个子目录对应1段Tianmouc视频。
             - 支持string格式(仅输入1个地址)或list格式(输入1个或多个地址)。
                - 这个地址可以是一个tmdat sample的绝对路径，也可以是数据集的路径
                - 如果是数据集路径(path或者path的任意多层子文件夹内有多个tmdat),可以用matchkey读取特定sample，也可以合并读取
             - 对于单目数据，每个sample下应包含rod和cone两个目录，多目数据额外还有目录rod_N和cone_N，N为相机编号N>=1
             - 双目数据补充：20240201测试结果，在实验过程中重启GUI不会导致两个相机标签交换
                 - 只要不插拔并交换接线，整个数据集中相机的idx将保持不变
         - 输入N：返回的dataset中包含多个sample，每个sample包含(N+1)帧COP，以及中间的所有AOP帧。
             - 默认N=1，在757fps模式下sample中有F0，F1两帧COP，以及中间的(25+1)帧AOP，最后一帧AOP与下一个sample第1帧AOP相同，可以跳过。
         - 输入matchkey：在dataPath所有路径下的子目录名称中匹配对应的，否则会输出所有数据。
             - 若输入超过1个路径，建议不同路径下不要出现同名子目录，否则可能出现bug。
         - 输入camera_idx：默认为0，表示识别单目输入，若为双目数据，则camera_idx=0,1分别录取双目数据。
         - 原先版本中的输入参数MAXLEN强制默认设为-1，即始终为读取全部数据。
-        - ## [输出]
+        
+        **输出**
+        
         - 输出dataset调用方式类似于列表，通过sample = dataset[index]逐一获取数据。
         - sample为字典类型，包含如下key
             - COP帧依次记录为F0，F1，F2...F(N)
-                - 'F0'默认使用ISP算法调色
+                - COP的精确帧率为30.3fps
+                - 'F0'默认使用ISP算法调色, 可以关闭
                 - 'F0_without_isp'不加额外处理，若加红外滤光片应使用这个数据
                 - 'F0_HDR'为简易融合算法处理结果，由同步的SD和RGB合成高动态图
             - AOP帧
-                - 'rawDiff'为AOP像素原始输出(160×160，带空洞)
-                - 'tsdiff_160x320'为rawDiff进行插值去空洞后上采样的图像(160×320)
-                - 'tsdiff'为tsdiff_160x320进一步插值得到的与COP同分辨率的图像(320×640)
+                - 'rawDiff'为AOP像素原始输出(160×160), 为tianmuocv非神经网络预处理接口的输入
+                - 'tsdiff'为rawDiff直接插值得到的与COP同分辨率的图像(320×640), 用于神经网络的输入
                 - 上述三个对应的key_value均为张量格式，torch.Size([3, X, height, width])
                     - 第0个维度为3，分别依次对应TD，SD1，SD2
-                    - 第1个维度对应AOP帧数目，在757fps模式下X=N×25+1
+                    - 第1个维度对应AOP帧数目，在757fps模式下X=N×25+1, 每25帧为一个单位
                     - 第2，3个维度对应AOP帧的分辨率
             - 'sysTimeStamp'为系统初始时间，用于在多目相机情况下进行时间对齐。
                 - 两相机之间初始时间差为sysTimeStamp1-sysTimeStamp2，单位为秒
                 - COP对齐时若Δt>33ms/2，建议让相机1的第K+Δt/33ms帧COP与相机2的第K帧COP对齐，这样时间差更小。
             - 'labels'用于标注HDR，HS，Blur，Noisy等4种极端情况分类，暂未实装。
             - 'meta'包含了该段目录的一些元数据，如文件存储目录，时间戳等等，需要详细数据分析时使用
     '''
@@ -71,30 +75,30 @@
                  cachePath=None,
                  ifcache = False, 
                  speedUpRate=1,
                  ifUniformSampling = False,
                  print_info=True,
                  training=True,
                  strict = True,
-                 rodfilepersample = 25):
+                 dark_level = os.path.dirname(os.path.abspath(__file__))+'/blc/camera605.npz'):
         
         self.N = N
         super().__init__(path,
                  showList=showList,
                  MAXLEN=MAXLEN,
                  camera_idx= camera_idx,
                  matchkey=matchkey,
                  cachePath=cachePath,
                  ifcache = ifcache, 
                  speedUpRate=speedUpRate,
                  ifUniformSampling = ifUniformSampling,
                  print_info=print_info,
                  training=training,
                  strict = strict,
-                 rodfilepersample = rodfilepersample) # 调用父类的属性赋值方法
+                 dark_level = dark_level) # 调用父类的属性赋值方法
         
         print('tianmoucData_multiple.py TODO：add overlap parameter')
             
     #你可以重写这个extration逻辑以获得更复杂的数据读取方法，例如抽帧等        
     def extraction(self,rate,MAXLEN,ifUniformSampling):
         for key in self.fileDict:
             pass
@@ -142,23 +146,22 @@
                 print(key,'origin length:',len(new_legalFileList))
 
     #同理，你也可以通过修改这个函数获得更复杂的数据预处理手段
     def packRead(self,idx,key,ifSync =True, needPreProcess = True):
         '''
         use the decoder and isp preprocess to generate a paired (RGB,n*TSD) sample dict:
         
-            - sample['tsdiff_160x320'] = RAW TSD data ajusted to coorect space(with hollow)
             - sample['tsdiff'] = TSD data upsample to 320*640
+            - sample['rawDiff']: raw TSD data, N*3*160*160, from t=t_0 to t=t+ T ms (T=33 in 757 @ 8 bit  mode)
             - sample['F0_without_isp'] = only demosaced frame data, 3*320*640, t=t_0
             - sample['F1_without_isp'] = only demosaced frame data, 3*320*640, t=t_0
             - sample['F0_HDR']: RGB+SD Blended HDR frame data, 3*320*640, t=t_0
-            - sample['F1_HDR']: RGB+SD Blended HDR frame data, 3*320*640, t=t_0+33ms
+            - sample['F1_HDR']: RGB+SD Blended HDR frame data, 3*320*640, t=t_0+T ms
             - sample['F0']: preprocessed frame data, 3*320*640, t=t_0
-            - sample['F1']: preprocessed frame data, 3*320*640, t=t_0+33ms
-            - sample['rawDiff']: raw TSD data, N*3*160*160, from t=t_0 to t=t+33ms
+            - sample['F1']: preprocessed frame data, 3*320*640, t=t_0+T ms
             - sample['meta']: path infomation and and timestamps for each data
             - sample['labels']: list of labels, if you have one
             - sample['sysTimeStamp']: system time stamp in us, use for multi-sensor sync
         '''       
         sample = dict([])
         metaInfo = dict([])
         legalSample = self.fileDict[key]['legalData'][idx]
@@ -203,36 +206,38 @@
             tsd[2,i,:,:] = torch.Tensor(sdr.astype(np.float32)).view(self.rod_height,self.rod_width)
             metaInfo['R_timestamp'].append(rodTimeStamp.astype(np.int64))
 
         sample['rawDiff'] = tsd
         mingap = (itter-1)//self.N
         if needPreProcess:
             tsdiff_inter  = self.tsd_preprocess(tsd)
-            sample['tsdiff_160x320'] = tsdiff_inter
             tsdiff_resized = F.interpolate(tsdiff_inter,(320,640),mode='bilinear')
             sample['tsdiff'] = tsdiff_resized
             
             for i in range(self.N+1): 
                 frame,frame_without_isp = self.rgb_preprocess(rgb_list[i])
                 frame_raw = raw_list[i]
                 sample['F'+str(i)+'_without_isp'] = frame_without_isp
                 sample['F'+str(i)] = frame
                 sample['F' + str(i)+"_raw"] = frame_raw
                 SD_t = tsd[1:,mingap*i,...]
-                sample['F'+str(i)+'_HDR'] = self.HDRRecon(SD_t/128.0,frame)
+                sample['F'+str(i)+'_HDR'] = self.HDRRecon(SD_t / 128,frame)
         sample['meta'] = metaInfo
         sample['labels'] = legalSample['labels']
         sample['sysTimeStamp'] = legalSample['sysTimeStamp']
+        
+        dataRatio = self.fileDict[key]['dataRatio']
+        sample['dataRatio']= dataRatio
         return sample
     
     def tsd_preprocess(self,tsdiff):
         return self.upsampleTSD_conv(tsdiff)/128.0   
     
     def rgb_preprocess(self,F_raw):
-        F,F_without_isp = default_rgb_isp(F_raw)
+        F,F_without_isp = default_rgb_isp(F_raw,blc=self.blc)
         return F,F_without_isp
  
     def __getitem__(self, index):
         #定位在哪个sample里
         key,relativeIndex = self.locateSample(index)
         sample = self.packRead(relativeIndex, key)
         '''
```

## tianmoucv/data/tianmoucData_basic.py

```diff
@@ -39,30 +39,35 @@
                  ifcache = False, 
                  speedUpRate=1,
                  ifUniformSampling = False,
                  print_info=True,
                  training=True,
                  strict = True,
                  camera_idx= 0,
-                 rodfilepersample = 25):
+                 dark_level = None):
         self.print_info = print_info
 
         modedict = {0:'para',1:'lvds'}
         self.rod_height = 160
         self.rod_width = 160
         self.showList = showList
         self.cone_height = 320
         self.cone_width = 320
         self.rodFileSize = 0
         self.sampleNumDict = dict([])
         self.sampleNum = 0
         self.EXT="tmdat"
-        
-        # a pack contain (RGB,N*TSD), N=25 for default usb module
-        self.rodfilepersample = rodfilepersample
+
+        self.blc = 0
+        if os.path.exists(dark_level):
+            if dark_level.split('.')[-1] == 'npz':
+                self.blc =  np.load(dark_level)['blc']
+            if dark_level.split('.')[-1] == 'npy':
+                self.blc =  np.load(dark_level)
+
         self.training = training
 
         # These buffers are used for fast data decoding
         # Rod buffer
         self.temp_diff_np = np.zeros((1, self.rod_width * self.rod_height), dtype=np.int8)
         self.spat_diff_left_np = np.zeros((1, self.rod_width * self.rod_height), dtype=np.int8)
         self.spat_diff_right_np = np.zeros((1, self.rod_width * self.rod_height), dtype=np.int8)
@@ -202,15 +207,14 @@
             for path in dataset_top:
                 self.find_all_tmdat_file(path,fileDict, camera_idx= camera_idx, matchkey=matchkey)
         elif isinstance(dataset_top,str):
             self.find_all_tmdat_file(dataset_top,fileDict, camera_idx= camera_idx, matchkey=matchkey)
         else:
             print('dataset_top:',dataset_top,' is not list or string')
 
-        #print(fileDict)
             
         keylist = [key for key in fileDict]
         # for each sample, extract all paired data id
 
         for key in keylist:
             labels = []
             labelFileName = os.path.join(key.split('@')[1],key.split('@')[0],'label.csv')
@@ -220,15 +224,48 @@
                     for row in csv_reader:
                         labels.append(row)
             
             #for each sample
             coneFileRawFile = fileDict[key][self.pathways[1]]
             rodFileRawFile = fileDict[key][self.pathways[0]]
             systimeStamp = fileDict[key]['sysTimeStamp']
+            rodfilepersample = 25
+            
+            try:
+                rod_tmdat_path = '/'+os.path.join(*rodFileRawFile.split('/')[:-1])
+                rod_tmdat_path_list = os.listdir(rod_tmdat_path)
+                for meta_file_name in rod_tmdat_path_list:
+                    if meta_file_name.split('.')[-1]=='txt':
+                        with open(os.path.join(rod_tmdat_path,meta_file_name), mode='r', newline='') as file:
+                            lines = file.readlines()
+                            line = lines[1]
+                            # 提取第二行中的四个变量的值
+                            values = line.split(',')
+                            exp_time = int(values[0].split(':')[1].split(' ')[0].strip())
+                            gain = int(values[1].split(':')[1].strip())
+                            rod_mode = int(values[2].split(':')[1].strip())
+                            rod_adc_precision = int(values[3].split(':')[1].strip())
+    
+                            if rod_adc_precision == 8 and rod_mode == 0:
+                                rodfilepersample = 50
+                            if rod_adc_precision == 8 and rod_mode == 1:
+                                rodfilepersample = 25
+                            if rod_adc_precision == 4 and rod_mode == 0:
+                                rodfilepersample = 110
+                            if rod_adc_precision == 4 and rod_mode == 1:
+                                rodfilepersample = 50    
+                            if rod_adc_precision == 2 and rod_mode == 0:
+                                rodfilepersample = 330
+                            if rod_adc_precision == 2 and rod_mode == 1:
+                                rodfilepersample = 110
+            except:
+                #旧文件，默认都是25或者自适应读取
+                pass
 
+                                        
             rodTimeList = []
             coneTimeList = []
             rodcntList = []
             conecntList = []
                 
             #use decoder with C++ backend, generate frame-based data from tmdat compact stream
             rodAddrlist =rdc.construct_frm_list(rodFileRawFile,rodTimeList,rodcntList)
@@ -272,15 +309,15 @@
                         search_index = ridx
                         ridx2 = ridx
                         break
                             
                 # check if satisfy the sample rate 
                 flag = False
                 if strict:
-                    flag = (ridx2 - ridx1 == self.rodfilepersample)
+                    flag = (ridx2 - ridx1 == rodfilepersample)
                 else:
                     flag = ridx2 > ridx1
                         
                 # if it is legal, build a data dict for one pack
                 if flag:
                     legalSample=dict([])
                     legalSample['sysTimeStamp'] = systimeStamp
@@ -292,31 +329,21 @@
                         legalSample['labels'] = labels
                     else:
                         legalSample['labels'] = [['HDR', '0'], ['HS', '0'], 
                                              ['Blur', '0'], ['Noisy', '0']]
                         
                     legalFileList.append(legalSample)
                 else:
+                    if self.print_info:
+                        print('recoreded rod:',ridx2 - ridx1,' expected:',rodfilepersample)
+                        print('if you wish to read all data neglecting data loss, set strict=False for datareader')
                     continue
-                    '''
-                        legalSample structur:
-                            legalSample['meta'] = {'key':key,
-                                               'C0':coneListSorted[coneID],
-                                               'C1':coneListSorted[coneID+1],
-                                               'R0':rodListSorted[rodRange[0]//self.rodfilepersample],
-                                               'R0_bias:':rodRange[0]%self.rodfilepersample,
-                                               'R1':rodListSorted[rodRange[0]//self.rodfilepersample],
-                                               'R1_bias:':rodRange[0]%self.rodfilepersample,
-                                               'C_time': (conetimestamp1,conetimestamp2),
-                                               'R_time': (rodtimestamp1,rodtimestamp2),
-                                               'C/R':self.aopcoprate,
-                                               'RpF':self.rodfilepersample}
-                        '''
+                    
             fileDict[key]['legalData'] = legalFileList
-            fileDict[key]['RpF'] = self.rodfilepersample
+            fileDict[key]['dataRatio'] = rodfilepersample
 
         return fileDict  
               
     
     def extraction(self,rate,MAXLEN,ifUniformSampling):
         '''
         cut the MAXLEN
@@ -364,34 +391,33 @@
                                                             self.cone_width)
         return self.cone_raw.copy(), self.c_img_timestamp_np[0]
 
     def packRead(self,idx,key,ifSync =True, needPreProcess = True):
         '''
         use the decoder and isp preprocess to generate a paired (RGB,n*TSD) sample dict:
         
-            sample['tsdiff_160x320'] = RAW TSD data ajusted to coorect space(with hollow)
-            sample['tsdiff'] = TSD data upsample to 320*640
-            sample['F0_raw'] = unprocessed raw data, 320*320, t=t_0
-            sample['F1_raw'] = unprocessed raw data, 320*320, t=t_0
-            sample['F0_without_isp'] = only demosaced frame data, 3*320*640, t=t_0
-            sample['F1_without_isp'] = only demosaced frame data, 3*320*640, t=t_0
-            sample['F0_HDR']: RGB+SD Blended HDR frame data, 3*320*640, t=t_0
-            sample['F1_HDR']: RGB+SD Blended HDR frame data, 3*320*640, t=t_0+33ms
-            sample['F0']: preprocessed frame data, 3*320*640, t=t_0
-            sample['F1']: preprocessed frame data, 3*320*640, t=t_0+33ms
-            sample['rawDiff']: raw TSD data, N*3*160*160, from t=t_0 to t=t+33ms
-            sample['meta']: path infomation and and timestamps for each data
-            sample['labels']: list of labels, if you have one
-            sample['sysTimeStamp']: system time stamp in us, use for multi-sensor sync
-        '''
+            - sample['tsdiff'] = TSD data upsample to 320*640
+            - sample['rawDiff']: raw TSD data, N*3*160*160, from t=t_0 to t=t+ T ms (T=33 in 757 @ 8 bit  mode)
+            - sample['F0_without_isp'] = only demosaced frame data, 3*320*640, t=t_0
+            - sample['F1_without_isp'] = only demosaced frame data, 3*320*640, t=t_0
+            - sample['F0_HDR']: RGB+SD Blended HDR frame data, 3*320*640, t=t_0
+            - sample['F1_HDR']: RGB+SD Blended HDR frame data, 3*320*640, t=t_0+T ms
+            - sample['F0']: preprocessed frame data, 3*320*640, t=t_0
+            - sample['F1']: preprocessed frame data, 3*320*640, t=t_0+T ms
+            - sample['meta']: path infomation and and timestamps for each data
+            - sample['labels']: list of labels, if you have one
+            - sample['sysTimeStamp']: system time stamp in us, use for multi-sensor sync
+        '''       
         sample = dict([])
         metaInfo = dict([])
         legalSample = self.fileDict[key]['legalData'][idx]
         conefilename = self.fileDict[key][self.pathways[1]]
         rodfilename  = self.fileDict[key][self.pathways[0]]
+        dataRatio = self.fileDict[key]['dataRatio']
+        
         coneAddrs = legalSample[self.pathways[1]]
         rodAddrs = legalSample[self.pathways[0]]
         
         start_frame_raw,coneTimeStamp1 = self.readConeFast(conefilename,coneAddrs[0])
         end_frame_raw,coneTimeStamp2 = self.readConeFast(conefilename,coneAddrs[1])
         
         start_frame_raw = np.reshape(start_frame_raw.astype(np.float32),(self.cone_height,self.cone_width))
@@ -424,47 +450,48 @@
             if i == 0:
                 SD_0 = tsd[1:,i,...]
             if i == itter - 1:
                 SD_1 = tsd[1:,i,...]
             
         if needPreProcess:
             start_frame,end_frame,tsdiff_inter,F0_without_isp,F1_without_isp  = self.preprocess(start_frame_raw,end_frame_raw,tsd)
-            sample['tsdiff_160x320'] = tsdiff_inter
+            #sample['tsdiff_160x320'] = tsdiff_inter
             tsdiff_resized = F.interpolate(tsdiff_inter,(320,640),mode='bilinear')
             sample['tsdiff'] = tsdiff_resized
             sample['F0_without_isp'] = F0_without_isp
             sample['F1_without_isp'] = F1_without_isp
             sample['F0_HDR'] = self.HDRRecon(SD_0/128.0,start_frame)
             sample['F1_HDR'] = self.HDRRecon(SD_1/128.0,end_frame)
         sample['F0'] = start_frame
         sample['F1'] = end_frame
         sample['rawDiff'] = tsd
         sample['meta'] = metaInfo
         sample['labels'] = legalSample['labels']
         sample['sysTimeStamp'] = legalSample['sysTimeStamp']
+        sample['dataRatio']= dataRatio
         return sample
     
     def HDRRecon(self,SD,F0):
         '''
         HDR fusion
         '''
         F0 = torch.Tensor(F0)
-        Ix,Iy= SD2XY(SD)
+        Ix,Iy= SD2XY(SD)#0-1
         Ix = F.interpolate(torch.Tensor(Ix).unsqueeze(0).unsqueeze(0), size=(320,640), mode='bilinear').squeeze(0).squeeze(0)
         Iy = F.interpolate(torch.Tensor(Iy).unsqueeze(0).unsqueeze(0), size=(320,640), mode='bilinear').squeeze(0).squeeze(0)
         blend_hdr = laplacian_blending(-Ix,-Iy, srcimg=F0, iteration=20, mask_rgb=True, mask_th = 32)
         return blend_hdr
     
     def preprocess(self,F0_raw,F1_raw,tsdiff):
         '''
         use isp in TIANMOUCV
         '''
         ts = time.time()
-        F0,F0_without_isp = default_rgb_isp(F0_raw,origin_demosaic=False)
-        F1,F1_without_isp = default_rgb_isp(F1_raw,origin_demosaic=False)
+        F0,F0_without_isp = default_rgb_isp(F0_raw,blc=self.blc)
+        F1,F1_without_isp = default_rgb_isp(F1_raw,blc=self.blc)
         te1 = time.time()
         tsdiff_inter = self.upsampleTSD_conv(tsdiff)/128.0
         te2 = time.time()
         return F0,F1,tsdiff_inter,F0_without_isp,F1_without_isp
 
     def upsampleTSD_conv(self,tsdiff):
         '''
```

## tianmoucv/isp/isp_basic.py

```diff
@@ -1,19 +1,24 @@
 #基础的一些isp操作与可视化函数，有些和算法的效果绑定
 __author__ = 'Y. Lin'
 __authorEmail__ = '532109881@qq.com'
 import numpy as np
 from scipy.signal import convolve2d
 import cv2
+import torch
+
+from .awb import gray_world_awb, AutoWhiteBalance
 
 ##############################
 #1. 图像基本处理
 #2. 可视化
 ##############################
-def default_rgb_isp(raw,gamma = 1.4, curve_factor = 0.015, saturation_factor = (32,24,48), denoising = False, raw_input = True, origin_demosaic=False):
+raw_awb = AutoWhiteBalance()
+
+def default_rgb_isp(raw, blc = 0, gamma = 0.9, raw_input = True):
     '''
     默认的RGB RAW数据处理流程
     
     - 空洞填补
     - 去马赛克
     - 白平衡
     - 自适应降噪
@@ -21,51 +26,42 @@
     - 自动曲线
     - 自动归一化
 
     注意: 速度非常慢，仅供参考
     '''
     #fill hole
     if raw_input:
+        raw = raw.astype(np.float32)
+        raw = raw - blc
+        raw[raw<0]=0
         raw = lyncam_raw_comp(raw)
-
+        image_demosaic_withoutisp = exp_bayer_to_rgb_conv(raw)
+        
+        blc_avg = np.mean(blc)
+        raw_after_awb = raw_awb(raw,method='GW',blc_avg=blc_avg)
+        raw_after_awb[raw_after_awb>1023]=1023
         #adjust gamma
-        raw_gamma = (raw/1024.0)**(1/gamma)*1024.0
-
-        #antialiasing
-        #aaf = AAF(raw_gamma)
-        #raw_aaf = aaf.execute()
+        raw_gamma = (raw_after_awb/1024.0)**(1/gamma)*1024.0
 
         #demosacing
-        if origin_demosaic:
-            image_demosaic = demosaicing_npy(raw_gamma, 'bggr', 1, 10)
-        else:
-            image_demosaic = exp_bayer_to_rgb_conv(raw_gamma)
-        
+        image_demosaic = exp_bayer_to_rgb_conv(raw_gamma)
     else:
-        image_demosaic = (raw/1024.0)**(1/gamma)*1024.0
-
-    #AWB
-    image = white_balance(image_demosaic.copy(),HSB=1023)
-    
-    image = (image/4.0).astype(np.uint8)
+        image_demosaic_withoutisp = (raw/1024.0)**(1/gamma)*1024.0
+        image_demosaic = gray_world_awb(image_demosaic_withoutisp.copy(),HSB=1023)
     
-    #denoising(a little bit slow,cost 0.8s, while others cost 0.05s)
-    if denoising:
-        image = cv2.fastNlMeansDenoising(image)
-   
     #adjust_saturation
-    image = adjust_saturation(image,saturation_factor)
-    
+    #saturation_factor = (96,128)
+    #image = adjust_saturation(image,saturation_factor)
     #adjust_curve
-    image = adjust_curve(image,curve_factor)
+    #curve_factor = 0.02
+    #image = adjust_curve(image,curve_factor)
 
-    #norm to 0-1
-    image = image.astype(np.float32)/256.0
+    image = image_demosaic.astype(np.float32)
     
-    return image,image_demosaic/1024.0
+    return image/1024.0,image_demosaic_withoutisp/1024.0
             
 
 # ===============================================================
 # ToneMapping
 # ===============================================================
 def ACESToneMapping(color, adapted_lum=1):
     '''
@@ -107,68 +103,39 @@
     # 将YCrCb图像转换回RGB颜色空间
     #print('curve:',np.max(yuv_image))
     yuv_image[yuv_image>255.0]=255.0
     output_image = cv2.cvtColor(yuv_image, cv2.COLOR_YCrCb2BGR)
 
     return output_image
 
-# ===============================================================
-# 白平衡调整——灰度世界假设
-#:param img: cv2.imread读取的图片数据
-#:return: 返回的白平衡结果图片数据
-# ===============================================================
-def white_balance(img,HSB=256):
-    '''
-    白平衡调整——灰度世界假设
-    
-    :param img: cv2.imread读取的图片数据
-    :return: 返回的白平衡结果图片数据
-    
-    '''
-    B, G, R = img[:, :, 0], img[:, :, 1], img[:, :, 2]
-    B_ave, G_ave, R_ave = np.mean(B), np.mean(G), np.mean(R)
-    K = (B_ave + G_ave + R_ave) / 3
-    Kb, Kg, Kr = K / (B_ave+1e-8), K / (G_ave+1e-8), K / (R_ave+1e-8)
-    Ba = (B * Kb)
-    Ga = (G * Kg)
-    Ra = (R * Kr)
-    Ba[Ba>HSB] = HSB
-    Ga[Ga>HSB] = HSB
-    Ra[Ra>HSB] = HSB
-    img[:, :, 0] = Ba
-    img[:, :, 1] = Ga
-    img[:, :, 2] = Ra
-    #print('wb:',np.max(img))
-    return img
 
 
-def adjust_saturation(image, saturation_factor = (48,48,64)):
+def adjust_saturation(image, saturation_factor = (128,256)):
     '''
     
     饱和度调整
      
     :param img: cv2.imread读取的图片数据
     :saturation_factor: 增加饱和度，saturation_factor越大饱和度越大
     :return: 返回的饱和度结果图片数据
     
     '''
 
-    target,threshold,max_value = saturation_factor
+    target,max_value = saturation_factor
 
     # 将图像转换为HSV颜色空间
     hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
     hsv_image = hsv_image.astype(np.float32)
     # 调整饱和度（增加饱和度可以使用更大的值，减少饱和度可以使用更小的值）
     V = hsv_image[:,:,1]
     
     factor = target / (1e-8+np.mean(V))
     V = V * factor
 
-    mask = V > threshold
-    V[mask] = max_value + -np.exp(-(V[mask]-threshold)/((max_value-threshold))) * (max_value-threshold)
+    V = max_value *(1 -np.exp(-V/max_value) )
 
     hsv_image[:,:,1] = V
     
     #print('st:',np.max(hsv_image))
     hsv_image = hsv_image.astype(np.uint8)
     result_image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2BGR)
 
@@ -394,32 +361,64 @@
         red[0::2, 1::2] += grad_v[0::2, 1::2]
         red[1::2, 0::2] += grad_h[1::2, 0::2]
     rgb = np.stack([red, green, blue], -1)
     rgb = np.clip(rgb, 0, max_v)
     return rgb
 
 
-
 # ===============================================================
 # 可视化差分数据
+# bg_color:white/black
 # ===============================================================
-def vizDiff(diff,thresh=0):
+def vizDiff(diff,thresh=0,bg_color='white'):
+
+    if bg_color == 'white':
+        return vizDiff_WBG(diff,thresh=thresh)
+    if bg_color == 'black':
+        return vizDiff_BBG(diff,thresh=thresh)
+    else:
+        print('not implemented,bg_color:white/black')
+        return None
+    return rgb_diff
+    
+# ===============================================================
+# 可视化差分数据(白底)
+# ===============================================================
+def vizDiff_WBG(diff,thresh=0):
     rgb_diff = 0
     w = h = 0
     if len(diff.shape)==2:
         w,h = diff.shape
     else:
         diff = diff[...,0]
         w,h = diff.shape
         
-    rgb_diff = np.ones([3,w,h]) * 255
+    rgb_diff = torch.ones([3,w,h]) * 255
     diff[abs(diff)<thresh] = 0
     rgb_diff[0,...][diff>0] = 0
     rgb_diff[1,...][diff>0] = diff[diff>0]
     rgb_diff[2,...][diff>0] = diff[diff>0]
     rgb_diff[0,...][diff<0] = -diff[diff<0]
     rgb_diff[1,...][diff<0] = 0
     rgb_diff[2,...][diff<0] = -diff[diff<0]
     return rgb_diff
 
 
+# ===============================================================
+# 可视化差分数据(黑底)
+# ===============================================================
+def vizDiff_BBG(diff,thresh=0):
+    rgb_diff = 0
+    w = h = 0
+    if len(diff.shape)==2:
+        w,h = diff.shape
+    else:
+        diff = diff[...,0]
+        w,h = diff.shape
+        
+    rgb_diff = torch.zeros([3,w,h])
+    diff[abs(diff)<thresh] = 0
+    rgb_diff[1,...][diff>0] = diff[diff>0]
+    rgb_diff[2,...][diff<0] = -diff[diff<0]
+    
+    return rgb_diff
```

## tianmoucv/proc/nn/unet_modules.py

```diff
@@ -130,27 +130,25 @@
         x = torch.cat([x2, x1], dim=1)
         x,_ = self.cbam(x)
         x = self.conv2(x)
         
         return x
 
 
-
 class Interp(nn.Module):
     def __init__(self, scale=None, size=None):
         super(Interp, self).__init__()
         self.scale = scale
         self.size = size
 
     def forward(self, x):
         y = F.interpolate(x, self.size, self.scale, mode='bilinear', align_corners=True)
         return y
 
 
-
 #############################
 #  @simpleNN
 #############################
 class UNetRecon(nn.Module):
     def __init__(self, inChannels, outChannels):
         super().__init__()
         # Initialize neural network blocks.
```

## tianmoucv/proc/nn/utils.py

```diff
@@ -4,21 +4,21 @@
 import torch.nn.functional as F
 import cv2
 import numpy as np
 
 def tdiff_split(td_,cdim = 1):
     td_pos = td_.clone()
     td_pos[td_pos<0] = 0
+    td_pos = torch.sum(td_pos,dim=2)
     td_neg = td_.clone()
     td_neg[td_neg>0] = 0
+    td_neg = torch.sum(td_neg,dim=2)
     td = torch.cat([td_pos,td_neg],dim=cdim)
     return td
 
-
-
 segmentation_classes = {0: 'unlabeled', 1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane', 6: 'bus', 7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light', 11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter', 15: 'bench', 16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse', 20: 'sheep', 21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra', 25: 'giraffe', 27: 'backpack', 28: 'umbrella', 31: 'handbag', 32: 'tie', 33: 'suitcase', 34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball', 38: 'kite', 39: 'baseball bat', 40: 'baseball glove', 41: 'skateboard', 42: 'surfboard', 43: 'tennis racket', 44: 'bottle', 46: 'wine glass', 47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon', 51: 'bowl', 52: 'banana', 53: 'apple', 54: 'sandwich', 55: 'orange', 56: 'broccoli', 57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut', 61: 'cake', 62: 'chair', 63: 'couch', 64: 'potted plant', 65: 'bed', 67: 'dining table', 70: 'toilet', 72: 'tv', 73: 'laptop', 74: 'mouse', 75: 'remote', 76: 'keyboard', 77: 'cell phone', 78: 'microwave', 79: 'oven', 80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book', 85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear', 89: 'hair drier', 90: 'toothbrush'}
         
 coco_segmentation_classes_80 = {
     0: 'unlabeled',
     1: 'person',
     2: 'bicycle',
     3: 'car',
```

## tianmoucv/proc/opticalflow/__init__.py

```diff
@@ -1,3 +1,3 @@
 from .estimator import LK_optical_flow,HS_optical_flow
 from .spy_net import TianmoucOF_SpyNet
-from .basic import interpolate_image,flow_to_image,backWarp,opticalDetector_Maxone
+from .basic import interpolate_image,flow_to_image,backWarp
```

## tianmoucv/proc/opticalflow/basic.py

```diff
@@ -182,81 +182,7 @@
         y = 2*(y/self.H - 0.5)
         # stacking X and Y
         grid = torch.stack((x,y), dim=3)
         # Sample pixels using bilinear interpolation.
         imgOut = torch.nn.functional.grid_sample(img, grid)
         return imgOut
 
-# ===============================================================
-# nature论文中用的光流filter
-# ===============================================================
-class opticalDetector_Maxone():
-    
-    def __init__(self,noiseThresh=8,distanceThresh=0.2):
-        self.noiseThresh = noiseThresh
-        self.th = distanceThresh
-        self.accumU = 0
-        self.accumV = 0
-        
-    def __call__(self,sd:torch.Tensor,td:torch.Tensor,ifInterploted = False):
-        
-        td[abs(td)<self.noiseThresh] = 0
-        sd[abs(sd)<self.noiseThresh] = 0
-
-        rawflow = HS_optical_flow(sd,td,ifInterploted = ifInterploted)
-        
-        flow = flow_to_image(rawflow.permute(1,2,0).numpy())
-        
-        flowup = np.zeros([flow.shape[0]*2,flow.shape[1]*2,3])
-        flowup[1::2,1::2,:] = flow/255.0
-        flowup[0::2,1::2,:] = flow/255.0
-        flowup[1::2,0::2,:] = flow/255.0
-        flowup[0::2,0::2,:] = flow/255.0
-
-        #计算平均速度
-        u = rawflow.permute(1,2,0).numpy()[:, :, 0]
-        v = rawflow.permute(1,2,0).numpy()[:, :, 1]
-        uv = [u,v]
-
-        # case相关，去掉u是正的的那些背景光流
-        distance = ((u)**2 + (v)**2) *(u<0)
-        
-        #和平均光流方向之差
-        distance[distance>self.th] = 1
-        distance[distance<self.th] = 0
-        distanceup = np.zeros([flow.shape[0]*2,flow.shape[1]*2])
-
-        # 膨胀
-        kernel = np.ones((3,3),np.uint8)              
-        distance = cv2.dilate(distance,kernel,iterations=3) 
-
-        distanceup[1::2,1::2] = distance * 255.0
-        distanceup[0::2,1::2] = distance * 255.0
-        distanceup[1::2,0::2] = distance * 255.0
-        distanceup[0::2,0::2] = distance * 255.0
-        f = (distanceup).copy().astype(np.uint8)
-        contours,hierarchy = cv2.findContours(f,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
-        cv2.drawContours(f, contours, -1, (0, 255, 255), 2)
-        #找到最大区域并填充
-        area = []
-        box = None
-        for i in range(len(contours)):
-            area.append(cv2.contourArea(contours[i]))
-        if len(area)>0:
-            if np.max(area) < 1200:
-                return None,distanceup,flowup
-            max_idx = np.argmax(area)
-            for i in range(max_idx - 1):
-                cv2.fillConvexPoly(f, contours[max_idx - 1], 0)
-            cv2.fillConvexPoly(f, contours[max_idx], 255)
-            #求最大连通域的中心坐标
-            maxcon = contours[max_idx]
-            x1 = np.min(maxcon[:,:,0])  
-            x2 = np.max(maxcon[:,:,0])  
-            y1 = np.min(maxcon[:,:,1])  
-            y2 = np.max(maxcon[:,:,1])  
-            box = [x1,y1,x2,y2]
-            #print(u[y1//2:y2//2,x1//2:x2//2]>0)
-            #print(u[y1//2:y2//2,x1//2:x2//2],v[y1//2:y2//2,x1//2:x2//2])
-
-        return box,distanceup,flowup
-
```

## tianmoucv/proc/reconstruct/basic.py

```diff
@@ -49,26 +49,35 @@
         lap_blend[:,0,1:-1,1:-1] = lap_blend_old_tmp + grad
         # Check for convergence
         if torch.sum(torch.abs(lap_blend - lap_blend_old)) < 0.1:
             return lap_blend
     # Return the blended image
     return lap_blend
 
+
+def smooth_edges(img):
+    # 自定义5x5 kernel
+    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
+    # 开运算，先腐蚀再膨胀
+    opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel, iterations=1)
+    # 闭运算，先膨胀再腐蚀，使边缘更平滑
+    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel, iterations=1)
+    # 使用高斯滤波进一步平滑边缘
+    blurred = cv2.GaussianBlur(closing, (5, 5), 0)
+    return blurred
+    
 def genMask(gray,th = 24, maxV=255, minV = 0):
     '''
     生成过欠曝区域遮罩
     '''
     gap = maxV- minV
-    mask_ts = ( (gray < (maxV-th)/gap) * (gray > (minV+th)/gap) ).float()
+    mask_ts = (gray < (maxV-th)/gap).float() #( (gray < (maxV-th)/gap) * (gray > (minV+th)/gap) ).float()
     mask_np = mask_ts.cpu().numpy()
     mask_np_b = (mask_np * gap).astype(np.uint8)
-    kernel = np.ones((5,5),np.uint8) * gap
-    kernel[0,4] = kernel[4,0] = kernel[4,4] = kernel[0,0] = 0
-    mask_np_b = cv2.erode(mask_np_b,kernel,iterations = 2)
-    mask_np_b = cv2.dilate(mask_np_b,kernel,iterations = 2)
+    mask_np_b = smooth_edges(mask_np_b)
     mask_np = (mask_np_b>0.5)
     return torch.Tensor(mask_np).to(gray.device).bool()
 
 def laplacian_blending(Ix,Iy,srcimg=None, iteration=20, mask_rgb=False, mask_th = 24):
     '''
     RGB/灰度 HDR 融合重建
 
@@ -143,27 +152,27 @@
                 SD0_batch[rawt,...] = tsdiff[:,1:,0,...]
                 SD1_batch[rawt,...] = tsdiff[:,1:,biast+t,...]
                 F_batch[rawt,...] = F0[:,:,biash:h+biash,biasw:w+biasw]
                     
                 if t == 0 and b == 0:
                     td_batch[rawt,...] = 0
                 else:
-                    TD_0_t = torch.sum(tsdiff[:,0:1,1:t,...],dim=2)
+                    TD_0_t = tsdiff[:,0:1,1:t,...]
                     td = tdiff_split(TD_0_t,cdim=1)#splie pos and neg
                     td_batch[rawt,...] = td
 
             print('finished:',biast,'->',biast+res-1,' ALL:',Ft_batch.size(0))        
             Ft1 = model.forward_batch(F_batch, td_batch,SD0_batch,SD1_batch)
             if not ifsingleDirection and res>=1:
                 for rawt in range(res):#F0->F1-dt
                     t = rawt*speedUpRate
                     SD0_batch[rawt,...] = tsdiff[:,1:,-1,...]
                     SD1_batch[rawt,...] = tsdiff[:,1:,biast+t,...]
                     F_batch[rawt,...] = F1[:,:,biash:h+biash,biasw:w+biasw]
-                    TD_0_t = torch.sum(tsdiff[:,0:1,1:t,...],dim=2)
+                    TD_0_t = tsdiff[:,0:1,1:t,...]
                     td = tdiff_split(TD_0_t,cdim=1)#splie pos and neg
                     td_batch[rawt,...] = td
 
                 print('finished:',biast+t,'->',-1,' ALL:',Ft_batch.size(0))
                 Ft2  = model.forward_batch(F_batch, td_batch,SD0_batch,SD1_batch)
                 Ft1 = (Ft1+Ft2)/2
```

## tianmoucv/proc/reconstruct/tiny_unet.py

```diff
@@ -10,24 +10,22 @@
 from tianmoucv.tools import check_url_or_local_path,download_file
 from tianmoucv.proc.nn.unet_modules import UNetRecon
 from tianmoucv.isp import upsampleTSD
 from tianmoucv.proc.nn.utils import tdiff_split
 
 class TianmoucRecon_tiny(nn.Module):
     '''
-    重建网络
-    权重链接:https://cloud.tsinghua.edu.cn/f/2baddb35cc034d31956e/?dl=1
-    old:https://cloud.tsinghua.edu.cn/f/9d4adcfa7f0245959747/?dl=1
+    重建网络 updated direct 2024-05-15
     '''
     def __init__(self,ckpt_path =None,_optim=True):
         super(TianmoucRecon_tiny, self).__init__()
         current_dir=os.path.dirname(__file__)
         
         if ckpt_path is None:
-            ckpt_path = 'https://cloud.tsinghua.edu.cn/f/2baddb35cc034d31956e/?dl=1'
+            ckpt_path = 'https://cloud.tsinghua.edu.cn/f/dcbaea7004854939b5ec/?dl=1'
         self.reconNet =  UNetRecon(7, 3)
         status = check_url_or_local_path(ckpt_path)
         print('loading..:',ckpt_path)
         if status == 1:
             default_file_name = 'tinyunet_best.ckpt'
             if not os.path.exists(default_file_name):
                 ckpt_path = download_file(url=ckpt_path,file_name=default_file_name)
@@ -82,15 +80,15 @@
             tsdiff = upsampleTSD(tsdiff)
             tsdiff = F.interpolate(tsdiff, size=(h,w), mode='bilinear')
             
         F0 = F0.unsqueeze(0).to(self.device)
         tsdiff = tsdiff.unsqueeze(0).to(self.device)
             
         SD1 = tsdiff[:,1:,t,...]
-        TD_0_t = torch.sum(tsdiff[:,0:1,1:t,...],dim=2)
+        TD_0_t = tsdiff[:,0:1,1:t,...]
         
         TD_0_t = tdiff_split(TD_0_t,cdim=1)#splie pos and neg
 
         I_1_rec = self.reconNet(torch.cat([F0,TD_0_t,SD1],dim=1))#3+1
 
         return I_1_rec 
 
@@ -115,15 +113,15 @@
         tsdiff = tsdiff.unsqueeze(0).to(self.device)#[b,c,n,w,h]
             
         FO_b = torch.stack([F0[0,...]]*n2,dim=0)
         SD1_b = tsdiff[0,1:,:,...].permute(1,0,2,3)
 
         TD_0_t_b = torch.zeros([n2,2,h,w]).to(self.device)
         for n in range(1,n2):
-            td_ = torch.sum(tsdiff[:,0:1,1:n+1,...],dim=2)
+            td_ = tsdiff[:,0:1,1:n+1,...]
             td = tdiff_split(td_,cdim=1)
             TD_0_t_b[n:n+1,...] = td
         
         stime = time.time()
         inputTensor = torch.cat([FO_b,TD_0_t_b,SD1_b],dim=1)
         I_1_rec = self.reconNet(inputTensor)#3+1
         etime = time.time()
```

## Comparing `tianmoucv-0.3.1.dist-info/LICENSE` & `tianmoucv-0.3.2.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `tianmoucv-0.3.1.dist-info/METADATA` & `tianmoucv-0.3.2.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: tianmoucv
-Version: 0.3.1
+Version: 0.3.2
 Summary: Algorithms library for Tianmouc sensor
 Home-page: https://github.com/Tianmouc/tianmoucv
 Author: Yihan Lin,Taoyi Wang
 Author-email: 532109881@qq.com
 Keywords: tianmoucv
 Classifier: Programming Language :: Python :: 3 :: Only
 Classifier: License :: OSI Approved :: MIT License
```

## Comparing `tianmoucv-0.3.1.dist-info/RECORD` & `tianmoucv-0.3.2.dist-info/RECORD`

 * *Files 11% similar despite different names*

```diff
@@ -1,33 +1,33 @@
-tianmoucv/__init__.py,sha256=Wl3hSUN0jn_n2CNNPUpEc4AkUKz81Ea_vGD-q9Veup0,308
+tianmoucv/__init__.py,sha256=YfaBwuGoW-9rvdZvo1Ju6Xj-BdXrJwGHAUVtPMSTvyk,355
 tianmoucv/tools.py,sha256=P_sc--I3XBTABGkX3LBBUv7cLWfeEbivVFBEdsEYshg,994
 tianmoucv/data/__init__.py,sha256=Gdll5DfJKeYwkJuHw_u1pLLKiYn_QSmXOnOaCE6KO5g,99
-tianmoucv/data/tianmoucData.py,sha256=7vutt5-83CimJTqSBtzoPF9FBZX5-P2XZ99B-UfCQvM,12911
-tianmoucv/data/tianmoucData_basic.py,sha256=uEp0F72OCSV0cC4_BmGrvHc0xcjAvauSmTPgWiuR3N0,25238
+tianmoucv/data/tianmoucData.py,sha256=oIPEDH7GPHU5RWsxa0GpWzhrhvhXXqmNcecWLz6JkQg,13039
+tianmoucv/data/tianmoucData_basic.py,sha256=TTDgsZDgt1FF44XKxYmBtPLjCle6IMFupRAbxUy023I,26412
 tianmoucv/data/tianmoucData_pcie.py,sha256=4pBnZfKvW8BTDKKI_Us9P6PawF9yPOHhkYbm5m7rHiA,25949
+tianmoucv/data/blc/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tianmoucv/isp/__init__.py,sha256=ffC5gY5ouq6FBPwKrdl-Mx4a1TBAXh6AQ3YoNBHI5WE,49
-tianmoucv/isp/isp_basic.py,sha256=BbMHKH_OHvvIS7Qs8gLZQi-jTXlAsbK8zocvwZrxOuU,15704
+tianmoucv/isp/awb.py,sha256=cf5PP9kplTsVfWbc15xdKzNmHZKYeWjDeRmwEFg9WE8,5803
+tianmoucv/isp/isp_basic.py,sha256=SypruW1UWqJOVWoHt0it8lij0CHg-rfKOplUWIkiRsU,15724
 tianmoucv/isp/transform.py,sha256=_65L-5avS9Zy_l9BPoKokERiP1dMH9Iui51pxMVWaXI,5569
-tianmoucv/nn/__init__.py,sha256=LwLQY7kq5ZPB3SOk1dJCrh048YKKLofATmpV8TpdxyU,96
-tianmoucv/nn/unet_modules.py,sha256=OTuQyIklMRJ5udTCbmrp16fe5V-Jrw6K0dNj14SwFyg,44
 tianmoucv/proc/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tianmoucv/proc/features/__init__.py,sha256=dapR6YLjhivtcqKz4Wa2rjL2K0SDgWc39fXGiuqnm7g,100
 tianmoucv/proc/features/diff.py,sha256=pkuXURX3TWah4yfLWAE4tMtBSvovp_wcYyHW5D2priA,12268
 tianmoucv/proc/nn/__init__.py,sha256=yGj6rsmkoFfAHbJJKZf9PE-M4fk2l4qTnwn5hUu3K2E,48
 tianmoucv/proc/nn/spy_modules.py,sha256=7OqquWsd4qHXmAiK1L1s1rcC00vCHlVIEPhQmaZw5lE,5473
-tianmoucv/proc/nn/unet_modules.py,sha256=cKbLjvD0lXZ5RI5cWNstYGUOjUIEK_exqV-HT4etV7o,6552
-tianmoucv/proc/nn/utils.py,sha256=7uiFZJbceQNozj3c20UfX89goGETKJmLHTXgla0eW7c,9995
-tianmoucv/proc/opticalflow/__init__.py,sha256=yn60Sonr4M5BbXRV55ttHT72i5RNsCLKh1BBEPE2B3k,177
-tianmoucv/proc/opticalflow/basic.py,sha256=w093VKOl4_oVcFMlGspsGJpdmNIoXBBTHzMcUxPG2b0,8974
+tianmoucv/proc/nn/unet_modules.py,sha256=ywhC0UYPGjAaitc8dK7qEuGeFZ2FgdTZ6IOBKV26xgc,6550
+tianmoucv/proc/nn/utils.py,sha256=gHTF7fzefp99EqULeHzOB0w2B338SJrIcEgIym-pGJw,10067
+tianmoucv/proc/opticalflow/__init__.py,sha256=kv7qcy92jnXhVGqmiqWDzlwAdhIgzcmRKt5EMdsqXy0,154
+tianmoucv/proc/opticalflow/basic.py,sha256=Uv5pevHOZQ21imrAmhofsGGnKLQ_Kh1WFHF_gU7RU6o,6140
 tianmoucv/proc/opticalflow/estimator.py,sha256=3kgYmuPghBqfDTo__sCu7sAUZ7CW6vVnwcJI5j5s7Sw,6043
 tianmoucv/proc/opticalflow/spy_net.py,sha256=3ryvKdoIF7qJDokuMsTIzQ7PvE6jnYXjvtpPYUXuJUU,3206
 tianmoucv/proc/reconstruct/__init__.py,sha256=idwwACWZ2RHrYPwosAak2U-3ZFZOMcoID1eghQB58Ao,226
-tianmoucv/proc/reconstruct/basic.py,sha256=t1_MVTWjK9zDLEaWMXm3X_fFjhdUYwccEwu4wayd6n4,6884
+tianmoucv/proc/reconstruct/basic.py,sha256=ODab9ctJZNe0IA8Rq0l3DXxTqvxnlgYRXxDVTYsC_7M,7180
 tianmoucv/proc/reconstruct/integration.py,sha256=OpY-FX07KR58uDx2j66auitKa_EV1krltKIGjht513o,2505
-tianmoucv/proc/reconstruct/tiny_unet.py,sha256=JGsg_8ch-15we0bCYQd_ZO1VKdfLVX-CgNynvCiTE5Q,5093
+tianmoucv/proc/reconstruct/tiny_unet.py,sha256=bFupbRbBiMfChqMZhI05khXxCwob72DOu_MZ1SQAT2A,4942
 tianmoucv/proc/tracking/__init__.py,sha256=rXQD56kSe1-16MjZVONDRG-_RACeluE50WxCUkO59sI,80
 tianmoucv/proc/tracking/feature_tracker.py,sha256=llMHRotmR-HnU_Ow4QsRP2FcPCQC__95M5VzWS3gBu0,3078
 tianmoucv/rdp_pcie/CMakeLists.txt,sha256=G0ulvvBvLG6rxq9dkwq0bwGnTijAD8ROqUO0PlnqyxM,150
 tianmoucv/rdp_pcie/ReadMe.md,sha256=39wZURwFlop-pB4shl_MPbE4GSqOINos6rUMeOiWTYU,283
 tianmoucv/rdp_pcie/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tianmoucv/rdp_pcie/compile_pybind.bat,sha256=lQl42Zr8yY0YolIwskU2xq2YvVX_NSjaK1hRGBj9h-E,818
 tianmoucv/rdp_pcie/compile_pybind.sh,sha256=axL5AqzbfLwLZOb2rXMMRLNWag8tO9ozt9an4m3y8-c,427
@@ -38,12 +38,12 @@
 tianmoucv/rdp_usb/ReadMe.md,sha256=39wZURwFlop-pB4shl_MPbE4GSqOINos6rUMeOiWTYU,283
 tianmoucv/rdp_usb/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tianmoucv/rdp_usb/compile_pybind.bat,sha256=lQl42Zr8yY0YolIwskU2xq2YvVX_NSjaK1hRGBj9h-E,818
 tianmoucv/rdp_usb/compile_pybind.sh,sha256=axL5AqzbfLwLZOb2rXMMRLNWag8tO9ozt9an4m3y8-c,427
 tianmoucv/rdp_usb/rod_decoder_py.cpp,sha256=zIzuNepeKVAvw5KIDqqFvTpcryxKbjsF5sicT_vKu4g,72985
 tianmoucv/rdp_usb/try_pcie2usb_conv.py,sha256=-6mB7yQNipbE4jhzU4c6fLT3Fm28d6MS6NtTrrH7fOg,677
 tianmoucv/rdp_usb/try_usb_data.py,sha256=_TU9O4ew-80bvYWp2rd_aCVRctAWU3iZFKrpLsVbRdI,2505
-tianmoucv-0.3.1.dist-info/LICENSE,sha256=OXLcl0T2SZ8Pmy2_dmlvKuetivmyPd5m1q-Gyd-zaYY,35149
-tianmoucv-0.3.1.dist-info/METADATA,sha256=nFX-NHt-5GZBtHIjmwgRfFjaDU2kGKslRo1slXZBA9A,2891
-tianmoucv-0.3.1.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-tianmoucv-0.3.1.dist-info/top_level.txt,sha256=G30zBqK-scBLtrBY5-F4Og4o4mRKBcrX9O2sLLUrXUE,10
-tianmoucv-0.3.1.dist-info/RECORD,,
+tianmoucv-0.3.2.dist-info/LICENSE,sha256=OXLcl0T2SZ8Pmy2_dmlvKuetivmyPd5m1q-Gyd-zaYY,35149
+tianmoucv-0.3.2.dist-info/METADATA,sha256=fMS-E5ZQI2zOt4td--b6YLpv1NsJmyWzqXpWmDMdF7o,2891
+tianmoucv-0.3.2.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+tianmoucv-0.3.2.dist-info/top_level.txt,sha256=G30zBqK-scBLtrBY5-F4Og4o4mRKBcrX9O2sLLUrXUE,10
+tianmoucv-0.3.2.dist-info/RECORD,,
```

