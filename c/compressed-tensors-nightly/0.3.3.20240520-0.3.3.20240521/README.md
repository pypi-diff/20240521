# Comparing `tmp/compressed_tensors_nightly-0.3.3.20240520-py3-none-any.whl.zip` & `tmp/compressed_tensors_nightly-0.3.3.20240521-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,45 +1,45 @@
-Zip file size: 62875 bytes, number of entries: 43
--rw-r--r--  2.0 unx      789 b- defN 24-May-20 00:03 compressed_tensors/__init__.py
--rw-r--r--  2.0 unx      755 b- defN 24-May-20 00:03 compressed_tensors/base.py
--rw-r--r--  2.0 unx     1512 b- defN 24-May-20 00:03 compressed_tensors/version.py
--rw-r--r--  2.0 unx      992 b- defN 24-May-20 00:03 compressed_tensors/compressors/__init__.py
--rw-r--r--  2.0 unx     2134 b- defN 24-May-20 00:03 compressed_tensors/compressors/base.py
--rw-r--r--  2.0 unx     1257 b- defN 24-May-20 00:03 compressed_tensors/compressors/dense.py
--rw-r--r--  2.0 unx     5403 b- defN 24-May-20 00:03 compressed_tensors/compressors/helpers.py
--rw-r--r--  2.0 unx     4744 b- defN 24-May-20 00:03 compressed_tensors/compressors/int_quantized.py
--rw-r--r--  2.0 unx    10426 b- defN 24-May-20 00:03 compressed_tensors/compressors/model_compressor.py
--rw-r--r--  2.0 unx     7885 b- defN 24-May-20 00:03 compressed_tensors/compressors/pack_quantized.py
--rw-r--r--  2.0 unx     8637 b- defN 24-May-20 00:03 compressed_tensors/compressors/sparse_bitmask.py
--rw-r--r--  2.0 unx      704 b- defN 24-May-20 00:03 compressed_tensors/config/__init__.py
--rw-r--r--  2.0 unx     1454 b- defN 24-May-20 00:03 compressed_tensors/config/base.py
--rw-r--r--  2.0 unx     1317 b- defN 24-May-20 00:03 compressed_tensors/config/dense.py
--rw-r--r--  2.0 unx     1308 b- defN 24-May-20 00:03 compressed_tensors/config/sparse_bitmask.py
--rw-r--r--  2.0 unx      760 b- defN 24-May-20 00:03 compressed_tensors/quantization/__init__.py
--rw-r--r--  2.0 unx     4360 b- defN 24-May-20 00:03 compressed_tensors/quantization/quant_args.py
--rw-r--r--  2.0 unx     8042 b- defN 24-May-20 00:03 compressed_tensors/quantization/quant_config.py
--rw-r--r--  2.0 unx     1480 b- defN 24-May-20 00:03 compressed_tensors/quantization/quant_scheme.py
--rw-r--r--  2.0 unx      798 b- defN 24-May-20 00:03 compressed_tensors/quantization/lifecycle/__init__.py
--rw-r--r--  2.0 unx     7625 b- defN 24-May-20 00:03 compressed_tensors/quantization/lifecycle/apply.py
--rw-r--r--  2.0 unx     1776 b- defN 24-May-20 00:03 compressed_tensors/quantization/lifecycle/calibration.py
--rw-r--r--  2.0 unx     2247 b- defN 24-May-20 00:03 compressed_tensors/quantization/lifecycle/compressed.py
--rw-r--r--  2.0 unx    11373 b- defN 24-May-20 00:03 compressed_tensors/quantization/lifecycle/forward.py
--rw-r--r--  2.0 unx     1726 b- defN 24-May-20 00:03 compressed_tensors/quantization/lifecycle/frozen.py
--rw-r--r--  2.0 unx     3697 b- defN 24-May-20 00:03 compressed_tensors/quantization/lifecycle/initialize.py
--rw-r--r--  2.0 unx      745 b- defN 24-May-20 00:03 compressed_tensors/quantization/observers/__init__.py
--rw-r--r--  2.0 unx     5156 b- defN 24-May-20 00:03 compressed_tensors/quantization/observers/base.py
--rw-r--r--  2.0 unx     2166 b- defN 24-May-20 00:03 compressed_tensors/quantization/observers/helpers.py
--rw-r--r--  2.0 unx     1859 b- defN 24-May-20 00:03 compressed_tensors/quantization/observers/memoryless.py
--rw-r--r--  2.0 unx     3071 b- defN 24-May-20 00:03 compressed_tensors/quantization/observers/min_max.py
--rw-r--r--  2.0 unx      656 b- defN 24-May-20 00:03 compressed_tensors/quantization/utils/__init__.py
--rw-r--r--  2.0 unx     6017 b- defN 24-May-20 00:03 compressed_tensors/quantization/utils/helpers.py
--rw-r--r--  2.0 unx      658 b- defN 24-May-20 00:03 compressed_tensors/registry/__init__.py
--rw-r--r--  2.0 unx    11890 b- defN 24-May-20 00:03 compressed_tensors/registry/registry.py
--rw-r--r--  2.0 unx      665 b- defN 24-May-20 00:03 compressed_tensors/utils/__init__.py
--rw-r--r--  2.0 unx     1735 b- defN 24-May-20 00:03 compressed_tensors/utils/helpers.py
--rw-r--r--  2.0 unx     8502 b- defN 24-May-20 00:03 compressed_tensors/utils/safetensors_load.py
--rw-r--r--  2.0 unx    11357 b- defN 24-May-20 00:05 compressed_tensors_nightly-0.3.3.20240520.dist-info/LICENSE
--rw-r--r--  2.0 unx     5633 b- defN 24-May-20 00:05 compressed_tensors_nightly-0.3.3.20240520.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-May-20 00:05 compressed_tensors_nightly-0.3.3.20240520.dist-info/WHEEL
--rw-r--r--  2.0 unx       19 b- defN 24-May-20 00:05 compressed_tensors_nightly-0.3.3.20240520.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     4376 b- defN 24-May-20 00:05 compressed_tensors_nightly-0.3.3.20240520.dist-info/RECORD
-43 files, 157798 bytes uncompressed, 55607 bytes compressed:  64.8%
+Zip file size: 62668 bytes, number of entries: 43
+-rw-r--r--  2.0 unx      789 b- defN 24-May-21 00:03 compressed_tensors/__init__.py
+-rw-r--r--  2.0 unx      755 b- defN 24-May-21 00:03 compressed_tensors/base.py
+-rw-r--r--  2.0 unx     1512 b- defN 24-May-21 00:03 compressed_tensors/version.py
+-rw-r--r--  2.0 unx      992 b- defN 24-May-21 00:03 compressed_tensors/compressors/__init__.py
+-rw-r--r--  2.0 unx     2134 b- defN 24-May-21 00:03 compressed_tensors/compressors/base.py
+-rw-r--r--  2.0 unx     1257 b- defN 24-May-21 00:03 compressed_tensors/compressors/dense.py
+-rw-r--r--  2.0 unx     5403 b- defN 24-May-21 00:03 compressed_tensors/compressors/helpers.py
+-rw-r--r--  2.0 unx     4744 b- defN 24-May-21 00:03 compressed_tensors/compressors/int_quantized.py
+-rw-r--r--  2.0 unx    10426 b- defN 24-May-21 00:03 compressed_tensors/compressors/model_compressor.py
+-rw-r--r--  2.0 unx     7885 b- defN 24-May-21 00:03 compressed_tensors/compressors/pack_quantized.py
+-rw-r--r--  2.0 unx     8637 b- defN 24-May-21 00:03 compressed_tensors/compressors/sparse_bitmask.py
+-rw-r--r--  2.0 unx      704 b- defN 24-May-21 00:03 compressed_tensors/config/__init__.py
+-rw-r--r--  2.0 unx     1454 b- defN 24-May-21 00:03 compressed_tensors/config/base.py
+-rw-r--r--  2.0 unx     1317 b- defN 24-May-21 00:03 compressed_tensors/config/dense.py
+-rw-r--r--  2.0 unx     1308 b- defN 24-May-21 00:03 compressed_tensors/config/sparse_bitmask.py
+-rw-r--r--  2.0 unx      760 b- defN 24-May-21 00:03 compressed_tensors/quantization/__init__.py
+-rw-r--r--  2.0 unx     4360 b- defN 24-May-21 00:03 compressed_tensors/quantization/quant_args.py
+-rw-r--r--  2.0 unx     8042 b- defN 24-May-21 00:03 compressed_tensors/quantization/quant_config.py
+-rw-r--r--  2.0 unx     1480 b- defN 24-May-21 00:03 compressed_tensors/quantization/quant_scheme.py
+-rw-r--r--  2.0 unx      798 b- defN 24-May-21 00:03 compressed_tensors/quantization/lifecycle/__init__.py
+-rw-r--r--  2.0 unx     7625 b- defN 24-May-21 00:03 compressed_tensors/quantization/lifecycle/apply.py
+-rw-r--r--  2.0 unx     1776 b- defN 24-May-21 00:03 compressed_tensors/quantization/lifecycle/calibration.py
+-rw-r--r--  2.0 unx     2247 b- defN 24-May-21 00:03 compressed_tensors/quantization/lifecycle/compressed.py
+-rw-r--r--  2.0 unx    10520 b- defN 24-May-21 00:03 compressed_tensors/quantization/lifecycle/forward.py
+-rw-r--r--  2.0 unx     1726 b- defN 24-May-21 00:03 compressed_tensors/quantization/lifecycle/frozen.py
+-rw-r--r--  2.0 unx     3697 b- defN 24-May-21 00:03 compressed_tensors/quantization/lifecycle/initialize.py
+-rw-r--r--  2.0 unx      745 b- defN 24-May-21 00:03 compressed_tensors/quantization/observers/__init__.py
+-rw-r--r--  2.0 unx     4900 b- defN 24-May-21 00:03 compressed_tensors/quantization/observers/base.py
+-rw-r--r--  2.0 unx     2166 b- defN 24-May-21 00:03 compressed_tensors/quantization/observers/helpers.py
+-rw-r--r--  2.0 unx     2045 b- defN 24-May-21 00:03 compressed_tensors/quantization/observers/memoryless.py
+-rw-r--r--  2.0 unx     2861 b- defN 24-May-21 00:03 compressed_tensors/quantization/observers/min_max.py
+-rw-r--r--  2.0 unx      656 b- defN 24-May-21 00:03 compressed_tensors/quantization/utils/__init__.py
+-rw-r--r--  2.0 unx     6017 b- defN 24-May-21 00:03 compressed_tensors/quantization/utils/helpers.py
+-rw-r--r--  2.0 unx      658 b- defN 24-May-21 00:03 compressed_tensors/registry/__init__.py
+-rw-r--r--  2.0 unx    11890 b- defN 24-May-21 00:03 compressed_tensors/registry/registry.py
+-rw-r--r--  2.0 unx      665 b- defN 24-May-21 00:03 compressed_tensors/utils/__init__.py
+-rw-r--r--  2.0 unx     1735 b- defN 24-May-21 00:03 compressed_tensors/utils/helpers.py
+-rw-r--r--  2.0 unx     8502 b- defN 24-May-21 00:03 compressed_tensors/utils/safetensors_load.py
+-rw-r--r--  2.0 unx    11357 b- defN 24-May-21 00:20 compressed_tensors_nightly-0.3.3.20240521.dist-info/LICENSE
+-rw-r--r--  2.0 unx     5633 b- defN 24-May-21 00:20 compressed_tensors_nightly-0.3.3.20240521.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-May-21 00:20 compressed_tensors_nightly-0.3.3.20240521.dist-info/WHEEL
+-rw-r--r--  2.0 unx       19 b- defN 24-May-21 00:20 compressed_tensors_nightly-0.3.3.20240521.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     4376 b- defN 24-May-21 00:20 compressed_tensors_nightly-0.3.3.20240521.dist-info/RECORD
+43 files, 156665 bytes uncompressed, 55400 bytes compressed:  64.6%
```

## zipnote {}

```diff
@@ -108,23 +108,23 @@
 
 Filename: compressed_tensors/utils/helpers.py
 Comment: 
 
 Filename: compressed_tensors/utils/safetensors_load.py
 Comment: 
 
-Filename: compressed_tensors_nightly-0.3.3.20240520.dist-info/LICENSE
+Filename: compressed_tensors_nightly-0.3.3.20240521.dist-info/LICENSE
 Comment: 
 
-Filename: compressed_tensors_nightly-0.3.3.20240520.dist-info/METADATA
+Filename: compressed_tensors_nightly-0.3.3.20240521.dist-info/METADATA
 Comment: 
 
-Filename: compressed_tensors_nightly-0.3.3.20240520.dist-info/WHEEL
+Filename: compressed_tensors_nightly-0.3.3.20240521.dist-info/WHEEL
 Comment: 
 
-Filename: compressed_tensors_nightly-0.3.3.20240520.dist-info/top_level.txt
+Filename: compressed_tensors_nightly-0.3.3.20240521.dist-info/top_level.txt
 Comment: 
 
-Filename: compressed_tensors_nightly-0.3.3.20240520.dist-info/RECORD
+Filename: compressed_tensors_nightly-0.3.3.20240521.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## compressed_tensors/quantization/lifecycle/forward.py

```diff
@@ -146,15 +146,14 @@
     do_dequantize: bool = True,
 ) -> torch.Tensor:
     bit_range = 2**args.num_bits
     q_max = torch.tensor(bit_range / 2 - 1, device=x.device)
     q_min = torch.tensor(-bit_range / 2, device=x.device)
     group_size = args.group_size
 
-    # group
     if args.strategy == QuantizationStrategy.GROUP:
 
         if do_dequantize:  # if dequantizing the output should be a fp type
             output = torch.zeros_like(x, dtype=scale.dtype)
         else:
             output_dtype = dtype if dtype is not None else x.dtype
             output = torch.zeros_like(x, dtype=output_dtype)
@@ -191,37 +190,15 @@
                 input = (
                     output[:, idx : (idx + group_size)]
                     if do_quantize
                     else x[:, idx : (idx + group_size)]
                 )
                 output[:, idx : (idx + group_size)] = _dequantize(input, sc, zp)
 
-    # channel-wise
-    elif args.strategy == QuantizationStrategy.CHANNEL:  # group_size == -1
-        if do_quantize:
-            output = _quantize(x, scale, zero_point, q_min, q_max, dtype=dtype)
-        if do_dequantize:
-            output = _dequantize(output if do_quantize else x, scale, zero_point)
-
-    # per-token
-    elif args.strategy == QuantizationStrategy.TOKEN:
-        # before: scale shape = [num_tokens]
-        # after: scale shape = [num_tokens, 1]
-        # x.shape = 1, num_tokens, 1]
-        # scale gets broadcasted as expected withput having [1, num_tokens, 1] shape
-
-        scale = scale.unsqueeze(1)
-        zero_point = zero_point.unsqueeze(1)
-
-        if do_quantize:
-            output = _quantize(x, scale, zero_point, q_min, q_max, dtype=dtype)
-        if do_dequantize:
-            output = _dequantize(output if do_quantize else x, scale, zero_point)
-
-    else:
+    else:  # covers channel, token and tensor strategies
         if do_quantize:
             output = _quantize(x, scale, zero_point, q_min, q_max, dtype=dtype)
         if do_dequantize:
             output = _dequantize(output if do_quantize else x, scale, zero_point)
 
     return output
```

## compressed_tensors/quantization/observers/base.py

```diff
@@ -46,17 +46,24 @@
         maps directly to get_qparams
         :param observed: optional observed tensor to calculate quantization parameters
             from
         :return: tuple of scale and zero point based on last observed value
         """
         return self.get_qparams(observed=observed)
 
-    def calculate_qparams(self, observed: Tensor) -> Tuple[FloatTensor, IntTensor]:
+    def calculate_qparams(
+        self,
+        observed: Tensor,
+        reduce_dims: Optional[Tuple[int]] = None,
+    ) -> Tuple[FloatTensor, IntTensor]:
         """
         :param observed: observed tensor to calculate quantization parameters for
+        :param reduce_dims: optional tuple of dimensions to reduce along,
+            returned scale and zero point will be shaped (1,) along the
+            reduced dimensions
         :return: tuple of scale and zero point derived from the observed tensor
         """
         raise NotImplementedError(f"{self.__class__} must implement calculate_qparams")
 
     def post_calculate_qparams(self) -> None:
         """
         Run any logic specific to its observers after running calculate_qparams
@@ -66,14 +73,15 @@
     def get_qparams(
         self, observed: Optional[Tensor] = None
     ) -> Tuple[FloatTensor, IntTensor]:
         """
         Convenience function to wrap overwritten calculate_qparams
         adds support to make observed tensor optional and support for tracking latest
         calculated scale and zero point
+
         :param observed: optional observed tensor to calculate quantization parameters
             from
         :return: tuple of scale and zero point based on last observed value
         """
         if observed is not None:
             group_size = self.quantization_args.group_size
 
@@ -96,35 +104,18 @@
                 self._zero_point = torch.stack(zero_points, dim=1, out=self._zero_point)
 
             elif self.quantization_args.strategy == QuantizationStrategy.CHANNEL:
                 # assume observed is transposed, because its the output, hence use dim 0
                 self._scale, self._zero_point = self.get_qparams_along_dim(observed, 0)
 
             elif self.quantization_args.strategy == QuantizationStrategy.TOKEN:
-
                 # use dim 1, assume the obsersed.shape = [batch, token, hidden]
                 # should be batch, token
-
                 self._scale, self._zero_point = self.get_qparams_along_dim(
                     observed, dim=1
                 )
 
         return self._scale, self._zero_point
 
     def get_qparams_along_dim(self, observed, dim: int):
-        # TODO: add documentation that specifies the shape must
-        #   be padded with 1-dims so the scales are along the right channel
-        # TODO: generalize the logic for reduce_dims
-        scales, zero_points = [], []
-
-        # TODO: make a more generic way to get the channel
-        num_dims = observed.shape[dim]
-
-        for dim_idx in range(num_dims):
-            scale, zero_point = self.calculate_qparams(
-                observed.select(dim=dim, index=dim_idx)
-            )
-
-            scales.append(scale)
-            zero_points.append(zero_point)
-        # breakpoint()
-        return torch.stack(scales), torch.stack(zero_points)
+        reduce_dims = tuple(idx for idx in range(observed.ndim) if idx != dim)
+        return self.calculate_qparams(observed, reduce_dims=reduce_dims)
```

## compressed_tensors/quantization/observers/memoryless.py

```diff
@@ -8,15 +8,15 @@
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from typing import Tuple
+from typing import Optional, Tuple
 
 import torch
 from compressed_tensors.quantization.observers.base import Observer
 from compressed_tensors.quantization.observers.helpers import calculate_qparams
 from torch import FloatTensor, IntTensor, Tensor
 
 
@@ -26,23 +26,29 @@
 @Observer.register("memoryless", alias=["dynamic"])
 class MemorylessObserver(Observer):
     """
     Implements a quantization observer that sets the scale and
     zero point based on the latest observed value without tracking state
     """
 
-    def calculate_qparams(self, observed: Tensor) -> Tuple[FloatTensor, IntTensor]:
+    def calculate_qparams(
+        self,
+        observed: Tensor,
+        reduce_dims: Optional[Tuple[int]] = None,
+    ) -> Tuple[FloatTensor, IntTensor]:
         """
-        Returns the min and max values of observed
+        Returns the min and max values of observed tensor
 
         :param observed: observed tensor to calculate quantization parameters for
+        :param reduce_dims: optional tuple of dimensions to reduce along,
+            returned scale and zero point will be shaped (1,) along the
+            reduced dimensions
         :return: tuple of scale and zero point derived from the observed tensor
         """
-        # TODO: Add support for full range of quantization Args, only supports 8bit
-        #       per tensor
-        min_val, max_val = torch.aminmax(observed)
-
-        # ensure zero is in the range
-        min_val = torch.min(min_val, torch.zeros_like(min_val))
-        max_val = torch.max(max_val, torch.zeros_like(max_val))
+
+        if not reduce_dims:
+            min_val, max_val = torch.aminmax(observed)
+        else:
+            min_val = torch.amin(observed, dim=reduce_dims, keepdims=True)
+            max_val = torch.amax(observed, dim=reduce_dims, keepdims=True)
 
         return calculate_qparams(min_val, max_val, self.quantization_args)
```

## compressed_tensors/quantization/observers/min_max.py

```diff
@@ -70,11 +70,7 @@
                 min_val - self.min_val
             )
             self.max_val = self.max_val + self.averaging_constant * (
                 max_val - self.max_val
             )
 
         return calculate_qparams(self.min_val, self.max_val, self.quantization_args)
-
-    def get_qparams_along_dim(self, observed, dim: int):
-        reduce_dims = tuple(idx for idx in range(observed.ndim) if idx != dim)
-        return self.calculate_qparams(observed, reduce_dims=reduce_dims)
```

## Comparing `compressed_tensors_nightly-0.3.3.20240520.dist-info/LICENSE` & `compressed_tensors_nightly-0.3.3.20240521.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `compressed_tensors_nightly-0.3.3.20240520.dist-info/METADATA` & `compressed_tensors_nightly-0.3.3.20240521.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: compressed-tensors-nightly
-Version: 0.3.3.20240520
+Version: 0.3.3.20240521
 Summary: Library for utilization of compressed safetensors of neural network models
 Home-page: https://github.com/neuralmagic/compressed-tensors
 Author: Neuralmagic, Inc.
 Author-email: support@neuralmagic.com
 License: Apache 2.0
 Description-Content-Type: text/markdown
 License-File: LICENSE
```

## Comparing `compressed_tensors_nightly-0.3.3.20240520.dist-info/RECORD` & `compressed_tensors_nightly-0.3.3.20240521.dist-info/RECORD`

 * *Files 18% similar despite different names*

```diff
@@ -17,27 +17,27 @@
 compressed_tensors/quantization/quant_args.py,sha256=A6b2V8lhsM8Ho8RjlPBQdxRUDNWhqq-ie5E3RR2_GNg,4360
 compressed_tensors/quantization/quant_config.py,sha256=U6oEzheNK1d-0kHARzwepasnmS7HHqU_zGwoDBJ-lxU,8042
 compressed_tensors/quantization/quant_scheme.py,sha256=X3oqmZPiIKtX5tEKKUj-0N6hB68NeiU2b1GcQEQPadQ,1480
 compressed_tensors/quantization/lifecycle/__init__.py,sha256=ggRGWRqhCxCaTTDWRcgTVX3axnS2xV6rc5YvdzK7fSg,798
 compressed_tensors/quantization/lifecycle/apply.py,sha256=whKfNGC_EZm0BC23AP7qWfjRe5OJVWmcZOpX7lryZZc,7625
 compressed_tensors/quantization/lifecycle/calibration.py,sha256=mLns4jlaWmBwOW8Jtlm5bMX-JET1AiZYUBO7qa-XuxI,1776
 compressed_tensors/quantization/lifecycle/compressed.py,sha256=VreB10xPwgSLQQlTu20UCrFpRS--cA7-lx5s7nrPPrg,2247
-compressed_tensors/quantization/lifecycle/forward.py,sha256=sXo7ReS2ehHFwbtwUbhPnsnnj-CZ3iyAZKmUzHxjTKc,11373
+compressed_tensors/quantization/lifecycle/forward.py,sha256=x9JaIX3TK7cb_-0aCOTTYtA4At9l6v5YOY_70GzIeFU,10520
 compressed_tensors/quantization/lifecycle/frozen.py,sha256=h1XYt89MouBTf3jTYLG_6OdFxIu5q2N8tPjsy6J4E6Y,1726
 compressed_tensors/quantization/lifecycle/initialize.py,sha256=U6g9qifSF6pagQZQZEwd-rwWC6uQ_dZXn1wg6nr1Abg,3697
 compressed_tensors/quantization/observers/__init__.py,sha256=DNH31NQYrIBBcmHsMyFA6whh4pbRsLwuNa6L8AeXaGc,745
-compressed_tensors/quantization/observers/base.py,sha256=X7zeeFj42JxP_5dX2XbEGHcqLrkiV53-nJN3qhW2NA8,5156
+compressed_tensors/quantization/observers/base.py,sha256=yIV2bd9PKPZwodgiBTZEco2ARbD3B0rOKDC0MOFluZs,4900
 compressed_tensors/quantization/observers/helpers.py,sha256=JwALNfBYY9Eyl8Q180t0lGh8szumQj8TygfNl-isErs,2166
-compressed_tensors/quantization/observers/memoryless.py,sha256=ZHTPh4aURE8LvHBFaP--HIC2JanMX5-VRdIkE2JHthw,1859
-compressed_tensors/quantization/observers/min_max.py,sha256=s2I40pzTXrVAjIsavNt6TLAl7-qDUmdc43Xd5rb4XAY,3071
+compressed_tensors/quantization/observers/memoryless.py,sha256=Gach22cZLhDms6ueKF56XOiLhyWVIEYIEXRRXP5Nu8I,2045
+compressed_tensors/quantization/observers/min_max.py,sha256=OGrtyn6_sWuTSx5QgUPVKRIiarfWrK9QqXeRXoJQynw,2861
 compressed_tensors/quantization/utils/__init__.py,sha256=VdtEmP0bvuND_IGQnyqUPc5lnFp-1_yD7StKSX4x80w,656
 compressed_tensors/quantization/utils/helpers.py,sha256=NzAH18Cn_-mTAR87y6IlcQU5gC393XSjgNKC9CRkr78,6017
 compressed_tensors/registry/__init__.py,sha256=FwLSNYqfIrb5JD_6OK_MT4_svvKTN_nEhpgQlQvGbjI,658
 compressed_tensors/registry/registry.py,sha256=fxjOjh2wklCvJhQxwofdy-zV8q7MkQ85SLG77nml2iA,11890
 compressed_tensors/utils/__init__.py,sha256=5DrYjoZbaEvSkJcC-GRSbM_RBHVF4tG9gMd3zsJnjLw,665
 compressed_tensors/utils/helpers.py,sha256=h0jfl9drs5FAx40tCHRcVtJqXixB5hT5yq_IG2aY_-w,1735
 compressed_tensors/utils/safetensors_load.py,sha256=wo9UirGrGlenBqZeqotvpCT7D5MEdjCo2J3HeRaIFoU,8502
-compressed_tensors_nightly-0.3.3.20240520.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-compressed_tensors_nightly-0.3.3.20240520.dist-info/METADATA,sha256=MqJ-XF68VE4vB-i1rD-bSHpKzPsCTHW0_JQCkGZbYIw,5633
-compressed_tensors_nightly-0.3.3.20240520.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-compressed_tensors_nightly-0.3.3.20240520.dist-info/top_level.txt,sha256=w2i-GyPs2s1UwVxvutSvN_lM22SXC2hQFBmoMcPnV7Y,19
-compressed_tensors_nightly-0.3.3.20240520.dist-info/RECORD,,
+compressed_tensors_nightly-0.3.3.20240521.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+compressed_tensors_nightly-0.3.3.20240521.dist-info/METADATA,sha256=DTxrrkh-4Wr9G5MAOS_2ILUsgrOIT-RDYi2IiVc13xg,5633
+compressed_tensors_nightly-0.3.3.20240521.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+compressed_tensors_nightly-0.3.3.20240521.dist-info/top_level.txt,sha256=w2i-GyPs2s1UwVxvutSvN_lM22SXC2hQFBmoMcPnV7Y,19
+compressed_tensors_nightly-0.3.3.20240521.dist-info/RECORD,,
```

