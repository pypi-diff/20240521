# Comparing `tmp/pioreactor-24.5.1rc0-py3-none-any.whl.zip` & `tmp/pioreactor-24.5.20rc0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,94 +1,94 @@
-Zip file size: 233961 bytes, number of entries: 92
--rw-r--r--  2.0 unx      117 b- defN 24-May-01 13:20 pioreactor/__init__.py
--rw-r--r--  2.0 unx     5868 b- defN 24-May-01 13:20 pioreactor/config.py
--rw-r--r--  2.0 unx      265 b- defN 24-May-01 13:20 pioreactor/error_codes.py
--rw-r--r--  2.0 unx      958 b- defN 24-May-01 13:20 pioreactor/exc.py
--rw-r--r--  2.0 unx     3854 b- defN 24-May-01 13:20 pioreactor/hardware.py
--rw-r--r--  2.0 unx     6588 b- defN 24-May-01 13:20 pioreactor/logging.py
--rw-r--r--  2.0 unx    15631 b- defN 24-May-01 13:20 pioreactor/mureq.py
--rw-r--r--  2.0 unx    10903 b- defN 24-May-01 13:20 pioreactor/pubsub.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-01 13:20 pioreactor/py.typed
--rw-r--r--  2.0 unx     6361 b- defN 24-May-01 13:20 pioreactor/structs.py
--rw-r--r--  2.0 unx     3304 b- defN 24-May-01 13:20 pioreactor/types.py
--rw-r--r--  2.0 unx     3022 b- defN 24-May-01 13:20 pioreactor/version.py
--rw-r--r--  2.0 unx     5844 b- defN 24-May-01 13:20 pioreactor/whoami.py
--rw-r--r--  2.0 unx      540 b- defN 24-May-01 13:20 pioreactor/actions/__init__.py
--rw-r--r--  2.0 unx     8810 b- defN 24-May-01 13:20 pioreactor/actions/led_intensity.py
--rw-r--r--  2.0 unx     9013 b- defN 24-May-01 13:20 pioreactor/actions/od_blank.py
--rw-r--r--  2.0 unx    24592 b- defN 24-May-01 13:20 pioreactor/actions/od_calibration.py
--rw-r--r--  2.0 unx    19799 b- defN 24-May-01 13:20 pioreactor/actions/pump.py
--rw-r--r--  2.0 unx    22445 b- defN 24-May-01 13:20 pioreactor/actions/pump_calibration.py
--rw-r--r--  2.0 unx    20153 b- defN 24-May-01 13:20 pioreactor/actions/self_test.py
--rw-r--r--  2.0 unx     5339 b- defN 24-May-01 13:20 pioreactor/actions/stirring_calibration.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-01 13:20 pioreactor/actions/leader/__init__.py
--rw-r--r--  2.0 unx     4902 b- defN 24-May-01 13:20 pioreactor/actions/leader/backup_database.py
--rw-r--r--  2.0 unx    25244 b- defN 24-May-01 13:20 pioreactor/actions/leader/experiment_profile.py
--rw-r--r--  2.0 unx     6544 b- defN 24-May-01 13:20 pioreactor/actions/leader/export_experiment_data.py
--rw-r--r--  2.0 unx      146 b- defN 24-May-01 13:20 pioreactor/automations/__init__.py
--rw-r--r--  2.0 unx     1000 b- defN 24-May-01 13:20 pioreactor/automations/base.py
--rw-r--r--  2.0 unx      459 b- defN 24-May-01 13:20 pioreactor/automations/dosing/__init__.py
--rw-r--r--  2.0 unx    29432 b- defN 24-May-01 13:20 pioreactor/automations/dosing/base.py
--rw-r--r--  2.0 unx     1424 b- defN 24-May-01 13:20 pioreactor/automations/dosing/chemostat.py
--rw-r--r--  2.0 unx     1497 b- defN 24-May-01 13:20 pioreactor/automations/dosing/fed_batch.py
--rw-r--r--  2.0 unx     4962 b- defN 24-May-01 13:20 pioreactor/automations/dosing/pid_morbidostat.py
--rw-r--r--  2.0 unx      476 b- defN 24-May-01 13:20 pioreactor/automations/dosing/silent.py
--rw-r--r--  2.0 unx     4936 b- defN 24-May-01 13:20 pioreactor/automations/dosing/turbidostat.py
--rw-r--r--  2.0 unx      510 b- defN 24-May-01 13:20 pioreactor/automations/events/__init__.py
--rw-r--r--  2.0 unx      567 b- defN 24-May-01 13:20 pioreactor/automations/led/__init__.py
--rw-r--r--  2.0 unx    12023 b- defN 24-May-01 13:20 pioreactor/automations/led/base.py
--rw-r--r--  2.0 unx     3875 b- defN 24-May-01 13:20 pioreactor/automations/led/light_dark_cycle.py
--rw-r--r--  2.0 unx      154 b- defN 24-May-01 13:20 pioreactor/automations/temperature/__init__.py
--rw-r--r--  2.0 unx     9317 b- defN 24-May-01 13:20 pioreactor/automations/temperature/base.py
--rw-r--r--  2.0 unx      561 b- defN 24-May-01 13:20 pioreactor/automations/temperature/only_record_temperature.py
--rw-r--r--  2.0 unx     4375 b- defN 24-May-01 13:20 pioreactor/automations/temperature/thermostat.py
--rw-r--r--  2.0 unx      715 b- defN 24-May-01 13:20 pioreactor/background_jobs/__init__.py
--rw-r--r--  2.0 unx    45137 b- defN 24-May-01 13:20 pioreactor/background_jobs/base.py
--rw-r--r--  2.0 unx     7043 b- defN 24-May-01 13:20 pioreactor/background_jobs/dosing_control.py
--rw-r--r--  2.0 unx    22053 b- defN 24-May-01 13:20 pioreactor/background_jobs/growth_rate_calculating.py
--rw-r--r--  2.0 unx     5806 b- defN 24-May-01 13:20 pioreactor/background_jobs/led_control.py
--rw-r--r--  2.0 unx    29930 b- defN 24-May-01 13:20 pioreactor/background_jobs/monitor.py
--rw-r--r--  2.0 unx    52952 b- defN 24-May-01 13:20 pioreactor/background_jobs/od_reading.py
--rw-r--r--  2.0 unx    18124 b- defN 24-May-01 13:20 pioreactor/background_jobs/stirring.py
--rw-r--r--  2.0 unx    26075 b- defN 24-May-01 13:20 pioreactor/background_jobs/temperature_control.py
--rw-r--r--  2.0 unx      605 b- defN 24-May-01 13:20 pioreactor/background_jobs/leader/__init__.py
--rw-r--r--  2.0 unx    16997 b- defN 24-May-01 13:20 pioreactor/background_jobs/leader/mqtt_to_db_streaming.py
--rw-r--r--  2.0 unx     4573 b- defN 24-May-01 13:20 pioreactor/background_jobs/leader/watchdog.py
--rw-r--r--  2.0 unx     1094 b- defN 24-May-01 13:20 pioreactor/background_jobs/subjobs/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-01 13:20 pioreactor/cli/__init__.py
--rw-r--r--  2.0 unx     1408 b- defN 24-May-01 13:20 pioreactor/cli/lazy_group.py
--rw-r--r--  2.0 unx    24433 b- defN 24-May-01 13:20 pioreactor/cli/pio.py
--rw-r--r--  2.0 unx    26918 b- defN 24-May-01 13:20 pioreactor/cli/pios.py
--rw-r--r--  2.0 unx      365 b- defN 24-May-01 13:20 pioreactor/cli/plugins.py
--rw-r--r--  2.0 unx     1949 b- defN 24-May-01 13:20 pioreactor/cli/run.py
--rw-r--r--  2.0 unx      700 b- defN 24-May-01 13:20 pioreactor/cli/workers.py
--rw-r--r--  2.0 unx    10403 b- defN 24-May-01 13:20 pioreactor/cluster_management/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-01 13:20 pioreactor/experiment_profiles/__init__.py
--rw-r--r--  2.0 unx     5488 b- defN 24-May-01 13:20 pioreactor/experiment_profiles/parser.py
--rw-r--r--  2.0 unx     2896 b- defN 24-May-01 13:20 pioreactor/experiment_profiles/profile_struct.py
--rw-r--r--  2.0 unx      197 b- defN 24-May-01 13:20 pioreactor/experiment_profiles/sly/__init__.py
--rw-r--r--  2.0 unx    16273 b- defN 24-May-01 13:20 pioreactor/experiment_profiles/sly/lex.py
--rw-r--r--  2.0 unx    83015 b- defN 24-May-01 13:20 pioreactor/experiment_profiles/sly/yacc.py
--rw-r--r--  2.0 unx     3807 b- defN 24-May-01 13:20 pioreactor/plugin_management/__init__.py
--rw-r--r--  2.0 unx     1439 b- defN 24-May-01 13:20 pioreactor/plugin_management/install_plugin.py
--rw-r--r--  2.0 unx     1123 b- defN 24-May-01 13:20 pioreactor/plugin_management/list_plugins.py
--rw-r--r--  2.0 unx     1782 b- defN 24-May-01 13:20 pioreactor/plugin_management/uninstall_plugin.py
--rw-r--r--  2.0 unx     1194 b- defN 24-May-01 13:20 pioreactor/plugin_management/utils.py
--rw-r--r--  2.0 unx    21578 b- defN 24-May-01 13:20 pioreactor/utils/__init__.py
--rw-r--r--  2.0 unx     4240 b- defN 24-May-01 13:20 pioreactor/utils/adcs.py
--rw-r--r--  2.0 unx     1930 b- defN 24-May-01 13:20 pioreactor/utils/dacs.py
--rw-r--r--  2.0 unx      976 b- defN 24-May-01 13:20 pioreactor/utils/gpio_helpers.py
--rw-r--r--  2.0 unx     3311 b- defN 24-May-01 13:20 pioreactor/utils/math_helpers.py
--rw-r--r--  2.0 unx     5211 b- defN 24-May-01 13:20 pioreactor/utils/mock.py
--rw-r--r--  2.0 unx     3622 b- defN 24-May-01 13:20 pioreactor/utils/networking.py
--rw-r--r--  2.0 unx    10230 b- defN 24-May-01 13:20 pioreactor/utils/pwm.py
--rw-r--r--  2.0 unx     3393 b- defN 24-May-01 13:20 pioreactor/utils/rpi_bad_power.py
--rw-r--r--  2.0 unx     7889 b- defN 24-May-01 13:20 pioreactor/utils/sqlite_worker.py
--rw-r--r--  2.0 unx    18416 b- defN 24-May-01 13:20 pioreactor/utils/streaming_calculations.py
--rw-r--r--  2.0 unx     5827 b- defN 24-May-01 13:20 pioreactor/utils/timing.py
--rw-r--r--  2.0 unx     1067 b- defN 24-May-01 13:20 pioreactor-24.5.1rc0.dist-info/LICENSE
--rw-r--r--  2.0 unx     3721 b- defN 24-May-01 13:20 pioreactor-24.5.1rc0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-May-01 13:20 pioreactor-24.5.1rc0.dist-info/WHEEL
--rw-r--r--  2.0 unx       79 b- defN 24-May-01 13:20 pioreactor-24.5.1rc0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       11 b- defN 24-May-01 13:20 pioreactor-24.5.1rc0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     8447 b- defN 24-May-01 13:20 pioreactor-24.5.1rc0.dist-info/RECORD
-92 files, 800344 bytes uncompressed, 220411 bytes compressed:  72.5%
+Zip file size: 235191 bytes, number of entries: 92
+-rw-r--r--  2.0 unx      117 b- defN 24-May-21 02:12 pioreactor/__init__.py
+-rw-r--r--  2.0 unx     5868 b- defN 24-May-21 02:12 pioreactor/config.py
+-rw-r--r--  2.0 unx      265 b- defN 24-May-21 02:12 pioreactor/error_codes.py
+-rw-r--r--  2.0 unx      958 b- defN 24-May-21 02:12 pioreactor/exc.py
+-rw-r--r--  2.0 unx     3870 b- defN 24-May-21 02:12 pioreactor/hardware.py
+-rw-r--r--  2.0 unx     6784 b- defN 24-May-21 02:12 pioreactor/logging.py
+-rw-r--r--  2.0 unx    15578 b- defN 24-May-21 02:12 pioreactor/mureq.py
+-rw-r--r--  2.0 unx    12814 b- defN 24-May-21 02:12 pioreactor/pubsub.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-21 02:12 pioreactor/py.typed
+-rw-r--r--  2.0 unx     6361 b- defN 24-May-21 02:12 pioreactor/structs.py
+-rw-r--r--  2.0 unx     3304 b- defN 24-May-21 02:12 pioreactor/types.py
+-rw-r--r--  2.0 unx     3023 b- defN 24-May-21 02:12 pioreactor/version.py
+-rw-r--r--  2.0 unx     5968 b- defN 24-May-21 02:12 pioreactor/whoami.py
+-rw-r--r--  2.0 unx      540 b- defN 24-May-21 02:12 pioreactor/actions/__init__.py
+-rw-r--r--  2.0 unx     8810 b- defN 24-May-21 02:12 pioreactor/actions/led_intensity.py
+-rw-r--r--  2.0 unx     9013 b- defN 24-May-21 02:12 pioreactor/actions/od_blank.py
+-rw-r--r--  2.0 unx    24499 b- defN 24-May-21 02:12 pioreactor/actions/od_calibration.py
+-rw-r--r--  2.0 unx    19823 b- defN 24-May-21 02:12 pioreactor/actions/pump.py
+-rw-r--r--  2.0 unx    22352 b- defN 24-May-21 02:12 pioreactor/actions/pump_calibration.py
+-rw-r--r--  2.0 unx    20768 b- defN 24-May-21 02:12 pioreactor/actions/self_test.py
+-rw-r--r--  2.0 unx     5339 b- defN 24-May-21 02:12 pioreactor/actions/stirring_calibration.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-21 02:12 pioreactor/actions/leader/__init__.py
+-rw-r--r--  2.0 unx     4902 b- defN 24-May-21 02:12 pioreactor/actions/leader/backup_database.py
+-rw-r--r--  2.0 unx    25120 b- defN 24-May-21 02:12 pioreactor/actions/leader/experiment_profile.py
+-rw-r--r--  2.0 unx     6544 b- defN 24-May-21 02:12 pioreactor/actions/leader/export_experiment_data.py
+-rw-r--r--  2.0 unx      146 b- defN 24-May-21 02:12 pioreactor/automations/__init__.py
+-rw-r--r--  2.0 unx     1000 b- defN 24-May-21 02:12 pioreactor/automations/base.py
+-rw-r--r--  2.0 unx      459 b- defN 24-May-21 02:12 pioreactor/automations/dosing/__init__.py
+-rw-r--r--  2.0 unx    29432 b- defN 24-May-21 02:12 pioreactor/automations/dosing/base.py
+-rw-r--r--  2.0 unx     1424 b- defN 24-May-21 02:12 pioreactor/automations/dosing/chemostat.py
+-rw-r--r--  2.0 unx     1497 b- defN 24-May-21 02:12 pioreactor/automations/dosing/fed_batch.py
+-rw-r--r--  2.0 unx     4962 b- defN 24-May-21 02:12 pioreactor/automations/dosing/pid_morbidostat.py
+-rw-r--r--  2.0 unx      476 b- defN 24-May-21 02:12 pioreactor/automations/dosing/silent.py
+-rw-r--r--  2.0 unx     4936 b- defN 24-May-21 02:12 pioreactor/automations/dosing/turbidostat.py
+-rw-r--r--  2.0 unx      510 b- defN 24-May-21 02:12 pioreactor/automations/events/__init__.py
+-rw-r--r--  2.0 unx      567 b- defN 24-May-21 02:12 pioreactor/automations/led/__init__.py
+-rw-r--r--  2.0 unx    12023 b- defN 24-May-21 02:12 pioreactor/automations/led/base.py
+-rw-r--r--  2.0 unx     3875 b- defN 24-May-21 02:12 pioreactor/automations/led/light_dark_cycle.py
+-rw-r--r--  2.0 unx      154 b- defN 24-May-21 02:12 pioreactor/automations/temperature/__init__.py
+-rw-r--r--  2.0 unx     9317 b- defN 24-May-21 02:12 pioreactor/automations/temperature/base.py
+-rw-r--r--  2.0 unx      561 b- defN 24-May-21 02:12 pioreactor/automations/temperature/only_record_temperature.py
+-rw-r--r--  2.0 unx     4375 b- defN 24-May-21 02:12 pioreactor/automations/temperature/thermostat.py
+-rw-r--r--  2.0 unx      715 b- defN 24-May-21 02:12 pioreactor/background_jobs/__init__.py
+-rw-r--r--  2.0 unx    46096 b- defN 24-May-21 02:12 pioreactor/background_jobs/base.py
+-rw-r--r--  2.0 unx     7012 b- defN 24-May-21 02:12 pioreactor/background_jobs/dosing_control.py
+-rw-r--r--  2.0 unx    22014 b- defN 24-May-21 02:12 pioreactor/background_jobs/growth_rate_calculating.py
+-rw-r--r--  2.0 unx     5776 b- defN 24-May-21 02:12 pioreactor/background_jobs/led_control.py
+-rw-r--r--  2.0 unx    30216 b- defN 24-May-21 02:12 pioreactor/background_jobs/monitor.py
+-rw-r--r--  2.0 unx    52593 b- defN 24-May-21 02:12 pioreactor/background_jobs/od_reading.py
+-rw-r--r--  2.0 unx    18187 b- defN 24-May-21 02:12 pioreactor/background_jobs/stirring.py
+-rw-r--r--  2.0 unx    26711 b- defN 24-May-21 02:12 pioreactor/background_jobs/temperature_control.py
+-rw-r--r--  2.0 unx      605 b- defN 24-May-21 02:12 pioreactor/background_jobs/leader/__init__.py
+-rw-r--r--  2.0 unx    17024 b- defN 24-May-21 02:12 pioreactor/background_jobs/leader/mqtt_to_db_streaming.py
+-rw-r--r--  2.0 unx     4679 b- defN 24-May-21 02:12 pioreactor/background_jobs/leader/watchdog.py
+-rw-r--r--  2.0 unx     1094 b- defN 24-May-21 02:12 pioreactor/background_jobs/subjobs/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-21 02:12 pioreactor/cli/__init__.py
+-rw-r--r--  2.0 unx     1408 b- defN 24-May-21 02:12 pioreactor/cli/lazy_group.py
+-rw-r--r--  2.0 unx    24386 b- defN 24-May-21 02:12 pioreactor/cli/pio.py
+-rw-r--r--  2.0 unx    27111 b- defN 24-May-21 02:12 pioreactor/cli/pios.py
+-rw-r--r--  2.0 unx      365 b- defN 24-May-21 02:12 pioreactor/cli/plugins.py
+-rw-r--r--  2.0 unx     1949 b- defN 24-May-21 02:12 pioreactor/cli/run.py
+-rw-r--r--  2.0 unx      700 b- defN 24-May-21 02:12 pioreactor/cli/workers.py
+-rw-r--r--  2.0 unx    10326 b- defN 24-May-21 02:12 pioreactor/cluster_management/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-21 02:12 pioreactor/experiment_profiles/__init__.py
+-rw-r--r--  2.0 unx     5945 b- defN 24-May-21 02:12 pioreactor/experiment_profiles/parser.py
+-rw-r--r--  2.0 unx     2896 b- defN 24-May-21 02:12 pioreactor/experiment_profiles/profile_struct.py
+-rw-r--r--  2.0 unx      197 b- defN 24-May-21 02:12 pioreactor/experiment_profiles/sly/__init__.py
+-rw-r--r--  2.0 unx    16273 b- defN 24-May-21 02:12 pioreactor/experiment_profiles/sly/lex.py
+-rw-r--r--  2.0 unx    83015 b- defN 24-May-21 02:12 pioreactor/experiment_profiles/sly/yacc.py
+-rw-r--r--  2.0 unx     3807 b- defN 24-May-21 02:12 pioreactor/plugin_management/__init__.py
+-rw-r--r--  2.0 unx     1439 b- defN 24-May-21 02:12 pioreactor/plugin_management/install_plugin.py
+-rw-r--r--  2.0 unx     1123 b- defN 24-May-21 02:12 pioreactor/plugin_management/list_plugins.py
+-rw-r--r--  2.0 unx     1782 b- defN 24-May-21 02:12 pioreactor/plugin_management/uninstall_plugin.py
+-rw-r--r--  2.0 unx     1194 b- defN 24-May-21 02:12 pioreactor/plugin_management/utils.py
+-rw-r--r--  2.0 unx    21710 b- defN 24-May-21 02:12 pioreactor/utils/__init__.py
+-rw-r--r--  2.0 unx     4348 b- defN 24-May-21 02:12 pioreactor/utils/adcs.py
+-rw-r--r--  2.0 unx     1930 b- defN 24-May-21 02:12 pioreactor/utils/dacs.py
+-rw-r--r--  2.0 unx      976 b- defN 24-May-21 02:12 pioreactor/utils/gpio_helpers.py
+-rw-r--r--  2.0 unx     3311 b- defN 24-May-21 02:12 pioreactor/utils/math_helpers.py
+-rw-r--r--  2.0 unx     5211 b- defN 24-May-21 02:12 pioreactor/utils/mock.py
+-rw-r--r--  2.0 unx     3829 b- defN 24-May-21 02:12 pioreactor/utils/networking.py
+-rw-r--r--  2.0 unx    10498 b- defN 24-May-21 02:12 pioreactor/utils/pwm.py
+-rw-r--r--  2.0 unx     3393 b- defN 24-May-21 02:12 pioreactor/utils/rpi_bad_power.py
+-rw-r--r--  2.0 unx     7889 b- defN 24-May-21 02:12 pioreactor/utils/sqlite_worker.py
+-rw-r--r--  2.0 unx    18416 b- defN 24-May-21 02:12 pioreactor/utils/streaming_calculations.py
+-rw-r--r--  2.0 unx     5827 b- defN 24-May-21 02:12 pioreactor/utils/timing.py
+-rw-r--r--  2.0 unx     1067 b- defN 24-May-21 02:12 pioreactor-24.5.20rc0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     3722 b- defN 24-May-21 02:12 pioreactor-24.5.20rc0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-May-21 02:12 pioreactor-24.5.20rc0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       79 b- defN 24-May-21 02:12 pioreactor-24.5.20rc0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       11 b- defN 24-May-21 02:12 pioreactor-24.5.20rc0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     8453 b- defN 24-May-21 02:12 pioreactor-24.5.20rc0.dist-info/RECORD
+92 files, 805734 bytes uncompressed, 221629 bytes compressed:  72.5%
```

## zipnote {}

```diff
@@ -252,26 +252,26 @@
 
 Filename: pioreactor/utils/streaming_calculations.py
 Comment: 
 
 Filename: pioreactor/utils/timing.py
 Comment: 
 
-Filename: pioreactor-24.5.1rc0.dist-info/LICENSE
+Filename: pioreactor-24.5.20rc0.dist-info/LICENSE
 Comment: 
 
-Filename: pioreactor-24.5.1rc0.dist-info/METADATA
+Filename: pioreactor-24.5.20rc0.dist-info/METADATA
 Comment: 
 
-Filename: pioreactor-24.5.1rc0.dist-info/WHEEL
+Filename: pioreactor-24.5.20rc0.dist-info/WHEEL
 Comment: 
 
-Filename: pioreactor-24.5.1rc0.dist-info/entry_points.txt
+Filename: pioreactor-24.5.20rc0.dist-info/entry_points.txt
 Comment: 
 
-Filename: pioreactor-24.5.1rc0.dist-info/top_level.txt
+Filename: pioreactor-24.5.20rc0.dist-info/top_level.txt
 Comment: 
 
-Filename: pioreactor-24.5.1rc0.dist-info/RECORD
+Filename: pioreactor-24.5.20rc0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## pioreactor/hardware.py

```diff
@@ -140,12 +140,12 @@
     if not is_testing_env():
         from pioreactor.utils.adcs import ADC as ADC_class
     else:
         from pioreactor.utils.mock import Mock_ADC as ADC_class  # type: ignore
 
     slope = 0.134  # from schematic
 
-    adc = ADC_class()
+    adc = ADC_class()  # type: ignore
     return round_to_precision(
         adc.from_raw_to_voltage(adc.read_from_channel(ADC_CHANNEL_FUNCS["aux"])) / slope,
         p=precision,
     )
```

## pioreactor/logging.py

```diff
@@ -1,12 +1,13 @@
 # -*- coding: utf-8 -*-
 from __future__ import annotations
 
 import logging
 from logging import handlers
+from time import sleep
 from typing import TYPE_CHECKING
 
 from json_log_formatter import JSONFormatter  # type: ignore
 
 from pioreactor.config import config
 from pioreactor.exc import NotAssignedAnExperimentError
 from pioreactor.whoami import get_assigned_experiment_name
@@ -105,16 +106,21 @@
         self.retain = retain
         self.mqtt_kwargs = mqtt_kwargs
         self.client = client
 
     def emit(self, record) -> None:
         payload = self.format(record)
 
-        if not self.client.is_connected():
-            return
+        attempts = 0
+        max_attempts = 10
+        while not self.client.is_connected() and attempts < max_attempts:
+            sleep(0.01)
+            attempts += 1
+            if attempts == max_attempts:
+                return
 
         mqtt_msg = self.client.publish(
             self.topic, payload, qos=self.qos, retain=self.retain, **self.mqtt_kwargs
         )
         # if Python exits too quickly, the last msg might never make it to the broker.
         mqtt_msg.wait_for_publish(timeout=2)
```

## pioreactor/mureq.py

```diff
@@ -24,16 +24,14 @@
 from msgspec.json import decode as loads
 from msgspec.json import encode as dumps
 
 
 DEFAULT_TIMEOUT = 15.0
 DEFAULT_UA = "Python/Pioreactor"
 
-JSON_HEADERS = {"Content-Type": "application/json"}
-
 
 def basic_auth(username: str, password: str) -> str:
     from base64 import b64encode
 
     # get(..., headers={ 'Authorization' : f'Basic {basic_auth(username, password)}'})
     token = b64encode(f"{username}:{password}".encode("utf-8")).decode("ascii")
     return token
```

## pioreactor/pubsub.py

```diff
@@ -6,42 +6,26 @@
 import string
 import threading
 from time import sleep
 from typing import Any
 from typing import Callable
 from typing import Optional
 
+from msgspec import Struct
 from msgspec.json import decode as loads
 from paho.mqtt.client import Client as PahoClient
+from paho.mqtt.enums import CallbackAPIVersion
 
+from pioreactor import mureq
 from pioreactor.config import config
+from pioreactor.config import leader_address
 from pioreactor.config import mqtt_address
 from pioreactor.types import MQTTMessage
 
 
-class MQTT_TOPIC:
-    def __init__(self, init: str):
-        self.body = init
-
-    def __truediv__(self, other: str | MQTT_TOPIC) -> MQTT_TOPIC:
-        return MQTT_TOPIC(self.body + "/" + str(other))
-
-    def __str__(self) -> str:
-        return self.body
-
-    def __repr__(self) -> str:
-        return str(self)
-
-    def __iter__(self):
-        return iter(str(self))
-
-
-PIOREACTOR = MQTT_TOPIC("pioreactor")
-
-
 def add_hash_suffix(s: str) -> str:
     """Adds random 4-character hash to the end of a string.
 
     Args:
         s: The string to which the hash should be added.
 
     Returns:
@@ -95,17 +79,17 @@
             from pioreactor.logging import create_logger
             from paho.mqtt.client import connack_string
 
             logger = create_logger("pubsub.create_client", to_mqtt=False)
             logger.error(f"Connection failed with error code {rc=}: {connack_string(rc)}")
 
     client = Client(
-        client_id=add_hash_suffix(client_id)
-        if client_id
-        else "",  # Note: if empty string, paho or mosquitto will autogenerate a good client id.
+        callback_api_version=CallbackAPIVersion.VERSION2,
+        # Note: if empty string, paho or mosquitto will autogenerate a good client id.
+        client_id=add_hash_suffix(client_id) if client_id else "",
         clean_session=clean_session,
         userdata=userdata,
     )
     client.username_pw_set(
         config.get("mqtt", "username", fallback="pioreactor"),
         config.get("mqtt", "password", fallback="raspberry"),
     )
@@ -130,15 +114,15 @@
 
     for retries in range(1, max_connection_attempts + 1):
         try:
             client.connect(hostname, port, keepalive=keepalive)
         except (socket.gaierror, OSError):
             if retries == max_connection_attempts:
                 break
-            sleep(retries * 2)
+            sleep(2 * retries)
         else:
             if not skip_loop:
                 client.loop_start()
             break
     return client
 
 
@@ -193,15 +177,15 @@
     topics: str, list of str
     name:
         Optional: provide a name, and logging will include it.
     """
 
     lock: Optional[threading.Lock]
 
-    def on_connect(client: Client, userdata, flags, rc) -> None:
+    def on_connect(client: Client, userdata, flags, reason_code, properties) -> None:
         client.subscribe(userdata["topics"])
         return
 
     def on_message(client: Client, userdata, message: MQTTMessage) -> None:
         if not allow_retained and message.retain:
             return
 
@@ -338,15 +322,15 @@
         self.experiment = experiment
         # create a bucket for the logs
         self.bucket: list[dict] = []
         # subscribe to the logs
 
         self.client: Client = subscribe_and_callback(
             self._collect_logs_into_bucket,
-            str(PIOREACTOR / self.unit / self.experiment / "logs" / "app"),
+            f"pioreactor/{self.unit}/{self.experiment}/logs/app",
         )
 
     def _collect_logs_into_bucket(self, message):
         # load the message
         log = loads(message.payload)
         # if the log level matches, add it to the bucket
         if log["level"] == self.log_level:
@@ -356,7 +340,56 @@
         return self.bucket
 
     def __exit__(self, *args):
         # stop listening for messages
         self.client.loop_stop()
         # disconnect from the broker
         self.client.disconnect()
+
+
+def get_from_leader(endpoint: str, **kwargs) -> mureq.Response:
+    assert endpoint.startswith("/api/") or endpoint.startswith("api/")
+
+    port = config.getint("ui", "port", fallback=80)
+    proto = config.get("ui", "proto", fallback="http")
+    endpoint = endpoint.removeprefix("/")
+    return mureq.get(f"{proto}://{leader_address}:{port}/{endpoint}", **kwargs)
+
+
+def put_into_leader(
+    endpoint: str, body: bytes | None = None, json: dict | Struct | None = None, **kwargs
+) -> mureq.Response:
+    assert endpoint.startswith("/api/") or endpoint.startswith("api/")
+
+    port = config.getint("ui", "port", fallback=80)
+    proto = config.get("ui", "proto", fallback="http")
+    endpoint = endpoint.removeprefix("/")
+    return mureq.put(f"{proto}://{leader_address}:{port}/{endpoint}", body=body, json=json, **kwargs)
+
+
+def patch_into_leader(
+    endpoint: str, body: bytes | None = None, json: dict | Struct | None = None, **kwargs
+) -> mureq.Response:
+    assert endpoint.startswith("/api/") or endpoint.startswith("api/")
+
+    port = config.getint("ui", "port", fallback=80)
+    proto = config.get("ui", "proto", fallback="http")
+    endpoint = endpoint.removeprefix("/")
+    return mureq.patch(f"{proto}://{leader_address}:{port}/{endpoint}", body=body, json=json, **kwargs)
+
+
+def post_into_leader(
+    endpoint: str, body: bytes | None = None, json: dict | Struct | None = None, **kwargs
+) -> mureq.Response:
+    assert endpoint.startswith("/api/") or endpoint.startswith("api/")
+    port = config.getint("ui", "port", fallback=80)
+    proto = config.get("ui", "proto", fallback="http")
+    endpoint = endpoint.removeprefix("/")
+    return mureq.post(f"{proto}://{leader_address}:{port}/{endpoint}", body=body, json=json, **kwargs)
+
+
+def delete_from_leader(endpoint: str, **kwargs) -> mureq.Response:
+    assert endpoint.startswith("/api/") or endpoint.startswith("api/")
+    port = config.getint("ui", "port", fallback=80)
+    proto = config.get("ui", "proto", fallback="http")
+    endpoint = endpoint.removeprefix("/")
+    return mureq.delete(f"{proto}://{leader_address}:{port}/{endpoint}", **kwargs)
```

## pioreactor/version.py

```diff
@@ -3,15 +3,15 @@
 
 import os
 
 # pioreactor version
 # Append ".dev0" if a dev version
 # Append "rc0" if a rc version
 # No zero padding!
-__version__ = "24.5.1rc0"
+__version__ = "24.5.20rc0"
 
 
 def get_hardware_version() -> tuple[int, int] | tuple[int, int, str]:
     if os.environ.get("HARDWARE") is not None:
         # ex: > HARDWARE=1.1 pio ...
         return int(os.environ["HARDWARE"].split(".")[0]), int(os.environ["HARDWARE"].split(".")[1])
```

## pioreactor/whoami.py

```diff
@@ -35,30 +35,30 @@
 
 @cache
 def get_assigned_experiment_name(unit_name: str) -> str:
     return _get_assigned_experiment_name(unit_name)
 
 
 def _get_assigned_experiment_name(unit_name: str) -> str:
+    from pioreactor.pubsub import get_from_leader
     from pioreactor.logging import create_logger
-    from pioreactor import mureq
 
     if os.environ.get("EXPERIMENT") is not None:
         return os.environ["EXPERIMENT"]
     elif is_testing_env():
         return "_testing_experiment"
 
     from pioreactor.config import leader_address
 
     retries = 6
     exit_reason = ""
 
     for attempt in range(retries):
         try:
-            result = mureq.get(f"http://{leader_address}/api/workers/{unit_name}/experiment")
+            result = get_from_leader(f"/api/workers/{unit_name}/experiment")
             result.raise_for_status()
             data = result.json()
             return data["experiment"]
         except mureq.HTTPErrorStatus as e:
             if e.status_code == 401:
                 # auth error, something is wrong
                 exit_reason = "auth"
@@ -87,26 +87,26 @@
             f"Not able to access experiments in UI. Check http://{leader_address} is online and check network."
         )
     return NO_EXPERIMENT
 
 
 @cache
 def is_active(unit_name: str) -> bool:
-    from pioreactor.config import leader_address
+    from pioreactor.pubsub import get_from_leader
 
     if os.environ.get("ACTIVE") == "1":
         return True
     elif os.environ.get("ACTIVE") == "0":
         return False
 
     if is_testing_env():
         return True
 
     try:
-        result = mureq.get(f"http://{leader_address}/api/workers/{unit_name}")
+        result = get_from_leader(f"/api/workers/{unit_name}")
         result.raise_for_status()
         data = result.json()
         return bool(data["is_active"])
     except mureq.HTTPErrorStatus as e:
         if e.status_code == 404:
             raise NoWorkerFoundError(f"Worker {unit_name} is not present in leader's inventory")
         else:
@@ -165,24 +165,28 @@
 @cache
 def get_pioreactor_version() -> tuple[int, int]:
     if os.environ.get("PIO_VERSION"):
         return version_text_to_tuple(os.environ["PIO_VERSION"])
 
     from pioreactor.config import config
 
-    return version_text_to_tuple(config.get("pioreactor", "version"))  # type: ignore
+    return version_text_to_tuple(config.get("pioreactor", "version", fallback="1.0"))  # type: ignore
 
 
 @cache
-def get_pioreactor_model() -> tuple[str, str]:
+def get_pioreactor_model() -> str:
     from pioreactor.config import config
 
     return config.get("pioreactor", "model")
 
 
+def get_pioreactor_model_and_version() -> str:
+    return f"{get_pioreactor_model()} v{'.'.join(map(str, get_pioreactor_version()))}"
+
+
 def get_image_git_hash() -> str:
     try:
         with open("/home/pioreactor/.pioreactor/.image_info") as f:
             return f.read().strip().split("=")[1]
     except OSError:  # catch FileNotFoundError, PermissionError, and other file-related exceptions
         return "<Failed to fetch>"
```

## pioreactor/actions/od_calibration.py

```diff
@@ -23,16 +23,16 @@
 from pioreactor import structs
 from pioreactor import types as pt
 from pioreactor.background_jobs.od_reading import start_od_reading
 from pioreactor.background_jobs.stirring import start_stirring as stirring
 from pioreactor.background_jobs.stirring import Stirrer
 from pioreactor.config import config
 from pioreactor.config import leader_address
-from pioreactor.mureq import patch
-from pioreactor.mureq import put
+from pioreactor.pubsub import patch_into_leader
+from pioreactor.pubsub import put_into_leader
 from pioreactor.utils import is_pio_job_running
 from pioreactor.utils import local_persistant_storage
 from pioreactor.utils import managed_lifecycle
 from pioreactor.utils.timing import current_utc_datestamp
 from pioreactor.utils.timing import current_utc_datetime
 from pioreactor.whoami import get_testing_experiment_name
 from pioreactor.whoami import get_unit_name
@@ -636,19 +636,15 @@
 
     with local_persistant_storage("od_calibrations") as all_calibrations:
         calibration_result = decode(
             all_calibrations[name], type=structs.subclass_union(structs.ODCalibration)
         )
 
     try:
-        res = put(
-            f"http://{leader_address}/api/calibrations",
-            encode(calibration_result),
-            headers={"Content-Type": "application/json"},
-        )
+        res = put_into_leader("/api/calibrations", json=calibration_result)
         if not res.ok:
             success = False
     except Exception as e:
         print(e)
         success = False
     if not success:
         echo(f"Could not update in database on leader at http://{leader_address}/api/calibrations ❌")
@@ -672,16 +668,16 @@
                 )
             else:
                 old_calibration = None
 
             current_calibrations[angle] = encode(new_calibration)
 
         try:
-            res = patch(
-                f"http://{leader_address}/api/calibrations/{get_unit_name()}/{new_calibration.type}/{new_calibration.name}",
+            res = patch_into_leader(
+                f"/api/calibrations/{get_unit_name()}/{new_calibration.type}/{new_calibration.name}",
                 json={"current": 1},
             )
             if not res.ok:
                 raise Exception
         except Exception:
             echo("Could not update in database on leader ❌")
```

## pioreactor/actions/pump.py

```diff
@@ -252,15 +252,15 @@
 
     if logger is None:
         logger = create_logger(action_name, experiment=experiment, unit=unit)
 
     try:
         pin = _get_pin(pump_type, config)
     except NoOptionError:
-        logger.error(f"Add `{pump_type}` to `PWM` section to config_{unit}.ini.")
+        logger.error(f"Config entry not found. Add `{pump_type}` to `PWM` section to config_{unit}.ini.")
         return 0.0
 
     if calibration is None:
         try:
             calibration = _get_calibration(pump_type)
         except exc.CalibrationError:
             pass
```

## pioreactor/actions/pump_calibration.py

```diff
@@ -25,16 +25,16 @@
 from pioreactor.actions.pump import add_alt_media
 from pioreactor.actions.pump import add_media
 from pioreactor.actions.pump import remove_waste
 from pioreactor.config import config
 from pioreactor.config import leader_address
 from pioreactor.hardware import voltage_in_aux
 from pioreactor.logging import create_logger
-from pioreactor.mureq import patch
-from pioreactor.mureq import put
+from pioreactor.pubsub import patch_into_leader
+from pioreactor.pubsub import put_into_leader
 from pioreactor.utils import local_persistant_storage
 from pioreactor.utils import managed_lifecycle
 from pioreactor.utils.math_helpers import correlation
 from pioreactor.utils.math_helpers import simple_linear_regression_with_forced_nil_intercept
 from pioreactor.utils.timing import current_utc_datestamp
 from pioreactor.utils.timing import current_utc_datetime
 from pioreactor.whoami import get_assigned_experiment_name
@@ -406,19 +406,15 @@
 
     with local_persistant_storage("pump_calibrations") as all_calibrations:
         calibration_result = decode(
             all_calibrations[name], type=structs.subclass_union(structs.PumpCalibration)
         )
 
     try:
-        res = put(
-            f"http://{leader_address}/api/calibrations",
-            encode(calibration_result),
-            headers={"Content-Type": "application/json"},
-        )
+        res = put_into_leader("/api/calibrations", json=calibration_result)
         res.raise_for_status()
     except Exception:
         success = False
     if not success:
         echo(f"❌ Could not publish on leader at http://{leader_address}/api/calibrations")
     return success
 
@@ -579,16 +575,16 @@
                 )
             else:
                 old_calibration = None
 
             current_calibrations[pump_type_from_new_calibration] = encode(new_calibration)
 
         try:
-            res = patch(
-                f"http://{leader_address}/api/calibrations/{get_unit_name()}/{new_calibration.type}/{new_calibration.name}",
+            res = patch_into_leader(
+                f"/api/calibrations/{get_unit_name()}/{new_calibration.type}/{new_calibration.name}",
                 json={"current": 1},
             )
             res.raise_for_status()
         except Exception:
             echo(
                 f"❌ Could not update on leader at http://{leader_address}/api/calibrations/{get_unit_name()}/{new_calibration.type}/{new_calibration.name}"
             )
```

## pioreactor/actions/self_test.py

```diff
@@ -125,15 +125,15 @@
     # upper bound shouldn't be too high, as it could saturate the ADC, and lower bound shouldn't be too low, else we don't detect anything.
 
     # what's up with this order? We originally did a shuffle() of list(range(20, 55, 3))
     # so as to reduce the effects of temperature.
     # the problem is that if an LED is directly across from a PD, a high intensity will quickly
     # saturate it and fail the test. So we try low intensities first, and if we exceed some threshold
     # we exit before moving to the high intensities.
-    INTENSITIES = [20, 23, 26, 53, 44, 38, 35, 29, 47, 50, 32, 41]
+    INTENSITIES = (32, 35, 53, 44, 38, 47, 50, 41, 56, 59, 62, 65)
 
     results: dict[tuple[LedChannel, PdChannel], float] = {}
 
     adc_reader = ADCReader(
         channels=ALL_PD_CHANNELS, dynamic_gain=False, fake_data=is_testing_env(), penalizer=0.0
     )
     adc_reader.setup_adc()
@@ -145,87 +145,94 @@
         {channel: 0 for channel in ALL_LED_CHANNELS},
         unit=unit,
         experiment=experiment,
         verbose=False,
         source_of_event="self_test",
     )
 
-    # for led_channel in ALL_LED_CHANNELS: # we use to check all LED channels, but most users don't need to check all, also https://github.com/Pioreactor/pioreactor/issues/445
-    for led_channel in [ir_led_channel]:  # fast to just check IR
-        varying_intensity_results: dict[PdChannel, list[float]] = {
-            pd_channel: [] for pd_channel in ALL_PD_CHANNELS
-        }
-        for intensity in INTENSITIES:
-            # turn on the LED to set intensity
-            led_intensity(
-                {led_channel: intensity},
-                unit=unit,
-                experiment=experiment,
-                verbose=False,
-                source_of_event="self_test",
-            )
+    with stirring.start_stirring(
+        target_rpm=1250,
+        unit=unit,
+        experiment=experiment,
+    ) as st:
+        st.block_until_rpm_is_close_to_target(abs_tolerance=150, timeout=10)
+        # for led_channel in ALL_LED_CHANNELS: # we use to check all LED channels, but most users don't need to check all, also https://github.com/Pioreactor/pioreactor/issues/445
+        for led_channel in [ir_led_channel]:  # fast to just check IR
+            varying_intensity_results: dict[PdChannel, list[float]] = {
+                pd_channel: [] for pd_channel in ALL_PD_CHANNELS
+            }
+            for intensity in INTENSITIES:
+                # turn on the LED to set intensity
+                led_intensity(
+                    {led_channel: intensity},
+                    unit=unit,
+                    experiment=experiment,
+                    verbose=False,
+                    source_of_event="self_test",
+                )
 
-            # record from ADC, we'll average them
-            avg_reading = average_over_pd_channel_to_voltages(
-                adc_reader.take_reading(), adc_reader.take_reading()
-            )
+                # record from ADC, we'll average them
+                avg_reading = average_over_pd_channel_to_voltages(
+                    adc_reader.take_reading(), adc_reader.take_reading(), adc_reader.take_reading()
+                )
 
-            # Add to accumulating list
-            for pd_channel in ALL_PD_CHANNELS:
-                varying_intensity_results[pd_channel].append(avg_reading[pd_channel])
-
-                if avg_reading[pd_channel] >= 2.0:
-                    # we are probably going to saturate the PD - clearly we are detecting something though!
-                    logger.debug(
-                        f"Saw {avg_reading:.2f} for pair {pd_channel=}, {led_channel=}@{intensity=} . Saturation possible. No solution implemented yet! See issue #445"
-                    )
+                # Add to accumulating list
+                for pd_channel in ALL_PD_CHANNELS:
+                    varying_intensity_results[pd_channel].append(avg_reading[pd_channel])
+
+                    if avg_reading[pd_channel] >= 2.0:
+                        # we are probably going to saturate the PD - clearly we are detecting something though!
+                        logger.debug(
+                            f"Saw {avg_reading[pd_channel]:.2f} for pair pd_channel={pd_channel}, led_channel={led_channel}@intensity={intensity}. Saturation possible. No solution implemented yet! See issue #445"
+                        )
 
         # compute the linear correlation between the intensities and observed PD measurements
         for pd_channel in ALL_PD_CHANNELS:
             measured_correlation = round(correlation(INTENSITIES, varying_intensity_results[pd_channel]), 2)
             results[(led_channel, pd_channel)] = measured_correlation
             logger.debug(f"Corr({led_channel}, {pd_channel}) = {measured_correlation}")
+            logger.debug(list(zip(INTENSITIES, varying_intensity_results[pd_channel])))
 
         # set back to 0
         led_intensity(
             {led_channel: 0},
             unit=unit,
             experiment=experiment,
             verbose=False,
             source_of_event="self_test",
         )
         adc_reader.clear_batched_readings()
 
     logger.debug(f"Correlations between LEDs and PD:\n{pformat(results)}")
     detected_relationships = []
     for (led_channel, pd_channel), measured_correlation in results.items():
-        if measured_correlation > 0.92:
+        if measured_correlation > 0.90:
             detected_relationships.append(
                 (
                     (config["leds"].get(led_channel) or led_channel),
                     (config["od_config.photodiode_channel"].get(pd_channel) or pd_channel),
                 )
             )
 
     client.publish(
-        f"pioreactor/{unit}/{experiment}/self_test/correlations_between_pds_and_leds",
+        f"pioreactor/{unit}/{get_assigned_experiment_name(unit)}/self_test/correlations_between_pds_and_leds",
         dumps(detected_relationships),
         retain=True,
     )
 
     # we require that the IR photodiodes defined in the config have a
     # correlation with the IR led
     pd_channels_to_test: list[PdChannel] = []
     for channel, angle_or_ref in config["od_config.photodiode_channel"].items():
         if angle_or_ref != "":
             channel = cast(PdChannel, channel)
             pd_channels_to_test.append(channel)
 
     for ir_pd_channel in pd_channels_to_test:
-        assert results[(ir_led_channel, ir_pd_channel)] > 0.9, f"missing {ir_led_channel} ⇝ {ir_pd_channel}"
+        assert results[(ir_led_channel, ir_pd_channel)] > 0.90, f"missing {ir_led_channel} ⇝ {ir_pd_channel}"
 
 
 def test_ambient_light_interference(client: Client, logger: CustomLogger, unit: str, experiment: str) -> None:
     # test ambient light IR interference. With all LEDs off, and the Pioreactor not in a sunny room, we should see near 0 light.
     assert is_HAT_present()
     adc_reader = ADCReader(
         channels=ALL_PD_CHANNELS,
@@ -277,16 +284,16 @@
     ):
         samples = []
 
         for i in range(6):
             samples.append(adc_reader.take_reading()[reference_channel])
 
         assert (
-            0.05 < mean(samples) < 0.256
-        ), f"Recorded {mean(samples)} in REF, should ideally be between 0.05 and 0.256. Current IR LED: {ir_intensity}%."
+            0.02 < mean(samples) < 0.256
+        ), f"Recorded {mean(samples):0.3f} in REF, should ideally be between 0.02 and 0.256. Current IR LED: {ir_intensity}%."
 
         # also check for stability: the std. of the reference should be quite low:
         assert variance(samples) < 1e-2, f"Too much noise in REF channel, observed {variance(samples)}."
 
 
 def test_PD_is_near_0_volts_for_blank(
     client: Client, logger: CustomLogger, unit: str, experiment: str
@@ -398,47 +405,48 @@
         measured_correlation = round(correlation(dcs, measured_rpms), 2)
         logger.debug(f"Correlation between stirring RPM and duty cycle: {measured_correlation}")
         logger.debug(f"{dcs=}, {measured_rpms=}")
         assert measured_correlation > 0.9, (dcs, measured_rpms)
 
 
 class BatchTestRunner:
-    def __init__(self, tests_to_run: list[Callable], *test_func_args) -> None:
+    def __init__(self, tests_to_run: list[Callable], *test_func_args, experiment: str) -> None:
         self.count_tested = 0
         self.count_passed = 0
         self.tests_to_run = tests_to_run
+        self.experiment = experiment
         self._thread = Thread(target=self._run, args=test_func_args)  # don't make me daemon: 295
 
     def start(self):
         self._thread.start()
         return self
 
     def collect(self) -> SummableDict:
         self._thread.join()
         return SummableDict({"count_tested": self.count_tested, "count_passed": self.count_passed})
 
-    def _run(self, client, logger: CustomLogger, unit: str, experiment_name: str) -> None:
+    def _run(self, client, logger: CustomLogger, unit: str, testing_experiment: str) -> None:
         for test in self.tests_to_run:
             res = False
             test_name = test.__name__
 
             try:
-                test(client, logger, unit, experiment_name)
+                test(client, logger, unit, testing_experiment)
                 res = True
             except Exception as e:
                 logger.debug(e, exc_info=True)
                 logger.warning(f" in {test_name.replace('_', ' ')}: {e}")
 
             logger.debug(f"{test_name}: {'✅' if res else '❌'}")
 
             self.count_tested += 1
             self.count_passed += int(res)
 
             client.publish(
-                f"pioreactor/{unit}/{experiment_name}/self_test/{test_name}",
+                f"pioreactor/{unit}/{self.experiment}/self_test/{test_name}",
                 int(res),
                 retain=True,
             )
 
 
 @click.command(name="self_test")
 @click.option("-k", help="see pytest's -k argument", type=str)
@@ -447,30 +455,30 @@
     Test the input/output in the Pioreactor
     """
     unit = get_unit_name()
     testing_experiment = get_testing_experiment_name()
     experiment = get_assigned_experiment_name(unit)
     logger = create_logger("self_test", unit=unit, experiment=experiment)
 
-    A_TESTS = [
+    A_TESTS = (
         test_pioreactor_HAT_present,
         test_detect_heating_pcb,
         test_positive_correlation_between_temperature_and_heating,
         test_aux_power_is_not_too_high,
-    ]
-    B_TESTS = [
+    )
+    B_TESTS = (
         test_all_positive_correlations_between_pds_and_leds,
         test_ambient_light_interference,
         test_REF_is_lower_than_0_dot_256_volts,
         test_REF_is_in_correct_position,
         test_PD_is_near_0_volts_for_blank,
         test_positive_correlation_between_rpm_and_stirring,
-    ]
+    )
 
-    with managed_lifecycle(unit, testing_experiment, "self_test") as state:
+    with managed_lifecycle(unit, experiment, "self_test") as state:
         client = state.mqtt_client
         if any(
             is_pio_job_running(
                 ["od_reading", "temperature_control", "stirring", "dosing_control", "led_control"]
             )
         ):
             logger.error(
@@ -489,30 +497,34 @@
         }
 
         logger.info(f"Starting self-test. Running {len(functions_to_test)} tests.")
 
         # and clear the mqtt cache first
         for f in functions_to_test:
             client.publish(
-                f"pioreactor/{unit}/{testing_experiment}/self_test/{f.__name__}",
+                f"pioreactor/{unit}/{experiment}/self_test/{f.__name__}",
                 None,
                 retain=True,
             )
 
         # some tests can be run in parallel.
         test_args = (client, logger, unit, testing_experiment)
-        RunnerA = BatchTestRunner([f for f in A_TESTS if f in functions_to_test], *test_args).start()
-        RunnerB = BatchTestRunner([f for f in B_TESTS if f in functions_to_test], *test_args).start()
+        RunnerA = BatchTestRunner(
+            [f for f in A_TESTS if f in functions_to_test], *test_args, experiment=experiment
+        ).start()
+        RunnerB = BatchTestRunner(
+            [f for f in B_TESTS if f in functions_to_test], *test_args, experiment=experiment
+        ).start()
 
         results = RunnerA.collect() + RunnerB.collect()
         count_tested, count_passed = results["count_tested"], results["count_passed"]
         count_failures = int(count_tested - count_passed)
 
         client.publish(
-            f"pioreactor/{unit}/{testing_experiment}/self_test/all_tests_passed",
+            f"pioreactor/{unit}/{experiment}/self_test/all_tests_passed",
             int(count_failures == 0),
             retain=True,
         )
 
         if count_tested == 0:
             logger.info("No tests ran 🟡")
         elif count_failures == 0:
```

## pioreactor/actions/leader/experiment_profile.py

```diff
@@ -9,20 +9,19 @@
 from typing import Optional
 
 import click
 from msgspec.json import encode
 from msgspec.yaml import decode
 
 from pioreactor.cluster_management import get_active_workers_in_experiment
-from pioreactor.config import leader_address
 from pioreactor.experiment_profiles import profile_struct as struct
 from pioreactor.logging import create_logger
 from pioreactor.logging import CustomLogger
-from pioreactor.mureq import put
 from pioreactor.pubsub import publish
+from pioreactor.pubsub import put_into_leader
 from pioreactor.utils import ClusterJobManager
 from pioreactor.utils import managed_lifecycle
 from pioreactor.utils.timing import current_utc_timestamp
 from pioreactor.whoami import get_assigned_experiment_name
 from pioreactor.whoami import get_unit_name
 
 bool_expression = str | bool
@@ -520,18 +519,16 @@
     assert _verify_experiment_profile(profile), "profile is incorrect"
     return profile
 
 
 def push_labels_to_ui(experiment, labels_map: dict[str, str]) -> None:
     try:
         for unit_name, label in labels_map.items():
-            put(
-                f"http://{leader_address}/api/experiments/{experiment}/unit_labels",
-                encode({"unit": unit_name, "label": label}),
-                headers={"Content-Type": "application/json"},
+            put_into_leader(
+                f"/api/experiments/{experiment}/unit_labels", json={"unit": unit_name, "label": label}
             )
     except Exception:
         pass
 
 
 def get_installed_packages() -> dict[str, str]:
     import pkg_resources
@@ -674,20 +671,20 @@
                 # we can use active workers in experiment, since if a worker leaves an experiment or goes inactive, it's jobs are stopped
                 workers = get_active_workers_in_experiment(experiment)
                 with ClusterJobManager(workers) as jm:
                     jm.kill_jobs(experiment=experiment, job_source="experiment_profile")
 
             else:
                 if dry_run:
-                    logger.notice(  # type: ignore
+                    logger.info(  # type: ignore
                         f"Finished executing DRY-RUN of profile {profile.experiment_profile_name}."
                     )
 
                 else:
-                    logger.notice(f"Finished executing profile {profile.experiment_profile_name}.")  # type: ignore
+                    logger.info(f"Finished executing profile {profile.experiment_profile_name}.")  # type: ignore
 
             state.mqtt_client.publish(
                 f"pioreactor/{unit}/{experiment}/{action_name}/experiment_profile_name",
                 None,
                 retain=True,
             )
             state.mqtt_client.publish(
@@ -707,15 +704,15 @@
     pass
 
 
 @click_experiment_profile.command(name="execute")
 @click.argument("filename", type=click.Path())
 @click.argument("experiment", type=str)
 @click.option("--dry-run", is_flag=True, help="Don't actually execute, just print to screen")
-def click_execute_experiment_profile(filename: str, experiment, dry_run: bool) -> None:
+def click_execute_experiment_profile(filename: str, experiment: str, dry_run: bool) -> None:
     """
     (leader only) Run an experiment profile.
     """
     execute_experiment_profile(filename, experiment, dry_run)
 
 
 @click_experiment_profile.command(name="verify")
```

## pioreactor/background_jobs/base.py

```diff
@@ -18,15 +18,14 @@
 from pioreactor import types as pt
 from pioreactor.config import config
 from pioreactor.config import leader_hostname
 from pioreactor.exc import NotActiveWorkerError
 from pioreactor.logging import create_logger
 from pioreactor.pubsub import Client
 from pioreactor.pubsub import create_client
-from pioreactor.pubsub import MQTT_TOPIC
 from pioreactor.pubsub import QOS
 from pioreactor.pubsub import subscribe
 from pioreactor.utils import append_signal_handlers
 from pioreactor.utils import is_pio_job_running
 from pioreactor.utils import JobManager
 from pioreactor.utils.timing import RepeatedTimer
 from pioreactor.whoami import is_active
@@ -340,14 +339,16 @@
         """
 
         with JobManager() as jm:
             self._jm_key = jm.register_and_set_running(
                 self.unit, self.experiment, self.job_name, self._job_source, getpid(), leader_hostname
             )
 
+        # setting READY should happen after we write to the job manager, since a job might do a long-running
+        # task in on_ready, which delays writing to the db, which means `pio kill` might not see it.
         self.set_state(self.READY)
 
     def start_passive_listeners(self) -> None:
         # overwrite this to in subclasses to subscribe to topics in MQTT
         # using this handles reconnects correctly.
         pass
 
@@ -421,15 +422,15 @@
             payload = dumps(payload)
 
         self.pub_client.publish(topic, payload=payload, **kwargs)
 
     def subscribe_and_callback(
         self,
         callback: t.Callable[[pt.MQTTMessage], None],
-        subscriptions: list[str | MQTT_TOPIC] | str | MQTT_TOPIC,
+        subscriptions: list[str] | str,
         allow_retained: bool = True,
         qos: int = QOS.EXACTLY_ONCE,
     ) -> None:
         """
         Parameters
         -------------
         callback: callable
@@ -588,16 +589,16 @@
             self.logger.info("Reconnected to the MQTT broker on leader.")
             self._publish_properties_string_to_broker(self.published_settings)
             self._publish_settings_metadata_to_broker(self.published_settings)
             self._publish_defined_settings_to_broker(self.published_settings)
             self._start_general_passive_listeners()
             self.start_passive_listeners()
 
-        def on_disconnect(client, userdata, rc: int) -> None:
-            self._on_mqtt_disconnect(client, rc)
+        def on_disconnect(client, userdata, flags, reason_code, properties) -> None:
+            self._on_mqtt_disconnect(client, reason_code)
 
         # we give the last_will to this sub client because when it reconnects, it
         # will republish state.
         last_will = {
             "topic": f"pioreactor/{self.unit}/{self.experiment}/{self.job_name}/$state",
             "payload": self.LOST,
             "qos": QOS.EXACTLY_ONCE,
@@ -621,28 +622,29 @@
             else:
                 break
 
         client.on_connect = reconnect_protocol
         client.on_disconnect = on_disconnect
         return client
 
-    def _on_mqtt_disconnect(self, client, rc: int) -> None:
-        from paho.mqtt import client as mqtt  # type: ignore
+    def _on_mqtt_disconnect(self, client: Client, reason_code: int) -> None:
+        from paho.mqtt.enums import MQTTErrorCode as mqtt
+        from paho.mqtt.client import error_string
 
-        if rc == mqtt.MQTT_ERR_SUCCESS:
+        if reason_code == mqtt.MQTT_ERR_SUCCESS:
             # MQTT_ERR_SUCCESS means that the client disconnected using disconnect()
             self.logger.debug("Disconnected successfully from MQTT.")
 
         # we won't exit, but the client object will try to reconnect
         # Error codes are below, but don't always align
         # https://github.com/eclipse/paho.mqtt.python/blob/42f0b13001cb39aee97c2b60a3b4807314dfcb4d/src/paho/mqtt/client.py#L147
-        elif rc == mqtt.MQTT_ERR_KEEPALIVE:
+        elif reason_code == mqtt.MQTT_ERR_KEEPALIVE:
             self.logger.warning("Lost contact with MQTT server. Is the leader Pioreactor still online?")
         else:
-            self.logger.debug(f"Disconnected from MQTT with {rc=}: {mqtt.error_string(rc)}")
+            self.logger.debug(f"Disconnected from MQTT with {reason_code=}: {error_string(reason_code)}")
         return
 
     def _publish_attr(self, attr: str) -> None:
         """
         Publish the current value of the class attribute `attr` to MQTT.
         """
         if attr == "state":
@@ -667,17 +669,21 @@
                 self.logger.debug(f"Exiting caused by signal {signal.strsignal(reason)}.")
             elif isinstance(reason, str):
                 self.logger.debug(f"Exiting caused by {reason}.")
 
             self.clean_up()
 
             if (reason == signal.SIGTERM) or (reason == getattr(signal, "SIGHUP", None)):
+                # wait for threads to clean up
+                sleep(1)
+
                 import sys
 
                 sys.exit()
+            return
 
         # signals only work in main thread - and if we set state via MQTT,
         # this would run in a thread - so just skip.
         if threading.current_thread() is threading.main_thread():
             atexit.register(exit_gracefully, "Python atexit")
 
             # terminate command, ex: pkill, kill
@@ -909,15 +915,16 @@
 
     def _confirm_state_in_broker(self, message: pt.MQTTMessage) -> None:
         if message.payload is None:
             return
 
         state_in_broker = message.payload.decode()
         if state_in_broker == self.LOST and state_in_broker != self.state:
-            self.logger.debug(f"Wrong state {state_in_broker} in broker - fixing by publishing {self.state}")
+            self.logger.debug(f"Wrong state {state_in_broker} in broker - fixing by publishing {self.state}.")
+            sleep(5)
             self._publish_attr("state")
 
     def _clear_mqtt_cache(self) -> None:
         """
         From homie: Devices can remove old properties and nodes by publishing a zero-length payload on the respective topics.
         Use "persist" to keep it from clearing.
         """
@@ -1047,18 +1054,26 @@
     sneak_in_timer: RepeatedTimer
     is_after_period: bool = False
 
     def __init__(self, *args, source="app", **kwargs) -> None:
         super().__init__(*args, source=source, **kwargs)  # type: ignore
 
         self.add_to_published_settings("enable_dodging_od", {"datatype": "boolean", "settable": True})
-        self.set_enable_dodging_od(bool(self.get_from_config("enable_dodging_od", fallback=True)))
+        self.set_enable_dodging_od(self.get_from_config("enable_dodging_od", cast=bool, fallback="True"))
 
-    def get_from_config(self, key, **get_kwargs):
-        return config.get(f"{self.job_name}.config", key, **get_kwargs)
+    def get_from_config(self, key: str, cast=None, **get_kwargs):
+        section = f"{self.job_name}.config"
+        if cast == float:
+            return config.getfloat(section, key, **get_kwargs)
+        elif cast == bool:
+            return config.getboolean(section, key, **get_kwargs)
+        elif cast == int:
+            return config.getint(section, key, **get_kwargs)
+        else:
+            return config.get(section, key, **get_kwargs)
 
     def action_to_do_before_od_reading(self) -> None:
         raise NotImplementedError()
 
     def action_to_do_after_od_reading(self) -> None:
         raise NotImplementedError()
 
@@ -1067,16 +1082,18 @@
             self._setup_actions,
             f"pioreactor/{self.unit}/{self.experiment}/od_reading/interval",
         )
 
     def set_enable_dodging_od(self, value: bool) -> None:
         self.enable_dodging_od = value
         if self.enable_dodging_od:
+            self.logger.info("Will attempt to stop during OD readings.")
             self._listen_for_od_reading()
         else:
+            self.logger.info("Running continuously through OD readings.")
             if hasattr(self, "sneak_in_timer"):
                 self.sneak_in_timer.cancel()
             try:
                 self.action_to_do_after_od_reading()
             except Exception:
                 pass
             self.sub_client.unsubscribe(f"pioreactor/{self.unit}/{self.experiment}/od_reading/interval")
@@ -1104,16 +1121,16 @@
             pass
 
         try:
             self.sneak_in_timer.cancel()
         except AttributeError:
             pass
 
-        post_delay = float(self.get_from_config("post_delay_duration", fallback=1.0))
-        pre_delay = float(self.get_from_config("pre_delay_duration", fallback=1.5))
+        post_delay = self.get_from_config("post_delay_duration", cast=float, fallback=1.0)
+        pre_delay = self.get_from_config("pre_delay_duration", cast=float, fallback=1.5)
 
         if post_delay <= 0.25:
             self.logger.warning("For optimal OD readings, keep `post_delay_duration` more than 0.25 seconds.")
 
         if pre_delay <= 0.25:
             self.logger.warning("For optimal OD readings, keep `pre_delay_duration` more than 0.25 seconds.")
 
@@ -1154,14 +1171,15 @@
             ads_interval,
             sneak_in,
             job_name=self.job_name,
             args=(ads_interval, post_delay, pre_delay),
             run_immediately=False,
         )
 
+        # TODO: shouldn't I just use run_after in `RepeatedTimer` instead of this?
         time_to_next_ads_reading = ads_interval - ((time() - ads_start_time) % ads_interval)
 
         sleep(time_to_next_ads_reading + (post_delay + self.OD_READING_DURATION))
         self.sneak_in_timer.start()
 
     def on_sleeping(self) -> None:
         try:
```

## pioreactor/background_jobs/dosing_control.py

```diff
@@ -182,18 +182,14 @@
 @click.pass_context
 def click_dosing_control(
     ctx: click.Context, automation_name: str, duration: float, skip_first_run: bool
 ) -> None:
     """
     Start a dosing automation
     """
-    import os
-
-    os.nice(1)
-
     dc = start_dosing_control(
         automation_name=automation_name,
         duration=duration,
         skip_first_run=bool(skip_first_run),
         **{ctx.args[i][2:].replace("-", "_"): ctx.args[i + 1] for i in range(0, len(ctx.args), 2)},
     )
     dc.block_until_disconnected()
```

## pioreactor/background_jobs/growth_rate_calculating.py

```diff
@@ -554,18 +554,14 @@
 @click.option("--ignore-cache", is_flag=True, help="Ignore the cached values (rerun)")
 @click.pass_context
 def click_growth_rate_calculating(ctx, ignore_cache):
     """
     Start calculating growth rate
     """
     if ctx.invoked_subcommand is None:
-        import os
-
-        os.nice(1)
-
         unit = whoami.get_unit_name()
         experiment = whoami.get_assigned_experiment_name(unit)
 
         calculator = GrowthRateCalculator(  # noqa: F841
             ignore_cache=ignore_cache,
             unit=unit,
             experiment=experiment,
```

## pioreactor/background_jobs/led_control.py

```diff
@@ -139,17 +139,14 @@
     help="Normally algo will run immediately. Set this flag to wait <duration>min before executing.",
 )
 @click.pass_context
 def click_led_control(ctx, automation_name, duration, skip_first_run):
     """
     Start an LED automation
     """
-    import os
-
-    os.nice(1)
 
     lc = start_led_control(
         automation_name=automation_name,
         duration=duration,
         skip_first_run=bool(skip_first_run),
         **{ctx.args[i][2:].replace("-", "_"): ctx.args[i + 1] for i in range(0, len(ctx.args), 2)},
     )
```

## pioreactor/background_jobs/monitor.py

```diff
@@ -1,13 +1,14 @@
 # -*- coding: utf-8 -*-
 from __future__ import annotations
 
 import subprocess
 from contextlib import suppress
-from shlex import join  # https://docs.python.org/3/library/shlex.html#shlex.quote
+from shlex import join
+from shlex import quote
 from threading import Thread
 from time import sleep
 from typing import Any
 from typing import Callable
 from typing import Optional
 
 import click
@@ -23,15 +24,15 @@
 from pioreactor.config import get_mqtt_address
 from pioreactor.exc import NotAssignedAnExperimentError
 from pioreactor.hardware import GPIOCHIP
 from pioreactor.hardware import is_HAT_present
 from pioreactor.hardware import PCB_BUTTON_PIN as BUTTON_PIN
 from pioreactor.hardware import PCB_LED_PIN as LED_PIN
 from pioreactor.hardware import TEMP
-from pioreactor.mureq import get
+from pioreactor.pubsub import get_from_leader
 from pioreactor.pubsub import QOS
 from pioreactor.structs import Voltage
 from pioreactor.types import MQTTMessage
 from pioreactor.utils.gpio_helpers import set_gpio_availability
 from pioreactor.utils.networking import get_ip
 from pioreactor.utils.timing import current_utc_datetime
 from pioreactor.utils.timing import current_utc_timestamp
@@ -348,15 +349,15 @@
             self.logger.debug(f"Error checking huey status: {e}", exc_info=True)
             self.logger.error(f"Error checking huey status: {e}")
 
         attempt = 0
         retries = 5
         while attempt < retries:
             attempt += 1
-            res = get("http://localhost/api/experiments/latest")
+            res = get_from_leader("/api/experiments/latest")
             if res.ok:
                 break
             sleep(1.0)
         else:
             self.logger.debug(f"Error pinging UI: {res.status_code}")
             self.logger.error(f"Error pinging UI: {res.status_code}")
             self.flicker_led_with_error_code(error_codes.WEBSERVER_OFFLINE)
@@ -376,24 +377,24 @@
         if whoami.is_testing_env():
             from pioreactor.utils.mock import MockTMP1075 as TMP1075
         else:
             try:
                 from TMP1075 import TMP1075  # type: ignore
             except ImportError:
                 # leader-only is a worker?
-                self.logger.warning(
+                self.logger.debug(
                     f"{self.unit} doesn't have TMP1075 software installed, but is acting as a worker."
                 )
                 return
 
         try:
             tmp_driver = TMP1075(address=TEMP)
         except ValueError:
             # No PCB detected using i2c - fine to exit.
-            self.logger.warning("Heater PCB is not detected.")
+            self.logger.debug("Heater PCB is not detected.")
             return
 
         observed_tmp = tmp_driver.get_temperature()
 
         if observed_tmp >= self.MAX_TEMP_TO_SHUTDOWN:
             # something is wrong - temperature_control should have detected this, but didn't, so it must have failed / incorrectly cleaned up.
             # we're going to just shutdown to be safe.
@@ -419,15 +420,14 @@
 
             self.logger.warning(
                 f"""Not able to connect MQTT clients to leader.
 1. Is the mqtt_adress={get_mqtt_address()}, in config.ini correct?
 2. Is the Pioreactor leader online and responsive?
 """
             )  # remember, this doesn't get published to leader...
-            self.logger.debug(f"{error_code_pc=}, {error_code_sc=}")
 
             # self.set_state(self.LOST)
             self.flicker_led_with_error_code(error_codes.MQTT_CLIENT_NOT_CONNECTED_TO_LEADER)
 
     def check_for_last_backup(self) -> None:
         with utils.local_persistant_storage("database_backups") as cache:
             if cache.get("latest_backup_timestamp"):
@@ -640,14 +640,16 @@
                 assigned_experiment = whoami._get_assigned_experiment_name(self.unit)
             except NotAssignedAnExperimentError:
                 assigned_experiment = whoami.NO_EXPERIMENT
 
             # make sure I'm assigned to the correct experiment
             if experiment != assigned_experiment:
                 return
+        else:
+            assigned_experiment = None
 
         payload = loads(msg.payload) if msg.payload else {"options": {}, "args": []}
 
         options = payload.get("options", {})
 
         args = payload.get("args", [])
 
@@ -688,40 +690,47 @@
             options["unit"] = self.unit
             options["experiment"] = experiment  # techdebt
             options["config"] = get_config()  # techdebt
             Thread(target=pump_action, kwargs=options, daemon=True).start()
             self.logger.debug(f"Running `{job_name}` from monitor job.")
 
         else:
-            command = self._job_options_and_args_to_shell_command(job_name, args, options)
+            command = self._job_options_and_args_to_shell_command(
+                job_name, assigned_experiment, args, options
+            )
             Thread(
                 target=subprocess.run,
                 args=(command,),
                 kwargs={"shell": True, "start_new_session": True},
                 daemon=True,
             ).start()
             self.logger.debug(f"Running `{command}` from monitor job.")
 
     @staticmethod
     def _job_options_and_args_to_shell_command(
-        job_name: str, args: list[str], options: dict[str, Any]
+        job_name: str, experiment: Optional[str], args: list[str], options: dict[str, Any]
     ) -> str:
         core_command = ["pio", "run", job_name]
-        env = [f'JOB_SOURCE={options.pop("job_source", "user")}']
+
+        # job source could be experiment_profile, but defaults to user
+        # we actually can skip another API request by reusing the assigned experiment above...
+        env = f'JOB_SOURCE={quote(options.pop("job_source", "user"))}'
+        if experiment:
+            env += f" EXPERIMENT={quote(experiment)}"
 
         list_of_options: list[str] = []
         for option, value in options.items():
             list_of_options.append(f"--{option.replace('_', '-')}")
             if value is not None:
                 # this handles flag arguments, like --dry-run
                 list_of_options.append(str(value))
 
         # shell-escaped to protect against injection vulnerabilities, see join docs
         # we don't escape the suffix.
-        return join(env + ["nohup"] + core_command + args + list_of_options) + " >/dev/null 2>&1 &"
+        return env + " " + join(["nohup"] + core_command + args + list_of_options) + " >/dev/null 2>&1 &"
 
     def flicker_error_code_from_mqtt(self, message: MQTTMessage) -> None:
         if self.led_in_use:
             return
 
         error_code = int(message.payload)
         Thread(target=self.flicker_led_with_error_code, args=(error_code,), daemon=True).start()
```

## pioreactor/background_jobs/od_reading.py

```diff
@@ -693,25 +693,20 @@
                         self.logger.error(msg)
                         raise exc.CalibrationError(msg)
                     # confirm that PD channel is the same as when calibration was performed
                     elif calibration_data.pd_channel != channel:
                         msg = f"The calibration `{name}` was calibrated with a different PD channel ({calibration_data.pd_channel} vs current: {channel})."
                         self.logger.error(msg)
                         raise exc.CalibrationError(msg)
-                    else:
-                        models[channel] = self._hydrate_model(calibration_data)
-                        self.logger.debug(
-                            f"Using calibration `{name}` for channel {channel}, {calibration_data.curve_type=}, {calibration_data.curve_data_=}"
-                        )
 
-                    # confirm that PD channel is the same as when calibration was performed
-                    if calibration_data.pd_channel != channel:
-                        msg = f"The calibration `{name}` was calibrated with a different PD channel ({calibration_data.pd_channel} vs current: {channel})."
-                        self.logger.error(msg)
-                        raise exc.CalibrationError(msg)
+                    models[channel] = self._hydrate_model(calibration_data)
+                    self.logger.info(f"Using OD calibration `{name}` for channel {channel}.")
+                    self.logger.debug(
+                        f"Using OD calibration `{name}` for channel {channel}, {calibration_data.curve_type=}, {calibration_data.curve_data_=}"
+                    )
 
                 else:
                     self.logger.debug(
                         f"No calibration available for channel {channel}, angle {angle}, skipping."
                     )
         return models
 
@@ -835,15 +830,15 @@
     od1: structs.ODReading
     od2: structs.ODReading
     ods: structs.ODReadings
 
     if whoami.get_pioreactor_version() == (1, 0):
         TARGET_REF_VOLTAGE = 0.10
     elif whoami.get_pioreactor_version() >= (1, 1):
-        TARGET_REF_VOLTAGE = 0.03
+        TARGET_REF_VOLTAGE = 0.05
 
     def __init__(
         self,
         channel_angle_map: dict[pt.PdChannel, pt.PdAngle],
         interval: Optional[float],
         adc_reader: ADCReader,
         unit: str,
```

## pioreactor/background_jobs/stirring.py

```diff
@@ -296,32 +296,33 @@
         with suppress(AttributeError):
             self.pwm.clean_up()
         with suppress(AttributeError):
             if self.rpm_calculator:
                 self.rpm_calculator.clean_up()
 
     def start_stirring(self) -> None:
-        self.logger.debug(f"Starting stirring with {self.target_rpm} RPM.")
+        self.logger.debug(
+            f"Starting stirring with {'no' if self.target_rpm is None  else  self.target_rpm} RPM."
+        )
         self.pwm.start(100)  # get momentum to start
-        sleep(0.20)
+        sleep(0.35)
         self.set_duty_cycle(self.duty_cycle)
-        sleep(0.50)
         if self.rpm_calculator is not None:
             self.rpm_check_repeated_thread.start()  # .start is idempotent
 
     def kick_stirring(self) -> None:
         self.logger.debug("Kicking stirring")
         _existing_duty_cycle = self.duty_cycle
         self.set_duty_cycle(0)
-        sleep(0.25)
+        sleep(0.30)
         self.set_duty_cycle(100)
-        sleep(0.15)
+        sleep(0.5)
         self.set_duty_cycle(
-            min(1.01 * _existing_duty_cycle, 50)
-        )  # DC should never need to be above 50 - simply not realistic. We want to avoid the death spiral to 100%.
+            min(1.01 * _existing_duty_cycle, 60)
+        )  # DC should never need to be above 60 - simply not realistic. We want to avoid the death spiral to 100%.
 
     def kick_stirring_but_avoid_od_reading(self) -> None:
         """
         This will determine when the next od reading occurs (if possible), and
         wait until it completes before kicking stirring.
         """
         first_od_obs_time_msg = subscribe(
@@ -362,35 +363,37 @@
         self._measured_rpm = recent_rpm
         self.measured_rpm = structs.MeasuredRPM(
             timestamp=current_utc_datetime(), measured_rpm=self._measured_rpm
         )
 
         if recent_rpm == 0 and self.state == self.READY:  # and not is_testing_env():
             self.logger.warning(
-                "Stirring RPM is 0 - attempting to restart it automatically. It may be a temporary stall, target RPM may be too low, or not reading sensor correctly."
+                "Stirring RPM is 0 - attempting to restart it automatically. It may be a temporary stall, target RPM may be too low, insufficient power applied to fan, or not reading sensor correctly."
             )
             self.blink_error_code(error_codes.STIRRING_FAILED)
 
             is_od_running = is_pio_job_running("od_reading")
 
             if not is_od_running:
                 self.kick_stirring()
             else:
                 self.kick_stirring_but_avoid_od_reading()
 
         return self.measured_rpm
 
     def poll_and_update_dc(self, poll_for_seconds: Optional[float] = None) -> None:
+        if self.rpm_calculator is None or self.target_rpm is None:
+            return
+
         if poll_for_seconds is None:
-            if self.target_rpm is None:
-                poll_for_seconds = 4.0  # this never runs? If target_rpm is None, what are we polling for?
-            else:
-                target_n_data_points = 12
-                rps = self.target_rpm / 60.0
-                poll_for_seconds = target_n_data_points / rps
+            target_n_data_points = 12
+            rps = self.target_rpm / 60.0
+            poll_for_seconds = target_n_data_points / rps
+        else:
+            poll_for_seconds = 4.0
 
         self.poll(poll_for_seconds)
 
         if self._measured_rpm is None or self.state != self.READY:
             return
 
         result = self.pid.update(self._measured_rpm)
@@ -434,20 +437,20 @@
 
         Returns
         --------
         bool: True if successfully waited until RPM is correct.
 
         """
 
-        if self.rpm_calculator is None:  # or is_testing_env():
+        if self.rpm_calculator is None or self.target_rpm is None:  # or is_testing_env():
             # can't block if we aren't recording the RPM
             return False
 
         sleep_time = 0.2
-        poll_time = 2  # usually 4, but we don't need high accuracy here,
+        poll_time = 2.0  # usually 4, but we don't need high accuracy here,
         self.logger.debug(f"{self.job_name} is blocking until RPM is near {self.target_rpm}.")
 
         self.rpm_check_repeated_thread.pause()
 
         with catchtime() as time_waiting:
             sleep(2)  # on init, the stirring is too fast from the initial "kick"
             self.poll_and_update_dc(poll_time)
```

## pioreactor/background_jobs/temperature_control.py

```diff
@@ -32,23 +32,25 @@
 import click
 
 from pioreactor import error_codes
 from pioreactor import exc
 from pioreactor import hardware
 from pioreactor import whoami
 from pioreactor.background_jobs.base import BackgroundJob
+from pioreactor.config import config
 from pioreactor.structs import Temperature
 from pioreactor.structs import TemperatureAutomation
 from pioreactor.utils import clamp
 from pioreactor.utils import local_intermittent_storage
 from pioreactor.utils.pwm import PWM
 from pioreactor.utils.timing import current_utc_datetime
 from pioreactor.utils.timing import current_utc_timestamp
 from pioreactor.utils.timing import RepeatedTimer
 from pioreactor.utils.timing import to_datetime
+from pioreactor.version import rpi_version_info
 
 
 class TemperatureController(BackgroundJob):
     """
 
     This job publishes to
 
@@ -402,20 +404,31 @@
         time_between_samples = self.INFERENCE_SAMPLES_EVERY_T_SECONDS
 
         assert not self.pwm.is_locked(), "PWM is locked - it shouldn't be though!"
         with self.pwm.lock_temporarily():
             previous_heater_dc = self.heater_duty_cycle
 
             features: dict[str, Any] = {}
+
+            # add how much heat/energy we just applied
             features["previous_heater_dc"] = previous_heater_dc
 
             # figure out a better way to estimate this... luckily inference is not too sensitive to this parameter.
             # users can override this function with something more accurate later.
             features["room_temp"] = self._get_room_temperature()
 
+            # B models have a hotter ambient env. TODO: what about As?
+            features["is_rpi_zero"] = rpi_version_info.startswith("Raspberry Pi Zero")
+
+            # the amount of liquid in the vial is a factor!
+            features["volume"] = 0.5 * (
+                config.getfloat("bioreactor", "initial_volume_ml")
+                + config.getfloat("bioreactor", "max_volume_ml")
+            )
+
             # turn off active heating, and start recording decay
             self._update_heater(0)
             time_series_of_temp = []
 
             try:
                 for i in range(N_sample_points):
                     time_series_of_temp.append(self.read_external_temperature())
@@ -563,50 +576,51 @@
     def approximate_temperature_2_0(features: dict[str, Any]) -> float:
         """
         This uses linear regression from historical data
         """
         if features["previous_heater_dc"] == 0:
             return features["time_series_of_temp"][-1]
 
-        X = features["time_series_of_temp"]
+        X = [features["previous_heater_dc"]] + features["time_series_of_temp"]
 
         # normalize to ~1.0, as we do this in training.
         X = [x / 35.0 for x in X]
 
         # add in non-linear features
-        X.append(X[0] ** 2)
-        X.append(X[0] ** 0.5)
+        X.append(X[1] ** 2)
+        X.append(X[20] * X[0])
 
         coefs = [
-            22.44950549,
-            -47.26707134,
-            -31.07494909,
-            -41.36629363,
-            -12.17348368,
-            55.03067504,
-            22.91692162,
-            35.96733783,
-            37.86185926,
-            49.00325047,
-            43.72159562,
-            47.12556322,
-            30.780167,
-            34.25574632,
-            21.12142635,
-            1.77795003,
-            -0.74499359,
-            -46.5411805,
-            -38.20418079,
-            -59.83658558,
-            -65.3550903,
-            -3.36141664,
-            -34.61894608,
+            -1.37221255e01,
+            1.50807347e02,
+            1.52808570e01,
+            -7.17124615e01,
+            -8.15352596e01,
+            -5.82053398e01,
+            -8.49915201e01,
+            -3.69729300e01,
+            -8.51994806e-02,
+            1.12635670e01,
+            3.37434235e01,
+            3.36348041e01,
+            4.25731033e01,
+            6.72551219e01,
+            8.37883314e01,
+            6.29508694e01,
+            4.95735854e01,
+            1.86594862e01,
+            3.12848519e-01,
+            -3.82815596e01,
+            -5.62834504e01,
+            -9.27840943e01,
+            -7.62113224e00,
+            8.18877406e00,
         ]
 
-        intercept = 13.358217809582857
+        intercept = -6.171633633597331
 
         def dot_product(vec1: list, vec2: list) -> float:
             if len(vec1) != len(vec2):
                 raise ValueError(f"Vectors must be of the same length. Got {len(vec1)=}, {len(vec2)=}")
             return sum(x * y for x, y in zip(vec1, vec2))
 
         return dot_product(coefs, X) + intercept
@@ -639,17 +653,14 @@
     required=True,
 )
 @click.pass_context
 def click_temperature_control(ctx, automation_name: str) -> None:
     """
     Start a temperature automation.
     """
-    import os
-
-    os.nice(1)
 
     kwargs = {ctx.args[i][2:].replace("-", "_"): ctx.args[i + 1] for i in range(0, len(ctx.args), 2)}
     if "skip_first_run" in kwargs:
         del kwargs["skip_first_run"]
 
     tc = start_temperature_control(
         automation_name=automation_name,
```

## pioreactor/background_jobs/leader/mqtt_to_db_streaming.py

```diff
@@ -13,15 +13,14 @@
 from msgspec.json import decode as msgspec_loads
 
 from pioreactor import structs
 from pioreactor import types as pt
 from pioreactor.background_jobs.base import LongRunningBackgroundJob
 from pioreactor.config import config
 from pioreactor.hardware import PWM_TO_PIN
-from pioreactor.pubsub import MQTT_TOPIC
 from pioreactor.pubsub import QOS
 from pioreactor.utils.sqlite_worker import Sqlite3Worker
 from pioreactor.utils.timing import current_utc_datetime
 from pioreactor.utils.timing import RepeatedTimer
 from pioreactor.utils.timing import to_iso_format
 from pioreactor.whoami import get_unit_name
 from pioreactor.whoami import UNIVERSAL_EXPERIMENT
@@ -41,21 +40,24 @@
 
     parser:
      - must return a dictionary | list[dictionary] with the column names as keys (order isn't important)
      - `produce_metadata` is a helper function, see definition.
      - parsers can return None as well, to skip adding the row to the database.
     """
 
-    topic: str | MQTT_TOPIC | list[str | MQTT_TOPIC]
+    topic: str | list[str]
     parser: Callable[[str, pt.MQTTMessagePayload], Optional[dict | list[dict]]]
     table: str
 
+    def __repr__(self):
+        return f"TopicToParserToTable(topic='{self.topic}', table='{self.table}', parser=...)"
+
 
 class TopicToCallback(Struct):
-    topic: str | MQTT_TOPIC | list[str | MQTT_TOPIC]
+    topic: str | list[str]
     callback: Callable[[pt.MQTTMessage], None]
 
 
 class MqttToDBStreamer(LongRunningBackgroundJob):
     job_name = "mqtt_to_db_streaming"
     published_settings = {
         "inserts_in_last_60s": {"datatype": "integer", "settable": False},
```

## pioreactor/background_jobs/leader/watchdog.py

```diff
@@ -24,26 +24,27 @@
 
         self.start_passive_listeners()
 
     def on_init_to_ready(self) -> None:
         threading.Thread(target=self.announce_new_workers, daemon=True).start()
 
     def announce_new_workers(self) -> None:
+        time.sleep(10)  # wait for the web server to be available
         for worker in discover_workers_on_network():
             # not in current cluster, and not leader
             if (worker not in get_workers_in_inventory()) and (worker != get_leader_hostname()):
                 # is there an MQTT state for this worker?
                 # a new worker doesn't have the leader_address, so it won't connect to the leaders MQTT.
                 result = subscribe(
                     f"pioreactor/{worker}/{UNIVERSAL_EXPERIMENT}/monitor/$state",
-                    timeout=5,
+                    timeout=3,
                     name=self.job_name,
                     retries=1,
                 )
-                if result is None:
+                if result is None or result.payload.decode() == self.LOST:
                     self.logger.notice(  # type: ignore
                         f"Pioreactor worker, {worker}, is available to be added to your cluster."
                     )
 
     def watch_for_lost_state(self, state_message: MQTTMessage) -> None:
         # generally, I hate this code below...
```

## pioreactor/cli/pio.py

```diff
@@ -20,31 +20,30 @@
 from pioreactor import config
 from pioreactor import exc
 from pioreactor import whoami
 from pioreactor.cli.lazy_group import LazyGroup
 from pioreactor.logging import create_logger
 from pioreactor.mureq import get
 from pioreactor.mureq import HTTPException
+from pioreactor.pubsub import get_from_leader
 from pioreactor.utils import JobManager
 from pioreactor.utils import local_intermittent_storage
 from pioreactor.utils import local_persistant_storage
 from pioreactor.utils.networking import is_using_local_access_point
 from pioreactor.utils.timing import current_utc_timestamp
 from pioreactor.whoami import am_I_leader
 
+lazy_subcommands = {
+    "run": "pioreactor.cli.run.run",
+    "plugins": "pioreactor.cli.plugins.plugins",
+}
+
 if am_I_leader():
-    lazy_subcommands = {
-        "run": "pioreactor.cli.run.run",
-        "workers": "pioreactor.cli.workers.workers",
-        "plugins": "pioreactor.cli.plugins.plugins",
-    }
-else:
-    lazy_subcommands = {
-        "run": "pioreactor.cli.run.run",
-    }
+    # add in ability to control workers
+    lazy_subcommands["workers"] = "pioreactor.cli.workers.workers"
 
 
 @click.group(
     cls=LazyGroup,
     lazy_subcommands=lazy_subcommands,
     invoke_without_command=True,
 )
@@ -170,43 +169,42 @@
 def kill(name: str | None, experiment: str | None, job_source: str | None, all_jobs: bool) -> None:
     """
     stop job(s).
     """
     if not (name or experiment or job_source or all_jobs):
         raise click.Abort("Provide an option to kill.")
     with JobManager() as jm:
-        count = jm.count_jobs(all_jobs=all_jobs, name=name, experiment=experiment, job_source=job_source)
-        jm.kill_jobs(all_jobs=all_jobs, name=name, experiment=experiment, job_source=job_source)
-    click.echo(f"Killed {count} job(s).")
+        count = jm.kill_jobs(all_jobs=all_jobs, name=name, experiment=experiment, job_source=job_source)
+    click.echo(f"Killed {count} job{'s' if count != 1 else ''}.")
 
 
 @pio.command(name="version", short_help="print the Pioreactor software version")
 @click.option("--verbose", "-v", is_flag=True, help="show more system information")
 def version(verbose: bool) -> None:
     if verbose:
         import platform
         from pioreactor.version import hardware_version_info
         from pioreactor.version import software_version_info
         from pioreactor.version import serial_number
         from pioreactor.version import tuple_to_text
         from pioreactor.version import get_firmware_version
         from pioreactor.version import rpi_version_info
-        from pioreactor.version import get_product_from_id
+        from pioreactor.whoami import get_pioreactor_model_and_version
 
         click.echo(f"Pioreactor software:    {tuple_to_text(software_version_info)}")
         click.echo(f"Pioreactor HAT:         {tuple_to_text(hardware_version_info)}")
         click.echo(f"Pioreactor firmware:    {tuple_to_text(get_firmware_version())}")
-        click.echo(f"Model name:             {get_product_from_id()}")
+        click.echo(f"Model name:             {get_pioreactor_model_and_version()}")
         click.echo(f"HAT serial number:      {serial_number}")
         click.echo(f"Operating system:       {platform.platform()}")
         click.echo(f"Raspberry Pi:           {rpi_version_info}")
         click.echo(f"Image version:          {whoami.get_image_git_hash()}")
         if whoami.am_I_leader():
             try:
-                result = get("http://127.0.0.1/api/versions/ui")
+                result = get_from_leader("api/versions/ui")
                 result.raise_for_status()
                 ui_version = result.body.decode()
             except Exception:
                 ui_version = "<Failed to fetch>"
 
             click.echo(f"Pioreactor UI:          {ui_version}")
     else:
```

## pioreactor/cli/pios.py

```diff
@@ -152,15 +152,15 @@
 
         def _thread_function(unit: str) -> bool:
             logger.debug(f"Copying {filepath} to {unit}:{filepath}...")
             try:
                 cp_file_across_cluster(unit, filepath, filepath, timeout=30)
                 return True
             except Exception as e:
-                logger.error(f"Error occurred: {e}. See logs for more.")
+                logger.error(f"Error occurred copying to {unit}. See logs for more.")
                 logger.debug(f"Error occurred: {e}.", exc_info=True)
                 return False
 
         for unit in units:
             _thread_function(unit)
 
     @pios.command("rm", short_help="rm a file across the cluster")
@@ -199,15 +199,16 @@
                 ssh(add_local(unit), command)
                 return True
             except ErrorReturnCode_255 as e:
                 logger.error(f"Unable to connect to unit {unit}. {e.stderr.decode()}")
                 logger.debug(e, exc_info=True)
                 return False
             except ErrorReturnCode_1 as e:
-                logger.error(f"Error occurred: {e}. See logs for more.")
+                logger.error(f"Error occurred rm-ing from {unit}. See logs for more.")
+                logger.debug(e, exc_info=True)
                 return False
 
         for unit in units:
             _thread_function(unit)
 
     @pios.command("update", short_help="update PioreactorApp on workers")
     @click.option(
@@ -270,15 +271,15 @@
                 ssh(add_local(unit), command)
                 return True
             except ErrorReturnCode_255 as e:
                 logger.error(f"Unable to connect to unit {unit}. {e.stderr.decode()}")
                 logger.debug(e, exc_info=True)
                 return False
             except ErrorReturnCode_1 as e:
-                logger.error(f"Error occurred: {e}. See logs for more.")
+                logger.error(f"Error occurred updating {unit}. See logs for more.")
                 logger.debug(e.stderr, exc_info=True)
                 return False
 
         with ThreadPoolExecutor(max_workers=len(units)) as executor:
             results = executor.map(_thread_function, units)
 
         if not all(results):
@@ -323,15 +324,15 @@
                 ssh(add_local(unit), command)
                 return True
             except ErrorReturnCode_255 as e:
                 logger.error(f"Unable to connect to unit {unit}. {e.stderr.decode()}")
                 logger.debug(e, exc_info=True)
                 return False
             except ErrorReturnCode_1 as e:
-                logger.error(f"Error occurred: {e}. See logs for more.")
+                logger.error(f"Error occurred installing plugin on {unit}. See logs for more.")
                 logger.debug(e.stderr, exc_info=True)
                 return False
 
         with ThreadPoolExecutor(max_workers=len(units)) as executor:
             results = executor.map(_thread_function, units)
 
         if not all(results):
@@ -355,15 +356,15 @@
         from sh import ssh  # type: ignore
         from sh import ErrorReturnCode_255  # type: ignore
         from sh import ErrorReturnCode_1  # type: ignore
         from shlex import quote
 
         logger = create_logger("uninstall_plugin", unit=get_unit_name(), experiment=UNIVERSAL_EXPERIMENT)
 
-        command = f"pio plugin uninstall {quote(plugin)}"
+        command = f"pio plugins uninstall {quote(plugin)}"
         units = add_leader(universal_identifier_to_all_workers(units))
 
         if not y:
             confirm = input(f"Confirm uninstalling {quote(plugin)} on {units}? Y/n: ").strip()
             if confirm != "Y":
                 raise click.Abort()
 
@@ -373,15 +374,15 @@
                 ssh(add_local(unit), command)
                 return True
             except ErrorReturnCode_255 as e:
                 logger.error(f"Unable to connect to unit {unit}. {e.stderr.decode()}")
                 logger.debug(e, exc_info=True)
                 return False
             except ErrorReturnCode_1 as e:
-                logger.error(f"Error occurred: {e}. See logs for more.")
+                logger.error(f"Error occurred uninstalling plugin on {unit}. See logs for more.")
                 logger.debug(e.stderr, exc_info=True)
                 return False
 
         with ThreadPoolExecutor(max_workers=len(units)) as executor:
             results = executor.map(_thread_function, units)
 
         if not all(results):
@@ -425,15 +426,15 @@
 
         def _thread_function(unit: str) -> bool:
             logger.debug(f"Syncing configs on {unit}...")
             try:
                 sync_config_files(unit, shared, specific)
                 return True
             except Exception as e:
-                logger.error(f"Error syncing configs to {unit}.")
+                logger.warning(f"Encountered error syncing configs to {unit}.")
                 logger.debug(e, exc_info=True)
                 return False
 
         if not skip_save:
             # save config.inis to database
             save_config_files_to_db(units, shared, specific)
 
@@ -560,15 +561,15 @@
             except ErrorReturnCode_255 as e:
                 logger = create_logger("CLI", unit=get_unit_name(), experiment=UNIVERSAL_EXPERIMENT)
                 logger.debug(e, exc_info=True)
                 logger.error(f"Unable to connect to unit {unit}. {e.stderr.decode()}")
                 return False
             except ErrorReturnCode_1 as e:
                 logger = create_logger("CLI", unit=get_unit_name(), experiment=UNIVERSAL_EXPERIMENT)
-                logger.error(f"Error occurred: {e}. See logs for more.")
+                logger.error(f"Error occurred running job on {unit}. See logs for more.")
                 logger.debug(e.stderr, exc_info=True)
                 return False
 
         with ThreadPoolExecutor(max_workers=len(units)) as executor:
             results = executor.map(_thread_function, units)
 
         if not all(results):
@@ -611,15 +612,15 @@
                 return True
             except ErrorReturnCode_255 as e:
                 logger = create_logger("CLI", unit=get_unit_name(), experiment=UNIVERSAL_EXPERIMENT)
                 logger.debug(e, exc_info=True)
                 logger.error(f"Unable to connect to unit {unit}. {e.stderr.decode()}")
                 return False
             except ErrorReturnCode_1 as e:
-                logger.error(f"Error occurred: {e}. See logs for more.")
+                logger.error(f"Error occurred shutting down {unit}. See logs for more.")
                 logger.debug(e.stderr, exc_info=True)
                 return False
 
         if len(units_san_leader) > 0:
             with ThreadPoolExecutor(max_workers=len(units_san_leader)) as executor:
                 executor.map(_thread_function, units_san_leader)
 
@@ -667,15 +668,15 @@
                 return True
             except ErrorReturnCode_255 as e:
                 logger = create_logger("CLI", unit=get_unit_name(), experiment=UNIVERSAL_EXPERIMENT)
                 logger.debug(e, exc_info=True)
                 logger.error(f"Unable to connect to unit {unit}. {e.stderr.decode()}")
                 return False
             except ErrorReturnCode_1 as e:
-                logger.error(f"Error occurred: {e}. See logs for more.")
+                logger.error(f"Error occurred rebooting {unit}. See logs for more.")
                 logger.debug(e.stderr, exc_info=True)
                 return False
 
         if len(units_san_leader) > 0:
             with ThreadPoolExecutor(max_workers=len(units_san_leader)) as executor:
                 executor.map(_thread_function, units_san_leader)
```

## pioreactor/cluster_management/__init__.py

```diff
@@ -7,42 +7,43 @@
 
 import click
 from msgspec.json import decode as loads
 from msgspec.json import encode as dumps
 
 from pioreactor import whoami
 from pioreactor.config import leader_address
+from pioreactor.config import leader_hostname
 from pioreactor.exc import BashScriptError
 from pioreactor.logging import create_logger
-from pioreactor.mureq import delete
-from pioreactor.mureq import get
 from pioreactor.mureq import HTTPErrorStatus
 from pioreactor.mureq import HTTPException
-from pioreactor.mureq import put
+from pioreactor.pubsub import delete_from_leader
+from pioreactor.pubsub import get_from_leader
+from pioreactor.pubsub import put_into_leader
 from pioreactor.utils import networking
 from pioreactor.utils.timing import catchtime
 
 
 def get_workers_in_inventory() -> tuple[str, ...]:
-    result = get(f"http://{leader_address}/api/workers")
+    result = get_from_leader("/api/workers")
     return tuple(worker["pioreactor_unit"] for worker in result.json())
 
 
 def get_active_workers_in_inventory() -> tuple[str, ...]:
-    result = get(f"http://{leader_address}/api/workers")
+    result = get_from_leader("/api/workers")
     return tuple(worker["pioreactor_unit"] for worker in result.json() if bool(worker["is_active"]))
 
 
 def get_workers_in_experiment(experiment: str) -> tuple[str, ...]:
-    result = get(f"http://{leader_address}/api/experiments/{experiment}/workers")
+    result = get_from_leader(f"/api/experiments/{experiment}/workers")
     return tuple(worker["pioreactor_unit"] for worker in result.json())
 
 
 def get_active_workers_in_experiment(experiment: str) -> tuple[str, ...]:
-    result = get(f"http://{leader_address}/api/experiments/{experiment}/workers")
+    result = get_from_leader(f"/api/experiments/{experiment}/workers")
     return tuple(worker["pioreactor_unit"] for worker in result.json() if bool(worker["is_active"]))
 
 
 @click.command(name="add", short_help="add a pioreactor worker")
 @click.argument("hostname")
 @click.option("--password", "-p", default="raspberry")
 @click.option("--version", "-v", default="1.1")
@@ -77,15 +78,15 @@
                 try:
                     socket.gethostbyname(hostname_dot_local)
                 except socket.gaierror:
                     sleep(sleep_time)
                     click.echo(f"`{hostname}` not found on network - checking again.")
                     if checks >= max_checks:
                         logger.error(
-                            f"`{hostname}` not found on network after {round(elapsed())} seconds. Check that you provided the right i) WiFi credentials to the network, ii) the hostname is correct, the iii) worker is turned on."
+                            f"`{hostname}` not found on network after {round(elapsed())} seconds. Check that you provided the right i) the name is correct, ii) worker is powered on, iii) any WiFi credentials to the network are correct."
                         )
                         raise click.Abort()
 
         res = subprocess.run(
             [
                 "bash",
                 "/usr/local/bin/add_new_pioreactor_worker_from_leader.sh",
@@ -98,18 +99,17 @@
             text=True,
         )
         if res.returncode > 0:
             logger.error(res.stderr)
             raise BashScriptError(res.stderr)
 
     try:
-        result = put(
-            f"http://{leader_address}/api/workers",
-            dumps({"pioreactor_unit": hostname}),
-            headers={"Content-Type": "application/json"},
+        result = put_into_leader(
+            "/api/workers",
+            json={"pioreactor_unit": hostname},
         )
         result.raise_for_status()
     except HTTPErrorStatus:
         logger.error("Did not add Pioreactor to backend")
         raise HTTPException("Did not add Pioreactor to backend")
     except HTTPException:
         logger.error("Could not connect to leader's webserver")
@@ -118,15 +118,15 @@
     logger.notice(f"New pioreactor {hostname} successfully added to cluster.")  # type: ignore
 
 
 @click.command(name="remove", short_help="remove a pioreactor worker")
 @click.argument("hostname")
 def remove_worker(hostname: str) -> None:
     try:
-        r = delete(f"http://{leader_address}/api/workers/{hostname}")
+        r = delete_from_leader(f"/api/workers/{hostname}")
         r.raise_for_status()
     except HTTPErrorStatus:
         click.echo(f"Worker {hostname} not present to be removed. Check hostname.")
         click.Abort()
     except HTTPException:
         click.echo("Not able to connect to leader's backend.")
         click.Abort()
@@ -135,16 +135,16 @@
 
 
 @click.command(name="assign", short_help="assign a pioreactor worker")
 @click.argument("hostname")
 @click.argument("experiment")
 def assign_worker_to_experiment(hostname: str, experiment: str) -> None:
     try:
-        r = put(
-            f"http://{leader_address}/api/experiments/{experiment}/workers",
+        r = put_into_leader(
+            f"/api/experiments/{experiment}/workers",
             json={"pioreactor_unit": hostname},
         )
         r.raise_for_status()
     except HTTPErrorStatus:
         click.echo("Not valid data. Check hostname or experiment.")
         click.Abort()
     except HTTPException:
@@ -155,35 +155,35 @@
 
 
 @click.command(name="unassign", short_help="unassign a pioreactor worker")
 @click.argument("hostname")
 @click.argument("experiment")
 def unassign_worker_from_experiment(hostname: str, experiment: str) -> None:
     try:
-        r = delete(
-            f"http://{leader_address}/api/experiments/{experiment}/workers/{hostname}",
+        r = delete_from_leader(
+            f"/api/experiments/{experiment}/workers/{hostname}",
         )
         r.raise_for_status()
     except HTTPErrorStatus:
         click.echo("Error")
         click.Abort()
     except HTTPException:
         click.echo("Not able to connect to leader's backend.")
         click.Abort()
     else:
         click.echo(f"Unassigned {hostname} from {experiment}")
 
 
 @click.command(name="update-active", short_help="change active of worker")
 @click.argument("hostname")
-@click.argument("active", type=int)
+@click.argument("active", type=click.IntRange(0, 1))
 def update_active(hostname: str, active: int) -> None:
     try:
-        r = delete(
-            f"http://{leader_address}/api//workers/{hostname}/is_active",
+        r = put_into_leader(
+            f"/api/workers/{hostname}/is_active",
             json={"is_active": active},
         )
         r.raise_for_status()
     except HTTPException:
         click.echo("Not able to connect to leader's backend.")
         click.Abort()
     else:
@@ -248,42 +248,42 @@
             app_version = "unknown"
 
         # is reachable?
         reachable = networking.is_reachable(networking.add_local(hostname))
 
         # get experiment
         try:
-            result = get(f"http://{leader_address}/api/workers/{hostname}/experiment")
+            result = get_from_leader(f"/api/workers/{hostname}/experiment")
             experiment = result.json()["experiment"]
         except Exception:
             experiment = ""
 
         return ip, state, reachable, app_version, experiment
 
     def display_data_for(worker: dict[str, str]) -> bool:
         hostname, is_active = worker["pioreactor_unit"], worker["is_active"]
 
         ip, state, reachable, version, experiment = get_metadata(hostname)
 
         statef = click.style(f"{state:15s}", fg="green" if state in ("ready", "init") else "red")
         ipf = f"{ip if (ip is not None) else 'unknown':20s}"
 
-        is_leaderf = f"{('Y' if hostname==leader_address else 'N'):15s}"
+        is_leaderf = f"{('Y' if hostname==leader_hostname else 'N'):15s}"
         hostnamef = f"{hostname:20s}"
         reachablef = f"{(click.style('Y', fg='green') if reachable else click.style('N', fg='red')):23s}"
         versionf = f"{version:15s}"
         is_activef = f"{(click.style('Y', fg='green') if is_active else click.style('N', fg='red')):24s}"
         experimentf = f"{experiment:15s}"
 
         click.echo(
             f"{hostnamef} {is_leaderf} {ipf} {statef} {is_activef} {reachablef} {versionf} {experimentf}"
         )
         return reachable & (state == "ready")
 
-    workers = get(f"http://{leader_address}/api/workers").json()
+    workers = get_from_leader("/api/workers").json()
     n_workers = len(workers)
 
     click.secho(
         f"{'Unit / hostname':20s} {'Is leader?':15s} {'IP address':20s} {'State':15s} {'Active?':15s} {'Reachable?':14s} {'Version':15s} {'Experiment':15s}",
         bold=True,
     )
     if n_workers == 0:
```

## pioreactor/experiment_profiles/parser.py

```diff
@@ -1,12 +1,15 @@
 # -*- coding: utf-8 -*-
 # mypy: ignore-errors
 # flake8: noqa
 from __future__ import annotations
 
+import math
+from random import random
+
 from msgspec import DecodeError
 from msgspec.json import decode
 
 from .sly import Lexer
 from .sly import Parser
 from pioreactor.pubsub import subscribe
 from pioreactor.whoami import get_assigned_experiment_name
@@ -30,40 +33,45 @@
     return input_str
 
 
 class ProfileLexer(Lexer):
     # != is the same as not
     tokens = {
         NAME,
+        FUNCTION,
         AND,
         OR,
         NOT,
         EQUAL,
         PLUS,
         MINUS,
         TIMES,
         DIVIDE,
+        EXPONENT,
         LESS_THAN,
         GREATER_THAN,
         LESS_THAN_OR_EQUAL,
         GREATER_THAN_OR_EQUAL,
         NUMBER,
         UNIT_JOB_SETTING,
     }
     ignore = " \t"
 
     # Tokens
     UNIT_JOB_SETTING = r"([a-zA-Z_\$][a-zA-Z0-9_]*:){2,}([a-zA-Z_\$][a-zA-Z0-9_]*\.)*[a-zA-Z_\$][a-zA-Z0-9_]*"
 
+    FUNCTION = r"[a-zA-Z_$][a-zA-Z0-9_]*\(\)"
+
     NAME = r"[a-zA-Z_$][a-zA-Z0-9_]*"
     NAME["and"] = AND
     NAME["or"] = OR
     NAME["not"] = NOT
 
     # Arithmetic Operators
+    EXPONENT = r"\*\*"  # Regular expression for exponentiation
     PLUS = r"\+"
     MINUS = r"-"
     TIMES = r"\*"
     DIVIDE = r"/"
 
     # Comparison Operators
     LESS_THAN_OR_EQUAL = r"<="
@@ -84,14 +92,15 @@
     precedence = (
         ("left", AND, OR),
         ("right", NOT),
         ("nonassoc", LESS_THAN, EQUAL, GREATER_THAN),
         ("right", UMINUS),
         ("left", PLUS, MINUS),
         ("left", TIMES, DIVIDE),
+        ("right", EXPONENT),
     )
 
     @_("expr AND expr", "expr OR expr")
     def expr(self, p):
         if p[1] == "and":
             return p.expr0 and p.expr1
         elif p[1] == "or":
@@ -100,14 +109,18 @@
     @_("PLUS expr %prec UMINUS", "MINUS expr %prec UMINUS")
     def expr(self, p):
         if p[0] == "+":
             return p.expr
         elif p[0] == "-":
             return -p.expr
 
+    @_("expr EXPONENT expr")  # Add rule for exponentiation
+    def expr(self, p):
+        return p.expr0**p.expr1
+
     @_("expr PLUS expr", "expr MINUS expr", "expr TIMES expr", "expr DIVIDE expr")
     def expr(self, p):
         if p[1] == "+":
             return p.expr0 + p.expr1
         elif p[1] == "-":
             return p.expr0 - p.expr1
         elif p[1] == "*":
@@ -137,19 +150,24 @@
         elif p[1] == "<=":
             return p.expr0 <= p.expr1
 
     @_("NOT expr")
     def expr(self, p):
         return not p.expr
 
+    @_("FUNCTION")
+    def expr(self, p):
+        if p.FUNCTION == "random()":
+            return random()
+
     @_("NAME")
     def expr(self, p):
-        if p.NAME == "True":
+        if p.NAME.lower() == "true":
             return True
-        elif p.NAME == "False":
+        elif p.NAME.lower() == "false":
             return False
         else:
             return p.NAME
 
     @_('"(" expr ")"')
     def expr(self, p):
         return p.expr
@@ -183,15 +201,15 @@
                 # its a nested json object, iteratively nest into it.
                 for key in keys:
                     value = value[key]
 
             return convert_string(value)
 
         else:
-            raise ValueError(f"{p.UNIT_JOB_SETTING} does not exist for experiment {experiment}")
+            raise ValueError(f"{p.UNIT_JOB_SETTING} does not exist for experiment `{experiment}`")
 
 
 def parse_profile_expression_to_bool(profile_string: str) -> bool:
     result = parse_profile_expression(profile_string)
     if result is None:
         # syntax error or something funky.
         raise SyntaxError(profile_string)
```

## pioreactor/plugin_management/install_plugin.py

```diff
@@ -10,20 +10,20 @@
 from pioreactor.logging import create_logger
 from pioreactor.whoami import UNIVERSAL_EXPERIMENT
 
 
 def install_plugin(name_of_plugin: str, source: str | None = None) -> None:
     logger = create_logger("install_plugin", experiment=UNIVERSAL_EXPERIMENT)
     logger.debug(f"Installing plugin {name_of_plugin}.")
-    command = [
+    command = (
         "bash",
         "/usr/local/bin/install_pioreactor_plugin.sh",
         quote(name_of_plugin),
         source or "",
-    ]
+    )
     logger.debug(" ".join(command))
 
     result = subprocess.run(command, capture_output=True)
 
     if result.returncode == 0:
         logger.notice(f"Successfully installed plugin {name_of_plugin}.")  # type: ignore
     else:
```

## pioreactor/utils/__init__.py

```diff
@@ -330,15 +330,15 @@
     > result = is_pio_job_running("od_reading")
     > # True
 
     > result = is_pio_job_running(["od_reading", "stirring"])
     > # [True, False]
     """
     if isinstance(target_jobs, str):
-        target_jobs = [target_jobs]
+        target_jobs = (target_jobs,)
 
     results = []
 
     with JobManager() as jm:
         for job in target_jobs:
             results.append(jm.is_job_running(job))
 
@@ -475,38 +475,44 @@
             time.sleep(sleep_for)
 
 
 def safe_kill(*args: int) -> None:
     from sh import kill  # type: ignore
 
     try:
-        kill(*args)
+        kill("-2", *args)
     except Exception:
         pass
 
 
 class ShellKill:
-    def __init__(self):
-        self.list_of_pids = []
+    def __init__(self) -> None:
+        self.list_of_pids: list[int] = []
 
-    def append(self, pid):
+    def append(self, pid: int) -> None:
         self.list_of_pids.append(pid)
 
-    def kill(self):
+    def kill(self) -> None:
+        if len(self.list_of_pids) == 0:
+            return
+
         safe_kill(*self.list_of_pids)
 
 
 class MQTTKill:
-    def __init__(self):
-        self.list_of_job_names = []
+    def __init__(self) -> None:
+        self.list_of_job_names: list[str] = []
 
-    def append(self, name):
+    def append(self, name: str) -> None:
         self.list_of_job_names.append(name)
 
-    def kill(self):
+    def kill(self) -> None:
+        if len(self.list_of_job_names) == 0:
+            return
+
         from pioreactor.pubsub import create_client
 
         with create_client() as client:
             for i, name in enumerate(self.list_of_job_names):
                 msg = client.publish(
                     f"pioreactor/{whoami.get_unit_name()}/{whoami.UNIVERSAL_EXPERIMENT}/{name}/$state/set",
                     "disconnected",
@@ -590,15 +596,14 @@
 
             # Construct the SELECT query
             select_query = f"""
                 SELECT
                     name, pid
                 FROM pio_job_metadata
                 WHERE is_running=1
-                AND name NOT IN {self.LONG_RUNNING_JOBS}
                 AND {where_clause};
             """
 
             # Execute the query and fetch the results
             self.cursor.execute(select_query, query)
 
         else:
@@ -606,38 +611,40 @@
             select_query = f"SELECT name, pid FROM pio_job_metadata WHERE is_running=1 AND name NOT IN {self.LONG_RUNNING_JOBS}"
 
             # Execute the query and fetch the results
             self.cursor.execute(select_query)
 
         return self.cursor.fetchall()
 
-    def count_jobs(self, all_jobs: bool = False, **query) -> int:
-        return len(self._get_jobs(all_jobs, **query))
-
-    def kill_jobs(self, all_jobs: bool = False, **query) -> None:
+    def kill_jobs(self, all_jobs: bool = False, **query) -> int:
         # ex: kill_jobs(experiment="testing_exp") should return end all jobs with experiment='testing_exp'
 
         mqtt_kill = MQTTKill()
         shell_kill = ShellKill()
+        count = 0
 
         for job, pid in self._get_jobs(all_jobs, **query):
             if job in self.PUMPING_JOBS:
                 mqtt_kill.append(job)
+                count += 1
             elif job == "led_intensity":
-                # led_intensity doesn't register with the JobManager, probably should somehow.
+                # led_intensity doesn't register with the JobManager, probably should somehow. #502
                 pass
             elif job in self.AUTOMATION_JOBS:
                 # don't kill them, the parent will.
                 pass
             else:
                 shell_kill.append(pid)
+                count += 1
 
         mqtt_kill.kill()
         shell_kill.kill()
 
+        return count
+
     def __enter__(self) -> JobManager:
         return self
 
     def __exit__(self, *args) -> None:
         self.conn.close()
         return
```

## pioreactor/utils/adcs.py

```diff
@@ -1,13 +1,11 @@
 # -*- coding: utf-8 -*-
 # adc abstraction
 from __future__ import annotations
 
-from typing import cast
-
 import busio  # type: ignore
 
 from pioreactor import exc
 from pioreactor import hardware
 from pioreactor import types as pt
 from pioreactor.version import hardware_version_info
 
@@ -75,15 +73,18 @@
                 break
 
     def set_ads_gain(self, gain: float) -> None:
         self._ads.gain = gain  # this assignment will check to see if the gain is allowed.
 
     def from_voltage_to_raw(self, voltage: pt.Voltage) -> pt.AnalogValue:
         # from https://github.com/adafruit/Adafruit_CircuitPython_ADS1x15/blob/e33ed60b8cc6bbd565fdf8080f0057965f816c6b/adafruit_ads1x15/analog_in.py#L61
-        return cast(pt.AnalogValue, voltage * 32767 / self.ADS1X15_PGA_RANGE[self.gain])
+        return int(voltage * 32767 / self.ADS1X15_PGA_RANGE[self.gain])
+
+    def from_voltage_to_raw_precise(self, voltage: pt.Voltage) -> pt.AnalogValue:
+        return voltage * 32767 / self.ADS1X15_PGA_RANGE[self.gain]
 
     def from_raw_to_voltage(self, raw: pt.AnalogValue) -> pt.Voltage:
         # from https://github.com/adafruit/Adafruit_CircuitPython_ADS1x15/blob/e33ed60b8cc6bbd565fdf8080f0057965f816c6b/adafruit_ads1x15/analog_in.py#L61
         return raw / 32767 * self.ADS1X15_PGA_RANGE[self.gain]
 
     def read_from_channel(self, channel: pt.AdcChannel) -> pt.AnalogValue:
         assert 0 <= channel <= 3
```

## pioreactor/utils/networking.py

```diff
@@ -61,15 +61,15 @@
     return False
 
 
 def get_ip() -> Optional[str]:
     # returns ipv4
     from psutil import net_if_addrs
 
-    interfaces = ["wlan0", "eth0"]
+    interfaces = ("wlan0", "eth0")
 
     for iface in interfaces:
         try:
             ipv4_addresses = [
                 addr.address for addr in net_if_addrs()[iface] if addr.family == 2
             ]  # AddressFamily.AF_INET == 2
             if ipv4_addresses:
@@ -104,15 +104,19 @@
 
     class Listener(ServiceListener):
         def __init__(self) -> None:
             self.hostnames: Queue[str] = Queue()
 
         def add_service(self, zc: Zeroconf, type_: str, name: str) -> None:
             info = zc.get_service_info(type_, name)
-            self.hostnames.put(info.server.removesuffix(".local."))  # type: ignore
+            try:
+                self.hostnames.put(info.server.removesuffix(".local."))  # type: ignore
+            except AttributeError:
+                # sometimes, we've seen info.server not exist, often when there is a problem with mdns reflections / duplications
+                pass
 
         def remove_service(self, *args, **kwargs):
             pass
 
         def update_service(self, *args, **kwargs):
             pass
```

## pioreactor/utils/pwm.py

```diff
@@ -246,15 +246,19 @@
             elif self.pin in cache and self.duty_cycle == 0:
                 cache.pop(self.pin)
             # else: # self.duty_cycle == 0 and self.pin not in cache, leave it.
 
             for k in cache:
                 if k == self.pin:
                     continue
-                current_values[k] = cache[k]
+                # we use get here because if two processes are updating the cache, and one of them deletes from the cache,
+                # this will raise a keyerror when we try to retrieve it.
+                value = cache.get(k, 0)
+                if value != 0:
+                    current_values[k] = value
 
         self.pubsub_client.publish(
             f"pioreactor/{self.unit}/{self.experiment}/pwms/dc", dumps(current_values), retain=True
         )
 
     def start(self, duty_cycle: pt.FloatBetween0and100) -> None:
         if not (0.0 <= duty_cycle <= 100.0):
```

## Comparing `pioreactor-24.5.1rc0.dist-info/LICENSE` & `pioreactor-24.5.20rc0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `pioreactor-24.5.1rc0.dist-info/METADATA` & `pioreactor-24.5.20rc0.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: pioreactor
-Version: 24.5.1rc0
+Version: 24.5.20rc0
 Summary: The core Python app of the Pioreactor. Control your bioreactor through Python.
 Home-page: https://github.com/pioreactor/pioreactor
 Author: Pioreactor
 Author-email: hello@pioreactor.com
 License: MIT
 Keywords: microbiology,bioreactor,turbidostat,raspberry pi,education,research
 Classifier: Topic :: Scientific/Engineering
@@ -12,37 +12,37 @@
 Classifier: Intended Audience :: Science/Research
 Classifier: Intended Audience :: Education
 Classifier: Development Status :: 5 - Production/Stable
 Requires-Python: >=3.11
 Description-Content-Type: text/markdown
 License-File: LICENSE
 Requires-Dist: click ==8.1.7
-Requires-Dist: paho-mqtt ==1.6.1
+Requires-Dist: paho-mqtt ==2.1.0
 Requires-Dist: psutil ==5.9.5
 Requires-Dist: sh ==2.0.6
 Requires-Dist: JSON-log-formatter ==0.5.1
 Requires-Dist: colorlog ==6.7.0
 Requires-Dist: msgspec ==0.18.5
 Requires-Dist: diskcache ==5.6.3
 Requires-Dist: wheel ==0.41.2
 Requires-Dist: crudini ==0.9.5
 Provides-Extra: leader
 Requires-Dist: zeroconf ==0.115.2 ; extra == 'leader'
-Requires-Dist: flask ==3.0.0 ; extra == 'leader'
+Requires-Dist: flask ==3.0.2 ; extra == 'leader'
 Requires-Dist: flup6 ==1.1.1 ; extra == 'leader'
-Requires-Dist: python-dotenv ==1.0.0 ; extra == 'leader'
+Requires-Dist: python-dotenv ==1.0.1 ; extra == 'leader'
 Requires-Dist: huey ==2.5.0 ; extra == 'leader'
-Requires-Dist: werkzeug ==3.0.1 ; extra == 'leader'
+Requires-Dist: werkzeug ==3.0.3 ; extra == 'leader'
 Provides-Extra: leader_worker
 Requires-Dist: zeroconf ==0.115.2 ; extra == 'leader_worker'
-Requires-Dist: flask ==3.0.0 ; extra == 'leader_worker'
+Requires-Dist: flask ==3.0.2 ; extra == 'leader_worker'
 Requires-Dist: flup6 ==1.1.1 ; extra == 'leader_worker'
-Requires-Dist: python-dotenv ==1.0.0 ; extra == 'leader_worker'
+Requires-Dist: python-dotenv ==1.0.1 ; extra == 'leader_worker'
 Requires-Dist: huey ==2.5.0 ; extra == 'leader_worker'
-Requires-Dist: werkzeug ==3.0.1 ; extra == 'leader_worker'
+Requires-Dist: werkzeug ==3.0.3 ; extra == 'leader_worker'
 Requires-Dist: adafruit-circuitpython-ads1x15 ==2.2.23 ; extra == 'leader_worker'
 Requires-Dist: DAC43608 ==0.2.7 ; extra == 'leader_worker'
 Requires-Dist: TMP1075 ==0.2.1 ; extra == 'leader_worker'
 Requires-Dist: rpi-hardware-pwm ==0.2.1 ; extra == 'leader_worker'
 Requires-Dist: plotext ==5.2.8 ; extra == 'leader_worker'
 Provides-Extra: worker
 Requires-Dist: adafruit-circuitpython-ads1x15 ==2.2.23 ; extra == 'worker'
```

## Comparing `pioreactor-24.5.1rc0.dist-info/RECORD` & `pioreactor-24.5.20rc0.dist-info/RECORD`

 * *Files 16% similar despite different names*

```diff
@@ -1,31 +1,31 @@
 pioreactor/__init__.py,sha256=YBDDaFMxxsG_1Dg9ss9llZcW95gAh8WqpcdCjhF0T-E,117
 pioreactor/config.py,sha256=QqeRVVJoqMOtMszp6M5nnbEPkjM1pCO7yrI1uFcgqas,5868
 pioreactor/error_codes.py,sha256=XDfT3fPTVKN9wIGM9DdrXdvrEUn7lQkf6CJd8Xj_vFo,265
 pioreactor/exc.py,sha256=9fnJVIpg9Yyxq2e1qoWrE1ekMu7QcMHkjdRRkc7Pk3w,958
-pioreactor/hardware.py,sha256=9kdFrdLxgNPMFgXZSijV8zjVJy26zPET0K9axVb-tmI,3854
-pioreactor/logging.py,sha256=8c5TZMQMQ1rIjxWX3BPxr7jHKrZhl__A6rUAeFWDuMY,6588
-pioreactor/mureq.py,sha256=HazeoeohPwmWKCMO2PlUYfJXxD9ukaAmnnXzILrLYtw,15631
-pioreactor/pubsub.py,sha256=vtox-oh0RtasA2hGAx3heS6J2KWN_toOYWx3xwnoSJU,10903
+pioreactor/hardware.py,sha256=JbrN1pcR6w1D736duno1hC0cjRrypJgUZ7iaD1jwvTE,3870
+pioreactor/logging.py,sha256=peMaE99jk137COtT07MzziDfrVUWjm9TFqe6v0Sjf4M,6784
+pioreactor/mureq.py,sha256=aClIM1v2g1n8exL6SqfRvzafDhqyC0JAyNcIvjr5KSs,15578
+pioreactor/pubsub.py,sha256=Jn4zxQTjigJXCw_XjwfDJfw3ECaZiFdIeZRZMSGrJRo,12814
 pioreactor/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pioreactor/structs.py,sha256=UIYVXEJEz80cHdjiqFOhWzwFoOaBv6-9zllGBfOlJXw,6361
 pioreactor/types.py,sha256=Dh5nDPrqQQ4maMtMeqrUeXRzwHsJIzKFM2QfR9ZPLQ8,3304
-pioreactor/version.py,sha256=qnTgL766manrib3NDARViSWKAXWEG0leurjpkzxY0Ig,3022
-pioreactor/whoami.py,sha256=JRko2UvKgPkLACo9om2UiuInqY6vviuuYSB1NL_Ou8A,5844
+pioreactor/version.py,sha256=6eJNy1IfzTFM_c8wQw4Km59cggPqReYTcmPni8E0W-M,3023
+pioreactor/whoami.py,sha256=ygOj7SXbhcT0kqOljIttyVT2DrQ5kjXOiYWlWaoWiB8,5968
 pioreactor/actions/__init__.py,sha256=VuwIL8llFFqBspvBRgC9yNm-Blu9tsE2kwgIJEs786o,540
 pioreactor/actions/led_intensity.py,sha256=_qhvooLA1mdGTSW3Z9dcxAXbR7hD6ZQqKg7MWi7PEEY,8810
 pioreactor/actions/od_blank.py,sha256=flKxWK0BySZzdJwW8oqn4RPiALIVRScI2yy5lpwlC2E,9013
-pioreactor/actions/od_calibration.py,sha256=LYZeQ217hw001RIDyHXeSMbQWItMMQqohbROD3hoAAA,24592
-pioreactor/actions/pump.py,sha256=6seq-0Do6CZSh25kaCKOhfs6RDGYmNWtcv72U9tbjeA,19799
-pioreactor/actions/pump_calibration.py,sha256=pRUlESvtvr1AhmKqr3HO50cRF5KTi4AixztxoHJvLow,22445
-pioreactor/actions/self_test.py,sha256=Ge_5OkSuaPYd8hMkjB0mod4g23Fa5RTrxefxospuCVM,20153
+pioreactor/actions/od_calibration.py,sha256=nkr0eLgjJJqI_XrBtL_3Lj5g9wgoOcAFA1jZi28MPeE,24499
+pioreactor/actions/pump.py,sha256=rLhZcai_q64xCFDLRJBmYe5jgYrrz6fkmLgrppOtvYY,19823
+pioreactor/actions/pump_calibration.py,sha256=w21j3J-CeTDTT6wFBRZcvxdtXKeo_V2SOXTB8h7Jzgw,22352
+pioreactor/actions/self_test.py,sha256=iH4LnhJJ0TA3d6JCWlplZF3UeOLuC_lMU_V32ga8LGw,20768
 pioreactor/actions/stirring_calibration.py,sha256=i2IGq2pUfKC6l63MNFgEwopouuy-ts7sJxuaGmCWpA4,5339
 pioreactor/actions/leader/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pioreactor/actions/leader/backup_database.py,sha256=G3SMLyMgR9Hrfo7qyjvfEVtVc9EcfcimuvsYBKfoAEI,4902
-pioreactor/actions/leader/experiment_profile.py,sha256=XmWcZlWrN6IBdrcGg5pAMKOEItptpnKI49swCiPKeFU,25244
+pioreactor/actions/leader/experiment_profile.py,sha256=G3M3K_gJtr9csy6PevFk18Az5qvBPQ7oRZTnXuCNNeU,25120
 pioreactor/actions/leader/export_experiment_data.py,sha256=qU-ZTC8RXtZZp6mzqjcyMM9JdKS5bP2zHmmF6cySZ8M,6544
 pioreactor/automations/__init__.py,sha256=PTQQNnA-xrcDLHa0a0ZVM1fYw--rwRSrcoXRvJDHSN0,146
 pioreactor/automations/base.py,sha256=ZCRXAMvz7rtER8zT6wFLxuw6KfimsMhf9f1G9k3y24o,1000
 pioreactor/automations/dosing/__init__.py,sha256=dqTWOveaUiOvaWZ_U90UtN2w_pqDbM1qBIn5X9dat_E,459
 pioreactor/automations/dosing/base.py,sha256=Cf-poCPOW67_43uVMbWK_boQAtpqmMUXBzQXnkpVQKI,29432
 pioreactor/automations/dosing/chemostat.py,sha256=bf3a3gAe_6OZztB7RsNuYFinimdZty5tR5WwJhYGBks,1424
 pioreactor/automations/dosing/fed_batch.py,sha256=YZv5h0PHRwXT4dpEELWGQnNbvgKypzE1CuxiUWuVl_k,1497
@@ -37,56 +37,56 @@
 pioreactor/automations/led/base.py,sha256=YeVMwzeWthExN7Boxd2cetkrKIgq57fDgtGY6g8spY8,12023
 pioreactor/automations/led/light_dark_cycle.py,sha256=GX50pON5HbZxIUxQMl_WfeYKV_ERtyiJjxQIgbfzNsE,3875
 pioreactor/automations/temperature/__init__.py,sha256=rxAitEYRWPQqFWvGUl_XIe9FwyzwRVQTQmaReafOfBM,154
 pioreactor/automations/temperature/base.py,sha256=jYxG-uG5VFtsyYmPp_HuVbCxemYnmgedaYQusxLPTew,9317
 pioreactor/automations/temperature/only_record_temperature.py,sha256=DB-6Dxn_CQ54YoNKsD46F6EnKi2o5kJDKkhfqB0ekKI,561
 pioreactor/automations/temperature/thermostat.py,sha256=dM6lOTffSGSP4Ow8rvqWFjOMaebde7h84CAWrDhISZE,4375
 pioreactor/background_jobs/__init__.py,sha256=pn23vImMyfiHjbdKObOWpAwzNUbE1xnHWUYk4j4KSJM,715
-pioreactor/background_jobs/base.py,sha256=dAaNirpR8Nxkg2_5heWgmDOXU1_OZryBdm6nmA0IxAM,45137
-pioreactor/background_jobs/dosing_control.py,sha256=PSohU2cgQANjMJbpS2i7Z5lobQUPgzBD-AB9Ordfma4,7043
-pioreactor/background_jobs/growth_rate_calculating.py,sha256=UYspbPYWQ6nH-hxvQr_NI3jLVlWj2jYzSzrkxHG_F0g,22053
-pioreactor/background_jobs/led_control.py,sha256=oS2rZtHlq8Ct2WZ_3y2L_coqbtIJGvQeqBdmwiYeG4o,5806
-pioreactor/background_jobs/monitor.py,sha256=qW5wlmD7Slmugls9ytQom1DBV_1V6KRRA3oqe3zUitk,29930
-pioreactor/background_jobs/od_reading.py,sha256=JTL0XZkeFqk0rVUrZ1UYqPVLhbOAfJbidFYaoWZWjkw,52952
-pioreactor/background_jobs/stirring.py,sha256=2xXIup_mC54bNfVM9-P6qIR6yKIiA3nUK3lvkIE7CDM,18124
-pioreactor/background_jobs/temperature_control.py,sha256=YBBrCn9av-bHVze3NMP621aPPKUmR0mJrN8S4qB_MpY,26075
+pioreactor/background_jobs/base.py,sha256=YvJTmE0aD8RwxoslkBTHxIi4hQAcO73_ze_xY06P65I,46096
+pioreactor/background_jobs/dosing_control.py,sha256=0z0s2zORTDtH1ZHw4u_eL67RRe4MtMZCRnFRONA6arQ,7012
+pioreactor/background_jobs/growth_rate_calculating.py,sha256=FMjnRGgTdlCasTZzosngXllPyNMsR7WUV0RCOa_uJmo,22014
+pioreactor/background_jobs/led_control.py,sha256=9fazgYqBkXBE060TaOyaTL04kn_cjfZFxLvZ7_NaMkI,5776
+pioreactor/background_jobs/monitor.py,sha256=zlTIHC3QdUrLkLRxsuaCME80MaaGoeUNTip8_cqaTRY,30216
+pioreactor/background_jobs/od_reading.py,sha256=U0HQgiscgPqXFwD3-rqE7Fyp2fwKHNcERp_fGrzAwnw,52593
+pioreactor/background_jobs/stirring.py,sha256=F8esFCQw0NLbQOuEOEkdPHI5tPN9EOBjzl3OD_kg-mY,18187
+pioreactor/background_jobs/temperature_control.py,sha256=3jozuOH8CP4DyZIWCYIIO53HF7gpVGSUC6uF5YKjjh8,26711
 pioreactor/background_jobs/leader/__init__.py,sha256=Uhl2Xksfkf06lmfmz2scTxmBWDBnwkA9rSil_V94aWQ,605
-pioreactor/background_jobs/leader/mqtt_to_db_streaming.py,sha256=IfYLPKM4CyaVdDlvx_DtL90bCdaRdCddxzWxdjCWkwk,16997
-pioreactor/background_jobs/leader/watchdog.py,sha256=yBY9lYoiAJI4K7b4OpEHTyaJDQNIDXn7Ug7d6u1a_GU,4573
+pioreactor/background_jobs/leader/mqtt_to_db_streaming.py,sha256=Y4I1yiRzauSj5vovWcVAOGJfSzRUi8KQHofYEP0pD28,17024
+pioreactor/background_jobs/leader/watchdog.py,sha256=OgOMSd5r4Rph3WGC6WIt20whMQS1v5Yw8UdYCuvPldo,4679
 pioreactor/background_jobs/subjobs/__init__.py,sha256=RP7U5Q5cWqmmlmiVwAbVnwGyEnhqJM6fk71VP-3Y0c0,1094
 pioreactor/cli/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pioreactor/cli/lazy_group.py,sha256=yVmwvXO1dInCcFbY13vFsH0lvYQozDHeWfr-7rlMYBE,1408
-pioreactor/cli/pio.py,sha256=af0TkVADm_z79OspGrZXHg6q1h0IGzksXDiYN3aHOjA,24433
-pioreactor/cli/pios.py,sha256=TGDqZZCOr2SKOyVQ8xIY57MKVGwkKy3ZyidOxyiUmgw,26918
+pioreactor/cli/pio.py,sha256=QMeldX8L-NIia8Q170tfeIFTLpom9TUfH53B-szaWDo,24386
+pioreactor/cli/pios.py,sha256=yeCoTk5SrvB0KCKIDIwRDhEBm33uRsLB0U8TnBVgQJ0,27111
 pioreactor/cli/plugins.py,sha256=ETiDAZscou6bCtpD9zPG2_5IYSKohqFlyvJh5xjA-bE,365
 pioreactor/cli/run.py,sha256=quWPHpNBZ2npTvPv29RuEiiUonc9pEA3-zx2cRhEflY,1949
 pioreactor/cli/workers.py,sha256=2I_NmtyvIDlkEYPO0Q8tU5EIwDpYoZGJAtoxWbkZqtk,700
-pioreactor/cluster_management/__init__.py,sha256=WJ_AUvY_jqTaWKUajlW3HtC1qZTC4DiZfXHcEzUN8lc,10403
+pioreactor/cluster_management/__init__.py,sha256=L1GLCLKKHoMo--PX39HFoYshDxjhGnxA2pCBf1R_nBE,10326
 pioreactor/experiment_profiles/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-pioreactor/experiment_profiles/parser.py,sha256=lYDWjhTirYWiWAx6o7T_K044FwQsmPNGmqQYmXT50sg,5488
+pioreactor/experiment_profiles/parser.py,sha256=KyLjnmRxkTeg03Ya0G9QWPqpmNlebwDZRBJpIK0BrFw,5945
 pioreactor/experiment_profiles/profile_struct.py,sha256=OIok66XPpbba8ghUqzQL9EkT9OqbAzO5gcXSohHP6oY,2896
 pioreactor/experiment_profiles/sly/__init__.py,sha256=Z7rV-XpX5Nz29NqaaJ7ln8hHgY6WYqC5t-59YYt8xqs,197
 pioreactor/experiment_profiles/sly/lex.py,sha256=Dwt9dJqVw92BpmfwWR0PzqduLpD5qE-ILgSj_vXUlRg,16273
 pioreactor/experiment_profiles/sly/yacc.py,sha256=EfzAO8Wg4Cb8wOPBaf8pK37MDsk0KFjTEN8BHgDMXi0,83015
 pioreactor/plugin_management/__init__.py,sha256=ivql-g9QTAWn_xvFCoFYj0BzUBcWxYp-AQKKifUdNXQ,3807
-pioreactor/plugin_management/install_plugin.py,sha256=7BCWXWfirkF71uJHwnjEeoRWKdbeldgUQVAG6OVyvGg,1439
+pioreactor/plugin_management/install_plugin.py,sha256=H5kr7MJRZbP-JW_e-Sx6gLnl8XRQm7xZ7ufiDKBq1vs,1439
 pioreactor/plugin_management/list_plugins.py,sha256=MM5eNvVO4ibbOwcj3B6yMkDnlrwAF912I2nO51chLVw,1123
 pioreactor/plugin_management/uninstall_plugin.py,sha256=S8x3nqQ2euSbhiBPTYVHtpQeuw3fqYxwB7M0XNYCCW4,1782
 pioreactor/plugin_management/utils.py,sha256=Cferq4vLR0JuXjZY135tm_fcszm5_8bNP4eToOH2Slw,1194
-pioreactor/utils/__init__.py,sha256=eg6BigGHepUYYj2qMegu8bLdBZryq6kNu9WdN4dUDoc,21578
-pioreactor/utils/adcs.py,sha256=8tLRJuZFUB0JFLCnQ7WFkx171DlYgigLcCzo3xy-pwQ,4240
+pioreactor/utils/__init__.py,sha256=DEoSiWeZcdxm8QSbOSgtB5ALTw7Wy2wJY9UW_EYyFWc,21710
+pioreactor/utils/adcs.py,sha256=60ZjR4RoZstII0K2hByzAJd7aF1K8S0ps62AhaQyQqg,4348
 pioreactor/utils/dacs.py,sha256=gPAEjRseVA3-Ta5MTHpwi0HRdbWVd47pD21FcCaQwFY,1930
 pioreactor/utils/gpio_helpers.py,sha256=9lAKuEMuLIqXtTk6wRisKABo_Ab0n-zGcBjtN8gjX2I,976
 pioreactor/utils/math_helpers.py,sha256=lHAaO2X6tH8oP5Znk7CoO5l-phdPpgAR1AQTecVZr88,3311
 pioreactor/utils/mock.py,sha256=o5tNfE40supfTBDurMCgbXp2dqtsCsXeK3Hl6LotJow,5211
-pioreactor/utils/networking.py,sha256=6I3sykzSFPfrS1erIRFu33Cq8x-25I_UFdJTdsn9KOg,3622
-pioreactor/utils/pwm.py,sha256=lg7TPhBNKemcMSQaJ3IEDW3JsBV2-mIgxrn0e8ySuXs,10230
+pioreactor/utils/networking.py,sha256=d_uSkTn4sGotXTowBwt9R_HrjCEQ_LqLZ6nZJ7X5Njg,3829
+pioreactor/utils/pwm.py,sha256=l-BAZK2vPPJYLLTfSlIsqVB28mdLymO1Izuuy12ubck,10498
 pioreactor/utils/rpi_bad_power.py,sha256=CbtzIi9x8pvtVAX6aID8MG5YXNzkeIRFYfhri4qI-Xo,3393
 pioreactor/utils/sqlite_worker.py,sha256=TKgohPrZu3HsttrzH7HDmwkk5KWSEkFT1sFTB7jQkBc,7889
 pioreactor/utils/streaming_calculations.py,sha256=RP2ZIG7oylkJipXRvCn8uxd2JO979MSrI1U6jFxHM80,18416
 pioreactor/utils/timing.py,sha256=x_CPXqm4pkaaz5I3XUkTM49XJbjTETXKya3YRkbCwSk,5827
-pioreactor-24.5.1rc0.dist-info/LICENSE,sha256=V9lTmv9cMeiSZ_9ezl7s5LVGXkZ4t7PUzVxIeVqkk7k,1067
-pioreactor-24.5.1rc0.dist-info/METADATA,sha256=OV-fvW5bl-DbgLlgdfz9yl-rOnSxB1YCxRK_ed2DAS8,3721
-pioreactor-24.5.1rc0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-pioreactor-24.5.1rc0.dist-info/entry_points.txt,sha256=1vQa-58PTH44hOQBeYFJdO3Tdfzea7_pYDxv5KQWvZ4,79
-pioreactor-24.5.1rc0.dist-info/top_level.txt,sha256=xhd14Ee_KR74whX88OzvljqlGXmfpBUHOSIqDrbs9_0,11
-pioreactor-24.5.1rc0.dist-info/RECORD,,
+pioreactor-24.5.20rc0.dist-info/LICENSE,sha256=V9lTmv9cMeiSZ_9ezl7s5LVGXkZ4t7PUzVxIeVqkk7k,1067
+pioreactor-24.5.20rc0.dist-info/METADATA,sha256=Cb9aXRH7bD412c7QckECiuzCKd8mBzqIWV_Hs5VhLAY,3722
+pioreactor-24.5.20rc0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+pioreactor-24.5.20rc0.dist-info/entry_points.txt,sha256=1vQa-58PTH44hOQBeYFJdO3Tdfzea7_pYDxv5KQWvZ4,79
+pioreactor-24.5.20rc0.dist-info/top_level.txt,sha256=xhd14Ee_KR74whX88OzvljqlGXmfpBUHOSIqDrbs9_0,11
+pioreactor-24.5.20rc0.dist-info/RECORD,,
```

