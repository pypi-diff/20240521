# Comparing `tmp/pygpc-0.3.8-cp39-cp39-win_amd64.whl.zip` & `tmp/pygpc-0.3.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.zip`

## zipinfo {}

```diff
@@ -1,43 +1,48 @@
-Zip file size: 942633 bytes, number of entries: 41
--rw-rw-rw-  2.0 fat    11978 b- defN 23-Oct-03 17:21 pygpc/AbstractModel.py
--rw-rw-rw-  2.0 fat   253432 b- defN 23-Oct-03 17:21 pygpc/Algorithm.py
--rw-rw-rw-  2.0 fat    21784 b- defN 23-Oct-03 17:21 pygpc/Basis.py
--rw-rw-rw-  2.0 fat    10464 b- defN 23-Oct-03 17:21 pygpc/BasisFunction.py
--rw-rw-rw-  2.0 fat     6340 b- defN 23-Oct-03 17:21 pygpc/Classifier.py
--rw-rw-rw-  2.0 fat    18799 b- defN 23-Oct-03 17:21 pygpc/Computation.py
--rw-rw-rw-  2.0 fat    51275 b- defN 23-Oct-03 17:21 pygpc/GPC.py
--rw-rw-rw-  2.0 fat    17811 b- defN 23-Oct-03 17:21 pygpc/Gradient.py
--rw-rw-rw-  2.0 fat   165623 b- defN 23-Oct-03 17:21 pygpc/Grid.py
--rw-rw-rw-  2.0 fat    38729 b- defN 23-Oct-03 17:21 pygpc/MEGPC.py
--rw-rw-rw-  2.0 fat     4397 b- defN 23-Oct-03 17:21 pygpc/Problem.py
--rw-rw-rw-  2.0 fat    12625 b- defN 23-Oct-03 17:21 pygpc/Quadrature.py
--rw-rw-rw-  2.0 fat    19943 b- defN 23-Oct-03 17:21 pygpc/RandomParameter.py
--rw-rw-rw-  2.0 fat    28505 b- defN 23-Oct-03 17:21 pygpc/SGPC.py
--rw-rw-rw-  2.0 fat     4941 b- defN 23-Oct-03 17:21 pygpc/Session.py
--rw-rw-rw-  2.0 fat    27944 b- defN 23-Oct-03 17:21 pygpc/Test.py
--rw-rw-rw-  2.0 fat    19044 b- defN 23-Oct-03 17:21 pygpc/TestBench.py
--rw-rw-rw-  2.0 fat     7364 b- defN 23-Oct-03 17:21 pygpc/ValidationSet.py
--rw-rw-rw-  2.0 fat    18580 b- defN 23-Oct-03 17:21 pygpc/Visualization.py
--rw-rw-rw-  2.0 fat     4150 b- defN 23-Oct-03 17:21 pygpc/Worker.py
--rw-rw-rw-  2.0 fat      522 b- defN 23-Oct-03 17:21 pygpc/__init__.py
--rw-rw-rw-  2.0 fat    40807 b- defN 23-Oct-03 17:21 pygpc/io.py
--rw-rw-rw-  2.0 fat    44760 b- defN 23-Oct-03 17:21 pygpc/misc.py
--rw-rw-rw-  2.0 fat     3628 b- defN 23-Oct-03 17:21 pygpc/oakley_ohagan_2004_M.txt
--rw-rw-rw-  2.0 fat      118 b- defN 23-Oct-03 17:21 pygpc/oakley_ohagan_2004_a1.txt
--rw-rw-rw-  2.0 fat      118 b- defN 23-Oct-03 17:21 pygpc/oakley_ohagan_2004_a2.txt
--rw-rw-rw-  2.0 fat      118 b- defN 23-Oct-03 17:21 pygpc/oakley_ohagan_2004_a3.txt
--rw-rw-rw-  2.0 fat    46666 b- defN 23-Oct-03 17:21 pygpc/postprocessing.py
--rw-rw-rw-  2.0 fat    12800 b- defN 23-Oct-03 17:24 pygpc/pygpc_extensions.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat    12148 b- defN 23-Oct-03 17:21 pygpc/sobol_saltelli.py
--rw-rw-rw-  2.0 fat  2984328 b- defN 23-Oct-03 17:21 pygpc/sobol_saltelli_directions.hdf5
--rw-rw-rw-  2.0 fat     7340 b- defN 23-Oct-03 17:21 pygpc/test_utils.py
--rw-rw-rw-  2.0 fat    18493 b- defN 23-Oct-03 17:21 pygpc/validation.py
--rw-rw-rw-  2.0 fat       30 b- defN 23-Oct-03 17:21 pygpc/testfunctions/__init__.py
--rw-rw-rw-  2.0 fat    20588 b- defN 23-Oct-03 17:21 pygpc/testfunctions/euber_libV3.py
--rw-rw-rw-  2.0 fat   144044 b- defN 23-Oct-03 17:21 pygpc/testfunctions/testfunctions.py
--rw-rw-rw-  2.0 fat    35823 b- defN 23-Oct-03 17:53 pygpc-0.3.8.dist-info/LICENSE
--rw-rw-rw-  2.0 fat      592 b- defN 23-Oct-03 17:53 pygpc-0.3.8.dist-info/METADATA
--rw-rw-rw-  2.0 fat      100 b- defN 23-Oct-03 17:53 pygpc-0.3.8.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        6 b- defN 23-Oct-03 17:53 pygpc-0.3.8.dist-info/top_level.txt
--rw-rw-r--  2.0 fat     3226 b- defN 23-Oct-03 17:53 pygpc-0.3.8.dist-info/RECORD
-41 files, 4119983 bytes uncompressed, 937647 bytes compressed:  77.3%
+Zip file size: 1024586 bytes, number of entries: 46
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-21 21:49 pygpc/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-21 21:49 pygpc.libs/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-21 21:49 pygpc-0.3.9.dist-info/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-21 21:49 pygpc/testfunctions/
+-rw-r--r--  2.0 unx    21343 b- defN 24-May-21 21:49 pygpc/Basis.py
+-rw-r--r--  2.0 unx    17421 b- defN 24-May-21 21:49 pygpc/Gradient.py
+-rw-r--r--  2.0 unx    18335 b- defN 24-May-21 21:49 pygpc/Computation.py
+-rw-r--r--  2.0 unx    10143 b- defN 24-May-21 21:49 pygpc/BasisFunction.py
+-rw-r--r--  2.0 unx      501 b- defN 24-May-21 21:49 pygpc/__init__.py
+-rw-r--r--  2.0 unx   248729 b- defN 24-May-21 21:49 pygpc/Algorithm.py
+-rwxr-xr-x  2.0 unx      104 b- defN 24-May-21 21:49 pygpc/oakley_ohagan_2004_a3.txt
+-rwxr-xr-x  2.0 unx    58393 b- defN 24-May-21 21:49 pygpc/pygpc_extensions.cpython-39-x86_64-linux-gnu.so
+-rw-r--r--  2.0 unx    45626 b- defN 24-May-21 21:49 pygpc/postprocessing.py
+-rw-r--r--  2.0 unx    50292 b- defN 24-May-21 21:49 pygpc/GPC.py
+-rw-r--r--  2.0 unx    11826 b- defN 24-May-21 21:49 pygpc/sobol_saltelli.py
+-rw-r--r--  2.0 unx    37857 b- defN 24-May-21 21:49 pygpc/MEGPC.py
+-rwxr-xr-x  2.0 unx      104 b- defN 24-May-21 21:49 pygpc/oakley_ohagan_2004_a1.txt
+-rw-r--r--  2.0 unx    39468 b- defN 24-May-21 21:49 pygpc/io.py
+-rw-r--r--  2.0 unx     4288 b- defN 24-May-21 21:49 pygpc/Problem.py
+-rwxr-xr-x  2.0 unx      104 b- defN 24-May-21 21:49 pygpc/oakley_ohagan_2004_a2.txt
+-rw-r--r--  2.0 unx    19280 b- defN 24-May-21 21:49 pygpc/RandomParameter.py
+-rw-r--r--  2.0 unx     6164 b- defN 24-May-21 21:49 pygpc/Classifier.py
+-rwxr-xr-x  2.0 unx  2984328 b- defN 24-May-21 21:49 pygpc/sobol_saltelli_directions.hdf5
+-rw-r--r--  2.0 unx    43468 b- defN 24-May-21 21:49 pygpc/misc.py
+-rw-r--r--  2.0 unx    18560 b- defN 24-May-21 21:49 pygpc/TestBench.py
+-rw-r--r--  2.0 unx    18123 b- defN 24-May-21 21:49 pygpc/validation.py
+-rwxr-xr-x  2.0 unx     3614 b- defN 24-May-21 21:49 pygpc/oakley_ohagan_2004_M.txt
+-rw-r--r--  2.0 unx     7168 b- defN 24-May-21 21:49 pygpc/test_utils.py
+-rw-r--r--  2.0 unx     4026 b- defN 24-May-21 21:49 pygpc/Worker.py
+-rw-r--r--  2.0 unx    26972 b- defN 24-May-21 21:49 pygpc/Test.py
+-rw-r--r--  2.0 unx     7182 b- defN 24-May-21 21:49 pygpc/ValidationSet.py
+-rw-r--r--  2.0 unx   161741 b- defN 24-May-21 21:49 pygpc/Grid.py
+-rw-r--r--  2.0 unx    11698 b- defN 24-May-21 21:49 pygpc/AbstractModel.py
+-rw-r--r--  2.0 unx     4800 b- defN 24-May-21 21:49 pygpc/Session.py
+-rw-r--r--  2.0 unx    12188 b- defN 24-May-21 21:49 pygpc/Quadrature.py
+-rw-r--r--  2.0 unx    27888 b- defN 24-May-21 21:49 pygpc/SGPC.py
+-rw-r--r--  2.0 unx    18114 b- defN 24-May-21 21:49 pygpc/Visualization.py
+-rw-r--r--  2.0 unx       29 b- defN 24-May-21 21:49 pygpc/testfunctions/__init__.py
+-rw-r--r--  2.0 unx   140001 b- defN 24-May-21 21:49 pygpc/testfunctions/testfunctions.py
+-rw-r--r--  2.0 unx    20150 b- defN 24-May-21 21:49 pygpc/testfunctions/euber_libV3.py
+-rwxr-xr-x  2.0 unx   168193 b- defN 24-May-21 21:49 pygpc.libs/libgomp-a34b3233.so.1.0.0
+-rw-r--r--  2.0 unx      148 b- defN 24-May-21 21:49 pygpc-0.3.9.dist-info/WHEEL
+-rwxr-xr-x  2.0 unx    35149 b- defN 24-May-21 21:49 pygpc-0.3.9.dist-info/LICENSE
+-rw-r--r--  2.0 unx        6 b- defN 24-May-21 21:49 pygpc-0.3.9.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     3375 b- defN 24-May-21 21:49 pygpc-0.3.9.dist-info/RECORD
+-rw-r--r--  2.0 unx      484 b- defN 24-May-21 21:49 pygpc-0.3.9.dist-info/METADATA
+46 files, 4307383 bytes uncompressed, 1019006 bytes compressed:  76.3%
```

## zipnote {}

```diff
@@ -1,124 +1,139 @@
-Filename: pygpc/AbstractModel.py
+Filename: pygpc/
 Comment: 
 
-Filename: pygpc/Algorithm.py
+Filename: pygpc.libs/
 Comment: 
 
-Filename: pygpc/Basis.py
+Filename: pygpc-0.3.9.dist-info/
 Comment: 
 
-Filename: pygpc/BasisFunction.py
+Filename: pygpc/testfunctions/
 Comment: 
 
-Filename: pygpc/Classifier.py
+Filename: pygpc/Basis.py
+Comment: 
+
+Filename: pygpc/Gradient.py
 Comment: 
 
 Filename: pygpc/Computation.py
 Comment: 
 
-Filename: pygpc/GPC.py
+Filename: pygpc/BasisFunction.py
 Comment: 
 
-Filename: pygpc/Gradient.py
+Filename: pygpc/__init__.py
 Comment: 
 
-Filename: pygpc/Grid.py
+Filename: pygpc/Algorithm.py
 Comment: 
 
-Filename: pygpc/MEGPC.py
+Filename: pygpc/oakley_ohagan_2004_a3.txt
 Comment: 
 
-Filename: pygpc/Problem.py
+Filename: pygpc/pygpc_extensions.cpython-39-x86_64-linux-gnu.so
 Comment: 
 
-Filename: pygpc/Quadrature.py
+Filename: pygpc/postprocessing.py
 Comment: 
 
-Filename: pygpc/RandomParameter.py
+Filename: pygpc/GPC.py
 Comment: 
 
-Filename: pygpc/SGPC.py
+Filename: pygpc/sobol_saltelli.py
 Comment: 
 
-Filename: pygpc/Session.py
+Filename: pygpc/MEGPC.py
 Comment: 
 
-Filename: pygpc/Test.py
+Filename: pygpc/oakley_ohagan_2004_a1.txt
 Comment: 
 
-Filename: pygpc/TestBench.py
+Filename: pygpc/io.py
 Comment: 
 
-Filename: pygpc/ValidationSet.py
+Filename: pygpc/Problem.py
 Comment: 
 
-Filename: pygpc/Visualization.py
+Filename: pygpc/oakley_ohagan_2004_a2.txt
 Comment: 
 
-Filename: pygpc/Worker.py
+Filename: pygpc/RandomParameter.py
 Comment: 
 
-Filename: pygpc/__init__.py
+Filename: pygpc/Classifier.py
 Comment: 
 
-Filename: pygpc/io.py
+Filename: pygpc/sobol_saltelli_directions.hdf5
 Comment: 
 
 Filename: pygpc/misc.py
 Comment: 
 
+Filename: pygpc/TestBench.py
+Comment: 
+
+Filename: pygpc/validation.py
+Comment: 
+
 Filename: pygpc/oakley_ohagan_2004_M.txt
 Comment: 
 
-Filename: pygpc/oakley_ohagan_2004_a1.txt
+Filename: pygpc/test_utils.py
 Comment: 
 
-Filename: pygpc/oakley_ohagan_2004_a2.txt
+Filename: pygpc/Worker.py
 Comment: 
 
-Filename: pygpc/oakley_ohagan_2004_a3.txt
+Filename: pygpc/Test.py
 Comment: 
 
-Filename: pygpc/postprocessing.py
+Filename: pygpc/ValidationSet.py
 Comment: 
 
-Filename: pygpc/pygpc_extensions.cp39-win_amd64.pyd
+Filename: pygpc/Grid.py
 Comment: 
 
-Filename: pygpc/sobol_saltelli.py
+Filename: pygpc/AbstractModel.py
 Comment: 
 
-Filename: pygpc/sobol_saltelli_directions.hdf5
+Filename: pygpc/Session.py
 Comment: 
 
-Filename: pygpc/test_utils.py
+Filename: pygpc/Quadrature.py
 Comment: 
 
-Filename: pygpc/validation.py
+Filename: pygpc/SGPC.py
+Comment: 
+
+Filename: pygpc/Visualization.py
 Comment: 
 
 Filename: pygpc/testfunctions/__init__.py
 Comment: 
 
+Filename: pygpc/testfunctions/testfunctions.py
+Comment: 
+
 Filename: pygpc/testfunctions/euber_libV3.py
 Comment: 
 
-Filename: pygpc/testfunctions/testfunctions.py
+Filename: pygpc.libs/libgomp-a34b3233.so.1.0.0
 Comment: 
 
-Filename: pygpc-0.3.8.dist-info/LICENSE
+Filename: pygpc-0.3.9.dist-info/WHEEL
 Comment: 
 
-Filename: pygpc-0.3.8.dist-info/METADATA
+Filename: pygpc-0.3.9.dist-info/LICENSE
 Comment: 
 
-Filename: pygpc-0.3.8.dist-info/WHEEL
+Filename: pygpc-0.3.9.dist-info/top_level.txt
 Comment: 
 
-Filename: pygpc-0.3.8.dist-info/top_level.txt
+Filename: pygpc-0.3.9.dist-info/RECORD
 Comment: 
 
-Filename: pygpc-0.3.8.dist-info/RECORD
+Filename: pygpc-0.3.9.dist-info/METADATA
 Comment: 
 
 Zip file comment:
```

## filetype from file(1)

```diff
@@ -1 +1 @@
-Zip archive data, at least v2.0 to extract, compression method=deflate
+Zip archive data, at least v2.0 to extract, compression method=store
```

## pygpc/AbstractModel.py

 * *Ordering differences only*

```diff
@@ -1,280 +1,280 @@
-import numpy as np
-import os
-import h5py
-import copy
-from abc import ABCMeta, abstractmethod
-from .misc import display_fancy_bar
-
-
-class AbstractModel:
-    """
-    Abstract base class for the SimulationWrapper.
-    This base class provides basic functions for serialization/deserialization and printing progress.
-    It cannot be used directly, but a derived class implementing the "simulate" method must be created.
-    """
-    __metaclass__ = ABCMeta
-
-    def __init__(self, matlab_model=False):
-        """
-        Constructor; initialized the SimulationWrapper class
-        The model is initialized once. The parameters are set with the set_parameters class.
-        Depending on the model, the user may call here some functions to initialize the model like
-        starting a Matlab engine etc...
-        """
-        self.matlab_model = matlab_model
-
-    def __copy__(self):
-        return copy.deepcopy(self)
-
-    def __clean__(self):
-        if self.__dict__:
-            del self.__dict__
-
-    def set_parameters(self, p, context=None):
-        """
-        Set model parameters and context of simulations.
-
-        Parameters
-        ----------
-        p : dictionary
-            Dictionary containing the model parameters
-        context : dictionary
-            dictionary that contains information about this worker's context
-            - lock        : reference to the Lock object that all processes share for synchronization
-            - max_grid    : size of the current sub-grid that is processed
-            - global_task_counter  : reference to the Value object that is shared among all processes to keep track
-                                     of the overall progress
-            - seq_number  : sequence number of the task this object represents; necessary to maintain the correct
-                            sequence of results
-            - fn_results  : location of the hdf5 file to serialize the results to
-            - i_grid      : current iteration in the sub-grid that is processed
-            - i_iter      : current main-iteration
-            - i_subiter   : current sub-iteration
-            - coords      : parameters of particular simulation in original parameter space
-            - coords_norm : parameters of particular simulation in normalized parameter space
-            - verbose     : print progress
-        """
-
-        self.p = p
-
-        if context is not None:
-            for key in context.keys():
-                setattr(self, key, context[key])
-
-        # return copy.deepcopy(self)
-        return self
-
-    def read_previous_results(self, coords):
-        """
-        This functions reads previous results from the hard disk (if present).
-        When reading from the array containing the results, the current
-        grid-index (i_grid) is considered to maintain the order of the results when the
-        SimulationModels are executed in parallel. If the function evaluated the results in parallel
-        internally, i_grid is a range [i_grid_min, i_grid_max].
-
-        Parameters
-        ----------
-        coords : ndarray of float [n_sims x dim]
-            Grid coordinates the simulations are conducted with
-
-        Returns
-        -------
-            None :
-                if no serialized results could be found or does not fit to grid
-            list :
-                data at coords
-        """
-        if self.fn_results:
-            if self.lock:
-                self.lock.acquire()
-            try:
-                if os.path.exists(self.fn_results + ".hdf5"):
-
-                    # read results and coords
-                    try:
-                        with h5py.File(self.fn_results + ".hdf5", 'r') as f:
-
-                            if type(self.i_grid) is list:
-                                res = f['model_evaluations/results'][self.i_grid[0]:self.i_grid[1], :]
-                                coords_read = f['grid/coords'][self.i_grid[0]:self.i_grid[1], :]
-                            else:
-                                res = f['model_evaluations/results'][self.i_grid, :]
-                                coords_read = f['grid/coords'][self.i_grid, :]
-
-                            if np.isclose(coords_read, coords).all():
-                                return res  #.tolist()
-                            else:
-                                return None
-
-                    except (KeyError, ValueError, IndexError):
-                        return None
-            finally:
-                if self.lock:
-                    self.lock.release()
-
-        return None
-
-    def write_results(self, data_dict):
-        """
-        This function writes the data to a file on hard disk.
-        When writing the data the current grid-index (i_grid) is considered.
-        The data are written to the row corresponding i_grid in order to
-        maintain the order of the results when the SimulationModels are
-        executed in parallel.
-
-        Parameters
-        ----------
-        data_dict : dict of ndarray
-            Dictionary, containing the data to write in an .hdf5 file. The keys are the dataset names.
-        """
-
-        if self.fn_results:     # full filename
-            if self.lock:
-                self.lock.acquire()
-            try:
-                # get new size of array
-                if type(self.i_grid) is list:
-                    require_size = np.max(self.i_grid)
-                else:
-                    require_size = self.i_grid + 1
-
-                with h5py.File(self.fn_results + ".hdf5", 'a') as f:
-                    for d in data_dict:
-                        # # change list or single str to np.array
-                        # if type(data_dict[d]) is list or type(data_dict[d]) is str:
-                        #     data_dict[d] = np.array(data_dict[d]).flatten()
-
-                        # change single numbers to np.array
-                        # if type(data_dict[d]) is float or type(data_dict[d]) is int \
-                        #         or type(data_dict[d]) is np.float64 or type(data_dict[d]) is np.int:
-                        #     data_dict[d] = np.array([[data_dict[d]]]).flatten()
-
-                        # # always flatten data because it has to be saved for every grid point
-                        # if data_dict[d].ndim > 1:
-                        #     data_dict[d] = data_dict[d].flatten()
-
-                        # add axes such that it can be added to previous array
-                        # if data_dict[d].ndim == 1:
-                        #     data_dict[d] = data_dict[d][np.newaxis, :]
-
-                        # check datatype
-                        if type(data_dict[d][0][0]) is np.float64 or type(data_dict[d][0]) is float:
-                            dtype='float64'
-                        elif type(data_dict[d][0][0]) is np.int64:
-                            dtype = 'int'
-                        elif type(data_dict[d][0][0]) is np.string_ or type(data_dict[d][0][0]) is np.str_:
-                            dtype = 'str'
-                        else:
-                            dtype='float64'
-
-                        try:
-                            ds = f[d]
-                            # append
-                            # for strings, the whole array has to be rewritten
-                            if dtype == "str":
-                                # ds = f[d][:]
-                                ds = f[d]
-                                del f[d]
-                                ds = np.vstack((ds, data_dict[d]))
-                                f.create_dataset(d, data=ds.astype("|S"))
-                            else:
-                                # change size of array and write data in it
-                                if ds.shape[0] < require_size:  # check if resize is necessary
-                                    ds.resize(require_size, axis=0)
-                                if type(self.i_grid) is list:
-                                    ds[self.i_grid[0]:self.i_grid[1], :] = data_dict[d]
-                                else:
-                                    ds[self.i_grid, :] = data_dict[d]
-
-                        except (KeyError, ValueError, TypeError, IndexError):
-                            # create
-                            try:
-                                del f[d]
-                            except KeyError:
-                                pass
-
-                            if dtype == "str":
-                                f.create_dataset(d, data=data_dict[d].astype("|S"))
-                            else:
-                                ds = f.create_dataset(d, (require_size, data_dict[d].shape[1]),
-                                                      maxshape=(None, data_dict[d].shape[1]),
-                                                      dtype=dtype)
-
-                                if type(self.i_grid) is list:
-                                    ds[self.i_grid[0]:self.i_grid[1], :] = data_dict[d]
-                                else:
-                                    ds[self.i_grid, :] = data_dict[d]
-            finally:
-                if self.lock:
-                    self.lock.release()
-
-    def increment_ctr(self):
-        """
-        This functions increments the global counter by 1.
-        """
-        if self.lock:
-            self.lock.acquire()
-        try:
-            if self.lock:
-                self.global_task_counter.value += 1
-            else:
-                self.global_task_counter += 1
-        finally:
-            if self.lock:
-                self.lock.release()
-
-    def print_progress(self, func_time=None, read_from_file=False):
-        """
-        This function prints the progress according to the current context and global_counter.
-        """
-        if self.lock:
-            self.lock.acquire()
-        try:
-            if func_time:
-                more_text = "Function evaluation took: " + repr(func_time) + "s"
-            elif read_from_file:
-                more_text = "Read data from " + self.fn_results + ".hdf5"
-            else:
-                more_text = None
-
-            if self.lock:
-                global_task_counter = self.global_task_counter.value
-            else:
-                global_task_counter = self.global_task_counter
-
-            display_fancy_bar("It/Sub-it: {}/{} Performing simulation".format(self.i_iter,
-                                                                              self.i_subiter),
-                              global_task_counter,
-                              self.max_grid,
-                              more_text)
-        finally:
-            if self.lock:
-                self.lock.release()
-
-    def get_seq_number(self):
-        return self.seq_number
-
-    @abstractmethod
-    def simulate(self, process_id=None, matlab_engine=None):
-        """
-        This abstract method must be implemented by the subclass.
-        It should perform the simulation task depending on the input_values provided to the object on instantiation.
-
-        Parameters
-        ----------
-        process_id : int
-            A unique identifier; no two processes of the pool will run concurrently with the same identifier
-        matlab_engine : Matlab engine object
-            Matlab engine to run Matlab models
-        """
-        pass
-
-    @abstractmethod
-    def validate(self):
-        """
-        This abstract method must be implemented by the subclass.
-        It should perform the validation task depending on the parameters defined in the problem.
-        In cases, the model may not run correctly for some parameter combinations, this function changes the definition
-        of the random parameters and the constants.
-        """
-        pass
+import numpy as np
+import os
+import h5py
+import copy
+from abc import ABCMeta, abstractmethod
+from .misc import display_fancy_bar
+
+
+class AbstractModel:
+    """
+    Abstract base class for the SimulationWrapper.
+    This base class provides basic functions for serialization/deserialization and printing progress.
+    It cannot be used directly, but a derived class implementing the "simulate" method must be created.
+    """
+    __metaclass__ = ABCMeta
+
+    def __init__(self, matlab_model=False):
+        """
+        Constructor; initialized the SimulationWrapper class
+        The model is initialized once. The parameters are set with the set_parameters class.
+        Depending on the model, the user may call here some functions to initialize the model like
+        starting a Matlab engine etc...
+        """
+        self.matlab_model = matlab_model
+
+    def __copy__(self):
+        return copy.deepcopy(self)
+
+    def __clean__(self):
+        if self.__dict__:
+            del self.__dict__
+
+    def set_parameters(self, p, context=None):
+        """
+        Set model parameters and context of simulations.
+
+        Parameters
+        ----------
+        p : dictionary
+            Dictionary containing the model parameters
+        context : dictionary
+            dictionary that contains information about this worker's context
+            - lock        : reference to the Lock object that all processes share for synchronization
+            - max_grid    : size of the current sub-grid that is processed
+            - global_task_counter  : reference to the Value object that is shared among all processes to keep track
+                                     of the overall progress
+            - seq_number  : sequence number of the task this object represents; necessary to maintain the correct
+                            sequence of results
+            - fn_results  : location of the hdf5 file to serialize the results to
+            - i_grid      : current iteration in the sub-grid that is processed
+            - i_iter      : current main-iteration
+            - i_subiter   : current sub-iteration
+            - coords      : parameters of particular simulation in original parameter space
+            - coords_norm : parameters of particular simulation in normalized parameter space
+            - verbose     : print progress
+        """
+
+        self.p = p
+
+        if context is not None:
+            for key in context.keys():
+                setattr(self, key, context[key])
+
+        # return copy.deepcopy(self)
+        return self
+
+    def read_previous_results(self, coords):
+        """
+        This functions reads previous results from the hard disk (if present).
+        When reading from the array containing the results, the current
+        grid-index (i_grid) is considered to maintain the order of the results when the
+        SimulationModels are executed in parallel. If the function evaluated the results in parallel
+        internally, i_grid is a range [i_grid_min, i_grid_max].
+
+        Parameters
+        ----------
+        coords : ndarray of float [n_sims x dim]
+            Grid coordinates the simulations are conducted with
+
+        Returns
+        -------
+            None :
+                if no serialized results could be found or does not fit to grid
+            list :
+                data at coords
+        """
+        if self.fn_results:
+            if self.lock:
+                self.lock.acquire()
+            try:
+                if os.path.exists(self.fn_results + ".hdf5"):
+
+                    # read results and coords
+                    try:
+                        with h5py.File(self.fn_results + ".hdf5", 'r') as f:
+
+                            if type(self.i_grid) is list:
+                                res = f['model_evaluations/results'][self.i_grid[0]:self.i_grid[1], :]
+                                coords_read = f['grid/coords'][self.i_grid[0]:self.i_grid[1], :]
+                            else:
+                                res = f['model_evaluations/results'][self.i_grid, :]
+                                coords_read = f['grid/coords'][self.i_grid, :]
+
+                            if np.isclose(coords_read, coords).all():
+                                return res  #.tolist()
+                            else:
+                                return None
+
+                    except (KeyError, ValueError, IndexError):
+                        return None
+            finally:
+                if self.lock:
+                    self.lock.release()
+
+        return None
+
+    def write_results(self, data_dict):
+        """
+        This function writes the data to a file on hard disk.
+        When writing the data the current grid-index (i_grid) is considered.
+        The data are written to the row corresponding i_grid in order to
+        maintain the order of the results when the SimulationModels are
+        executed in parallel.
+
+        Parameters
+        ----------
+        data_dict : dict of ndarray
+            Dictionary, containing the data to write in an .hdf5 file. The keys are the dataset names.
+        """
+
+        if self.fn_results:     # full filename
+            if self.lock:
+                self.lock.acquire()
+            try:
+                # get new size of array
+                if type(self.i_grid) is list:
+                    require_size = np.max(self.i_grid)
+                else:
+                    require_size = self.i_grid + 1
+
+                with h5py.File(self.fn_results + ".hdf5", 'a') as f:
+                    for d in data_dict:
+                        # # change list or single str to np.array
+                        # if type(data_dict[d]) is list or type(data_dict[d]) is str:
+                        #     data_dict[d] = np.array(data_dict[d]).flatten()
+
+                        # change single numbers to np.array
+                        # if type(data_dict[d]) is float or type(data_dict[d]) is int \
+                        #         or type(data_dict[d]) is np.float64 or type(data_dict[d]) is np.int:
+                        #     data_dict[d] = np.array([[data_dict[d]]]).flatten()
+
+                        # # always flatten data because it has to be saved for every grid point
+                        # if data_dict[d].ndim > 1:
+                        #     data_dict[d] = data_dict[d].flatten()
+
+                        # add axes such that it can be added to previous array
+                        # if data_dict[d].ndim == 1:
+                        #     data_dict[d] = data_dict[d][np.newaxis, :]
+
+                        # check datatype
+                        if type(data_dict[d][0][0]) is np.float64 or type(data_dict[d][0]) is float:
+                            dtype='float64'
+                        elif type(data_dict[d][0][0]) is np.int64:
+                            dtype = 'int'
+                        elif type(data_dict[d][0][0]) is np.string_ or type(data_dict[d][0][0]) is np.str_:
+                            dtype = 'str'
+                        else:
+                            dtype='float64'
+
+                        try:
+                            ds = f[d]
+                            # append
+                            # for strings, the whole array has to be rewritten
+                            if dtype == "str":
+                                # ds = f[d][:]
+                                ds = f[d]
+                                del f[d]
+                                ds = np.vstack((ds, data_dict[d]))
+                                f.create_dataset(d, data=ds.astype("|S"))
+                            else:
+                                # change size of array and write data in it
+                                if ds.shape[0] < require_size:  # check if resize is necessary
+                                    ds.resize(require_size, axis=0)
+                                if type(self.i_grid) is list:
+                                    ds[self.i_grid[0]:self.i_grid[1], :] = data_dict[d]
+                                else:
+                                    ds[self.i_grid, :] = data_dict[d]
+
+                        except (KeyError, ValueError, TypeError, IndexError):
+                            # create
+                            try:
+                                del f[d]
+                            except KeyError:
+                                pass
+
+                            if dtype == "str":
+                                f.create_dataset(d, data=data_dict[d].astype("|S"))
+                            else:
+                                ds = f.create_dataset(d, (require_size, data_dict[d].shape[1]),
+                                                      maxshape=(None, data_dict[d].shape[1]),
+                                                      dtype=dtype)
+
+                                if type(self.i_grid) is list:
+                                    ds[self.i_grid[0]:self.i_grid[1], :] = data_dict[d]
+                                else:
+                                    ds[self.i_grid, :] = data_dict[d]
+            finally:
+                if self.lock:
+                    self.lock.release()
+
+    def increment_ctr(self):
+        """
+        This functions increments the global counter by 1.
+        """
+        if self.lock:
+            self.lock.acquire()
+        try:
+            if self.lock:
+                self.global_task_counter.value += 1
+            else:
+                self.global_task_counter += 1
+        finally:
+            if self.lock:
+                self.lock.release()
+
+    def print_progress(self, func_time=None, read_from_file=False):
+        """
+        This function prints the progress according to the current context and global_counter.
+        """
+        if self.lock:
+            self.lock.acquire()
+        try:
+            if func_time:
+                more_text = "Function evaluation took: " + repr(func_time) + "s"
+            elif read_from_file:
+                more_text = "Read data from " + self.fn_results + ".hdf5"
+            else:
+                more_text = None
+
+            if self.lock:
+                global_task_counter = self.global_task_counter.value
+            else:
+                global_task_counter = self.global_task_counter
+
+            display_fancy_bar("It/Sub-it: {}/{} Performing simulation".format(self.i_iter,
+                                                                              self.i_subiter),
+                              global_task_counter,
+                              self.max_grid,
+                              more_text)
+        finally:
+            if self.lock:
+                self.lock.release()
+
+    def get_seq_number(self):
+        return self.seq_number
+
+    @abstractmethod
+    def simulate(self, process_id=None, matlab_engine=None):
+        """
+        This abstract method must be implemented by the subclass.
+        It should perform the simulation task depending on the input_values provided to the object on instantiation.
+
+        Parameters
+        ----------
+        process_id : int
+            A unique identifier; no two processes of the pool will run concurrently with the same identifier
+        matlab_engine : Matlab engine object
+            Matlab engine to run Matlab models
+        """
+        pass
+
+    @abstractmethod
+    def validate(self):
+        """
+        This abstract method must be implemented by the subclass.
+        It should perform the validation task depending on the parameters defined in the problem.
+        In cases, the model may not run correctly for some parameter combinations, this function changes the definition
+        of the random parameters and the constants.
+        """
+        pass
```

## pygpc/Algorithm.py

 * *Ordering differences only*

```diff
@@ -1,4704 +1,4704 @@
-import os
-import copy
-import h5py
-import time
-import shutil
-import warnings
-
-import numpy as np
-
-from .Problem import *
-from .SGPC import *
-from .misc import determine_projection_matrix, poly_expand, get_non_enclosed_multi_indices
-from .misc import get_num_coeffs_sparse
-from .misc import ten2mat
-from .misc import mat2ten
-from .misc import get_gradient_idx_domain
-from .misc import get_coords_discontinuity
-from .misc import increment_basis
-from .misc import get_coords_discontinuity
-from .misc import get_num_coeffs_sparse
-from .testfunctions import Dummy
-from .Grid import *
-from .MEGPC import *
-from .Classifier import Classifier
-from .Gradient import get_gradient
-
-
-class Algorithm(object):
-    """
-    Class for GPC algorithms
-
-    Parameters
-    ----------
-    problem : Problem object
-        Object instance of gPC problem to investigate
-    options : dict
-        Algorithm specific options (see sub-classes for more details)
-    grid : Grid object
-        Grid object
-    validation : ValidationSet object
-        ValidationSet object
-    """
-
-    def __init__(self, problem, options, grid=None, validation=None):
-        """
-        Constructor; Initializes GPC algorithm
-        """
-        self.problem = problem
-        self.problem_reduced = []
-        self.validation = validation
-        self.options = options
-        self.grid = grid
-        self.grid_gradient = []
-        self.qoi_specific = None
-
-        # Generate results folder if it doesn't exist
-        if self.options["fn_results"] is not None:
-            if not os.path.exists(os.path.split(self.options["fn_results"])[0]):
-                os.makedirs(os.path.split(self.options["fn_results"])[0])
-
-        self.check_basic_options()
-
-    def check_basic_options(self):
-        """
-        Checks self.options dictionary and sets default
-
-        options["eps"] : float, optional, default=1e-3
-            Relative mean error of leave-one-out cross validation
-        options["error_norm"] : str, optional, default="relative"
-            Choose if error is determined "relative" or "absolute". Use "absolute" error when the
-            model generates outputs equal to zero.
-        options["error_type"] : str, optional, default="loocv"
-            Choose type of error to validate gpc approximation. Use "loocv" (Leave-one-Out cross validation)
-            to omit any additional calculations and "nrmsd" (normalized root mean square deviation) to compare
-            against a Problem.ValidationSet.
-        options["fn_results"] : string, optional, default=None
-            If provided, model evaluations are saved in fn_results.hdf5 file and gpc object in fn_results.pkl file
-        options["gradient_enhanced"] : boolean, optional, default: False
-            Use gradient information to determine the gPC coefficients.
-        options["gradient_calculation"] : str, optional, default="standard_forward"
-            Type of the calculation scheme to determine the gradient in the grid points
-            - "FD_fwd": Finite difference forward approximation of the gradient using n_grid x dim additional sampling
-            points stored in self.grid.coords_gradient and self.grid.coords_gradient_norm [n_grid x dim x dim].
-            - "FD_1st": Finite difference approximation of 1st order accuracy using only the available samples [1]
-            - "FD_2nd": Finite difference approximation of 2nd order accuracy using only the available samples [1]
-            - "FD_1st2nd": Finite difference approximation of 1st and (where possible) 2nd order accuracy
-        options["gradient_calculation_options"] : dict, optional, default: {"dx": 0.01, "distance_weight": -2}
-            Options for gradient calculation (details in get_gradient() function in Gradient.py)
-        options["backend"] : str, optional, default: "python"
-            Default computing backend, certain functions can be computed with Multicore-CPU or GPU acceleration
-        options["lambda_eps_gradient"] : float, optional, default: 0.95
-            Bound of principal components in %. All eigenvectors are included until lambda_eps of total sum of all
-            eigenvalues is included in the system.
-        options["matrix_ratio"]: float, optional, default=1.5
-            Ration between the number of model evaluations and the number of basis functions.
-            If "adaptive_sampling" is activated this factor is only used to
-            construct the initial grid depending on the initial number of basis functions determined by "order_start".
-            (>1 results in an overdetermined system)
-        options["matlab_model"] : boolean, optional, default: False
-            Use a Matlab model function
-        options["method"]: str
-            GPC method to apply ['Reg', 'Quad']
-        options["n_cpu"] : int, optional, default=1
-            Number of threads to use for parallel evaluation of the model function.
-        options["n_samples_validation"] : int, optional, default: 1e4
-            Number of validation points used to determine the NRMSD if chosen as "error_type". Does not create a
-            validation set if there is already one present in the Problem instance (problem.validation).
-        options["print_func_time"] : boolean, optional, default: False
-            Print function evaluation time for every single run
-        options["projection"] : boolean, optional, default: False
-            Use projection approach
-        options["solver"]: str
-            Solver to determine the gPC coefficients
-            - 'Moore-Penrose' ... Pseudoinverse of gPC matrix (SGPC.Reg, EGPC)
-            - 'OMP' ... Orthogonal Matching Pursuit, sparse recovery approach (SGPC.Reg, EGPC)
-        options["settings"]: dict
-            Solver settings
-            - 'Moore-Penrose' ... None
-            - 'OMP' ... {"n_coeffs_sparse": int} Number of gPC coefficients != 0
-        options["verbose"] : boolean, optional, default=True
-            Print output of iterations and sub-iterations (True/False)
-        options["backend"] : str
-            Backend for performance intensive computations
-            - "python" ... Use native python implementation
-            - "cpu" .. Use C Implementaion without multicore-support
-        options["plot_basis"] : bool
-            Plot basis functions and save as fn_results + _basis_iter#.png
-        options["grid_extension_method"] : str, optional, default: GPR
-            Method to extend random grids when adaptive_sampling is turned on:
-            - "GPR": Gaussian Process Regression (sample location is optimized according to posterior variance)
-            - "random": Samples are added randomly
-        """
-
-        if "eps" not in self.options.keys():
-            self.options["eps"] = 1e-3
-
-        if "error_norm" not in self.options.keys():
-            self.options["error_norm"] = "relative"
-
-        if "error_type" not in self.options.keys():
-            self.options["error_type"] = "loocv"
-
-        if "fn_results" not in self.options.keys():
-            self.options["fn_results"] = None
-
-        if "gradient_enhanced" not in self.options.keys():
-            self.options["gradient_enhanced"] = False
-
-        if "gradient_calculation" not in self.options.keys():
-            self.options["gradient_calculation"] = "FD_fwd"
-
-        if "gradient_calculation_options" not in self.options.keys():
-            self.options["gradient_calculation_options"] = {"dx": 0.001, "distance_weight": -2}
-
-        if "dx" not in self.options["gradient_calculation_options"]:
-            self.options["gradient_calculation_options"]["dx"] = 0.001
-
-        if "distance_weight" not in self.options["gradient_calculation_options"]:
-            self.options["gradient_calculation_options"]["distance_weight"] = -2
-
-        if "backend" not in self.options.keys():
-            self.options["backend"] = "python"
-
-        if "lambda_eps_gradient" not in self.options.keys():
-            self.options["lambda_eps_gradient"] = 0.95
-
-        if "matrix_ratio" not in self.options.keys():
-            self.options["matrix_ratio"] = 2
-
-        if "matlab_model" not in self.options.keys():
-            self.options["matlab_model"] = False
-
-        if "method" in self.options.keys():
-            if self.options["method"] == "quad":
-                self.options["solver"] = 'NumInt'
-                self.options["settings"] = None
-            elif self.options["method"] == "reg" and not (self.options["solver"] == "Moore-Penrose" or
-                                                          self.options["solver"] == "OMP" or
-                                                          self.options["solver"] == "LarsLasso"):
-                raise AssertionError("Please specify 'Moore-Penrose' or 'OMP' as solver for 'reg' method")
-
-        if "n_cpu" in self.options.keys():
-            self.n_cpu = self.options["n_cpu"]
-        else:
-            self.options["n_cpu"] = 1
-            self.n_cpu = 1
-
-        if "n_samples_validation" not in self.options.keys():
-            self.options["n_samples_validation"] = 1e4
-
-        if "save_session_format" not in self.options.keys():
-            self.options["save_session_format"] = ".hdf5"
-        elif self.options["save_session_format"] not in [".hdf5", ".pkl"]:
-            self.options["save_session_format"] = ".hdf5"
-        elif self.options["save_session_format"] in [".hdf5"]:
-            self.options["save_session_format"] = ".hdf5"
-        elif self.options["save_session_format"] in [".pkl"]:
-            self.options["save_session_format"] = ".pkl"
-
-        if self.options["fn_results"] is not None:
-            self.options["fn_session"] = os.path.splitext(self.options["fn_results"])[0] + \
-                                         self.options["save_session_format"]
-            if self.options["save_session_format"] == ".hdf5":
-                self.options["fn_session_folder"] = "session"
-            else:
-                self.options["fn_session_folder"] = None
-        else:
-            self.options["fn_session"] = None
-            self.options["fn_session_folder"] = None
-
-        if "print_func_time" not in self.options.keys():
-            self.options["print_func_time"] = False
-
-        if "projection" not in self.options.keys():
-            self.options["projection"] = False
-
-        if "seed" not in self.options.keys():
-            self.options["seed"] = None
-
-        if self.options["solver"] == "Moore-Penrose":
-            self.options["settings"] = None
-
-        if self.options["solver"] == "OMP" and ("settings" not in self.options.keys() or not (
-                "n_coeffs_sparse" not in self.options["settings"].keys() or
-                "sparsity" not in self.options["settings"].keys())):
-            raise AssertionError("Please specify correct solver settings for OMP in 'settings'")
-
-        if self.options["solver"] == "LarsLasso":
-            if "settings" in self.options.keys():
-                if type(self.options["settings"]) is dict:
-                    if "alpha" not in self.options["settings"].keys():
-                        self.options["settings"]["alpha"] = 1e-5
-                else:
-                    self.options["settings"] = {"alpha": 1e-5}
-            else:
-                self.options["settings"] = {"alpha": 1e-5}
-
-        if "verbose" not in self.options.keys():
-            self.options["verbose"] = True
-
-        if "grid" not in self.options.keys():
-            self.options["grid"] = Random
-            self.options["grid_options"] = None
-
-        if "backend" not in self.options.keys():
-            self.options["backend"] = "python"
-
-        if "n_grid" not in self.options.keys():
-            self.options["n_grid"] = None
-
-        if "adaptive_sampling" not in self.options.keys():
-            self.options["adaptive_sampling"] = False
-
-        if "plot_basis" not in self.options.keys():
-            self.options["plot_basis"] = False
-
-        if "grid_extension_method" not in self.options.keys():
-            self.options["grid_extension_method"] = "GPR"
-
-    def check_results(self, results, grid, gradient_results=None, gradient_results_idx=None, com=None, resample=True):
-        """
-        Check the validity of the results and resample if required.
-        Updates the gPC object, the containing grid, and the results array.
-
-        Parameters
-        ----------
-        results : np.ndarray of float [n_samples x n_qoi]
-            Model output at sampling points.
-        grid : Grid object instance
-            Grid object instance the results are computed for.
-        gradient_results : ndarray of float [n_grid x n_out x dim], optional, default: None
-            Gradient of model function in grid points.
-        gradient_results_idx : ndarray of int [n_grid], optional, default: None
-            Indices of grid points where the gradient was evaluated.
-        com : Computation class instance, optional, default: None
-            Computation class instance to run the model if resample is True.
-        resample : bool, optional, default: True
-            Resample grid points and rerun model (requires Computational class instance to run model).
-            If False, the grid points and results are just deleted.
-
-        Returns
-        -------
-        results : np.ndarray of float [n_samples x n_qoi]
-            Updated (fixed) model output at sampling points.
-        gpc : SGPC or MEGPC object instance or list of SGPC or MEGPC object instances
-            GPC object(s) containing the basis functions and the updated grid.
-        gradient_results : ndarray of float [n_grid x n_out x dim]
-            Updated (fixed) gradients of model function in grid points not containing the points where
-            the gradients were NaN.
-        gradient_results_idx : ndarray of int [n_grid], optional, default: None
-            Updated (fixed) indices of grid points where the gradient was evaluated not containing the points where
-            the gradients were NaN.
-        grid : Grid object instance
-            Updated (fixed) grid object instance the results are computed for not containing the grid points where
-            the results were NaN.
-        """
-        # get the indices of the sampling points where any of the QOIs were NaN
-        idx_nan = np.unique(np.where(np.isnan(results))[0])
-        idx_nan_gradient = np.array([])
-
-        if gradient_results is not None:
-            idx_nan_gradient_local = np.unique(np.where(np.isnan(gradient_results))[0])
-
-            if len(idx_nan_gradient_local) > 0:
-                idx_nan_gradient = gradient_results_idx[idx_nan_gradient_local]
-
-        idx_nan = np.unique(np.hstack((idx_nan, idx_nan_gradient)).astype(int))
-
-        if resample:
-            while len(idx_nan) > 0:
-                if self.options["verbose"]:
-                    print(f"WARNING! Detected {len(idx_nan)} grid points with NaN results. Resampling ...")
-
-                # resample grid points
-                grid.resample(idx=idx_nan)
-
-                # determine results at resampled grid points
-                results_resample = com.run(model=self.problem.model,
-                                           problem=self.problem,
-                                           coords=grid.coords[idx_nan, :],
-                                           coords_norm=grid.coords_norm[idx_nan, :],
-                                           i_iter=None,
-                                           i_subiter=None,
-                                           fn_results=None,
-                                           print_func_time=self.options["print_func_time"],
-                                           verbose=self.options["verbose"])
-
-                # Determine gradient [n_grid x n_out x dim]
-                if gradient_results is not None:
-                    if self.options["gradient_calculation"] == "FD_fwd":
-                        # for forward gradient calculation only pass the resampled grid points
-                        grid_gradient = copy.deepcopy(grid)
-                        idx_not_nan = np.array([i for i in range(grid.n_grid) if i not in idx_nan])
-                        grid_gradient.delete(idx=idx_not_nan)
-
-                    else:
-                        # for gradient calculation from adjacent grid points pass the complete grid
-                        grid_gradient = grid
-
-                    gradient_results_resample, gradient_results_idx_resample = get_gradient(
-                        model=self.problem.model,
-                        problem=self.problem,
-                        grid=grid_gradient,
-                        results=results_resample,
-                        com=com,
-                        method=self.options["gradient_calculation"],
-                        gradient_results_present=None,
-                        gradient_idx_skip=None,
-                        i_iter=None,
-                        i_subiter=None,
-                        print_func_time=self.options["print_func_time"],
-                        dx=self.options["gradient_calculation_options"]["dx"],
-                        distance_weight=self.options["gradient_calculation_options"]["distance_weight"],
-                        verbose=self.options["verbose"])
-
-                    if self.options["gradient_calculation"] == "FD_fwd":
-                        gradient_results[idx_nan, :, :] = gradient_results_resample
-                        gradient_results_idx[idx_nan] = idx_nan[gradient_results_idx_resample]
-                    else:
-                        gradient_results = gradient_results_resample
-                        gradient_results_idx = gradient_results_idx_resample
-
-                # replace NaN results with new results at resampled grid points
-                results[idx_nan, :] = results_resample
-
-                # get the indices of the sampling points where any of the QOIs where NaN
-                idx_nan = np.unique(np.where(np.isnan(results))[0])
-        else:
-            # remove grid points with NaN results
-            grid.delete(idx=idx_nan)
-
-            # remove NaN results
-            results = np.delete(results, idx_nan, axis=0)
-
-            if gradient_results is not None:
-                gradient_results = np.delete(gradient_results, idx_nan_gradient_local, axis=0)
-                gradient_results_idx = np.delete(gradient_results_idx, idx_nan_gradient_local, axis=0)
-
-        return results, gradient_results, gradient_results_idx, grid
-
-
-class Static_IO(Algorithm):
-    """
-    Static gPC algorithm, which uses precomputed input output relationships to construct the gPC approximation
-
-    Parameters
-    ----------
-    parameters: OrderedDict containing the RandomParameter class instances
-        Dictionary (ordered) containing the properties of the random parameters
-    options["order"]: list of int [dim]
-        Maximum individual expansion order [order_1, order_2, ..., order_dim].
-        Generates individual polynomials also if maximum expansion order in order_max is exceeded
-    options["order_max"]: int
-        Maximum global expansion order.
-        The maximum expansion order considers the sum of the orders of combined polynomials together with the
-        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
-        monomial orders.
-    options["order_max_norm"]: float
-        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
-        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
-        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
-        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
-    options["interaction_order"]: int
-        Number of random variables, which can interact with each other.
-        All polynomials are ignored, which have an interaction order greater than the specified
-    grid: Grid object instance
-        Grid object to use for static gPC (Random, SparseGrid, TensorGrid) containing the parameter values, where the
-        output relations were calculated
-    results: ndarray of float [N_grid x N_qoi]
-        Model output at each grid point for each QOI
-    validation: Validation Set class instance, optional
-        Validation set containing reference solutions at precomputed grid points
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> # initialize static gPC algorithm using precomputed IO relationships
-    >>> algorithm = pygpc.Static_IO(parameters=parameters, options=options, grid=grid, results=results)
-    >>> # run algorithm
-    >>> gpc, coeffs = algorithm.run()
-    """
-    def __init__(self, parameters, options, results, grid, validation=None):
-        """
-        Constructor; Initializes static gPC algorithm
-        """
-        # create dummy model
-        model = Dummy()
-
-        # create dummy problem
-        problem = Problem(model, parameters)
-
-        super(Static_IO, self).__init__(problem=problem, options=options, validation=validation, grid=grid)
-
-        self.res = results
-
-        if "order" not in self.options.keys():
-            raise AssertionError("Please specify 'order'=[order_1, order_2, ..., order_dim] in options dictionary")
-
-        if "order_max" not in self.options.keys():
-            raise AssertionError("Please specify 'order_max' in options dictionary")
-
-        if "order_max_norm" not in self.options.keys():
-            self.options["order_max_norm"] = 1.
-
-        if "interaction_order" not in self.options.keys():
-            self.options["interaction_order"] = self.problem.dim
-
-        #if "error_type" not in self.options.keys():
-        #    self.options["error_type"] = "loocv"
-
-        #if self.options["error_type"] != "loocv":
-            #    self.options["error_type"] = "loocv"
-            #warnings.warn("Changing error calculation type to loocv ...")
-
-    def run(self):
-        """
-        Runs static gPC algorithm using precomputed IO relationships to construct surrogate model.
-
-        Returns
-        -------
-        gpc : GPC object instance
-            GPC object containing all information i.e., Problem, Model, Grid, Basis, RandomParameter instances
-        coeffs: ndarray of float [n_basis x n_out]
-            GPC coefficients
-        """
-
-        if self.options["fn_results"] is not None:
-            fn_results = os.path.splitext(self.options["fn_results"])[0]
-
-            if os.path.exists(fn_results + ".hdf5"):
-                os.remove(fn_results + ".hdf5")
-        else:
-            fn_results = None
-
-        # Initialize gPC object
-        gpc = Reg(problem=self.problem,
-                  order=self.options["order"],
-                  order_max=self.options["order_max"],
-                  order_max_norm=self.options["order_max_norm"],
-                  interaction_order=self.options["interaction_order"],
-                  interaction_order_current=self.options["interaction_order"],
-                  options=self.options,
-                  validation=self.validation)
-
-        gpc.backend = self.options["backend"]
-
-        # determine number of basis functions
-        n_coeffs = get_num_coeffs_sparse(order_dim_max=self.options["order"],
-                                         order_glob_max=self.options["order_max"],
-                                         order_inter_max=self.options["interaction_order"],
-                                         dim=self.problem.dim)
-
-        print(f" > Determining {n_coeffs} gPC coeffs with {self.res.shape[0]} simulations!")
-
-        # Write grid in gpc object
-        gpc.grid = self.grid
-
-        # Initialize gpc matrix
-        gpc.init_gpc_matrix()
-
-        # Compute gpc coefficients
-        coeffs = gpc.solve(results=self.res,
-                           solver=self.options["solver"],
-                           settings=self.options["settings"],
-                           verbose=self.options["verbose"])
-
-        # validate gpc approximation (determine nrmsd or loocv specified in options["error_type"])
-        eps = gpc.validate(coeffs=coeffs, results=self.res)
-
-        iprint("-> {} {} error = {}".format(self.options["error_norm"],
-                                            self.options["error_type"],
-                                            eps), tab=0, verbose=self.options["verbose"])
-
-        # save gpc object and gpc coeffs
-        if self.options["fn_results"] is not None:
-
-            with h5py.File(fn_results + ".hdf5", "a") as f:
-
-                f.create_dataset("misc/fn_session",
-                                 data=np.array([os.path.split(self.options["fn_session"])[1]]).astype("|S"))
-                f.create_dataset("misc/fn_session_folder",
-                                 data=np.array([self.options["fn_session_folder"]]).astype("|S"))
-                f.create_dataset("misc/error_type", data=self.options["error_type"])
-                f.create_dataset("error", data=eps, maxshape=None, dtype="float64")
-                f.create_dataset("grid/coords", maxshape=None, data=gpc.grid.coords, dtype="float64")
-                f.create_dataset("grid/coords_norm", maxshape=None, data=gpc.grid.coords_norm, dtype="float64")
-
-                if gpc.grid.coords_gradient is not None:
-                    f.create_dataset("grid/coords_gradient", data=gpc.grid.coords_gradient,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("grid/coords_gradient_norm", data=gpc.grid.coords_gradient_norm,
-                                     maxshape=None, dtype="float64")
-
-                f.create_dataset("coeffs", data=coeffs,
-                                 maxshape=None, dtype="float64")
-                f.create_dataset("gpc_matrix", data=gpc.gpc_matrix,
-                                 maxshape=None, dtype="float64")
-
-                if gpc.gpc_matrix_gradient is not None:
-                    f.create_dataset("gpc_matrix_gradient",
-                                     data=gpc.gpc_matrix_gradient, maxshape=None, dtype="float64")
-
-                f.create_dataset("model_evaluations/results", data=self.res, maxshape=None, dtype="float64")
-
-                if gpc.validation is not None:
-                    f.create_dataset("validation/model_evaluations/results", data=gpc.validation.results,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("validation/grid/coords", data=gpc.validation.grid.coords,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("validation/grid/coords_norm", data=gpc.validation.grid.coords_norm,
-                                     maxshape=None, dtype="float64")
-
-        return gpc, coeffs, self.res
-
-
-class Static(Algorithm):
-    """
-    Static gPC algorithm
-
-    Parameters
-    ----------
-    problem : Problem object
-        Object instance of gPC problem to investigate
-    options["method"]: str
-        GPC method to apply ['Reg', 'Quad']
-    options["order"]: list of int [dim]
-        Maximum individual expansion order [order_1, order_2, ..., order_dim].
-        Generates individual polynomials also if maximum expansion order in order_max is exceeded
-    options["order_max"]: int
-        Maximum global expansion order.
-        The maximum expansion order considers the sum of the orders of combined polynomials together with the
-        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
-        monomial orders.
-    options["order_max_norm"]: float
-        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
-        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
-        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
-        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
-    options["interaction_order"]: int
-        Number of random variables, which can interact with each other.
-        All polynomials are ignored, which have an interaction order greater than the specified
-    grid: Grid object instance
-        Grid object to use for static gPC (Random, SparseGrid, TensorGrid)
-    validation: Validation Set class instance, optional
-        Validation set containing reference solutions at precomputed grid points
-
-    Notes
-    -----
-    .. [1] Blatman, G., & Sudret, B. (2011). Adaptive sparse polynomial chaos expansion based on least angle
-       regression. Journal of Computational Physics, 230(6), 2345-2367.
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> # initialize static gPC algorithm
-    >>> algorithm = pygpc.Static(problem=problem, options=options, grid=grid)
-    >>> # run algorithm
-    >>> gpc, coeffs, results = algorithm.run()
-    """
-
-    def __init__(self, problem, options, grid=None, validation=None, gpc=None):
-        """
-        Constructor; Initializes static gPC algorithm
-        """
-        super(Static, self).__init__(problem=problem, options=options, validation=validation, grid=grid)
-
-        self.qoi_specific = False
-        self.gpc = gpc
-
-        # check contents of settings dict and set defaults
-        if "method" not in self.options.keys():
-            raise AssertionError("Please specify 'method' with either 'reg' or 'quad' in options dictionary")
-
-        if "order" not in self.options.keys():
-            raise AssertionError("Please specify 'order'=[order_1, order_2, ..., order_dim] in options dictionary")
-
-        if "order_max" not in self.options.keys():
-            raise AssertionError("Please specify 'order_max' in options dictionary")
-
-        if "order_max_norm" not in self.options.keys():
-            self.options["order_max_norm"] = 1.
-
-        if "interaction_order" not in self.options.keys():
-            self.options["interaction_order"] = self.problem.dim
-
-    def run(self):
-        """
-        Runs static gPC algorithm to solve problem.
-
-        Returns
-        -------
-        gpc : GPC object instance
-            GPC object containing all information i.e., Problem, Model, Grid, Basis, RandomParameter instances
-        coeffs: ndarray of float [n_basis x n_out]
-            GPC coefficients
-        res : ndarray of float [n_grid x n_out]
-            Simulation results at n_grid points of the n_out output variables
-        """
-
-        if self.options["fn_results"] is not None:
-            fn_results = os.path.splitext(self.options["fn_results"])[0]
-
-            if os.path.exists(fn_results + ".hdf5"):
-                os.remove(fn_results + ".hdf5")
-        else:
-            fn_results = None
-
-        grad_res_3D = None
-        gradient_idx = None
-
-        # Create gPC object
-        if self.options["method"] == "reg":
-            if self.gpc is None:
-                gpc = Reg(problem=self.problem,
-                          order=self.options["order"],
-                          order_max=self.options["order_max"],
-                          order_max_norm=self.options["order_max_norm"],
-                          interaction_order=self.options["interaction_order"],
-                          interaction_order_current=self.options["interaction_order"],
-                          options=self.options,
-                          validation=self.validation)
-            else:
-                gpc = self.gpc
-                gpc.options["fn_results"] = self.options["fn_results"]
-                gpc.fn_results = self.options["fn_results"]
-
-        elif self.options["method"] == "quad":
-            gpc = Quad(problem=self.problem,
-                       order=self.options["order"],
-                       order_max=self.options["order_max"],
-                       order_max_norm=self.options["order_max_norm"],
-                       interaction_order=self.options["interaction_order"],
-                       interaction_order_current=self.options["interaction_order"],
-                       options=self.options,
-                       validation=self.validation)
-
-        else:
-            raise AssertionError("Please specify correct gPC method ('reg' or 'quad')")
-
-        gpc.backend = self.options["backend"]
-
-        # determine number of basis functions
-        n_coeffs = get_num_coeffs_sparse(order_dim_max=self.options["order"],
-                                         order_glob_max=self.options["order_max"],
-                                         order_inter_max=self.options["interaction_order"],
-                                         dim=self.problem.dim)
-
-        if self.options["n_grid"] is not None:
-            n_grid = self.options["n_grid"]
-        else:
-            n_grid = self.options["matrix_ratio"] * n_coeffs
-
-        # Write grid in gpc object
-        if self.grid is not None:
-            if self.options["method"] == "reg":
-                print(f"Using user-predefined grid with n_grid={self.grid.n_grid}")
-                gpc.grid = self.options["grid"](parameters_random=self.problem.parameters_random,
-                                                coords=self.grid.coords,
-                                                coords_norm=self.grid.coords_norm,
-                                                coords_gradient=self.grid.coords_gradient,
-                                                coords_gradient_norm=self.grid.coords_gradient_norm,
-                                                options=self.options["grid_options"])
-            elif self.options["method"] == "quad":
-                gpc.grid = self.grid
-
-        elif self.options["grid"] == Random or self.options["grid"] == LHS or self.options["grid"] == GP:
-            gpc.grid = self.options["grid"](parameters_random=self.problem.parameters_random,
-                                            n_grid=n_grid,
-                                            options=self.options["grid_options"])
-
-        elif self.options["grid"] == L1 or self.options["grid"] == L1_LHS or self.options["grid"] == LHS_L1\
-                or self.options["grid"] == FIM or self.options["grid"] == CO:
-            gpc.grid = self.options["grid"](parameters_random=self.problem.parameters_random,
-                                            n_grid=n_grid,
-                                            options=self.options["grid_options"],
-                                            gpc=gpc)
-
-        else:
-            raise ValueError("Grid not provided and specified grid type not known!")
-
-        gpc.interaction_order_current = copy.deepcopy(self.options["interaction_order"])
-
-        # Initialize parallel Computation class
-        com = Computation(n_cpu=self.n_cpu, matlab_model=self.options["matlab_model"])
-
-        eps = self.options["eps"] + 1
-        eps_pre = eps + 1
-        i_grid = 0
-
-        res = np.array([])
-
-        # determine gpc approximation and determine error (increase grid size in case of adaptive sampling)
-        while eps > self.options["eps"]:
-            # Run simulations
-            iprint("Performing {} simulations!".format(gpc.grid.n_grid - i_grid),
-                   tab=0, verbose=self.options["verbose"])
-
-            start_time = time.time()
-
-            res_new = com.run(model=self.problem.model,
-                              problem=self.problem,
-                              coords=gpc.grid.coords[i_grid:gpc.grid.n_grid, :],
-                              coords_norm=gpc.grid.coords_norm[i_grid:gpc.grid.n_grid, :],
-                              i_iter=gpc.order_max,
-                              i_subiter=gpc.interaction_order,
-                              fn_results=None,
-                              print_func_time=self.options["print_func_time"],
-                              verbose=self.options["verbose"])
-
-            if len(res) > 0:
-                res = np.vstack((res, res_new))
-            else:
-                res = res_new
-
-            i_grid = gpc.grid.n_grid
-
-            iprint('Total parallel function evaluation: ' + str(time.time() - start_time) + ' sec',
-                   tab=0, verbose=self.options["verbose"])
-
-            # Determine gradient [n_grid x n_out x dim]
-            if self.options["gradient_enhanced"]:
-                start_time = time.time()
-
-                grad_res_3D, gradient_idx = get_gradient(model=self.problem.model,
-                                                         problem=self.problem,
-                                                         grid=gpc.grid,
-                                                         results=res,
-                                                         com=com,
-                                                         method=self.options["gradient_calculation"],
-                                                         gradient_results_present=None,
-                                                         gradient_idx_skip=None,
-                                                         i_iter=gpc.order_max,
-                                                         i_subiter=gpc.interaction_order,
-                                                         print_func_time=self.options["print_func_time"],
-                                                         dx=self.options["gradient_calculation_options"]["dx"],
-                                                         distance_weight=self.options["gradient_calculation_options"]["distance_weight"],
-                                                         verbose=self.options["verbose"])
-
-                iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
-                       tab=0, verbose=self.options["verbose"])
-
-            # check validity of results and resample in case the model could not be evaluated at some sampling points
-            res, grad_res_3D, gradient_idx, gpc.grid = self.check_results(results=res,
-                                                                          gradient_results=grad_res_3D,
-                                                                          gradient_results_idx=gradient_idx,
-                                                                          grid=gpc.grid,
-                                                                          com=com)
-
-            # Initialize gpc matrix
-            gpc.init_gpc_matrix(gradient_idx=gradient_idx)
-
-            # Compute gpc coefficients
-            coeffs = gpc.solve(results=res,
-                               gradient_results=grad_res_3D,
-                               solver=self.options["solver"],
-                               settings=self.options["settings"],
-                               verbose=self.options["verbose"])
-
-            # create validation set if necessary
-            if self.options["error_type"] == "nrmsd" and gpc.validation is None:
-                gpc.create_validation_set(n_samples=self.options["n_samples_validation"],
-                                          n_cpu=self.options["n_cpu"])
-
-            # validate gpc approximation (determine nrmsd or loocv specified in options["error_type"])
-            eps = gpc.validate(coeffs=coeffs, results=res, gradient_results=grad_res_3D)
-
-            iprint("-> {} {} error = {}".format(self.options["error_norm"],
-                                                self.options["error_type"],
-                                                eps), tab=0, verbose=self.options["verbose"])
-
-            if not self.options["adaptive_sampling"]:  # (0 < (eps_pre-eps)/eps < 0.01):
-                break
-
-            if eps > self.options["eps"]:
-                # extend grid by 5% of number of basis functions and restart loop
-                n_grid_new = gpc.grid.n_grid + 1  # int(np.ceil(gpc.grid.n_grid + 5e-2 * gpc.basis.n_basis))
-                iprint('Extending grid from {} to {} by {} sampling points using grid_extension_method {}'.format(
-                    gpc.grid.n_grid, n_grid_new, n_grid_new - gpc.grid.n_grid, self.options["grid_extension_method"]),
-                    tab=0, verbose=self.options["verbose"])
-                if self.options["grid_extension_method"] == "GPR":
-                    gpc.grid.extend_random_grid(n_grid_new=n_grid_new, results=res, type="GP")
-                else:
-                    gpc.grid.extend_random_grid(n_grid_new=n_grid_new)
-
-            # eps_pre = eps
-
-        # save gpc object and gpc coeffs
-        if self.options["fn_results"] is not None:
-
-            with h5py.File(fn_results + ".hdf5", "a") as f:
-
-                f.create_dataset("misc/fn_session",
-                                 data=np.array([os.path.split(self.options["fn_session"])[1]]).astype("|S"))
-                f.create_dataset("misc/fn_session_folder",
-                                 data=np.array([self.options["fn_session_folder"]]).astype("|S"))
-                f.create_dataset("misc/error_type", data=self.options["error_type"])
-                f.create_dataset("error", data=eps, maxshape=None, dtype="float64")
-                f.create_dataset("grid/coords", maxshape=None, data=gpc.grid.coords, dtype="float64")
-                f.create_dataset("grid/coords_norm", maxshape=None, data=gpc.grid.coords_norm, dtype="float64")
-
-                if gpc.grid.coords_gradient is not None:
-                    f.create_dataset("grid/coords_gradient", data=gpc.grid.coords_gradient,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("grid/coords_gradient_norm", data=gpc.grid.coords_gradient_norm,
-                                     maxshape=None, dtype="float64")
-
-                f.create_dataset("coeffs", data=coeffs,
-                                 maxshape=None, dtype="float64")
-                f.create_dataset("gpc_matrix", data=gpc.gpc_matrix,
-                                 maxshape=None, dtype="float64")
-
-                if gpc.gpc_matrix_gradient is not None:
-                    f.create_dataset("gpc_matrix_gradient",
-                                     data=gpc.gpc_matrix_gradient, maxshape=None, dtype="float64")
-
-                f.create_dataset("model_evaluations/results", data=res, maxshape=None, dtype="float64")
-
-                if grad_res_3D is not None:
-                    f.create_dataset("model_evaluations/gradient_results", data=ten2mat(grad_res_3D),
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("model_evaluations/gradient_results_idx", data=gpc.gradient_idx,
-                                     maxshape=None, dtype="int64")
-
-                if gpc.validation is not None:
-                    f.create_dataset("validation/model_evaluations/results", data=gpc.validation.results,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("validation/grid/coords", data=gpc.validation.grid.coords,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("validation/grid/coords_norm", data=gpc.validation.grid.coords_norm,
-                                     maxshape=None, dtype="float64")
-
-        com.close()
-
-        return gpc, coeffs, res
-
-
-class MEStatic(Algorithm):
-    """
-    Multi-Element Static gPC algorithm
-
-    Parameters
-    ----------
-    problem : Problem object
-        Object instance of gPC problem to investigate
-    options["method"]: str
-        GPC method to apply ['Reg', 'Quad']
-    options["order"]: list of int [dim]
-        Maximum individual expansion order [order_1, order_2, ..., order_dim].
-        Generates individual polynomials also if maximum expansion order in order_max is exceeded
-    options["order_max"]: int
-        Maximum global expansion order.
-        The maximum expansion order considers the sum of the orders of combined polynomials together with the
-        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
-        monomial orders.
-    options["order_max_norm"]: float
-        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
-        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
-        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
-        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
-    options["interaction_order"]: int
-        Number of random variables, which can interact with each other.
-        All polynomials are ignored, which have an interaction order greater than the specified
-    options["qoi"] : int or str, optional, default: 0
-        Choose for which QOI the projection is determined for. The other QOIs use the same projection.
-        Alternatively, the projection can be determined for every QOI independently (qoi_index or "all").
-    options["classifier"] : str, optional, default: "learning"
-        Classification algorithm to subdivide parameter domain.
-        - "learning" ... ClassifierLearning algorithm based on Unsupervised and supervised learning
-    options["classifier_options"] : dict, optional, default: default settings
-        Options of classifier
-    grid: Grid object instance
-        Grid object to use for static gPC (Random, SparseGrid, TensorGrid)
-
-    Notes
-    -----
-    .. [1] Blatman, G., & Sudret, B. (2011). Adaptive sparse polynomial chaos expansion based on least angle
-       regression. Journal of Computational Physics, 230(6), 2345-2367.
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> # initialize static gPC algorithm
-    >>> algorithm = pygpc.MEStatic(problem=problem, options=options, grid=grid)
-    >>> # run algorithm
-    >>> gpc, coeffs, results = algorithm.run()
-    """
-
-    def __init__(self, problem, options, grid=None, validation=None):
-        """
-        Constructor; Initializes multi-element static gPC algorithm
-        """
-        super(MEStatic, self).__init__(problem=problem, options=options, validation=validation, grid=grid)
-
-        # check contents of settings dict and set defaults
-        if "method" not in self.options.keys():
-            raise AssertionError("Please specify 'method' with either 'reg' or 'quad' in options dictionary")
-
-        if "order" not in self.options.keys():
-            raise AssertionError("Please specify 'order'=[order_1, order_2, ..., order_dim] in options dictionary")
-
-        if "order_max" not in self.options.keys():
-            raise AssertionError("Please specify 'order_max' in options dictionary")
-
-        if "interaction_order" not in self.options.keys():
-            self.options["interaction_order"] = self.problem.dim
-
-        if "order_max_norm" not in self.options.keys():
-            self.options["order_max_norm"] = 1.
-
-        if "qoi" not in self.options.keys():
-            self.options["qoi"] = 0
-
-        if "classifier" not in self.options.keys():
-            self.options["classifier"] = "learning"
-
-        if "classifier_options" not in self.options.keys():
-            self.options["classifier_options"] = None
-
-        if self.options["qoi"] == "all":
-            self.qoi_specific = True
-        else:
-            self.qoi_specific = False
-
-    def run(self):
-        """
-        Runs Multi-Element Static gPC algorithm to solve problem.
-
-        Returns
-        -------
-        megpc : Multi-element GPC object instance
-            MEGPC object containing all information i.e., Problem, Model, Grid, Basis, RandomParameter instances
-        coeffs: list of ndarray of float [n_gpc][n_basis x n_out]
-            GPC coefficients
-        res : ndarray of float [n_grid x n_out]
-            Simulation results at n_grid points of the n_out output variables
-        """
-        if self.options["fn_results"] is not None:
-            fn_results = os.path.splitext(self.options["fn_results"])[0]
-
-            if os.path.exists(fn_results + ".hdf5"):
-                os.remove(fn_results + ".hdf5")
-        else:
-            fn_results = None
-
-        grad_res_3D = None
-        grad_res_3D_all = None
-        gradient_idx = None
-        res_all_list = []
-
-        if self.options["n_grid"] is not None:
-            n_grid = self.options["n_grid"]
-        else:
-            n_grid = None
-
-        # Write grid in gpc object
-        if self.grid is not None:
-            print(f"Using user-predefined grid with n_grid={n_grid}")
-            grid = self.options["grid"](parameters_random=self.problem.parameters_random,
-                                        coords=self.grid.coords,
-                                        coords_norm=self.grid.coords_norm,
-                                        coords_gradient=self.grid.coords_gradient,
-                                        coords_gradient_norm=self.grid.coords_gradient_norm,
-                                        options=self.options["grid_options"])
-
-        elif n_grid is None:
-            raise ValueError("If grid is not provided during initialization please provide options['n_grid']")
-
-        elif self.options["grid"] == Random or self.options["grid"] == LHS or self.options["grid"] == GP:
-            print(f"Creating initial grid ({self.options['grid'].__name__}) with n_grid={int(n_grid)}")
-            grid = self.options["grid"](parameters_random=self.problem.parameters_random,
-                                        n_grid=n_grid,
-                                        options=self.options["grid_options"])
-
-        elif self.options["grid"] == L1 or self.options["grid"] == L1_LHS or self.options["grid"] == LHS_L1 \
-                or self.options["grid"] == FIM:
-            raise NotImplementedError("Grid type not possible for MEStatic algorithm."
-                                      "Please use either 'Random' or 'LHS'.")
-
-        else:
-            raise ValueError("Grid not provided and specified grid type not known!")
-
-        # Initialize parallel Computation class
-        com = Computation(n_cpu=self.n_cpu, matlab_model=self.options["matlab_model"])
-
-        megpc = []
-        coeffs = []
-        eps = self.options["eps"] + 1
-        i_grid = 0
-        i_qoi = 0
-
-        if self.options["qoi"] is not None and self.options["qoi"] != "all":
-            q_idx = self.options["qoi"]
-            qoi_idx = [q_idx]
-        else:
-            qoi_idx = np.arange(1)
-            q_idx = qoi_idx[0]
-
-        n_qoi = len(qoi_idx)
-
-        while i_qoi < n_qoi:
-            q_idx = qoi_idx[i_qoi]
-            print_str = "Determining gPC approximation for QOI #{}:".format(q_idx)
-            iprint(print_str, tab=0, verbose=self.options["verbose"])
-            iprint("=" * len(print_str), tab=0, verbose=self.options["verbose"])
-            megpc.append(0)
-            coeffs.append(0)
-            eps_pre = eps + 1
-
-            # Create MEGPC object
-            megpc[i_qoi] = MEGPC(problem=self.problem,
-                                 options=self.options,
-                                 validation=self.validation)
-
-            res_all = np.array([])
-
-            # determine gpc approximation and determine error (increase grid size in case of adaptive sampling)
-            while eps > self.options["eps"]:
-                if i_grid < grid.n_grid:
-                    # run simulations
-                    iprint("Performing {} simulations!".format(grid.n_grid - i_grid),
-                           tab=0, verbose=self.options["verbose"])
-
-                    start_time = time.time()
-
-                    res_new = com.run(model=self.problem.model,
-                                      problem=self.problem,
-                                      coords=grid.coords[i_grid:grid.n_grid, :],
-                                      coords_norm=grid.coords_norm[i_grid:grid.n_grid, :],
-                                      i_iter=self.options["order_max"],
-                                      i_subiter=self.options["interaction_order"],
-                                      fn_results=None,
-                                      print_func_time=self.options["print_func_time"],
-                                      verbose=self.options["verbose"])
-
-                    if len(res_all) > 0:
-                        res_all = np.vstack(res_all, res_new)
-                    else:
-                        res_all = res_new
-
-                    if i_qoi == 0 and i_grid == 0:
-                        if self.options["qoi"] == "all":
-                            qoi_idx = np.arange(res_all.shape[1])
-                            n_qoi = len(qoi_idx)
-
-                    i_grid = grid.n_grid
-
-                    iprint('Total function evaluation: ' + str(time.time() - start_time) + ' sec',
-                           tab=0, verbose=self.options["verbose"])
-
-                    # Determine gradient [n_grid x n_out x dim]
-                    if self.options["gradient_enhanced"]:
-                        start_time = time.time()
-
-                        grad_res_3D_all, gradient_idx = get_gradient(model=self.problem.model,
-                                                                     problem=self.problem,
-                                                                     grid=grid,
-                                                                     results=res_all,
-                                                                     com=com,
-                                                                     method=self.options["gradient_calculation"],
-                                                                     gradient_results_present=grad_res_3D_all,
-                                                                     gradient_idx_skip=gradient_idx,
-                                                                     i_iter=self.options["order_max"],
-                                                                     i_subiter=self.options["interaction_order"],
-                                                                     print_func_time=self.options["print_func_time"],
-                                                                     dx=self.options["gradient_calculation_options"]["dx"],
-                                                                     distance_weight=
-                                                                     self.options["gradient_calculation_options"][
-                                                                         "distance_weight"],
-                                                                     verbose=self.options["verbose"])
-
-                        iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
-                               tab=0, verbose=self.options["verbose"])
-
-                    # check validity of results and resample in case the model could not be evaluated at some sampling points
-                    res_all, grad_res_3D_all, gradient_idx, grid = self.check_results(results=res_all,
-                                                                                      gradient_results=grad_res_3D_all,
-                                                                                      gradient_results_idx=gradient_idx,
-                                                                                      grid=grid,
-                                                                                      com=com)
-                # crop results to considered qoi
-                if self.options["qoi"] != "all":
-                    res = copy.deepcopy(res_all)
-                    grad_res_3D = copy.deepcopy(grad_res_3D_all)
-                    hdf5_subfolder = ""
-                    output_idx_passed_validation = None
-
-                else:
-                    res = res_all[:, q_idx][:, np.newaxis]
-                    hdf5_subfolder = "/qoi_" + str(q_idx)
-                    output_idx_passed_validation = q_idx
-
-                    if grad_res_3D_all is not None:
-                        grad_res_3D = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
-
-                # Write grid in gpc object
-                megpc[i_qoi].grid = copy.deepcopy(grid)
-
-                # determine gpc domains
-                megpc[i_qoi].init_classifier(coords=megpc[i_qoi].grid.coords_norm,
-                                             results=res_all[:, q_idx][:, np.newaxis],
-                                             algorithm=self.options["classifier"],
-                                             options=self.options["classifier_options"])
-
-                # initialize sub-gPCs
-                for d in np.unique(megpc[i_qoi].domains):
-                    megpc[i_qoi].add_sub_gpc(problem=megpc[i_qoi].problem,
-                                             order=[self.options["order"][0] for _ in range(megpc[i_qoi].problem.dim)],
-                                             order_max=self.options["order_max"],
-                                             order_max_norm=self.options["order_max_norm"],
-                                             interaction_order=self.options["interaction_order"],
-                                             interaction_order_current=self.options["interaction_order"],
-                                             options=self.options,
-                                             domain=d,
-                                             validation=None)
-
-                # assign grids to sub-gPCs (rotate sub-grids in case of projection)
-                megpc[i_qoi].assign_grids(gradient_idx=gradient_idx)
-
-                # Initialize gpc matrices
-                megpc[i_qoi].init_gpc_matrices()
-
-                # Compute gpc coefficients
-                coeffs[i_qoi] = megpc[i_qoi].solve(results=res,
-                                                   gradient_results=grad_res_3D,
-                                                   solver=self.options["solver"],
-                                                   settings=self.options["settings"],
-                                                   verbose=self.options["verbose"])
-
-                # create validation set if necessary
-                if self.options["error_type"] == "nrmsd" and megpc[0].validation is None:
-                    megpc[0].create_validation_set(n_samples=self.options["n_samples_validation"],
-                                                   n_cpu=self.options["n_cpu"])
-                elif self.options["error_type"] == "nrmsd" and megpc[0].validation is not None:
-                    megpc[i_qoi].validation = copy.deepcopy(megpc[0].validation)
-
-                # validate gpc approximation (determine nrmsd or loocv specified in options["error_type"])
-                eps = megpc[i_qoi].validate(coeffs=coeffs[i_qoi], results=res, gradient_results=grad_res_3D)
-
-                iprint("-> {} {} error = {}".format(self.options["error_norm"],
-                                                    self.options["error_type"],
-                                                    eps), tab=0, verbose=self.options["verbose"])
-
-                # domain specific error
-                eps_domain = [0 for _ in range(len(np.unique(megpc[i_qoi].domains)))]
-                for i_gpc, d in enumerate(np.unique(megpc[i_qoi].domains)):
-                    eps_domain[d] = megpc[i_qoi].validate(coeffs=coeffs[i_qoi],
-                                                          results=res,
-                                                          domain=d,
-                                                          output_idx=output_idx_passed_validation)
-
-                if not self.options["adaptive_sampling"] or (0 < (eps_pre-eps)/eps < 0.01):
-                    break
-
-                if eps > self.options["eps"]:
-                    # extend grid by 10% of number of grid points
-                    n_grid_new = int(np.ceil(1.1*grid.n_grid))
-                    iprint("Extending grid from {} to {} by {} sampling points".format(
-                        grid.n_grid, n_grid_new, n_grid_new - grid.n_grid),
-                        tab=0, verbose=self.options["verbose"])
-                    grid.extend_random_grid(n_grid_new=n_grid_new)
-
-                eps_pre = eps
-
-            # save data
-            if self.options["fn_results"] is not None:
-
-                with h5py.File(fn_results + ".hdf5", "a") as f:
-
-                    try:
-                        fn_session = f["misc/fn_session"]
-
-                    except KeyError:
-                        f.create_dataset("misc/fn_session",
-                                         data=np.array([os.path.split(self.options["fn_session"])[1]]).astype("|S"))
-                        f.create_dataset("misc/fn_session_folder",
-                                         data=np.array([self.options["fn_session_folder"]]).astype("|S"))
-
-                    for i_gpc in range(megpc[i_qoi].n_gpc):
-                        f.create_dataset("error" + hdf5_subfolder + "/dom_" + str(i_gpc),
-                                         data=eps_domain[i_gpc],
-                                         maxshape=None, dtype="float64")
-
-                        f.create_dataset("coeffs" + hdf5_subfolder + "/dom_" + str(i_gpc),
-                                         data=coeffs[i_qoi][i_gpc],
-                                         maxshape=None, dtype="float64")
-
-                    f.create_dataset("domains" + hdf5_subfolder,
-                                     data=megpc[i_qoi].domains,
-                                     maxshape=None, dtype="int64")
-
-                    for i_gpc in range(megpc[i_qoi].n_gpc):
-                        f.create_dataset("gpc_matrix" + hdf5_subfolder + "/dom_" + str(i_gpc),
-                                         data=megpc[i_qoi].gpc[i_gpc].gpc_matrix,
-                                         maxshape=None, dtype="float64")
-
-                        if megpc[i_qoi].gpc[0].gpc_matrix_gradient is not None:
-                            if self.options["gradient_enhanced"]:
-                                f.create_dataset("gpc_matrix_gradient" + hdf5_subfolder + "/dom_" + str(i_gpc),
-                                                 data=megpc[i_qoi].gpc[i_gpc].gpc_matrix_gradient,
-                                                 maxshape=None, dtype="float64")
-
-            i_qoi += 1
-
-        if self.options["fn_results"] is not None:
-
-            with h5py.File(fn_results + ".hdf5", "a") as f:
-
-                try:
-                    del f["grid/coords"]
-                    del f["grid/coords_norm"]
-                    del f["grid/coords_gradient"]
-                    del f["grid/coords_gradient_norm"]
-
-                except KeyError:
-                    pass
-
-                f.create_dataset("grid/coords", data=grid.coords,
-                                 maxshape=None, dtype="float64")
-                f.create_dataset("grid/coords_norm", data=grid.coords_norm,
-                                 maxshape=None, dtype="float64")
-
-                if grid.coords_gradient is not None:
-                    f.create_dataset("grid/coords_gradient",
-                                     data=grid.coords_gradient,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("grid/coords_gradient_norm",
-                                     data=grid.coords_gradient_norm,
-                                     maxshape=None, dtype="float64")
-
-                f.create_dataset("model_evaluations/results", data=res,
-                                 maxshape=None, dtype="float64")
-                if grad_res_3D is not None:
-                    f.create_dataset("model_evaluations/gradient_results", data=ten2mat(grad_res_3D),
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("model_evaluations/gradient_results_idx", data=megpc[-1].gradient_idx,
-                                     maxshape=None, dtype="int64")
-
-                f.create_dataset("misc/error_type", data=self.options["error_type"])
-
-                if megpc[0].validation is not None:
-                    f.create_dataset("validation/model_evaluations/results", data=megpc[0].validation.results,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("validation/grid/coords", data=megpc[0].validation.grid.coords,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("validation/grid/coords_norm", data=megpc[0].validation.grid.coords_norm,
-                                     maxshape=None, dtype="float64")
-
-        com.close()
-
-        return megpc, coeffs, res
-
-
-class MEStatic_IO(Algorithm):
-    """
-    Multi-Element Static gPC algorithm using precomputed IO data
-
-    Parameters
-    ----------
-    parameters: OrderedDict containing the RandomParameter class instances
-        Dictionary (ordered) containing the properties of the random parameters
-    options["order"]: list of int [dim]
-        Maximum individual expansion order [order_1, order_2, ..., order_dim].
-        Generates individual polynomials also if maximum expansion order in order_max is exceeded
-    options["order_max"]: int
-        Maximum global expansion order.
-        The maximum expansion order considers the sum of the orders of combined polynomials together with the
-        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
-        monomial orders.
-    options["order_max_norm"]: float
-        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
-        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
-        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
-        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
-    options["interaction_order"]: int
-        Number of random variables, which can interact with each other.
-        All polynomials are ignored, which have an interaction order greater than the specified
-    options["qoi"] : int or str, optional, default: 0
-        Choose for which QOI the projection is determined for. The other QOIs use the same projection.
-        Alternatively, the projection can be determined for every QOI independently (qoi_index or "all").
-    options["classifier"] : str, optional, default: "learning"
-        Classification algorithm to subdivide parameter domain.
-        - "learning" ... ClassifierLearning algorithm based on Unsupervised and supervised learning
-    options["classifier_options"] : dict, optional, default: default settings
-        Options of classifier
-    grid: Grid object instance
-        Grid object to use for static gPC (Random, SparseGrid, TensorGrid) containing the parameter values, where the
-        output relations were calculated
-    results: ndarray of float [N_grid x N_qoi]
-        Model output at each grid point for each QOI
-
-    Notes
-    -----
-    .. [1] Blatman, G., & Sudret, B. (2011). Adaptive sparse polynomial chaos expansion based on least angle
-       regression. Journal of Computational Physics, 230(6), 2345-2367.
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> # initialize static gPC algorithm
-    >>> algorithm = pygpc.MEStatic_IO(parameters=parameters, options=options, results=results, grid=grid)
-    >>> # run algorithm
-    >>> gpc, coeffs, results = algorithm.run()
-    """
-
-    def __init__(self, parameters, options, results, grid, validation=None):
-        """
-        Constructor; Initializes multi-element static gPC algorithm
-        """
-        # create dummy model
-        model = Dummy()
-
-        # create dummy problem
-        problem = Problem(model, parameters)
-
-        super(MEStatic_IO, self).__init__(problem=problem, options=options, validation=validation, grid=grid)
-        self.res = results
-
-        # check contents of settings dict and set defaults
-        if "order" not in self.options.keys():
-            raise AssertionError("Please specify 'order'=[order_1, order_2, ..., order_dim] in options dictionary")
-
-        if "order_max" not in self.options.keys():
-            raise AssertionError("Please specify 'order_max' in options dictionary")
-
-        if "interaction_order" not in self.options.keys():
-            self.options["interaction_order"] = self.problem.dim
-
-        if "order_max_norm" not in self.options.keys():
-            self.options["order_max_norm"] = 1.
-
-        if "qoi" not in self.options.keys():
-            self.options["qoi"] = 0
-
-        if "classifier" not in self.options.keys():
-            self.options["classifier"] = "learning"
-
-        if "classifier_options" not in self.options.keys():
-            self.options["classifier_options"] = None
-
-        if self.options["qoi"] == "all":
-            self.qoi_specific = True
-        else:
-            self.qoi_specific = False
-
-        # if self.options["error_type"] != "loocv":
-            # self.options["error_type"] = "loocv"
-            # warnings.warn("Changing error calculation type to loocv ...")
-
-    def run(self):
-        """
-        Runs Multi-Element Static gPC algorithm using precomputed IO data to construct gPC approximation.
-
-        Returns
-        -------
-        megpc : Multi-element GPC object instance
-            MEGPC object containing all information i.e., Problem, Model, Grid, Basis, RandomParameter instances
-        coeffs: list of ndarray of float [n_gpc][n_basis x n_out]
-            GPC coefficients
-        res : ndarray of float [n_grid x n_out]
-            Simulation results at n_grid points of the n_out output variables
-        """
-        if self.options["fn_results"] is not None:
-            fn_results = os.path.splitext(self.options["fn_results"])[0]
-
-            if os.path.exists(fn_results + ".hdf5"):
-                os.remove(fn_results + ".hdf5")
-        else:
-            fn_results = None
-
-        megpc = []
-        coeffs = []
-        i_grid = 0
-        i_qoi = 0
-
-        if self.options["qoi"] is not None and self.options["qoi"] != "all":
-            q_idx = self.options["qoi"]
-            qoi_idx = [q_idx]
-        else:
-            qoi_idx = np.arange(1)
-            q_idx = qoi_idx[0]
-
-        n_qoi = len(qoi_idx)
-
-        while i_qoi < n_qoi:
-            q_idx = qoi_idx[i_qoi]
-            print_str = "Determining gPC approximation for QOI #{}:".format(q_idx)
-            iprint(print_str, tab=0, verbose=self.options["verbose"])
-            iprint("=" * len(print_str), tab=0, verbose=self.options["verbose"])
-            megpc.append(0)
-            coeffs.append(0)
-
-            # Create MEGPC object
-            megpc[i_qoi] = MEGPC(problem=self.problem,
-                                 options=self.options,
-                                 validation=self.validation)
-
-            if i_qoi == 0 and i_grid == 0:
-                if self.options["qoi"] == "all":
-                    qoi_idx = np.arange(self.res.shape[1])
-                    n_qoi = len(qoi_idx)
-
-            # crop results to considered qoi
-            if self.options["qoi"] != "all":
-                res = copy.deepcopy(self.res)
-                hdf5_subfolder = ""
-                output_idx_passed_validation = None
-            else:
-                res = self.res[:, q_idx][:, np.newaxis]
-                hdf5_subfolder = "/qoi_" + str(q_idx)
-                output_idx_passed_validation = q_idx
-
-            # Write grid in gpc object
-            megpc[i_qoi].grid = copy.deepcopy(self.grid)
-
-            # determine gpc domains
-            megpc[i_qoi].init_classifier(coords=megpc[i_qoi].grid.coords_norm,
-                                         results=self.res[:, q_idx][:, np.newaxis],
-                                         algorithm=self.options["classifier"],
-                                         options=self.options["classifier_options"])
-
-            # initialize sub-gPCs
-            for d in np.unique(megpc[i_qoi].domains):
-                megpc[i_qoi].add_sub_gpc(problem=megpc[i_qoi].problem,
-                                         order=[self.options["order"][0] for _ in range(megpc[i_qoi].problem.dim)],
-                                         order_max=self.options["order_max"],
-                                         order_max_norm=self.options["order_max_norm"],
-                                         interaction_order=self.options["interaction_order"],
-                                         interaction_order_current=self.options["interaction_order"],
-                                         options=self.options,
-                                         domain=d,
-                                         validation=None)
-
-            # assign grids to sub-gPCs (rotate sub-grids in case of projection)
-            megpc[i_qoi].assign_grids()
-
-            # Initialize gpc matrices
-            megpc[i_qoi].init_gpc_matrices()
-
-            # Compute gpc coefficients
-            coeffs[i_qoi] = megpc[i_qoi].solve(results=res,
-                                               solver=self.options["solver"],
-                                               settings=self.options["settings"],
-                                               verbose=self.options["verbose"])
-
-             # validate gpc approximation (determine nrmsd or loocv specified in options["error_type"])
-            eps = megpc[i_qoi].validate(coeffs=coeffs[i_qoi], results=res)
-
-            iprint("-> {} {} error = {}".format(self.options["error_norm"],
-                                                self.options["error_type"],
-                                                eps), tab=0, verbose=self.options["verbose"])
-
-            # domain specific error
-            eps_domain = [0 for _ in range(len(np.unique(megpc[i_qoi].domains)))]
-            for i_gpc, d in enumerate(np.unique(megpc[i_qoi].domains)):
-                eps_domain[d] = megpc[i_qoi].validate(coeffs=coeffs[i_qoi],
-                                                      results=res,
-                                                      domain=d,
-                                                      output_idx=output_idx_passed_validation)
-
-            # save data
-            if self.options["fn_results"] is not None:
-
-                with h5py.File(fn_results + ".hdf5", "a") as f:
-
-                    try:
-                        fn_session = f["misc/fn_session"]
-
-                    except KeyError:
-                        f.create_dataset("misc/fn_session",
-                                         data=np.array([os.path.split(self.options["fn_session"])[1]]).astype("|S"))
-                        f.create_dataset("misc/fn_session_folder",
-                                         data=np.array([self.options["fn_session_folder"]]).astype("|S"))
-
-                    for i_gpc in range(megpc[i_qoi].n_gpc):
-                        f.create_dataset("error" + hdf5_subfolder + "/dom_" + str(i_gpc),
-                                         data=eps_domain[i_gpc],
-                                         maxshape=None, dtype="float64")
-
-                        f.create_dataset("coeffs" + hdf5_subfolder + "/dom_" + str(i_gpc),
-                                         data=coeffs[i_qoi][i_gpc],
-                                         maxshape=None, dtype="float64")
-
-                    f.create_dataset("domains" + hdf5_subfolder,
-                                     data=megpc[i_qoi].domains,
-                                     maxshape=None, dtype="int64")
-
-                    for i_gpc in range(megpc[i_qoi].n_gpc):
-                        f.create_dataset("gpc_matrix" + hdf5_subfolder + "/dom_" + str(i_gpc),
-                                         data=megpc[i_qoi].gpc[i_gpc].gpc_matrix,
-                                         maxshape=None, dtype="float64")
-
-                        if megpc[i_qoi].gpc[0].gpc_matrix_gradient is not None:
-                            if self.options["gradient_enhanced"]:
-                                f.create_dataset("gpc_matrix_gradient" + hdf5_subfolder + "/dom_" + str(i_gpc),
-                                                 data=megpc[i_qoi].gpc[i_gpc].gpc_matrix_gradient,
-                                                 maxshape=None, dtype="float64")
-
-            i_qoi += 1
-
-        if self.options["fn_results"] is not None:
-
-            with h5py.File(fn_results + ".hdf5", "a") as f:
-
-                try:
-                    del f["grid/coords"]
-                    del f["grid/coords_norm"]
-                    del f["grid/coords_gradient"]
-                    del f["grid/coords_gradient_norm"]
-
-                except KeyError:
-                    pass
-
-                f.create_dataset("grid/coords", data=self.grid.coords,
-                                 maxshape=None, dtype="float64")
-                f.create_dataset("grid/coords_norm", data=self.grid.coords_norm,
-                                 maxshape=None, dtype="float64")
-
-                if self.grid.coords_gradient is not None:
-                    f.create_dataset("grid/coords_gradient",
-                                     data=self.grid.coords_gradient,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("grid/coords_gradient_norm",
-                                     data=self.grid.coords_gradient_norm,
-                                     maxshape=None, dtype="float64")
-
-                f.create_dataset("model_evaluations/results", data=self.res,
-                                 maxshape=None, dtype="float64")
-
-                f.create_dataset("misc/error_type", data=self.options["error_type"])
-
-                if megpc[0].validation is not None:
-                    f.create_dataset("validation/model_evaluations/results", data=megpc[0].validation.results,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("validation/grid/coords", data=megpc[0].validation.grid.coords,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("validation/grid/coords_norm", data=megpc[0].validation.grid.coords_norm,
-                                     maxshape=None, dtype="float64")
-
-        return megpc, coeffs, self.res
-
-
-class StaticProjection(Algorithm):
-    """
-    Static gPC algorithm using Basis Projection approach
-
-    Parameters
-    ----------
-    problem : Problem object
-        Object instance of gPC problem to investigate
-    options["method"]: str
-        GPC method to apply ['Reg', 'Quad']
-    options["order"]: int
-        Expansion order, each projected variable \\eta is expanded to.
-        Generates individual polynomials also if maximum expansion order in order_max is exceeded
-    options["order_max"]: int
-        Maximum global expansion order.
-        The maximum expansion order considers the sum of the orders of combined polynomials together with the
-        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
-        monomial orders.
-    options["order_max_norm"]: float
-        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
-        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
-        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
-        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
-    options["interaction_order"]: int
-        Number of random variables, which can interact with each other.
-        All polynomials are ignored, which have an interaction order greater than the specified
-    options["qoi"] : int or str, optional, default: 0
-        Choose for which QOI the projection is determined for. The other QOIs use the same projection.
-        Alternatively, the projection can be determined for every QOI independently (qoi_index or "all").
-    options["n_grid"] : float, optional, default: 10
-        Number of initial grid points to determine gradient and projection matrix
-
-    Notes
-    -----
-    .. [1] Blatman, G., & Sudret, B. (2011). Adaptive sparse polynomial chaos expansion based on least angle
-       regression. Journal of Computational Physics, 230(6), 2345-2367.
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> # initialize static gPC algorithm
-    >>> algorithm = pygpc.StaticProjection(problem=problem, options=options)
-    >>> # run algorithm
-    >>> gpc, coeffs, results = algorithm.run
-    """
-
-    def __init__(self, problem, options, validation=None, grid=None):
-        """
-        Constructor; Initializes static gPC algorithm
-        """
-        super(StaticProjection, self).__init__(problem=problem, options=options, validation=validation, grid=grid)
-
-        # check contents of settings dict and set defaults
-        if "method" not in self.options.keys():
-            raise AssertionError("Please specify 'method' with either 'reg' or 'quad' in options dictionary")
-
-        if "order" not in self.options.keys():
-            raise AssertionError("Please specify 'order'=[order_1, order_2, ..., order_dim] in options dictionary")
-
-        if "order_max" not in self.options.keys():
-            raise AssertionError("Please specify 'order_max' in options dictionary")
-
-        if "interaction_order" not in self.options.keys():
-            self.options["interaction_order"] = self.problem.dim
-
-        if "order_max_norm" not in self.options.keys():
-            self.options["order_max_norm"] = 1.
-
-        if "n_grid" not in self.options.keys():
-            self.options["n_grid"] = 10
-
-        if "qoi" not in self.options.keys():
-            self.options["qoi"] = 0
-
-        if self.options["qoi"] == "all":
-            self.qoi_specific = True
-        else:
-            self.qoi_specific = False
-
-    def run(self):
-        """
-        Runs static gPC algorithm using Projection to solve problem.
-
-        Returns
-        -------
-        gpc : GPC object instance
-            GPC object containing all information i.e., Problem, Model, Grid, Basis, RandomParameter instances
-        coeffs: list of ndarray of float [n_qoi][n_basis x n_out]
-            GPC coefficients for different qoi
-        res : ndarray of float [n_grid x n_out]
-            Simulation results at n_grid points of the n_out output variables
-        """
-
-        if self.options["fn_results"] is not None:
-            fn_results = os.path.splitext(self.options["fn_results"])[0]
-
-            if os.path.exists(fn_results + ".hdf5"):
-                os.remove(fn_results + ".hdf5")
-        else:
-            fn_results = None
-
-        grad_res_3D = None
-        grad_res_3D_all = None
-        gradient_idx = None
-        res_all_list = []
-
-        n_grid = self.options["n_grid"]
-
-        # make initial grid to determine gradients and projection matrix. By default, it is an LHS (ese) grid
-        if self.grid is not None:
-            print(f"Using user-predefined grid with n_grid={self.grid.n_grid}")
-            grid_original = self.options["grid"](parameters_random=self.problem.parameters_random,
-                                                 coords=self.grid.coords,
-                                                 coords_norm=self.grid.coords_norm,
-                                                 coords_gradient=self.grid.coords_gradient,
-                                                 coords_gradient_norm=self.grid.coords_gradient_norm,
-                                                 options=self.options["grid_options"])
-        elif self.options["grid"] == Random or self.options["grid"] == GP:
-            print(f"Creating initial grid ({self.options['grid'].__name__}) with n_grid={int(n_grid)}")
-            grid_original = self.options["grid"](parameters_random=self.problem.parameters_random,
-                                   n_grid=n_grid,
-                                   options=self.options["grid_options"])
-        else:
-            print(f"Creating initial grid ({self.options['grid'].__name__}) with n_grid={int(n_grid)}")
-            grid_original = LHS(parameters_random=self.problem.parameters_random,
-                                n_grid=n_grid,
-                                options={"criterion": "ese",
-                                         "seed": self.options["seed"]})
-
-        # Initialize parallel Computation class
-        com = Computation(n_cpu=self.n_cpu, matlab_model=self.options["matlab_model"])
-
-        # Set up reduced gPC
-        self.problem_reduced = []
-        gpc = []
-        coeffs = []
-        eps = self.options["eps"] + 1
-        i_grid = 0
-        i_qoi = 0
-
-        if self.options["qoi"] is not None and self.options["qoi"] != "all":
-            q_idx = self.options["qoi"]
-            qoi_idx = [q_idx]
-        else:
-            qoi_idx = np.arange(1)
-            q_idx = qoi_idx[0]
-
-        n_qoi = len(qoi_idx)
-
-        while i_qoi < n_qoi:
-            q_idx = qoi_idx[i_qoi]
-            print_str = "Determining gPC approximation for QOI #{}:".format(q_idx)
-            iprint(print_str, tab=0, verbose=self.options["verbose"])
-            iprint("=" * len(print_str), tab=0, verbose=self.options["verbose"])
-            self.problem_reduced.append(0)
-            gpc.append(0)
-            coeffs.append(0)
-            eps_pre = eps + 1
-
-            # determine gpc approximation and determine error (increase grid size in case of adaptive sampling)
-            while eps > self.options["eps"]:
-                # run simulations
-                if i_grid < grid_original.n_grid:
-                    iprint("Performing {} simulations!".format(grid_original.n_grid - i_grid),
-                           tab=0, verbose=self.options["verbose"])
-
-                    start_time = time.time()
-
-                    res_all_list.append(com.run(model=self.problem.model,
-                                                problem=self.problem,
-                                                coords=grid_original.coords[i_grid:grid_original.n_grid, :],
-                                                coords_norm=grid_original.coords_norm[i_grid:grid_original.n_grid, :],
-                                                i_iter=self.options["order_max"],
-                                                i_subiter=self.options["interaction_order"],
-                                                fn_results=None,
-                                                print_func_time=self.options["print_func_time"],
-                                                verbose=self.options["verbose"]))
-
-                    res_all = np.vstack(res_all_list)
-
-                    if i_qoi == 0 and i_grid == 0:
-                        if self.options["qoi"] == "all":
-                            qoi_idx = np.arange(res_all.shape[1])
-                            n_qoi = len(qoi_idx)
-
-                    i_grid = grid_original.n_grid
-
-                    iprint('Total function evaluation: ' + str(time.time() - start_time) + ' sec',
-                           tab=0, verbose=self.options["verbose"])
-
-                    # Determine gradient [n_grid x n_out x dim]
-                    start_time = time.time()
-
-                    grad_res_3D_all, gradient_idx = get_gradient(model=self.problem.model,
-                                                                 problem=self.problem,
-                                                                 grid=grid_original,
-                                                                 results=res_all,
-                                                                 com=com,
-                                                                 method="FD_fwd",
-                                                                 gradient_results_present=grad_res_3D_all,
-                                                                 gradient_idx_skip=gradient_idx,
-                                                                 i_iter=self.options["order_max"],
-                                                                 i_subiter=self.options["interaction_order"],
-                                                                 print_func_time=self.options["print_func_time"],
-                                                                 dx=self.options["gradient_calculation_options"]["dx"],
-                                                                 distance_weight=
-                                                                 self.options["gradient_calculation_options"][
-                                                                     "distance_weight"],
-                                                                 verbose=self.options["verbose"])
-
-                    iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
-                           tab=0, verbose=self.options["verbose"])
-
-                    # check validity of results and resample in case the model could not be evaluated at some sampling points
-                    res_all, grad_res_3D_all, gradient_idx, grid_original = self.check_results(results=res_all,
-                                                                                               gradient_results=grad_res_3D_all,
-                                                                                               gradient_results_idx=gradient_idx,
-                                                                                               grid=grid_original,
-                                                                                               com=com)
-
-                # crop results to considered qoi
-                if self.options["qoi"] != "all":
-                    res = copy.deepcopy(res_all)
-                    grad_res_3D = copy.deepcopy(grad_res_3D_all)
-                    hdf5_subfolder = ""
-
-                else:
-                    res = res_all[:, q_idx][:, np.newaxis]
-                    grad_res_3D = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
-                    hdf5_subfolder = "/qoi_" + str(q_idx)
-
-                # Determine projection matrix
-                p_matrix, p_matrix_complete = determine_projection_matrix(gradient_results=grad_res_3D_all[:, q_idx, :],
-                                                                          lambda_eps=self.options["lambda_eps_gradient"])
-                p_matrix_norm = np.sum(np.abs(p_matrix), axis=1)
-
-                dim_reduced = p_matrix.shape[0]
-                parameters_reduced = OrderedDict()
-
-                for i in range(dim_reduced):
-                    parameters_reduced["n{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
-
-                self.problem_reduced[i_qoi] = Problem(model=self.problem.model, parameters=parameters_reduced)
-
-                # Create reduced gPC object
-                gpc[i_qoi] = Reg(problem=self.problem_reduced[i_qoi],
-                                 order=[self.options["order"][0] for _ in range(dim_reduced)],
-                                 order_max=self.options["order_max"],
-                                 order_max_norm=self.options["order_max_norm"],
-                                 interaction_order=self.options["interaction_order"],
-                                 interaction_order_current=self.options["interaction_order"],
-                                 options=self.options,
-                                 validation=self.validation)
-
-                # save original problem in gpc object
-                gpc[i_qoi].problem_original = self.problem
-
-                # save projection matrix in gPC object
-                gpc[i_qoi].p_matrix = copy.deepcopy(p_matrix)
-                gpc[i_qoi].p_matrix_norm = copy.deepcopy(p_matrix_norm)
-
-                # re-initialize grid in case of [L1, L1_LHS, LHS_L1, FIM] because initial grid was Random or LHS (ese)
-                if self.options["grid"] in [L1, L1_LHS, LHS_L1, FIM]:
-                    grid_original = self.options["grid"](parameters_random=self.problem.parameters_random,
-                                                         coords=grid_original.coords,
-                                                         coords_norm=grid_original.coords_norm,
-                                                         coords_gradient=grid_original.coords_gradient,
-                                                         coords_gradient_norm=grid_original.coords_gradient_norm,
-                                                         options=self.options["grid_options"],
-                                                         gpc=gpc[i_qoi])
-
-                # copy grid to gPC object and initialize transformed grid
-                gpc[i_qoi].grid_original = copy.deepcopy(grid_original)
-                gpc[i_qoi].grid = project_grid(grid=grid_original, p_matrix=p_matrix, mode="reduce")
-                gpc[i_qoi].options = copy.deepcopy(self.options)
-
-                # Initialize gpc matrix
-                gpc[i_qoi].init_gpc_matrix(gradient_idx=gradient_idx)
-
-                # Someone might not use the gradient to determine the gpc coeffs
-                if self.options["gradient_enhanced"]:
-                    grad_res_3D_passed = grad_res_3D
-                else:
-                    grad_res_3D_passed = None
-
-                # Compute gpc coefficients
-                coeffs[i_qoi] = gpc[i_qoi].solve(results=res,
-                                                 gradient_results=grad_res_3D_passed,
-                                                 solver=self.options["solver"],
-                                                 settings=self.options["settings"],
-                                                 verbose=self.options["verbose"])
-
-                # validate gpc approximation (determine nrmsd or loocv specified in options["error_type"])
-                if self.options["error_type"] == "nrmsd" and gpc[0].validation is None:
-                    gpc[0].create_validation_set(n_samples=self.options["n_samples_validation"],
-                                                 n_cpu=self.options["n_cpu"])
-                elif self.options["error_type"] == "nrmsd" and gpc[0].validation is not None:
-                    gpc[i_qoi].validation = copy.deepcopy(gpc[0].validation)
-
-                eps = gpc[i_qoi].validate(coeffs=coeffs[i_qoi], results=res, gradient_results=grad_res_3D_passed)
-
-                iprint("-> {} {} error = {}".format(self.options["error_norm"],
-                                                    self.options["error_type"],
-                                                    eps), tab=0, verbose=self.options["verbose"])
-
-                if not self.options["adaptive_sampling"] or (0 < (eps_pre-eps)/eps < 0.01):
-                    break
-
-                if eps > self.options["eps"]:
-                    # extend grid by 5% of number of basis functions and restart loop
-                    n_grid_new = int(np.ceil(grid_original.n_grid + 5e-2 * gpc[i_qoi].basis.n_basis))
-                    iprint("Extending grid from {} to {} by {} sampling points".format(
-                        grid_original.n_grid, n_grid_new, n_grid_new - grid_original.n_grid),
-                        tab=0, verbose=self.options["verbose"])
-                    grid_original.extend_random_grid(n_grid_new=n_grid_new)
-
-                eps_pre = eps
-
-            # save gpc objects and gpc coeffs
-            if self.options["fn_results"] is not None:
-
-                with h5py.File(fn_results + ".hdf5", "a") as f:
-
-                    try:
-                        fn_session = f["misc/fn_session"]
-
-                    except KeyError:
-                        f.create_dataset("misc/fn_session",
-                                         data=np.array([os.path.split(self.options["fn_session"])[1]]).astype("|S"))
-                        f.create_dataset("misc/fn_session_folder",
-                                         data=np.array([self.options["fn_session_folder"]]).astype("|S"))
-
-                    f.create_dataset("error" + hdf5_subfolder,
-                                     data=eps,
-                                     maxshape=None, dtype="float64")
-
-                    f.create_dataset("coeffs" + hdf5_subfolder,
-                                     data=coeffs[i_qoi],
-                                     maxshape=None, dtype="float64")
-
-                    f.create_dataset("gpc_matrix" + hdf5_subfolder,
-                                     data=gpc[i_qoi].gpc_matrix,
-                                     maxshape=None, dtype="float64")
-
-                    if gpc[i_qoi].gpc_matrix_gradient is not None:
-                        f.create_dataset("gpc_matrix_gradient" + hdf5_subfolder,
-                                         data=gpc[i_qoi].gpc_matrix_gradient,
-                                         maxshape=None, dtype="float64")
-
-                    f.create_dataset("p_matrix" + hdf5_subfolder,
-                                     data=gpc[i_qoi].p_matrix,
-                                     maxshape=None, dtype="float64")
-
-            i_qoi += 1
-
-        if self.options["fn_results"] is not None:
-
-            with h5py.File(fn_results + ".hdf5", "a") as f:
-                f.create_dataset("grid/coords", data=grid_original.coords,
-                                 maxshape=None, dtype="float64")
-                f.create_dataset("grid/coords_norm", data=grid_original.coords_norm,
-                                 maxshape=None, dtype="float64")
-
-                if grid_original.coords_gradient is not None:
-                    f.create_dataset("grid/coords_gradient",
-                                     data=grid_original.coords_gradient,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("grid/coords_gradient_norm",
-                                     data=grid_original.coords_gradient_norm,
-                                     maxshape=None, dtype="float64")
-
-                f.create_dataset("model_evaluations/results", data=res,
-                                 maxshape=None, dtype="float64")
-                if grad_res_3D is not None:
-                    f.create_dataset("model_evaluations/gradient_results", data=ten2mat(grad_res_3D),
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("model_evaluations/gradient_results_idx", data=gpc[-1].gradient_idx,
-                                     maxshape=None, dtype="int64")
-
-                f.create_dataset("misc/error_type", data=self.options["error_type"])
-
-                if gpc[0].validation is not None:
-                    f.create_dataset("validation/model_evaluations/results", data=gpc[0].validation.results,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("validation/grid/coords", data=gpc[0].validation.grid.coords,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("validation/grid/coords_norm", data=gpc[0].validation.grid.coords_norm,
-                                     maxshape=None, dtype="float64")
-
-        com.close()
-
-        return gpc, coeffs, res_all
-
-
-class MEStaticProjection(Algorithm):
-    """
-    Static gPC algorithm using Basis Projection approach
-
-    Parameters
-    ----------
-    problem : Problem object
-        Object instance of gPC problem to investigate
-    options["order"]: int
-        Expansion order, each projected variable \\eta is expanded to.
-        Generates individual polynomials also if maximum expansion order in order_max is exceeded
-    options["order_max"]: int
-        Maximum global expansion order.
-        The maximum expansion order considers the sum of the orders of combined polynomials together with the
-        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
-        monomial orders.
-    options["interaction_order"]: int
-        Number of random variables, which can interact with each other.
-        All polynomials are ignored, which have an interaction order greater than the specified
-    options["qoi"] : int or str, optional, default: 0
-        Choose for which QOI the projection is determined for. The other QOIs use the same projection.
-        Alternatively, the projection can be determined for every QOI independently (qoi_index or "all").
-    options["n_grid_gradient"] : float, optional, default: 10
-        Number of initial grid points to determine gradient and projection matrix
-    options["classifier"] : str, optional, default: "learning"
-        Classification algorithm to subdivide parameter domain.
-        - "learning" ... ClassifierLearning algorithm based on Unsupervised and supervised learning
-    options["classifier_options"] : dict, optional, default: default settings
-        Options of classifier
-
-    Notes
-    -----
-    .. [1] Blatman, G., & Sudret, B. (2011). Adaptive sparse polynomial chaos expansion based on least angle
-       regression. Journal of Computational Physics, 230(6), 2345-2367.
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> # initialize static gPC algorithm
-    >>> algorithm = pygpc.MEStaticProjection(problem=problem, options=options)
-    >>> # run algorithm
-    >>> gpc, coeffs, results = algorithm.run
-    """
-
-    def __init__(self, problem, options, validation=None, grid=None):
-        """
-        Constructor; Initializes static gPC algorithm
-        """
-        super(MEStaticProjection, self).__init__(problem=problem, options=options, validation=validation, grid=grid)
-
-        # check contents of settings dict and set defaults
-        if "method" not in self.options.keys():
-            raise AssertionError("Please specify 'method' with either 'reg' or 'quad' in options dictionary")
-
-        if "order" not in self.options.keys():
-            raise AssertionError("Please specify 'order'=[order_1, order_2, ..., order_dim] in options dictionary")
-
-        if "order_max" not in self.options.keys():
-            raise AssertionError("Please specify 'order_max' in options dictionary")
-
-        if "interaction_order" not in self.options.keys():
-            self.options["interaction_order"] = self.problem.dim
-
-        if "order_max_norm" not in self.options.keys():
-            self.options["order_max_norm"] = 1.
-
-        if "n_grid_gradient" not in self.options.keys():
-            self.options["n_grid_gradient"] = 10
-
-        if "qoi" not in self.options.keys():
-            self.options["qoi"] = 0
-
-        if "classifier" not in self.options.keys():
-            self.options["classifier"] = "learning"
-
-        if "classifier_options" not in self.options.keys():
-            self.options["classifier_options"] = None
-
-        if self.options["qoi"] == "all":
-            self.qoi_specific = True
-        else:
-            self.qoi_specific = False
-
-    def run(self):
-        """
-        Runs static multi-element gPC algorithm with projection.
-
-        Returns
-        -------
-        megpc : MEGPC object instance
-            MEGPC object containing all information i.e., Problem, Model, Grid, Basis, RandomParameter instances
-            and sub-gPCs
-        coeffs: list of list of ndarray of float [n_qoi][n_gpc][n_basis x n_out]
-            GPC coefficients of different qoi and sub-gPCs
-        res : ndarray of float [n_grid x n_out]
-            Simulation results at n_grid points of the n_out output variables
-        """
-
-        if self.options["fn_results"] is not None:
-            fn_results = os.path.splitext(self.options["fn_results"])[0]
-
-            if os.path.exists(fn_results + ".hdf5"):
-                os.remove(fn_results + ".hdf5")
-        else:
-            fn_results = None
-
-        grad_res_3D = None
-        grad_res_3D_all = None
-        gradient_idx = None
-        res_all_list = []
-
-        # make initial random grid to determine gradients and projection matrix
-        if self.grid is not None:
-            print(f"Using user-predefined grid with n_grid={self.grid.n_grid}")
-            grid = self.options["grid"](parameters_random=self.problem.parameters_random,
-                                        coords=self.grid.coords,
-                                        coords_norm=self.grid.coords_norm,
-                                        coords_gradient=self.grid.coords_gradient,
-                                        coords_gradient_norm=self.grid.coords_gradient_norm,
-                                        options=self.options["grid_options"])
-
-        elif self.options["grid"] == Random or self.options["grid"] == LHS or self.options["grid"] == GP:
-            print(f"Creating initial grid ({self.options['grid'].__name__}) with n_grid={int(self.options['n_grid'])}")
-            grid = self.options["grid"](parameters_random=self.problem.parameters_random,
-                                        n_grid=self.options["n_grid"],
-                                        options=self.options["grid_options"])
-
-        elif self.options["grid"] == L1 or self.options["grid"] == L1_LHS or self.options["grid"] == LHS_L1 \
-                or self.options["grid"] == FIM:
-            raise NotImplementedError("Grid type not possible for MEStaticProjection algorithm."
-                                      "Please use either 'Random' or 'LHS'.")
-
-        # Initialize parallel Computation class
-        com = Computation(n_cpu=self.n_cpu, matlab_model=self.options["matlab_model"])
-
-        megpc = []
-        coeffs = []
-        eps = self.options["eps"] + 1
-        i_grid = 0
-        i_qoi = 0
-
-        if self.options["qoi"] is not None and self.options["qoi"] != "all":
-            q_idx = self.options["qoi"]
-            qoi_idx = [q_idx]
-        else:
-            qoi_idx = np.arange(1)
-            q_idx = qoi_idx[0]
-
-        n_qoi = len(qoi_idx)
-
-        res_all = np.array([])
-
-        while i_qoi < n_qoi:
-            q_idx = qoi_idx[i_qoi]
-            print_str = "Determining gPC approximation for QOI #{}:".format(q_idx)
-            iprint(print_str, tab=0, verbose=self.options["verbose"])
-            iprint("=" * len(print_str), tab=0, verbose=self.options["verbose"])
-            megpc.append(0)
-            coeffs.append(0)
-
-            # Create MEGPC object
-            megpc[i_qoi] = MEGPC(problem=self.problem,
-                                 options=self.options,
-                                 validation=self.validation)
-
-            eps = self.options["eps"] + 1
-
-            # determine gpc approximation and determine error (increase grid size in case of adaptive sampling)
-            while eps > self.options["eps"]:
-                if i_grid < grid.n_grid:
-                    # run simulations
-                    iprint("Performing {} simulations!".format(grid.n_grid - i_grid),
-                           tab=0, verbose=self.options["verbose"])
-
-                    start_time = time.time()
-
-                    res_new = com.run(model=self.problem.model,
-                                      problem=self.problem,
-                                      coords=grid.coords[i_grid:grid.n_grid, :],
-                                      coords_norm=grid.coords_norm[i_grid:grid.n_grid, :],
-                                      i_iter=self.options["order_max"],
-                                      i_subiter=self.options["interaction_order"],
-                                      fn_results=None,
-                                      print_func_time=self.options["print_func_time"],
-                                      verbose=self.options["verbose"])
-
-                    if len(res_all) > 0:
-                        res_all = np.vstack(res_all, res_new)
-                    else:
-                        res_all = res_new
-
-                    if i_qoi == 0 and i_grid == 0:
-                        if self.options["qoi"] == "all":
-                            qoi_idx = np.arange(res_all.shape[1])
-                            n_qoi = len(qoi_idx)
-
-                    i_grid = grid.n_grid
-
-                    iprint('Total function evaluation: ' + str(time.time() - start_time) + ' sec',
-                           tab=0, verbose=self.options["verbose"])
-
-                    # Determine gradient [n_grid x n_out x dim]
-                    start_time = time.time()
-
-                    grad_res_3D_all, gradient_idx = get_gradient(model=self.problem.model,
-                                                                 problem=self.problem,
-                                                                 grid=grid,
-                                                                 results=res_all,
-                                                                 com=com,
-                                                                 method="FD_fwd",
-                                                                 gradient_results_present=grad_res_3D_all,
-                                                                 gradient_idx_skip=gradient_idx,
-                                                                 i_iter=self.options["order_max"],
-                                                                 i_subiter=self.options["interaction_order"],
-                                                                 print_func_time=self.options["print_func_time"],
-                                                                 dx=self.options["gradient_calculation_options"]["dx"],
-                                                                 distance_weight=
-                                                                 self.options["gradient_calculation_options"][
-                                                                     "distance_weight"],
-                                                                 verbose=self.options["verbose"])
-
-                    iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
-                           tab=0, verbose=self.options["verbose"])
-
-                    # check validity of results and resample in case the model could not be evaluated at some sampling points
-                    res_all, grad_res_3D_all, gradient_idx, grid = self.check_results(results=res_all,
-                                                                                      gradient_results=grad_res_3D_all,
-                                                                                      gradient_results_idx=gradient_idx,
-                                                                                      grid=grid,
-                                                                                      com=com)
-
-                # crop results to considered qoi
-                if self.options["qoi"] != "all":
-                    res = copy.deepcopy(res_all)
-                    grad_res_3D = copy.deepcopy(grad_res_3D_all)
-                    hdf5_subfolder = ""
-                    output_idx_passed_validation = None
-
-                else:
-                    res = res_all[:, q_idx][:, np.newaxis]
-                    grad_res_3D = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
-                    hdf5_subfolder = "/qoi_" + str(q_idx)
-                    output_idx_passed_validation = q_idx
-
-                megpc[i_qoi].grid = copy.deepcopy(grid)
-
-                # determine gpc domains
-                megpc[i_qoi].init_classifier(coords=megpc[i_qoi].grid.coords_norm,
-                                             results=res_all[:, q_idx][:, np.newaxis],
-                                             algorithm=self.options["classifier"],
-                                             options=self.options["classifier_options"])
-
-                problem_reduced = [0 for _ in range(megpc[i_qoi].n_gpc)]
-                p_matrix = [0 for _ in range(megpc[i_qoi].n_gpc)]
-                p_matrix_norm = [0 for _ in range(megpc[i_qoi].n_gpc)]
-                dim_reduced = [0 for _ in range(megpc[i_qoi].n_gpc)]
-                parameters_reduced = [OrderedDict() for _ in range(megpc[i_qoi].n_gpc)]
-                megpc[i_qoi].gpc = [0 for _ in range(megpc[i_qoi].n_gpc)]
-
-                # Determine projection matrices for sub gPCs
-                for d in np.unique(megpc[i_qoi].domains):
-                    p_matrix[d], _ = determine_projection_matrix(
-                        gradient_results=grad_res_3D_all[megpc[i_qoi].domains[gradient_idx] == d, q_idx, :],
-                        lambda_eps=self.options["lambda_eps_gradient"])
-
-                    p_matrix_norm[d] = np.sum(np.abs(p_matrix[d]), axis=1)
-                    dim_reduced[d] = p_matrix[d].shape[0]
-
-                    for i in range(dim_reduced[d]):
-                        parameters_reduced[d]["n{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
-
-                    problem_reduced[d] = Problem(model=self.problem.model, parameters=parameters_reduced[d])
-
-                    # Set up reduced gPC for this domain
-                    megpc[i_qoi].add_sub_gpc(problem=problem_reduced[d],
-                                             order=[self.options["order"][0] for _ in range(dim_reduced[d])],
-                                             order_max=self.options["order_max"],
-                                             order_max_norm=self.options["order_max_norm"],
-                                             interaction_order=self.options["interaction_order"],
-                                             interaction_order_current=self.options["interaction_order"],
-                                             options=self.options,
-                                             domain=d,
-                                             validation=None)
-
-                    # save original problem in gpc object
-                    megpc[i_qoi].gpc[d].problem_original = self.problem
-
-                    # save projection matrix in gPC object
-                    megpc[i_qoi].gpc[d].p_matrix = copy.deepcopy(p_matrix[d])
-                    megpc[i_qoi].gpc[d].p_matrix_norm = copy.deepcopy(p_matrix_norm[d])
-
-                # copy options to MEGPC object
-                megpc[i_qoi].options = copy.deepcopy(self.options)
-
-                # assign grids to sub-gPCs (rotate sub-grids in case of projection)
-                megpc[i_qoi].assign_grids(gradient_idx=gradient_idx)
-
-                # Initialize gpc matrices
-                megpc[i_qoi].init_gpc_matrices()
-
-                # Someone might not use the gradient to determine the gpc coeffs
-                if megpc[i_qoi].gradient:
-                    grad_res_3D_passed = grad_res_3D
-                else:
-                    grad_res_3D_passed = None
-
-                # Compute gpc coefficients
-                coeffs[i_qoi] = megpc[i_qoi].solve(results=res,
-                                                   gradient_results=grad_res_3D_passed,
-                                                   solver=self.options["solver"],
-                                                   settings=self.options["settings"],
-                                                   verbose=self.options["verbose"])
-
-                # validate gpc approximation (determine nrmsd or loocv specified in options["error_type"])
-                if self.options["error_type"] == "nrmsd" and megpc[0].validation is None:
-                    megpc[0].create_validation_set(n_samples=self.options["n_samples_validation"],
-                                                   n_cpu=self.options["n_cpu"])
-                elif self.options["error_type"] == "nrmsd" and megpc[0].validation is not None:
-                    megpc[i_qoi].validation = copy.deepcopy(megpc[0].validation)
-
-                eps = megpc[i_qoi].validate(coeffs=coeffs[i_qoi], results=res, gradient_results=grad_res_3D_passed)
-
-                iprint("-> {} {} error = {}".format(self.options["error_norm"],
-                                                    self.options["error_type"],
-                                                    eps), tab=0, verbose=self.options["verbose"])
-
-                # domain specific error
-                eps_domain = [0 for _ in range(len(np.unique(megpc[i_qoi].domains)))]
-                for i_gpc, d in enumerate(np.unique(megpc[i_qoi].domains)):
-                    eps_domain[d] = megpc[i_qoi].validate(coeffs=coeffs[i_qoi],
-                                                          results=res,
-                                                          domain=d,
-                                                          output_idx=output_idx_passed_validation)
-
-                if not self.options["adaptive_sampling"] or (0 < (eps_pre-eps)/eps < 0.01):
-                    break
-
-                if eps > self.options["eps"]:
-                    # extend grid by 10% of number of grid points
-                    n_grid_new = int(np.ceil(1.1*grid.n_grid))
-                    iprint("Extending grid from {} to {} by {} sampling points".format(
-                        grid.n_grid, n_grid_new, n_grid_new - grid.n_grid),
-                        tab=0, verbose=self.options["verbose"])
-                    grid.extend_random_grid(n_grid_new=n_grid_new)
-
-                eps_pre = eps
-
-            # save data
-            if self.options["fn_results"] is not None:
-
-                with h5py.File(fn_results + ".hdf5", "a") as f:
-
-                    try:
-                        fn_session = f["misc/fn_session"]
-
-                    except KeyError:
-                        f.create_dataset("misc/fn_session",
-                                         data=np.array([os.path.split(self.options["fn_session"])[1]]).astype("|S"))
-                        f.create_dataset("misc/fn_session_folder",
-                                         data=np.array([self.options["fn_session_folder"]]).astype("|S"))
-
-                    for i_gpc in range(megpc[i_qoi].n_gpc):
-                        f.create_dataset("error" + hdf5_subfolder + "/dom_" + str(i_gpc),
-                                         data=eps_domain[i_gpc],
-                                         maxshape=None, dtype="float64")
-
-                        f.create_dataset("coeffs" + hdf5_subfolder + "/dom_" + str(i_gpc),
-                                         data=coeffs[i_qoi][i_gpc],
-                                         maxshape=None, dtype="float64")
-
-                    f.create_dataset("domains" + hdf5_subfolder,
-                                     data=megpc[i_qoi].domains,
-                                     maxshape=None, dtype="int64")
-
-                    for i_gpc in range(megpc[i_qoi].n_gpc):
-                        f.create_dataset("gpc_matrix" + hdf5_subfolder + "/dom_" + str(i_gpc),
-                                         data=megpc[i_qoi].gpc[i_gpc].gpc_matrix,
-                                         maxshape=None, dtype="float64")
-
-                        if megpc[i_qoi].gpc[0].gpc_matrix_gradient is not None:
-                            if self.options["gradient_enhanced"]:
-                                f.create_dataset("gpc_matrix_gradient" + hdf5_subfolder + "/dom_" + str(i_gpc),
-                                                 data=megpc[i_qoi].gpc[i_gpc].gpc_matrix_gradient,
-                                                 maxshape=None, dtype="float64")
-
-                    for i_gpc in range(megpc[i_qoi].n_gpc):
-                        f.create_dataset("p_matrix" + hdf5_subfolder + "/dom_" + str(i_gpc),
-                                         data=megpc[i_qoi].gpc[i_gpc].p_matrix,
-                                         maxshape=None, dtype="float64")
-            i_qoi += 1
-
-        if self.options["fn_results"] is not None:
-
-            with h5py.File(fn_results + ".hdf5", "a") as f:
-
-                try:
-                    del f["grid/coords"]
-                    del f["grid/coords_norm"]
-                    del f["grid/coords_gradient"]
-                    del f["grid/coords_gradient_norm"]
-
-                except KeyError:
-                    pass
-
-                f.create_dataset("grid/coords", data=grid.coords,
-                                 maxshape=None, dtype="float64")
-                f.create_dataset("grid/coords_norm", data=grid.coords_norm,
-                                 maxshape=None, dtype="float64")
-
-                if grid.coords_gradient is not None:
-                    f.create_dataset("grid/coords_gradient",
-                                     data=grid.coords_gradient,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("grid/coords_gradient_norm",
-                                     data=grid.coords_gradient_norm,
-                                     maxshape=None, dtype="float64")
-
-                f.create_dataset("model_evaluations/results", data=res,
-                                 maxshape=None, dtype="float64")
-                if grad_res_3D is not None:
-                    f.create_dataset("model_evaluations/gradient_results", data=ten2mat(grad_res_3D),
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("model_evaluations/gradient_results_idx", data=megpc[-1].gradient_idx,
-                                     maxshape=None, dtype="int64")
-
-                f.create_dataset("misc/error_type", data=self.options["error_type"])
-
-                if megpc[0].validation is not None:
-                    f.create_dataset("validation/model_evaluations/results", data=megpc[0].validation.results,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("validation/grid/coords", data=megpc[0].validation.grid.coords,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("validation/grid/coords_norm", data=megpc[0].validation.grid.coords_norm,
-                                     maxshape=None, dtype="float64")
-
-        com.close()
-
-        return megpc, coeffs, res
-
-
-class RegAdaptive(Algorithm):
-    """
-    Adaptive regression approach based on leave one out cross validation error estimation
-
-    Parameters
-    ----------
-    problem: Problem class instance
-        GPC problem under investigation
-    options["order_start"] : int, optional, default=0
-          Initial gPC expansion order (maximum order)
-    options["order_end"] : int, optional, default=10
-        Maximum Gpc expansion order to expand to (algorithm will terminate afterwards)
-    options["interaction_order"]: int, optional, default=dim
-        Define maximum interaction order of parameters (default: all interactions)
-    options["order_max_norm"]: float
-        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
-        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
-        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
-        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
-    options["adaptive_sampling"] : boolean, optional, default: True
-        Adds samples adaptively to the expansion until the error is converged and continues by
-        adding new basis functions.
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> # initialize adaptive gPC algorithm
-    >>> algorithm = pygpc.RegAdaptive(problem=problem, options=options)
-    >>> # run algorithm
-    >>> gpc, coeffs, results = algorithm.run()
-    """
-
-    def __init__(self, problem, options, validation=None, grid=None):
-        """
-        Constructor; Initializes RegAdaptive algorithm
-        """
-        super(RegAdaptive, self).__init__(problem=problem, options=options, validation=validation, grid=grid)
-
-        self.qoi_specific = False
-
-        # check contents of settings dict and set defaults
-        if "order_start" not in self.options.keys():
-            self.options["order_start"] = 0
-
-        if "order_end" not in self.options.keys():
-            self.options["order_end"] = 10
-
-        if "interaction_order" not in self.options.keys():
-            self.options["interaction_order"] = problem.dim
-
-        if "order_max_norm" not in self.options.keys():
-            self.options["order_max_norm"] = 1.
-
-        if "adaptive_sampling" not in self.options.keys():
-            self.options["adaptive_sampling"] = True
-
-        if "basis_increment_strategy" not in self.options.keys():
-            self.options["basis_increment_strategy"] = "isotropic"
-
-    def run(self):
-        """
-        Runs adaptive gPC algorithm to solve problem.
-
-        Returns
-        -------
-        gpc : GPC object instance
-            GPC object containing all information i.e., Problem, Model, Grid, Basis, RandomParameter instances
-        coeffs: ndarray of float [n_basis x n_out]
-            GPC coefficients
-        res : ndarray of float [n_grid x n_out]
-            Simulation results at n_grid points of the n_out output variables
-        """
-
-        if self.options["fn_results"] is not None:
-            fn_results = os.path.splitext(self.options["fn_results"])[0]
-
-            if os.path.exists(fn_results + ".hdf5"):
-                os.remove(fn_results + ".hdf5")
-        else:
-            fn_results = None
-
-        # initialize iterators
-        eps = self.options["eps"] + 1.0
-        i_grid = 0
-        order = self.options["order_start"]
-        first_iter = True
-        grad_res_3D = None
-        gradient_idx = None
-        gradient_idx_FD_fwd = None
-        grad_res_3D_FD_fwd = None
-        basis_order = np.array([self.options["order_start"],
-                                min(self.options["interaction_order"], self.options["order_start"])])
-
-        # Initialize parallel Computation class
-        com = Computation(n_cpu=self.n_cpu, matlab_model=self.options["matlab_model"])
-
-        # Initialize Reg gPC object
-        print("Initializing gPC object...")
-        gpc = Reg(problem=self.problem,
-                  order=self.options["order_start"] * np.ones(self.problem.dim),
-                  order_max=self.options["order_start"],
-                  order_max_norm=self.options["order_max_norm"],
-                  interaction_order=self.options["interaction_order"],
-                  interaction_order_current=self.options["interaction_order"],
-                  options=self.options,
-                  validation=self.validation)
-        extended_basis = True
-
-        # Add a validation set if nrmsd is chosen and no validation set is yet present
-        if self.options["error_type"] == "nrmsd" and not isinstance(self.validation, ValidationSet):
-            gpc.create_validation_set(n_samples=self.options["n_samples_validation"],
-                                      n_cpu=self.options["n_cpu"])
-
-        # Initialize Grid object
-        if self.grid is not None:
-            print(f"Using user-predefined grid with n_grid={self.grid.n_grid}")
-            gpc.grid = self.options["grid"](parameters_random=self.problem.parameters_random,
-                                            coords=self.grid.coords,
-                                            coords_norm=self.grid.coords_norm,
-                                            coords_gradient=self.grid.coords_gradient,
-                                            coords_gradient_norm=self.grid.coords_gradient_norm,
-                                            options=self.options["grid_options"])
-        else:
-            n_grid_init = np.ceil(self.options["matrix_ratio"] * gpc.basis.n_basis)
-            print(f"Creating initial grid ({self.options['grid'].__name__}) with n_grid={int(n_grid_init)}")
-
-            if self.options["grid"] in [L1, L1_LHS, LHS_L1, FIM, CO]:
-                if "n_pool" in self.options["grid_options"]:
-                    if self.options["grid_options"]["n_pool"] < int(n_grid_init):
-                        warnings.warn('self.options["grid_options"]["n_pool"] < n_grid_init ... setting n_pool to 2*n_grid_init')
-                        self.options["grid_options"]["n_pool"] = 2*int(n_grid_init)
-
-                gpc.grid = self.options["grid"](parameters_random=self.problem.parameters_random,
-                                                n_grid=int(n_grid_init),
-                                                options=self.options["grid_options"],
-                                                gpc=gpc)
-
-            else:
-                gpc.grid = self.options["grid"](parameters_random=self.problem.parameters_random,
-                                                n_grid=n_grid_init,
-                                                options=self.options["grid_options"])
-
-        gpc.solver = self.options["solver"]
-        gpc.settings = self.options["settings"]
-        gpc.options = copy.deepcopy(self.options)
-
-        # Initialize gpc matrix
-        print("Initializing gPC matrix...")
-        gpc.init_gpc_matrix(gradient_idx=gradient_idx)
-        gpc.n_grid.pop(0)
-        gpc.n_basis.pop(0)
-
-        if gpc.options["gradient_enhanced"]:
-            gpc.grid.create_gradient_grid()
-
-        # Main iterations (order)
-        i_iter = 0
-        while eps > self.options["eps"]:
-
-            if first_iter:
-                basis_increment = 0
-            else:
-                basis_increment = 1
-
-            if self.options["basis_increment_strategy"] == "anisotropic":
-                if not first_iter:
-                    if np.max(np.sum(gpc.basis.multi_indices, axis=1)) >= self.options["order_end"]:
-                        break
-
-                    # determine potential polynomials which can be extended
-                    # (not enclosed by other already existing polynomials)
-                    active_non_enclosed_set, poly_indices_non_enclosed = get_non_enclosed_multi_indices(
-                        multi_indices=gpc.basis.multi_indices,
-                        interaction_order=self.options["interaction_order"])
-
-                    # get index of highest non enclosed coefficient
-                    coeff_max_idx_non_enclosed = np.argmax(np.linalg.norm(coeffs[poly_indices_non_enclosed, :], axis=1))
-
-                    # determine multi-indices to add
-                    multi_indices_to_add = poly_expand(current_set=gpc.basis.multi_indices,
-                                                       to_expand=active_non_enclosed_set[coeff_max_idx_non_enclosed],
-                                                       order_max=self.options["order_end"],
-                                                       interaction_order=self.options["interaction_order"])
-
-                    # update basis
-                    b_added = gpc.basis.add_basis_poly_by_order(multi_indices=multi_indices_to_add,
-                                                                problem=gpc.problem)
-
-                    if b_added is not None:
-                        print_str = f"Added multi-indices to basis: \n {np.matrix(multi_indices_to_add)}"
-                        iprint(print_str, tab=0, verbose=self.options["verbose"])
-                        iprint("=" * 100, tab=0, verbose=self.options["verbose"])
-                        extended_basis = True
-
-            else:
-                # increase basis isotropic
-                basis_order[0], basis_order[1] = increment_basis(order_current=basis_order[0],
-                                                                 interaction_order_current=basis_order[1],
-                                                                 interaction_order_max=self.options["interaction_order"],
-                                                                 incr=basis_increment)
-
-                if basis_order[0] > self.options["order_end"]:
-                    break
-
-                # update basis
-                b_added = gpc.basis.set_basis_poly(order=basis_order[0] * np.ones(self.problem.dim),
-                                                   order_max=basis_order[0],
-                                                   order_max_norm=self.options["order_max_norm"],
-                                                   interaction_order=self.options["interaction_order"],
-                                                   interaction_order_current=basis_order[1],
-                                                   problem=gpc.problem)
-
-                if b_added is not None:
-                    print_str = "Order/Interaction order: {}/{}".format(basis_order[0], basis_order[1])
-                    iprint(print_str, tab=0, verbose=self.options["verbose"])
-                    iprint("=" * len(print_str), tab=0, verbose=self.options["verbose"])
-                    extended_basis = True
-
-            # plot basis
-            if self.options["plot_basis"]:
-                gpc.basis.plot_basis(dims=np.arange(np.min((gpc.problem.dim, 3))),
-                                     fn_plot=self.options["fn_results"] + f"_basis_{i_iter}")
-            i_iter += 1
-
-            if self.options["adaptive_sampling"]:
-                iprint("Starting adaptive sampling:", tab=0, verbose=self.options["verbose"])
-
-            add_samples = True   # if adaptive sampling is False, the while loop will be only executed once
-            delta_eps_target = 1e-1
-            delta_eps = delta_eps_target + 1
-            delta_samples = 5e-2
-
-            while add_samples and delta_eps > delta_eps_target and eps > self.options["eps"]:
-
-                if not self.options["adaptive_sampling"]:
-                    add_samples = False
-
-                # new sample size
-                if extended_basis and self.options["adaptive_sampling"]:
-                    # do not increase sample size immediately when basis was extended, try first with old samples
-                    n_grid_new = gpc.grid.n_grid
-                elif self.options["adaptive_sampling"] and not first_iter:
-                    # increase sample size stepwise (adaptive sampling)
-                    n_grid_new = int(np.ceil(gpc.grid.n_grid + delta_samples * gpc.basis.n_basis))
-                else:
-                    # increase sample size according to matrix ratio w.r.t. number of basis functions
-                    n_grid_new = int(np.ceil(gpc.basis.n_basis * self.options["matrix_ratio"]))
-
-                # run model if grid points were added
-                if i_grid < n_grid_new or extended_basis:
-                    # extend grid
-                    if i_grid < n_grid_new:
-                        iprint("Extending grid from {} to {} by {} sampling points".format(
-                            gpc.grid.n_grid, n_grid_new, n_grid_new - gpc.grid.n_grid),
-                            tab=0, verbose=self.options["verbose"])
-
-                        if self.options["grid"] in [L1, L1_LHS, LHS_L1, FIM, CO]:
-                            if "n_pool" in self.options["grid_options"]:
-                                if self.options["grid_options"]["n_pool"] < int(n_grid_init):
-                                    warnings.warn(
-                                        'self.options["grid_options"]["n_pool"] < n_grid_new ... '
-                                        'setting n_pool to 2*n_grid_new')
-                                    self.options["grid_options"]["n_pool"] = 2 * int(n_grid_new)
-
-                        gpc.grid.extend_random_grid(n_grid_new=n_grid_new)
-
-                        # run simulations
-                        iprint("Performing simulations " + str(i_grid + 1) + " to " + str(gpc.grid.coords.shape[0]),
-                               tab=0, verbose=self.options["verbose"])
-
-                        start_time = time.time()
-
-                        res_new = com.run(model=gpc.problem.model,
-                                          problem=gpc.problem,
-                                          coords=gpc.grid.coords[int(i_grid):int(len(gpc.grid.coords))],
-                                          coords_norm=gpc.grid.coords_norm[int(i_grid):int(len(gpc.grid.coords))],
-                                          i_iter=basis_order[0],
-                                          i_subiter=basis_order[1],
-                                          fn_results=gpc.fn_results,
-                                          print_func_time=self.options["print_func_time"],
-                                          verbose=self.options["verbose"])
-
-                        iprint('Total parallel function evaluation: ' + str(time.time() - start_time) + ' sec',
-                               tab=0, verbose=self.options["verbose"])
-
-                        # Append result to solution matrix (RHS)
-                        if i_grid == 0:
-                            res = res_new
-                        else:
-                            res = np.vstack([res, res_new])
-
-                        if self.options["gradient_enhanced"]:
-                            start_time = time.time()
-
-                            grad_res_3D, gradient_idx = get_gradient(model=self.problem.model,
-                                                                     problem=self.problem,
-                                                                     grid=gpc.grid,
-                                                                     results=res,
-                                                                     com=com,
-                                                                     method=self.options["gradient_calculation"],
-                                                                     gradient_results_present=grad_res_3D_FD_fwd,
-                                                                     gradient_idx_skip=gradient_idx_FD_fwd,
-                                                                     i_iter=basis_order[0],
-                                                                     i_subiter=basis_order[1],
-                                                                     print_func_time=self.options["print_func_time"],
-                                                                     dx=self.options["gradient_calculation_options"]["dx"],
-                                                                     distance_weight=self.options["gradient_calculation_options"]["distance_weight"],
-                                                                     verbose=self.options["verbose"])
-
-                            iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
-                                   tab=0, verbose=self.options["verbose"])
-
-                        # check validity of results and resample in case the model could not be evaluated at some sampling points
-                        res, grad_res_3D, gradient_idx, gpc.grid = self.check_results(results=res,
-                                                                                      gradient_results=grad_res_3D,
-                                                                                      gradient_results_idx=gradient_idx,
-                                                                                      grid=gpc.grid,
-                                                                                      com=com)
-
-                        if self.options["gradient_enhanced"] and self.options["gradient_calculation"] == "FD_fwd":
-                            gradient_idx_FD_fwd = gradient_idx
-                            grad_res_3D_FD_fwd = grad_res_3D
-
-                        i_grid = gpc.grid.coords.shape[0]
-
-                    # update gpc matrix
-                    gpc.init_gpc_matrix(gradient_idx=gradient_idx)
-
-                    # determine gpc coefficients
-                    coeffs = gpc.solve(results=res,
-                                       gradient_results=grad_res_3D,
-                                       solver=gpc.solver,
-                                       settings=gpc.settings,
-                                       verbose=self.options["verbose"])
-
-                    # validate gpc approximation (determine nrmsd or loocv specified in options["error_type"])
-                    eps = gpc.validate(coeffs=coeffs,
-                                       results=res,
-                                       gradient_results=grad_res_3D)
-
-                    if extended_basis:
-                        eps_ref = copy.deepcopy(eps)
-                    else:
-                        delta_eps = np.abs((gpc.error[-1] - gpc.error[-2]) / eps_ref)
-
-                    iprint("-> {} {} error = {}".format(self.options["error_norm"],
-                                                        self.options["error_type"],
-                                                        eps), tab=0, verbose=self.options["verbose"])
-
-                    # extend basis further if error was decreased (except in very first iteration)
-                    if not first_iter and extended_basis and gpc.error[-1] < gpc.error[-2]:
-                        break
-
-                    extended_basis = False
-                    first_iter = False
-
-                    # exit adaptive sampling loop if no adaptive sampling was chosen
-                    if not self.options["adaptive_sampling"]:
-                        break
-
-            # save gpc coeffs for this sub-iteration
-            if self.options["fn_results"] is not None:
-
-                with h5py.File(os.path.splitext(self.options["fn_results"])[0] + ".hdf5", "a") as f:
-
-                    # overwrite coeffs
-                    if "coeffs" in f.keys():
-                        del f['coeffs']
-                    f.create_dataset("coeffs", data=coeffs, maxshape=None, dtype="float64")
-
-                    # Append gradient of results
-                    if grad_res_3D is not None:
-                        grad_res_2D = ten2mat(grad_res_3D)
-
-                        try:
-                            del f["model_evaluations/gradient_results"]
-                            del f["model_evaluations/gradient_results_idx"]
-                        except KeyError:
-                            pass
-
-                        f.create_dataset("model_evaluations/gradient_results",
-                                         (grad_res_2D.shape[0], grad_res_2D.shape[1]),
-                                         maxshape=(None, None),
-                                         dtype="float64",
-                                         data=grad_res_2D)
-
-                        f.create_dataset("model_evaluations/gradient_results_idx", data=gpc.gradient_idx,
-                                         maxshape=None, dtype="int64")
-
-                    try:
-                        del f["gpc_matrix"]
-                    except KeyError:
-                        pass
-                    f.create_dataset("gpc_matrix",
-                                     data=gpc.gpc_matrix,
-                                     maxshape=None, dtype="float64")
-
-                    if gpc.gpc_matrix_gradient is not None:
-                        try:
-                            del f["gpc_matrix_gradient"]
-                        except KeyError:
-                            pass
-                        f.create_dataset("gpc_matrix_gradient",
-                                         data=gpc.gpc_matrix_gradient,
-                                         maxshape=None, dtype="float64")
-
-        # determine gpc coefficients
-        coeffs = gpc.solve(results=res,
-                           gradient_results=grad_res_3D,
-                           solver=gpc.solver,
-                           settings=gpc.settings,
-                           verbose=self.options["verbose"])
-
-        # save gpc object and gpc coeffs
-        if self.options["fn_results"] is not None:
-
-            with h5py.File(os.path.splitext(self.options["fn_results"])[0] + ".hdf5", "a") as f:
-                if "coeffs" in f.keys():
-                    del f['coeffs']
-                f.create_dataset("coeffs", data=coeffs, maxshape=None, dtype="float64")
-
-                try:
-                    del f["gpc_matrix"]
-                except KeyError:
-                    pass
-                f.create_dataset("gpc_matrix",
-                                 data=gpc.gpc_matrix,
-                                 maxshape=None, dtype="float64")
-
-                if gpc.gpc_matrix_gradient is not None:
-                    try:
-                        del f["gpc_matrix_gradient"]
-                    except KeyError:
-                        pass
-                    f.create_dataset("gpc_matrix_gradient",
-                                     data=gpc.gpc_matrix_gradient,
-                                     maxshape=None, dtype="float64")
-
-                # misc
-                f.create_dataset("misc/fn_session",
-                                 data=np.array([os.path.split(self.options["fn_session"])[1]]).astype("|S"))
-                f.create_dataset("misc/fn_session_folder",
-                                 data=np.array([self.options["fn_session_folder"]]).astype("|S"))
-                f.create_dataset("misc/error_type", data=self.options["error_type"])
-                f.create_dataset("error", data=eps, maxshape=None, dtype="float64")
-
-                if gpc.validation is not None:
-                    f.create_dataset("validation/model_evaluations/results", data=gpc.validation.results,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("validation/grid/coords", data=gpc.validation.grid.coords,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("validation/grid/coords_norm", data=gpc.validation.grid.coords_norm,
-                                     maxshape=None, dtype="float64")
-
-                if self.options["gradient_enhanced"]:
-                    f.create_dataset("grid/coords_gradient", data=gpc.grid.coords_gradient,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("grid/coords_gradient_norm", data=gpc.grid.coords_gradient_norm,
-                                     maxshape=None, dtype="float64")
-
-        com.close()
-
-        return gpc, coeffs, res
-
-
-class MERegAdaptiveProjection(Algorithm):
-    """
-    Adaptive regression approach based on leave one out cross validation error estimation
-
-    Parameters
-    ----------
-    problem: Problem class instance
-        GPC problem under investigation
-    options["order_start"] : int, optional, default=0
-          Initial gPC expansion order (maximum order)
-    options["order_end"] : int, optional, default=10
-        Maximum Gpc expansion order to expand to (algorithm will terminate afterwards)
-    options["interaction_order"]: int, optional, default=dim
-        Define maximum interaction order of parameters (default: all interactions)
-    options["order_max_norm"]: float
-        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
-        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
-        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
-        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
-    options["adaptive_sampling"] : boolean, optional, default: True
-        Adds samples adaptively to the expansion until the error is converged and continues by
-        adding new basis functions.
-    options["n_samples_discontinuity"] : int, optional, default: 10
-        Number of grid points close to discontinuity to refine its location
-    options["n_grid_init"] : int, optional, default: 10
-        Number of initial simulations to explore the parameter space
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> # initialize adaptive gPC algorithm
-    >>> algorithm = pygpc.MERegAdaptiveProjection(problem=problem, options=options)
-    >>> # run algorithm
-    >>> gpc, coeffs, results = algorithm.run()
-    """
-
-    def __init__(self, problem, options, validation=None, grid=None):
-        """
-        Constructor; Initializes MERegAdaptiveProjection Algorithm
-        """
-        super(MERegAdaptiveProjection, self).__init__(problem=problem, options=options, validation=validation, grid=grid)
-
-        # check contents of settings dict and set defaults
-        if "order_start" not in self.options.keys():
-            self.options["order_start"] = 0
-
-        if "order_end" not in self.options.keys():
-            self.options["order_end"] = 10
-
-        if "interaction_order" not in self.options.keys():
-            self.options["interaction_order"] = problem.dim
-
-        if "order_max_norm" not in self.options.keys():
-            self.options["order_max_norm"] = 1.
-
-        if "adaptive_sampling" not in self.options.keys():
-            self.options["adaptive_sampling"] = True
-
-        if "n_samples_discontinuity" not in self.options.keys():
-            self.options["n_samples_discontinuity"] = 10
-
-        if "n_grid_init" not in self.options.keys():
-            self.options["n_grid_init"] = 10
-
-        if self.options["qoi"] == "all":
-            self.qoi_specific = True
-        else:
-            self.qoi_specific = False
-
-    def run(self):
-        """
-        Runs Multi-Element adaptive gPC algorithm to solve problem (optional projection).
-
-        Returns
-        -------
-        megpc : Multi-element GPC object instance
-            MEGPC object containing all information i.e., Problem, Model, Grid, Basis, RandomParameter instances
-        coeffs: list of ndarray of float [n_gpc][n_basis x n_out]
-            GPC coefficients
-        res : ndarray of float [n_grid x n_out]
-            Simulation results at n_grid points of the n_out output variables
-        """
-
-        if self.options["fn_results"] is not None:
-            fn_results = os.path.splitext(self.options["fn_results"])[0]
-
-            if os.path.exists(fn_results + ".hdf5"):
-                os.remove(fn_results + ".hdf5")
-        else:
-            fn_results = None
-
-        grid = self.options["grid"]
-        problem_original = copy.deepcopy(self.problem)
-
-        # initialize iterators
-        grad_res_3D = None
-        grad_res_3D_all = None
-        gradient_idx = None
-        gradient_idx_FD_fwd = None
-        basis_increment = 0
-
-        n_grid_init = self.options["n_grid_init"]
-
-        # make initial random grid to determine number of output variables and to estimate projection
-        if self.grid is not None:
-            print(f"Using user-predefined grid with n_grid={grid.n_grid}")
-            self.options["grid"](parameters_random=self.problem.parameters_random,
-                                 coords=grid.coords,
-                                 coords_norm=grid.coords_norm,
-                                 coords_gradient=grid.coords_gradient,
-                                 coords_gradient_norm=grid.coords_gradient_norm,
-                                 options=self.options["grid_options"])
-
-        elif self.options["grid"] == Random or self.options["grid"] == LHS or self.options["grid"] == GP:
-            print(f"Creating initial grid ({self.options['grid'].__name__}) with n_grid={int(n_grid_init)}")
-            grid = self.options["grid"](parameters_random=self.problem.parameters_random,
-                                        n_grid=n_grid_init,
-                                        options=self.options["grid_options"])
-
-        elif self.options["grid"] == L1 or self.options["grid"] == L1_LHS or self.options["grid"] == LHS_L1 \
-                or self.options["grid"] == FIM:
-            raise NotImplementedError("Grid type not possible for MERegAdaptiveProjection algorithm."
-                                      "Please use either 'Random', 'LHS' or 'GP'.")
-
-        # Initialize parallel Computation class
-        com = Computation(n_cpu=self.n_cpu, matlab_model=self.options["matlab_model"])
-
-        # Run initial simulations to determine initial projection matrix
-        iprint("Performing {} initial simulations!".format(grid.coords.shape[0]),
-               tab=0, verbose=self.options["verbose"])
-
-        start_time = time.time()
-
-        res_all = com.run(model=self.problem.model,
-                          problem=self.problem,
-                          coords=grid.coords,
-                          coords_norm=grid.coords_norm,
-                          i_iter=self.options["order_start"],
-                          i_subiter=self.options["interaction_order"],
-                          fn_results=self.options["fn_results"],  # + "_temp"
-                          print_func_time=self.options["print_func_time"],
-                          verbose=self.options["verbose"])
-
-        i_grid = grid.n_grid
-
-        iprint('Total function evaluation: ' + str(time.time() - start_time) + ' sec',
-               tab=0, verbose=self.options["verbose"])
-
-        if self.options["qoi"] == "all":
-            qoi_idx = np.arange(res_all.shape[1])
-            n_qoi = len(qoi_idx)
-            error = [None for _ in range(n_qoi)]
-        else:
-            qoi_idx = [self.options["qoi"]]
-            n_qoi = 1
-            error = [0]
-
-        # Determine gradient for projection [n_grid x n_out x dim]
-        if self.options["gradient_enhanced"] or self.options["projection"]:
-            if self.options["projection"] or self.options["gradient_calculation"] == "FD_fwd":
-                method = "FD_fwd"
-                dx = 1e-3
-                distance_weight = None
-            else:
-                method = self.options["gradient_calculation"]
-                dx = self.options["gradient_calculation_options"]["dx"]
-                distance_weight = self.options["gradient_calculation_options"]["distance_weight"]
-
-            start_time = time.time()
-
-            grad_res_3D_all, gradient_idx = get_gradient(model=self.problem.model,
-                                                         problem=self.problem,
-                                                         grid=grid,
-                                                         results=res_all,
-                                                         com=com,
-                                                         method=method,
-                                                         gradient_results_present=None,
-                                                         gradient_idx_skip=None,
-                                                         i_iter=self.options["order_start"],
-                                                         i_subiter=self.options["interaction_order"],
-                                                         print_func_time=self.options["print_func_time"],
-                                                         dx=dx,
-                                                         distance_weight=distance_weight,
-                                                         verbose=self.options["verbose"])
-
-            if method == "FD_fwd":
-                gradient_idx_FD_fwd = gradient_idx
-                grad_res_3D_all_FD_fwd = grad_res_3D_all
-            else:
-                gradient_idx_FD_fwd = None
-                grad_res_3D_all_FD_fwd = None
-
-            iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
-                   tab=0, verbose=self.options["verbose"])
-
-        # check validity of results and resample in case the model could not be evaluated at some sampling points
-        res_all, grad_res_3D_all, gradient_idx, grid = self.check_results(results=res_all,
-                                                                          gradient_results=grad_res_3D_all,
-                                                                          gradient_results_idx=gradient_idx,
-                                                                          grid=grid,
-                                                                          com=com)
-
-        megpc = [0 for _ in range(n_qoi)]
-        coeffs = [0 for _ in range(n_qoi)]
-
-        for i_qoi, q_idx in enumerate(qoi_idx):
-            print_str = "Determining gPC approximation for QOI #{}:".format(q_idx)
-            iprint(print_str, tab=0, verbose=self.options["verbose"])
-            iprint("=" * len(print_str), tab=0, verbose=self.options["verbose"])
-
-            first_iter = True
-
-            # crop results to considered qoi
-            if self.options["qoi"] != "all":
-                res = copy.deepcopy(res_all)
-                grad_res_3D = copy.deepcopy(grad_res_3D_all)
-                hdf5_subfolder = ""
-                output_idx_passed_validation = None
-                # the gPC is constructed for all QOI but only using info for projection etc of desired QOI
-                # validation is done for all qoi
-
-            else:
-                res = res_all[:, q_idx][:, np.newaxis]
-                hdf5_subfolder = "/qoi_" + str(q_idx)
-                output_idx_passed_validation = q_idx
-
-                if grad_res_3D_all is not None:
-                    grad_res_3D = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
-
-            # Create MEGPC object
-            megpc[i_qoi] = MEGPC(problem=self.problem,
-                                 options=self.options,
-                                 validation=self.validation)
-
-            # Write grid in gpc object
-            megpc[i_qoi].grid = copy.deepcopy(grid)
-
-            # determine gpc domains
-            iprint("Determining gPC domains ...", tab=0, verbose=self.options["verbose"])
-            megpc[i_qoi].init_classifier(coords=megpc[i_qoi].grid.coords_norm,
-                                         results=res_all[:, q_idx][:, np.newaxis],
-                                         algorithm=self.options["classifier"],
-                                         options=self.options["classifier_options"])
-
-            error[i_qoi] = [[] for _ in range(len(np.unique(megpc[i_qoi].classifier.domains)))]
-            p_matrix = [0 for _ in range(megpc[i_qoi].n_gpc)]
-            p_matrix_norm = [0 for _ in range(megpc[i_qoi].n_gpc)]
-            dim = [0 for _ in range(megpc[i_qoi].n_gpc)]
-            parameters= [OrderedDict() for _ in range(megpc[i_qoi].n_gpc)]
-            problem = [0 for _ in range(megpc[i_qoi].n_gpc)]
-            basis_order = OrderedDict()
-            n_grid_reinit = [0 for _ in range(megpc[i_qoi].n_gpc)]
-
-            # determine initial projection and initialize sub-gPCs
-            for d in np.unique(megpc[i_qoi].domains):
-
-                if self.options["projection"]:
-                    p_matrix[d], _ = determine_projection_matrix(
-                        gradient_results=grad_res_3D_all[megpc[i_qoi].domains[gradient_idx] == d, q_idx, :],
-                        lambda_eps=self.options["lambda_eps_gradient"])
-
-                    p_matrix_norm[d] = np.sum(np.abs(p_matrix[d]), axis=1)
-                    dim[d] = p_matrix[d].shape[0]
-
-                    for i in range(dim[d]):
-                        parameters[d]["n{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
-
-                    problem[d] = Problem(model=self.problem.model, parameters=parameters[d])
-
-                else:
-                    p_matrix[d] = None
-                    p_matrix_norm[d] = None
-                    dim[d] = problem_original.dim
-                    parameters[d] = problem_original.parameters_random
-                    problem[d] = copy.deepcopy(problem_original)
-
-                # Set up reduced gPC for this domain
-                megpc[i_qoi].add_sub_gpc(problem=problem[d],
-                                         order=[self.options["order_start"] for _ in range(dim[d])],
-                                         order_max=self.options["order_start"],
-                                         order_max_norm=self.options["order_max_norm"],
-                                         interaction_order=self.options["interaction_order"],
-                                         interaction_order_current=self.options["interaction_order"],
-                                         options=self.options,
-                                         domain=d,
-                                         validation=None)
-
-                # save original problem in gpc object
-                megpc[i_qoi].gpc[d].problem_original = copy.deepcopy(problem_original)
-
-                # save projection matrix in gPC object
-                megpc[i_qoi].gpc[d].p_matrix = copy.deepcopy(p_matrix[d])
-                megpc[i_qoi].gpc[d].p_matrix_norm = copy.deepcopy(p_matrix_norm[d])
-
-                # initialize dict containing approximation orders of sub-gPCs [order, interaction_order_current]
-                basis_order["poly_dom_{}".format(d)] = np.array([self.options["order_start"],
-                                                                 self.options["interaction_order"]])
-
-                # initialize solver settings
-                megpc[i_qoi].gpc[d].solver = self.options["solver"]
-                megpc[i_qoi].gpc[d].settings = self.options["settings"]
-
-                # extend initial grid and perform additional simulations if necessary
-                if not self.options["adaptive_sampling"] or megpc[i_qoi].gpc[d].solver == "Moore-Penrose":
-                    n_coeffs = get_num_coeffs_sparse(
-                        order_dim_max=[self.options["order_start"] for _ in range(dim[d])],
-                        order_glob_max=self.options["order_start"],
-                        order_inter_max=self.options["interaction_order"],
-                        order_inter_current=self.options["interaction_order"],
-                        dim=dim[d])
-
-                    n_grid_reinit[d] = n_coeffs * self.options["matrix_ratio"]
-
-                # Check if we have enough samples in this particular domain for the given order we start
-                if n_grid_reinit[d] > np.sum(megpc[i_qoi].domains == d):
-
-                    # extend random grid
-                    grid.extend_random_grid(n_grid_new=grid.n_grid - np.sum(megpc[i_qoi].domains == d) + n_grid_reinit[d],
-                                            domain=d)
-
-                    megpc[i_qoi].grid = copy.deepcopy(grid)
-
-            if grid.n_grid > i_grid:
-
-                # Run some more initial simulations
-                iprint("Performing {} more initial simulations "
-                       "to fulfil order constraint!".format(grid.n_grid - i_grid),
-                       tab=0, verbose=self.options["verbose"])
-
-                start_time = time.time()
-
-                res_new = com.run(model=self.problem.model,
-                                  problem=self.problem,
-                                  coords=grid.coords[i_grid:, ],
-                                  coords_norm=grid.coords_norm[i_grid:, ],
-                                  i_iter=None,
-                                  i_subiter=None,
-                                  fn_results=self.options["fn_results"],
-                                  print_func_time=self.options["print_func_time"],
-                                  verbose=self.options["verbose"])
-
-                # add results to results array
-                res_all = np.vstack((res_all, res_new))
-                i_grid = grid.n_grid
-
-                iprint('Total function evaluation: ' + str(time.time() - start_time) + ' sec',
-                       tab=0, verbose=self.options["verbose"])
-
-                # Determine gradient [n_grid x n_out x dim]
-                if self.options["gradient_enhanced"] or self.options["projection"]:
-                    if self.options["projection"] or self.options["gradient_calculation"] == "FD_fwd":
-                        method = "FD_fwd"
-                        dx = 1e-3
-                        distance_weight = None
-                    else:
-                        method = self.options["gradient_calculation"]
-                        dx = self.options["gradient_calculation_options"]["dx"]
-                        distance_weight = self.options["gradient_calculation_options"]["distance_weight"]
-
-                    start_time = time.time()
-
-                    grad_res_3D_all, gradient_idx = get_gradient(model=self.problem.model,
-                                                                 problem=self.problem,
-                                                                 grid=grid,
-                                                                 results=res_all,
-                                                                 com=com,
-                                                                 method=method,
-                                                                 gradient_results_present=grad_res_3D_all_FD_fwd,
-                                                                 gradient_idx_skip=gradient_idx_FD_fwd,
-                                                                 i_iter=None,
-                                                                 i_subiter=None,
-                                                                 print_func_time=self.options["print_func_time"],
-                                                                 dx=dx,
-                                                                 distance_weight=distance_weight,
-                                                                 verbose=self.options["verbose"])
-
-                    if method == "FD_fwd":
-                        gradient_idx_FD_fwd = gradient_idx
-                        grad_res_3D_all_FD_fwd = grad_res_3D_all
-                    else:
-                        gradient_idx_FD_fwd = None
-                        grad_res_3D_all_FD_fwd = None
-
-                    iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
-                           tab=0, verbose=self.options["verbose"])
-
-                # check validity of results and resample in case the model could not be evaluated at some sampling points
-                res_all, grad_res_3D_all, gradient_idx, grid = self.check_results(results=res_all,
-                                                                                  gradient_results=grad_res_3D_all,
-                                                                                  gradient_results_idx=gradient_idx,
-                                                                                  grid=grid,
-                                                                                  com=com)
-
-                megpc[i_qoi].grid = copy.deepcopy(grid)
-
-                # update classifier
-                iprint("Updating classifier ...", tab=0, verbose=self.options["verbose"])
-                megpc[i_qoi].update_classifier(coords=megpc[i_qoi].grid.coords_norm,
-                                               results=res_all[:, q_idx][:, np.newaxis])
-
-            # create validation set if necessary
-            if self.options["error_type"] == "nrmsd" and megpc[0].validation is None:
-                iprint("Determining validation set of size {} "
-                       "for NRMSD error calculation ...".format(int(self.options["n_samples_validation"])),
-                       tab=0, verbose=self.options["verbose"])
-                megpc[0].create_validation_set(n_samples=self.options["n_samples_validation"],
-                                               n_cpu=self.options["n_cpu"],
-                                               gradient=self.options["gradient_enhanced"])
-
-            elif self.options["error_type"] == "nrmsd" and megpc[0].validation is not None:
-                megpc[i_qoi].validation = copy.deepcopy(megpc[0].validation)
-
-            extended_basis = True
-
-            # initialize domain specific error
-            eps = np.array([self.options["eps"] + 1.0 for _ in range(megpc[i_qoi].n_gpc)])
-
-            # Main iterations (order)
-            while (eps > self.options["eps"]).any():
-
-                stop_by_order = [(basis_order["poly_dom_{}".format(i)] == [self.options["order_end"],
-                                                                           self.options["interaction_order"]]).all() for
-                                 i in range(megpc[i_qoi].n_gpc)]
-                stop_by_error = eps < self.options["eps"]
-
-                # print("stop_by_order: {}".format(stop_by_order))
-                # print("stop_by_error: {}".format(stop_by_error))
-                # print("eps: {}".format(eps))
-
-                # TODO: ValueError: operands could not be broadcast together with shapes (2,) (3,)
-                if np.logical_or(stop_by_order, stop_by_error).all():
-                    break
-
-                iprint("Refining domain boundary ...", tab=0, verbose=self.options["verbose"])
-
-                # determine grid points close to discontinuity
-                coords_norm_disc = get_coords_discontinuity(classifier=megpc[i_qoi].classifier,
-                                                            x_min=[-1 for _ in range(megpc[i_qoi].problem.dim)],
-                                                            x_max=[+1 for _ in range(megpc[i_qoi].problem.dim)],
-                                                            n_coords_disc=self.options["n_samples_discontinuity"],
-                                                            border_sampling="structured")
-
-                coords_disc = grid.get_denormalized_coordinates(coords_norm_disc)
-
-                # add grid points close to discontinuity to global grid
-                grid.extend_random_grid(coords=coords_disc,
-                                        coords_norm=coords_norm_disc,
-                                        gradient=self.options["gradient_enhanced"])
-
-                # run simulations close to discontinuity
-                iprint("Performing {} simulations to refine discontinuity location!".format(
-                    self.options["n_samples_discontinuity"]), tab=0, verbose=self.options["verbose"])
-
-                start_time = time.time()
-
-                res_disc = com.run(model=self.problem.model,
-                                   problem=self.problem,
-                                   coords=coords_disc,
-                                   coords_norm=coords_norm_disc,
-                                   i_iter="Domain boundary",
-                                   i_subiter=None,
-                                   fn_results=self.options["fn_results"],
-                                   print_func_time=self.options["print_func_time"],
-                                   verbose=self.options["verbose"])
-
-                iprint('Total function evaluation: ' + str(time.time() - start_time) + ' sec',
-                       tab=0, verbose=self.options["verbose"])
-
-                # add results to results array
-                res_all = np.vstack((res_all, res_disc))
-
-                # Determine gradient [n_grid x n_out x dim]
-                if self.options["gradient_enhanced"] or self.options["projection"]:
-                    start_time = time.time()
-
-                    grad_res_3D_all, gradient_idx = get_gradient(model=self.problem.model,
-                                                                 problem=self.problem,
-                                                                 grid=grid,
-                                                                 results=res_all,
-                                                                 com=com,
-                                                                 method=self.options["gradient_calculation"],
-                                                                 gradient_results_present=grad_res_3D_all_FD_fwd,
-                                                                 gradient_idx_skip=gradient_idx_FD_fwd,
-                                                                 i_iter="Domain boundary",
-                                                                 i_subiter=None,
-                                                                 print_func_time=self.options["print_func_time"],
-                                                                 dx=self.options["gradient_calculation_options"]["dx"],
-                                                                 distance_weight=self.options["gradient_calculation_options"]["distance_weight"],
-                                                                 verbose=self.options["verbose"])
-
-                    if self.options["gradient_calculation"] == "FD_fwd":
-                        gradient_idx_FD_fwd = gradient_idx
-                        grad_res_3D_all_FD_fwd = grad_res_3D_all
-
-                    iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
-                           tab=0, verbose=self.options["verbose"])
-
-                # check validity of results and resample in case the model could not be evaluated at some sampling points
-                res_all, grad_res_3D_all, gradient_idx, grid = self.check_results(results=res_all,
-                                                                                  gradient_results=grad_res_3D_all,
-                                                                                  gradient_results_idx=gradient_idx,
-                                                                                  grid=grid,
-                                                                                  com=com)
-
-                i_grid = grid.n_grid
-
-                # crop results to considered qoi
-                if self.options["qoi"] != "all":
-                    res = copy.deepcopy(res_all)
-                    grad_res_3D = copy.deepcopy(grad_res_3D_all)
-
-                else:
-                    res = res_all[:, q_idx][:, np.newaxis]
-
-                    if grad_res_3D_all is not None:
-                        grad_res_3D = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
-
-                # Write grid in gpc object
-                megpc[i_qoi].grid = copy.deepcopy(grid)
-
-                # update classifier
-                iprint("Updating classifier ...", tab=0, verbose=self.options["verbose"])
-                megpc[i_qoi].update_classifier(coords=megpc[i_qoi].grid.coords_norm,
-                                               results=res_all[:, q_idx][:, np.newaxis])
-
-                # update sub-gPCs if number of domains changed
-                if len(np.unique(megpc[i_qoi].domains)) != len(megpc[i_qoi].gpc):
-
-                    iprint("New domains found! Updating number of sub-gPCs from {} to {} ".
-                           format(len(megpc[i_qoi].gpc), len(np.unique(megpc[i_qoi].domains))),
-                           tab=0, verbose=self.options["verbose"])
-
-                    megpc[i_qoi].gpc = None
-
-                    megpc[i_qoi].init_classifier(coords=megpc[i_qoi].grid.coords_norm,
-                                                 results=res_all[:, q_idx][:, np.newaxis],
-                                                 algorithm=self.options["classifier"],
-                                                 options=self.options["classifier_options"])
-
-                    basis_order["poly_dom_{}".format(d)][0] = self.options["order_start"]
-                    basis_order["poly_dom_{}".format(d)][1] = self.options["interaction_order"]
-
-                    # eps = np.hstack((eps, np.array(self.options["eps"] + 1)))
-                    eps = np.array([self.options["eps"] + 1.0 for _ in range(len(np.unique(megpc[i_qoi].domains)))])
-
-                    for i_gpc, d in enumerate(np.unique(megpc[i_qoi].domains)):
-                        megpc[i_qoi].add_sub_gpc(problem=problem_original,
-                                                 order=basis_order["poly_dom_{}".format(d)][0] * np.ones(
-                                                     self.problem.dim),
-                                                 order_max=self.options["order_start"],
-                                                 order_max_norm=self.options["order_max_norm"],
-                                                 interaction_order=self.options["interaction_order"],
-                                                 interaction_order_current=basis_order["poly_dom_{}".format(d)][1],
-                                                 options=self.options,
-                                                 domain=d,
-                                                 validation=None)
-
-                        # save original problem in gpc object
-                        megpc[i_qoi].gpc[d].problem_original = copy.deepcopy(problem_original)
-
-                        # initialize domain specific interaction order and other settings
-                        megpc[i_qoi].gpc[i_gpc].solver = self.options["solver"]
-                        megpc[i_qoi].gpc[i_gpc].settings = self.options["settings"]
-
-                # update projection matrices
-                if self.options["projection"]:
-                    p_matrix = [0 for _ in range(megpc[i_qoi].n_gpc)]
-                    p_matrix_norm = [0 for _ in range(megpc[i_qoi].n_gpc)]
-                    dim = [0 for _ in range(megpc[i_qoi].n_gpc)]
-                    parameters = [OrderedDict() for _ in range(megpc[i_qoi].n_gpc)]
-                    problem = [0 for _ in range(megpc[i_qoi].n_gpc)]
-
-                    for d in np.unique(megpc[i_qoi].domains):
-                        p_matrix[d], _ = determine_projection_matrix(
-                            gradient_results=grad_res_3D_all[megpc[i_qoi].domains[gradient_idx] == d, q_idx, :],
-                            lambda_eps=self.options["lambda_eps_gradient"])
-
-                        p_matrix_norm[d] = np.sum(np.abs(p_matrix[d]), axis=1)
-                        dim[d] = p_matrix[d].shape[0]
-
-                        for i in range(dim[d]):
-                            parameters[d]["n{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
-
-                        problem[d] = Problem(model=self.problem.model, parameters=parameters[d])
-
-                        # replace sub-gpc with the one containing the reduced problem
-                        megpc[i_qoi].add_sub_gpc(problem=problem[d],
-                                                 order=basis_order["poly_dom_{}".format(d)][0] * np.ones(dim[d]),
-                                                 order_max=self.options["order_start"],
-                                                 order_max_norm=self.options["order_max_norm"],
-                                                 interaction_order=self.options["interaction_order"],
-                                                 interaction_order_current=basis_order["poly_dom_{}".format(d)][1],
-                                                 options=self.options,
-                                                 domain=d,
-                                                 validation=None)
-
-                        # save original problem in gpc object
-                        megpc[i_qoi].gpc[d].problem_original = copy.deepcopy(problem_original)
-
-                        # save projection matrix in gPC object
-                        megpc[i_qoi].gpc[d].p_matrix = copy.deepcopy(p_matrix[d])
-                        megpc[i_qoi].gpc[d].p_matrix_norm = copy.deepcopy(p_matrix_norm[d])
-
-                        # initialize domain specific interaction order and other settings
-                        megpc[i_qoi].gpc[d].solver = self.options["solver"]
-                        megpc[i_qoi].gpc[d].settings = self.options["settings"]
-
-                # update gpc approximation with new grid points close to discontinuity
-                # assign grids to sub-gPCs (rotate sub-grids in case of projection)
-                megpc[i_qoi].assign_grids(gradient_idx=gradient_idx)
-
-                # Initialize gpc matrices
-                megpc[i_qoi].init_gpc_matrices()
-
-                # Compute gpc coefficients
-                if self.options["gradient_enhanced"]:
-                    grad_res_3D_passed = grad_res_3D
-                else:
-                    grad_res_3D_passed = None
-
-                coeffs[i_qoi] = megpc[i_qoi].solve(results=res,
-                                                   gradient_results=grad_res_3D_passed,
-                                                   solver=self.options["solver"],
-                                                   settings=self.options["settings"],
-                                                   verbose=self.options["verbose"])
-
-                # domain specific error
-                for i_gpc, d in enumerate(np.unique(megpc[i_qoi].domains)):
-                    eps[d] = megpc[i_qoi].validate(coeffs=coeffs[i_qoi],
-                                                   results=res,
-                                                   domain=d,
-                                                   output_idx=output_idx_passed_validation)
-                    error[i_qoi][d].append(eps[d])
-
-                    iprint("-> Domain: {} {} {} "
-                           "error = {}".format(d,
-                                               self.options["error_norm"],
-                                               self.options["error_type"],
-                                               eps[d]), tab=0, verbose=self.options["verbose"])
-
-                # loop over domains and increase order if necessary
-                for i_gpc, d in enumerate(np.unique(megpc[i_qoi].domains)):
-
-                    skip = (basis_order["poly_dom_{}".format(d)] ==
-                            [self.options["order_end"], self.options["interaction_order"]]).all()
-
-                    if (eps[d] > self.options["eps"]) and not skip:
-
-                        # increase basis by 1 interaction order
-                        order_new = increment_basis(order_current=basis_order["poly_dom_{}".format(d)][0],
-                                                    interaction_order_current=basis_order["poly_dom_{}".format(d)][1],
-                                                    interaction_order_max=self.options["interaction_order"],
-                                                    incr=basis_increment)
-
-                        basis_order["poly_dom_{}".format(d)][0] = order_new[0]
-                        basis_order["poly_dom_{}".format(d)][1] = order_new[1]
-
-                        print_str = "Domain: {}, Order: #{}, Sub-iteration: #{}".format(
-                            d,
-                            basis_order["poly_dom_{}".format(d)][0],
-                            basis_order["poly_dom_{}".format(d)][1])
-
-                        iprint(print_str, tab=0, verbose=self.options["verbose"])
-                        iprint("=" * len(print_str), tab=0, verbose=self.options["verbose"])
-
-                        # update basis
-                        b_added = megpc[i_qoi].gpc[d].basis.set_basis_poly(
-                            order=basis_order["poly_dom_{}".format(d)][0] * np.ones(dim[d]),
-                            order_max=basis_order["poly_dom_{}".format(d)][0],
-                            order_max_norm=self.options["order_max_norm"],
-                            interaction_order=self.options["interaction_order"],
-                            interaction_order_current=basis_order["poly_dom_{}".format(d)][1],
-                            problem=problem[d])
-
-                        # continue algorithm if no basis function was added because of max norm constraint
-                        if b_added is not None:
-                            extended_basis = True
-                        else:
-                            extended_basis = False
-                            # iprint("-> Domain: {} {} {} "
-                            #        "error = {}".format(d,
-                            #                            self.options["error_norm"],
-                            #                            self.options["error_type"],
-                            #                            eps[d]), tab=0, verbose=self.options["verbose"])
-                            # iprint("-> No basis functions to add in domain {} ... Continuing ... ".format(d),
-                            #        tab=0, verbose=self.options["verbose"])
-                            continue
-
-                        # update gpc matrix
-                        gradient_idx_gpc = get_gradient_idx_domain(domains=megpc[i_qoi].domains,
-                                                                   d=d,
-                                                                   gradient_idx=megpc[i_qoi].gradient_idx)
-
-                        megpc[i_qoi].gpc[d].init_gpc_matrix(gradient_idx=gradient_idx_gpc)
-
-                        # determine gpc coefficients with new basis but old samples
-                        if self.options["gradient_enhanced"]:
-                            grad_res_3D_passed = grad_res_3D[megpc[i_qoi].domains[gradient_idx] == d, :, :]
-                        else:
-                            grad_res_3D_passed = None
-
-                        coeffs[i_qoi][d] = megpc[i_qoi].gpc[d].solve(results=res[megpc[i_qoi].domains == d, ],
-                                                                     gradient_results=grad_res_3D_passed,
-                                                                     solver=megpc[i_qoi].gpc[d].solver,
-                                                                     settings=megpc[i_qoi].gpc[d].settings,
-                                                                     verbose=self.options["verbose"])
-
-                        # Add samples
-                        add_samples = True  # if adaptive sampling is False, the loop will be only executed once
-                        delta_eps_target = 1e-1
-                        delta_eps = delta_eps_target + 1
-                        delta_samples = 4*5e-2
-
-                        if self.options["adaptive_sampling"]:
-                            iprint("Starting adaptive sampling:", tab=0, verbose=self.options["verbose"])
-
-                        # only increase samples if error increased and until error converges again
-                        while add_samples and delta_eps > delta_eps_target and eps[d] > self.options["eps"]:
-
-                            if not self.options["adaptive_sampling"]:
-                                add_samples = False
-
-                            # new sample size
-                            if extended_basis and self.options["adaptive_sampling"]:
-                                # do not increase sample size immediately when basis was extended
-                                # try first with old samples
-                                n_grid_new = megpc[i_qoi].gpc[d].grid.n_grid
-                            elif self.options["adaptive_sampling"] and not first_iter:
-                                # increase sample size stepwise (adaptive sampling)
-                                n_grid_new = int(np.ceil(megpc[i_qoi].gpc[d].grid.n_grid +
-                                                         delta_samples * megpc[i_qoi].gpc[d].basis.n_basis))
-                            else:
-                                # increase sample size according to matrix ratio w.r.t. number of basis functions
-                                n_grid_new = int(
-                                    np.ceil(megpc[i_qoi].gpc[d].basis.n_basis * self.options["matrix_ratio"]))
-
-                            # run model if grid points were added
-                            if megpc[i_qoi].gpc[d].grid.n_grid < n_grid_new or extended_basis:
-                                # extend grid
-                                if megpc[i_qoi].gpc[d].grid.n_grid < n_grid_new:
-                                    iprint("Extending grid in domain {} from {} to {} by {} sampling points "
-                                           "(global grid: {})".format(d, megpc[i_qoi].gpc[d].grid.n_grid, n_grid_new,
-                                                                      n_grid_new - megpc[i_qoi].gpc[d].grid.n_grid,
-                                                                      megpc[i_qoi].grid.n_grid),
-                                           tab=0, verbose=self.options["verbose"])
-
-                                    # add grid points in this domain to global grid
-                                    grid.extend_random_grid(
-                                        n_grid_new=grid.n_grid - megpc[i_qoi].gpc[d].grid.n_grid + n_grid_new,
-                                        classifier=megpc[i_qoi].classifier,
-                                        domain=d,
-                                        gradient=self.options["gradient_enhanced"])
-
-                                    # run simulations
-                                    iprint("Performing simulations {} to {}".format(
-                                        i_grid + 1, grid.coords.shape[0]),
-                                        tab=0, verbose=self.options["verbose"])
-
-                                    start_time = time.time()
-
-                                    res_new = com.run(model=self.problem.model,
-                                                      problem=self.problem,
-                                                      coords=grid.coords[int(i_grid):, :],
-                                                      coords_norm=grid.coords_norm[int(i_grid):, :],
-                                                      i_iter=basis_order["poly_dom_{}".format(d)][0],
-                                                      i_subiter=basis_order["poly_dom_{}".format(d)][1],
-                                                      fn_results=self.options["fn_results"],
-                                                      print_func_time=self.options["print_func_time"],
-                                                      verbose=self.options["verbose"])
-
-                                    iprint('Total parallel function evaluation {} sec'.format(
-                                        str(time.time() - start_time)),
-                                        tab=0, verbose=self.options["verbose"])
-
-                                    # append to results array containing all qoi
-                                    res_all = np.vstack([res_all, res_new])
-
-                                    if self.options["gradient_enhanced"] or self.options["projection"]:
-                                        start_time = time.time()
-
-                                        grad_res_3D_all, gradient_idx = get_gradient(model=self.problem.model,
-                                                                                     problem=self.problem,
-                                                                                     grid=grid,
-                                                                                     results=res_all,
-                                                                                     com=com,
-                                                                                     method=self.options["gradient_calculation"],
-                                                                                     gradient_results_present=grad_res_3D_all_FD_fwd,
-                                                                                     gradient_idx_skip=gradient_idx_FD_fwd,
-                                                                                     i_iter=basis_order["poly_dom_{}".format(d)][0],
-                                                                                     i_subiter=basis_order["poly_dom_{}".format(d)][1],
-                                                                                     print_func_time=self.options["print_func_time"],
-                                                                                     dx=self.options["gradient_calculation_options"]["dx"],
-                                                                                     distance_weight=self.options["gradient_calculation_options"]["distance_weight"],
-                                                                                     verbose=self.options["verbose"])
-
-                                        if self.options["gradient_calculation"] == "FD_fwd":
-                                            gradient_idx_FD_fwd = gradient_idx
-                                            grad_res_3D_all_FD_fwd = grad_res_3D_all
-
-                                        iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
-                                               tab=0, verbose=self.options["verbose"])
-
-                                    # check validity of results and resample in case the model could not be evaluated at some sampling points
-                                    res_all, grad_res_3D_all, gradient_idx, grid = self.check_results(
-                                        results=res_all,
-                                        gradient_results=grad_res_3D_all,
-                                        gradient_results_idx=gradient_idx,
-                                        grid=grid,
-                                        com=com)
-
-                                    # crop results to considered qoi
-                                    if self.options["qoi"] != "all":
-                                        res = copy.deepcopy(res_all)
-                                        grad_res_3D = copy.deepcopy(grad_res_3D_all)
-
-                                    else:
-                                        res = res_all[:, q_idx][:, np.newaxis]
-
-                                        if grad_res_3D_all is not None:
-                                            grad_res_3D = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
-
-                                    i_grid = grid.coords.shape[0]
-
-                                    # update classifier
-                                    iprint("Updating classifier ...", tab=0, verbose=self.options["verbose"])
-                                    megpc[i_qoi].update_classifier(coords=grid.coords_norm,
-                                                                   results=res_all[:, q_idx][:, np.newaxis])
-
-                                    # TODO: the number of sub-gpcs could change here :/
-                                    # update projection matrices
-                                    if self.options["projection"]:
-
-                                        for dd in np.unique(megpc[i_qoi].domains):
-
-                                            p_matrix[dd], _ = determine_projection_matrix(
-                                                gradient_results=grad_res_3D_all[megpc[i_qoi].domains[gradient_idx] ==
-                                                                                 dd, q_idx, :],
-                                                lambda_eps=self.options["lambda_eps_gradient"])
-
-                                            p_matrix_norm[dd] = np.sum(np.abs(p_matrix[dd]), axis=1)
-                                            dim[dd] = p_matrix[dd].shape[0]
-
-                                            for i in range(dim[d]):
-                                                parameters[d]["n{}".format(i)] = Beta(pdf_shape=[1., 1.],
-                                                                                      pdf_limits=[-1., 1.])
-
-                                            problem[d] = Problem(model=self.problem.model, parameters=parameters[d])
-
-                                            # replace sub-gpc with the one containing the reduced problem
-                                            megpc[i_qoi].add_sub_gpc(problem=problem[d],
-                                                                     order=basis_order["poly_dom_{}".format(d)][
-                                                                               0] * np.ones(dim[d]),
-                                                                     order_max=self.options["order_start"],
-                                                                     order_max_norm=self.options["order_max_norm"],
-                                                                     interaction_order=self.options[
-                                                                         "interaction_order"],
-                                                                     interaction_order_current=
-                                                                     basis_order["poly_dom_{}".format(d)][1],
-                                                                     options=self.options,
-                                                                     domain=d,
-                                                                     validation=None)
-
-                                            # save original problem in gpc object
-                                            megpc[i_qoi].gpc[d].problem_original = copy.deepcopy(problem_original)
-
-                                            # save projection matrix in gPC object
-                                            megpc[i_qoi].gpc[d].p_matrix = copy.deepcopy(p_matrix[d])
-                                            megpc[i_qoi].gpc[d].p_matrix_norm = copy.deepcopy(p_matrix_norm[d])
-
-                                            # initialize domain specific interaction order and other settings
-                                            megpc[i_qoi].gpc[d].solver = self.options["solver"]
-                                            megpc[i_qoi].gpc[d].settings = self.options["settings"]
-
-                                    # update and assign grids
-                                    megpc[i_qoi].grid = copy.deepcopy(grid)
-
-                                    # assign grids to sub-gPCs (rotate sub-grids in case of projection)
-                                    megpc[i_qoi].assign_grids(gradient_idx=gradient_idx)
-
-                                    # update gpc matrix
-                                    gradient_idx_gpc = get_gradient_idx_domain(domains=megpc[i_qoi].domains,
-                                                                               d=d,
-                                                                               gradient_idx=megpc[i_qoi].gradient_idx)
-
-                                    megpc[i_qoi].gpc[d].init_gpc_matrix(gradient_idx=gradient_idx_gpc)
-
-                                    # determine gpc coefficients
-                                    if self.options["gradient_enhanced"]:
-                                        grad_res_3D_passed = grad_res_3D[megpc[i_qoi].domains[gradient_idx] == d, :, :]
-                                    else:
-                                        grad_res_3D_passed = None
-
-                                    coeffs[i_qoi][d] = megpc[i_qoi].gpc[d].solve(
-                                        results=res[megpc[i_qoi].domains == d, ],
-                                        gradient_results=grad_res_3D_passed,
-                                        solver=megpc[i_qoi].gpc[d].solver,
-                                        settings=megpc[i_qoi].gpc[d].settings,
-                                        verbose=self.options["verbose"])
-
-                                # validate gpc approximation
-                                eps[d] = megpc[i_qoi].validate(coeffs=coeffs[i_qoi],
-                                                               results=res,
-                                                               domain=d,
-                                                               output_idx=output_idx_passed_validation)
-                                error[i_qoi][d].append(eps[d])
-
-                                if extended_basis or first_iter:
-                                    eps_ref = copy.deepcopy(eps[d])
-                                else:
-                                    delta_eps = np.abs((error[i_qoi][d][-1] -
-                                                        error[i_qoi][d][-2]) / eps_ref)
-
-                                first_iter = False
-
-                                iprint("-> Domain: {} {} {} "
-                                       "error = {}".format(d,
-                                                           self.options["error_norm"],
-                                                           self.options["error_type"],
-                                                           eps[d]), tab=0, verbose=self.options["verbose"])
-
-                                # stop adaptive sampling and extend basis further if error
-                                # was decreased (except in very first iteration)
-                                if extended_basis and error[i_qoi][d][-1] < error[i_qoi][d][-2]:
-                                    break
-
-                                extended_basis = False
-
-                                # exit adaptive sampling loop if no adaptive sampling was chosen
-                                if not self.options["adaptive_sampling"]:
-                                    break
-
-                    # save gpc object and coeffs for this sub-iteration
-                    if self.options["fn_results"] is not None:
-
-                        with h5py.File(os.path.splitext(self.options["fn_results"])[0] + ".hdf5", "a") as f:
-
-                            # overwrite coeffs
-                            try:
-                                del f["coeffs" + hdf5_subfolder + "/dom_" + str(d)]
-                            except KeyError:
-                                pass
-
-                            f.create_dataset("coeffs" + hdf5_subfolder + "/dom_" + str(d),
-                                             data=coeffs[i_qoi][d], maxshape=None, dtype="float64")
-
-                            # overwrite domains
-                            try:
-                                del f["domains" + hdf5_subfolder]
-                            except KeyError:
-                                pass
-                            f.create_dataset("domains" + hdf5_subfolder,
-                                             data=megpc[i_qoi].domains, maxshape=None, dtype="int64")
-
-                            # save gpc matrix
-                            try:
-                                del f["gpc_matrix" + hdf5_subfolder + "/dom_" + str(d)]
-                            except KeyError:
-                                pass
-                            f.create_dataset("gpc_matrix" + hdf5_subfolder + "/dom_" + str(d),
-                                             data=megpc[i_qoi].gpc[d].gpc_matrix,
-                                             maxshape=None, dtype="float64")
-
-                            if megpc[i_qoi].gpc[d].p_matrix is not None:
-                                try:
-                                    del f["p_matrix" + hdf5_subfolder + "/dom_" + str(d)]
-                                except KeyError:
-                                    pass
-                                f.create_dataset("p_matrix" + hdf5_subfolder + "/dom_" + str(d),
-                                                 data=megpc[i_qoi].gpc[d].p_matrix,
-                                                 maxshape=None, dtype="float64")
-
-                            # save gradient gpc matrix
-                            if megpc[i_qoi].gpc[0].gpc_matrix_gradient is not None:
-                                try:
-                                    del f["gpc_matrix_gradient" + hdf5_subfolder + "/dom_" + str(d)]
-                                except KeyError:
-                                    pass
-                                if self.options["gradient_enhanced"]:
-                                    f.create_dataset("gpc_matrix_gradient" + hdf5_subfolder + "/dom_" + str(d),
-                                                     data=megpc[i_qoi].gpc[d].gpc_matrix_gradient,
-                                                     maxshape=None, dtype="float64")
-
-                            # save results
-                            try:
-                                del f["model_evaluations/results"]
-                            except KeyError:
-                                pass
-
-                            f.create_dataset("model_evaluations/results",
-                                             (res_all.shape[0], res_all.shape[1]),
-                                             maxshape=(None, None),
-                                             dtype="float64",
-                                             data=res_all)
-
-                            # save gradient of results
-                            if grad_res_3D is not None:
-
-                                try:
-                                    del f["model_evaluations/gradient_results"]
-                                    del f["model_evaluations/gradient_results_idx"]
-                                except KeyError:
-                                    pass
-
-                                grad_res_2D_all = ten2mat(grad_res_3D_all)
-                                f.create_dataset("model_evaluations/gradient_results",
-                                                 (grad_res_2D_all.shape[0], grad_res_2D_all.shape[1]),
-                                                 maxshape=(None, None),
-                                                 dtype="float64",
-                                                 data=grad_res_2D_all)
-
-                                f.create_dataset("model_evaluations/gradient_results_idx",
-                                                 dtype="int64",
-                                                 data=gradient_idx)
-
-                            try:
-                                del f["error" + hdf5_subfolder + "/dom_" + str(d)]
-                            except KeyError:
-                                pass
-                            f.create_dataset("error" + hdf5_subfolder + "/dom_" + str(d),
-                                             data=eps[d],
-                                             maxshape=None, dtype="float64")
-
-                basis_increment = 1
-
-            megpc[i_qoi].update_classifier(coords=megpc[i_qoi].grid.coords_norm,
-                                           results=res_all[:, q_idx][:, np.newaxis])
-
-            megpc[i_qoi].assign_grids(gradient_idx=gradient_idx)
-            megpc[i_qoi].init_gpc_matrices()
-
-            # determine gpc coefficients
-            #
-            #     grad_res_3D_passed = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
-            # else:
-            #     grad_res_3D_passed = None
-
-            # crop results to considered qoi
-            if self.options["qoi"] != "all":
-                res = copy.deepcopy(res_all)
-                grad_res_3D_passed = copy.deepcopy(grad_res_3D_all)
-
-            else:
-                res = res_all[:, q_idx][:, np.newaxis]
-                if grad_res_3D_all is not None:
-                    grad_res_3D_passed = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
-
-            if not self.options["gradient_enhanced"]:
-                grad_res_3D_passed = None
-
-            # determine gpc coefficients
-            coeffs[i_qoi] = megpc[i_qoi].solve(results=res,
-                                               gradient_results=grad_res_3D_passed,
-                                               solver=megpc[i_qoi].gpc[d].solver,
-                                               settings=megpc[i_qoi].gpc[d].settings,
-                                               verbose=self.options["verbose"])
-            megpc[i_qoi].error = error[i_qoi]
-
-            # save gpc object and gpc coeffs
-            if self.options["fn_results"] is not None:
-
-                with h5py.File(os.path.splitext(self.options["fn_results"])[0] + ".hdf5", "a") as f:
-
-                    try:
-                        fn_session = f["misc/fn_session"]
-
-                    except KeyError:
-                        f.create_dataset("misc/fn_session",
-                                         data=np.array([os.path.split(self.options["fn_session"])[1]]).astype("|S"))
-                        f.create_dataset("misc/fn_session_folder",
-                                         data=np.array([self.options["fn_session_folder"]]).astype("|S"))
-
-                    try:
-                        del f["grid"]
-                    except KeyError:
-                        pass
-
-                    f.create_dataset("grid/coords", data=grid.coords,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("grid/coords_norm", data=grid.coords_norm,
-                                     maxshape=None, dtype="float64")
-
-                    if megpc[i_qoi].grid.coords_gradient is not None:
-                        f.create_dataset("grid/coords_gradient",
-                                         data=grid.coords_gradient,
-                                         maxshape=None, dtype="float64")
-                        f.create_dataset("grid/coords_gradient_norm",
-                                         data=grid.coords_gradient_norm,
-                                         maxshape=None, dtype="float64")
-
-                    try:
-                        del f["model_evaluations"]
-                    except KeyError:
-                        pass
-                    f.create_dataset("model_evaluations/results", data=res_all,
-                                     maxshape=None, dtype="float64")
-                    if grad_res_3D_all is not None:
-                        f.create_dataset("model_evaluations/gradient_results", data=ten2mat(grad_res_3D_all),
-                                         maxshape=None, dtype="float64")
-                        f.create_dataset("model_evaluations/gradient_results_idx", data=gradient_idx,
-                                         maxshape=None, dtype="int64")
-
-                    try:
-                        f.create_dataset("misc/error_type", data=self.options["error_type"])
-                    except RuntimeError:
-                        pass
-
-                    if megpc[0].validation is not None:
-                        try:
-                            del f["validation"]
-                        except KeyError:
-                            f.create_dataset("validation/model_evaluations/results", data=megpc[0].validation.results,
-                                             maxshape=None, dtype="float64")
-                            f.create_dataset("validation/grid/coords", data=megpc[0].validation.grid.coords,
-                                             maxshape=None, dtype="float64")
-                            f.create_dataset("validation/grid/coords_norm", data=megpc[0].validation.grid.coords_norm,
-                                             maxshape=None, dtype="float64")
-
-                    # save gpc matrix
-                    for i_gpc, d in enumerate(np.unique(megpc[i_qoi].domains)):
-                        try:
-                            del f["gpc_matrix" + hdf5_subfolder + "/dom_" + str(d)]
-                        except KeyError:
-                            pass
-                        f.create_dataset("gpc_matrix" + hdf5_subfolder + "/dom_" + str(d),
-                                         data=megpc[i_qoi].gpc[d].gpc_matrix,
-                                         maxshape=None, dtype="float64")
-
-                        # save gradient gpc matrix
-                        if megpc[i_qoi].gpc[0].gpc_matrix_gradient is not None:
-                            try:
-                                del f["gpc_matrix_gradient" + hdf5_subfolder + "/dom_" + str(d)]
-                            except KeyError:
-                                pass
-                            if self.options["gradient_enhanced"]:
-                                f.create_dataset("gpc_matrix_gradient" + hdf5_subfolder + "/dom_" + str(d),
-                                                 data=megpc[i_qoi].gpc[d].gpc_matrix_gradient,
-                                                 maxshape=None, dtype="float64")
-
-                    try:
-                        for i_gpc in range(megpc[i_qoi].n_gpc):
-                            del f["coeffs" + hdf5_subfolder + "/dom_" + str(i_gpc)]
-                    except KeyError:
-                        pass
-
-                    for i_gpc in range(megpc[i_qoi].n_gpc):
-                        f.create_dataset("coeffs" + hdf5_subfolder + "/dom_" + str(i_gpc),
-                                         data=coeffs[i_qoi][i_gpc],
-                                         maxshape=None, dtype="float64")
-
-        com.close()
-
-        return megpc, coeffs, res_all
-
-
-class RegAdaptiveProjection(Algorithm):
-    """
-    Adaptive regression approach using projection and leave one out cross validation error estimation
-
-    Parameters
-    ----------
-    problem: Problem class instance
-        GPC problem under investigation
-    options["order_start"] : int, optional, default=0
-          Initial gPC expansion order (maximum order)
-    options["order_end"] : int, optional, default=10
-        Maximum Gpc expansion order to expand to (algorithm will terminate afterwards)
-    options["interaction_order"]: int, optional, default=dim
-        Define maximum interaction order of parameters (default: all interactions)
-    options["order_max_norm"]: float
-        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
-        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
-        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
-        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
-    options["n_grid_gradient"] : float, optional, default: 10
-        Number of initial grid points to determine gradient and projection matrix. When the algorithm goes
-        into the main interations the number will be increased depending on the options "matrix_ratio"
-        and "adaptive_sampling".
-    options["qoi"] : int or str, optional, default: 0
-        Choose for which QOI the projection is determined for. The other QOIs use the same projection.
-        Alternatively, the projection can be determined for every QOI independently (qoi_index or "all").
-    options["adaptive_sampling"] : boolean, optional, default: True
-        Adds samples adaptively to the expansion until the error is converged and continues by
-        adding new basis functions.
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> # initialize adaptive gPC algorithm
-    >>> algorithm = pygpc.RegAdaptiveProjection(problem=problem, options=options)
-    >>> # run algorithm
-    >>> gpc, coeffs, results = algorithm.run()
-    """
-
-    def __init__(self, problem, options, validation=None, grid=None):
-        """
-        Constructor; Initializes RegAdaptiveProjection algorithm
-        """
-        super(RegAdaptiveProjection, self).__init__(problem=problem, options=options, validation=validation, grid=grid)
-
-        # check contents of settings dict and set defaults
-        if "order_start" not in self.options.keys():
-            self.options["order_start"] = 0
-
-        if "order_end" not in self.options.keys():
-            self.options["order_end"] = 10
-
-        if "interaction_order" not in self.options.keys():
-            self.options["interaction_order"] = problem.dim
-
-        if "order_max_norm" not in self.options.keys():
-            self.options["order_max_norm"] = 1.
-
-        if "n_grid_gradient" not in self.options.keys():
-            self.options["n_grid_gradient"] = 10
-
-        if "qoi" not in self.options.keys():
-            self.options["qoi"] = 0
-
-        if "adaptive_sampling" not in self.options.keys():
-            self.options["adaptive_sampling"] = True
-
-        if self.options["qoi"] == "all":
-            self.qoi_specific = True
-        else:
-            self.qoi_specific = False
-
-    def run(self):
-        """
-        Runs adaptive gPC algorithm using projection to solve problem.
-
-        Returns
-        -------
-        gpc : GPC object instance
-            GPC object containing all information i.e., Problem, Model, Grid, Basis, RandomParameter instances
-        coeffs: ndarray of float [n_basis x n_out]
-            GPC coefficients
-        res : ndarray of float [n_grid x n_out]
-            Simulation results at n_grid points of the n_out output variables
-        """
-
-        if self.options["fn_results"] is not None:
-            fn_results = os.path.splitext(self.options["fn_results"])[0]
-
-            if os.path.exists(fn_results + ".hdf5"):
-                os.remove(fn_results + ".hdf5")
-            if os.path.exists(fn_results + "_temp.hdf5"):
-                os.remove(fn_results + "_temp.hdf5")
-        else:
-            fn_results = None
-
-        grad_res_3D = None
-        gradient_idx = None
-
-        # initialize iterators
-        eps = self.options["eps"] + 1.0
-        order = self.options["order_start"]
-        error = []
-        nrmsd = []
-        loocv = []
-
-        # make initial grid to determine gradients and projection matrix. By default, it is an LHS (ese) grid
-        if self.grid is not None:
-            print(f"Using user-predefined grid with n_grid={self.grid.n_grid}")
-            grid_original = self.options["grid"](parameters_random=self.problem.parameters_random,
-                                                 coords=self.grid.coords,
-                                                 coords_norm=self.grid.coords_norm,
-                                                 coords_gradient=self.grid.coords_gradient,
-                                                 coords_gradient_norm=self.grid.coords_gradient_norm,
-                                                 options=self.options["grid_options"])
-
-        elif self.options["grid"] == Random or self.options["grid"] == GP:
-            print(f"Creating initial grid ({self.options['grid'].__init__}) with n_grid={int(self.options['n_grid_gradient'])}")
-            grid_original = self.options["grid"](parameters_random=self.problem.parameters_random,
-                                                 n_grid=self.options["n_grid_gradient"],
-                                                 options=self.options["grid_options"])
-        else:
-            print(f"Creating initial grid ({self.options['grid'].__init__}) with n_grid={int(self.options['n_grid_gradient'])}")
-            grid_original = LHS(parameters_random=self.problem.parameters_random,
-                                n_grid=self.options["n_grid_gradient"],
-                                options={"criterion": "ese",
-                                         "seed": self.options["grid_options"]["seed"]})
-
-        # Initialize parallel Computation class
-        com = Computation(n_cpu=self.n_cpu, matlab_model=self.options["matlab_model"])
-
-        # Run initial simulations to determine initial projection matrix
-        iprint("Performing {} simulations!".format(grid_original.coords.shape[0]),
-               tab=0, verbose=self.options["verbose"])
-
-        start_time = time.time()
-
-        res_all = com.run(model=self.problem.model,
-                          problem=self.problem,
-                          coords=grid_original.coords,
-                          coords_norm=grid_original.coords_norm,
-                          i_iter=self.options["order_start"],
-                          i_subiter=self.options["interaction_order"],
-                          fn_results=self.options["fn_results"],
-                          print_func_time=self.options["print_func_time"],
-                          verbose=self.options["verbose"])
-
-        i_grid = grid_original.n_grid
-
-        iprint('Total function evaluation: ' + str(time.time() - start_time) + ' sec',
-               tab=0, verbose=self.options["verbose"])
-
-        # Determine gradient for projection matrix (method: FD_fwd)
-        start_time = time.time()
-
-        grad_res_3D_all, gradient_idx = get_gradient(model=self.problem.model,
-                                                     problem=self.problem,
-                                                     grid=grid_original,
-                                                     results=res_all,
-                                                     com=com,
-                                                     method="FD_fwd",
-                                                     gradient_results_present=None,
-                                                     gradient_idx_skip=None,
-                                                     i_iter=self.options["order_start"],
-                                                     i_subiter=self.options["interaction_order"],
-                                                     print_func_time=self.options["print_func_time"],
-                                                     dx=1e-3,
-                                                     distance_weight=None,
-                                                     verbose=self.options["verbose"])
-
-        gradient_idx_FD_fwd = gradient_idx
-        grad_res_3D_all_FD_fwd = grad_res_3D_all
-
-        iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
-               tab=0, verbose=self.options["verbose"])
-
-        # check validity of results and resample in case the model could not be evaluated at some sampling points
-        res_all, grad_res_3D_all, gradient_idx, grid_original = self.check_results(
-            results=res_all,
-            gradient_results=grad_res_3D_all,
-            gradient_results_idx=gradient_idx,
-            grid=grid_original,
-            com=com)
-
-        # set qoi indices
-        if self.options["qoi"] == "all":
-            qoi_idx = np.arange(res_all.shape[1])
-            n_qoi = len(qoi_idx)
-
-        else:
-            qoi_idx = [self.options["qoi"]]
-            n_qoi = 1
-
-        # init variables
-        self.problem_reduced = [None for _ in range(n_qoi)]
-        gpc = [None for _ in range(n_qoi)]
-        coeffs = [None for _ in range(n_qoi)]
-        self.options["order_max"] = None
-
-        # loop over qoi (projection is qoi specific)
-        for i_qoi, q_idx in enumerate(qoi_idx):
-
-            basis_order = np.array([self.options["order_start"],
-                                    min(self.options["interaction_order"], self.options["order_start"])])
-
-            if self.options["qoi"] == "all":
-                qoi_idx_validate = q_idx
-            else:
-                qoi_idx_validate = np.arange(res_all.shape[1])
-
-            first_iter = True
-
-            # crop results to considered qoi
-            if self.options["qoi"] != "all":
-                res = copy.deepcopy(res_all)
-                grad_res_3D = copy.deepcopy(grad_res_3D_all)
-                hdf5_subfolder = ""
-
-            else:
-                res = res_all[:, q_idx][:, np.newaxis]
-                grad_res_3D = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
-                hdf5_subfolder = "/qoi_" + str(q_idx)
-
-            # copy results of initial simulation
-            # shutil.copy2(os.path.splitext(self.options["fn_results"])[0] + "_temp.hdf5", fn_results + ".hdf5")
-
-            # Set up initial reduced problem
-            # Determine projection matrix
-            p_matrix, p_matrix_complete = determine_projection_matrix(gradient_results=grad_res_3D_all[:, q_idx, :],
-                                                                      lambda_eps=self.options["lambda_eps_gradient"])
-            p_matrix_norm = np.sum(np.abs(p_matrix), axis=1)
-
-            # Set up initial reduced problem
-            dim_reduced = p_matrix.shape[0]
-            parameters_reduced = OrderedDict()
-
-            for i in range(dim_reduced):
-                parameters_reduced["n{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
-
-            self.problem_reduced[i_qoi] = Problem(model=self.problem.model, parameters=parameters_reduced)
-
-            # Create initial reduced gPC object
-            gpc[i_qoi] = Reg(problem=self.problem_reduced[i_qoi],
-                             order=[self.options["order_start"] for _ in range(dim_reduced)],
-                             order_max=self.options["order_start"],
-                             order_max_norm=self.options["order_max_norm"],
-                             interaction_order=self.options["interaction_order"],
-                             interaction_order_current=self.options["interaction_order"],
-                             options=self.options,
-                             validation=self.validation)
-
-            # save original problem in gpc object
-            gpc[i_qoi].problem_original = self.problem
-
-            extended_basis = False
-
-            # save projection matrix in gPC object
-            gpc[i_qoi].p_matrix = copy.deepcopy(p_matrix)
-            gpc[i_qoi].p_matrix_norm = copy.deepcopy(p_matrix_norm)
-
-            # copy global grid, passing it from qoi to qoi but in the first iteration, we have to initialize a new
-            # grid in case of L1, L1_LHS, LHS_L1 and FIM because they depend on the gpc object which can be different
-            # for every QOI due to different projections and termination criteria. We are passing the coordinates
-            # of the initial LHS (ese) grid to it
-            if self.options["grid"] in [L1, L1_LHS, LHS_L1, FIM]:
-                grid_original = self.options["grid"](parameters_random=self.problem.parameters_random,
-                                                     coords=grid_original.coords,
-                                                     coords_norm=grid_original.coords_norm,
-                                                     coords_gradient=grid_original.coords_gradient,
-                                                     coords_gradient_norm=grid_original.coords_gradient_norm,
-                                                     options=self.options["grid_options"],
-                                                     gpc=gpc[i_qoi])
-
-            # assign transformed grid
-            gpc[i_qoi].grid = project_grid(grid=grid_original, p_matrix=p_matrix, mode="reduce")
-
-            # Initialize gpc matrix
-            gpc[i_qoi].init_gpc_matrix(gradient_idx=gradient_idx)
-            gpc[i_qoi].n_grid.pop(0)
-            gpc[i_qoi].n_basis.pop(0)
-
-            gpc[i_qoi].solver = self.options["solver"]
-            gpc[i_qoi].settings = self.options["settings"]
-
-            # Main iterations (order)
-            while eps > self.options["eps"]:
-
-                if first_iter:
-                    basis_increment = 0
-                else:
-                    basis_increment = 1
-
-                # increase basis
-                basis_order[0], basis_order[1] = increment_basis(order_current=basis_order[0],
-                                                                 interaction_order_current=basis_order[1],
-                                                                 interaction_order_max=np.min([
-                                                                     self.options["interaction_order"],
-                                                                     self.problem_reduced[i_qoi].dim]),
-                                                                 incr=basis_increment)
-
-                if basis_order[0] > self.options["order_end"]:
-                    break
-
-                # update basis
-                b_added = gpc[i_qoi].basis.set_basis_poly(order=basis_order[0] *
-                                                                np.ones(self.problem_reduced[i_qoi].dim),
-                                                          order_max=basis_order[0],
-                                                          order_max_norm=self.options["order_max_norm"],
-                                                          interaction_order=self.options["interaction_order"],
-                                                          interaction_order_current=basis_order[1],
-                                                          problem=self.problem_reduced[i_qoi])
-
-                print_str = "Order/Interaction order: {}/{}".format(basis_order[0], basis_order[1])
-                iprint(print_str, tab=0, verbose=self.options["verbose"])
-                iprint("=" * len(print_str), tab=0, verbose=self.options["verbose"])
-
-                if b_added is not None:
-                    extended_basis = True
-
-                if self.options["adaptive_sampling"]:
-                    iprint("Starting adaptive sampling:", tab=0, verbose=self.options["verbose"])
-
-                add_samples = True  # if adaptive sampling is False, the while loop will be only executed once
-                delta_eps_target = 1e-1
-                delta_eps = delta_eps_target + 1
-                delta_samples = 5e-2
-
-                if gpc[i_qoi].error:
-                    eps_ref = gpc[i_qoi].error[-1]
-
-                while add_samples and delta_eps > delta_eps_target and eps > self.options["eps"]:
-
-                    if not self.options["adaptive_sampling"]:
-                        add_samples = False
-
-                    # new sample size
-                    if extended_basis and self.options["adaptive_sampling"]:
-                        # don't increase sample size immediately when basis was extended, try first with old samples
-                        n_grid_new = gpc[i_qoi].grid.n_grid
-                    elif self.options["adaptive_sampling"]:
-                        # increase sample size stepwise (adaptive sampling)
-                        n_grid_new = int(np.ceil(gpc[i_qoi].grid.n_grid + delta_samples * gpc[i_qoi].basis.n_basis))
-                    else:
-                        # increase sample size according to matrix ratio w.r.t. number of basis functions
-                        n_grid_new = int(np.ceil(gpc[i_qoi].basis.n_basis * self.options["matrix_ratio"]))
-
-                    # run model and update projection matrix if grid points were added
-                    # (Skip simulations of first run because we already simulated it)
-                    if i_grid < n_grid_new or extended_basis:
-                        # extend grid
-                        if i_grid < n_grid_new:
-                            iprint("Extending grid from {} to {} by {} sampling points".format(
-                                gpc[i_qoi].grid.n_grid, n_grid_new, n_grid_new - gpc[i_qoi].grid.n_grid),
-                                tab=0, verbose=self.options["verbose"])
-
-                            grid_original.gpc = gpc[i_qoi]
-                            grid_original.extend_random_grid(n_grid_new=n_grid_new)
-
-                            # run simulations
-                            iprint("Performing simulations " + str(i_grid + 1) + " to " +
-                                   str(grid_original.coords.shape[0]),
-                                   tab=0, verbose=self.options["verbose"])
-
-                            start_time = time.time()
-                            res_new = com.run(model=self.problem.model,
-                                              problem=self.problem,
-                                              coords=grid_original.coords[i_grid:grid_original.coords.shape[0]],
-                                              coords_norm=grid_original.coords_norm[
-                                                          i_grid:grid_original.coords.shape[0]],
-                                              i_iter=basis_order[0],
-                                              i_subiter=basis_order[1],
-                                              fn_results=gpc[i_qoi].fn_results,
-                                              print_func_time=self.options["print_func_time"],
-                                              verbose=self.options["verbose"])
-
-                            res_all = np.vstack((res_all, res_new))
-
-                            iprint('Total parallel function evaluation: ' + str(time.time() - start_time) + ' sec',
-                                   tab=0, verbose=self.options["verbose"])
-
-                            i_grid = grid_original.coords.shape[0]
-
-                            # Determine gradient and update projection matrix in case of gradient enhanced gPC
-                            start_time = time.time()
-                            grad_res_3D_all, gradient_idx = get_gradient(model=self.problem.model,
-                                                                         problem=self.problem,
-                                                                         grid=grid_original,
-                                                                         results=res_all,
-                                                                         com=com,
-                                                                         method=self.options["gradient_calculation"],
-                                                                         gradient_results_present=grad_res_3D_all_FD_fwd,
-                                                                         gradient_idx_skip=gradient_idx_FD_fwd,
-                                                                         i_iter=basis_order[0],
-                                                                         i_subiter=basis_order[1],
-                                                                         print_func_time=self.options["print_func_time"],
-                                                                         dx=self.options["gradient_calculation_options"]["dx"],
-                                                                         distance_weight=self.options["gradient_calculation_options"]["distance_weight"],
-                                                                         verbose=self.options["verbose"])
-
-                            if self.options["gradient_calculation"] == "FD_fwd":
-                                gradient_idx_FD_fwd = gradient_idx
-                                grad_res_3D_all_FD_fwd = grad_res_3D_all
-
-                            iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
-                                   tab=0, verbose=self.options["verbose"])
-
-                            # check validity of results and resample in case the model could not be evaluated at some sampling points
-                            res_all, grad_res_3D_all, gradient_idx, grid_original = self.check_results(
-                                results=res_all,
-                                gradient_results=grad_res_3D_all,
-                                gradient_results_idx=gradient_idx,
-                                grid=grid_original,
-                                com=com)
-
-                            # Determine projection matrix
-                            p_matrix, p_matrix_complete = determine_projection_matrix(gradient_results=grad_res_3D_all[:, q_idx, :],
-                                                                                      lambda_eps=self.options["lambda_eps_gradient"])
-                            p_matrix_norm = np.sum(np.abs(p_matrix), axis=1)
-
-                            # save projection matrix in gPC object
-                            gpc[i_qoi].p_matrix = copy.deepcopy(p_matrix)
-                            gpc[i_qoi].p_matrix_norm = copy.deepcopy(p_matrix_norm)
-
-                            # Set up reduced gPC
-                            dim_reduced = p_matrix.shape[0]
-                            iprint("Dimension of reduced problem: {}".format(dim_reduced),
-                                   tab=0, verbose=self.options["verbose"])
-
-                            # Update gPC object if dimension has changed
-                            if dim_reduced != gpc[i_qoi].problem.dim:
-                                parameters_reduced = OrderedDict()
-
-                                for i in range(dim_reduced):
-                                    parameters_reduced["n{}".format(i)] = Beta(pdf_shape=[1., 1.],
-                                                                               pdf_limits=[-1., 1.])
-
-                                self.problem_reduced[i_qoi] = Problem(model=self.problem.model,
-                                                                      parameters=parameters_reduced)
-
-                                # Create reduced gPC object of order - 1 and add rest of basisfunctions
-                                # of this subiteration afterwards
-                                gpc[i_qoi] = Reg(problem=self.problem_reduced[i_qoi],
-                                                 order=basis_order[0] * np.ones(self.problem_reduced[i_qoi].dim),
-                                                 order_max=basis_order[0],
-                                                 order_max_norm=self.options["order_max_norm"],
-                                                 interaction_order=self.options["interaction_order"],
-                                                 interaction_order_current=basis_order[1],
-                                                 options=self.options,
-                                                 validation=self.validation)
-
-                                # save original problem
-                                gpc[i_qoi].problem_original = self.problem
-
-                                # save projection matrix in gPC object
-                                gpc[i_qoi].p_matrix = copy.deepcopy(p_matrix)
-                                gpc[i_qoi].p_matrix_norm = copy.deepcopy(p_matrix_norm)
-
-                                # Save settings and options in gpc object
-                                gpc[i_qoi].solver = self.options["solver"]
-                                gpc[i_qoi].settings = self.options["settings"]
-                                gpc[i_qoi].options = copy.deepcopy(self.options)
-                                gpc[i_qoi].error = error
-                                gpc[i_qoi].relative_error_nrmsd = nrmsd
-                                gpc[i_qoi].relative_error_loocv = loocv
-
-                    # assign transformed grid
-                    gpc[i_qoi].grid = project_grid(grid=grid_original, p_matrix=p_matrix, mode="reduce")
-
-                    # in case of L1, L1-LHS, LHS-L1 or FIM grids copy new gpc object into it
-                    if self.options["grid"] in [L1, L1_LHS, LHS_L1, FIM]:
-                        gpc[i_qoi].grid.gpc = gpc[i_qoi]
-
-                    # crop results to considered qoi
-                    if self.options["qoi"] != "all":
-                        res = copy.deepcopy(res_all)
-                        grad_res_3D = copy.deepcopy(grad_res_3D_all)
-                    else:
-                        res = res_all[:, q_idx][:, np.newaxis]
-                        grad_res_3D = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
-
-                    # Someone might not use the gradient to determine the gpc coeffs
-                    if gpc[i_qoi].gradient:
-                        grad_res_3D_passed = grad_res_3D
-                        gpc[i_qoi].init_gpc_matrix(gradient_idx=gradient_idx)
-                    else:
-                        grad_res_3D_passed = None
-                        gpc[i_qoi].init_gpc_matrix(gradient_idx=None)
-
-                    # determine gpc coefficients
-                    coeffs[i_qoi] = gpc[i_qoi].solve(results=res,
-                                                     gradient_results=grad_res_3D_passed,
-                                                     solver=gpc[i_qoi].solver,
-                                                     settings=gpc[i_qoi].settings,
-                                                     verbose=self.options["verbose"])
-
-                    # Add a validation set if nrmsd is chosen and no validation set is yet present
-                    if self.options["error_type"] == "nrmsd" and not isinstance(gpc[0].validation, ValidationSet):
-                        gpc[0].create_validation_set(n_samples=self.options["n_samples_validation"],
-                                                     n_cpu=self.options["n_cpu"])
-
-                    elif self.options["error_type"] == "nrmsd" and isinstance(gpc[0].validation, ValidationSet):
-                        gpc[i_qoi].validation = copy.deepcopy(gpc[0].validation)
-
-                    # validate gpc approximation (determine nrmsd or loocv specified in options["error_type"])
-                    eps = gpc[i_qoi].validate(coeffs=coeffs[i_qoi],
-                                              results=res,
-                                              gradient_results=grad_res_3D_passed,
-                                              qoi_idx=qoi_idx_validate)
-
-                    # save error in case that dimension has changed and the gpc object had to be reinitialized
-                    error = copy.deepcopy(gpc[i_qoi].error)
-                    nrmsd = copy.deepcopy(gpc[i_qoi].relative_error_nrmsd)
-                    loocv = copy.deepcopy(gpc[i_qoi].relative_error_loocv)
-
-                    if extended_basis or first_iter:
-                        eps_ref = copy.deepcopy(eps)
-                    else:
-                        delta_eps = np.abs((gpc[i_qoi].error[-1] - gpc[i_qoi].error[-2]) / eps_ref)
-
-                    first_iter = False
-
-                    iprint("-> {} {} error = {}".format(self.options["error_norm"],
-                                                        self.options["error_type"],
-                                                        eps), tab=0, verbose=self.options["verbose"])
-
-                    # extend basis further if error was decreased (except in very first iteration)
-                    if order != self.options["order_start"]:
-                        if extended_basis and gpc[i_qoi].error[-1] < gpc[i_qoi].error[-2]:
-                            break
-
-                    extended_basis = False
-
-                    # exit adaptive sampling loop if no adaptive sampling was chosen
-                    if not self.options["adaptive_sampling"]:
-                        break
-
-                # save gpc object and coeffs for this sub-iteration
-                if self.options["fn_results"] is not None:
-
-                    with h5py.File(os.path.splitext(fn_results)[0] + ".hdf5", "a") as f:
-                        # overwrite coeffs
-                        try:
-                            del f["coeffs" + hdf5_subfolder]
-                        except KeyError:
-                            pass
-
-                        f.create_dataset("coeffs" + hdf5_subfolder,
-                                         data=coeffs[i_qoi], maxshape=None, dtype="float64")
-
-                        # save projection matrix
-                        try:
-                            del f["p_matrix" + hdf5_subfolder]
-                        except KeyError:
-                            f.create_dataset("p_matrix" + hdf5_subfolder,
-                                             data=p_matrix, maxshape=None, dtype="float64")
-
-                        # save gradient of results
-                        if grad_res_3D is not None:
-
-                            try:
-                                del f["model_evaluations/gradient_results"]
-                                del f["model_evaluations/gradient_results_idx"]
-                            except KeyError:
-                                pass
-
-                            grad_res_2D_all = ten2mat(grad_res_3D_all)
-                            f.create_dataset("model_evaluations/gradient_results",
-                                             (grad_res_2D_all.shape[0], grad_res_2D_all.shape[1]),
-                                             maxshape=(None, None),
-                                             dtype="float64",
-                                             data=grad_res_2D_all)
-
-                            f.create_dataset("model_evaluations/gradient_results_idx",
-                                             dtype="int64",
-                                             data=gradient_idx)
-
-                        try:
-                            del f["gpc_matrix" + hdf5_subfolder]
-                        except KeyError:
-                            pass
-                        f.create_dataset("gpc_matrix" + hdf5_subfolder,
-                                         data=gpc[i_qoi].gpc_matrix,
-                                         maxshape=None, dtype="float64")
-
-                        if gpc[i_qoi].gpc_matrix_gradient is not None:
-                            try:
-                                del f["gpc_matrix_gradient" + hdf5_subfolder]
-                            except KeyError:
-                                pass
-                            f.create_dataset("gpc_matrix_gradient" + hdf5_subfolder,
-                                             data=gpc[i_qoi].gpc_matrix_gradient,
-                                             maxshape=None, dtype="float64")
-
-                        try:
-                            del f["error" + hdf5_subfolder]
-                        except KeyError:
-                            pass
-                        f.create_dataset("error" + hdf5_subfolder,
-                                         data=eps,
-                                         maxshape=None, dtype="float64")
-
-            # determine gpc coefficients
-            coeffs[i_qoi] = gpc[i_qoi].solve(results=res,
-                                             gradient_results=grad_res_3D_passed,
-                                             solver=gpc[i_qoi].solver,
-                                             settings=gpc[i_qoi].settings,
-                                             verbose=self.options["verbose"])
-
-            # save original grid
-            gpc[i_qoi].grid_original = copy.deepcopy(grid_original)
-
-            # save gpc object gpc coeffs and projection matrix
-            if self.options["fn_results"] is not None:
-
-                with h5py.File(fn_results + ".hdf5", "a") as f:
-
-                    try:
-                        fn_session = f["misc/fn_session"][:]
-
-                    except KeyError:
-                        f.create_dataset("misc/fn_session",
-                                         data=np.array([os.path.split(self.options["fn_session"])[1]]).astype("|S"))
-                        f.create_dataset("misc/fn_session_folder",
-                                         data=np.array([self.options["fn_session_folder"]]).astype("|S"))
-
-                    try:
-                        del f["coeffs" + hdf5_subfolder]
-                    except KeyError:
-                        pass
-                    f.create_dataset("coeffs" + hdf5_subfolder, data=coeffs[i_qoi], maxshape=None, dtype="float64")
-
-                    try:
-                        del f["p_matrix" + hdf5_subfolder]
-                    except KeyError:
-                        pass
-                    f.create_dataset("p_matrix" + hdf5_subfolder, data=p_matrix, maxshape=None, dtype="float64")
-
-                    f.create_dataset("misc/error_type", data=self.options["error_type"])
-
-                    if self.options["gradient_enhanced"] or gpc[-1].grid.coords_gradient is not None:
-                        f.create_dataset("grid/coords_gradient", data=gpc[-1].grid.coords_gradient,
-                                         maxshape=None, dtype="float64")
-                        f.create_dataset("grid/coords_gradient_norm", data=gpc[-1].grid.coords_gradient_norm,
-                                         maxshape=None, dtype="float64")
-
-            # reset iterators
-            eps = self.options["eps"] + 1.0
-            order = self.options["order_start"]
-            error = []
-            nrmsd = []
-            loocv = []
-
-        if self.options["fn_results"] is not None:
-            with h5py.File(fn_results + ".hdf5", "a") as f:
-                if gpc[0].validation is not None:
-                    f.create_dataset("validation/model_evaluations/results", data=gpc[0].validation.results,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("validation/grid/coords", data=gpc[0].validation.grid.coords,
-                                     maxshape=None, dtype="float64")
-                    f.create_dataset("validation/grid/coords_norm", data=gpc[0].validation.grid.coords_norm,
-                                     maxshape=None, dtype="float64")
-                    try:
-                        f.create_dataset("misc/error_type", data=self.options["error_type"])
-                    except (RuntimeError, ValueError):
-                        del f["misc/error_type"]
-                        f.create_dataset("misc/error_type", data=self.options["error_type"])
-
-        com.close()
-
+import os
+import copy
+import h5py
+import time
+import shutil
+import warnings
+
+import numpy as np
+
+from .Problem import *
+from .SGPC import *
+from .misc import determine_projection_matrix, poly_expand, get_non_enclosed_multi_indices
+from .misc import get_num_coeffs_sparse
+from .misc import ten2mat
+from .misc import mat2ten
+from .misc import get_gradient_idx_domain
+from .misc import get_coords_discontinuity
+from .misc import increment_basis
+from .misc import get_coords_discontinuity
+from .misc import get_num_coeffs_sparse
+from .testfunctions import Dummy
+from .Grid import *
+from .MEGPC import *
+from .Classifier import Classifier
+from .Gradient import get_gradient
+
+
+class Algorithm(object):
+    """
+    Class for GPC algorithms
+
+    Parameters
+    ----------
+    problem : Problem object
+        Object instance of gPC problem to investigate
+    options : dict
+        Algorithm specific options (see sub-classes for more details)
+    grid : Grid object
+        Grid object
+    validation : ValidationSet object
+        ValidationSet object
+    """
+
+    def __init__(self, problem, options, grid=None, validation=None):
+        """
+        Constructor; Initializes GPC algorithm
+        """
+        self.problem = problem
+        self.problem_reduced = []
+        self.validation = validation
+        self.options = options
+        self.grid = grid
+        self.grid_gradient = []
+        self.qoi_specific = None
+
+        # Generate results folder if it doesn't exist
+        if self.options["fn_results"] is not None:
+            if not os.path.exists(os.path.split(self.options["fn_results"])[0]):
+                os.makedirs(os.path.split(self.options["fn_results"])[0])
+
+        self.check_basic_options()
+
+    def check_basic_options(self):
+        """
+        Checks self.options dictionary and sets default
+
+        options["eps"] : float, optional, default=1e-3
+            Relative mean error of leave-one-out cross validation
+        options["error_norm"] : str, optional, default="relative"
+            Choose if error is determined "relative" or "absolute". Use "absolute" error when the
+            model generates outputs equal to zero.
+        options["error_type"] : str, optional, default="loocv"
+            Choose type of error to validate gpc approximation. Use "loocv" (Leave-one-Out cross validation)
+            to omit any additional calculations and "nrmsd" (normalized root mean square deviation) to compare
+            against a Problem.ValidationSet.
+        options["fn_results"] : string, optional, default=None
+            If provided, model evaluations are saved in fn_results.hdf5 file and gpc object in fn_results.pkl file
+        options["gradient_enhanced"] : boolean, optional, default: False
+            Use gradient information to determine the gPC coefficients.
+        options["gradient_calculation"] : str, optional, default="standard_forward"
+            Type of the calculation scheme to determine the gradient in the grid points
+            - "FD_fwd": Finite difference forward approximation of the gradient using n_grid x dim additional sampling
+            points stored in self.grid.coords_gradient and self.grid.coords_gradient_norm [n_grid x dim x dim].
+            - "FD_1st": Finite difference approximation of 1st order accuracy using only the available samples [1]
+            - "FD_2nd": Finite difference approximation of 2nd order accuracy using only the available samples [1]
+            - "FD_1st2nd": Finite difference approximation of 1st and (where possible) 2nd order accuracy
+        options["gradient_calculation_options"] : dict, optional, default: {"dx": 0.01, "distance_weight": -2}
+            Options for gradient calculation (details in get_gradient() function in Gradient.py)
+        options["backend"] : str, optional, default: "python"
+            Default computing backend, certain functions can be computed with Multicore-CPU or GPU acceleration
+        options["lambda_eps_gradient"] : float, optional, default: 0.95
+            Bound of principal components in %. All eigenvectors are included until lambda_eps of total sum of all
+            eigenvalues is included in the system.
+        options["matrix_ratio"]: float, optional, default=1.5
+            Ration between the number of model evaluations and the number of basis functions.
+            If "adaptive_sampling" is activated this factor is only used to
+            construct the initial grid depending on the initial number of basis functions determined by "order_start".
+            (>1 results in an overdetermined system)
+        options["matlab_model"] : boolean, optional, default: False
+            Use a Matlab model function
+        options["method"]: str
+            GPC method to apply ['Reg', 'Quad']
+        options["n_cpu"] : int, optional, default=1
+            Number of threads to use for parallel evaluation of the model function.
+        options["n_samples_validation"] : int, optional, default: 1e4
+            Number of validation points used to determine the NRMSD if chosen as "error_type". Does not create a
+            validation set if there is already one present in the Problem instance (problem.validation).
+        options["print_func_time"] : boolean, optional, default: False
+            Print function evaluation time for every single run
+        options["projection"] : boolean, optional, default: False
+            Use projection approach
+        options["solver"]: str
+            Solver to determine the gPC coefficients
+            - 'Moore-Penrose' ... Pseudoinverse of gPC matrix (SGPC.Reg, EGPC)
+            - 'OMP' ... Orthogonal Matching Pursuit, sparse recovery approach (SGPC.Reg, EGPC)
+        options["settings"]: dict
+            Solver settings
+            - 'Moore-Penrose' ... None
+            - 'OMP' ... {"n_coeffs_sparse": int} Number of gPC coefficients != 0
+        options["verbose"] : boolean, optional, default=True
+            Print output of iterations and sub-iterations (True/False)
+        options["backend"] : str
+            Backend for performance intensive computations
+            - "python" ... Use native python implementation
+            - "cpu" .. Use C Implementaion without multicore-support
+        options["plot_basis"] : bool
+            Plot basis functions and save as fn_results + _basis_iter#.png
+        options["grid_extension_method"] : str, optional, default: GPR
+            Method to extend random grids when adaptive_sampling is turned on:
+            - "GPR": Gaussian Process Regression (sample location is optimized according to posterior variance)
+            - "random": Samples are added randomly
+        """
+
+        if "eps" not in self.options.keys():
+            self.options["eps"] = 1e-3
+
+        if "error_norm" not in self.options.keys():
+            self.options["error_norm"] = "relative"
+
+        if "error_type" not in self.options.keys():
+            self.options["error_type"] = "loocv"
+
+        if "fn_results" not in self.options.keys():
+            self.options["fn_results"] = None
+
+        if "gradient_enhanced" not in self.options.keys():
+            self.options["gradient_enhanced"] = False
+
+        if "gradient_calculation" not in self.options.keys():
+            self.options["gradient_calculation"] = "FD_fwd"
+
+        if "gradient_calculation_options" not in self.options.keys():
+            self.options["gradient_calculation_options"] = {"dx": 0.001, "distance_weight": -2}
+
+        if "dx" not in self.options["gradient_calculation_options"]:
+            self.options["gradient_calculation_options"]["dx"] = 0.001
+
+        if "distance_weight" not in self.options["gradient_calculation_options"]:
+            self.options["gradient_calculation_options"]["distance_weight"] = -2
+
+        if "backend" not in self.options.keys():
+            self.options["backend"] = "python"
+
+        if "lambda_eps_gradient" not in self.options.keys():
+            self.options["lambda_eps_gradient"] = 0.95
+
+        if "matrix_ratio" not in self.options.keys():
+            self.options["matrix_ratio"] = 2
+
+        if "matlab_model" not in self.options.keys():
+            self.options["matlab_model"] = False
+
+        if "method" in self.options.keys():
+            if self.options["method"] == "quad":
+                self.options["solver"] = 'NumInt'
+                self.options["settings"] = None
+            elif self.options["method"] == "reg" and not (self.options["solver"] == "Moore-Penrose" or
+                                                          self.options["solver"] == "OMP" or
+                                                          self.options["solver"] == "LarsLasso"):
+                raise AssertionError("Please specify 'Moore-Penrose' or 'OMP' as solver for 'reg' method")
+
+        if "n_cpu" in self.options.keys():
+            self.n_cpu = self.options["n_cpu"]
+        else:
+            self.options["n_cpu"] = 1
+            self.n_cpu = 1
+
+        if "n_samples_validation" not in self.options.keys():
+            self.options["n_samples_validation"] = 1e4
+
+        if "save_session_format" not in self.options.keys():
+            self.options["save_session_format"] = ".hdf5"
+        elif self.options["save_session_format"] not in [".hdf5", ".pkl"]:
+            self.options["save_session_format"] = ".hdf5"
+        elif self.options["save_session_format"] in [".hdf5"]:
+            self.options["save_session_format"] = ".hdf5"
+        elif self.options["save_session_format"] in [".pkl"]:
+            self.options["save_session_format"] = ".pkl"
+
+        if self.options["fn_results"] is not None:
+            self.options["fn_session"] = os.path.splitext(self.options["fn_results"])[0] + \
+                                         self.options["save_session_format"]
+            if self.options["save_session_format"] == ".hdf5":
+                self.options["fn_session_folder"] = "session"
+            else:
+                self.options["fn_session_folder"] = None
+        else:
+            self.options["fn_session"] = None
+            self.options["fn_session_folder"] = None
+
+        if "print_func_time" not in self.options.keys():
+            self.options["print_func_time"] = False
+
+        if "projection" not in self.options.keys():
+            self.options["projection"] = False
+
+        if "seed" not in self.options.keys():
+            self.options["seed"] = None
+
+        if self.options["solver"] == "Moore-Penrose":
+            self.options["settings"] = None
+
+        if self.options["solver"] == "OMP" and ("settings" not in self.options.keys() or not (
+                "n_coeffs_sparse" not in self.options["settings"].keys() or
+                "sparsity" not in self.options["settings"].keys())):
+            raise AssertionError("Please specify correct solver settings for OMP in 'settings'")
+
+        if self.options["solver"] == "LarsLasso":
+            if "settings" in self.options.keys():
+                if type(self.options["settings"]) is dict:
+                    if "alpha" not in self.options["settings"].keys():
+                        self.options["settings"]["alpha"] = 1e-5
+                else:
+                    self.options["settings"] = {"alpha": 1e-5}
+            else:
+                self.options["settings"] = {"alpha": 1e-5}
+
+        if "verbose" not in self.options.keys():
+            self.options["verbose"] = True
+
+        if "grid" not in self.options.keys():
+            self.options["grid"] = Random
+            self.options["grid_options"] = None
+
+        if "backend" not in self.options.keys():
+            self.options["backend"] = "python"
+
+        if "n_grid" not in self.options.keys():
+            self.options["n_grid"] = None
+
+        if "adaptive_sampling" not in self.options.keys():
+            self.options["adaptive_sampling"] = False
+
+        if "plot_basis" not in self.options.keys():
+            self.options["plot_basis"] = False
+
+        if "grid_extension_method" not in self.options.keys():
+            self.options["grid_extension_method"] = "GPR"
+
+    def check_results(self, results, grid, gradient_results=None, gradient_results_idx=None, com=None, resample=True):
+        """
+        Check the validity of the results and resample if required.
+        Updates the gPC object, the containing grid, and the results array.
+
+        Parameters
+        ----------
+        results : np.ndarray of float [n_samples x n_qoi]
+            Model output at sampling points.
+        grid : Grid object instance
+            Grid object instance the results are computed for.
+        gradient_results : ndarray of float [n_grid x n_out x dim], optional, default: None
+            Gradient of model function in grid points.
+        gradient_results_idx : ndarray of int [n_grid], optional, default: None
+            Indices of grid points where the gradient was evaluated.
+        com : Computation class instance, optional, default: None
+            Computation class instance to run the model if resample is True.
+        resample : bool, optional, default: True
+            Resample grid points and rerun model (requires Computational class instance to run model).
+            If False, the grid points and results are just deleted.
+
+        Returns
+        -------
+        results : np.ndarray of float [n_samples x n_qoi]
+            Updated (fixed) model output at sampling points.
+        gpc : SGPC or MEGPC object instance or list of SGPC or MEGPC object instances
+            GPC object(s) containing the basis functions and the updated grid.
+        gradient_results : ndarray of float [n_grid x n_out x dim]
+            Updated (fixed) gradients of model function in grid points not containing the points where
+            the gradients were NaN.
+        gradient_results_idx : ndarray of int [n_grid], optional, default: None
+            Updated (fixed) indices of grid points where the gradient was evaluated not containing the points where
+            the gradients were NaN.
+        grid : Grid object instance
+            Updated (fixed) grid object instance the results are computed for not containing the grid points where
+            the results were NaN.
+        """
+        # get the indices of the sampling points where any of the QOIs were NaN
+        idx_nan = np.unique(np.where(np.isnan(results))[0])
+        idx_nan_gradient = np.array([])
+
+        if gradient_results is not None:
+            idx_nan_gradient_local = np.unique(np.where(np.isnan(gradient_results))[0])
+
+            if len(idx_nan_gradient_local) > 0:
+                idx_nan_gradient = gradient_results_idx[idx_nan_gradient_local]
+
+        idx_nan = np.unique(np.hstack((idx_nan, idx_nan_gradient)).astype(int))
+
+        if resample:
+            while len(idx_nan) > 0:
+                if self.options["verbose"]:
+                    print(f"WARNING! Detected {len(idx_nan)} grid points with NaN results. Resampling ...")
+
+                # resample grid points
+                grid.resample(idx=idx_nan)
+
+                # determine results at resampled grid points
+                results_resample = com.run(model=self.problem.model,
+                                           problem=self.problem,
+                                           coords=grid.coords[idx_nan, :],
+                                           coords_norm=grid.coords_norm[idx_nan, :],
+                                           i_iter=None,
+                                           i_subiter=None,
+                                           fn_results=None,
+                                           print_func_time=self.options["print_func_time"],
+                                           verbose=self.options["verbose"])
+
+                # Determine gradient [n_grid x n_out x dim]
+                if gradient_results is not None:
+                    if self.options["gradient_calculation"] == "FD_fwd":
+                        # for forward gradient calculation only pass the resampled grid points
+                        grid_gradient = copy.deepcopy(grid)
+                        idx_not_nan = np.array([i for i in range(grid.n_grid) if i not in idx_nan])
+                        grid_gradient.delete(idx=idx_not_nan)
+
+                    else:
+                        # for gradient calculation from adjacent grid points pass the complete grid
+                        grid_gradient = grid
+
+                    gradient_results_resample, gradient_results_idx_resample = get_gradient(
+                        model=self.problem.model,
+                        problem=self.problem,
+                        grid=grid_gradient,
+                        results=results_resample,
+                        com=com,
+                        method=self.options["gradient_calculation"],
+                        gradient_results_present=None,
+                        gradient_idx_skip=None,
+                        i_iter=None,
+                        i_subiter=None,
+                        print_func_time=self.options["print_func_time"],
+                        dx=self.options["gradient_calculation_options"]["dx"],
+                        distance_weight=self.options["gradient_calculation_options"]["distance_weight"],
+                        verbose=self.options["verbose"])
+
+                    if self.options["gradient_calculation"] == "FD_fwd":
+                        gradient_results[idx_nan, :, :] = gradient_results_resample
+                        gradient_results_idx[idx_nan] = idx_nan[gradient_results_idx_resample]
+                    else:
+                        gradient_results = gradient_results_resample
+                        gradient_results_idx = gradient_results_idx_resample
+
+                # replace NaN results with new results at resampled grid points
+                results[idx_nan, :] = results_resample
+
+                # get the indices of the sampling points where any of the QOIs where NaN
+                idx_nan = np.unique(np.where(np.isnan(results))[0])
+        else:
+            # remove grid points with NaN results
+            grid.delete(idx=idx_nan)
+
+            # remove NaN results
+            results = np.delete(results, idx_nan, axis=0)
+
+            if gradient_results is not None:
+                gradient_results = np.delete(gradient_results, idx_nan_gradient_local, axis=0)
+                gradient_results_idx = np.delete(gradient_results_idx, idx_nan_gradient_local, axis=0)
+
+        return results, gradient_results, gradient_results_idx, grid
+
+
+class Static_IO(Algorithm):
+    """
+    Static gPC algorithm, which uses precomputed input output relationships to construct the gPC approximation
+
+    Parameters
+    ----------
+    parameters: OrderedDict containing the RandomParameter class instances
+        Dictionary (ordered) containing the properties of the random parameters
+    options["order"]: list of int [dim]
+        Maximum individual expansion order [order_1, order_2, ..., order_dim].
+        Generates individual polynomials also if maximum expansion order in order_max is exceeded
+    options["order_max"]: int
+        Maximum global expansion order.
+        The maximum expansion order considers the sum of the orders of combined polynomials together with the
+        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
+        monomial orders.
+    options["order_max_norm"]: float
+        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
+        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
+        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
+        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
+    options["interaction_order"]: int
+        Number of random variables, which can interact with each other.
+        All polynomials are ignored, which have an interaction order greater than the specified
+    grid: Grid object instance
+        Grid object to use for static gPC (Random, SparseGrid, TensorGrid) containing the parameter values, where the
+        output relations were calculated
+    results: ndarray of float [N_grid x N_qoi]
+        Model output at each grid point for each QOI
+    validation: Validation Set class instance, optional
+        Validation set containing reference solutions at precomputed grid points
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> # initialize static gPC algorithm using precomputed IO relationships
+    >>> algorithm = pygpc.Static_IO(parameters=parameters, options=options, grid=grid, results=results)
+    >>> # run algorithm
+    >>> gpc, coeffs = algorithm.run()
+    """
+    def __init__(self, parameters, options, results, grid, validation=None):
+        """
+        Constructor; Initializes static gPC algorithm
+        """
+        # create dummy model
+        model = Dummy()
+
+        # create dummy problem
+        problem = Problem(model, parameters)
+
+        super(Static_IO, self).__init__(problem=problem, options=options, validation=validation, grid=grid)
+
+        self.res = results
+
+        if "order" not in self.options.keys():
+            raise AssertionError("Please specify 'order'=[order_1, order_2, ..., order_dim] in options dictionary")
+
+        if "order_max" not in self.options.keys():
+            raise AssertionError("Please specify 'order_max' in options dictionary")
+
+        if "order_max_norm" not in self.options.keys():
+            self.options["order_max_norm"] = 1.
+
+        if "interaction_order" not in self.options.keys():
+            self.options["interaction_order"] = self.problem.dim
+
+        #if "error_type" not in self.options.keys():
+        #    self.options["error_type"] = "loocv"
+
+        #if self.options["error_type"] != "loocv":
+            #    self.options["error_type"] = "loocv"
+            #warnings.warn("Changing error calculation type to loocv ...")
+
+    def run(self):
+        """
+        Runs static gPC algorithm using precomputed IO relationships to construct surrogate model.
+
+        Returns
+        -------
+        gpc : GPC object instance
+            GPC object containing all information i.e., Problem, Model, Grid, Basis, RandomParameter instances
+        coeffs: ndarray of float [n_basis x n_out]
+            GPC coefficients
+        """
+
+        if self.options["fn_results"] is not None:
+            fn_results = os.path.splitext(self.options["fn_results"])[0]
+
+            if os.path.exists(fn_results + ".hdf5"):
+                os.remove(fn_results + ".hdf5")
+        else:
+            fn_results = None
+
+        # Initialize gPC object
+        gpc = Reg(problem=self.problem,
+                  order=self.options["order"],
+                  order_max=self.options["order_max"],
+                  order_max_norm=self.options["order_max_norm"],
+                  interaction_order=self.options["interaction_order"],
+                  interaction_order_current=self.options["interaction_order"],
+                  options=self.options,
+                  validation=self.validation)
+
+        gpc.backend = self.options["backend"]
+
+        # determine number of basis functions
+        n_coeffs = get_num_coeffs_sparse(order_dim_max=self.options["order"],
+                                         order_glob_max=self.options["order_max"],
+                                         order_inter_max=self.options["interaction_order"],
+                                         dim=self.problem.dim)
+
+        print(f" > Determining {n_coeffs} gPC coeffs with {self.res.shape[0]} simulations!")
+
+        # Write grid in gpc object
+        gpc.grid = self.grid
+
+        # Initialize gpc matrix
+        gpc.init_gpc_matrix()
+
+        # Compute gpc coefficients
+        coeffs = gpc.solve(results=self.res,
+                           solver=self.options["solver"],
+                           settings=self.options["settings"],
+                           verbose=self.options["verbose"])
+
+        # validate gpc approximation (determine nrmsd or loocv specified in options["error_type"])
+        eps = gpc.validate(coeffs=coeffs, results=self.res)
+
+        iprint("-> {} {} error = {}".format(self.options["error_norm"],
+                                            self.options["error_type"],
+                                            eps), tab=0, verbose=self.options["verbose"])
+
+        # save gpc object and gpc coeffs
+        if self.options["fn_results"] is not None:
+
+            with h5py.File(fn_results + ".hdf5", "a") as f:
+
+                f.create_dataset("misc/fn_session",
+                                 data=np.array([os.path.split(self.options["fn_session"])[1]]).astype("|S"))
+                f.create_dataset("misc/fn_session_folder",
+                                 data=np.array([self.options["fn_session_folder"]]).astype("|S"))
+                f.create_dataset("misc/error_type", data=self.options["error_type"])
+                f.create_dataset("error", data=eps, maxshape=None, dtype="float64")
+                f.create_dataset("grid/coords", maxshape=None, data=gpc.grid.coords, dtype="float64")
+                f.create_dataset("grid/coords_norm", maxshape=None, data=gpc.grid.coords_norm, dtype="float64")
+
+                if gpc.grid.coords_gradient is not None:
+                    f.create_dataset("grid/coords_gradient", data=gpc.grid.coords_gradient,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("grid/coords_gradient_norm", data=gpc.grid.coords_gradient_norm,
+                                     maxshape=None, dtype="float64")
+
+                f.create_dataset("coeffs", data=coeffs,
+                                 maxshape=None, dtype="float64")
+                f.create_dataset("gpc_matrix", data=gpc.gpc_matrix,
+                                 maxshape=None, dtype="float64")
+
+                if gpc.gpc_matrix_gradient is not None:
+                    f.create_dataset("gpc_matrix_gradient",
+                                     data=gpc.gpc_matrix_gradient, maxshape=None, dtype="float64")
+
+                f.create_dataset("model_evaluations/results", data=self.res, maxshape=None, dtype="float64")
+
+                if gpc.validation is not None:
+                    f.create_dataset("validation/model_evaluations/results", data=gpc.validation.results,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("validation/grid/coords", data=gpc.validation.grid.coords,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("validation/grid/coords_norm", data=gpc.validation.grid.coords_norm,
+                                     maxshape=None, dtype="float64")
+
+        return gpc, coeffs, self.res
+
+
+class Static(Algorithm):
+    """
+    Static gPC algorithm
+
+    Parameters
+    ----------
+    problem : Problem object
+        Object instance of gPC problem to investigate
+    options["method"]: str
+        GPC method to apply ['Reg', 'Quad']
+    options["order"]: list of int [dim]
+        Maximum individual expansion order [order_1, order_2, ..., order_dim].
+        Generates individual polynomials also if maximum expansion order in order_max is exceeded
+    options["order_max"]: int
+        Maximum global expansion order.
+        The maximum expansion order considers the sum of the orders of combined polynomials together with the
+        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
+        monomial orders.
+    options["order_max_norm"]: float
+        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
+        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
+        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
+        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
+    options["interaction_order"]: int
+        Number of random variables, which can interact with each other.
+        All polynomials are ignored, which have an interaction order greater than the specified
+    grid: Grid object instance
+        Grid object to use for static gPC (Random, SparseGrid, TensorGrid)
+    validation: Validation Set class instance, optional
+        Validation set containing reference solutions at precomputed grid points
+
+    Notes
+    -----
+    .. [1] Blatman, G., & Sudret, B. (2011). Adaptive sparse polynomial chaos expansion based on least angle
+       regression. Journal of Computational Physics, 230(6), 2345-2367.
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> # initialize static gPC algorithm
+    >>> algorithm = pygpc.Static(problem=problem, options=options, grid=grid)
+    >>> # run algorithm
+    >>> gpc, coeffs, results = algorithm.run()
+    """
+
+    def __init__(self, problem, options, grid=None, validation=None, gpc=None):
+        """
+        Constructor; Initializes static gPC algorithm
+        """
+        super(Static, self).__init__(problem=problem, options=options, validation=validation, grid=grid)
+
+        self.qoi_specific = False
+        self.gpc = gpc
+
+        # check contents of settings dict and set defaults
+        if "method" not in self.options.keys():
+            raise AssertionError("Please specify 'method' with either 'reg' or 'quad' in options dictionary")
+
+        if "order" not in self.options.keys():
+            raise AssertionError("Please specify 'order'=[order_1, order_2, ..., order_dim] in options dictionary")
+
+        if "order_max" not in self.options.keys():
+            raise AssertionError("Please specify 'order_max' in options dictionary")
+
+        if "order_max_norm" not in self.options.keys():
+            self.options["order_max_norm"] = 1.
+
+        if "interaction_order" not in self.options.keys():
+            self.options["interaction_order"] = self.problem.dim
+
+    def run(self):
+        """
+        Runs static gPC algorithm to solve problem.
+
+        Returns
+        -------
+        gpc : GPC object instance
+            GPC object containing all information i.e., Problem, Model, Grid, Basis, RandomParameter instances
+        coeffs: ndarray of float [n_basis x n_out]
+            GPC coefficients
+        res : ndarray of float [n_grid x n_out]
+            Simulation results at n_grid points of the n_out output variables
+        """
+
+        if self.options["fn_results"] is not None:
+            fn_results = os.path.splitext(self.options["fn_results"])[0]
+
+            if os.path.exists(fn_results + ".hdf5"):
+                os.remove(fn_results + ".hdf5")
+        else:
+            fn_results = None
+
+        grad_res_3D = None
+        gradient_idx = None
+
+        # Create gPC object
+        if self.options["method"] == "reg":
+            if self.gpc is None:
+                gpc = Reg(problem=self.problem,
+                          order=self.options["order"],
+                          order_max=self.options["order_max"],
+                          order_max_norm=self.options["order_max_norm"],
+                          interaction_order=self.options["interaction_order"],
+                          interaction_order_current=self.options["interaction_order"],
+                          options=self.options,
+                          validation=self.validation)
+            else:
+                gpc = self.gpc
+                gpc.options["fn_results"] = self.options["fn_results"]
+                gpc.fn_results = self.options["fn_results"]
+
+        elif self.options["method"] == "quad":
+            gpc = Quad(problem=self.problem,
+                       order=self.options["order"],
+                       order_max=self.options["order_max"],
+                       order_max_norm=self.options["order_max_norm"],
+                       interaction_order=self.options["interaction_order"],
+                       interaction_order_current=self.options["interaction_order"],
+                       options=self.options,
+                       validation=self.validation)
+
+        else:
+            raise AssertionError("Please specify correct gPC method ('reg' or 'quad')")
+
+        gpc.backend = self.options["backend"]
+
+        # determine number of basis functions
+        n_coeffs = get_num_coeffs_sparse(order_dim_max=self.options["order"],
+                                         order_glob_max=self.options["order_max"],
+                                         order_inter_max=self.options["interaction_order"],
+                                         dim=self.problem.dim)
+
+        if self.options["n_grid"] is not None:
+            n_grid = self.options["n_grid"]
+        else:
+            n_grid = self.options["matrix_ratio"] * n_coeffs
+
+        # Write grid in gpc object
+        if self.grid is not None:
+            if self.options["method"] == "reg":
+                print(f"Using user-predefined grid with n_grid={self.grid.n_grid}")
+                gpc.grid = self.options["grid"](parameters_random=self.problem.parameters_random,
+                                                coords=self.grid.coords,
+                                                coords_norm=self.grid.coords_norm,
+                                                coords_gradient=self.grid.coords_gradient,
+                                                coords_gradient_norm=self.grid.coords_gradient_norm,
+                                                options=self.options["grid_options"])
+            elif self.options["method"] == "quad":
+                gpc.grid = self.grid
+
+        elif self.options["grid"] == Random or self.options["grid"] == LHS or self.options["grid"] == GP:
+            gpc.grid = self.options["grid"](parameters_random=self.problem.parameters_random,
+                                            n_grid=n_grid,
+                                            options=self.options["grid_options"])
+
+        elif self.options["grid"] == L1 or self.options["grid"] == L1_LHS or self.options["grid"] == LHS_L1\
+                or self.options["grid"] == FIM or self.options["grid"] == CO:
+            gpc.grid = self.options["grid"](parameters_random=self.problem.parameters_random,
+                                            n_grid=n_grid,
+                                            options=self.options["grid_options"],
+                                            gpc=gpc)
+
+        else:
+            raise ValueError("Grid not provided and specified grid type not known!")
+
+        gpc.interaction_order_current = copy.deepcopy(self.options["interaction_order"])
+
+        # Initialize parallel Computation class
+        com = Computation(n_cpu=self.n_cpu, matlab_model=self.options["matlab_model"])
+
+        eps = self.options["eps"] + 1
+        eps_pre = eps + 1
+        i_grid = 0
+
+        res = np.array([])
+
+        # determine gpc approximation and determine error (increase grid size in case of adaptive sampling)
+        while eps > self.options["eps"]:
+            # Run simulations
+            iprint("Performing {} simulations!".format(gpc.grid.n_grid - i_grid),
+                   tab=0, verbose=self.options["verbose"])
+
+            start_time = time.time()
+
+            res_new = com.run(model=self.problem.model,
+                              problem=self.problem,
+                              coords=gpc.grid.coords[i_grid:gpc.grid.n_grid, :],
+                              coords_norm=gpc.grid.coords_norm[i_grid:gpc.grid.n_grid, :],
+                              i_iter=gpc.order_max,
+                              i_subiter=gpc.interaction_order,
+                              fn_results=None,
+                              print_func_time=self.options["print_func_time"],
+                              verbose=self.options["verbose"])
+
+            if len(res) > 0:
+                res = np.vstack((res, res_new))
+            else:
+                res = res_new
+
+            i_grid = gpc.grid.n_grid
+
+            iprint('Total parallel function evaluation: ' + str(time.time() - start_time) + ' sec',
+                   tab=0, verbose=self.options["verbose"])
+
+            # Determine gradient [n_grid x n_out x dim]
+            if self.options["gradient_enhanced"]:
+                start_time = time.time()
+
+                grad_res_3D, gradient_idx = get_gradient(model=self.problem.model,
+                                                         problem=self.problem,
+                                                         grid=gpc.grid,
+                                                         results=res,
+                                                         com=com,
+                                                         method=self.options["gradient_calculation"],
+                                                         gradient_results_present=None,
+                                                         gradient_idx_skip=None,
+                                                         i_iter=gpc.order_max,
+                                                         i_subiter=gpc.interaction_order,
+                                                         print_func_time=self.options["print_func_time"],
+                                                         dx=self.options["gradient_calculation_options"]["dx"],
+                                                         distance_weight=self.options["gradient_calculation_options"]["distance_weight"],
+                                                         verbose=self.options["verbose"])
+
+                iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
+                       tab=0, verbose=self.options["verbose"])
+
+            # check validity of results and resample in case the model could not be evaluated at some sampling points
+            res, grad_res_3D, gradient_idx, gpc.grid = self.check_results(results=res,
+                                                                          gradient_results=grad_res_3D,
+                                                                          gradient_results_idx=gradient_idx,
+                                                                          grid=gpc.grid,
+                                                                          com=com)
+
+            # Initialize gpc matrix
+            gpc.init_gpc_matrix(gradient_idx=gradient_idx)
+
+            # Compute gpc coefficients
+            coeffs = gpc.solve(results=res,
+                               gradient_results=grad_res_3D,
+                               solver=self.options["solver"],
+                               settings=self.options["settings"],
+                               verbose=self.options["verbose"])
+
+            # create validation set if necessary
+            if self.options["error_type"] == "nrmsd" and gpc.validation is None:
+                gpc.create_validation_set(n_samples=self.options["n_samples_validation"],
+                                          n_cpu=self.options["n_cpu"])
+
+            # validate gpc approximation (determine nrmsd or loocv specified in options["error_type"])
+            eps = gpc.validate(coeffs=coeffs, results=res, gradient_results=grad_res_3D)
+
+            iprint("-> {} {} error = {}".format(self.options["error_norm"],
+                                                self.options["error_type"],
+                                                eps), tab=0, verbose=self.options["verbose"])
+
+            if not self.options["adaptive_sampling"]:  # (0 < (eps_pre-eps)/eps < 0.01):
+                break
+
+            if eps > self.options["eps"]:
+                # extend grid by 5% of number of basis functions and restart loop
+                n_grid_new = gpc.grid.n_grid + 1  # int(np.ceil(gpc.grid.n_grid + 5e-2 * gpc.basis.n_basis))
+                iprint('Extending grid from {} to {} by {} sampling points using grid_extension_method {}'.format(
+                    gpc.grid.n_grid, n_grid_new, n_grid_new - gpc.grid.n_grid, self.options["grid_extension_method"]),
+                    tab=0, verbose=self.options["verbose"])
+                if self.options["grid_extension_method"] == "GPR":
+                    gpc.grid.extend_random_grid(n_grid_new=n_grid_new, results=res, type="GP")
+                else:
+                    gpc.grid.extend_random_grid(n_grid_new=n_grid_new)
+
+            # eps_pre = eps
+
+        # save gpc object and gpc coeffs
+        if self.options["fn_results"] is not None:
+
+            with h5py.File(fn_results + ".hdf5", "a") as f:
+
+                f.create_dataset("misc/fn_session",
+                                 data=np.array([os.path.split(self.options["fn_session"])[1]]).astype("|S"))
+                f.create_dataset("misc/fn_session_folder",
+                                 data=np.array([self.options["fn_session_folder"]]).astype("|S"))
+                f.create_dataset("misc/error_type", data=self.options["error_type"])
+                f.create_dataset("error", data=eps, maxshape=None, dtype="float64")
+                f.create_dataset("grid/coords", maxshape=None, data=gpc.grid.coords, dtype="float64")
+                f.create_dataset("grid/coords_norm", maxshape=None, data=gpc.grid.coords_norm, dtype="float64")
+
+                if gpc.grid.coords_gradient is not None:
+                    f.create_dataset("grid/coords_gradient", data=gpc.grid.coords_gradient,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("grid/coords_gradient_norm", data=gpc.grid.coords_gradient_norm,
+                                     maxshape=None, dtype="float64")
+
+                f.create_dataset("coeffs", data=coeffs,
+                                 maxshape=None, dtype="float64")
+                f.create_dataset("gpc_matrix", data=gpc.gpc_matrix,
+                                 maxshape=None, dtype="float64")
+
+                if gpc.gpc_matrix_gradient is not None:
+                    f.create_dataset("gpc_matrix_gradient",
+                                     data=gpc.gpc_matrix_gradient, maxshape=None, dtype="float64")
+
+                f.create_dataset("model_evaluations/results", data=res, maxshape=None, dtype="float64")
+
+                if grad_res_3D is not None:
+                    f.create_dataset("model_evaluations/gradient_results", data=ten2mat(grad_res_3D),
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("model_evaluations/gradient_results_idx", data=gpc.gradient_idx,
+                                     maxshape=None, dtype="int64")
+
+                if gpc.validation is not None:
+                    f.create_dataset("validation/model_evaluations/results", data=gpc.validation.results,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("validation/grid/coords", data=gpc.validation.grid.coords,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("validation/grid/coords_norm", data=gpc.validation.grid.coords_norm,
+                                     maxshape=None, dtype="float64")
+
+        com.close()
+
+        return gpc, coeffs, res
+
+
+class MEStatic(Algorithm):
+    """
+    Multi-Element Static gPC algorithm
+
+    Parameters
+    ----------
+    problem : Problem object
+        Object instance of gPC problem to investigate
+    options["method"]: str
+        GPC method to apply ['Reg', 'Quad']
+    options["order"]: list of int [dim]
+        Maximum individual expansion order [order_1, order_2, ..., order_dim].
+        Generates individual polynomials also if maximum expansion order in order_max is exceeded
+    options["order_max"]: int
+        Maximum global expansion order.
+        The maximum expansion order considers the sum of the orders of combined polynomials together with the
+        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
+        monomial orders.
+    options["order_max_norm"]: float
+        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
+        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
+        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
+        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
+    options["interaction_order"]: int
+        Number of random variables, which can interact with each other.
+        All polynomials are ignored, which have an interaction order greater than the specified
+    options["qoi"] : int or str, optional, default: 0
+        Choose for which QOI the projection is determined for. The other QOIs use the same projection.
+        Alternatively, the projection can be determined for every QOI independently (qoi_index or "all").
+    options["classifier"] : str, optional, default: "learning"
+        Classification algorithm to subdivide parameter domain.
+        - "learning" ... ClassifierLearning algorithm based on Unsupervised and supervised learning
+    options["classifier_options"] : dict, optional, default: default settings
+        Options of classifier
+    grid: Grid object instance
+        Grid object to use for static gPC (Random, SparseGrid, TensorGrid)
+
+    Notes
+    -----
+    .. [1] Blatman, G., & Sudret, B. (2011). Adaptive sparse polynomial chaos expansion based on least angle
+       regression. Journal of Computational Physics, 230(6), 2345-2367.
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> # initialize static gPC algorithm
+    >>> algorithm = pygpc.MEStatic(problem=problem, options=options, grid=grid)
+    >>> # run algorithm
+    >>> gpc, coeffs, results = algorithm.run()
+    """
+
+    def __init__(self, problem, options, grid=None, validation=None):
+        """
+        Constructor; Initializes multi-element static gPC algorithm
+        """
+        super(MEStatic, self).__init__(problem=problem, options=options, validation=validation, grid=grid)
+
+        # check contents of settings dict and set defaults
+        if "method" not in self.options.keys():
+            raise AssertionError("Please specify 'method' with either 'reg' or 'quad' in options dictionary")
+
+        if "order" not in self.options.keys():
+            raise AssertionError("Please specify 'order'=[order_1, order_2, ..., order_dim] in options dictionary")
+
+        if "order_max" not in self.options.keys():
+            raise AssertionError("Please specify 'order_max' in options dictionary")
+
+        if "interaction_order" not in self.options.keys():
+            self.options["interaction_order"] = self.problem.dim
+
+        if "order_max_norm" not in self.options.keys():
+            self.options["order_max_norm"] = 1.
+
+        if "qoi" not in self.options.keys():
+            self.options["qoi"] = 0
+
+        if "classifier" not in self.options.keys():
+            self.options["classifier"] = "learning"
+
+        if "classifier_options" not in self.options.keys():
+            self.options["classifier_options"] = None
+
+        if self.options["qoi"] == "all":
+            self.qoi_specific = True
+        else:
+            self.qoi_specific = False
+
+    def run(self):
+        """
+        Runs Multi-Element Static gPC algorithm to solve problem.
+
+        Returns
+        -------
+        megpc : Multi-element GPC object instance
+            MEGPC object containing all information i.e., Problem, Model, Grid, Basis, RandomParameter instances
+        coeffs: list of ndarray of float [n_gpc][n_basis x n_out]
+            GPC coefficients
+        res : ndarray of float [n_grid x n_out]
+            Simulation results at n_grid points of the n_out output variables
+        """
+        if self.options["fn_results"] is not None:
+            fn_results = os.path.splitext(self.options["fn_results"])[0]
+
+            if os.path.exists(fn_results + ".hdf5"):
+                os.remove(fn_results + ".hdf5")
+        else:
+            fn_results = None
+
+        grad_res_3D = None
+        grad_res_3D_all = None
+        gradient_idx = None
+        res_all_list = []
+
+        if self.options["n_grid"] is not None:
+            n_grid = self.options["n_grid"]
+        else:
+            n_grid = None
+
+        # Write grid in gpc object
+        if self.grid is not None:
+            print(f"Using user-predefined grid with n_grid={n_grid}")
+            grid = self.options["grid"](parameters_random=self.problem.parameters_random,
+                                        coords=self.grid.coords,
+                                        coords_norm=self.grid.coords_norm,
+                                        coords_gradient=self.grid.coords_gradient,
+                                        coords_gradient_norm=self.grid.coords_gradient_norm,
+                                        options=self.options["grid_options"])
+
+        elif n_grid is None:
+            raise ValueError("If grid is not provided during initialization please provide options['n_grid']")
+
+        elif self.options["grid"] == Random or self.options["grid"] == LHS or self.options["grid"] == GP:
+            print(f"Creating initial grid ({self.options['grid'].__name__}) with n_grid={int(n_grid)}")
+            grid = self.options["grid"](parameters_random=self.problem.parameters_random,
+                                        n_grid=n_grid,
+                                        options=self.options["grid_options"])
+
+        elif self.options["grid"] == L1 or self.options["grid"] == L1_LHS or self.options["grid"] == LHS_L1 \
+                or self.options["grid"] == FIM:
+            raise NotImplementedError("Grid type not possible for MEStatic algorithm."
+                                      "Please use either 'Random' or 'LHS'.")
+
+        else:
+            raise ValueError("Grid not provided and specified grid type not known!")
+
+        # Initialize parallel Computation class
+        com = Computation(n_cpu=self.n_cpu, matlab_model=self.options["matlab_model"])
+
+        megpc = []
+        coeffs = []
+        eps = self.options["eps"] + 1
+        i_grid = 0
+        i_qoi = 0
+
+        if self.options["qoi"] is not None and self.options["qoi"] != "all":
+            q_idx = self.options["qoi"]
+            qoi_idx = [q_idx]
+        else:
+            qoi_idx = np.arange(1)
+            q_idx = qoi_idx[0]
+
+        n_qoi = len(qoi_idx)
+
+        while i_qoi < n_qoi:
+            q_idx = qoi_idx[i_qoi]
+            print_str = "Determining gPC approximation for QOI #{}:".format(q_idx)
+            iprint(print_str, tab=0, verbose=self.options["verbose"])
+            iprint("=" * len(print_str), tab=0, verbose=self.options["verbose"])
+            megpc.append(0)
+            coeffs.append(0)
+            eps_pre = eps + 1
+
+            # Create MEGPC object
+            megpc[i_qoi] = MEGPC(problem=self.problem,
+                                 options=self.options,
+                                 validation=self.validation)
+
+            res_all = np.array([])
+
+            # determine gpc approximation and determine error (increase grid size in case of adaptive sampling)
+            while eps > self.options["eps"]:
+                if i_grid < grid.n_grid:
+                    # run simulations
+                    iprint("Performing {} simulations!".format(grid.n_grid - i_grid),
+                           tab=0, verbose=self.options["verbose"])
+
+                    start_time = time.time()
+
+                    res_new = com.run(model=self.problem.model,
+                                      problem=self.problem,
+                                      coords=grid.coords[i_grid:grid.n_grid, :],
+                                      coords_norm=grid.coords_norm[i_grid:grid.n_grid, :],
+                                      i_iter=self.options["order_max"],
+                                      i_subiter=self.options["interaction_order"],
+                                      fn_results=None,
+                                      print_func_time=self.options["print_func_time"],
+                                      verbose=self.options["verbose"])
+
+                    if len(res_all) > 0:
+                        res_all = np.vstack(res_all, res_new)
+                    else:
+                        res_all = res_new
+
+                    if i_qoi == 0 and i_grid == 0:
+                        if self.options["qoi"] == "all":
+                            qoi_idx = np.arange(res_all.shape[1])
+                            n_qoi = len(qoi_idx)
+
+                    i_grid = grid.n_grid
+
+                    iprint('Total function evaluation: ' + str(time.time() - start_time) + ' sec',
+                           tab=0, verbose=self.options["verbose"])
+
+                    # Determine gradient [n_grid x n_out x dim]
+                    if self.options["gradient_enhanced"]:
+                        start_time = time.time()
+
+                        grad_res_3D_all, gradient_idx = get_gradient(model=self.problem.model,
+                                                                     problem=self.problem,
+                                                                     grid=grid,
+                                                                     results=res_all,
+                                                                     com=com,
+                                                                     method=self.options["gradient_calculation"],
+                                                                     gradient_results_present=grad_res_3D_all,
+                                                                     gradient_idx_skip=gradient_idx,
+                                                                     i_iter=self.options["order_max"],
+                                                                     i_subiter=self.options["interaction_order"],
+                                                                     print_func_time=self.options["print_func_time"],
+                                                                     dx=self.options["gradient_calculation_options"]["dx"],
+                                                                     distance_weight=
+                                                                     self.options["gradient_calculation_options"][
+                                                                         "distance_weight"],
+                                                                     verbose=self.options["verbose"])
+
+                        iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
+                               tab=0, verbose=self.options["verbose"])
+
+                    # check validity of results and resample in case the model could not be evaluated at some sampling points
+                    res_all, grad_res_3D_all, gradient_idx, grid = self.check_results(results=res_all,
+                                                                                      gradient_results=grad_res_3D_all,
+                                                                                      gradient_results_idx=gradient_idx,
+                                                                                      grid=grid,
+                                                                                      com=com)
+                # crop results to considered qoi
+                if self.options["qoi"] != "all":
+                    res = copy.deepcopy(res_all)
+                    grad_res_3D = copy.deepcopy(grad_res_3D_all)
+                    hdf5_subfolder = ""
+                    output_idx_passed_validation = None
+
+                else:
+                    res = res_all[:, q_idx][:, np.newaxis]
+                    hdf5_subfolder = "/qoi_" + str(q_idx)
+                    output_idx_passed_validation = q_idx
+
+                    if grad_res_3D_all is not None:
+                        grad_res_3D = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
+
+                # Write grid in gpc object
+                megpc[i_qoi].grid = copy.deepcopy(grid)
+
+                # determine gpc domains
+                megpc[i_qoi].init_classifier(coords=megpc[i_qoi].grid.coords_norm,
+                                             results=res_all[:, q_idx][:, np.newaxis],
+                                             algorithm=self.options["classifier"],
+                                             options=self.options["classifier_options"])
+
+                # initialize sub-gPCs
+                for d in np.unique(megpc[i_qoi].domains):
+                    megpc[i_qoi].add_sub_gpc(problem=megpc[i_qoi].problem,
+                                             order=[self.options["order"][0] for _ in range(megpc[i_qoi].problem.dim)],
+                                             order_max=self.options["order_max"],
+                                             order_max_norm=self.options["order_max_norm"],
+                                             interaction_order=self.options["interaction_order"],
+                                             interaction_order_current=self.options["interaction_order"],
+                                             options=self.options,
+                                             domain=d,
+                                             validation=None)
+
+                # assign grids to sub-gPCs (rotate sub-grids in case of projection)
+                megpc[i_qoi].assign_grids(gradient_idx=gradient_idx)
+
+                # Initialize gpc matrices
+                megpc[i_qoi].init_gpc_matrices()
+
+                # Compute gpc coefficients
+                coeffs[i_qoi] = megpc[i_qoi].solve(results=res,
+                                                   gradient_results=grad_res_3D,
+                                                   solver=self.options["solver"],
+                                                   settings=self.options["settings"],
+                                                   verbose=self.options["verbose"])
+
+                # create validation set if necessary
+                if self.options["error_type"] == "nrmsd" and megpc[0].validation is None:
+                    megpc[0].create_validation_set(n_samples=self.options["n_samples_validation"],
+                                                   n_cpu=self.options["n_cpu"])
+                elif self.options["error_type"] == "nrmsd" and megpc[0].validation is not None:
+                    megpc[i_qoi].validation = copy.deepcopy(megpc[0].validation)
+
+                # validate gpc approximation (determine nrmsd or loocv specified in options["error_type"])
+                eps = megpc[i_qoi].validate(coeffs=coeffs[i_qoi], results=res, gradient_results=grad_res_3D)
+
+                iprint("-> {} {} error = {}".format(self.options["error_norm"],
+                                                    self.options["error_type"],
+                                                    eps), tab=0, verbose=self.options["verbose"])
+
+                # domain specific error
+                eps_domain = [0 for _ in range(len(np.unique(megpc[i_qoi].domains)))]
+                for i_gpc, d in enumerate(np.unique(megpc[i_qoi].domains)):
+                    eps_domain[d] = megpc[i_qoi].validate(coeffs=coeffs[i_qoi],
+                                                          results=res,
+                                                          domain=d,
+                                                          output_idx=output_idx_passed_validation)
+
+                if not self.options["adaptive_sampling"] or (0 < (eps_pre-eps)/eps < 0.01):
+                    break
+
+                if eps > self.options["eps"]:
+                    # extend grid by 10% of number of grid points
+                    n_grid_new = int(np.ceil(1.1*grid.n_grid))
+                    iprint("Extending grid from {} to {} by {} sampling points".format(
+                        grid.n_grid, n_grid_new, n_grid_new - grid.n_grid),
+                        tab=0, verbose=self.options["verbose"])
+                    grid.extend_random_grid(n_grid_new=n_grid_new)
+
+                eps_pre = eps
+
+            # save data
+            if self.options["fn_results"] is not None:
+
+                with h5py.File(fn_results + ".hdf5", "a") as f:
+
+                    try:
+                        fn_session = f["misc/fn_session"]
+
+                    except KeyError:
+                        f.create_dataset("misc/fn_session",
+                                         data=np.array([os.path.split(self.options["fn_session"])[1]]).astype("|S"))
+                        f.create_dataset("misc/fn_session_folder",
+                                         data=np.array([self.options["fn_session_folder"]]).astype("|S"))
+
+                    for i_gpc in range(megpc[i_qoi].n_gpc):
+                        f.create_dataset("error" + hdf5_subfolder + "/dom_" + str(i_gpc),
+                                         data=eps_domain[i_gpc],
+                                         maxshape=None, dtype="float64")
+
+                        f.create_dataset("coeffs" + hdf5_subfolder + "/dom_" + str(i_gpc),
+                                         data=coeffs[i_qoi][i_gpc],
+                                         maxshape=None, dtype="float64")
+
+                    f.create_dataset("domains" + hdf5_subfolder,
+                                     data=megpc[i_qoi].domains,
+                                     maxshape=None, dtype="int64")
+
+                    for i_gpc in range(megpc[i_qoi].n_gpc):
+                        f.create_dataset("gpc_matrix" + hdf5_subfolder + "/dom_" + str(i_gpc),
+                                         data=megpc[i_qoi].gpc[i_gpc].gpc_matrix,
+                                         maxshape=None, dtype="float64")
+
+                        if megpc[i_qoi].gpc[0].gpc_matrix_gradient is not None:
+                            if self.options["gradient_enhanced"]:
+                                f.create_dataset("gpc_matrix_gradient" + hdf5_subfolder + "/dom_" + str(i_gpc),
+                                                 data=megpc[i_qoi].gpc[i_gpc].gpc_matrix_gradient,
+                                                 maxshape=None, dtype="float64")
+
+            i_qoi += 1
+
+        if self.options["fn_results"] is not None:
+
+            with h5py.File(fn_results + ".hdf5", "a") as f:
+
+                try:
+                    del f["grid/coords"]
+                    del f["grid/coords_norm"]
+                    del f["grid/coords_gradient"]
+                    del f["grid/coords_gradient_norm"]
+
+                except KeyError:
+                    pass
+
+                f.create_dataset("grid/coords", data=grid.coords,
+                                 maxshape=None, dtype="float64")
+                f.create_dataset("grid/coords_norm", data=grid.coords_norm,
+                                 maxshape=None, dtype="float64")
+
+                if grid.coords_gradient is not None:
+                    f.create_dataset("grid/coords_gradient",
+                                     data=grid.coords_gradient,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("grid/coords_gradient_norm",
+                                     data=grid.coords_gradient_norm,
+                                     maxshape=None, dtype="float64")
+
+                f.create_dataset("model_evaluations/results", data=res,
+                                 maxshape=None, dtype="float64")
+                if grad_res_3D is not None:
+                    f.create_dataset("model_evaluations/gradient_results", data=ten2mat(grad_res_3D),
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("model_evaluations/gradient_results_idx", data=megpc[-1].gradient_idx,
+                                     maxshape=None, dtype="int64")
+
+                f.create_dataset("misc/error_type", data=self.options["error_type"])
+
+                if megpc[0].validation is not None:
+                    f.create_dataset("validation/model_evaluations/results", data=megpc[0].validation.results,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("validation/grid/coords", data=megpc[0].validation.grid.coords,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("validation/grid/coords_norm", data=megpc[0].validation.grid.coords_norm,
+                                     maxshape=None, dtype="float64")
+
+        com.close()
+
+        return megpc, coeffs, res
+
+
+class MEStatic_IO(Algorithm):
+    """
+    Multi-Element Static gPC algorithm using precomputed IO data
+
+    Parameters
+    ----------
+    parameters: OrderedDict containing the RandomParameter class instances
+        Dictionary (ordered) containing the properties of the random parameters
+    options["order"]: list of int [dim]
+        Maximum individual expansion order [order_1, order_2, ..., order_dim].
+        Generates individual polynomials also if maximum expansion order in order_max is exceeded
+    options["order_max"]: int
+        Maximum global expansion order.
+        The maximum expansion order considers the sum of the orders of combined polynomials together with the
+        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
+        monomial orders.
+    options["order_max_norm"]: float
+        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
+        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
+        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
+        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
+    options["interaction_order"]: int
+        Number of random variables, which can interact with each other.
+        All polynomials are ignored, which have an interaction order greater than the specified
+    options["qoi"] : int or str, optional, default: 0
+        Choose for which QOI the projection is determined for. The other QOIs use the same projection.
+        Alternatively, the projection can be determined for every QOI independently (qoi_index or "all").
+    options["classifier"] : str, optional, default: "learning"
+        Classification algorithm to subdivide parameter domain.
+        - "learning" ... ClassifierLearning algorithm based on Unsupervised and supervised learning
+    options["classifier_options"] : dict, optional, default: default settings
+        Options of classifier
+    grid: Grid object instance
+        Grid object to use for static gPC (Random, SparseGrid, TensorGrid) containing the parameter values, where the
+        output relations were calculated
+    results: ndarray of float [N_grid x N_qoi]
+        Model output at each grid point for each QOI
+
+    Notes
+    -----
+    .. [1] Blatman, G., & Sudret, B. (2011). Adaptive sparse polynomial chaos expansion based on least angle
+       regression. Journal of Computational Physics, 230(6), 2345-2367.
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> # initialize static gPC algorithm
+    >>> algorithm = pygpc.MEStatic_IO(parameters=parameters, options=options, results=results, grid=grid)
+    >>> # run algorithm
+    >>> gpc, coeffs, results = algorithm.run()
+    """
+
+    def __init__(self, parameters, options, results, grid, validation=None):
+        """
+        Constructor; Initializes multi-element static gPC algorithm
+        """
+        # create dummy model
+        model = Dummy()
+
+        # create dummy problem
+        problem = Problem(model, parameters)
+
+        super(MEStatic_IO, self).__init__(problem=problem, options=options, validation=validation, grid=grid)
+        self.res = results
+
+        # check contents of settings dict and set defaults
+        if "order" not in self.options.keys():
+            raise AssertionError("Please specify 'order'=[order_1, order_2, ..., order_dim] in options dictionary")
+
+        if "order_max" not in self.options.keys():
+            raise AssertionError("Please specify 'order_max' in options dictionary")
+
+        if "interaction_order" not in self.options.keys():
+            self.options["interaction_order"] = self.problem.dim
+
+        if "order_max_norm" not in self.options.keys():
+            self.options["order_max_norm"] = 1.
+
+        if "qoi" not in self.options.keys():
+            self.options["qoi"] = 0
+
+        if "classifier" not in self.options.keys():
+            self.options["classifier"] = "learning"
+
+        if "classifier_options" not in self.options.keys():
+            self.options["classifier_options"] = None
+
+        if self.options["qoi"] == "all":
+            self.qoi_specific = True
+        else:
+            self.qoi_specific = False
+
+        # if self.options["error_type"] != "loocv":
+            # self.options["error_type"] = "loocv"
+            # warnings.warn("Changing error calculation type to loocv ...")
+
+    def run(self):
+        """
+        Runs Multi-Element Static gPC algorithm using precomputed IO data to construct gPC approximation.
+
+        Returns
+        -------
+        megpc : Multi-element GPC object instance
+            MEGPC object containing all information i.e., Problem, Model, Grid, Basis, RandomParameter instances
+        coeffs: list of ndarray of float [n_gpc][n_basis x n_out]
+            GPC coefficients
+        res : ndarray of float [n_grid x n_out]
+            Simulation results at n_grid points of the n_out output variables
+        """
+        if self.options["fn_results"] is not None:
+            fn_results = os.path.splitext(self.options["fn_results"])[0]
+
+            if os.path.exists(fn_results + ".hdf5"):
+                os.remove(fn_results + ".hdf5")
+        else:
+            fn_results = None
+
+        megpc = []
+        coeffs = []
+        i_grid = 0
+        i_qoi = 0
+
+        if self.options["qoi"] is not None and self.options["qoi"] != "all":
+            q_idx = self.options["qoi"]
+            qoi_idx = [q_idx]
+        else:
+            qoi_idx = np.arange(1)
+            q_idx = qoi_idx[0]
+
+        n_qoi = len(qoi_idx)
+
+        while i_qoi < n_qoi:
+            q_idx = qoi_idx[i_qoi]
+            print_str = "Determining gPC approximation for QOI #{}:".format(q_idx)
+            iprint(print_str, tab=0, verbose=self.options["verbose"])
+            iprint("=" * len(print_str), tab=0, verbose=self.options["verbose"])
+            megpc.append(0)
+            coeffs.append(0)
+
+            # Create MEGPC object
+            megpc[i_qoi] = MEGPC(problem=self.problem,
+                                 options=self.options,
+                                 validation=self.validation)
+
+            if i_qoi == 0 and i_grid == 0:
+                if self.options["qoi"] == "all":
+                    qoi_idx = np.arange(self.res.shape[1])
+                    n_qoi = len(qoi_idx)
+
+            # crop results to considered qoi
+            if self.options["qoi"] != "all":
+                res = copy.deepcopy(self.res)
+                hdf5_subfolder = ""
+                output_idx_passed_validation = None
+            else:
+                res = self.res[:, q_idx][:, np.newaxis]
+                hdf5_subfolder = "/qoi_" + str(q_idx)
+                output_idx_passed_validation = q_idx
+
+            # Write grid in gpc object
+            megpc[i_qoi].grid = copy.deepcopy(self.grid)
+
+            # determine gpc domains
+            megpc[i_qoi].init_classifier(coords=megpc[i_qoi].grid.coords_norm,
+                                         results=self.res[:, q_idx][:, np.newaxis],
+                                         algorithm=self.options["classifier"],
+                                         options=self.options["classifier_options"])
+
+            # initialize sub-gPCs
+            for d in np.unique(megpc[i_qoi].domains):
+                megpc[i_qoi].add_sub_gpc(problem=megpc[i_qoi].problem,
+                                         order=[self.options["order"][0] for _ in range(megpc[i_qoi].problem.dim)],
+                                         order_max=self.options["order_max"],
+                                         order_max_norm=self.options["order_max_norm"],
+                                         interaction_order=self.options["interaction_order"],
+                                         interaction_order_current=self.options["interaction_order"],
+                                         options=self.options,
+                                         domain=d,
+                                         validation=None)
+
+            # assign grids to sub-gPCs (rotate sub-grids in case of projection)
+            megpc[i_qoi].assign_grids()
+
+            # Initialize gpc matrices
+            megpc[i_qoi].init_gpc_matrices()
+
+            # Compute gpc coefficients
+            coeffs[i_qoi] = megpc[i_qoi].solve(results=res,
+                                               solver=self.options["solver"],
+                                               settings=self.options["settings"],
+                                               verbose=self.options["verbose"])
+
+             # validate gpc approximation (determine nrmsd or loocv specified in options["error_type"])
+            eps = megpc[i_qoi].validate(coeffs=coeffs[i_qoi], results=res)
+
+            iprint("-> {} {} error = {}".format(self.options["error_norm"],
+                                                self.options["error_type"],
+                                                eps), tab=0, verbose=self.options["verbose"])
+
+            # domain specific error
+            eps_domain = [0 for _ in range(len(np.unique(megpc[i_qoi].domains)))]
+            for i_gpc, d in enumerate(np.unique(megpc[i_qoi].domains)):
+                eps_domain[d] = megpc[i_qoi].validate(coeffs=coeffs[i_qoi],
+                                                      results=res,
+                                                      domain=d,
+                                                      output_idx=output_idx_passed_validation)
+
+            # save data
+            if self.options["fn_results"] is not None:
+
+                with h5py.File(fn_results + ".hdf5", "a") as f:
+
+                    try:
+                        fn_session = f["misc/fn_session"]
+
+                    except KeyError:
+                        f.create_dataset("misc/fn_session",
+                                         data=np.array([os.path.split(self.options["fn_session"])[1]]).astype("|S"))
+                        f.create_dataset("misc/fn_session_folder",
+                                         data=np.array([self.options["fn_session_folder"]]).astype("|S"))
+
+                    for i_gpc in range(megpc[i_qoi].n_gpc):
+                        f.create_dataset("error" + hdf5_subfolder + "/dom_" + str(i_gpc),
+                                         data=eps_domain[i_gpc],
+                                         maxshape=None, dtype="float64")
+
+                        f.create_dataset("coeffs" + hdf5_subfolder + "/dom_" + str(i_gpc),
+                                         data=coeffs[i_qoi][i_gpc],
+                                         maxshape=None, dtype="float64")
+
+                    f.create_dataset("domains" + hdf5_subfolder,
+                                     data=megpc[i_qoi].domains,
+                                     maxshape=None, dtype="int64")
+
+                    for i_gpc in range(megpc[i_qoi].n_gpc):
+                        f.create_dataset("gpc_matrix" + hdf5_subfolder + "/dom_" + str(i_gpc),
+                                         data=megpc[i_qoi].gpc[i_gpc].gpc_matrix,
+                                         maxshape=None, dtype="float64")
+
+                        if megpc[i_qoi].gpc[0].gpc_matrix_gradient is not None:
+                            if self.options["gradient_enhanced"]:
+                                f.create_dataset("gpc_matrix_gradient" + hdf5_subfolder + "/dom_" + str(i_gpc),
+                                                 data=megpc[i_qoi].gpc[i_gpc].gpc_matrix_gradient,
+                                                 maxshape=None, dtype="float64")
+
+            i_qoi += 1
+
+        if self.options["fn_results"] is not None:
+
+            with h5py.File(fn_results + ".hdf5", "a") as f:
+
+                try:
+                    del f["grid/coords"]
+                    del f["grid/coords_norm"]
+                    del f["grid/coords_gradient"]
+                    del f["grid/coords_gradient_norm"]
+
+                except KeyError:
+                    pass
+
+                f.create_dataset("grid/coords", data=self.grid.coords,
+                                 maxshape=None, dtype="float64")
+                f.create_dataset("grid/coords_norm", data=self.grid.coords_norm,
+                                 maxshape=None, dtype="float64")
+
+                if self.grid.coords_gradient is not None:
+                    f.create_dataset("grid/coords_gradient",
+                                     data=self.grid.coords_gradient,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("grid/coords_gradient_norm",
+                                     data=self.grid.coords_gradient_norm,
+                                     maxshape=None, dtype="float64")
+
+                f.create_dataset("model_evaluations/results", data=self.res,
+                                 maxshape=None, dtype="float64")
+
+                f.create_dataset("misc/error_type", data=self.options["error_type"])
+
+                if megpc[0].validation is not None:
+                    f.create_dataset("validation/model_evaluations/results", data=megpc[0].validation.results,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("validation/grid/coords", data=megpc[0].validation.grid.coords,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("validation/grid/coords_norm", data=megpc[0].validation.grid.coords_norm,
+                                     maxshape=None, dtype="float64")
+
+        return megpc, coeffs, self.res
+
+
+class StaticProjection(Algorithm):
+    """
+    Static gPC algorithm using Basis Projection approach
+
+    Parameters
+    ----------
+    problem : Problem object
+        Object instance of gPC problem to investigate
+    options["method"]: str
+        GPC method to apply ['Reg', 'Quad']
+    options["order"]: int
+        Expansion order, each projected variable \\eta is expanded to.
+        Generates individual polynomials also if maximum expansion order in order_max is exceeded
+    options["order_max"]: int
+        Maximum global expansion order.
+        The maximum expansion order considers the sum of the orders of combined polynomials together with the
+        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
+        monomial orders.
+    options["order_max_norm"]: float
+        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
+        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
+        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
+        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
+    options["interaction_order"]: int
+        Number of random variables, which can interact with each other.
+        All polynomials are ignored, which have an interaction order greater than the specified
+    options["qoi"] : int or str, optional, default: 0
+        Choose for which QOI the projection is determined for. The other QOIs use the same projection.
+        Alternatively, the projection can be determined for every QOI independently (qoi_index or "all").
+    options["n_grid"] : float, optional, default: 10
+        Number of initial grid points to determine gradient and projection matrix
+
+    Notes
+    -----
+    .. [1] Blatman, G., & Sudret, B. (2011). Adaptive sparse polynomial chaos expansion based on least angle
+       regression. Journal of Computational Physics, 230(6), 2345-2367.
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> # initialize static gPC algorithm
+    >>> algorithm = pygpc.StaticProjection(problem=problem, options=options)
+    >>> # run algorithm
+    >>> gpc, coeffs, results = algorithm.run
+    """
+
+    def __init__(self, problem, options, validation=None, grid=None):
+        """
+        Constructor; Initializes static gPC algorithm
+        """
+        super(StaticProjection, self).__init__(problem=problem, options=options, validation=validation, grid=grid)
+
+        # check contents of settings dict and set defaults
+        if "method" not in self.options.keys():
+            raise AssertionError("Please specify 'method' with either 'reg' or 'quad' in options dictionary")
+
+        if "order" not in self.options.keys():
+            raise AssertionError("Please specify 'order'=[order_1, order_2, ..., order_dim] in options dictionary")
+
+        if "order_max" not in self.options.keys():
+            raise AssertionError("Please specify 'order_max' in options dictionary")
+
+        if "interaction_order" not in self.options.keys():
+            self.options["interaction_order"] = self.problem.dim
+
+        if "order_max_norm" not in self.options.keys():
+            self.options["order_max_norm"] = 1.
+
+        if "n_grid" not in self.options.keys():
+            self.options["n_grid"] = 10
+
+        if "qoi" not in self.options.keys():
+            self.options["qoi"] = 0
+
+        if self.options["qoi"] == "all":
+            self.qoi_specific = True
+        else:
+            self.qoi_specific = False
+
+    def run(self):
+        """
+        Runs static gPC algorithm using Projection to solve problem.
+
+        Returns
+        -------
+        gpc : GPC object instance
+            GPC object containing all information i.e., Problem, Model, Grid, Basis, RandomParameter instances
+        coeffs: list of ndarray of float [n_qoi][n_basis x n_out]
+            GPC coefficients for different qoi
+        res : ndarray of float [n_grid x n_out]
+            Simulation results at n_grid points of the n_out output variables
+        """
+
+        if self.options["fn_results"] is not None:
+            fn_results = os.path.splitext(self.options["fn_results"])[0]
+
+            if os.path.exists(fn_results + ".hdf5"):
+                os.remove(fn_results + ".hdf5")
+        else:
+            fn_results = None
+
+        grad_res_3D = None
+        grad_res_3D_all = None
+        gradient_idx = None
+        res_all_list = []
+
+        n_grid = self.options["n_grid"]
+
+        # make initial grid to determine gradients and projection matrix. By default, it is an LHS (ese) grid
+        if self.grid is not None:
+            print(f"Using user-predefined grid with n_grid={self.grid.n_grid}")
+            grid_original = self.options["grid"](parameters_random=self.problem.parameters_random,
+                                                 coords=self.grid.coords,
+                                                 coords_norm=self.grid.coords_norm,
+                                                 coords_gradient=self.grid.coords_gradient,
+                                                 coords_gradient_norm=self.grid.coords_gradient_norm,
+                                                 options=self.options["grid_options"])
+        elif self.options["grid"] == Random or self.options["grid"] == GP:
+            print(f"Creating initial grid ({self.options['grid'].__name__}) with n_grid={int(n_grid)}")
+            grid_original = self.options["grid"](parameters_random=self.problem.parameters_random,
+                                   n_grid=n_grid,
+                                   options=self.options["grid_options"])
+        else:
+            print(f"Creating initial grid ({self.options['grid'].__name__}) with n_grid={int(n_grid)}")
+            grid_original = LHS(parameters_random=self.problem.parameters_random,
+                                n_grid=n_grid,
+                                options={"criterion": "ese",
+                                         "seed": self.options["seed"]})
+
+        # Initialize parallel Computation class
+        com = Computation(n_cpu=self.n_cpu, matlab_model=self.options["matlab_model"])
+
+        # Set up reduced gPC
+        self.problem_reduced = []
+        gpc = []
+        coeffs = []
+        eps = self.options["eps"] + 1
+        i_grid = 0
+        i_qoi = 0
+
+        if self.options["qoi"] is not None and self.options["qoi"] != "all":
+            q_idx = self.options["qoi"]
+            qoi_idx = [q_idx]
+        else:
+            qoi_idx = np.arange(1)
+            q_idx = qoi_idx[0]
+
+        n_qoi = len(qoi_idx)
+
+        while i_qoi < n_qoi:
+            q_idx = qoi_idx[i_qoi]
+            print_str = "Determining gPC approximation for QOI #{}:".format(q_idx)
+            iprint(print_str, tab=0, verbose=self.options["verbose"])
+            iprint("=" * len(print_str), tab=0, verbose=self.options["verbose"])
+            self.problem_reduced.append(0)
+            gpc.append(0)
+            coeffs.append(0)
+            eps_pre = eps + 1
+
+            # determine gpc approximation and determine error (increase grid size in case of adaptive sampling)
+            while eps > self.options["eps"]:
+                # run simulations
+                if i_grid < grid_original.n_grid:
+                    iprint("Performing {} simulations!".format(grid_original.n_grid - i_grid),
+                           tab=0, verbose=self.options["verbose"])
+
+                    start_time = time.time()
+
+                    res_all_list.append(com.run(model=self.problem.model,
+                                                problem=self.problem,
+                                                coords=grid_original.coords[i_grid:grid_original.n_grid, :],
+                                                coords_norm=grid_original.coords_norm[i_grid:grid_original.n_grid, :],
+                                                i_iter=self.options["order_max"],
+                                                i_subiter=self.options["interaction_order"],
+                                                fn_results=None,
+                                                print_func_time=self.options["print_func_time"],
+                                                verbose=self.options["verbose"]))
+
+                    res_all = np.vstack(res_all_list)
+
+                    if i_qoi == 0 and i_grid == 0:
+                        if self.options["qoi"] == "all":
+                            qoi_idx = np.arange(res_all.shape[1])
+                            n_qoi = len(qoi_idx)
+
+                    i_grid = grid_original.n_grid
+
+                    iprint('Total function evaluation: ' + str(time.time() - start_time) + ' sec',
+                           tab=0, verbose=self.options["verbose"])
+
+                    # Determine gradient [n_grid x n_out x dim]
+                    start_time = time.time()
+
+                    grad_res_3D_all, gradient_idx = get_gradient(model=self.problem.model,
+                                                                 problem=self.problem,
+                                                                 grid=grid_original,
+                                                                 results=res_all,
+                                                                 com=com,
+                                                                 method="FD_fwd",
+                                                                 gradient_results_present=grad_res_3D_all,
+                                                                 gradient_idx_skip=gradient_idx,
+                                                                 i_iter=self.options["order_max"],
+                                                                 i_subiter=self.options["interaction_order"],
+                                                                 print_func_time=self.options["print_func_time"],
+                                                                 dx=self.options["gradient_calculation_options"]["dx"],
+                                                                 distance_weight=
+                                                                 self.options["gradient_calculation_options"][
+                                                                     "distance_weight"],
+                                                                 verbose=self.options["verbose"])
+
+                    iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
+                           tab=0, verbose=self.options["verbose"])
+
+                    # check validity of results and resample in case the model could not be evaluated at some sampling points
+                    res_all, grad_res_3D_all, gradient_idx, grid_original = self.check_results(results=res_all,
+                                                                                               gradient_results=grad_res_3D_all,
+                                                                                               gradient_results_idx=gradient_idx,
+                                                                                               grid=grid_original,
+                                                                                               com=com)
+
+                # crop results to considered qoi
+                if self.options["qoi"] != "all":
+                    res = copy.deepcopy(res_all)
+                    grad_res_3D = copy.deepcopy(grad_res_3D_all)
+                    hdf5_subfolder = ""
+
+                else:
+                    res = res_all[:, q_idx][:, np.newaxis]
+                    grad_res_3D = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
+                    hdf5_subfolder = "/qoi_" + str(q_idx)
+
+                # Determine projection matrix
+                p_matrix, p_matrix_complete = determine_projection_matrix(gradient_results=grad_res_3D_all[:, q_idx, :],
+                                                                          lambda_eps=self.options["lambda_eps_gradient"])
+                p_matrix_norm = np.sum(np.abs(p_matrix), axis=1)
+
+                dim_reduced = p_matrix.shape[0]
+                parameters_reduced = OrderedDict()
+
+                for i in range(dim_reduced):
+                    parameters_reduced["n{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
+
+                self.problem_reduced[i_qoi] = Problem(model=self.problem.model, parameters=parameters_reduced)
+
+                # Create reduced gPC object
+                gpc[i_qoi] = Reg(problem=self.problem_reduced[i_qoi],
+                                 order=[self.options["order"][0] for _ in range(dim_reduced)],
+                                 order_max=self.options["order_max"],
+                                 order_max_norm=self.options["order_max_norm"],
+                                 interaction_order=self.options["interaction_order"],
+                                 interaction_order_current=self.options["interaction_order"],
+                                 options=self.options,
+                                 validation=self.validation)
+
+                # save original problem in gpc object
+                gpc[i_qoi].problem_original = self.problem
+
+                # save projection matrix in gPC object
+                gpc[i_qoi].p_matrix = copy.deepcopy(p_matrix)
+                gpc[i_qoi].p_matrix_norm = copy.deepcopy(p_matrix_norm)
+
+                # re-initialize grid in case of [L1, L1_LHS, LHS_L1, FIM] because initial grid was Random or LHS (ese)
+                if self.options["grid"] in [L1, L1_LHS, LHS_L1, FIM]:
+                    grid_original = self.options["grid"](parameters_random=self.problem.parameters_random,
+                                                         coords=grid_original.coords,
+                                                         coords_norm=grid_original.coords_norm,
+                                                         coords_gradient=grid_original.coords_gradient,
+                                                         coords_gradient_norm=grid_original.coords_gradient_norm,
+                                                         options=self.options["grid_options"],
+                                                         gpc=gpc[i_qoi])
+
+                # copy grid to gPC object and initialize transformed grid
+                gpc[i_qoi].grid_original = copy.deepcopy(grid_original)
+                gpc[i_qoi].grid = project_grid(grid=grid_original, p_matrix=p_matrix, mode="reduce")
+                gpc[i_qoi].options = copy.deepcopy(self.options)
+
+                # Initialize gpc matrix
+                gpc[i_qoi].init_gpc_matrix(gradient_idx=gradient_idx)
+
+                # Someone might not use the gradient to determine the gpc coeffs
+                if self.options["gradient_enhanced"]:
+                    grad_res_3D_passed = grad_res_3D
+                else:
+                    grad_res_3D_passed = None
+
+                # Compute gpc coefficients
+                coeffs[i_qoi] = gpc[i_qoi].solve(results=res,
+                                                 gradient_results=grad_res_3D_passed,
+                                                 solver=self.options["solver"],
+                                                 settings=self.options["settings"],
+                                                 verbose=self.options["verbose"])
+
+                # validate gpc approximation (determine nrmsd or loocv specified in options["error_type"])
+                if self.options["error_type"] == "nrmsd" and gpc[0].validation is None:
+                    gpc[0].create_validation_set(n_samples=self.options["n_samples_validation"],
+                                                 n_cpu=self.options["n_cpu"])
+                elif self.options["error_type"] == "nrmsd" and gpc[0].validation is not None:
+                    gpc[i_qoi].validation = copy.deepcopy(gpc[0].validation)
+
+                eps = gpc[i_qoi].validate(coeffs=coeffs[i_qoi], results=res, gradient_results=grad_res_3D_passed)
+
+                iprint("-> {} {} error = {}".format(self.options["error_norm"],
+                                                    self.options["error_type"],
+                                                    eps), tab=0, verbose=self.options["verbose"])
+
+                if not self.options["adaptive_sampling"] or (0 < (eps_pre-eps)/eps < 0.01):
+                    break
+
+                if eps > self.options["eps"]:
+                    # extend grid by 5% of number of basis functions and restart loop
+                    n_grid_new = int(np.ceil(grid_original.n_grid + 5e-2 * gpc[i_qoi].basis.n_basis))
+                    iprint("Extending grid from {} to {} by {} sampling points".format(
+                        grid_original.n_grid, n_grid_new, n_grid_new - grid_original.n_grid),
+                        tab=0, verbose=self.options["verbose"])
+                    grid_original.extend_random_grid(n_grid_new=n_grid_new)
+
+                eps_pre = eps
+
+            # save gpc objects and gpc coeffs
+            if self.options["fn_results"] is not None:
+
+                with h5py.File(fn_results + ".hdf5", "a") as f:
+
+                    try:
+                        fn_session = f["misc/fn_session"]
+
+                    except KeyError:
+                        f.create_dataset("misc/fn_session",
+                                         data=np.array([os.path.split(self.options["fn_session"])[1]]).astype("|S"))
+                        f.create_dataset("misc/fn_session_folder",
+                                         data=np.array([self.options["fn_session_folder"]]).astype("|S"))
+
+                    f.create_dataset("error" + hdf5_subfolder,
+                                     data=eps,
+                                     maxshape=None, dtype="float64")
+
+                    f.create_dataset("coeffs" + hdf5_subfolder,
+                                     data=coeffs[i_qoi],
+                                     maxshape=None, dtype="float64")
+
+                    f.create_dataset("gpc_matrix" + hdf5_subfolder,
+                                     data=gpc[i_qoi].gpc_matrix,
+                                     maxshape=None, dtype="float64")
+
+                    if gpc[i_qoi].gpc_matrix_gradient is not None:
+                        f.create_dataset("gpc_matrix_gradient" + hdf5_subfolder,
+                                         data=gpc[i_qoi].gpc_matrix_gradient,
+                                         maxshape=None, dtype="float64")
+
+                    f.create_dataset("p_matrix" + hdf5_subfolder,
+                                     data=gpc[i_qoi].p_matrix,
+                                     maxshape=None, dtype="float64")
+
+            i_qoi += 1
+
+        if self.options["fn_results"] is not None:
+
+            with h5py.File(fn_results + ".hdf5", "a") as f:
+                f.create_dataset("grid/coords", data=grid_original.coords,
+                                 maxshape=None, dtype="float64")
+                f.create_dataset("grid/coords_norm", data=grid_original.coords_norm,
+                                 maxshape=None, dtype="float64")
+
+                if grid_original.coords_gradient is not None:
+                    f.create_dataset("grid/coords_gradient",
+                                     data=grid_original.coords_gradient,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("grid/coords_gradient_norm",
+                                     data=grid_original.coords_gradient_norm,
+                                     maxshape=None, dtype="float64")
+
+                f.create_dataset("model_evaluations/results", data=res,
+                                 maxshape=None, dtype="float64")
+                if grad_res_3D is not None:
+                    f.create_dataset("model_evaluations/gradient_results", data=ten2mat(grad_res_3D),
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("model_evaluations/gradient_results_idx", data=gpc[-1].gradient_idx,
+                                     maxshape=None, dtype="int64")
+
+                f.create_dataset("misc/error_type", data=self.options["error_type"])
+
+                if gpc[0].validation is not None:
+                    f.create_dataset("validation/model_evaluations/results", data=gpc[0].validation.results,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("validation/grid/coords", data=gpc[0].validation.grid.coords,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("validation/grid/coords_norm", data=gpc[0].validation.grid.coords_norm,
+                                     maxshape=None, dtype="float64")
+
+        com.close()
+
+        return gpc, coeffs, res_all
+
+
+class MEStaticProjection(Algorithm):
+    """
+    Static gPC algorithm using Basis Projection approach
+
+    Parameters
+    ----------
+    problem : Problem object
+        Object instance of gPC problem to investigate
+    options["order"]: int
+        Expansion order, each projected variable \\eta is expanded to.
+        Generates individual polynomials also if maximum expansion order in order_max is exceeded
+    options["order_max"]: int
+        Maximum global expansion order.
+        The maximum expansion order considers the sum of the orders of combined polynomials together with the
+        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
+        monomial orders.
+    options["interaction_order"]: int
+        Number of random variables, which can interact with each other.
+        All polynomials are ignored, which have an interaction order greater than the specified
+    options["qoi"] : int or str, optional, default: 0
+        Choose for which QOI the projection is determined for. The other QOIs use the same projection.
+        Alternatively, the projection can be determined for every QOI independently (qoi_index or "all").
+    options["n_grid_gradient"] : float, optional, default: 10
+        Number of initial grid points to determine gradient and projection matrix
+    options["classifier"] : str, optional, default: "learning"
+        Classification algorithm to subdivide parameter domain.
+        - "learning" ... ClassifierLearning algorithm based on Unsupervised and supervised learning
+    options["classifier_options"] : dict, optional, default: default settings
+        Options of classifier
+
+    Notes
+    -----
+    .. [1] Blatman, G., & Sudret, B. (2011). Adaptive sparse polynomial chaos expansion based on least angle
+       regression. Journal of Computational Physics, 230(6), 2345-2367.
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> # initialize static gPC algorithm
+    >>> algorithm = pygpc.MEStaticProjection(problem=problem, options=options)
+    >>> # run algorithm
+    >>> gpc, coeffs, results = algorithm.run
+    """
+
+    def __init__(self, problem, options, validation=None, grid=None):
+        """
+        Constructor; Initializes static gPC algorithm
+        """
+        super(MEStaticProjection, self).__init__(problem=problem, options=options, validation=validation, grid=grid)
+
+        # check contents of settings dict and set defaults
+        if "method" not in self.options.keys():
+            raise AssertionError("Please specify 'method' with either 'reg' or 'quad' in options dictionary")
+
+        if "order" not in self.options.keys():
+            raise AssertionError("Please specify 'order'=[order_1, order_2, ..., order_dim] in options dictionary")
+
+        if "order_max" not in self.options.keys():
+            raise AssertionError("Please specify 'order_max' in options dictionary")
+
+        if "interaction_order" not in self.options.keys():
+            self.options["interaction_order"] = self.problem.dim
+
+        if "order_max_norm" not in self.options.keys():
+            self.options["order_max_norm"] = 1.
+
+        if "n_grid_gradient" not in self.options.keys():
+            self.options["n_grid_gradient"] = 10
+
+        if "qoi" not in self.options.keys():
+            self.options["qoi"] = 0
+
+        if "classifier" not in self.options.keys():
+            self.options["classifier"] = "learning"
+
+        if "classifier_options" not in self.options.keys():
+            self.options["classifier_options"] = None
+
+        if self.options["qoi"] == "all":
+            self.qoi_specific = True
+        else:
+            self.qoi_specific = False
+
+    def run(self):
+        """
+        Runs static multi-element gPC algorithm with projection.
+
+        Returns
+        -------
+        megpc : MEGPC object instance
+            MEGPC object containing all information i.e., Problem, Model, Grid, Basis, RandomParameter instances
+            and sub-gPCs
+        coeffs: list of list of ndarray of float [n_qoi][n_gpc][n_basis x n_out]
+            GPC coefficients of different qoi and sub-gPCs
+        res : ndarray of float [n_grid x n_out]
+            Simulation results at n_grid points of the n_out output variables
+        """
+
+        if self.options["fn_results"] is not None:
+            fn_results = os.path.splitext(self.options["fn_results"])[0]
+
+            if os.path.exists(fn_results + ".hdf5"):
+                os.remove(fn_results + ".hdf5")
+        else:
+            fn_results = None
+
+        grad_res_3D = None
+        grad_res_3D_all = None
+        gradient_idx = None
+        res_all_list = []
+
+        # make initial random grid to determine gradients and projection matrix
+        if self.grid is not None:
+            print(f"Using user-predefined grid with n_grid={self.grid.n_grid}")
+            grid = self.options["grid"](parameters_random=self.problem.parameters_random,
+                                        coords=self.grid.coords,
+                                        coords_norm=self.grid.coords_norm,
+                                        coords_gradient=self.grid.coords_gradient,
+                                        coords_gradient_norm=self.grid.coords_gradient_norm,
+                                        options=self.options["grid_options"])
+
+        elif self.options["grid"] == Random or self.options["grid"] == LHS or self.options["grid"] == GP:
+            print(f"Creating initial grid ({self.options['grid'].__name__}) with n_grid={int(self.options['n_grid'])}")
+            grid = self.options["grid"](parameters_random=self.problem.parameters_random,
+                                        n_grid=self.options["n_grid"],
+                                        options=self.options["grid_options"])
+
+        elif self.options["grid"] == L1 or self.options["grid"] == L1_LHS or self.options["grid"] == LHS_L1 \
+                or self.options["grid"] == FIM:
+            raise NotImplementedError("Grid type not possible for MEStaticProjection algorithm."
+                                      "Please use either 'Random' or 'LHS'.")
+
+        # Initialize parallel Computation class
+        com = Computation(n_cpu=self.n_cpu, matlab_model=self.options["matlab_model"])
+
+        megpc = []
+        coeffs = []
+        eps = self.options["eps"] + 1
+        i_grid = 0
+        i_qoi = 0
+
+        if self.options["qoi"] is not None and self.options["qoi"] != "all":
+            q_idx = self.options["qoi"]
+            qoi_idx = [q_idx]
+        else:
+            qoi_idx = np.arange(1)
+            q_idx = qoi_idx[0]
+
+        n_qoi = len(qoi_idx)
+
+        res_all = np.array([])
+
+        while i_qoi < n_qoi:
+            q_idx = qoi_idx[i_qoi]
+            print_str = "Determining gPC approximation for QOI #{}:".format(q_idx)
+            iprint(print_str, tab=0, verbose=self.options["verbose"])
+            iprint("=" * len(print_str), tab=0, verbose=self.options["verbose"])
+            megpc.append(0)
+            coeffs.append(0)
+
+            # Create MEGPC object
+            megpc[i_qoi] = MEGPC(problem=self.problem,
+                                 options=self.options,
+                                 validation=self.validation)
+
+            eps = self.options["eps"] + 1
+
+            # determine gpc approximation and determine error (increase grid size in case of adaptive sampling)
+            while eps > self.options["eps"]:
+                if i_grid < grid.n_grid:
+                    # run simulations
+                    iprint("Performing {} simulations!".format(grid.n_grid - i_grid),
+                           tab=0, verbose=self.options["verbose"])
+
+                    start_time = time.time()
+
+                    res_new = com.run(model=self.problem.model,
+                                      problem=self.problem,
+                                      coords=grid.coords[i_grid:grid.n_grid, :],
+                                      coords_norm=grid.coords_norm[i_grid:grid.n_grid, :],
+                                      i_iter=self.options["order_max"],
+                                      i_subiter=self.options["interaction_order"],
+                                      fn_results=None,
+                                      print_func_time=self.options["print_func_time"],
+                                      verbose=self.options["verbose"])
+
+                    if len(res_all) > 0:
+                        res_all = np.vstack(res_all, res_new)
+                    else:
+                        res_all = res_new
+
+                    if i_qoi == 0 and i_grid == 0:
+                        if self.options["qoi"] == "all":
+                            qoi_idx = np.arange(res_all.shape[1])
+                            n_qoi = len(qoi_idx)
+
+                    i_grid = grid.n_grid
+
+                    iprint('Total function evaluation: ' + str(time.time() - start_time) + ' sec',
+                           tab=0, verbose=self.options["verbose"])
+
+                    # Determine gradient [n_grid x n_out x dim]
+                    start_time = time.time()
+
+                    grad_res_3D_all, gradient_idx = get_gradient(model=self.problem.model,
+                                                                 problem=self.problem,
+                                                                 grid=grid,
+                                                                 results=res_all,
+                                                                 com=com,
+                                                                 method="FD_fwd",
+                                                                 gradient_results_present=grad_res_3D_all,
+                                                                 gradient_idx_skip=gradient_idx,
+                                                                 i_iter=self.options["order_max"],
+                                                                 i_subiter=self.options["interaction_order"],
+                                                                 print_func_time=self.options["print_func_time"],
+                                                                 dx=self.options["gradient_calculation_options"]["dx"],
+                                                                 distance_weight=
+                                                                 self.options["gradient_calculation_options"][
+                                                                     "distance_weight"],
+                                                                 verbose=self.options["verbose"])
+
+                    iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
+                           tab=0, verbose=self.options["verbose"])
+
+                    # check validity of results and resample in case the model could not be evaluated at some sampling points
+                    res_all, grad_res_3D_all, gradient_idx, grid = self.check_results(results=res_all,
+                                                                                      gradient_results=grad_res_3D_all,
+                                                                                      gradient_results_idx=gradient_idx,
+                                                                                      grid=grid,
+                                                                                      com=com)
+
+                # crop results to considered qoi
+                if self.options["qoi"] != "all":
+                    res = copy.deepcopy(res_all)
+                    grad_res_3D = copy.deepcopy(grad_res_3D_all)
+                    hdf5_subfolder = ""
+                    output_idx_passed_validation = None
+
+                else:
+                    res = res_all[:, q_idx][:, np.newaxis]
+                    grad_res_3D = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
+                    hdf5_subfolder = "/qoi_" + str(q_idx)
+                    output_idx_passed_validation = q_idx
+
+                megpc[i_qoi].grid = copy.deepcopy(grid)
+
+                # determine gpc domains
+                megpc[i_qoi].init_classifier(coords=megpc[i_qoi].grid.coords_norm,
+                                             results=res_all[:, q_idx][:, np.newaxis],
+                                             algorithm=self.options["classifier"],
+                                             options=self.options["classifier_options"])
+
+                problem_reduced = [0 for _ in range(megpc[i_qoi].n_gpc)]
+                p_matrix = [0 for _ in range(megpc[i_qoi].n_gpc)]
+                p_matrix_norm = [0 for _ in range(megpc[i_qoi].n_gpc)]
+                dim_reduced = [0 for _ in range(megpc[i_qoi].n_gpc)]
+                parameters_reduced = [OrderedDict() for _ in range(megpc[i_qoi].n_gpc)]
+                megpc[i_qoi].gpc = [0 for _ in range(megpc[i_qoi].n_gpc)]
+
+                # Determine projection matrices for sub gPCs
+                for d in np.unique(megpc[i_qoi].domains):
+                    p_matrix[d], _ = determine_projection_matrix(
+                        gradient_results=grad_res_3D_all[megpc[i_qoi].domains[gradient_idx] == d, q_idx, :],
+                        lambda_eps=self.options["lambda_eps_gradient"])
+
+                    p_matrix_norm[d] = np.sum(np.abs(p_matrix[d]), axis=1)
+                    dim_reduced[d] = p_matrix[d].shape[0]
+
+                    for i in range(dim_reduced[d]):
+                        parameters_reduced[d]["n{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
+
+                    problem_reduced[d] = Problem(model=self.problem.model, parameters=parameters_reduced[d])
+
+                    # Set up reduced gPC for this domain
+                    megpc[i_qoi].add_sub_gpc(problem=problem_reduced[d],
+                                             order=[self.options["order"][0] for _ in range(dim_reduced[d])],
+                                             order_max=self.options["order_max"],
+                                             order_max_norm=self.options["order_max_norm"],
+                                             interaction_order=self.options["interaction_order"],
+                                             interaction_order_current=self.options["interaction_order"],
+                                             options=self.options,
+                                             domain=d,
+                                             validation=None)
+
+                    # save original problem in gpc object
+                    megpc[i_qoi].gpc[d].problem_original = self.problem
+
+                    # save projection matrix in gPC object
+                    megpc[i_qoi].gpc[d].p_matrix = copy.deepcopy(p_matrix[d])
+                    megpc[i_qoi].gpc[d].p_matrix_norm = copy.deepcopy(p_matrix_norm[d])
+
+                # copy options to MEGPC object
+                megpc[i_qoi].options = copy.deepcopy(self.options)
+
+                # assign grids to sub-gPCs (rotate sub-grids in case of projection)
+                megpc[i_qoi].assign_grids(gradient_idx=gradient_idx)
+
+                # Initialize gpc matrices
+                megpc[i_qoi].init_gpc_matrices()
+
+                # Someone might not use the gradient to determine the gpc coeffs
+                if megpc[i_qoi].gradient:
+                    grad_res_3D_passed = grad_res_3D
+                else:
+                    grad_res_3D_passed = None
+
+                # Compute gpc coefficients
+                coeffs[i_qoi] = megpc[i_qoi].solve(results=res,
+                                                   gradient_results=grad_res_3D_passed,
+                                                   solver=self.options["solver"],
+                                                   settings=self.options["settings"],
+                                                   verbose=self.options["verbose"])
+
+                # validate gpc approximation (determine nrmsd or loocv specified in options["error_type"])
+                if self.options["error_type"] == "nrmsd" and megpc[0].validation is None:
+                    megpc[0].create_validation_set(n_samples=self.options["n_samples_validation"],
+                                                   n_cpu=self.options["n_cpu"])
+                elif self.options["error_type"] == "nrmsd" and megpc[0].validation is not None:
+                    megpc[i_qoi].validation = copy.deepcopy(megpc[0].validation)
+
+                eps = megpc[i_qoi].validate(coeffs=coeffs[i_qoi], results=res, gradient_results=grad_res_3D_passed)
+
+                iprint("-> {} {} error = {}".format(self.options["error_norm"],
+                                                    self.options["error_type"],
+                                                    eps), tab=0, verbose=self.options["verbose"])
+
+                # domain specific error
+                eps_domain = [0 for _ in range(len(np.unique(megpc[i_qoi].domains)))]
+                for i_gpc, d in enumerate(np.unique(megpc[i_qoi].domains)):
+                    eps_domain[d] = megpc[i_qoi].validate(coeffs=coeffs[i_qoi],
+                                                          results=res,
+                                                          domain=d,
+                                                          output_idx=output_idx_passed_validation)
+
+                if not self.options["adaptive_sampling"] or (0 < (eps_pre-eps)/eps < 0.01):
+                    break
+
+                if eps > self.options["eps"]:
+                    # extend grid by 10% of number of grid points
+                    n_grid_new = int(np.ceil(1.1*grid.n_grid))
+                    iprint("Extending grid from {} to {} by {} sampling points".format(
+                        grid.n_grid, n_grid_new, n_grid_new - grid.n_grid),
+                        tab=0, verbose=self.options["verbose"])
+                    grid.extend_random_grid(n_grid_new=n_grid_new)
+
+                eps_pre = eps
+
+            # save data
+            if self.options["fn_results"] is not None:
+
+                with h5py.File(fn_results + ".hdf5", "a") as f:
+
+                    try:
+                        fn_session = f["misc/fn_session"]
+
+                    except KeyError:
+                        f.create_dataset("misc/fn_session",
+                                         data=np.array([os.path.split(self.options["fn_session"])[1]]).astype("|S"))
+                        f.create_dataset("misc/fn_session_folder",
+                                         data=np.array([self.options["fn_session_folder"]]).astype("|S"))
+
+                    for i_gpc in range(megpc[i_qoi].n_gpc):
+                        f.create_dataset("error" + hdf5_subfolder + "/dom_" + str(i_gpc),
+                                         data=eps_domain[i_gpc],
+                                         maxshape=None, dtype="float64")
+
+                        f.create_dataset("coeffs" + hdf5_subfolder + "/dom_" + str(i_gpc),
+                                         data=coeffs[i_qoi][i_gpc],
+                                         maxshape=None, dtype="float64")
+
+                    f.create_dataset("domains" + hdf5_subfolder,
+                                     data=megpc[i_qoi].domains,
+                                     maxshape=None, dtype="int64")
+
+                    for i_gpc in range(megpc[i_qoi].n_gpc):
+                        f.create_dataset("gpc_matrix" + hdf5_subfolder + "/dom_" + str(i_gpc),
+                                         data=megpc[i_qoi].gpc[i_gpc].gpc_matrix,
+                                         maxshape=None, dtype="float64")
+
+                        if megpc[i_qoi].gpc[0].gpc_matrix_gradient is not None:
+                            if self.options["gradient_enhanced"]:
+                                f.create_dataset("gpc_matrix_gradient" + hdf5_subfolder + "/dom_" + str(i_gpc),
+                                                 data=megpc[i_qoi].gpc[i_gpc].gpc_matrix_gradient,
+                                                 maxshape=None, dtype="float64")
+
+                    for i_gpc in range(megpc[i_qoi].n_gpc):
+                        f.create_dataset("p_matrix" + hdf5_subfolder + "/dom_" + str(i_gpc),
+                                         data=megpc[i_qoi].gpc[i_gpc].p_matrix,
+                                         maxshape=None, dtype="float64")
+            i_qoi += 1
+
+        if self.options["fn_results"] is not None:
+
+            with h5py.File(fn_results + ".hdf5", "a") as f:
+
+                try:
+                    del f["grid/coords"]
+                    del f["grid/coords_norm"]
+                    del f["grid/coords_gradient"]
+                    del f["grid/coords_gradient_norm"]
+
+                except KeyError:
+                    pass
+
+                f.create_dataset("grid/coords", data=grid.coords,
+                                 maxshape=None, dtype="float64")
+                f.create_dataset("grid/coords_norm", data=grid.coords_norm,
+                                 maxshape=None, dtype="float64")
+
+                if grid.coords_gradient is not None:
+                    f.create_dataset("grid/coords_gradient",
+                                     data=grid.coords_gradient,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("grid/coords_gradient_norm",
+                                     data=grid.coords_gradient_norm,
+                                     maxshape=None, dtype="float64")
+
+                f.create_dataset("model_evaluations/results", data=res,
+                                 maxshape=None, dtype="float64")
+                if grad_res_3D is not None:
+                    f.create_dataset("model_evaluations/gradient_results", data=ten2mat(grad_res_3D),
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("model_evaluations/gradient_results_idx", data=megpc[-1].gradient_idx,
+                                     maxshape=None, dtype="int64")
+
+                f.create_dataset("misc/error_type", data=self.options["error_type"])
+
+                if megpc[0].validation is not None:
+                    f.create_dataset("validation/model_evaluations/results", data=megpc[0].validation.results,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("validation/grid/coords", data=megpc[0].validation.grid.coords,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("validation/grid/coords_norm", data=megpc[0].validation.grid.coords_norm,
+                                     maxshape=None, dtype="float64")
+
+        com.close()
+
+        return megpc, coeffs, res
+
+
+class RegAdaptive(Algorithm):
+    """
+    Adaptive regression approach based on leave one out cross validation error estimation
+
+    Parameters
+    ----------
+    problem: Problem class instance
+        GPC problem under investigation
+    options["order_start"] : int, optional, default=0
+          Initial gPC expansion order (maximum order)
+    options["order_end"] : int, optional, default=10
+        Maximum Gpc expansion order to expand to (algorithm will terminate afterwards)
+    options["interaction_order"]: int, optional, default=dim
+        Define maximum interaction order of parameters (default: all interactions)
+    options["order_max_norm"]: float
+        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
+        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
+        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
+        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
+    options["adaptive_sampling"] : boolean, optional, default: True
+        Adds samples adaptively to the expansion until the error is converged and continues by
+        adding new basis functions.
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> # initialize adaptive gPC algorithm
+    >>> algorithm = pygpc.RegAdaptive(problem=problem, options=options)
+    >>> # run algorithm
+    >>> gpc, coeffs, results = algorithm.run()
+    """
+
+    def __init__(self, problem, options, validation=None, grid=None):
+        """
+        Constructor; Initializes RegAdaptive algorithm
+        """
+        super(RegAdaptive, self).__init__(problem=problem, options=options, validation=validation, grid=grid)
+
+        self.qoi_specific = False
+
+        # check contents of settings dict and set defaults
+        if "order_start" not in self.options.keys():
+            self.options["order_start"] = 0
+
+        if "order_end" not in self.options.keys():
+            self.options["order_end"] = 10
+
+        if "interaction_order" not in self.options.keys():
+            self.options["interaction_order"] = problem.dim
+
+        if "order_max_norm" not in self.options.keys():
+            self.options["order_max_norm"] = 1.
+
+        if "adaptive_sampling" not in self.options.keys():
+            self.options["adaptive_sampling"] = True
+
+        if "basis_increment_strategy" not in self.options.keys():
+            self.options["basis_increment_strategy"] = "isotropic"
+
+    def run(self):
+        """
+        Runs adaptive gPC algorithm to solve problem.
+
+        Returns
+        -------
+        gpc : GPC object instance
+            GPC object containing all information i.e., Problem, Model, Grid, Basis, RandomParameter instances
+        coeffs: ndarray of float [n_basis x n_out]
+            GPC coefficients
+        res : ndarray of float [n_grid x n_out]
+            Simulation results at n_grid points of the n_out output variables
+        """
+
+        if self.options["fn_results"] is not None:
+            fn_results = os.path.splitext(self.options["fn_results"])[0]
+
+            if os.path.exists(fn_results + ".hdf5"):
+                os.remove(fn_results + ".hdf5")
+        else:
+            fn_results = None
+
+        # initialize iterators
+        eps = self.options["eps"] + 1.0
+        i_grid = 0
+        order = self.options["order_start"]
+        first_iter = True
+        grad_res_3D = None
+        gradient_idx = None
+        gradient_idx_FD_fwd = None
+        grad_res_3D_FD_fwd = None
+        basis_order = np.array([self.options["order_start"],
+                                min(self.options["interaction_order"], self.options["order_start"])])
+
+        # Initialize parallel Computation class
+        com = Computation(n_cpu=self.n_cpu, matlab_model=self.options["matlab_model"])
+
+        # Initialize Reg gPC object
+        print("Initializing gPC object...")
+        gpc = Reg(problem=self.problem,
+                  order=self.options["order_start"] * np.ones(self.problem.dim),
+                  order_max=self.options["order_start"],
+                  order_max_norm=self.options["order_max_norm"],
+                  interaction_order=self.options["interaction_order"],
+                  interaction_order_current=self.options["interaction_order"],
+                  options=self.options,
+                  validation=self.validation)
+        extended_basis = True
+
+        # Add a validation set if nrmsd is chosen and no validation set is yet present
+        if self.options["error_type"] == "nrmsd" and not isinstance(self.validation, ValidationSet):
+            gpc.create_validation_set(n_samples=self.options["n_samples_validation"],
+                                      n_cpu=self.options["n_cpu"])
+
+        # Initialize Grid object
+        if self.grid is not None:
+            print(f"Using user-predefined grid with n_grid={self.grid.n_grid}")
+            gpc.grid = self.options["grid"](parameters_random=self.problem.parameters_random,
+                                            coords=self.grid.coords,
+                                            coords_norm=self.grid.coords_norm,
+                                            coords_gradient=self.grid.coords_gradient,
+                                            coords_gradient_norm=self.grid.coords_gradient_norm,
+                                            options=self.options["grid_options"])
+        else:
+            n_grid_init = np.ceil(self.options["matrix_ratio"] * gpc.basis.n_basis)
+            print(f"Creating initial grid ({self.options['grid'].__name__}) with n_grid={int(n_grid_init)}")
+
+            if self.options["grid"] in [L1, L1_LHS, LHS_L1, FIM, CO]:
+                if "n_pool" in self.options["grid_options"]:
+                    if self.options["grid_options"]["n_pool"] < int(n_grid_init):
+                        warnings.warn('self.options["grid_options"]["n_pool"] < n_grid_init ... setting n_pool to 2*n_grid_init')
+                        self.options["grid_options"]["n_pool"] = 2*int(n_grid_init)
+
+                gpc.grid = self.options["grid"](parameters_random=self.problem.parameters_random,
+                                                n_grid=int(n_grid_init),
+                                                options=self.options["grid_options"],
+                                                gpc=gpc)
+
+            else:
+                gpc.grid = self.options["grid"](parameters_random=self.problem.parameters_random,
+                                                n_grid=n_grid_init,
+                                                options=self.options["grid_options"])
+
+        gpc.solver = self.options["solver"]
+        gpc.settings = self.options["settings"]
+        gpc.options = copy.deepcopy(self.options)
+
+        # Initialize gpc matrix
+        print("Initializing gPC matrix...")
+        gpc.init_gpc_matrix(gradient_idx=gradient_idx)
+        gpc.n_grid.pop(0)
+        gpc.n_basis.pop(0)
+
+        if gpc.options["gradient_enhanced"]:
+            gpc.grid.create_gradient_grid()
+
+        # Main iterations (order)
+        i_iter = 0
+        while eps > self.options["eps"]:
+
+            if first_iter:
+                basis_increment = 0
+            else:
+                basis_increment = 1
+
+            if self.options["basis_increment_strategy"] == "anisotropic":
+                if not first_iter:
+                    if np.max(np.sum(gpc.basis.multi_indices, axis=1)) >= self.options["order_end"]:
+                        break
+
+                    # determine potential polynomials which can be extended
+                    # (not enclosed by other already existing polynomials)
+                    active_non_enclosed_set, poly_indices_non_enclosed = get_non_enclosed_multi_indices(
+                        multi_indices=gpc.basis.multi_indices,
+                        interaction_order=self.options["interaction_order"])
+
+                    # get index of highest non enclosed coefficient
+                    coeff_max_idx_non_enclosed = np.argmax(np.linalg.norm(coeffs[poly_indices_non_enclosed, :], axis=1))
+
+                    # determine multi-indices to add
+                    multi_indices_to_add = poly_expand(current_set=gpc.basis.multi_indices,
+                                                       to_expand=active_non_enclosed_set[coeff_max_idx_non_enclosed],
+                                                       order_max=self.options["order_end"],
+                                                       interaction_order=self.options["interaction_order"])
+
+                    # update basis
+                    b_added = gpc.basis.add_basis_poly_by_order(multi_indices=multi_indices_to_add,
+                                                                problem=gpc.problem)
+
+                    if b_added is not None:
+                        print_str = f"Added multi-indices to basis: \n {np.matrix(multi_indices_to_add)}"
+                        iprint(print_str, tab=0, verbose=self.options["verbose"])
+                        iprint("=" * 100, tab=0, verbose=self.options["verbose"])
+                        extended_basis = True
+
+            else:
+                # increase basis isotropic
+                basis_order[0], basis_order[1] = increment_basis(order_current=basis_order[0],
+                                                                 interaction_order_current=basis_order[1],
+                                                                 interaction_order_max=self.options["interaction_order"],
+                                                                 incr=basis_increment)
+
+                if basis_order[0] > self.options["order_end"]:
+                    break
+
+                # update basis
+                b_added = gpc.basis.set_basis_poly(order=basis_order[0] * np.ones(self.problem.dim),
+                                                   order_max=basis_order[0],
+                                                   order_max_norm=self.options["order_max_norm"],
+                                                   interaction_order=self.options["interaction_order"],
+                                                   interaction_order_current=basis_order[1],
+                                                   problem=gpc.problem)
+
+                if b_added is not None:
+                    print_str = "Order/Interaction order: {}/{}".format(basis_order[0], basis_order[1])
+                    iprint(print_str, tab=0, verbose=self.options["verbose"])
+                    iprint("=" * len(print_str), tab=0, verbose=self.options["verbose"])
+                    extended_basis = True
+
+            # plot basis
+            if self.options["plot_basis"]:
+                gpc.basis.plot_basis(dims=np.arange(np.min((gpc.problem.dim, 3))),
+                                     fn_plot=self.options["fn_results"] + f"_basis_{i_iter}")
+            i_iter += 1
+
+            if self.options["adaptive_sampling"]:
+                iprint("Starting adaptive sampling:", tab=0, verbose=self.options["verbose"])
+
+            add_samples = True   # if adaptive sampling is False, the while loop will be only executed once
+            delta_eps_target = 1e-1
+            delta_eps = delta_eps_target + 1
+            delta_samples = 5e-2
+
+            while add_samples and delta_eps > delta_eps_target and eps > self.options["eps"]:
+
+                if not self.options["adaptive_sampling"]:
+                    add_samples = False
+
+                # new sample size
+                if extended_basis and self.options["adaptive_sampling"]:
+                    # do not increase sample size immediately when basis was extended, try first with old samples
+                    n_grid_new = gpc.grid.n_grid
+                elif self.options["adaptive_sampling"] and not first_iter:
+                    # increase sample size stepwise (adaptive sampling)
+                    n_grid_new = int(np.ceil(gpc.grid.n_grid + delta_samples * gpc.basis.n_basis))
+                else:
+                    # increase sample size according to matrix ratio w.r.t. number of basis functions
+                    n_grid_new = int(np.ceil(gpc.basis.n_basis * self.options["matrix_ratio"]))
+
+                # run model if grid points were added
+                if i_grid < n_grid_new or extended_basis:
+                    # extend grid
+                    if i_grid < n_grid_new:
+                        iprint("Extending grid from {} to {} by {} sampling points".format(
+                            gpc.grid.n_grid, n_grid_new, n_grid_new - gpc.grid.n_grid),
+                            tab=0, verbose=self.options["verbose"])
+
+                        if self.options["grid"] in [L1, L1_LHS, LHS_L1, FIM, CO]:
+                            if "n_pool" in self.options["grid_options"]:
+                                if self.options["grid_options"]["n_pool"] < int(n_grid_init):
+                                    warnings.warn(
+                                        'self.options["grid_options"]["n_pool"] < n_grid_new ... '
+                                        'setting n_pool to 2*n_grid_new')
+                                    self.options["grid_options"]["n_pool"] = 2 * int(n_grid_new)
+
+                        gpc.grid.extend_random_grid(n_grid_new=n_grid_new)
+
+                        # run simulations
+                        iprint("Performing simulations " + str(i_grid + 1) + " to " + str(gpc.grid.coords.shape[0]),
+                               tab=0, verbose=self.options["verbose"])
+
+                        start_time = time.time()
+
+                        res_new = com.run(model=gpc.problem.model,
+                                          problem=gpc.problem,
+                                          coords=gpc.grid.coords[int(i_grid):int(len(gpc.grid.coords))],
+                                          coords_norm=gpc.grid.coords_norm[int(i_grid):int(len(gpc.grid.coords))],
+                                          i_iter=basis_order[0],
+                                          i_subiter=basis_order[1],
+                                          fn_results=gpc.fn_results,
+                                          print_func_time=self.options["print_func_time"],
+                                          verbose=self.options["verbose"])
+
+                        iprint('Total parallel function evaluation: ' + str(time.time() - start_time) + ' sec',
+                               tab=0, verbose=self.options["verbose"])
+
+                        # Append result to solution matrix (RHS)
+                        if i_grid == 0:
+                            res = res_new
+                        else:
+                            res = np.vstack([res, res_new])
+
+                        if self.options["gradient_enhanced"]:
+                            start_time = time.time()
+
+                            grad_res_3D, gradient_idx = get_gradient(model=self.problem.model,
+                                                                     problem=self.problem,
+                                                                     grid=gpc.grid,
+                                                                     results=res,
+                                                                     com=com,
+                                                                     method=self.options["gradient_calculation"],
+                                                                     gradient_results_present=grad_res_3D_FD_fwd,
+                                                                     gradient_idx_skip=gradient_idx_FD_fwd,
+                                                                     i_iter=basis_order[0],
+                                                                     i_subiter=basis_order[1],
+                                                                     print_func_time=self.options["print_func_time"],
+                                                                     dx=self.options["gradient_calculation_options"]["dx"],
+                                                                     distance_weight=self.options["gradient_calculation_options"]["distance_weight"],
+                                                                     verbose=self.options["verbose"])
+
+                            iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
+                                   tab=0, verbose=self.options["verbose"])
+
+                        # check validity of results and resample in case the model could not be evaluated at some sampling points
+                        res, grad_res_3D, gradient_idx, gpc.grid = self.check_results(results=res,
+                                                                                      gradient_results=grad_res_3D,
+                                                                                      gradient_results_idx=gradient_idx,
+                                                                                      grid=gpc.grid,
+                                                                                      com=com)
+
+                        if self.options["gradient_enhanced"] and self.options["gradient_calculation"] == "FD_fwd":
+                            gradient_idx_FD_fwd = gradient_idx
+                            grad_res_3D_FD_fwd = grad_res_3D
+
+                        i_grid = gpc.grid.coords.shape[0]
+
+                    # update gpc matrix
+                    gpc.init_gpc_matrix(gradient_idx=gradient_idx)
+
+                    # determine gpc coefficients
+                    coeffs = gpc.solve(results=res,
+                                       gradient_results=grad_res_3D,
+                                       solver=gpc.solver,
+                                       settings=gpc.settings,
+                                       verbose=self.options["verbose"])
+
+                    # validate gpc approximation (determine nrmsd or loocv specified in options["error_type"])
+                    eps = gpc.validate(coeffs=coeffs,
+                                       results=res,
+                                       gradient_results=grad_res_3D)
+
+                    if extended_basis:
+                        eps_ref = copy.deepcopy(eps)
+                    else:
+                        delta_eps = np.abs((gpc.error[-1] - gpc.error[-2]) / eps_ref)
+
+                    iprint("-> {} {} error = {}".format(self.options["error_norm"],
+                                                        self.options["error_type"],
+                                                        eps), tab=0, verbose=self.options["verbose"])
+
+                    # extend basis further if error was decreased (except in very first iteration)
+                    if not first_iter and extended_basis and gpc.error[-1] < gpc.error[-2]:
+                        break
+
+                    extended_basis = False
+                    first_iter = False
+
+                    # exit adaptive sampling loop if no adaptive sampling was chosen
+                    if not self.options["adaptive_sampling"]:
+                        break
+
+            # save gpc coeffs for this sub-iteration
+            if self.options["fn_results"] is not None:
+
+                with h5py.File(os.path.splitext(self.options["fn_results"])[0] + ".hdf5", "a") as f:
+
+                    # overwrite coeffs
+                    if "coeffs" in f.keys():
+                        del f['coeffs']
+                    f.create_dataset("coeffs", data=coeffs, maxshape=None, dtype="float64")
+
+                    # Append gradient of results
+                    if grad_res_3D is not None:
+                        grad_res_2D = ten2mat(grad_res_3D)
+
+                        try:
+                            del f["model_evaluations/gradient_results"]
+                            del f["model_evaluations/gradient_results_idx"]
+                        except KeyError:
+                            pass
+
+                        f.create_dataset("model_evaluations/gradient_results",
+                                         (grad_res_2D.shape[0], grad_res_2D.shape[1]),
+                                         maxshape=(None, None),
+                                         dtype="float64",
+                                         data=grad_res_2D)
+
+                        f.create_dataset("model_evaluations/gradient_results_idx", data=gpc.gradient_idx,
+                                         maxshape=None, dtype="int64")
+
+                    try:
+                        del f["gpc_matrix"]
+                    except KeyError:
+                        pass
+                    f.create_dataset("gpc_matrix",
+                                     data=gpc.gpc_matrix,
+                                     maxshape=None, dtype="float64")
+
+                    if gpc.gpc_matrix_gradient is not None:
+                        try:
+                            del f["gpc_matrix_gradient"]
+                        except KeyError:
+                            pass
+                        f.create_dataset("gpc_matrix_gradient",
+                                         data=gpc.gpc_matrix_gradient,
+                                         maxshape=None, dtype="float64")
+
+        # determine gpc coefficients
+        coeffs = gpc.solve(results=res,
+                           gradient_results=grad_res_3D,
+                           solver=gpc.solver,
+                           settings=gpc.settings,
+                           verbose=self.options["verbose"])
+
+        # save gpc object and gpc coeffs
+        if self.options["fn_results"] is not None:
+
+            with h5py.File(os.path.splitext(self.options["fn_results"])[0] + ".hdf5", "a") as f:
+                if "coeffs" in f.keys():
+                    del f['coeffs']
+                f.create_dataset("coeffs", data=coeffs, maxshape=None, dtype="float64")
+
+                try:
+                    del f["gpc_matrix"]
+                except KeyError:
+                    pass
+                f.create_dataset("gpc_matrix",
+                                 data=gpc.gpc_matrix,
+                                 maxshape=None, dtype="float64")
+
+                if gpc.gpc_matrix_gradient is not None:
+                    try:
+                        del f["gpc_matrix_gradient"]
+                    except KeyError:
+                        pass
+                    f.create_dataset("gpc_matrix_gradient",
+                                     data=gpc.gpc_matrix_gradient,
+                                     maxshape=None, dtype="float64")
+
+                # misc
+                f.create_dataset("misc/fn_session",
+                                 data=np.array([os.path.split(self.options["fn_session"])[1]]).astype("|S"))
+                f.create_dataset("misc/fn_session_folder",
+                                 data=np.array([self.options["fn_session_folder"]]).astype("|S"))
+                f.create_dataset("misc/error_type", data=self.options["error_type"])
+                f.create_dataset("error", data=eps, maxshape=None, dtype="float64")
+
+                if gpc.validation is not None:
+                    f.create_dataset("validation/model_evaluations/results", data=gpc.validation.results,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("validation/grid/coords", data=gpc.validation.grid.coords,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("validation/grid/coords_norm", data=gpc.validation.grid.coords_norm,
+                                     maxshape=None, dtype="float64")
+
+                if self.options["gradient_enhanced"]:
+                    f.create_dataset("grid/coords_gradient", data=gpc.grid.coords_gradient,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("grid/coords_gradient_norm", data=gpc.grid.coords_gradient_norm,
+                                     maxshape=None, dtype="float64")
+
+        com.close()
+
+        return gpc, coeffs, res
+
+
+class MERegAdaptiveProjection(Algorithm):
+    """
+    Adaptive regression approach based on leave one out cross validation error estimation
+
+    Parameters
+    ----------
+    problem: Problem class instance
+        GPC problem under investigation
+    options["order_start"] : int, optional, default=0
+          Initial gPC expansion order (maximum order)
+    options["order_end"] : int, optional, default=10
+        Maximum Gpc expansion order to expand to (algorithm will terminate afterwards)
+    options["interaction_order"]: int, optional, default=dim
+        Define maximum interaction order of parameters (default: all interactions)
+    options["order_max_norm"]: float
+        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
+        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
+        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
+        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
+    options["adaptive_sampling"] : boolean, optional, default: True
+        Adds samples adaptively to the expansion until the error is converged and continues by
+        adding new basis functions.
+    options["n_samples_discontinuity"] : int, optional, default: 10
+        Number of grid points close to discontinuity to refine its location
+    options["n_grid_init"] : int, optional, default: 10
+        Number of initial simulations to explore the parameter space
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> # initialize adaptive gPC algorithm
+    >>> algorithm = pygpc.MERegAdaptiveProjection(problem=problem, options=options)
+    >>> # run algorithm
+    >>> gpc, coeffs, results = algorithm.run()
+    """
+
+    def __init__(self, problem, options, validation=None, grid=None):
+        """
+        Constructor; Initializes MERegAdaptiveProjection Algorithm
+        """
+        super(MERegAdaptiveProjection, self).__init__(problem=problem, options=options, validation=validation, grid=grid)
+
+        # check contents of settings dict and set defaults
+        if "order_start" not in self.options.keys():
+            self.options["order_start"] = 0
+
+        if "order_end" not in self.options.keys():
+            self.options["order_end"] = 10
+
+        if "interaction_order" not in self.options.keys():
+            self.options["interaction_order"] = problem.dim
+
+        if "order_max_norm" not in self.options.keys():
+            self.options["order_max_norm"] = 1.
+
+        if "adaptive_sampling" not in self.options.keys():
+            self.options["adaptive_sampling"] = True
+
+        if "n_samples_discontinuity" not in self.options.keys():
+            self.options["n_samples_discontinuity"] = 10
+
+        if "n_grid_init" not in self.options.keys():
+            self.options["n_grid_init"] = 10
+
+        if self.options["qoi"] == "all":
+            self.qoi_specific = True
+        else:
+            self.qoi_specific = False
+
+    def run(self):
+        """
+        Runs Multi-Element adaptive gPC algorithm to solve problem (optional projection).
+
+        Returns
+        -------
+        megpc : Multi-element GPC object instance
+            MEGPC object containing all information i.e., Problem, Model, Grid, Basis, RandomParameter instances
+        coeffs: list of ndarray of float [n_gpc][n_basis x n_out]
+            GPC coefficients
+        res : ndarray of float [n_grid x n_out]
+            Simulation results at n_grid points of the n_out output variables
+        """
+
+        if self.options["fn_results"] is not None:
+            fn_results = os.path.splitext(self.options["fn_results"])[0]
+
+            if os.path.exists(fn_results + ".hdf5"):
+                os.remove(fn_results + ".hdf5")
+        else:
+            fn_results = None
+
+        grid = self.options["grid"]
+        problem_original = copy.deepcopy(self.problem)
+
+        # initialize iterators
+        grad_res_3D = None
+        grad_res_3D_all = None
+        gradient_idx = None
+        gradient_idx_FD_fwd = None
+        basis_increment = 0
+
+        n_grid_init = self.options["n_grid_init"]
+
+        # make initial random grid to determine number of output variables and to estimate projection
+        if self.grid is not None:
+            print(f"Using user-predefined grid with n_grid={grid.n_grid}")
+            self.options["grid"](parameters_random=self.problem.parameters_random,
+                                 coords=grid.coords,
+                                 coords_norm=grid.coords_norm,
+                                 coords_gradient=grid.coords_gradient,
+                                 coords_gradient_norm=grid.coords_gradient_norm,
+                                 options=self.options["grid_options"])
+
+        elif self.options["grid"] == Random or self.options["grid"] == LHS or self.options["grid"] == GP:
+            print(f"Creating initial grid ({self.options['grid'].__name__}) with n_grid={int(n_grid_init)}")
+            grid = self.options["grid"](parameters_random=self.problem.parameters_random,
+                                        n_grid=n_grid_init,
+                                        options=self.options["grid_options"])
+
+        elif self.options["grid"] == L1 or self.options["grid"] == L1_LHS or self.options["grid"] == LHS_L1 \
+                or self.options["grid"] == FIM:
+            raise NotImplementedError("Grid type not possible for MERegAdaptiveProjection algorithm."
+                                      "Please use either 'Random', 'LHS' or 'GP'.")
+
+        # Initialize parallel Computation class
+        com = Computation(n_cpu=self.n_cpu, matlab_model=self.options["matlab_model"])
+
+        # Run initial simulations to determine initial projection matrix
+        iprint("Performing {} initial simulations!".format(grid.coords.shape[0]),
+               tab=0, verbose=self.options["verbose"])
+
+        start_time = time.time()
+
+        res_all = com.run(model=self.problem.model,
+                          problem=self.problem,
+                          coords=grid.coords,
+                          coords_norm=grid.coords_norm,
+                          i_iter=self.options["order_start"],
+                          i_subiter=self.options["interaction_order"],
+                          fn_results=self.options["fn_results"],  # + "_temp"
+                          print_func_time=self.options["print_func_time"],
+                          verbose=self.options["verbose"])
+
+        i_grid = grid.n_grid
+
+        iprint('Total function evaluation: ' + str(time.time() - start_time) + ' sec',
+               tab=0, verbose=self.options["verbose"])
+
+        if self.options["qoi"] == "all":
+            qoi_idx = np.arange(res_all.shape[1])
+            n_qoi = len(qoi_idx)
+            error = [None for _ in range(n_qoi)]
+        else:
+            qoi_idx = [self.options["qoi"]]
+            n_qoi = 1
+            error = [0]
+
+        # Determine gradient for projection [n_grid x n_out x dim]
+        if self.options["gradient_enhanced"] or self.options["projection"]:
+            if self.options["projection"] or self.options["gradient_calculation"] == "FD_fwd":
+                method = "FD_fwd"
+                dx = 1e-3
+                distance_weight = None
+            else:
+                method = self.options["gradient_calculation"]
+                dx = self.options["gradient_calculation_options"]["dx"]
+                distance_weight = self.options["gradient_calculation_options"]["distance_weight"]
+
+            start_time = time.time()
+
+            grad_res_3D_all, gradient_idx = get_gradient(model=self.problem.model,
+                                                         problem=self.problem,
+                                                         grid=grid,
+                                                         results=res_all,
+                                                         com=com,
+                                                         method=method,
+                                                         gradient_results_present=None,
+                                                         gradient_idx_skip=None,
+                                                         i_iter=self.options["order_start"],
+                                                         i_subiter=self.options["interaction_order"],
+                                                         print_func_time=self.options["print_func_time"],
+                                                         dx=dx,
+                                                         distance_weight=distance_weight,
+                                                         verbose=self.options["verbose"])
+
+            if method == "FD_fwd":
+                gradient_idx_FD_fwd = gradient_idx
+                grad_res_3D_all_FD_fwd = grad_res_3D_all
+            else:
+                gradient_idx_FD_fwd = None
+                grad_res_3D_all_FD_fwd = None
+
+            iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
+                   tab=0, verbose=self.options["verbose"])
+
+        # check validity of results and resample in case the model could not be evaluated at some sampling points
+        res_all, grad_res_3D_all, gradient_idx, grid = self.check_results(results=res_all,
+                                                                          gradient_results=grad_res_3D_all,
+                                                                          gradient_results_idx=gradient_idx,
+                                                                          grid=grid,
+                                                                          com=com)
+
+        megpc = [0 for _ in range(n_qoi)]
+        coeffs = [0 for _ in range(n_qoi)]
+
+        for i_qoi, q_idx in enumerate(qoi_idx):
+            print_str = "Determining gPC approximation for QOI #{}:".format(q_idx)
+            iprint(print_str, tab=0, verbose=self.options["verbose"])
+            iprint("=" * len(print_str), tab=0, verbose=self.options["verbose"])
+
+            first_iter = True
+
+            # crop results to considered qoi
+            if self.options["qoi"] != "all":
+                res = copy.deepcopy(res_all)
+                grad_res_3D = copy.deepcopy(grad_res_3D_all)
+                hdf5_subfolder = ""
+                output_idx_passed_validation = None
+                # the gPC is constructed for all QOI but only using info for projection etc of desired QOI
+                # validation is done for all qoi
+
+            else:
+                res = res_all[:, q_idx][:, np.newaxis]
+                hdf5_subfolder = "/qoi_" + str(q_idx)
+                output_idx_passed_validation = q_idx
+
+                if grad_res_3D_all is not None:
+                    grad_res_3D = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
+
+            # Create MEGPC object
+            megpc[i_qoi] = MEGPC(problem=self.problem,
+                                 options=self.options,
+                                 validation=self.validation)
+
+            # Write grid in gpc object
+            megpc[i_qoi].grid = copy.deepcopy(grid)
+
+            # determine gpc domains
+            iprint("Determining gPC domains ...", tab=0, verbose=self.options["verbose"])
+            megpc[i_qoi].init_classifier(coords=megpc[i_qoi].grid.coords_norm,
+                                         results=res_all[:, q_idx][:, np.newaxis],
+                                         algorithm=self.options["classifier"],
+                                         options=self.options["classifier_options"])
+
+            error[i_qoi] = [[] for _ in range(len(np.unique(megpc[i_qoi].classifier.domains)))]
+            p_matrix = [0 for _ in range(megpc[i_qoi].n_gpc)]
+            p_matrix_norm = [0 for _ in range(megpc[i_qoi].n_gpc)]
+            dim = [0 for _ in range(megpc[i_qoi].n_gpc)]
+            parameters= [OrderedDict() for _ in range(megpc[i_qoi].n_gpc)]
+            problem = [0 for _ in range(megpc[i_qoi].n_gpc)]
+            basis_order = OrderedDict()
+            n_grid_reinit = [0 for _ in range(megpc[i_qoi].n_gpc)]
+
+            # determine initial projection and initialize sub-gPCs
+            for d in np.unique(megpc[i_qoi].domains):
+
+                if self.options["projection"]:
+                    p_matrix[d], _ = determine_projection_matrix(
+                        gradient_results=grad_res_3D_all[megpc[i_qoi].domains[gradient_idx] == d, q_idx, :],
+                        lambda_eps=self.options["lambda_eps_gradient"])
+
+                    p_matrix_norm[d] = np.sum(np.abs(p_matrix[d]), axis=1)
+                    dim[d] = p_matrix[d].shape[0]
+
+                    for i in range(dim[d]):
+                        parameters[d]["n{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
+
+                    problem[d] = Problem(model=self.problem.model, parameters=parameters[d])
+
+                else:
+                    p_matrix[d] = None
+                    p_matrix_norm[d] = None
+                    dim[d] = problem_original.dim
+                    parameters[d] = problem_original.parameters_random
+                    problem[d] = copy.deepcopy(problem_original)
+
+                # Set up reduced gPC for this domain
+                megpc[i_qoi].add_sub_gpc(problem=problem[d],
+                                         order=[self.options["order_start"] for _ in range(dim[d])],
+                                         order_max=self.options["order_start"],
+                                         order_max_norm=self.options["order_max_norm"],
+                                         interaction_order=self.options["interaction_order"],
+                                         interaction_order_current=self.options["interaction_order"],
+                                         options=self.options,
+                                         domain=d,
+                                         validation=None)
+
+                # save original problem in gpc object
+                megpc[i_qoi].gpc[d].problem_original = copy.deepcopy(problem_original)
+
+                # save projection matrix in gPC object
+                megpc[i_qoi].gpc[d].p_matrix = copy.deepcopy(p_matrix[d])
+                megpc[i_qoi].gpc[d].p_matrix_norm = copy.deepcopy(p_matrix_norm[d])
+
+                # initialize dict containing approximation orders of sub-gPCs [order, interaction_order_current]
+                basis_order["poly_dom_{}".format(d)] = np.array([self.options["order_start"],
+                                                                 self.options["interaction_order"]])
+
+                # initialize solver settings
+                megpc[i_qoi].gpc[d].solver = self.options["solver"]
+                megpc[i_qoi].gpc[d].settings = self.options["settings"]
+
+                # extend initial grid and perform additional simulations if necessary
+                if not self.options["adaptive_sampling"] or megpc[i_qoi].gpc[d].solver == "Moore-Penrose":
+                    n_coeffs = get_num_coeffs_sparse(
+                        order_dim_max=[self.options["order_start"] for _ in range(dim[d])],
+                        order_glob_max=self.options["order_start"],
+                        order_inter_max=self.options["interaction_order"],
+                        order_inter_current=self.options["interaction_order"],
+                        dim=dim[d])
+
+                    n_grid_reinit[d] = n_coeffs * self.options["matrix_ratio"]
+
+                # Check if we have enough samples in this particular domain for the given order we start
+                if n_grid_reinit[d] > np.sum(megpc[i_qoi].domains == d):
+
+                    # extend random grid
+                    grid.extend_random_grid(n_grid_new=grid.n_grid - np.sum(megpc[i_qoi].domains == d) + n_grid_reinit[d],
+                                            domain=d)
+
+                    megpc[i_qoi].grid = copy.deepcopy(grid)
+
+            if grid.n_grid > i_grid:
+
+                # Run some more initial simulations
+                iprint("Performing {} more initial simulations "
+                       "to fulfil order constraint!".format(grid.n_grid - i_grid),
+                       tab=0, verbose=self.options["verbose"])
+
+                start_time = time.time()
+
+                res_new = com.run(model=self.problem.model,
+                                  problem=self.problem,
+                                  coords=grid.coords[i_grid:, ],
+                                  coords_norm=grid.coords_norm[i_grid:, ],
+                                  i_iter=None,
+                                  i_subiter=None,
+                                  fn_results=self.options["fn_results"],
+                                  print_func_time=self.options["print_func_time"],
+                                  verbose=self.options["verbose"])
+
+                # add results to results array
+                res_all = np.vstack((res_all, res_new))
+                i_grid = grid.n_grid
+
+                iprint('Total function evaluation: ' + str(time.time() - start_time) + ' sec',
+                       tab=0, verbose=self.options["verbose"])
+
+                # Determine gradient [n_grid x n_out x dim]
+                if self.options["gradient_enhanced"] or self.options["projection"]:
+                    if self.options["projection"] or self.options["gradient_calculation"] == "FD_fwd":
+                        method = "FD_fwd"
+                        dx = 1e-3
+                        distance_weight = None
+                    else:
+                        method = self.options["gradient_calculation"]
+                        dx = self.options["gradient_calculation_options"]["dx"]
+                        distance_weight = self.options["gradient_calculation_options"]["distance_weight"]
+
+                    start_time = time.time()
+
+                    grad_res_3D_all, gradient_idx = get_gradient(model=self.problem.model,
+                                                                 problem=self.problem,
+                                                                 grid=grid,
+                                                                 results=res_all,
+                                                                 com=com,
+                                                                 method=method,
+                                                                 gradient_results_present=grad_res_3D_all_FD_fwd,
+                                                                 gradient_idx_skip=gradient_idx_FD_fwd,
+                                                                 i_iter=None,
+                                                                 i_subiter=None,
+                                                                 print_func_time=self.options["print_func_time"],
+                                                                 dx=dx,
+                                                                 distance_weight=distance_weight,
+                                                                 verbose=self.options["verbose"])
+
+                    if method == "FD_fwd":
+                        gradient_idx_FD_fwd = gradient_idx
+                        grad_res_3D_all_FD_fwd = grad_res_3D_all
+                    else:
+                        gradient_idx_FD_fwd = None
+                        grad_res_3D_all_FD_fwd = None
+
+                    iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
+                           tab=0, verbose=self.options["verbose"])
+
+                # check validity of results and resample in case the model could not be evaluated at some sampling points
+                res_all, grad_res_3D_all, gradient_idx, grid = self.check_results(results=res_all,
+                                                                                  gradient_results=grad_res_3D_all,
+                                                                                  gradient_results_idx=gradient_idx,
+                                                                                  grid=grid,
+                                                                                  com=com)
+
+                megpc[i_qoi].grid = copy.deepcopy(grid)
+
+                # update classifier
+                iprint("Updating classifier ...", tab=0, verbose=self.options["verbose"])
+                megpc[i_qoi].update_classifier(coords=megpc[i_qoi].grid.coords_norm,
+                                               results=res_all[:, q_idx][:, np.newaxis])
+
+            # create validation set if necessary
+            if self.options["error_type"] == "nrmsd" and megpc[0].validation is None:
+                iprint("Determining validation set of size {} "
+                       "for NRMSD error calculation ...".format(int(self.options["n_samples_validation"])),
+                       tab=0, verbose=self.options["verbose"])
+                megpc[0].create_validation_set(n_samples=self.options["n_samples_validation"],
+                                               n_cpu=self.options["n_cpu"],
+                                               gradient=self.options["gradient_enhanced"])
+
+            elif self.options["error_type"] == "nrmsd" and megpc[0].validation is not None:
+                megpc[i_qoi].validation = copy.deepcopy(megpc[0].validation)
+
+            extended_basis = True
+
+            # initialize domain specific error
+            eps = np.array([self.options["eps"] + 1.0 for _ in range(megpc[i_qoi].n_gpc)])
+
+            # Main iterations (order)
+            while (eps > self.options["eps"]).any():
+
+                stop_by_order = [(basis_order["poly_dom_{}".format(i)] == [self.options["order_end"],
+                                                                           self.options["interaction_order"]]).all() for
+                                 i in range(megpc[i_qoi].n_gpc)]
+                stop_by_error = eps < self.options["eps"]
+
+                # print("stop_by_order: {}".format(stop_by_order))
+                # print("stop_by_error: {}".format(stop_by_error))
+                # print("eps: {}".format(eps))
+
+                # TODO: ValueError: operands could not be broadcast together with shapes (2,) (3,)
+                if np.logical_or(stop_by_order, stop_by_error).all():
+                    break
+
+                iprint("Refining domain boundary ...", tab=0, verbose=self.options["verbose"])
+
+                # determine grid points close to discontinuity
+                coords_norm_disc = get_coords_discontinuity(classifier=megpc[i_qoi].classifier,
+                                                            x_min=[-1 for _ in range(megpc[i_qoi].problem.dim)],
+                                                            x_max=[+1 for _ in range(megpc[i_qoi].problem.dim)],
+                                                            n_coords_disc=self.options["n_samples_discontinuity"],
+                                                            border_sampling="structured")
+
+                coords_disc = grid.get_denormalized_coordinates(coords_norm_disc)
+
+                # add grid points close to discontinuity to global grid
+                grid.extend_random_grid(coords=coords_disc,
+                                        coords_norm=coords_norm_disc,
+                                        gradient=self.options["gradient_enhanced"])
+
+                # run simulations close to discontinuity
+                iprint("Performing {} simulations to refine discontinuity location!".format(
+                    self.options["n_samples_discontinuity"]), tab=0, verbose=self.options["verbose"])
+
+                start_time = time.time()
+
+                res_disc = com.run(model=self.problem.model,
+                                   problem=self.problem,
+                                   coords=coords_disc,
+                                   coords_norm=coords_norm_disc,
+                                   i_iter="Domain boundary",
+                                   i_subiter=None,
+                                   fn_results=self.options["fn_results"],
+                                   print_func_time=self.options["print_func_time"],
+                                   verbose=self.options["verbose"])
+
+                iprint('Total function evaluation: ' + str(time.time() - start_time) + ' sec',
+                       tab=0, verbose=self.options["verbose"])
+
+                # add results to results array
+                res_all = np.vstack((res_all, res_disc))
+
+                # Determine gradient [n_grid x n_out x dim]
+                if self.options["gradient_enhanced"] or self.options["projection"]:
+                    start_time = time.time()
+
+                    grad_res_3D_all, gradient_idx = get_gradient(model=self.problem.model,
+                                                                 problem=self.problem,
+                                                                 grid=grid,
+                                                                 results=res_all,
+                                                                 com=com,
+                                                                 method=self.options["gradient_calculation"],
+                                                                 gradient_results_present=grad_res_3D_all_FD_fwd,
+                                                                 gradient_idx_skip=gradient_idx_FD_fwd,
+                                                                 i_iter="Domain boundary",
+                                                                 i_subiter=None,
+                                                                 print_func_time=self.options["print_func_time"],
+                                                                 dx=self.options["gradient_calculation_options"]["dx"],
+                                                                 distance_weight=self.options["gradient_calculation_options"]["distance_weight"],
+                                                                 verbose=self.options["verbose"])
+
+                    if self.options["gradient_calculation"] == "FD_fwd":
+                        gradient_idx_FD_fwd = gradient_idx
+                        grad_res_3D_all_FD_fwd = grad_res_3D_all
+
+                    iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
+                           tab=0, verbose=self.options["verbose"])
+
+                # check validity of results and resample in case the model could not be evaluated at some sampling points
+                res_all, grad_res_3D_all, gradient_idx, grid = self.check_results(results=res_all,
+                                                                                  gradient_results=grad_res_3D_all,
+                                                                                  gradient_results_idx=gradient_idx,
+                                                                                  grid=grid,
+                                                                                  com=com)
+
+                i_grid = grid.n_grid
+
+                # crop results to considered qoi
+                if self.options["qoi"] != "all":
+                    res = copy.deepcopy(res_all)
+                    grad_res_3D = copy.deepcopy(grad_res_3D_all)
+
+                else:
+                    res = res_all[:, q_idx][:, np.newaxis]
+
+                    if grad_res_3D_all is not None:
+                        grad_res_3D = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
+
+                # Write grid in gpc object
+                megpc[i_qoi].grid = copy.deepcopy(grid)
+
+                # update classifier
+                iprint("Updating classifier ...", tab=0, verbose=self.options["verbose"])
+                megpc[i_qoi].update_classifier(coords=megpc[i_qoi].grid.coords_norm,
+                                               results=res_all[:, q_idx][:, np.newaxis])
+
+                # update sub-gPCs if number of domains changed
+                if len(np.unique(megpc[i_qoi].domains)) != len(megpc[i_qoi].gpc):
+
+                    iprint("New domains found! Updating number of sub-gPCs from {} to {} ".
+                           format(len(megpc[i_qoi].gpc), len(np.unique(megpc[i_qoi].domains))),
+                           tab=0, verbose=self.options["verbose"])
+
+                    megpc[i_qoi].gpc = None
+
+                    megpc[i_qoi].init_classifier(coords=megpc[i_qoi].grid.coords_norm,
+                                                 results=res_all[:, q_idx][:, np.newaxis],
+                                                 algorithm=self.options["classifier"],
+                                                 options=self.options["classifier_options"])
+
+                    basis_order["poly_dom_{}".format(d)][0] = self.options["order_start"]
+                    basis_order["poly_dom_{}".format(d)][1] = self.options["interaction_order"]
+
+                    # eps = np.hstack((eps, np.array(self.options["eps"] + 1)))
+                    eps = np.array([self.options["eps"] + 1.0 for _ in range(len(np.unique(megpc[i_qoi].domains)))])
+
+                    for i_gpc, d in enumerate(np.unique(megpc[i_qoi].domains)):
+                        megpc[i_qoi].add_sub_gpc(problem=problem_original,
+                                                 order=basis_order["poly_dom_{}".format(d)][0] * np.ones(
+                                                     self.problem.dim),
+                                                 order_max=self.options["order_start"],
+                                                 order_max_norm=self.options["order_max_norm"],
+                                                 interaction_order=self.options["interaction_order"],
+                                                 interaction_order_current=basis_order["poly_dom_{}".format(d)][1],
+                                                 options=self.options,
+                                                 domain=d,
+                                                 validation=None)
+
+                        # save original problem in gpc object
+                        megpc[i_qoi].gpc[d].problem_original = copy.deepcopy(problem_original)
+
+                        # initialize domain specific interaction order and other settings
+                        megpc[i_qoi].gpc[i_gpc].solver = self.options["solver"]
+                        megpc[i_qoi].gpc[i_gpc].settings = self.options["settings"]
+
+                # update projection matrices
+                if self.options["projection"]:
+                    p_matrix = [0 for _ in range(megpc[i_qoi].n_gpc)]
+                    p_matrix_norm = [0 for _ in range(megpc[i_qoi].n_gpc)]
+                    dim = [0 for _ in range(megpc[i_qoi].n_gpc)]
+                    parameters = [OrderedDict() for _ in range(megpc[i_qoi].n_gpc)]
+                    problem = [0 for _ in range(megpc[i_qoi].n_gpc)]
+
+                    for d in np.unique(megpc[i_qoi].domains):
+                        p_matrix[d], _ = determine_projection_matrix(
+                            gradient_results=grad_res_3D_all[megpc[i_qoi].domains[gradient_idx] == d, q_idx, :],
+                            lambda_eps=self.options["lambda_eps_gradient"])
+
+                        p_matrix_norm[d] = np.sum(np.abs(p_matrix[d]), axis=1)
+                        dim[d] = p_matrix[d].shape[0]
+
+                        for i in range(dim[d]):
+                            parameters[d]["n{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
+
+                        problem[d] = Problem(model=self.problem.model, parameters=parameters[d])
+
+                        # replace sub-gpc with the one containing the reduced problem
+                        megpc[i_qoi].add_sub_gpc(problem=problem[d],
+                                                 order=basis_order["poly_dom_{}".format(d)][0] * np.ones(dim[d]),
+                                                 order_max=self.options["order_start"],
+                                                 order_max_norm=self.options["order_max_norm"],
+                                                 interaction_order=self.options["interaction_order"],
+                                                 interaction_order_current=basis_order["poly_dom_{}".format(d)][1],
+                                                 options=self.options,
+                                                 domain=d,
+                                                 validation=None)
+
+                        # save original problem in gpc object
+                        megpc[i_qoi].gpc[d].problem_original = copy.deepcopy(problem_original)
+
+                        # save projection matrix in gPC object
+                        megpc[i_qoi].gpc[d].p_matrix = copy.deepcopy(p_matrix[d])
+                        megpc[i_qoi].gpc[d].p_matrix_norm = copy.deepcopy(p_matrix_norm[d])
+
+                        # initialize domain specific interaction order and other settings
+                        megpc[i_qoi].gpc[d].solver = self.options["solver"]
+                        megpc[i_qoi].gpc[d].settings = self.options["settings"]
+
+                # update gpc approximation with new grid points close to discontinuity
+                # assign grids to sub-gPCs (rotate sub-grids in case of projection)
+                megpc[i_qoi].assign_grids(gradient_idx=gradient_idx)
+
+                # Initialize gpc matrices
+                megpc[i_qoi].init_gpc_matrices()
+
+                # Compute gpc coefficients
+                if self.options["gradient_enhanced"]:
+                    grad_res_3D_passed = grad_res_3D
+                else:
+                    grad_res_3D_passed = None
+
+                coeffs[i_qoi] = megpc[i_qoi].solve(results=res,
+                                                   gradient_results=grad_res_3D_passed,
+                                                   solver=self.options["solver"],
+                                                   settings=self.options["settings"],
+                                                   verbose=self.options["verbose"])
+
+                # domain specific error
+                for i_gpc, d in enumerate(np.unique(megpc[i_qoi].domains)):
+                    eps[d] = megpc[i_qoi].validate(coeffs=coeffs[i_qoi],
+                                                   results=res,
+                                                   domain=d,
+                                                   output_idx=output_idx_passed_validation)
+                    error[i_qoi][d].append(eps[d])
+
+                    iprint("-> Domain: {} {} {} "
+                           "error = {}".format(d,
+                                               self.options["error_norm"],
+                                               self.options["error_type"],
+                                               eps[d]), tab=0, verbose=self.options["verbose"])
+
+                # loop over domains and increase order if necessary
+                for i_gpc, d in enumerate(np.unique(megpc[i_qoi].domains)):
+
+                    skip = (basis_order["poly_dom_{}".format(d)] ==
+                            [self.options["order_end"], self.options["interaction_order"]]).all()
+
+                    if (eps[d] > self.options["eps"]) and not skip:
+
+                        # increase basis by 1 interaction order
+                        order_new = increment_basis(order_current=basis_order["poly_dom_{}".format(d)][0],
+                                                    interaction_order_current=basis_order["poly_dom_{}".format(d)][1],
+                                                    interaction_order_max=self.options["interaction_order"],
+                                                    incr=basis_increment)
+
+                        basis_order["poly_dom_{}".format(d)][0] = order_new[0]
+                        basis_order["poly_dom_{}".format(d)][1] = order_new[1]
+
+                        print_str = "Domain: {}, Order: #{}, Sub-iteration: #{}".format(
+                            d,
+                            basis_order["poly_dom_{}".format(d)][0],
+                            basis_order["poly_dom_{}".format(d)][1])
+
+                        iprint(print_str, tab=0, verbose=self.options["verbose"])
+                        iprint("=" * len(print_str), tab=0, verbose=self.options["verbose"])
+
+                        # update basis
+                        b_added = megpc[i_qoi].gpc[d].basis.set_basis_poly(
+                            order=basis_order["poly_dom_{}".format(d)][0] * np.ones(dim[d]),
+                            order_max=basis_order["poly_dom_{}".format(d)][0],
+                            order_max_norm=self.options["order_max_norm"],
+                            interaction_order=self.options["interaction_order"],
+                            interaction_order_current=basis_order["poly_dom_{}".format(d)][1],
+                            problem=problem[d])
+
+                        # continue algorithm if no basis function was added because of max norm constraint
+                        if b_added is not None:
+                            extended_basis = True
+                        else:
+                            extended_basis = False
+                            # iprint("-> Domain: {} {} {} "
+                            #        "error = {}".format(d,
+                            #                            self.options["error_norm"],
+                            #                            self.options["error_type"],
+                            #                            eps[d]), tab=0, verbose=self.options["verbose"])
+                            # iprint("-> No basis functions to add in domain {} ... Continuing ... ".format(d),
+                            #        tab=0, verbose=self.options["verbose"])
+                            continue
+
+                        # update gpc matrix
+                        gradient_idx_gpc = get_gradient_idx_domain(domains=megpc[i_qoi].domains,
+                                                                   d=d,
+                                                                   gradient_idx=megpc[i_qoi].gradient_idx)
+
+                        megpc[i_qoi].gpc[d].init_gpc_matrix(gradient_idx=gradient_idx_gpc)
+
+                        # determine gpc coefficients with new basis but old samples
+                        if self.options["gradient_enhanced"]:
+                            grad_res_3D_passed = grad_res_3D[megpc[i_qoi].domains[gradient_idx] == d, :, :]
+                        else:
+                            grad_res_3D_passed = None
+
+                        coeffs[i_qoi][d] = megpc[i_qoi].gpc[d].solve(results=res[megpc[i_qoi].domains == d, ],
+                                                                     gradient_results=grad_res_3D_passed,
+                                                                     solver=megpc[i_qoi].gpc[d].solver,
+                                                                     settings=megpc[i_qoi].gpc[d].settings,
+                                                                     verbose=self.options["verbose"])
+
+                        # Add samples
+                        add_samples = True  # if adaptive sampling is False, the loop will be only executed once
+                        delta_eps_target = 1e-1
+                        delta_eps = delta_eps_target + 1
+                        delta_samples = 4*5e-2
+
+                        if self.options["adaptive_sampling"]:
+                            iprint("Starting adaptive sampling:", tab=0, verbose=self.options["verbose"])
+
+                        # only increase samples if error increased and until error converges again
+                        while add_samples and delta_eps > delta_eps_target and eps[d] > self.options["eps"]:
+
+                            if not self.options["adaptive_sampling"]:
+                                add_samples = False
+
+                            # new sample size
+                            if extended_basis and self.options["adaptive_sampling"]:
+                                # do not increase sample size immediately when basis was extended
+                                # try first with old samples
+                                n_grid_new = megpc[i_qoi].gpc[d].grid.n_grid
+                            elif self.options["adaptive_sampling"] and not first_iter:
+                                # increase sample size stepwise (adaptive sampling)
+                                n_grid_new = int(np.ceil(megpc[i_qoi].gpc[d].grid.n_grid +
+                                                         delta_samples * megpc[i_qoi].gpc[d].basis.n_basis))
+                            else:
+                                # increase sample size according to matrix ratio w.r.t. number of basis functions
+                                n_grid_new = int(
+                                    np.ceil(megpc[i_qoi].gpc[d].basis.n_basis * self.options["matrix_ratio"]))
+
+                            # run model if grid points were added
+                            if megpc[i_qoi].gpc[d].grid.n_grid < n_grid_new or extended_basis:
+                                # extend grid
+                                if megpc[i_qoi].gpc[d].grid.n_grid < n_grid_new:
+                                    iprint("Extending grid in domain {} from {} to {} by {} sampling points "
+                                           "(global grid: {})".format(d, megpc[i_qoi].gpc[d].grid.n_grid, n_grid_new,
+                                                                      n_grid_new - megpc[i_qoi].gpc[d].grid.n_grid,
+                                                                      megpc[i_qoi].grid.n_grid),
+                                           tab=0, verbose=self.options["verbose"])
+
+                                    # add grid points in this domain to global grid
+                                    grid.extend_random_grid(
+                                        n_grid_new=grid.n_grid - megpc[i_qoi].gpc[d].grid.n_grid + n_grid_new,
+                                        classifier=megpc[i_qoi].classifier,
+                                        domain=d,
+                                        gradient=self.options["gradient_enhanced"])
+
+                                    # run simulations
+                                    iprint("Performing simulations {} to {}".format(
+                                        i_grid + 1, grid.coords.shape[0]),
+                                        tab=0, verbose=self.options["verbose"])
+
+                                    start_time = time.time()
+
+                                    res_new = com.run(model=self.problem.model,
+                                                      problem=self.problem,
+                                                      coords=grid.coords[int(i_grid):, :],
+                                                      coords_norm=grid.coords_norm[int(i_grid):, :],
+                                                      i_iter=basis_order["poly_dom_{}".format(d)][0],
+                                                      i_subiter=basis_order["poly_dom_{}".format(d)][1],
+                                                      fn_results=self.options["fn_results"],
+                                                      print_func_time=self.options["print_func_time"],
+                                                      verbose=self.options["verbose"])
+
+                                    iprint('Total parallel function evaluation {} sec'.format(
+                                        str(time.time() - start_time)),
+                                        tab=0, verbose=self.options["verbose"])
+
+                                    # append to results array containing all qoi
+                                    res_all = np.vstack([res_all, res_new])
+
+                                    if self.options["gradient_enhanced"] or self.options["projection"]:
+                                        start_time = time.time()
+
+                                        grad_res_3D_all, gradient_idx = get_gradient(model=self.problem.model,
+                                                                                     problem=self.problem,
+                                                                                     grid=grid,
+                                                                                     results=res_all,
+                                                                                     com=com,
+                                                                                     method=self.options["gradient_calculation"],
+                                                                                     gradient_results_present=grad_res_3D_all_FD_fwd,
+                                                                                     gradient_idx_skip=gradient_idx_FD_fwd,
+                                                                                     i_iter=basis_order["poly_dom_{}".format(d)][0],
+                                                                                     i_subiter=basis_order["poly_dom_{}".format(d)][1],
+                                                                                     print_func_time=self.options["print_func_time"],
+                                                                                     dx=self.options["gradient_calculation_options"]["dx"],
+                                                                                     distance_weight=self.options["gradient_calculation_options"]["distance_weight"],
+                                                                                     verbose=self.options["verbose"])
+
+                                        if self.options["gradient_calculation"] == "FD_fwd":
+                                            gradient_idx_FD_fwd = gradient_idx
+                                            grad_res_3D_all_FD_fwd = grad_res_3D_all
+
+                                        iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
+                                               tab=0, verbose=self.options["verbose"])
+
+                                    # check validity of results and resample in case the model could not be evaluated at some sampling points
+                                    res_all, grad_res_3D_all, gradient_idx, grid = self.check_results(
+                                        results=res_all,
+                                        gradient_results=grad_res_3D_all,
+                                        gradient_results_idx=gradient_idx,
+                                        grid=grid,
+                                        com=com)
+
+                                    # crop results to considered qoi
+                                    if self.options["qoi"] != "all":
+                                        res = copy.deepcopy(res_all)
+                                        grad_res_3D = copy.deepcopy(grad_res_3D_all)
+
+                                    else:
+                                        res = res_all[:, q_idx][:, np.newaxis]
+
+                                        if grad_res_3D_all is not None:
+                                            grad_res_3D = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
+
+                                    i_grid = grid.coords.shape[0]
+
+                                    # update classifier
+                                    iprint("Updating classifier ...", tab=0, verbose=self.options["verbose"])
+                                    megpc[i_qoi].update_classifier(coords=grid.coords_norm,
+                                                                   results=res_all[:, q_idx][:, np.newaxis])
+
+                                    # TODO: the number of sub-gpcs could change here :/
+                                    # update projection matrices
+                                    if self.options["projection"]:
+
+                                        for dd in np.unique(megpc[i_qoi].domains):
+
+                                            p_matrix[dd], _ = determine_projection_matrix(
+                                                gradient_results=grad_res_3D_all[megpc[i_qoi].domains[gradient_idx] ==
+                                                                                 dd, q_idx, :],
+                                                lambda_eps=self.options["lambda_eps_gradient"])
+
+                                            p_matrix_norm[dd] = np.sum(np.abs(p_matrix[dd]), axis=1)
+                                            dim[dd] = p_matrix[dd].shape[0]
+
+                                            for i in range(dim[d]):
+                                                parameters[d]["n{}".format(i)] = Beta(pdf_shape=[1., 1.],
+                                                                                      pdf_limits=[-1., 1.])
+
+                                            problem[d] = Problem(model=self.problem.model, parameters=parameters[d])
+
+                                            # replace sub-gpc with the one containing the reduced problem
+                                            megpc[i_qoi].add_sub_gpc(problem=problem[d],
+                                                                     order=basis_order["poly_dom_{}".format(d)][
+                                                                               0] * np.ones(dim[d]),
+                                                                     order_max=self.options["order_start"],
+                                                                     order_max_norm=self.options["order_max_norm"],
+                                                                     interaction_order=self.options[
+                                                                         "interaction_order"],
+                                                                     interaction_order_current=
+                                                                     basis_order["poly_dom_{}".format(d)][1],
+                                                                     options=self.options,
+                                                                     domain=d,
+                                                                     validation=None)
+
+                                            # save original problem in gpc object
+                                            megpc[i_qoi].gpc[d].problem_original = copy.deepcopy(problem_original)
+
+                                            # save projection matrix in gPC object
+                                            megpc[i_qoi].gpc[d].p_matrix = copy.deepcopy(p_matrix[d])
+                                            megpc[i_qoi].gpc[d].p_matrix_norm = copy.deepcopy(p_matrix_norm[d])
+
+                                            # initialize domain specific interaction order and other settings
+                                            megpc[i_qoi].gpc[d].solver = self.options["solver"]
+                                            megpc[i_qoi].gpc[d].settings = self.options["settings"]
+
+                                    # update and assign grids
+                                    megpc[i_qoi].grid = copy.deepcopy(grid)
+
+                                    # assign grids to sub-gPCs (rotate sub-grids in case of projection)
+                                    megpc[i_qoi].assign_grids(gradient_idx=gradient_idx)
+
+                                    # update gpc matrix
+                                    gradient_idx_gpc = get_gradient_idx_domain(domains=megpc[i_qoi].domains,
+                                                                               d=d,
+                                                                               gradient_idx=megpc[i_qoi].gradient_idx)
+
+                                    megpc[i_qoi].gpc[d].init_gpc_matrix(gradient_idx=gradient_idx_gpc)
+
+                                    # determine gpc coefficients
+                                    if self.options["gradient_enhanced"]:
+                                        grad_res_3D_passed = grad_res_3D[megpc[i_qoi].domains[gradient_idx] == d, :, :]
+                                    else:
+                                        grad_res_3D_passed = None
+
+                                    coeffs[i_qoi][d] = megpc[i_qoi].gpc[d].solve(
+                                        results=res[megpc[i_qoi].domains == d, ],
+                                        gradient_results=grad_res_3D_passed,
+                                        solver=megpc[i_qoi].gpc[d].solver,
+                                        settings=megpc[i_qoi].gpc[d].settings,
+                                        verbose=self.options["verbose"])
+
+                                # validate gpc approximation
+                                eps[d] = megpc[i_qoi].validate(coeffs=coeffs[i_qoi],
+                                                               results=res,
+                                                               domain=d,
+                                                               output_idx=output_idx_passed_validation)
+                                error[i_qoi][d].append(eps[d])
+
+                                if extended_basis or first_iter:
+                                    eps_ref = copy.deepcopy(eps[d])
+                                else:
+                                    delta_eps = np.abs((error[i_qoi][d][-1] -
+                                                        error[i_qoi][d][-2]) / eps_ref)
+
+                                first_iter = False
+
+                                iprint("-> Domain: {} {} {} "
+                                       "error = {}".format(d,
+                                                           self.options["error_norm"],
+                                                           self.options["error_type"],
+                                                           eps[d]), tab=0, verbose=self.options["verbose"])
+
+                                # stop adaptive sampling and extend basis further if error
+                                # was decreased (except in very first iteration)
+                                if extended_basis and error[i_qoi][d][-1] < error[i_qoi][d][-2]:
+                                    break
+
+                                extended_basis = False
+
+                                # exit adaptive sampling loop if no adaptive sampling was chosen
+                                if not self.options["adaptive_sampling"]:
+                                    break
+
+                    # save gpc object and coeffs for this sub-iteration
+                    if self.options["fn_results"] is not None:
+
+                        with h5py.File(os.path.splitext(self.options["fn_results"])[0] + ".hdf5", "a") as f:
+
+                            # overwrite coeffs
+                            try:
+                                del f["coeffs" + hdf5_subfolder + "/dom_" + str(d)]
+                            except KeyError:
+                                pass
+
+                            f.create_dataset("coeffs" + hdf5_subfolder + "/dom_" + str(d),
+                                             data=coeffs[i_qoi][d], maxshape=None, dtype="float64")
+
+                            # overwrite domains
+                            try:
+                                del f["domains" + hdf5_subfolder]
+                            except KeyError:
+                                pass
+                            f.create_dataset("domains" + hdf5_subfolder,
+                                             data=megpc[i_qoi].domains, maxshape=None, dtype="int64")
+
+                            # save gpc matrix
+                            try:
+                                del f["gpc_matrix" + hdf5_subfolder + "/dom_" + str(d)]
+                            except KeyError:
+                                pass
+                            f.create_dataset("gpc_matrix" + hdf5_subfolder + "/dom_" + str(d),
+                                             data=megpc[i_qoi].gpc[d].gpc_matrix,
+                                             maxshape=None, dtype="float64")
+
+                            if megpc[i_qoi].gpc[d].p_matrix is not None:
+                                try:
+                                    del f["p_matrix" + hdf5_subfolder + "/dom_" + str(d)]
+                                except KeyError:
+                                    pass
+                                f.create_dataset("p_matrix" + hdf5_subfolder + "/dom_" + str(d),
+                                                 data=megpc[i_qoi].gpc[d].p_matrix,
+                                                 maxshape=None, dtype="float64")
+
+                            # save gradient gpc matrix
+                            if megpc[i_qoi].gpc[0].gpc_matrix_gradient is not None:
+                                try:
+                                    del f["gpc_matrix_gradient" + hdf5_subfolder + "/dom_" + str(d)]
+                                except KeyError:
+                                    pass
+                                if self.options["gradient_enhanced"]:
+                                    f.create_dataset("gpc_matrix_gradient" + hdf5_subfolder + "/dom_" + str(d),
+                                                     data=megpc[i_qoi].gpc[d].gpc_matrix_gradient,
+                                                     maxshape=None, dtype="float64")
+
+                            # save results
+                            try:
+                                del f["model_evaluations/results"]
+                            except KeyError:
+                                pass
+
+                            f.create_dataset("model_evaluations/results",
+                                             (res_all.shape[0], res_all.shape[1]),
+                                             maxshape=(None, None),
+                                             dtype="float64",
+                                             data=res_all)
+
+                            # save gradient of results
+                            if grad_res_3D is not None:
+
+                                try:
+                                    del f["model_evaluations/gradient_results"]
+                                    del f["model_evaluations/gradient_results_idx"]
+                                except KeyError:
+                                    pass
+
+                                grad_res_2D_all = ten2mat(grad_res_3D_all)
+                                f.create_dataset("model_evaluations/gradient_results",
+                                                 (grad_res_2D_all.shape[0], grad_res_2D_all.shape[1]),
+                                                 maxshape=(None, None),
+                                                 dtype="float64",
+                                                 data=grad_res_2D_all)
+
+                                f.create_dataset("model_evaluations/gradient_results_idx",
+                                                 dtype="int64",
+                                                 data=gradient_idx)
+
+                            try:
+                                del f["error" + hdf5_subfolder + "/dom_" + str(d)]
+                            except KeyError:
+                                pass
+                            f.create_dataset("error" + hdf5_subfolder + "/dom_" + str(d),
+                                             data=eps[d],
+                                             maxshape=None, dtype="float64")
+
+                basis_increment = 1
+
+            megpc[i_qoi].update_classifier(coords=megpc[i_qoi].grid.coords_norm,
+                                           results=res_all[:, q_idx][:, np.newaxis])
+
+            megpc[i_qoi].assign_grids(gradient_idx=gradient_idx)
+            megpc[i_qoi].init_gpc_matrices()
+
+            # determine gpc coefficients
+            #
+            #     grad_res_3D_passed = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
+            # else:
+            #     grad_res_3D_passed = None
+
+            # crop results to considered qoi
+            if self.options["qoi"] != "all":
+                res = copy.deepcopy(res_all)
+                grad_res_3D_passed = copy.deepcopy(grad_res_3D_all)
+
+            else:
+                res = res_all[:, q_idx][:, np.newaxis]
+                if grad_res_3D_all is not None:
+                    grad_res_3D_passed = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
+
+            if not self.options["gradient_enhanced"]:
+                grad_res_3D_passed = None
+
+            # determine gpc coefficients
+            coeffs[i_qoi] = megpc[i_qoi].solve(results=res,
+                                               gradient_results=grad_res_3D_passed,
+                                               solver=megpc[i_qoi].gpc[d].solver,
+                                               settings=megpc[i_qoi].gpc[d].settings,
+                                               verbose=self.options["verbose"])
+            megpc[i_qoi].error = error[i_qoi]
+
+            # save gpc object and gpc coeffs
+            if self.options["fn_results"] is not None:
+
+                with h5py.File(os.path.splitext(self.options["fn_results"])[0] + ".hdf5", "a") as f:
+
+                    try:
+                        fn_session = f["misc/fn_session"]
+
+                    except KeyError:
+                        f.create_dataset("misc/fn_session",
+                                         data=np.array([os.path.split(self.options["fn_session"])[1]]).astype("|S"))
+                        f.create_dataset("misc/fn_session_folder",
+                                         data=np.array([self.options["fn_session_folder"]]).astype("|S"))
+
+                    try:
+                        del f["grid"]
+                    except KeyError:
+                        pass
+
+                    f.create_dataset("grid/coords", data=grid.coords,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("grid/coords_norm", data=grid.coords_norm,
+                                     maxshape=None, dtype="float64")
+
+                    if megpc[i_qoi].grid.coords_gradient is not None:
+                        f.create_dataset("grid/coords_gradient",
+                                         data=grid.coords_gradient,
+                                         maxshape=None, dtype="float64")
+                        f.create_dataset("grid/coords_gradient_norm",
+                                         data=grid.coords_gradient_norm,
+                                         maxshape=None, dtype="float64")
+
+                    try:
+                        del f["model_evaluations"]
+                    except KeyError:
+                        pass
+                    f.create_dataset("model_evaluations/results", data=res_all,
+                                     maxshape=None, dtype="float64")
+                    if grad_res_3D_all is not None:
+                        f.create_dataset("model_evaluations/gradient_results", data=ten2mat(grad_res_3D_all),
+                                         maxshape=None, dtype="float64")
+                        f.create_dataset("model_evaluations/gradient_results_idx", data=gradient_idx,
+                                         maxshape=None, dtype="int64")
+
+                    try:
+                        f.create_dataset("misc/error_type", data=self.options["error_type"])
+                    except RuntimeError:
+                        pass
+
+                    if megpc[0].validation is not None:
+                        try:
+                            del f["validation"]
+                        except KeyError:
+                            f.create_dataset("validation/model_evaluations/results", data=megpc[0].validation.results,
+                                             maxshape=None, dtype="float64")
+                            f.create_dataset("validation/grid/coords", data=megpc[0].validation.grid.coords,
+                                             maxshape=None, dtype="float64")
+                            f.create_dataset("validation/grid/coords_norm", data=megpc[0].validation.grid.coords_norm,
+                                             maxshape=None, dtype="float64")
+
+                    # save gpc matrix
+                    for i_gpc, d in enumerate(np.unique(megpc[i_qoi].domains)):
+                        try:
+                            del f["gpc_matrix" + hdf5_subfolder + "/dom_" + str(d)]
+                        except KeyError:
+                            pass
+                        f.create_dataset("gpc_matrix" + hdf5_subfolder + "/dom_" + str(d),
+                                         data=megpc[i_qoi].gpc[d].gpc_matrix,
+                                         maxshape=None, dtype="float64")
+
+                        # save gradient gpc matrix
+                        if megpc[i_qoi].gpc[0].gpc_matrix_gradient is not None:
+                            try:
+                                del f["gpc_matrix_gradient" + hdf5_subfolder + "/dom_" + str(d)]
+                            except KeyError:
+                                pass
+                            if self.options["gradient_enhanced"]:
+                                f.create_dataset("gpc_matrix_gradient" + hdf5_subfolder + "/dom_" + str(d),
+                                                 data=megpc[i_qoi].gpc[d].gpc_matrix_gradient,
+                                                 maxshape=None, dtype="float64")
+
+                    try:
+                        for i_gpc in range(megpc[i_qoi].n_gpc):
+                            del f["coeffs" + hdf5_subfolder + "/dom_" + str(i_gpc)]
+                    except KeyError:
+                        pass
+
+                    for i_gpc in range(megpc[i_qoi].n_gpc):
+                        f.create_dataset("coeffs" + hdf5_subfolder + "/dom_" + str(i_gpc),
+                                         data=coeffs[i_qoi][i_gpc],
+                                         maxshape=None, dtype="float64")
+
+        com.close()
+
+        return megpc, coeffs, res_all
+
+
+class RegAdaptiveProjection(Algorithm):
+    """
+    Adaptive regression approach using projection and leave one out cross validation error estimation
+
+    Parameters
+    ----------
+    problem: Problem class instance
+        GPC problem under investigation
+    options["order_start"] : int, optional, default=0
+          Initial gPC expansion order (maximum order)
+    options["order_end"] : int, optional, default=10
+        Maximum Gpc expansion order to expand to (algorithm will terminate afterwards)
+    options["interaction_order"]: int, optional, default=dim
+        Define maximum interaction order of parameters (default: all interactions)
+    options["order_max_norm"]: float
+        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
+        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
+        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
+        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
+    options["n_grid_gradient"] : float, optional, default: 10
+        Number of initial grid points to determine gradient and projection matrix. When the algorithm goes
+        into the main interations the number will be increased depending on the options "matrix_ratio"
+        and "adaptive_sampling".
+    options["qoi"] : int or str, optional, default: 0
+        Choose for which QOI the projection is determined for. The other QOIs use the same projection.
+        Alternatively, the projection can be determined for every QOI independently (qoi_index or "all").
+    options["adaptive_sampling"] : boolean, optional, default: True
+        Adds samples adaptively to the expansion until the error is converged and continues by
+        adding new basis functions.
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> # initialize adaptive gPC algorithm
+    >>> algorithm = pygpc.RegAdaptiveProjection(problem=problem, options=options)
+    >>> # run algorithm
+    >>> gpc, coeffs, results = algorithm.run()
+    """
+
+    def __init__(self, problem, options, validation=None, grid=None):
+        """
+        Constructor; Initializes RegAdaptiveProjection algorithm
+        """
+        super(RegAdaptiveProjection, self).__init__(problem=problem, options=options, validation=validation, grid=grid)
+
+        # check contents of settings dict and set defaults
+        if "order_start" not in self.options.keys():
+            self.options["order_start"] = 0
+
+        if "order_end" not in self.options.keys():
+            self.options["order_end"] = 10
+
+        if "interaction_order" not in self.options.keys():
+            self.options["interaction_order"] = problem.dim
+
+        if "order_max_norm" not in self.options.keys():
+            self.options["order_max_norm"] = 1.
+
+        if "n_grid_gradient" not in self.options.keys():
+            self.options["n_grid_gradient"] = 10
+
+        if "qoi" not in self.options.keys():
+            self.options["qoi"] = 0
+
+        if "adaptive_sampling" not in self.options.keys():
+            self.options["adaptive_sampling"] = True
+
+        if self.options["qoi"] == "all":
+            self.qoi_specific = True
+        else:
+            self.qoi_specific = False
+
+    def run(self):
+        """
+        Runs adaptive gPC algorithm using projection to solve problem.
+
+        Returns
+        -------
+        gpc : GPC object instance
+            GPC object containing all information i.e., Problem, Model, Grid, Basis, RandomParameter instances
+        coeffs: ndarray of float [n_basis x n_out]
+            GPC coefficients
+        res : ndarray of float [n_grid x n_out]
+            Simulation results at n_grid points of the n_out output variables
+        """
+
+        if self.options["fn_results"] is not None:
+            fn_results = os.path.splitext(self.options["fn_results"])[0]
+
+            if os.path.exists(fn_results + ".hdf5"):
+                os.remove(fn_results + ".hdf5")
+            if os.path.exists(fn_results + "_temp.hdf5"):
+                os.remove(fn_results + "_temp.hdf5")
+        else:
+            fn_results = None
+
+        grad_res_3D = None
+        gradient_idx = None
+
+        # initialize iterators
+        eps = self.options["eps"] + 1.0
+        order = self.options["order_start"]
+        error = []
+        nrmsd = []
+        loocv = []
+
+        # make initial grid to determine gradients and projection matrix. By default, it is an LHS (ese) grid
+        if self.grid is not None:
+            print(f"Using user-predefined grid with n_grid={self.grid.n_grid}")
+            grid_original = self.options["grid"](parameters_random=self.problem.parameters_random,
+                                                 coords=self.grid.coords,
+                                                 coords_norm=self.grid.coords_norm,
+                                                 coords_gradient=self.grid.coords_gradient,
+                                                 coords_gradient_norm=self.grid.coords_gradient_norm,
+                                                 options=self.options["grid_options"])
+
+        elif self.options["grid"] == Random or self.options["grid"] == GP:
+            print(f"Creating initial grid ({self.options['grid'].__init__}) with n_grid={int(self.options['n_grid_gradient'])}")
+            grid_original = self.options["grid"](parameters_random=self.problem.parameters_random,
+                                                 n_grid=self.options["n_grid_gradient"],
+                                                 options=self.options["grid_options"])
+        else:
+            print(f"Creating initial grid ({self.options['grid'].__init__}) with n_grid={int(self.options['n_grid_gradient'])}")
+            grid_original = LHS(parameters_random=self.problem.parameters_random,
+                                n_grid=self.options["n_grid_gradient"],
+                                options={"criterion": "ese",
+                                         "seed": self.options["grid_options"]["seed"]})
+
+        # Initialize parallel Computation class
+        com = Computation(n_cpu=self.n_cpu, matlab_model=self.options["matlab_model"])
+
+        # Run initial simulations to determine initial projection matrix
+        iprint("Performing {} simulations!".format(grid_original.coords.shape[0]),
+               tab=0, verbose=self.options["verbose"])
+
+        start_time = time.time()
+
+        res_all = com.run(model=self.problem.model,
+                          problem=self.problem,
+                          coords=grid_original.coords,
+                          coords_norm=grid_original.coords_norm,
+                          i_iter=self.options["order_start"],
+                          i_subiter=self.options["interaction_order"],
+                          fn_results=self.options["fn_results"],
+                          print_func_time=self.options["print_func_time"],
+                          verbose=self.options["verbose"])
+
+        i_grid = grid_original.n_grid
+
+        iprint('Total function evaluation: ' + str(time.time() - start_time) + ' sec',
+               tab=0, verbose=self.options["verbose"])
+
+        # Determine gradient for projection matrix (method: FD_fwd)
+        start_time = time.time()
+
+        grad_res_3D_all, gradient_idx = get_gradient(model=self.problem.model,
+                                                     problem=self.problem,
+                                                     grid=grid_original,
+                                                     results=res_all,
+                                                     com=com,
+                                                     method="FD_fwd",
+                                                     gradient_results_present=None,
+                                                     gradient_idx_skip=None,
+                                                     i_iter=self.options["order_start"],
+                                                     i_subiter=self.options["interaction_order"],
+                                                     print_func_time=self.options["print_func_time"],
+                                                     dx=1e-3,
+                                                     distance_weight=None,
+                                                     verbose=self.options["verbose"])
+
+        gradient_idx_FD_fwd = gradient_idx
+        grad_res_3D_all_FD_fwd = grad_res_3D_all
+
+        iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
+               tab=0, verbose=self.options["verbose"])
+
+        # check validity of results and resample in case the model could not be evaluated at some sampling points
+        res_all, grad_res_3D_all, gradient_idx, grid_original = self.check_results(
+            results=res_all,
+            gradient_results=grad_res_3D_all,
+            gradient_results_idx=gradient_idx,
+            grid=grid_original,
+            com=com)
+
+        # set qoi indices
+        if self.options["qoi"] == "all":
+            qoi_idx = np.arange(res_all.shape[1])
+            n_qoi = len(qoi_idx)
+
+        else:
+            qoi_idx = [self.options["qoi"]]
+            n_qoi = 1
+
+        # init variables
+        self.problem_reduced = [None for _ in range(n_qoi)]
+        gpc = [None for _ in range(n_qoi)]
+        coeffs = [None for _ in range(n_qoi)]
+        self.options["order_max"] = None
+
+        # loop over qoi (projection is qoi specific)
+        for i_qoi, q_idx in enumerate(qoi_idx):
+
+            basis_order = np.array([self.options["order_start"],
+                                    min(self.options["interaction_order"], self.options["order_start"])])
+
+            if self.options["qoi"] == "all":
+                qoi_idx_validate = q_idx
+            else:
+                qoi_idx_validate = np.arange(res_all.shape[1])
+
+            first_iter = True
+
+            # crop results to considered qoi
+            if self.options["qoi"] != "all":
+                res = copy.deepcopy(res_all)
+                grad_res_3D = copy.deepcopy(grad_res_3D_all)
+                hdf5_subfolder = ""
+
+            else:
+                res = res_all[:, q_idx][:, np.newaxis]
+                grad_res_3D = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
+                hdf5_subfolder = "/qoi_" + str(q_idx)
+
+            # copy results of initial simulation
+            # shutil.copy2(os.path.splitext(self.options["fn_results"])[0] + "_temp.hdf5", fn_results + ".hdf5")
+
+            # Set up initial reduced problem
+            # Determine projection matrix
+            p_matrix, p_matrix_complete = determine_projection_matrix(gradient_results=grad_res_3D_all[:, q_idx, :],
+                                                                      lambda_eps=self.options["lambda_eps_gradient"])
+            p_matrix_norm = np.sum(np.abs(p_matrix), axis=1)
+
+            # Set up initial reduced problem
+            dim_reduced = p_matrix.shape[0]
+            parameters_reduced = OrderedDict()
+
+            for i in range(dim_reduced):
+                parameters_reduced["n{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
+
+            self.problem_reduced[i_qoi] = Problem(model=self.problem.model, parameters=parameters_reduced)
+
+            # Create initial reduced gPC object
+            gpc[i_qoi] = Reg(problem=self.problem_reduced[i_qoi],
+                             order=[self.options["order_start"] for _ in range(dim_reduced)],
+                             order_max=self.options["order_start"],
+                             order_max_norm=self.options["order_max_norm"],
+                             interaction_order=self.options["interaction_order"],
+                             interaction_order_current=self.options["interaction_order"],
+                             options=self.options,
+                             validation=self.validation)
+
+            # save original problem in gpc object
+            gpc[i_qoi].problem_original = self.problem
+
+            extended_basis = False
+
+            # save projection matrix in gPC object
+            gpc[i_qoi].p_matrix = copy.deepcopy(p_matrix)
+            gpc[i_qoi].p_matrix_norm = copy.deepcopy(p_matrix_norm)
+
+            # copy global grid, passing it from qoi to qoi but in the first iteration, we have to initialize a new
+            # grid in case of L1, L1_LHS, LHS_L1 and FIM because they depend on the gpc object which can be different
+            # for every QOI due to different projections and termination criteria. We are passing the coordinates
+            # of the initial LHS (ese) grid to it
+            if self.options["grid"] in [L1, L1_LHS, LHS_L1, FIM]:
+                grid_original = self.options["grid"](parameters_random=self.problem.parameters_random,
+                                                     coords=grid_original.coords,
+                                                     coords_norm=grid_original.coords_norm,
+                                                     coords_gradient=grid_original.coords_gradient,
+                                                     coords_gradient_norm=grid_original.coords_gradient_norm,
+                                                     options=self.options["grid_options"],
+                                                     gpc=gpc[i_qoi])
+
+            # assign transformed grid
+            gpc[i_qoi].grid = project_grid(grid=grid_original, p_matrix=p_matrix, mode="reduce")
+
+            # Initialize gpc matrix
+            gpc[i_qoi].init_gpc_matrix(gradient_idx=gradient_idx)
+            gpc[i_qoi].n_grid.pop(0)
+            gpc[i_qoi].n_basis.pop(0)
+
+            gpc[i_qoi].solver = self.options["solver"]
+            gpc[i_qoi].settings = self.options["settings"]
+
+            # Main iterations (order)
+            while eps > self.options["eps"]:
+
+                if first_iter:
+                    basis_increment = 0
+                else:
+                    basis_increment = 1
+
+                # increase basis
+                basis_order[0], basis_order[1] = increment_basis(order_current=basis_order[0],
+                                                                 interaction_order_current=basis_order[1],
+                                                                 interaction_order_max=np.min([
+                                                                     self.options["interaction_order"],
+                                                                     self.problem_reduced[i_qoi].dim]),
+                                                                 incr=basis_increment)
+
+                if basis_order[0] > self.options["order_end"]:
+                    break
+
+                # update basis
+                b_added = gpc[i_qoi].basis.set_basis_poly(order=basis_order[0] *
+                                                                np.ones(self.problem_reduced[i_qoi].dim),
+                                                          order_max=basis_order[0],
+                                                          order_max_norm=self.options["order_max_norm"],
+                                                          interaction_order=self.options["interaction_order"],
+                                                          interaction_order_current=basis_order[1],
+                                                          problem=self.problem_reduced[i_qoi])
+
+                print_str = "Order/Interaction order: {}/{}".format(basis_order[0], basis_order[1])
+                iprint(print_str, tab=0, verbose=self.options["verbose"])
+                iprint("=" * len(print_str), tab=0, verbose=self.options["verbose"])
+
+                if b_added is not None:
+                    extended_basis = True
+
+                if self.options["adaptive_sampling"]:
+                    iprint("Starting adaptive sampling:", tab=0, verbose=self.options["verbose"])
+
+                add_samples = True  # if adaptive sampling is False, the while loop will be only executed once
+                delta_eps_target = 1e-1
+                delta_eps = delta_eps_target + 1
+                delta_samples = 5e-2
+
+                if gpc[i_qoi].error:
+                    eps_ref = gpc[i_qoi].error[-1]
+
+                while add_samples and delta_eps > delta_eps_target and eps > self.options["eps"]:
+
+                    if not self.options["adaptive_sampling"]:
+                        add_samples = False
+
+                    # new sample size
+                    if extended_basis and self.options["adaptive_sampling"]:
+                        # don't increase sample size immediately when basis was extended, try first with old samples
+                        n_grid_new = gpc[i_qoi].grid.n_grid
+                    elif self.options["adaptive_sampling"]:
+                        # increase sample size stepwise (adaptive sampling)
+                        n_grid_new = int(np.ceil(gpc[i_qoi].grid.n_grid + delta_samples * gpc[i_qoi].basis.n_basis))
+                    else:
+                        # increase sample size according to matrix ratio w.r.t. number of basis functions
+                        n_grid_new = int(np.ceil(gpc[i_qoi].basis.n_basis * self.options["matrix_ratio"]))
+
+                    # run model and update projection matrix if grid points were added
+                    # (Skip simulations of first run because we already simulated it)
+                    if i_grid < n_grid_new or extended_basis:
+                        # extend grid
+                        if i_grid < n_grid_new:
+                            iprint("Extending grid from {} to {} by {} sampling points".format(
+                                gpc[i_qoi].grid.n_grid, n_grid_new, n_grid_new - gpc[i_qoi].grid.n_grid),
+                                tab=0, verbose=self.options["verbose"])
+
+                            grid_original.gpc = gpc[i_qoi]
+                            grid_original.extend_random_grid(n_grid_new=n_grid_new)
+
+                            # run simulations
+                            iprint("Performing simulations " + str(i_grid + 1) + " to " +
+                                   str(grid_original.coords.shape[0]),
+                                   tab=0, verbose=self.options["verbose"])
+
+                            start_time = time.time()
+                            res_new = com.run(model=self.problem.model,
+                                              problem=self.problem,
+                                              coords=grid_original.coords[i_grid:grid_original.coords.shape[0]],
+                                              coords_norm=grid_original.coords_norm[
+                                                          i_grid:grid_original.coords.shape[0]],
+                                              i_iter=basis_order[0],
+                                              i_subiter=basis_order[1],
+                                              fn_results=gpc[i_qoi].fn_results,
+                                              print_func_time=self.options["print_func_time"],
+                                              verbose=self.options["verbose"])
+
+                            res_all = np.vstack((res_all, res_new))
+
+                            iprint('Total parallel function evaluation: ' + str(time.time() - start_time) + ' sec',
+                                   tab=0, verbose=self.options["verbose"])
+
+                            i_grid = grid_original.coords.shape[0]
+
+                            # Determine gradient and update projection matrix in case of gradient enhanced gPC
+                            start_time = time.time()
+                            grad_res_3D_all, gradient_idx = get_gradient(model=self.problem.model,
+                                                                         problem=self.problem,
+                                                                         grid=grid_original,
+                                                                         results=res_all,
+                                                                         com=com,
+                                                                         method=self.options["gradient_calculation"],
+                                                                         gradient_results_present=grad_res_3D_all_FD_fwd,
+                                                                         gradient_idx_skip=gradient_idx_FD_fwd,
+                                                                         i_iter=basis_order[0],
+                                                                         i_subiter=basis_order[1],
+                                                                         print_func_time=self.options["print_func_time"],
+                                                                         dx=self.options["gradient_calculation_options"]["dx"],
+                                                                         distance_weight=self.options["gradient_calculation_options"]["distance_weight"],
+                                                                         verbose=self.options["verbose"])
+
+                            if self.options["gradient_calculation"] == "FD_fwd":
+                                gradient_idx_FD_fwd = gradient_idx
+                                grad_res_3D_all_FD_fwd = grad_res_3D_all
+
+                            iprint('Gradient evaluation: ' + str(time.time() - start_time) + ' sec',
+                                   tab=0, verbose=self.options["verbose"])
+
+                            # check validity of results and resample in case the model could not be evaluated at some sampling points
+                            res_all, grad_res_3D_all, gradient_idx, grid_original = self.check_results(
+                                results=res_all,
+                                gradient_results=grad_res_3D_all,
+                                gradient_results_idx=gradient_idx,
+                                grid=grid_original,
+                                com=com)
+
+                            # Determine projection matrix
+                            p_matrix, p_matrix_complete = determine_projection_matrix(gradient_results=grad_res_3D_all[:, q_idx, :],
+                                                                                      lambda_eps=self.options["lambda_eps_gradient"])
+                            p_matrix_norm = np.sum(np.abs(p_matrix), axis=1)
+
+                            # save projection matrix in gPC object
+                            gpc[i_qoi].p_matrix = copy.deepcopy(p_matrix)
+                            gpc[i_qoi].p_matrix_norm = copy.deepcopy(p_matrix_norm)
+
+                            # Set up reduced gPC
+                            dim_reduced = p_matrix.shape[0]
+                            iprint("Dimension of reduced problem: {}".format(dim_reduced),
+                                   tab=0, verbose=self.options["verbose"])
+
+                            # Update gPC object if dimension has changed
+                            if dim_reduced != gpc[i_qoi].problem.dim:
+                                parameters_reduced = OrderedDict()
+
+                                for i in range(dim_reduced):
+                                    parameters_reduced["n{}".format(i)] = Beta(pdf_shape=[1., 1.],
+                                                                               pdf_limits=[-1., 1.])
+
+                                self.problem_reduced[i_qoi] = Problem(model=self.problem.model,
+                                                                      parameters=parameters_reduced)
+
+                                # Create reduced gPC object of order - 1 and add rest of basisfunctions
+                                # of this subiteration afterwards
+                                gpc[i_qoi] = Reg(problem=self.problem_reduced[i_qoi],
+                                                 order=basis_order[0] * np.ones(self.problem_reduced[i_qoi].dim),
+                                                 order_max=basis_order[0],
+                                                 order_max_norm=self.options["order_max_norm"],
+                                                 interaction_order=self.options["interaction_order"],
+                                                 interaction_order_current=basis_order[1],
+                                                 options=self.options,
+                                                 validation=self.validation)
+
+                                # save original problem
+                                gpc[i_qoi].problem_original = self.problem
+
+                                # save projection matrix in gPC object
+                                gpc[i_qoi].p_matrix = copy.deepcopy(p_matrix)
+                                gpc[i_qoi].p_matrix_norm = copy.deepcopy(p_matrix_norm)
+
+                                # Save settings and options in gpc object
+                                gpc[i_qoi].solver = self.options["solver"]
+                                gpc[i_qoi].settings = self.options["settings"]
+                                gpc[i_qoi].options = copy.deepcopy(self.options)
+                                gpc[i_qoi].error = error
+                                gpc[i_qoi].relative_error_nrmsd = nrmsd
+                                gpc[i_qoi].relative_error_loocv = loocv
+
+                    # assign transformed grid
+                    gpc[i_qoi].grid = project_grid(grid=grid_original, p_matrix=p_matrix, mode="reduce")
+
+                    # in case of L1, L1-LHS, LHS-L1 or FIM grids copy new gpc object into it
+                    if self.options["grid"] in [L1, L1_LHS, LHS_L1, FIM]:
+                        gpc[i_qoi].grid.gpc = gpc[i_qoi]
+
+                    # crop results to considered qoi
+                    if self.options["qoi"] != "all":
+                        res = copy.deepcopy(res_all)
+                        grad_res_3D = copy.deepcopy(grad_res_3D_all)
+                    else:
+                        res = res_all[:, q_idx][:, np.newaxis]
+                        grad_res_3D = grad_res_3D_all[:, q_idx, :][:, np.newaxis, :]
+
+                    # Someone might not use the gradient to determine the gpc coeffs
+                    if gpc[i_qoi].gradient:
+                        grad_res_3D_passed = grad_res_3D
+                        gpc[i_qoi].init_gpc_matrix(gradient_idx=gradient_idx)
+                    else:
+                        grad_res_3D_passed = None
+                        gpc[i_qoi].init_gpc_matrix(gradient_idx=None)
+
+                    # determine gpc coefficients
+                    coeffs[i_qoi] = gpc[i_qoi].solve(results=res,
+                                                     gradient_results=grad_res_3D_passed,
+                                                     solver=gpc[i_qoi].solver,
+                                                     settings=gpc[i_qoi].settings,
+                                                     verbose=self.options["verbose"])
+
+                    # Add a validation set if nrmsd is chosen and no validation set is yet present
+                    if self.options["error_type"] == "nrmsd" and not isinstance(gpc[0].validation, ValidationSet):
+                        gpc[0].create_validation_set(n_samples=self.options["n_samples_validation"],
+                                                     n_cpu=self.options["n_cpu"])
+
+                    elif self.options["error_type"] == "nrmsd" and isinstance(gpc[0].validation, ValidationSet):
+                        gpc[i_qoi].validation = copy.deepcopy(gpc[0].validation)
+
+                    # validate gpc approximation (determine nrmsd or loocv specified in options["error_type"])
+                    eps = gpc[i_qoi].validate(coeffs=coeffs[i_qoi],
+                                              results=res,
+                                              gradient_results=grad_res_3D_passed,
+                                              qoi_idx=qoi_idx_validate)
+
+                    # save error in case that dimension has changed and the gpc object had to be reinitialized
+                    error = copy.deepcopy(gpc[i_qoi].error)
+                    nrmsd = copy.deepcopy(gpc[i_qoi].relative_error_nrmsd)
+                    loocv = copy.deepcopy(gpc[i_qoi].relative_error_loocv)
+
+                    if extended_basis or first_iter:
+                        eps_ref = copy.deepcopy(eps)
+                    else:
+                        delta_eps = np.abs((gpc[i_qoi].error[-1] - gpc[i_qoi].error[-2]) / eps_ref)
+
+                    first_iter = False
+
+                    iprint("-> {} {} error = {}".format(self.options["error_norm"],
+                                                        self.options["error_type"],
+                                                        eps), tab=0, verbose=self.options["verbose"])
+
+                    # extend basis further if error was decreased (except in very first iteration)
+                    if order != self.options["order_start"]:
+                        if extended_basis and gpc[i_qoi].error[-1] < gpc[i_qoi].error[-2]:
+                            break
+
+                    extended_basis = False
+
+                    # exit adaptive sampling loop if no adaptive sampling was chosen
+                    if not self.options["adaptive_sampling"]:
+                        break
+
+                # save gpc object and coeffs for this sub-iteration
+                if self.options["fn_results"] is not None:
+
+                    with h5py.File(os.path.splitext(fn_results)[0] + ".hdf5", "a") as f:
+                        # overwrite coeffs
+                        try:
+                            del f["coeffs" + hdf5_subfolder]
+                        except KeyError:
+                            pass
+
+                        f.create_dataset("coeffs" + hdf5_subfolder,
+                                         data=coeffs[i_qoi], maxshape=None, dtype="float64")
+
+                        # save projection matrix
+                        try:
+                            del f["p_matrix" + hdf5_subfolder]
+                        except KeyError:
+                            f.create_dataset("p_matrix" + hdf5_subfolder,
+                                             data=p_matrix, maxshape=None, dtype="float64")
+
+                        # save gradient of results
+                        if grad_res_3D is not None:
+
+                            try:
+                                del f["model_evaluations/gradient_results"]
+                                del f["model_evaluations/gradient_results_idx"]
+                            except KeyError:
+                                pass
+
+                            grad_res_2D_all = ten2mat(grad_res_3D_all)
+                            f.create_dataset("model_evaluations/gradient_results",
+                                             (grad_res_2D_all.shape[0], grad_res_2D_all.shape[1]),
+                                             maxshape=(None, None),
+                                             dtype="float64",
+                                             data=grad_res_2D_all)
+
+                            f.create_dataset("model_evaluations/gradient_results_idx",
+                                             dtype="int64",
+                                             data=gradient_idx)
+
+                        try:
+                            del f["gpc_matrix" + hdf5_subfolder]
+                        except KeyError:
+                            pass
+                        f.create_dataset("gpc_matrix" + hdf5_subfolder,
+                                         data=gpc[i_qoi].gpc_matrix,
+                                         maxshape=None, dtype="float64")
+
+                        if gpc[i_qoi].gpc_matrix_gradient is not None:
+                            try:
+                                del f["gpc_matrix_gradient" + hdf5_subfolder]
+                            except KeyError:
+                                pass
+                            f.create_dataset("gpc_matrix_gradient" + hdf5_subfolder,
+                                             data=gpc[i_qoi].gpc_matrix_gradient,
+                                             maxshape=None, dtype="float64")
+
+                        try:
+                            del f["error" + hdf5_subfolder]
+                        except KeyError:
+                            pass
+                        f.create_dataset("error" + hdf5_subfolder,
+                                         data=eps,
+                                         maxshape=None, dtype="float64")
+
+            # determine gpc coefficients
+            coeffs[i_qoi] = gpc[i_qoi].solve(results=res,
+                                             gradient_results=grad_res_3D_passed,
+                                             solver=gpc[i_qoi].solver,
+                                             settings=gpc[i_qoi].settings,
+                                             verbose=self.options["verbose"])
+
+            # save original grid
+            gpc[i_qoi].grid_original = copy.deepcopy(grid_original)
+
+            # save gpc object gpc coeffs and projection matrix
+            if self.options["fn_results"] is not None:
+
+                with h5py.File(fn_results + ".hdf5", "a") as f:
+
+                    try:
+                        fn_session = f["misc/fn_session"][:]
+
+                    except KeyError:
+                        f.create_dataset("misc/fn_session",
+                                         data=np.array([os.path.split(self.options["fn_session"])[1]]).astype("|S"))
+                        f.create_dataset("misc/fn_session_folder",
+                                         data=np.array([self.options["fn_session_folder"]]).astype("|S"))
+
+                    try:
+                        del f["coeffs" + hdf5_subfolder]
+                    except KeyError:
+                        pass
+                    f.create_dataset("coeffs" + hdf5_subfolder, data=coeffs[i_qoi], maxshape=None, dtype="float64")
+
+                    try:
+                        del f["p_matrix" + hdf5_subfolder]
+                    except KeyError:
+                        pass
+                    f.create_dataset("p_matrix" + hdf5_subfolder, data=p_matrix, maxshape=None, dtype="float64")
+
+                    f.create_dataset("misc/error_type", data=self.options["error_type"])
+
+                    if self.options["gradient_enhanced"] or gpc[-1].grid.coords_gradient is not None:
+                        f.create_dataset("grid/coords_gradient", data=gpc[-1].grid.coords_gradient,
+                                         maxshape=None, dtype="float64")
+                        f.create_dataset("grid/coords_gradient_norm", data=gpc[-1].grid.coords_gradient_norm,
+                                         maxshape=None, dtype="float64")
+
+            # reset iterators
+            eps = self.options["eps"] + 1.0
+            order = self.options["order_start"]
+            error = []
+            nrmsd = []
+            loocv = []
+
+        if self.options["fn_results"] is not None:
+            with h5py.File(fn_results + ".hdf5", "a") as f:
+                if gpc[0].validation is not None:
+                    f.create_dataset("validation/model_evaluations/results", data=gpc[0].validation.results,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("validation/grid/coords", data=gpc[0].validation.grid.coords,
+                                     maxshape=None, dtype="float64")
+                    f.create_dataset("validation/grid/coords_norm", data=gpc[0].validation.grid.coords_norm,
+                                     maxshape=None, dtype="float64")
+                    try:
+                        f.create_dataset("misc/error_type", data=self.options["error_type"])
+                    except (RuntimeError, ValueError):
+                        del f["misc/error_type"]
+                        f.create_dataset("misc/error_type", data=self.options["error_type"])
+
+        com.close()
+
         return gpc, coeffs, res
```

## pygpc/Basis.py

```diff
@@ -1,480 +1,484 @@
-import os
-import uuid
-import time
-import numpy as np
-import multiprocessing
-import multiprocessing.pool
-import matplotlib.pyplot as plt
-from _functools import partial
-from .misc import get_multi_indices
-# from mpl_toolkits.mplot3d import Axes3D
-from .BasisFunction import *
-
-
-class Basis:
-    """
-    Basis class of gPC
-
-    Attributes
-    ----------
-    b : list of list of BasisFunction object instances [n_basis][n_dim]
-        Parameter wise basis function objects used in gPC.
-        Multiplying all elements in a row at location xi = (x1, x2, ..., x_dim) yields the global basis function.
-    b_array : ndarray of float [n_poly_coeffs]
-        Polynomial coefficients of basis functions
-    b_id : list of UUID objects (version 4) [n_basis]
-        Unique IDs of global basis functions
-    b_norm : ndarray of float [n_basis x dim]
-        Normalization factor of individual basis functions
-    b_norm_basis : ndarray of float [n_basis x 1]
-        Normalization factor of global basis functions
-    dim : int
-        Number of variables
-    n_basis : int
-        Total number of (global) basis function
-    multi_indices: ndarray [n_basis x dim]
-        Multi-indices of polynomial basis functions
-    """
-    def __init__(self):
-        """
-        Constructor; initializes the Basis class
-        """
-        self.b = None
-        self.b_array = None
-        self.b_array_grad = None
-        self.b_id = None
-        self.b_norm = None
-        self.b_norm_basis = None
-        self.dim = None
-        self.n_basis = 0
-        self.multi_indices = None
-
-    def set_basis(self, i_basis, problem):
-        """
-        Worker function to initialize a global basis function (called by multiprocessing.pool).
-        It also initializes polynomial basis coefficients for fast processing. Converts list of lists of basis
-        into np.ndarray that can be processed on multi core systems.
-
-        Parameters
-        ----------
-        i_basis : int
-            Index of global basis function
-        problem : Problem class instance
-            gPC problem
-
-        Returns
-        -------
-        b_ : list [n_dim]
-            List containing the individual basis functions of the parameters
-        b_a_ : ndarray of int
-            Concatenated list of polynomial basis coefficients
-        b_a_grad_ : ndarray of int
-            Concatenated list of polynomial basis coefficients for gradient evaluation
-        """
-
-        b_ = [0 for _ in range(problem.dim)]
-        b_a_ = []
-        b_a_grad_ = []
-
-        for i_dim, p in enumerate(problem.parameters_random):   # OrderedDict of RandomParameter objects
-            b_[i_dim] = problem.parameters_random[p].init_basis_function(order=self.multi_indices[i_basis, i_dim])
-
-        for i_dim in range(problem.dim):
-            for i_dim_inner in range(problem.dim):
-                if i_dim == 0:
-                    b_a_ = b_a_ + [np.array([b_[i_dim_inner].fun.order]),
-                                   b_[i_dim_inner].fun.c]
-                if i_dim == i_dim_inner:
-                    b_a_grad_ = b_a_grad_ + [np.array([b_[i_dim_inner].fun.deriv().order]),
-                                             b_[i_dim_inner].fun.deriv().c]
-                else:
-                    b_a_grad_ = b_a_grad_ + [np.array([b_[i_dim_inner].fun.order]),
-                                             b_[i_dim_inner].fun.c]
-
-        b_a_ = np.concatenate(b_a_)
-        b_a_grad_ = np.concatenate(b_a_grad_)
-
-        return b_, b_a_, b_a_grad_
-
-    def init_basis_sgpc(self, problem, order, order_max, order_max_norm, interaction_order,
-                        interaction_order_current=None):
-        """
-        Initializes basis functions for standard gPC.
-
-        Parameters
-        ----------
-        problem : Problem object
-            GPC Problem to analyze
-        order : list of int [dim]
-            Maximum individual expansion order
-            Generates individual polynomials also if maximum expansion order in order_max is exceeded
-        order_max : int
-            Maximum global expansion order.
-            The maximum expansion order considers the sum of the orders of combined polynomials together with the
-            chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
-            monomial orders.
-        order_max_norm : float
-            Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
-            of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
-            is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
-            where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
-        interaction_order : int
-            Number of random variables, which can interact with each other
-        interaction_order_current : int, optional, default: interaction_order
-            Number of random variables currently interacting with respect to the highest order.
-            (interaction_order_current <= interaction_order)
-            The parameters for lower orders are all interacting with "interaction order".
-
-        Notes
-        -----
-        .. [1] Blatman, G., & Sudret, B. (2011). Adaptive sparse polynomial chaos expansion based on least angle
-           regression. Journal of Computational Physics, 230(6), 2345-2367.
-
-        .. math::
-           \\begin{tabular}{l*{4}{c}}
-            Polynomial Index    & Dimension 1 & Dimension 2 & ... & Dimension M \\\\
-           \\hline
-            Basis 1             & [Order D1] & [Order D2] & \\vdots & [Order M] \\\\
-            Basis 2             & [Order D1] & [Order D2] & \\vdots & [Order M] \\\\
-           \\vdots              & [Order D1] & [Order D2] & \\vdots  & [Order M] \\\\
-            Basis N           & [Order D1] & [Order D2] & \\vdots & [Order M] \\\\
-           \\end{tabular}
-
-        Adds Attributes:
-
-        b: list of BasisFunction object instances [n_basis x n_dim]
-            Parameter wise basis function objects used in gPC.
-            Multiplying all elements in a row at location xi = (x1, x2, ..., x_dim) yields the global basis function.
-        """
-
-        self.dim = problem.dim
-        assert self.dim == len(order), "gPC order does not fit to number of random variables"
-
-        if self.dim == 1:
-            self.multi_indices = np.linspace(0, order_max, order_max + 1, dtype=int)[:, np.newaxis]
-        else:
-            self.multi_indices = get_multi_indices(order=order,
-                                                   order_max=order_max,
-                                                   order_max_norm=order_max_norm,
-                                                   interaction_order=interaction_order,
-                                                   interaction_order_current=interaction_order_current)
-
-        # get total number of basis functions
-        self.n_basis = self.multi_indices.shape[0]
-
-        # construct 2D list with BasisFunction objects and array with coefficients and
-        # initialize array of basis coefficients
-        workhorse_partial = partial(self.set_basis, problem=problem)
-
-        with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:
-            out = pool.map(workhorse_partial, range(self.n_basis))
-            self.b = [o[0] for o in out]
-            self.b_array = np.concatenate([o[1] for o in out])
-            self.b_array_grad = np.concatenate([o[2] for o in out])
-
-        # This is the single core implementation:
-        # self.b = [[0 for _ in range(self.dim)] for _ in range(self.n_basis)]
-        #
-        # for i_basis in range(self.n_basis):
-        #     for i_dim, p in enumerate(problem.parameters_random):   # OrderedDict of RandomParameter objects
-        #         self.b[i_basis][i_dim] = problem.parameters_random[p].init_basis_function(
-        #             order=self.multi_indices[i_basis, i_dim])
-
-        # Generate unique IDs of basis functions
-        self.b_id = [uuid.uuid4() for _ in range(self.n_basis)]
-
-        # initialize normalization factor (self.b_norm and self.b_norm_basis)
-        self.init_basis_norm()
-
-    def init_basis_norm(self):
-        """
-        Construct array of scaling factors self.b_norm [n_basis x dim] and self.b_norm_basis [n_basis x 1]
-        to normalize basis functions <psi^2> = int(psi^2*p)dx
-        """
-        # read individual normalization factors from function objects
-        self.b_norm = np.array([list(map(lambda x:x.fun_norm, _b)) for _b in self.b])
-
-        # determine global normalization factor of basis function
-        self.b_norm_basis = np.prod(self.b_norm, axis=1)
-
-    def set_basis_poly(self, order, order_max, order_max_norm, interaction_order, interaction_order_current, problem):
-        """
-        Sets up polynomial basis self.b for given order, order_max_norm and interaction order. Adds only the basis
-        functions, which are not yet included.
-
-        Parameters
-        ----------
-        order : list of int
-            Maximum individual expansion order
-            Generates individual polynomials also if maximum expansion order in order_max is exceeded
-        order_max : int
-            Maximum global expansion order.
-            The maximum expansion order considers the sum of the orders of combined polynomials together with the
-            chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
-            monomial orders.
-        order_max_norm : float
-            Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
-            of polynomials in the expansion such that interaction terms are penalized more.
-            sum(a_i^q)^1/q <= p, where p is order_max and q is order_max_norm (for more details see eq (11) in [1]).
-        interaction_order : int
-            Number of random variables, which can interact with each other
-            All polynomials are ignored, which have an interaction order greater than specified
-        interaction_order_current : int, optional, default: interaction_order
-            Number of random variables currently interacting with respect to the highest order.
-            (interaction_order_current <= interaction_order)
-            The parameters for lower orders are all interacting with interaction_order.
-        problem : Problem class instance
-            GPC Problem to analyze
-        """
-        b_added = None
-
-        dim = len(order)
-
-        # determine new possible set of basis functions for next main iteration
-        multi_indices_all_new = get_multi_indices(order=order,
-                                                  order_max=order_max,
-                                                  order_max_norm=order_max_norm,
-                                                  interaction_order=interaction_order,
-                                                  interaction_order_current=interaction_order_current)
-
-        # delete multi-indices, which are already present
-        if self.b is not None:
-            multi_indices_all_current = np.array([list(map(lambda x: x.p["i"], _b)) for _b in self.b])
-
-            idx_old = np.hstack([np.where((multi_indices_all_current[i, :] == multi_indices_all_new).all(axis=1))
-                                 for i in range(multi_indices_all_current.shape[0])])
-
-            multi_indices_all_new = np.delete(multi_indices_all_new, idx_old, axis=0)
-
-        if multi_indices_all_new.any():
-
-            # construct 2D list with new BasisFunction objects
-            b_added = [[0 for _ in range(dim)] for _ in range(multi_indices_all_new.shape[0])]
-
-            for i_basis in range(multi_indices_all_new.shape[0]):
-                for i_p, p in enumerate(problem.parameters_random):
-                    b_added[i_basis][i_p] = problem.parameters_random[p].init_basis_function(
-                        order=multi_indices_all_new[i_basis, i_p])
-
-            # extend basis
-            self.extend_basis(b_added)
-
-        return b_added
-
-    def add_basis_poly_by_order(self, multi_indices, problem):
-        """
-        Adds polynomial basis self.b for given order, order_max_norm and interaction order. Adds only the basis
-        functions, which are not yet included.
-
-        Parameters
-        ----------
-        multi_indices : ndarray of int [n_basis_new, dim]
-            Array containing the orders of the polynomials to be added to the basis
-        problem : Problem class instance
-            GPC Problem to analyze
-        """
-        # delete multi-indices, which are already present
-        if self.b is not None:
-            multi_indices_all_current = np.array([list(map(lambda x: x.p["i"], _b)) for _b in self.b])
-
-            idx_old = np.hstack([np.where((multi_indices_all_current[i, :] == multi_indices).all(axis=1))
-                                 for i in range(multi_indices_all_current.shape[0])])
-
-            multi_indices = np.delete(multi_indices, idx_old, axis=0)
-
-        if multi_indices.any():
-            # construct 2D list with new BasisFunction objects
-            b_added = [[0 for _ in range(problem.dim)] for _ in range(multi_indices.shape[0])]
-
-            for i_basis in range(multi_indices.shape[0]):
-                for i_p, p in enumerate(problem.parameters_random):
-                    b_added[i_basis][i_p] = problem.parameters_random[p].init_basis_function(
-                        order=multi_indices[i_basis, i_p])
-
-            # extend basis
-            self.extend_basis(b_added)
-
-        return b_added
-
-    def extend_basis(self, b_added):
-        """
-        Extend set of basis functions. Skips basis functions, which are already present in self.b.
-
-        Parameters
-        ----------
-        b_added: list of list of BasisFunction instances [n_b_added][dim]
-            Individual BasisFunctions to add
-        """
-        if self.b is None:
-            self.b = []
-
-        if self.b_id is None:
-            self.b_id = []
-
-        # add b_added to b (check for duplicates) and generate IDs
-        for i_row, _b in enumerate(b_added):
-            if _b not in self.b:
-                self.b.append(_b)
-                self.b_id.append(uuid.uuid4())
-                self.multi_indices = np.vstack((self.multi_indices,
-                                               np.array([_b[i_dim].p["i"] for i_dim in range(self.dim)])))
-
-        # update size
-        self.n_basis = len(self.b)
-
-        # update normalization factors
-        self.init_basis_norm()
-
-        # extend array of basis coefficients
-        self.extend_basis_array(b_added)
-
-    def init_basis_array(self):
-        """
-        Initialize polynomial basis coefficients for fast processing. Converts list of lists of self.b
-        into np.ndarray that can be processed on multi core systems.
-        """
-
-        _b_array = []
-        _b_array_grad = []
-        for i_basis in range(self.n_basis):
-            for i_dim_outer in range(self.dim):
-                for i_dim_inner in range(self.dim):
-                    if i_dim_outer == 0:
-                        _b_array = _b_array + [np.array([self.b[i_basis][i_dim_inner].fun.order]),
-                                               self.b[i_basis][i_dim_inner].fun.c]
-                    if i_dim_outer == i_dim_inner:
-                        _b_array_grad = _b_array_grad + [np.array([self.b[i_basis][i_dim_inner].fun.deriv().order]),
-                                                         self.b[i_basis][i_dim_inner].fun.deriv().c]
-                    else:
-                        _b_array_grad = _b_array_grad + [np.array([self.b[i_basis][i_dim_inner].fun.order]),
-                                                         self.b[i_basis][i_dim_inner].fun.c]
-
-        self.b_array = np.concatenate(_b_array)
-        self.b_array_grad = np.concatenate(_b_array_grad)
-
-    def extend_basis_array(self, b_added):
-        """
-        Extends polynomial basis coefficients for fast processing. Converts list of lists of b_added
-        into np.ndarray that can be processed on multi core systems.
-
-        Parameters
-        ----------
-        b_added: list of list of BasisFunction instances [n_b_added][dim]
-            Individual BasisFunctions to add
-        """
-
-        _b_array = []
-        _b_array_grad = []
-        for i_basis in range(len(b_added)):
-            for i_dim_outer in range(self.dim):
-                for i_dim_inner in range(self.dim):
-                    if i_dim_outer == 0:
-                        _b_array = _b_array + [np.array([b_added[i_basis][i_dim_inner].fun.order]),
-                                               b_added[i_basis][i_dim_inner].fun.c]
-                    if i_dim_outer == i_dim_inner:
-                        _b_array_grad = _b_array_grad + [np.array([b_added[i_basis][i_dim_inner].fun.deriv().order]),
-                                                         b_added[i_basis][i_dim_inner].fun.deriv().c]
-                    else:
-                        _b_array_grad = _b_array_grad + [np.array([b_added[i_basis][i_dim_inner].fun.order]),
-                                                         b_added[i_basis][i_dim_inner].fun.c]
-
-        if self.b_array is not None:
-            self.b_array = np.hstack((self.b_array, np.concatenate(_b_array)))
-        else:
-            self.b_array = np.concatenate(_b_array)
-
-        if self.b_array_grad is not None:
-            self.b_array_grad = np.hstack((self.b_array_grad, np.concatenate(_b_array_grad)))
-        else:
-            self.b_array_grad = np.concatenate(_b_array_grad)
-
-    def plot_basis(self, dims, fn_plot=None, dynamic_plot_update=False):
-        """
-        Generate 2D or 3D cube-plot of basis functions.
-
-        Parameters
-        ----------
-        dims : list of int of length [2] or [3]
-            Indices of parameters in gPC expansion to plot
-        fn_plot : str, optional, default: None
-            Filename of plot to save (with .png or .pdf extension)
-
-        Returns
-        -------
-        <File> : *.png and *.pdf file
-            Plot of basis functions
-        """
-
-        plt.rc('text', usetex=False)
-        plt.rc('font', family='serif', size=14)
-
-        multi_indices = np.array([list(map(lambda x: x.p["i"], _b)) for _b in self.b])
-
-        fig = plt.figure(figsize=[6, 6])
-
-        if len(dims) == 2:
-            ax = fig.add_subplot(111)
-        else:
-            ax = fig.add_subplot(111, projection='3d')
-
-        for i_poly in range(multi_indices.shape[0]):
-
-            if len(dims) == 2:
-                ax.scatter(multi_indices[i_poly, dims[0]],  # lower corner coordinates
-                           multi_indices[i_poly, dims[1]],
-                           c=np.array([[51, 153, 255]]) / 255.0,  # bar colour
-                           marker="s",
-                           s=450)  # transparency of the bars
-
-                ax.set_xlabel("$x_1$", fontsize=18)
-                ax.set_ylabel("$x_2$", fontsize=18)
-
-                ax.set_xlim([-1, np.max(multi_indices) + 1])
-                ax.set_ylim([-1, np.max(multi_indices) + 1])
-
-                ax.set_xticklabels(range(np.max(multi_indices) + 1))
-                ax.set_xticks(range(np.max(multi_indices) + 1))
-                ax.set_yticklabels(range(np.max(multi_indices) + 1))
-                ax.set_yticks(range(np.max(multi_indices) + 1))
-
-                ax.set_aspect('equal', 'box')
-
-            else:
-                ax.bar3d(multi_indices[i_poly, dims[0]] - 0.4,  # lower corner coordinates
-                         multi_indices[i_poly, dims[1]] - 0.4,
-                         multi_indices[i_poly, dims[2]] - 0.4,
-                         0.8, 0.8, 0.8,  # width, depth and height
-                         color=np.array([51, 153, 255]) / 255.0,  # bar colour
-                         alpha=1)  # transparency of the bars
-                ax.view_init(elev=30, azim=45)
-
-                ax.set_xlabel("$x_1$", fontsize=18)
-                ax.set_ylabel("$x_2$", fontsize=18)
-                ax.set_zlabel("$x_3$", fontsize=18)
-
-                ax.set_xlim([0, np.max(multi_indices) + 1])
-                ax.set_ylim([0, np.max(multi_indices) + 1])
-                ax.set_zlim([0, np.max(multi_indices) + 1])
-
-                ax.set_xticklabels(range(np.max(multi_indices) + 1))
-                ax.set_xticks(range(np.max(multi_indices) + 1))
-                ax.set_yticklabels(range(np.max(multi_indices) + 1))
-                ax.set_yticks(range(np.max(multi_indices) + 1))
-                ax.set_zticklabels(range(np.max(multi_indices) + 1))
-                ax.set_zticks(range(np.max(multi_indices) + 1))
-
-                # ax.set_xlim([0, 5])
-                # ax.set_ylim([0, 5])
-                # ax.set_zlim([0, 5])
-                #
-                # ax.set_xticklabels(range(5))
-                # ax.set_xticks(range(5))
-                # ax.set_yticklabels(range(5))
-                # ax.set_yticks(range(5))
-                # ax.set_zticklabels(range(5))
-                # ax.set_zticks(range(5))
-
-        if fn_plot is not None:
-            if os.path.splitext(fn_plot) not in [".pdf", ".png"]:
-                fn_plot = fn_plot + ".png"
-            plt.savefig(fn_plot, dpi=600)
+import os
+import uuid
+import time
+import numpy as np
+import multiprocessing
+import multiprocessing.pool
+from _functools import partial
+from .misc import get_multi_indices
+# from mpl_toolkits.mplot3d import Axes3D
+from .BasisFunction import *
+
+try:
+    import matplotlib.pyplot as plt
+except ImportError:
+    pass
+
+
+class Basis:
+    """
+    Basis class of gPC
+
+    Attributes
+    ----------
+    b : list of list of BasisFunction object instances [n_basis][n_dim]
+        Parameter wise basis function objects used in gPC.
+        Multiplying all elements in a row at location xi = (x1, x2, ..., x_dim) yields the global basis function.
+    b_array : ndarray of float [n_poly_coeffs]
+        Polynomial coefficients of basis functions
+    b_id : list of UUID objects (version 4) [n_basis]
+        Unique IDs of global basis functions
+    b_norm : ndarray of float [n_basis x dim]
+        Normalization factor of individual basis functions
+    b_norm_basis : ndarray of float [n_basis x 1]
+        Normalization factor of global basis functions
+    dim : int
+        Number of variables
+    n_basis : int
+        Total number of (global) basis function
+    multi_indices: ndarray [n_basis x dim]
+        Multi-indices of polynomial basis functions
+    """
+    def __init__(self):
+        """
+        Constructor; initializes the Basis class
+        """
+        self.b = None
+        self.b_array = None
+        self.b_array_grad = None
+        self.b_id = None
+        self.b_norm = None
+        self.b_norm_basis = None
+        self.dim = None
+        self.n_basis = 0
+        self.multi_indices = None
+
+    def set_basis(self, i_basis, problem):
+        """
+        Worker function to initialize a global basis function (called by multiprocessing.pool).
+        It also initializes polynomial basis coefficients for fast processing. Converts list of lists of basis
+        into np.ndarray that can be processed on multi core systems.
+
+        Parameters
+        ----------
+        i_basis : int
+            Index of global basis function
+        problem : Problem class instance
+            gPC problem
+
+        Returns
+        -------
+        b_ : list [n_dim]
+            List containing the individual basis functions of the parameters
+        b_a_ : ndarray of int
+            Concatenated list of polynomial basis coefficients
+        b_a_grad_ : ndarray of int
+            Concatenated list of polynomial basis coefficients for gradient evaluation
+        """
+
+        b_ = [0 for _ in range(problem.dim)]
+        b_a_ = []
+        b_a_grad_ = []
+
+        for i_dim, p in enumerate(problem.parameters_random):   # OrderedDict of RandomParameter objects
+            b_[i_dim] = problem.parameters_random[p].init_basis_function(order=self.multi_indices[i_basis, i_dim])
+
+        for i_dim in range(problem.dim):
+            for i_dim_inner in range(problem.dim):
+                if i_dim == 0:
+                    b_a_ = b_a_ + [np.array([b_[i_dim_inner].fun.order]),
+                                   b_[i_dim_inner].fun.c]
+                if i_dim == i_dim_inner:
+                    b_a_grad_ = b_a_grad_ + [np.array([b_[i_dim_inner].fun.deriv().order]),
+                                             b_[i_dim_inner].fun.deriv().c]
+                else:
+                    b_a_grad_ = b_a_grad_ + [np.array([b_[i_dim_inner].fun.order]),
+                                             b_[i_dim_inner].fun.c]
+
+        b_a_ = np.concatenate(b_a_)
+        b_a_grad_ = np.concatenate(b_a_grad_)
+
+        return b_, b_a_, b_a_grad_
+
+    def init_basis_sgpc(self, problem, order, order_max, order_max_norm, interaction_order,
+                        interaction_order_current=None):
+        """
+        Initializes basis functions for standard gPC.
+
+        Parameters
+        ----------
+        problem : Problem object
+            GPC Problem to analyze
+        order : list of int [dim]
+            Maximum individual expansion order
+            Generates individual polynomials also if maximum expansion order in order_max is exceeded
+        order_max : int
+            Maximum global expansion order.
+            The maximum expansion order considers the sum of the orders of combined polynomials together with the
+            chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
+            monomial orders.
+        order_max_norm : float
+            Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
+            of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
+            is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
+            where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
+        interaction_order : int
+            Number of random variables, which can interact with each other
+        interaction_order_current : int, optional, default: interaction_order
+            Number of random variables currently interacting with respect to the highest order.
+            (interaction_order_current <= interaction_order)
+            The parameters for lower orders are all interacting with "interaction order".
+
+        Notes
+        -----
+        .. [1] Blatman, G., & Sudret, B. (2011). Adaptive sparse polynomial chaos expansion based on least angle
+           regression. Journal of Computational Physics, 230(6), 2345-2367.
+
+        .. math::
+           \\begin{tabular}{l*{4}{c}}
+            Polynomial Index    & Dimension 1 & Dimension 2 & ... & Dimension M \\\\
+           \\hline
+            Basis 1             & [Order D1] & [Order D2] & \\vdots & [Order M] \\\\
+            Basis 2             & [Order D1] & [Order D2] & \\vdots & [Order M] \\\\
+           \\vdots              & [Order D1] & [Order D2] & \\vdots  & [Order M] \\\\
+            Basis N           & [Order D1] & [Order D2] & \\vdots & [Order M] \\\\
+           \\end{tabular}
+
+        Adds Attributes:
+
+        b: list of BasisFunction object instances [n_basis x n_dim]
+            Parameter wise basis function objects used in gPC.
+            Multiplying all elements in a row at location xi = (x1, x2, ..., x_dim) yields the global basis function.
+        """
+
+        self.dim = problem.dim
+        assert self.dim == len(order), "gPC order does not fit to number of random variables"
+
+        if self.dim == 1:
+            self.multi_indices = np.linspace(0, order_max, order_max + 1, dtype=int)[:, np.newaxis]
+        else:
+            self.multi_indices = get_multi_indices(order=order,
+                                                   order_max=order_max,
+                                                   order_max_norm=order_max_norm,
+                                                   interaction_order=interaction_order,
+                                                   interaction_order_current=interaction_order_current)
+
+        # get total number of basis functions
+        self.n_basis = self.multi_indices.shape[0]
+
+        # construct 2D list with BasisFunction objects and array with coefficients and
+        # initialize array of basis coefficients
+        workhorse_partial = partial(self.set_basis, problem=problem)
+
+        with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:
+            out = pool.map(workhorse_partial, range(self.n_basis))
+            self.b = [o[0] for o in out]
+            self.b_array = np.concatenate([o[1] for o in out])
+            self.b_array_grad = np.concatenate([o[2] for o in out])
+
+        # This is the single core implementation:
+        # self.b = [[0 for _ in range(self.dim)] for _ in range(self.n_basis)]
+        #
+        # for i_basis in range(self.n_basis):
+        #     for i_dim, p in enumerate(problem.parameters_random):   # OrderedDict of RandomParameter objects
+        #         self.b[i_basis][i_dim] = problem.parameters_random[p].init_basis_function(
+        #             order=self.multi_indices[i_basis, i_dim])
+
+        # Generate unique IDs of basis functions
+        self.b_id = [uuid.uuid4() for _ in range(self.n_basis)]
+
+        # initialize normalization factor (self.b_norm and self.b_norm_basis)
+        self.init_basis_norm()
+
+    def init_basis_norm(self):
+        """
+        Construct array of scaling factors self.b_norm [n_basis x dim] and self.b_norm_basis [n_basis x 1]
+        to normalize basis functions <psi^2> = int(psi^2*p)dx
+        """
+        # read individual normalization factors from function objects
+        self.b_norm = np.array([list(map(lambda x:x.fun_norm, _b)) for _b in self.b])
+
+        # determine global normalization factor of basis function
+        self.b_norm_basis = np.prod(self.b_norm, axis=1)
+
+    def set_basis_poly(self, order, order_max, order_max_norm, interaction_order, interaction_order_current, problem):
+        """
+        Sets up polynomial basis self.b for given order, order_max_norm and interaction order. Adds only the basis
+        functions, which are not yet included.
+
+        Parameters
+        ----------
+        order : list of int
+            Maximum individual expansion order
+            Generates individual polynomials also if maximum expansion order in order_max is exceeded
+        order_max : int
+            Maximum global expansion order.
+            The maximum expansion order considers the sum of the orders of combined polynomials together with the
+            chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
+            monomial orders.
+        order_max_norm : float
+            Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
+            of polynomials in the expansion such that interaction terms are penalized more.
+            sum(a_i^q)^1/q <= p, where p is order_max and q is order_max_norm (for more details see eq (11) in [1]).
+        interaction_order : int
+            Number of random variables, which can interact with each other
+            All polynomials are ignored, which have an interaction order greater than specified
+        interaction_order_current : int, optional, default: interaction_order
+            Number of random variables currently interacting with respect to the highest order.
+            (interaction_order_current <= interaction_order)
+            The parameters for lower orders are all interacting with interaction_order.
+        problem : Problem class instance
+            GPC Problem to analyze
+        """
+        b_added = None
+
+        dim = len(order)
+
+        # determine new possible set of basis functions for next main iteration
+        multi_indices_all_new = get_multi_indices(order=order,
+                                                  order_max=order_max,
+                                                  order_max_norm=order_max_norm,
+                                                  interaction_order=interaction_order,
+                                                  interaction_order_current=interaction_order_current)
+
+        # delete multi-indices, which are already present
+        if self.b is not None:
+            multi_indices_all_current = np.array([list(map(lambda x: x.p["i"], _b)) for _b in self.b])
+
+            idx_old = np.hstack([np.where((multi_indices_all_current[i, :] == multi_indices_all_new).all(axis=1))
+                                 for i in range(multi_indices_all_current.shape[0])])
+
+            multi_indices_all_new = np.delete(multi_indices_all_new, idx_old, axis=0)
+
+        if multi_indices_all_new.any():
+
+            # construct 2D list with new BasisFunction objects
+            b_added = [[0 for _ in range(dim)] for _ in range(multi_indices_all_new.shape[0])]
+
+            for i_basis in range(multi_indices_all_new.shape[0]):
+                for i_p, p in enumerate(problem.parameters_random):
+                    b_added[i_basis][i_p] = problem.parameters_random[p].init_basis_function(
+                        order=multi_indices_all_new[i_basis, i_p])
+
+            # extend basis
+            self.extend_basis(b_added)
+
+        return b_added
+
+    def add_basis_poly_by_order(self, multi_indices, problem):
+        """
+        Adds polynomial basis self.b for given order, order_max_norm and interaction order. Adds only the basis
+        functions, which are not yet included.
+
+        Parameters
+        ----------
+        multi_indices : ndarray of int [n_basis_new, dim]
+            Array containing the orders of the polynomials to be added to the basis
+        problem : Problem class instance
+            GPC Problem to analyze
+        """
+        # delete multi-indices, which are already present
+        if self.b is not None:
+            multi_indices_all_current = np.array([list(map(lambda x: x.p["i"], _b)) for _b in self.b])
+
+            idx_old = np.hstack([np.where((multi_indices_all_current[i, :] == multi_indices).all(axis=1))
+                                 for i in range(multi_indices_all_current.shape[0])])
+
+            multi_indices = np.delete(multi_indices, idx_old, axis=0)
+
+        if multi_indices.any():
+            # construct 2D list with new BasisFunction objects
+            b_added = [[0 for _ in range(problem.dim)] for _ in range(multi_indices.shape[0])]
+
+            for i_basis in range(multi_indices.shape[0]):
+                for i_p, p in enumerate(problem.parameters_random):
+                    b_added[i_basis][i_p] = problem.parameters_random[p].init_basis_function(
+                        order=multi_indices[i_basis, i_p])
+
+            # extend basis
+            self.extend_basis(b_added)
+
+        return b_added
+
+    def extend_basis(self, b_added):
+        """
+        Extend set of basis functions. Skips basis functions, which are already present in self.b.
+
+        Parameters
+        ----------
+        b_added: list of list of BasisFunction instances [n_b_added][dim]
+            Individual BasisFunctions to add
+        """
+        if self.b is None:
+            self.b = []
+
+        if self.b_id is None:
+            self.b_id = []
+
+        # add b_added to b (check for duplicates) and generate IDs
+        for i_row, _b in enumerate(b_added):
+            if _b not in self.b:
+                self.b.append(_b)
+                self.b_id.append(uuid.uuid4())
+                self.multi_indices = np.vstack((self.multi_indices,
+                                               np.array([_b[i_dim].p["i"] for i_dim in range(self.dim)])))
+
+        # update size
+        self.n_basis = len(self.b)
+
+        # update normalization factors
+        self.init_basis_norm()
+
+        # extend array of basis coefficients
+        self.extend_basis_array(b_added)
+
+    def init_basis_array(self):
+        """
+        Initialize polynomial basis coefficients for fast processing. Converts list of lists of self.b
+        into np.ndarray that can be processed on multi core systems.
+        """
+
+        _b_array = []
+        _b_array_grad = []
+        for i_basis in range(self.n_basis):
+            for i_dim_outer in range(self.dim):
+                for i_dim_inner in range(self.dim):
+                    if i_dim_outer == 0:
+                        _b_array = _b_array + [np.array([self.b[i_basis][i_dim_inner].fun.order]),
+                                               self.b[i_basis][i_dim_inner].fun.c]
+                    if i_dim_outer == i_dim_inner:
+                        _b_array_grad = _b_array_grad + [np.array([self.b[i_basis][i_dim_inner].fun.deriv().order]),
+                                                         self.b[i_basis][i_dim_inner].fun.deriv().c]
+                    else:
+                        _b_array_grad = _b_array_grad + [np.array([self.b[i_basis][i_dim_inner].fun.order]),
+                                                         self.b[i_basis][i_dim_inner].fun.c]
+
+        self.b_array = np.concatenate(_b_array)
+        self.b_array_grad = np.concatenate(_b_array_grad)
+
+    def extend_basis_array(self, b_added):
+        """
+        Extends polynomial basis coefficients for fast processing. Converts list of lists of b_added
+        into np.ndarray that can be processed on multi core systems.
+
+        Parameters
+        ----------
+        b_added: list of list of BasisFunction instances [n_b_added][dim]
+            Individual BasisFunctions to add
+        """
+
+        _b_array = []
+        _b_array_grad = []
+        for i_basis in range(len(b_added)):
+            for i_dim_outer in range(self.dim):
+                for i_dim_inner in range(self.dim):
+                    if i_dim_outer == 0:
+                        _b_array = _b_array + [np.array([b_added[i_basis][i_dim_inner].fun.order]),
+                                               b_added[i_basis][i_dim_inner].fun.c]
+                    if i_dim_outer == i_dim_inner:
+                        _b_array_grad = _b_array_grad + [np.array([b_added[i_basis][i_dim_inner].fun.deriv().order]),
+                                                         b_added[i_basis][i_dim_inner].fun.deriv().c]
+                    else:
+                        _b_array_grad = _b_array_grad + [np.array([b_added[i_basis][i_dim_inner].fun.order]),
+                                                         b_added[i_basis][i_dim_inner].fun.c]
+
+        if self.b_array is not None:
+            self.b_array = np.hstack((self.b_array, np.concatenate(_b_array)))
+        else:
+            self.b_array = np.concatenate(_b_array)
+
+        if self.b_array_grad is not None:
+            self.b_array_grad = np.hstack((self.b_array_grad, np.concatenate(_b_array_grad)))
+        else:
+            self.b_array_grad = np.concatenate(_b_array_grad)
+
+    def plot_basis(self, dims, fn_plot=None, dynamic_plot_update=False):
+        """
+        Generate 2D or 3D cube-plot of basis functions.
+
+        Parameters
+        ----------
+        dims : list of int of length [2] or [3]
+            Indices of parameters in gPC expansion to plot
+        fn_plot : str, optional, default: None
+            Filename of plot to save (with .png or .pdf extension)
+
+        Returns
+        -------
+        <File> : *.png and *.pdf file
+            Plot of basis functions
+        """
+
+        plt.rc('text', usetex=False)
+        plt.rc('font', family='serif', size=14)
+
+        multi_indices = np.array([list(map(lambda x: x.p["i"], _b)) for _b in self.b])
+
+        fig = plt.figure(figsize=[6, 6])
+
+        if len(dims) == 2:
+            ax = fig.add_subplot(111)
+        else:
+            ax = fig.add_subplot(111, projection='3d')
+
+        for i_poly in range(multi_indices.shape[0]):
+
+            if len(dims) == 2:
+                ax.scatter(multi_indices[i_poly, dims[0]],  # lower corner coordinates
+                           multi_indices[i_poly, dims[1]],
+                           c=np.array([[51, 153, 255]]) / 255.0,  # bar colour
+                           marker="s",
+                           s=450)  # transparency of the bars
+
+                ax.set_xlabel("$x_1$", fontsize=18)
+                ax.set_ylabel("$x_2$", fontsize=18)
+
+                ax.set_xlim([-1, np.max(multi_indices) + 1])
+                ax.set_ylim([-1, np.max(multi_indices) + 1])
+
+                ax.set_xticklabels(range(np.max(multi_indices) + 1))
+                ax.set_xticks(range(np.max(multi_indices) + 1))
+                ax.set_yticklabels(range(np.max(multi_indices) + 1))
+                ax.set_yticks(range(np.max(multi_indices) + 1))
+
+                ax.set_aspect('equal', 'box')
+
+            else:
+                ax.bar3d(multi_indices[i_poly, dims[0]] - 0.4,  # lower corner coordinates
+                         multi_indices[i_poly, dims[1]] - 0.4,
+                         multi_indices[i_poly, dims[2]] - 0.4,
+                         0.8, 0.8, 0.8,  # width, depth and height
+                         color=np.array([51, 153, 255]) / 255.0,  # bar colour
+                         alpha=1)  # transparency of the bars
+                ax.view_init(elev=30, azim=45)
+
+                ax.set_xlabel("$x_1$", fontsize=18)
+                ax.set_ylabel("$x_2$", fontsize=18)
+                ax.set_zlabel("$x_3$", fontsize=18)
+
+                ax.set_xlim([0, np.max(multi_indices) + 1])
+                ax.set_ylim([0, np.max(multi_indices) + 1])
+                ax.set_zlim([0, np.max(multi_indices) + 1])
+
+                ax.set_xticklabels(range(np.max(multi_indices) + 1))
+                ax.set_xticks(range(np.max(multi_indices) + 1))
+                ax.set_yticklabels(range(np.max(multi_indices) + 1))
+                ax.set_yticks(range(np.max(multi_indices) + 1))
+                ax.set_zticklabels(range(np.max(multi_indices) + 1))
+                ax.set_zticks(range(np.max(multi_indices) + 1))
+
+                # ax.set_xlim([0, 5])
+                # ax.set_ylim([0, 5])
+                # ax.set_zlim([0, 5])
+                #
+                # ax.set_xticklabels(range(5))
+                # ax.set_xticks(range(5))
+                # ax.set_yticklabels(range(5))
+                # ax.set_yticks(range(5))
+                # ax.set_zticklabels(range(5))
+                # ax.set_zticks(range(5))
+
+        if fn_plot is not None:
+            if os.path.splitext(fn_plot) not in [".pdf", ".png"]:
+                fn_plot = fn_plot + ".png"
+            plt.savefig(fn_plot, dpi=600)
```

## pygpc/BasisFunction.py

 * *Ordering differences only*

```diff
@@ -1,321 +1,321 @@
-import scipy.special
-import scipy.stats
-import numpy as np
-from .Quadrature import get_quadrature_jacobi_1d
-from .Quadrature import get_quadrature_hermite_1d
-from .Quadrature import get_quadrature_laguerre_1d
-from .Grid import *
-
-
-class BasisFunction(object):
-    """
-    Abstract class of basis functions.
-    This base class provides basic properties and methods for the basis functions.
-    It cannot be used directly, but inherits properties and methods to the specific basis function sub classes.
-
-    Parameters
-    ----------
-    p : dict
-        Parameters of the polynomial (see subclasses for details)
-    """
-
-    def __init__(self, p):
-        """
-        Constructor; initialized a Basis function class
-        """
-        self.p = p
-        self.fun = None
-        self.fun_der = None
-        self.fun_norm = None
-
-    def __call__(self, x, derivative=False):
-        """
-        Evaluates basis function for argument x
-
-        Parameters
-        ----------
-        x : float or ndarray of float
-            Argument for which the basis function is evaluated
-        derivative : boolean, optional, default: False
-            Returns derivative of basis function at argument x
-
-        Returns
-        -------
-        y : float or ndarray of float
-            Function value or derivative of basis function at argument x
-        """
-
-        if derivative:
-            return self.fun_der(x)
-        else:
-            return self.fun(x)
-
-
-class Jacobi(BasisFunction):
-    """
-    Jacobi basis function used in the orthogonal gPC to model beta distributed random variables.
-
-    Parameters
-    ----------
-    p : dict
-        Parameters of the Jacobi polynomial
-        - p["i"] ... order
-        - p["p"] ... first shape parameter
-        - p["q"] ... second shape parameter
-    """
-
-    def __init__(self, p):
-        """
-        Constructor; initialized a Jacobi basis function
-        """
-
-        super(Jacobi, self).__init__(p)
-
-        # determine polynomial normalization factor
-        beta_norm = (scipy.special.gamma(self.p["q"]) * scipy.special.gamma(self.p["p"]) /
-                     scipy.special.gamma(self.p["p"] + self.p["q"]) * 2.0 ** (self.p["p"] + self.p["q"] - 1)) ** (-1)
-
-        jacobi_norm = 2 ** (self.p["p"] + self.p["q"] - 1) / (
-                      (2.0 * self.p["i"] + self.p["p"] + self.p["q"] - 1)) * (
-                      scipy.special.gamma(self.p["i"] + self.p["p"])) * (
-                      scipy.special.gamma(self.p["i"] + self.p["q"])) / (
-                              scipy.special.gamma(self.p["i"] + self.p["p"] + self.p["q"] - 1) *
-                              scipy.special.factorial(self.p["i"]))
-
-        # normalization factor of polynomial (to later normalize basis functions <psi^2> = int(psi^2*p)dx)
-        self.fun_norm = jacobi_norm * beta_norm
-
-        # define basis function
-        self.fun = scipy.special.jacobi(self.p["i"],
-                                        self.p["q"] - 1,  # beta-pdf: alpha=p /// jacobi-poly: alpha=q-1  !!!
-                                        self.p["p"] - 1,  # beta-pdf: beta=q  /// jacobi-poly: beta=p-1   !!!
-                                        monic=False) / np.sqrt(self.fun_norm)
-
-        # derivative of polynomial
-        self.fun_der = np.polyder(self.fun)
-
-        # integral of fun and fun_der w.r.t. pdf (numerical integration with corresponding weights)
-        knots, weights = get_quadrature_jacobi_1d(n=10 * self.p["i"], p=self.p["p"] - 1, q=self.p["q"] - 1)
-        self.fun_int = np.dot(self.fun(knots), weights)
-        self.fun_der_int = np.dot(self.fun_der(knots), weights)
-
-
-class Hermite(BasisFunction):
-    """
-    Hermite basis function used in the orthogonal gPC to model normal distributed random variables.
-
-    Parameters
-    ----------
-    p : dict
-        Parameters of the Hermite polynomial
-        - p["i"] ... order
-    """
-
-    def __init__(self, p):
-        """
-        Constructor; initializes a Hermite basis function
-        """
-
-        super(Hermite, self).__init__(p)
-
-        # normalization factor of polynomial (to later normalize basis functions <psi^2> = int(psi^2*p)dx)
-        self.fun_norm = np.float64(scipy.special.factorial(p["i"]))
-
-        # define basis function
-        self.fun = scipy.special.hermitenorm(p["i"], monic=False) / np.sqrt(self.fun_norm)
-
-        # derivative of polynomial
-        self.fun_der = np.polyder(self.fun)
-
-        # integral of fun and fun_der w.r.t. pdf (numerical integration with corresponding weights)
-        if self.p["i"] == 0:
-            self.fun_int = 1.0
-            self.fun_der_int = 0.0
-        else:
-            knots, weights = get_quadrature_hermite_1d(n=10 * self.p["i"])
-            self.fun_int = np.dot(self.fun(knots), weights)
-            self.fun_der_int = np.dot(self.fun_der(knots), weights)
-
-
-class Laguerre(BasisFunction):
-    """
-    Laguerre basis function used in the orthogonal gPC to model gamma distributed random variables.
-    It is defined in the gpc space from [0, inf]
-
-    Parameters
-    ----------
-    p : dict
-        Parameters of the Laguerre polynomial
-        - p["i"] ... order
-        - p["alpha"] ... shape parameter (alpha_poly = alpha_pdf - 1)
-        - p["beta"] ... rate parameter
-    """
-
-    def __init__(self, p):
-        """
-        Constructor; initializes a Laguerre basis function
-        """
-
-        super(Laguerre, self).__init__(p)
-
-        self.fun_norm = (scipy.special.factorial(p["i"]+p["alpha"]) / scipy.special.factorial(p["i"])) / \
-                        scipy.special.gamma(p["alpha"] + 1)
-
-        # define basis function
-        self.fun = scipy.special.genlaguerre(p["i"], alpha=p["alpha"], monic=False) / np.sqrt(self.fun_norm)
-
-        # derivative of polynomial
-        self.fun_der = np.polyder(self.fun)
-
-        # integral of fun and fun_der w.r.t. pdf (numerical integration with corresponding weights)
-        if self.p["i"] == 0:
-            self.fun_int = 1.0
-            self.fun_der_int = 0.0
-        else:
-            knots, weights = get_quadrature_laguerre_1d(n=10 * self.p["i"], alpha=p["alpha"])
-            self.fun_int = np.dot(self.fun(knots), weights)
-            self.fun_der_int = np.dot(self.fun_der(knots), weights)
-
-
-class StepUp(BasisFunction):
-    """
-    StepUp (from 0 to 1) basis function used in the non-orthogonal gPC.
-
-    Parameters
-    ----------
-    p : dict
-        Parameters of the StepUp function
-        - p["xs"] ... location of step
-    """
-
-    def __init__(self, p):
-        """
-        Constructor; initializes a StepUp basis function
-        """
-
-        super(StepUp, self).__init__(p)
-
-        # normalization factor of function (to later normalize basis functions <psi^2> = int(psi^2*p)dx)
-        self.fun_norm = 1.0
-
-        # define basis function
-        self.fun = lambda x: 0.0 if x < p["xs"] else (0.5 if x == p["xs"] else 1.0)
-
-        # derivative
-        self.fun_der = lambda x: 0.0
-
-
-class StepDown(BasisFunction):
-    """
-    StepDown (from 1 to 0) basis function used in the non-orthogonal gPC.
-
-    Parameters
-    ----------
-    p : dict
-        Parameters of the StepDown function
-        - p["xs"] ... location of step
-    """
-
-    def __init__(self, p):
-        """
-        Constructor; initializes a StepDown basis function
-        """
-
-        super(StepDown, self).__init__(p)
-
-        # normalization factor of function (to later normalize basis functions <psi^2> = int(psi^2*p)dx)
-        self.fun_norm = 1.0
-
-        # define basis function
-        self.fun = lambda x: 1.0 if x < p["xs"] else (0.5 if x == p["xs"] else 0.0)
-
-        # derivative
-        self.fun_der = lambda x: 0.0
-
-
-class Rect(BasisFunction):
-    """
-    Rectangular basis function used in the non-orthogonal gPC.
-
-    Parameters
-    ----------
-    p : dict
-        Parameters of the Rect function
-        - p["x1"] ... location of positive flank (0 -> 1)
-        - p["x2"] ... location of negative flank (1 -> 0)
-    """
-
-    def __init__(self, p):
-        """
-        Constructor; initializes a Rect basis function
-        """
-
-        super(Rect, self).__init__(p)
-
-        # normalization factor of function (to later normalize basis functions <psi^2> = int(psi^2*p)dx)
-        self.fun_norm = 1.0
-
-        # define basis function
-        self.fun = lambda x: 1.0 if p["x1"] < x < p["x2"] else (0.5 if x == p["x1"] or x == p["x2"] else 0.0)
-
-        # derivative
-        self.fun_der = lambda x: 0.0
-
-
-class SigmoidUp(BasisFunction):
-    """
-    SigmoidUp (from 0 to 1) basis function used in the non-orthogonal gPC.
-
-    Parameters
-    ----------
-    p : dict
-        Parameters of the SigmoidUp function
-        - p["xs"] ... location of turning point
-        - p["r"] ... steepness
-    """
-
-    def __init__(self, p):
-        """
-        Constructor; initializes a SigmoidUp basis function
-        """
-
-        super(SigmoidUp, self).__init__(p)
-
-        # normalization factor of function (to later normalize basis functions <psi^2> = int(psi^2*p)dx)
-        self.fun_norm = 1.0
-
-        # define basis function
-        self.fun = lambda x: 1.0 / (1 + np.exp(-p["r"] * (x - p["xs"])))
-
-        # derivative
-        self.fun_der = lambda x: (p["r"] * np.exp(-p["r"] * (x - p["xs"]))) / (1 + np.exp(-p["r"] * (x - p["xs"])))**2
-
-
-class SigmoidDown(BasisFunction):
-    """
-    SigmoidDown (from 0 to 1) basis function used in the non-orthogonal gPC.
-
-    Parameters
-    ----------
-    p : dict
-        Parameters of the SigmoidDown function
-        - p["xs"] ... location of turning point
-        - p["r"] ... steepness
-    """
-
-    def __init__(self, p):
-        """
-        Constructor; initializes a SigmoidDown basis function
-        """
-
-        super(SigmoidDown, self).__init__(p)
-
-        # normalization factor of function (to later normalize basis functions <psi^2> = int(psi^2*p)dx)
-        self.fun_norm = 1.0
-
-        # define basis function
-        self.fun = lambda x: 1.0 / (1 + np.exp(-p["r"] * (- x + p["xs"])))
-
-        # derivative
-        self.fun_der = lambda x: (- p["r"] * np.exp(-p["r"] * (- x + p["xs"]))) / (1 + np.exp(-p["r"] *
-                                 (- x + p["xs"])))**2
+import scipy.special
+import scipy.stats
+import numpy as np
+from .Quadrature import get_quadrature_jacobi_1d
+from .Quadrature import get_quadrature_hermite_1d
+from .Quadrature import get_quadrature_laguerre_1d
+from .Grid import *
+
+
+class BasisFunction(object):
+    """
+    Abstract class of basis functions.
+    This base class provides basic properties and methods for the basis functions.
+    It cannot be used directly, but inherits properties and methods to the specific basis function sub classes.
+
+    Parameters
+    ----------
+    p : dict
+        Parameters of the polynomial (see subclasses for details)
+    """
+
+    def __init__(self, p):
+        """
+        Constructor; initialized a Basis function class
+        """
+        self.p = p
+        self.fun = None
+        self.fun_der = None
+        self.fun_norm = None
+
+    def __call__(self, x, derivative=False):
+        """
+        Evaluates basis function for argument x
+
+        Parameters
+        ----------
+        x : float or ndarray of float
+            Argument for which the basis function is evaluated
+        derivative : boolean, optional, default: False
+            Returns derivative of basis function at argument x
+
+        Returns
+        -------
+        y : float or ndarray of float
+            Function value or derivative of basis function at argument x
+        """
+
+        if derivative:
+            return self.fun_der(x)
+        else:
+            return self.fun(x)
+
+
+class Jacobi(BasisFunction):
+    """
+    Jacobi basis function used in the orthogonal gPC to model beta distributed random variables.
+
+    Parameters
+    ----------
+    p : dict
+        Parameters of the Jacobi polynomial
+        - p["i"] ... order
+        - p["p"] ... first shape parameter
+        - p["q"] ... second shape parameter
+    """
+
+    def __init__(self, p):
+        """
+        Constructor; initialized a Jacobi basis function
+        """
+
+        super(Jacobi, self).__init__(p)
+
+        # determine polynomial normalization factor
+        beta_norm = (scipy.special.gamma(self.p["q"]) * scipy.special.gamma(self.p["p"]) /
+                     scipy.special.gamma(self.p["p"] + self.p["q"]) * 2.0 ** (self.p["p"] + self.p["q"] - 1)) ** (-1)
+
+        jacobi_norm = 2 ** (self.p["p"] + self.p["q"] - 1) / (
+                      (2.0 * self.p["i"] + self.p["p"] + self.p["q"] - 1)) * (
+                      scipy.special.gamma(self.p["i"] + self.p["p"])) * (
+                      scipy.special.gamma(self.p["i"] + self.p["q"])) / (
+                              scipy.special.gamma(self.p["i"] + self.p["p"] + self.p["q"] - 1) *
+                              scipy.special.factorial(self.p["i"]))
+
+        # normalization factor of polynomial (to later normalize basis functions <psi^2> = int(psi^2*p)dx)
+        self.fun_norm = jacobi_norm * beta_norm
+
+        # define basis function
+        self.fun = scipy.special.jacobi(self.p["i"],
+                                        self.p["q"] - 1,  # beta-pdf: alpha=p /// jacobi-poly: alpha=q-1  !!!
+                                        self.p["p"] - 1,  # beta-pdf: beta=q  /// jacobi-poly: beta=p-1   !!!
+                                        monic=False) / np.sqrt(self.fun_norm)
+
+        # derivative of polynomial
+        self.fun_der = np.polyder(self.fun)
+
+        # integral of fun and fun_der w.r.t. pdf (numerical integration with corresponding weights)
+        knots, weights = get_quadrature_jacobi_1d(n=10 * self.p["i"], p=self.p["p"] - 1, q=self.p["q"] - 1)
+        self.fun_int = np.dot(self.fun(knots), weights)
+        self.fun_der_int = np.dot(self.fun_der(knots), weights)
+
+
+class Hermite(BasisFunction):
+    """
+    Hermite basis function used in the orthogonal gPC to model normal distributed random variables.
+
+    Parameters
+    ----------
+    p : dict
+        Parameters of the Hermite polynomial
+        - p["i"] ... order
+    """
+
+    def __init__(self, p):
+        """
+        Constructor; initializes a Hermite basis function
+        """
+
+        super(Hermite, self).__init__(p)
+
+        # normalization factor of polynomial (to later normalize basis functions <psi^2> = int(psi^2*p)dx)
+        self.fun_norm = np.float64(scipy.special.factorial(p["i"]))
+
+        # define basis function
+        self.fun = scipy.special.hermitenorm(p["i"], monic=False) / np.sqrt(self.fun_norm)
+
+        # derivative of polynomial
+        self.fun_der = np.polyder(self.fun)
+
+        # integral of fun and fun_der w.r.t. pdf (numerical integration with corresponding weights)
+        if self.p["i"] == 0:
+            self.fun_int = 1.0
+            self.fun_der_int = 0.0
+        else:
+            knots, weights = get_quadrature_hermite_1d(n=10 * self.p["i"])
+            self.fun_int = np.dot(self.fun(knots), weights)
+            self.fun_der_int = np.dot(self.fun_der(knots), weights)
+
+
+class Laguerre(BasisFunction):
+    """
+    Laguerre basis function used in the orthogonal gPC to model gamma distributed random variables.
+    It is defined in the gpc space from [0, inf]
+
+    Parameters
+    ----------
+    p : dict
+        Parameters of the Laguerre polynomial
+        - p["i"] ... order
+        - p["alpha"] ... shape parameter (alpha_poly = alpha_pdf - 1)
+        - p["beta"] ... rate parameter
+    """
+
+    def __init__(self, p):
+        """
+        Constructor; initializes a Laguerre basis function
+        """
+
+        super(Laguerre, self).__init__(p)
+
+        self.fun_norm = (scipy.special.factorial(p["i"]+p["alpha"]) / scipy.special.factorial(p["i"])) / \
+                        scipy.special.gamma(p["alpha"] + 1)
+
+        # define basis function
+        self.fun = scipy.special.genlaguerre(p["i"], alpha=p["alpha"], monic=False) / np.sqrt(self.fun_norm)
+
+        # derivative of polynomial
+        self.fun_der = np.polyder(self.fun)
+
+        # integral of fun and fun_der w.r.t. pdf (numerical integration with corresponding weights)
+        if self.p["i"] == 0:
+            self.fun_int = 1.0
+            self.fun_der_int = 0.0
+        else:
+            knots, weights = get_quadrature_laguerre_1d(n=10 * self.p["i"], alpha=p["alpha"])
+            self.fun_int = np.dot(self.fun(knots), weights)
+            self.fun_der_int = np.dot(self.fun_der(knots), weights)
+
+
+class StepUp(BasisFunction):
+    """
+    StepUp (from 0 to 1) basis function used in the non-orthogonal gPC.
+
+    Parameters
+    ----------
+    p : dict
+        Parameters of the StepUp function
+        - p["xs"] ... location of step
+    """
+
+    def __init__(self, p):
+        """
+        Constructor; initializes a StepUp basis function
+        """
+
+        super(StepUp, self).__init__(p)
+
+        # normalization factor of function (to later normalize basis functions <psi^2> = int(psi^2*p)dx)
+        self.fun_norm = 1.0
+
+        # define basis function
+        self.fun = lambda x: 0.0 if x < p["xs"] else (0.5 if x == p["xs"] else 1.0)
+
+        # derivative
+        self.fun_der = lambda x: 0.0
+
+
+class StepDown(BasisFunction):
+    """
+    StepDown (from 1 to 0) basis function used in the non-orthogonal gPC.
+
+    Parameters
+    ----------
+    p : dict
+        Parameters of the StepDown function
+        - p["xs"] ... location of step
+    """
+
+    def __init__(self, p):
+        """
+        Constructor; initializes a StepDown basis function
+        """
+
+        super(StepDown, self).__init__(p)
+
+        # normalization factor of function (to later normalize basis functions <psi^2> = int(psi^2*p)dx)
+        self.fun_norm = 1.0
+
+        # define basis function
+        self.fun = lambda x: 1.0 if x < p["xs"] else (0.5 if x == p["xs"] else 0.0)
+
+        # derivative
+        self.fun_der = lambda x: 0.0
+
+
+class Rect(BasisFunction):
+    """
+    Rectangular basis function used in the non-orthogonal gPC.
+
+    Parameters
+    ----------
+    p : dict
+        Parameters of the Rect function
+        - p["x1"] ... location of positive flank (0 -> 1)
+        - p["x2"] ... location of negative flank (1 -> 0)
+    """
+
+    def __init__(self, p):
+        """
+        Constructor; initializes a Rect basis function
+        """
+
+        super(Rect, self).__init__(p)
+
+        # normalization factor of function (to later normalize basis functions <psi^2> = int(psi^2*p)dx)
+        self.fun_norm = 1.0
+
+        # define basis function
+        self.fun = lambda x: 1.0 if p["x1"] < x < p["x2"] else (0.5 if x == p["x1"] or x == p["x2"] else 0.0)
+
+        # derivative
+        self.fun_der = lambda x: 0.0
+
+
+class SigmoidUp(BasisFunction):
+    """
+    SigmoidUp (from 0 to 1) basis function used in the non-orthogonal gPC.
+
+    Parameters
+    ----------
+    p : dict
+        Parameters of the SigmoidUp function
+        - p["xs"] ... location of turning point
+        - p["r"] ... steepness
+    """
+
+    def __init__(self, p):
+        """
+        Constructor; initializes a SigmoidUp basis function
+        """
+
+        super(SigmoidUp, self).__init__(p)
+
+        # normalization factor of function (to later normalize basis functions <psi^2> = int(psi^2*p)dx)
+        self.fun_norm = 1.0
+
+        # define basis function
+        self.fun = lambda x: 1.0 / (1 + np.exp(-p["r"] * (x - p["xs"])))
+
+        # derivative
+        self.fun_der = lambda x: (p["r"] * np.exp(-p["r"] * (x - p["xs"]))) / (1 + np.exp(-p["r"] * (x - p["xs"])))**2
+
+
+class SigmoidDown(BasisFunction):
+    """
+    SigmoidDown (from 0 to 1) basis function used in the non-orthogonal gPC.
+
+    Parameters
+    ----------
+    p : dict
+        Parameters of the SigmoidDown function
+        - p["xs"] ... location of turning point
+        - p["r"] ... steepness
+    """
+
+    def __init__(self, p):
+        """
+        Constructor; initializes a SigmoidDown basis function
+        """
+
+        super(SigmoidDown, self).__init__(p)
+
+        # normalization factor of function (to later normalize basis functions <psi^2> = int(psi^2*p)dx)
+        self.fun_norm = 1.0
+
+        # define basis function
+        self.fun = lambda x: 1.0 / (1 + np.exp(-p["r"] * (- x + p["xs"])))
+
+        # derivative
+        self.fun_der = lambda x: (- p["r"] * np.exp(-p["r"] * (- x + p["xs"]))) / (1 + np.exp(-p["r"] *
+                                 (- x + p["xs"])))**2
```

## pygpc/Classifier.py

 * *Ordering differences only*

```diff
@@ -1,176 +1,176 @@
-import numpy as np
-import copy
-from sklearn.cluster import KMeans
-from sklearn.cluster import spectral_clustering
-from sklearn.neural_network import MLPClassifier
-
-
-def Classifier(coords, results, algorithm="learning", options=None):
-    """
-    Helper function to initialize Classifier class.
-
-    Parameters
-    ----------
-    coords: ndarray of float [n_grid, n_dim]
-        Set of n_grid parameter combinations
-    results: ndarray [n_grid x n_out]
-        Results of the model evaluation
-    algorithm: str, optional, default: "learning"
-        Algorithm to classify grid points
-        - "learning" ... 2-step procedure with unsupervised and supervised learning
-        - ...
-    options: dict, optional, default=None
-        Classifier options
-
-    Returns
-    -------
-    obj : object instance of Classifier class
-        Object instance of Classifier class
-    """
-    if algorithm == "learning":
-        return ClassifierLearning(coords=coords, results=results, options=options)
-    else:
-        raise AttributeError("Please specify correct classification algorithm: {""learning"", ...}")
-
-
-class ClassifierLearning(object):
-    """
-    ClassifierLearning class
-
-    Parameters
-    ----------
-    coords: ndarray of float [n_grid, n_dim]
-        Grid points to train the classifier
-    results: ndarray [n_grid x n_out]
-        Results of the model evaluation
-    options: dict, optional, default=None
-        Classifier options
-        - options["clusterer"] ... Cluster algorithm (e.g. "KMeans")
-        - options["n_clusters"] ... Number of clusters in case of "KMeans"
-        - options["classifier"] ... Classification algorithm (e.g. "MLPClassifier")
-        - options["classifier_solver"] ... Classification algorithm (e.g. "adam" or "lbfgs")
-
-    Attributes
-    ----------
-    coords: ndarray of float [n_grid, n_dim]
-        Grid points to train the classifier
-    results: ndarray [n_grid x n_out]
-        Results of the model evaluation
-    options: dict, optional, default=None
-        Classifier options
-    clf: Classifier object
-        Classifier object
-    """
-    def __init__(self, coords, results, options=None):
-        """
-        Constructor; Initializes ClassifierLearning class
-        """
-        self.results = results
-        self.coords = coords
-        self.options = options
-
-        # set defaults
-        if options is None:
-            options = dict()
-            options["clusterer"] = "KMeans"
-            options["n_clusters"] = 2
-            options["classifier"] = "MLPClassifier"
-            options["classifier_solver"] = "lbfgs"
-
-        # setup clusterer to determine domains (unsupervised learning)
-        if options["clusterer"] == "KMeans":
-            self.clusterer = KMeans(n_clusters=options["n_clusters"],
-                                    random_state=42,
-                                    n_init=100)
-
-        elif options["clusterer"] == "spectral_clustering":
-            raise NotImplementedError("spectral projection not implemented yet")
-            adjacency_matrix = None
-            self.clusterer = spectral_clustering(adjacency_matrix,
-                                                 n_clusters=options["n_clusters"],
-                                                 random_state=0,
-                                                 eigen_solver='arpack',
-                                                 assign_labels="discretize")
-
-        else:
-            raise AttributeError("Please specify correct clusterer: {""KMeans"", ""spectral_clustering""...}")
-
-        self.clusterer.fit(results)
-        self.domains = self.clusterer.labels_
-        self.swap_idx = np.arange(len(np.unique(self.domains)))
-
-        # setup classifier for prediction (supervised learning)
-        if options["classifier"] == "MLPClassifier":
-            self.clf = MLPClassifier(alpha=0.01,
-                                     max_iter=1000,
-                                     activation="relu",
-                                     solver=options["classifier_solver"])
-        else:
-            raise AttributeError("Please specify correct classifier: {""MLPClassifier"", ...}")
-
-        self.clf.fit(coords, self.domains)
-
-    def update(self, coords, results):
-        """
-        Updates classifier using the previous results
-
-        Parameters
-        ----------
-        coords: ndarray of float [n_grid, n_dim]
-            Grid points to train the classifier
-        results: ndarray [n_grid x n_out]
-            Results of the model evaluation
-        """
-        self.coords = coords
-        self.results = results
-
-        domains_old = copy.deepcopy(self.domains)
-
-        # rerun clusterer
-        self.clusterer.fit(self.results)
-        self.domains = self.clusterer.labels_
-
-        # check if domain labels are swapped and change it back to initial order
-        domains_new = self.domains[:len(domains_old)]
-        domains_unique = np.unique(domains_old)
-
-        self.swap_idx = np.arange(len(domains_unique))
-        for d in domains_unique:
-            if np.mean(domains_old[domains_old == d] == domains_new[domains_old == d]) < 0.5:
-                count = np.zeros(len(domains_unique))
-                for di in domains_unique:
-                    count[di] = np.sum(domains_new[domains_old == d] == di)
-
-                if np.max(count) > 0:
-                    self.swap_idx[d] = np.argmax(count)
-                else:
-                    self.swap_idx[d] = d
-
-        domains_temp = np.zeros(self.domains.shape)
-
-        for d in domains_unique:
-            domains_temp[self.domains == d] = self.swap_idx[d]
-
-        self.domains = domains_temp.astype(int)
-
-        # rerun classifier
-        self.clf.fit(self.coords, self.domains)
-
-    def predict(self, coords):
-        """
-        Predict domains from new coordinates
-
-        Parameters
-        ----------
-        coords: ndarray of float [n_grid, n_dim]
-            Grid points to classify (has to be a 2D array)
-
-        Returns
-        -------
-        domains: ndarray of float [n_grid, n_dim]
-            Domain IDs of grid-points
-        """
-
-        domains = self.clf.predict(coords)
-
-        return domains
+import numpy as np
+import copy
+from sklearn.cluster import KMeans
+from sklearn.cluster import spectral_clustering
+from sklearn.neural_network import MLPClassifier
+
+
+def Classifier(coords, results, algorithm="learning", options=None):
+    """
+    Helper function to initialize Classifier class.
+
+    Parameters
+    ----------
+    coords: ndarray of float [n_grid, n_dim]
+        Set of n_grid parameter combinations
+    results: ndarray [n_grid x n_out]
+        Results of the model evaluation
+    algorithm: str, optional, default: "learning"
+        Algorithm to classify grid points
+        - "learning" ... 2-step procedure with unsupervised and supervised learning
+        - ...
+    options: dict, optional, default=None
+        Classifier options
+
+    Returns
+    -------
+    obj : object instance of Classifier class
+        Object instance of Classifier class
+    """
+    if algorithm == "learning":
+        return ClassifierLearning(coords=coords, results=results, options=options)
+    else:
+        raise AttributeError("Please specify correct classification algorithm: {""learning"", ...}")
+
+
+class ClassifierLearning(object):
+    """
+    ClassifierLearning class
+
+    Parameters
+    ----------
+    coords: ndarray of float [n_grid, n_dim]
+        Grid points to train the classifier
+    results: ndarray [n_grid x n_out]
+        Results of the model evaluation
+    options: dict, optional, default=None
+        Classifier options
+        - options["clusterer"] ... Cluster algorithm (e.g. "KMeans")
+        - options["n_clusters"] ... Number of clusters in case of "KMeans"
+        - options["classifier"] ... Classification algorithm (e.g. "MLPClassifier")
+        - options["classifier_solver"] ... Classification algorithm (e.g. "adam" or "lbfgs")
+
+    Attributes
+    ----------
+    coords: ndarray of float [n_grid, n_dim]
+        Grid points to train the classifier
+    results: ndarray [n_grid x n_out]
+        Results of the model evaluation
+    options: dict, optional, default=None
+        Classifier options
+    clf: Classifier object
+        Classifier object
+    """
+    def __init__(self, coords, results, options=None):
+        """
+        Constructor; Initializes ClassifierLearning class
+        """
+        self.results = results
+        self.coords = coords
+        self.options = options
+
+        # set defaults
+        if options is None:
+            options = dict()
+            options["clusterer"] = "KMeans"
+            options["n_clusters"] = 2
+            options["classifier"] = "MLPClassifier"
+            options["classifier_solver"] = "lbfgs"
+
+        # setup clusterer to determine domains (unsupervised learning)
+        if options["clusterer"] == "KMeans":
+            self.clusterer = KMeans(n_clusters=options["n_clusters"],
+                                    random_state=42,
+                                    n_init=100)
+
+        elif options["clusterer"] == "spectral_clustering":
+            raise NotImplementedError("spectral projection not implemented yet")
+            adjacency_matrix = None
+            self.clusterer = spectral_clustering(adjacency_matrix,
+                                                 n_clusters=options["n_clusters"],
+                                                 random_state=0,
+                                                 eigen_solver='arpack',
+                                                 assign_labels="discretize")
+
+        else:
+            raise AttributeError("Please specify correct clusterer: {""KMeans"", ""spectral_clustering""...}")
+
+        self.clusterer.fit(results)
+        self.domains = self.clusterer.labels_
+        self.swap_idx = np.arange(len(np.unique(self.domains)))
+
+        # setup classifier for prediction (supervised learning)
+        if options["classifier"] == "MLPClassifier":
+            self.clf = MLPClassifier(alpha=0.01,
+                                     max_iter=1000,
+                                     activation="relu",
+                                     solver=options["classifier_solver"])
+        else:
+            raise AttributeError("Please specify correct classifier: {""MLPClassifier"", ...}")
+
+        self.clf.fit(coords, self.domains)
+
+    def update(self, coords, results):
+        """
+        Updates classifier using the previous results
+
+        Parameters
+        ----------
+        coords: ndarray of float [n_grid, n_dim]
+            Grid points to train the classifier
+        results: ndarray [n_grid x n_out]
+            Results of the model evaluation
+        """
+        self.coords = coords
+        self.results = results
+
+        domains_old = copy.deepcopy(self.domains)
+
+        # rerun clusterer
+        self.clusterer.fit(self.results)
+        self.domains = self.clusterer.labels_
+
+        # check if domain labels are swapped and change it back to initial order
+        domains_new = self.domains[:len(domains_old)]
+        domains_unique = np.unique(domains_old)
+
+        self.swap_idx = np.arange(len(domains_unique))
+        for d in domains_unique:
+            if np.mean(domains_old[domains_old == d] == domains_new[domains_old == d]) < 0.5:
+                count = np.zeros(len(domains_unique))
+                for di in domains_unique:
+                    count[di] = np.sum(domains_new[domains_old == d] == di)
+
+                if np.max(count) > 0:
+                    self.swap_idx[d] = np.argmax(count)
+                else:
+                    self.swap_idx[d] = d
+
+        domains_temp = np.zeros(self.domains.shape)
+
+        for d in domains_unique:
+            domains_temp[self.domains == d] = self.swap_idx[d]
+
+        self.domains = domains_temp.astype(int)
+
+        # rerun classifier
+        self.clf.fit(self.coords, self.domains)
+
+    def predict(self, coords):
+        """
+        Predict domains from new coordinates
+
+        Parameters
+        ----------
+        coords: ndarray of float [n_grid, n_dim]
+            Grid points to classify (has to be a 2D array)
+
+        Returns
+        -------
+        domains: ndarray of float [n_grid, n_dim]
+            Domain IDs of grid-points
+        """
+
+        domains = self.clf.predict(coords)
+
+        return domains
```

## pygpc/Computation.py

 * *Ordering differences only*

```diff
@@ -1,464 +1,464 @@
-import subprocess
-import time
-import copy
-import numpy as np
-import os
-import re
-import multiprocessing
-import multiprocessing.pool
-# import dispy
-from collections import OrderedDict
-from pygpc import Worker
-from .io import iprint
-from .RandomParameter import *
-
-
-def Computation(n_cpu, matlab_model=False):
-    """
-    Helper function to initialize the Computation class.
-    n_cpu = 0 : use this if the model is capable of to evaluate several parameterizations in parallel
-    n_cpu = 1 : the model is called in serial for every paramerization.
-    n_cpu > 1 : A multiprocessing.Pool will be opened and n_cpu parameterizations are calculated in parallel
-
-    Parameters
-    ----------
-    n_cpu : int
-        Number of CPU cores to use (parallel model evaluations)
-    matlab_model : boolean, optional, default: False
-        Use a Matlab model
-
-    Returns
-    -------
-    obj : object instance of Computation class
-        Object instance of Computation class
-    """
-    if n_cpu == 0:
-        return ComputationFuncPar(n_cpu, matlab_model=matlab_model)
-    else:
-        return ComputationPoolMap(n_cpu, matlab_model=matlab_model)
-
-
-class ComputationPoolMap:
-    """
-    Computation sub-class to run the model using a processing pool for parallelization
-
-    Parameters
-    ----------
-    n_cpu : int
-        Number of CPU cores to use (parallel model evaluations)
-    matlab_model : boolean, optional, default: False
-        Use a Matlab model
-    """
-
-    def __init__(self, n_cpu, matlab_model=False):
-        """
-        Constructor; Initializes ComputationPoolMap class
-        """
-        # Setting up parallelization (setup thread pool)
-        n_cpu_available = multiprocessing.cpu_count()
-        self.n_cpu = min(n_cpu, n_cpu_available)
-
-        self.i_grid = 0
-
-        # Use a process queue to assign persistent, unique IDs to the processes in the pool
-        self.process_manager = multiprocessing.Manager()
-        self.process_queue = self.process_manager.Queue()
-        self.process_pool = multiprocessing.Pool(self.n_cpu, Worker.init, (self.process_queue,))
-
-        # Global counter used by all threads to keep track of the progress
-        self.global_task_counter = self.process_manager.Value('i', 0)
-
-        for i in range(0, n_cpu):
-            self.process_queue.put(i)
-
-        # Necessary to synchronize read/write access to serialized results
-        self.global_lock = self.process_manager.RLock()
-
-        self.matlab_engine = None
-
-        # start matlab engine
-        if matlab_model:
-            import matlab.engine
-            iprint("Starting Matlab engine ...", tab=0, verbose=False)
-            self.matlab_engine = matlab.engine.start_matlab()
-
-    def run(self, model, problem, coords, coords_norm=None, i_iter=None, i_subiter=None, fn_results=None,
-            print_func_time=False, increment_grid=True, verbose=False):
-        """
-        Runs model evaluations for parameter combinations specified in coords array
-
-        Parameters
-        ----------
-        model: Model object
-            Model object instance of model to investigate (derived from AbstractModel class, implemented by user)
-        problem: Problem class instance
-            GPC Problem under investigation, includes the parameters of the model (constant and random)
-        coords: ndarray of float [n_sims, n_dim]
-            Set of n_sims parameter combinations to run the model with (only the random parameters!).
-        coords_norm: ndarray of float [n_sims, n_dim]
-            Set of n_sims parameter combinations to run the model with (normalized coordinates [-1, 1].
-        i_iter: int
-            Index of main-iteration
-        i_subiter: int
-            Index of sub-iteration
-        fn_results : string, optional, default=None
-            If provided, model evaluations are saved in fn_results.hdf5 file and gpc object in fn_results.pkl file
-        print_func_time : bool
-            Print time of single function evaluation
-        increment_grid : bool
-            Increment grid counter (not done in case of gradient calculation)
-        verbose : bool, optional, default: False
-            Print progress
-
-        Returns
-        -------
-        res: ndarray of float [n_sims x n_out]
-            n_sims simulation results of the n_out output quantities of the model under investigation.
-        """
-        if i_iter is None:
-            i_iter = "N/A"
-
-        if i_subiter is None:
-            i_subiter = "N/A"
-
-        # read new grid points and convert to list for multiprocessing
-        grid_new = coords.tolist()
-
-        n_grid_new = len(grid_new)
-
-        # create worker objects that will evaluate the function
-        worker_objs = []
-        self.global_task_counter.value = 0  # since we re-use the  global counter, we need to reset it first
-        seq_num = 0
-
-        # assign the instances of the random_vars to the respective
-        # replace random vars of the Problem with single instances
-        # determined by the PyGPC framework:
-        # assign the instances of the random_vars to the respective
-        # entries of the dictionary
-        # -> As a result we have the same keys in the dictionary but
-        #    no RandomParameters anymore but a sample from the defined PDF.
-
-        # deepcopy model and delete attributes
-        model_ = copy.deepcopy(model)
-        model_.__clean__()
-
-        for j, random_var_instances in enumerate(grid_new):
-
-            if coords_norm is None:
-                c_norm = None
-            else:
-                c_norm = coords_norm[j, :][np.newaxis, :]
-
-            # setup context (let the process know which iteration, interaction order etc.)
-            context = {
-                'global_task_counter': self.global_task_counter,
-                'lock': self.global_lock,
-                'seq_number': seq_num,
-                'i_grid': self.i_grid,
-                'max_grid': n_grid_new,
-                'i_iter': i_iter,
-                'i_subiter': i_subiter,
-                'fn_results': fn_results,
-                'coords': np.array(random_var_instances)[np.newaxis, :],
-                'coords_norm': c_norm,
-                'print_func_time': print_func_time,
-                'verbose': verbose,
-            }
-
-            # deepcopy parameters
-            parameters = OrderedDict()
-            for key in problem.parameters:
-                parameters[key] = problem.parameters[key]
-
-            # replace RandomParameters with grid points
-            for i in range(0, len(random_var_instances)):
-                if type(random_var_instances[i]) is not np.array:
-                    random_var_instances[i] = np.array([random_var_instances[i]])
-                parameters[list(problem.parameters_random.keys())[i]] = random_var_instances[i]
-
-            # append new worker which will evaluate the model with particular parameters from grid
-            import time
-
-            # start = time.time()
-            # model_ = copy.deepcopy(model)
-            # end = time.time()
-            # print("copy.deepcopy: {}s".format(end-start))
-
-            # start = time.time()
-            # model_worker = model_.__copy__().set_parameters(p=parameters, context=context)
-            # model_worker1 = model_.__copy__().set_parameters(p=parameters, context=context)
-            # end = time.time()
-            # print("__copy__: {}s".format(end - start))
-
-            # model_worker.p["exp_idx"] = 99
-            # model_worker1.p["exp_idx"]
-
-            worker_objs.append(model_.__copy__().set_parameters(p=parameters, context=context))
-
-            if increment_grid:
-                self.i_grid += 1
-            seq_num += 1
-
-        # start model evaluations
-        if self.n_cpu == 1:
-            res_new_list = []
-
-            for i in range(len(worker_objs)):
-                res_new_list.append(Worker.run(obj=worker_objs[i], matlab_engine=self.matlab_engine))
-
-        else:
-            # The map-function deals with chunking the data
-            res_new_list = self.process_pool.map(Worker.run, worker_objs, self.matlab_engine)
-
-        # Initialize the result array with the correct size and set the elements according to their order
-        # (the first element in 'res' might not necessarily be the result of the first Process/i_grid)
-        res = [None] * n_grid_new
-        for result in res_new_list:
-            res[result[0]] = result[1]
-
-        res = np.vstack(res)
-
-        return res
-
-    def close(self):
-        """ Closes the pool """
-        self.process_pool.close()
-        self.process_pool.join()
-
-
-class ComputationFuncPar:
-    """
-    Computation sub-class to run the model using a the models internal parallelization
-
-    Parameters
-    ----------
-    n_cpu : int
-        Number of CPU cores to use (parallel model evaluations)
-    matlab_model : boolean, optional, default: False
-        Use a Matlab model
-    """
-
-    def __init__(self, n_cpu, matlab_model):
-        """
-        Constructor; Initializes ComputationPoolMap class
-        """
-        # Setting up parallelization (setup thread pool)
-        n_cpu_available = multiprocessing.cpu_count()
-        self.n_cpu = min(n_cpu, n_cpu_available)
-
-        self.i_grid = 0
-
-        # Global counter used by all threads to keep track of the progress
-        self.global_task_counter = 0
-
-        self.matlab_engine = None
-
-        # start matlab engine
-        if matlab_model:
-            import matlab.engine
-            iprint("Starting Matlab engine ...", tab=0, verbose=True)
-            self.matlab_engine = matlab.engine.start_matlab()
-
-    def run(self, model, problem, coords, coords_norm=None, i_iter=None, i_subiter=None, fn_results=None,
-            print_func_time=False, increment_grid=True, verbose=False):
-        """
-        Runs model evaluations for parameter combinations specified in coords array
-
-        Parameters
-        ----------
-        model: Model object
-            Model object instance of model to investigate (derived from AbstractModel class, implemented by user)
-        problem: Problem class instance
-            GPC Problem under investigation, includes the parameters of the model (constant and random)
-        coords: ndarray of float [n_sims, n_dim]
-            Set of n_sims parameter combinations to run the model with (only the random parameters!).
-        coords_norm: ndarray of float [n_sims, n_dim]
-            Set of n_sims parameter combinations to run the model with (normalized coordinates [-1, 1].
-        i_iter: int
-            Index of main-iteration
-        i_subiter: int
-            Index of sub-iteration
-        fn_results : string, optional, default=None
-            If provided, model evaluations are saved in fn_results.hdf5 file and gpc object in fn_results.pkl file
-        print_func_time : bool
-            Print time of single function evaluation
-        increment_grid : bool
-            Increment grid counter (not done in case of gradient calculation)
-        verbose : bool, optional, default: False
-            Print progress
-
-        Returns
-        -------
-        res: ndarray of float [n_sims x n_out]
-            n_sims simulation results of the n_out output quantities of the model under investigation.
-        """
-        if i_iter is None:
-            i_iter = "N/A"
-
-        if i_subiter is None:
-            i_subiter = "N/A"
-
-        n_grid = coords.shape[0]
-
-        # i_grid indices is now a range [min_idx, max_idx]
-        if increment_grid:
-            self.i_grid = [np.max(self.i_grid), np.max(self.i_grid) + n_grid]
-
-        # assign the instances of the random_vars to the respective
-        # replace random vars of the Problem with single instances
-        # determined by the PyGPC framework:
-        # assign the instances of the random_vars to the respective
-        # entries of the dictionary
-        # -> As a result we have the same keys in the dictionary but
-        #    no RandomParameters anymore but a sample from the defined PDF.
-
-        if coords_norm is None:
-            c_norm = None
-        else:
-            c_norm = coords_norm
-
-        # setup context (let the process know which iteration, interaction order etc.)
-        context = {
-            'global_task_counter': self.global_task_counter,
-            'lock': None,
-            'seq_number': None,
-            'i_grid': self.i_grid,
-            'max_grid': n_grid,
-            'i_iter': i_iter,
-            'i_subiter': i_subiter,
-            'fn_results': fn_results,
-            'coords': coords,
-            'coords_norm': c_norm,
-            'print_func_time': print_func_time,
-            'verbose': verbose
-        }
-
-        parameters = OrderedDict()
-        i_random_parameter = 0
-
-        for key in problem.parameters:
-
-            if isinstance(problem.parameters[key], RandomParameter):
-                # replace RandomParameters with grid points
-                parameters[key] = coords[:, i_random_parameter]
-                i_random_parameter += 1
-
-            else:
-                # copy constant parameters n_grid times
-                if type(problem.parameters[key]) == str:
-                    parameters[key] = [problem.parameters[key] for _ in range(n_grid)]
-                elif type(problem.parameters[key]) == float or problem.parameters[key].size == 1:
-                    parameters[key] = problem.parameters[key] * np.ones(n_grid)
-                else:
-                    if str(type(problem.parameters[key])) == "<class 'matlab.engine.matlabengine.MatlabEngine'>":
-                        parameters[key] = problem.parameters[key]
-                    else:
-                        parameters[key] = np.tile(problem.parameters[key], (n_grid, 1))
-
-        # generate worker, which will evaluate the model (here only one for all grid points in coords)
-        worker_objs = model.set_parameters(p=parameters, context=context)
-
-        # start model evaluations
-        res = Worker.run(obj=worker_objs, matlab_engine=self.matlab_engine)
-
-        res = np.array(res[1])
-
-        return res
-
-    def close(self):
-        """ Closes the pool """
-        pass
-
-
-# def compute_cluster(algorithms, nodes, start_scheduler=True):
-#     """
-#     Computes Algorithm instances on compute cluster composed of nodes. The first node is also the dispy-scheduler.
-#     Afterwards, the dispy-nodes are started on every node. On every node, screen sessions are started with the names
-#     "scheduler" and "node", where the scheduler and the nodes are residing, respectively.
-#     They can be accessed by "screen -rD scheduler" or "screen -rD node" when connected via ssh to the machines.
-#
-#     Parameters
-#     ----------
-#     algorithms : list of Algorithm instances
-#         Algorithm instances initialized with different gPC problems and/or models
-#     nodes : str or list of str
-#         Node names
-#     start_scheduler : bool
-#         Starts a scheduler on the first machine in the nodes list or not. Set this to False if a scheduler is already
-#         running somewhere on the cluster.
-#     """
-#
-#     def _algorithm_run(f):
-#         f.run
-#
-#     dispy.MsgTimeout = 90
-#
-#     for n in nodes:
-#         # screen/dispy output will be send to devnull, to keep the terminal window clean
-#         with open(os.devnull, 'w') as f:
-#
-#             # get PIDs for old scheduler and node screens and kill them
-#             regexp_pid = "\t(\d*)."  # after \tab, get digits until '.'
-#
-#             for name in ["scheduler", "node"]:
-#                 # get screen -list output for correct screen, which also has the pid
-#                 stdout, stderr = subprocess.Popen(['ssh', n, 'screen -list | grep {}'.format(name)],
-#                                                   stdout=subprocess.PIPE,
-#                                                   stderr=subprocess.PIPE).communicate()
-#                 subprocess.Popen(['ssh', n, 'screen', "-wipe"]).communicate()
-#                 try:
-#                     pid = re.search(regexp_pid, stdout).group(0)[:-1]  # remove last char (.)
-#                     subprocess.Popen(['ssh', n, 'kill', pid]).communicate()
-#
-#                 except AttributeError:
-#                     # no 'scheduler' or 'node' screen session found on host
-#                     pass
-#
-#             # start scheduler on first node
-#             if start_scheduler:
-#                 print("Starting dispy scheduler on " + n)
-#
-#                 # subprocess.Popen("ssh -tt " + n + " screen -R scheduler -d -m python "
-#                 #                  + os.path.join(dispy.__path__[0], "dispyscheduler.py &"), shell=True)
-#
-#                 # ssh -tt: pseudo terminal allocation
-#                 #
-#                 # screen
-#                 #        -R scheduler: Reconnect or create session with name scheduler
-#                 #        -d detach (is it needed?)
-#                 #        -m "ignore $STY variable, do create a new screen session" ??
-#                 #
-#                 # subprocess
-#                 #        -shell: False. If True, opens new shell and does not return
-#                 #                If true, do not use [] argument passing style.
-#                 #        -stdout: devnull. Pipe leads to flooded terminal.
-#                 #
-#                 # "export", "TERM=screen", "&&",
-#                 #
-#                 subprocess.Popen(["ssh", "-tt", n,
-#                                   "screen", "-dmS", "scheduler",
-#                                   "python " + os.path.join(dispy.__path__[0], "dispyscheduler.py")],
-#                                   shell=False, stdout=f)
-#                 time.sleep(5)
-#
-#             print("Starting dispy node on " + n)
-#             subprocess.Popen(["ssh", "-tt", n,
-#                               "screen", "-dmS", "node",
-#                               "python " + os.path.join(dispy.__path__[0], "dispynode.py --clean")],
-#                               shell=False, stdout=f)
-#             time.sleep(5)
-#
-#     cluster = dispy.SharedJobCluster(_algorithm_run, scheduler_node=nodes[0], reentrant=True, port=0)
-#
-#     time.sleep(5)
-#
-#     # build job list and start computations
-#     jobs = []
-#     for a in algorithms:
-#         job = cluster.submit(a)
-#         job.id = a
-#         jobs.append(job)
-#
-#     # wait until cluster finished the computations
-#     cluster.wait()
+import subprocess
+import time
+import copy
+import numpy as np
+import os
+import re
+import multiprocessing
+import multiprocessing.pool
+# import dispy
+from collections import OrderedDict
+from pygpc import Worker
+from .io import iprint
+from .RandomParameter import *
+
+
+def Computation(n_cpu, matlab_model=False):
+    """
+    Helper function to initialize the Computation class.
+    n_cpu = 0 : use this if the model is capable of to evaluate several parameterizations in parallel
+    n_cpu = 1 : the model is called in serial for every paramerization.
+    n_cpu > 1 : A multiprocessing.Pool will be opened and n_cpu parameterizations are calculated in parallel
+
+    Parameters
+    ----------
+    n_cpu : int
+        Number of CPU cores to use (parallel model evaluations)
+    matlab_model : boolean, optional, default: False
+        Use a Matlab model
+
+    Returns
+    -------
+    obj : object instance of Computation class
+        Object instance of Computation class
+    """
+    if n_cpu == 0:
+        return ComputationFuncPar(n_cpu, matlab_model=matlab_model)
+    else:
+        return ComputationPoolMap(n_cpu, matlab_model=matlab_model)
+
+
+class ComputationPoolMap:
+    """
+    Computation sub-class to run the model using a processing pool for parallelization
+
+    Parameters
+    ----------
+    n_cpu : int
+        Number of CPU cores to use (parallel model evaluations)
+    matlab_model : boolean, optional, default: False
+        Use a Matlab model
+    """
+
+    def __init__(self, n_cpu, matlab_model=False):
+        """
+        Constructor; Initializes ComputationPoolMap class
+        """
+        # Setting up parallelization (setup thread pool)
+        n_cpu_available = multiprocessing.cpu_count()
+        self.n_cpu = min(n_cpu, n_cpu_available)
+
+        self.i_grid = 0
+
+        # Use a process queue to assign persistent, unique IDs to the processes in the pool
+        self.process_manager = multiprocessing.Manager()
+        self.process_queue = self.process_manager.Queue()
+        self.process_pool = multiprocessing.Pool(self.n_cpu, Worker.init, (self.process_queue,))
+
+        # Global counter used by all threads to keep track of the progress
+        self.global_task_counter = self.process_manager.Value('i', 0)
+
+        for i in range(0, n_cpu):
+            self.process_queue.put(i)
+
+        # Necessary to synchronize read/write access to serialized results
+        self.global_lock = self.process_manager.RLock()
+
+        self.matlab_engine = None
+
+        # start matlab engine
+        if matlab_model:
+            import matlab.engine
+            iprint("Starting Matlab engine ...", tab=0, verbose=False)
+            self.matlab_engine = matlab.engine.start_matlab()
+
+    def run(self, model, problem, coords, coords_norm=None, i_iter=None, i_subiter=None, fn_results=None,
+            print_func_time=False, increment_grid=True, verbose=False):
+        """
+        Runs model evaluations for parameter combinations specified in coords array
+
+        Parameters
+        ----------
+        model: Model object
+            Model object instance of model to investigate (derived from AbstractModel class, implemented by user)
+        problem: Problem class instance
+            GPC Problem under investigation, includes the parameters of the model (constant and random)
+        coords: ndarray of float [n_sims, n_dim]
+            Set of n_sims parameter combinations to run the model with (only the random parameters!).
+        coords_norm: ndarray of float [n_sims, n_dim]
+            Set of n_sims parameter combinations to run the model with (normalized coordinates [-1, 1].
+        i_iter: int
+            Index of main-iteration
+        i_subiter: int
+            Index of sub-iteration
+        fn_results : string, optional, default=None
+            If provided, model evaluations are saved in fn_results.hdf5 file and gpc object in fn_results.pkl file
+        print_func_time : bool
+            Print time of single function evaluation
+        increment_grid : bool
+            Increment grid counter (not done in case of gradient calculation)
+        verbose : bool, optional, default: False
+            Print progress
+
+        Returns
+        -------
+        res: ndarray of float [n_sims x n_out]
+            n_sims simulation results of the n_out output quantities of the model under investigation.
+        """
+        if i_iter is None:
+            i_iter = "N/A"
+
+        if i_subiter is None:
+            i_subiter = "N/A"
+
+        # read new grid points and convert to list for multiprocessing
+        grid_new = coords.tolist()
+
+        n_grid_new = len(grid_new)
+
+        # create worker objects that will evaluate the function
+        worker_objs = []
+        self.global_task_counter.value = 0  # since we re-use the  global counter, we need to reset it first
+        seq_num = 0
+
+        # assign the instances of the random_vars to the respective
+        # replace random vars of the Problem with single instances
+        # determined by the PyGPC framework:
+        # assign the instances of the random_vars to the respective
+        # entries of the dictionary
+        # -> As a result we have the same keys in the dictionary but
+        #    no RandomParameters anymore but a sample from the defined PDF.
+
+        # deepcopy model and delete attributes
+        model_ = copy.deepcopy(model)
+        model_.__clean__()
+
+        for j, random_var_instances in enumerate(grid_new):
+
+            if coords_norm is None:
+                c_norm = None
+            else:
+                c_norm = coords_norm[j, :][np.newaxis, :]
+
+            # setup context (let the process know which iteration, interaction order etc.)
+            context = {
+                'global_task_counter': self.global_task_counter,
+                'lock': self.global_lock,
+                'seq_number': seq_num,
+                'i_grid': self.i_grid,
+                'max_grid': n_grid_new,
+                'i_iter': i_iter,
+                'i_subiter': i_subiter,
+                'fn_results': fn_results,
+                'coords': np.array(random_var_instances)[np.newaxis, :],
+                'coords_norm': c_norm,
+                'print_func_time': print_func_time,
+                'verbose': verbose,
+            }
+
+            # deepcopy parameters
+            parameters = OrderedDict()
+            for key in problem.parameters:
+                parameters[key] = problem.parameters[key]
+
+            # replace RandomParameters with grid points
+            for i in range(0, len(random_var_instances)):
+                if type(random_var_instances[i]) is not np.array:
+                    random_var_instances[i] = np.array([random_var_instances[i]])
+                parameters[list(problem.parameters_random.keys())[i]] = random_var_instances[i]
+
+            # append new worker which will evaluate the model with particular parameters from grid
+            import time
+
+            # start = time.time()
+            # model_ = copy.deepcopy(model)
+            # end = time.time()
+            # print("copy.deepcopy: {}s".format(end-start))
+
+            # start = time.time()
+            # model_worker = model_.__copy__().set_parameters(p=parameters, context=context)
+            # model_worker1 = model_.__copy__().set_parameters(p=parameters, context=context)
+            # end = time.time()
+            # print("__copy__: {}s".format(end - start))
+
+            # model_worker.p["exp_idx"] = 99
+            # model_worker1.p["exp_idx"]
+
+            worker_objs.append(model_.__copy__().set_parameters(p=parameters, context=context))
+
+            if increment_grid:
+                self.i_grid += 1
+            seq_num += 1
+
+        # start model evaluations
+        if self.n_cpu == 1:
+            res_new_list = []
+
+            for i in range(len(worker_objs)):
+                res_new_list.append(Worker.run(obj=worker_objs[i], matlab_engine=self.matlab_engine))
+
+        else:
+            # The map-function deals with chunking the data
+            res_new_list = self.process_pool.map(Worker.run, worker_objs, self.matlab_engine)
+
+        # Initialize the result array with the correct size and set the elements according to their order
+        # (the first element in 'res' might not necessarily be the result of the first Process/i_grid)
+        res = [None] * n_grid_new
+        for result in res_new_list:
+            res[result[0]] = result[1]
+
+        res = np.vstack(res)
+
+        return res
+
+    def close(self):
+        """ Closes the pool """
+        self.process_pool.close()
+        self.process_pool.join()
+
+
+class ComputationFuncPar:
+    """
+    Computation sub-class to run the model using a the models internal parallelization
+
+    Parameters
+    ----------
+    n_cpu : int
+        Number of CPU cores to use (parallel model evaluations)
+    matlab_model : boolean, optional, default: False
+        Use a Matlab model
+    """
+
+    def __init__(self, n_cpu, matlab_model):
+        """
+        Constructor; Initializes ComputationPoolMap class
+        """
+        # Setting up parallelization (setup thread pool)
+        n_cpu_available = multiprocessing.cpu_count()
+        self.n_cpu = min(n_cpu, n_cpu_available)
+
+        self.i_grid = 0
+
+        # Global counter used by all threads to keep track of the progress
+        self.global_task_counter = 0
+
+        self.matlab_engine = None
+
+        # start matlab engine
+        if matlab_model:
+            import matlab.engine
+            iprint("Starting Matlab engine ...", tab=0, verbose=True)
+            self.matlab_engine = matlab.engine.start_matlab()
+
+    def run(self, model, problem, coords, coords_norm=None, i_iter=None, i_subiter=None, fn_results=None,
+            print_func_time=False, increment_grid=True, verbose=False):
+        """
+        Runs model evaluations for parameter combinations specified in coords array
+
+        Parameters
+        ----------
+        model: Model object
+            Model object instance of model to investigate (derived from AbstractModel class, implemented by user)
+        problem: Problem class instance
+            GPC Problem under investigation, includes the parameters of the model (constant and random)
+        coords: ndarray of float [n_sims, n_dim]
+            Set of n_sims parameter combinations to run the model with (only the random parameters!).
+        coords_norm: ndarray of float [n_sims, n_dim]
+            Set of n_sims parameter combinations to run the model with (normalized coordinates [-1, 1].
+        i_iter: int
+            Index of main-iteration
+        i_subiter: int
+            Index of sub-iteration
+        fn_results : string, optional, default=None
+            If provided, model evaluations are saved in fn_results.hdf5 file and gpc object in fn_results.pkl file
+        print_func_time : bool
+            Print time of single function evaluation
+        increment_grid : bool
+            Increment grid counter (not done in case of gradient calculation)
+        verbose : bool, optional, default: False
+            Print progress
+
+        Returns
+        -------
+        res: ndarray of float [n_sims x n_out]
+            n_sims simulation results of the n_out output quantities of the model under investigation.
+        """
+        if i_iter is None:
+            i_iter = "N/A"
+
+        if i_subiter is None:
+            i_subiter = "N/A"
+
+        n_grid = coords.shape[0]
+
+        # i_grid indices is now a range [min_idx, max_idx]
+        if increment_grid:
+            self.i_grid = [np.max(self.i_grid), np.max(self.i_grid) + n_grid]
+
+        # assign the instances of the random_vars to the respective
+        # replace random vars of the Problem with single instances
+        # determined by the PyGPC framework:
+        # assign the instances of the random_vars to the respective
+        # entries of the dictionary
+        # -> As a result we have the same keys in the dictionary but
+        #    no RandomParameters anymore but a sample from the defined PDF.
+
+        if coords_norm is None:
+            c_norm = None
+        else:
+            c_norm = coords_norm
+
+        # setup context (let the process know which iteration, interaction order etc.)
+        context = {
+            'global_task_counter': self.global_task_counter,
+            'lock': None,
+            'seq_number': None,
+            'i_grid': self.i_grid,
+            'max_grid': n_grid,
+            'i_iter': i_iter,
+            'i_subiter': i_subiter,
+            'fn_results': fn_results,
+            'coords': coords,
+            'coords_norm': c_norm,
+            'print_func_time': print_func_time,
+            'verbose': verbose
+        }
+
+        parameters = OrderedDict()
+        i_random_parameter = 0
+
+        for key in problem.parameters:
+
+            if isinstance(problem.parameters[key], RandomParameter):
+                # replace RandomParameters with grid points
+                parameters[key] = coords[:, i_random_parameter]
+                i_random_parameter += 1
+
+            else:
+                # copy constant parameters n_grid times
+                if type(problem.parameters[key]) == str:
+                    parameters[key] = [problem.parameters[key] for _ in range(n_grid)]
+                elif type(problem.parameters[key]) == float or problem.parameters[key].size == 1:
+                    parameters[key] = problem.parameters[key] * np.ones(n_grid)
+                else:
+                    if str(type(problem.parameters[key])) == "<class 'matlab.engine.matlabengine.MatlabEngine'>":
+                        parameters[key] = problem.parameters[key]
+                    else:
+                        parameters[key] = np.tile(problem.parameters[key], (n_grid, 1))
+
+        # generate worker, which will evaluate the model (here only one for all grid points in coords)
+        worker_objs = model.set_parameters(p=parameters, context=context)
+
+        # start model evaluations
+        res = Worker.run(obj=worker_objs, matlab_engine=self.matlab_engine)
+
+        res = np.array(res[1])
+
+        return res
+
+    def close(self):
+        """ Closes the pool """
+        pass
+
+
+# def compute_cluster(algorithms, nodes, start_scheduler=True):
+#     """
+#     Computes Algorithm instances on compute cluster composed of nodes. The first node is also the dispy-scheduler.
+#     Afterwards, the dispy-nodes are started on every node. On every node, screen sessions are started with the names
+#     "scheduler" and "node", where the scheduler and the nodes are residing, respectively.
+#     They can be accessed by "screen -rD scheduler" or "screen -rD node" when connected via ssh to the machines.
+#
+#     Parameters
+#     ----------
+#     algorithms : list of Algorithm instances
+#         Algorithm instances initialized with different gPC problems and/or models
+#     nodes : str or list of str
+#         Node names
+#     start_scheduler : bool
+#         Starts a scheduler on the first machine in the nodes list or not. Set this to False if a scheduler is already
+#         running somewhere on the cluster.
+#     """
+#
+#     def _algorithm_run(f):
+#         f.run
+#
+#     dispy.MsgTimeout = 90
+#
+#     for n in nodes:
+#         # screen/dispy output will be send to devnull, to keep the terminal window clean
+#         with open(os.devnull, 'w') as f:
+#
+#             # get PIDs for old scheduler and node screens and kill them
+#             regexp_pid = "\t(\d*)."  # after \tab, get digits until '.'
+#
+#             for name in ["scheduler", "node"]:
+#                 # get screen -list output for correct screen, which also has the pid
+#                 stdout, stderr = subprocess.Popen(['ssh', n, 'screen -list | grep {}'.format(name)],
+#                                                   stdout=subprocess.PIPE,
+#                                                   stderr=subprocess.PIPE).communicate()
+#                 subprocess.Popen(['ssh', n, 'screen', "-wipe"]).communicate()
+#                 try:
+#                     pid = re.search(regexp_pid, stdout).group(0)[:-1]  # remove last char (.)
+#                     subprocess.Popen(['ssh', n, 'kill', pid]).communicate()
+#
+#                 except AttributeError:
+#                     # no 'scheduler' or 'node' screen session found on host
+#                     pass
+#
+#             # start scheduler on first node
+#             if start_scheduler:
+#                 print("Starting dispy scheduler on " + n)
+#
+#                 # subprocess.Popen("ssh -tt " + n + " screen -R scheduler -d -m python "
+#                 #                  + os.path.join(dispy.__path__[0], "dispyscheduler.py &"), shell=True)
+#
+#                 # ssh -tt: pseudo terminal allocation
+#                 #
+#                 # screen
+#                 #        -R scheduler: Reconnect or create session with name scheduler
+#                 #        -d detach (is it needed?)
+#                 #        -m "ignore $STY variable, do create a new screen session" ??
+#                 #
+#                 # subprocess
+#                 #        -shell: False. If True, opens new shell and does not return
+#                 #                If true, do not use [] argument passing style.
+#                 #        -stdout: devnull. Pipe leads to flooded terminal.
+#                 #
+#                 # "export", "TERM=screen", "&&",
+#                 #
+#                 subprocess.Popen(["ssh", "-tt", n,
+#                                   "screen", "-dmS", "scheduler",
+#                                   "python " + os.path.join(dispy.__path__[0], "dispyscheduler.py")],
+#                                   shell=False, stdout=f)
+#                 time.sleep(5)
+#
+#             print("Starting dispy node on " + n)
+#             subprocess.Popen(["ssh", "-tt", n,
+#                               "screen", "-dmS", "node",
+#                               "python " + os.path.join(dispy.__path__[0], "dispynode.py --clean")],
+#                               shell=False, stdout=f)
+#             time.sleep(5)
+#
+#     cluster = dispy.SharedJobCluster(_algorithm_run, scheduler_node=nodes[0], reentrant=True, port=0)
+#
+#     time.sleep(5)
+#
+#     # build job list and start computations
+#     jobs = []
+#     for a in algorithms:
+#         job = cluster.submit(a)
+#         job.id = a
+#         jobs.append(job)
+#
+#     # wait until cluster finished the computations
+#     cluster.wait()
```

## pygpc/GPC.py

```diff
@@ -1,1111 +1,1116 @@
-import numpy as np
-import fastmat as fm
-import scipy.stats
-import copy
-import h5py
-import time
-import random
-import sys
-from sklearn import linear_model
-from scipy.signal import savgol_filter
-from .misc import get_cartesian_product
-from .misc import display_fancy_bar
-from .misc import nrmsd
-from .misc import mat2ten
-from .misc import ten2mat
-from .pygpc_extensions import create_gpc_matrix_cpu
-from .pygpc_extensions import create_gpc_matrix_omp
-from .ValidationSet import *
-from .Computation import *
-from .Grid import *
-
-
-try:
-    from .pygpc_extensions_cuda import create_gpc_matrix_cuda
-except ImportError:
-    pass
-
-
-class GPC(object):
-    """
-    General gPC base class
-
-    Parameters
-    ----------
-    problem: Problem class instance
-        GPC Problem under investigation
-    options : dict
-        Options of gPC algorithm
-    validation: ValidationSet object (optional)
-        Object containing a set of validation points and corresponding solutions. Can be used
-        to validate gpc approximation setting options["error_type"]="nrmsd".
-        - grid: Grid object containing the validation points (grid.coords, grid.coords_norm)
-        - results: ndarray [n_grid x n_out] results
-
-    Attributes
-    ----------
-    problem: Problem class instance
-        GPC Problem under investigation
-    basis: Basis class instance
-        Basis of the gPC including BasisFunctions
-    grid: Grid class instance
-        Grid of the derived gPC approximation
-    validation: ValidationSet object (optional)
-        Object containing a set of validation points and corresponding solutions. Can be used
-        to validate gpc approximation setting options["error_type"]="nrmsd".
-        - grid: Grid object containing the validation points (grid.coords, grid.coords_norm)
-        - results: ndarray [n_grid x n_out] results
-    gpc_matrix: [N_samples x N_poly] ndarray of float
-        Generalized polynomial chaos matrix
-    gpc_matrix_gradient: [N_samples * dim x N_poly] ndarray of float
-        Derivative of generalized polynomial chaos matrix
-    matrix_inv: [N_poly (+ N_gradient) x N_samples] ndarray of float
-        Pseudo inverse of the generalized polynomial chaos matrix (with or without gradient)
-    p_matrix: [dim_red x dim] ndarray of float
-        Projection matrix to reduce number of efficient dimensions (\\eta = p_matrix * \\xi)
-    p_matrix_norm: [dim_red] ndarray of float
-        Maximal possible length of new axis in \\eta space. Since the projected variables are modelled in
-        the normalized space between [-1, 1], the transformed coordinates need to be scaled.
-    nan_elm: ndarray of int
-        Indices of NaN elements of model output
-    gpc_matrix_coords_id: list of UUID4()
-        UUID4() IDs of grid points the gPC matrix derived with
-    gpc_matrix_b_id: list of UUID4()
-        UUID4() IDs of basis functions the gPC matrix derived with
-    n_basis: int or list of int
-        Number of basis functions (for iterative solvers, this is a list of its history)
-    n_grid: int or list of int
-        Number of grid points (for iterative solvers, this is a list of its history)
-    solver: str
-        Default solver to determine the gPC coefficients (can be chosen during GPC.solve)
-        - 'Moore-Penrose' ... Pseudoinverse of gPC matrix (SGPC.Reg, EGPC)
-        - 'OMP' ... Orthogonal Matching Pursuit, sparse recovery approach (SGPC.Reg, EGPC)
-        - 'LarsLasso' ... {"alpha": float 0...1} Regularization parameter
-        - 'NumInt' ... Numerical integration, spectral projection (SGPC.Quad)
-    verbose: bool
-        Boolean value to determine if to print out the progress into the standard output
-    fn_results : string, optional, default=None
-        If provided, model evaluations are saved in fn_results.hdf5 file and gpc object in fn_results.pkl file
-    relative_error_loocv: list of float
-        Relative error of the leave-one-out-cross-validation
-    relative_error_nrmsd: list of float
-        Normalized root mean square deviation between model and gpc approximation
-    options : dict
-        Options of gPC algorithm
-    """
-
-    def __init__(self, problem, options, validation=None):
-        """
-        Constructor; Initializes GPC class
-        """
-        # objects
-        self.problem = problem
-        self.problem_original = None
-        self.basis = None
-        self.grid = None
-        self.validation = validation
-
-        # arrays
-        self.gpc_matrix = None
-        self.gpc_matrix_gradient = None
-        self.matrix_inv = None
-        self.p_matrix = None
-        self.p_matrix_norm = None
-        self.nan_elm = []
-        self.gpc_matrix_coords_id = None
-        self.gpc_matrix_b_id = None
-        self.gpc_matrix_gradient_coords_id = None
-        self.gpc_matrix_gradient_b_id = None
-        self.n_basis = []
-        self.n_grid = []
-        self.relative_error_nrmsd = []
-        self.relative_error_loocv = []
-        self.error = []
-        self.n_out = []
-        self.gradient_idx = None
-
-        # options
-        if options is not None:
-            if "gradient_enhanced" not in options.keys():
-                options["gradient_enhanced"] = False
-
-            if "fn_results" not in options.keys():
-                options["fn_results"] = None
-
-            if "matlab_model" not in options.keys():
-                options["matlab_model"] = False
-
-            if "backend" not in options.keys():
-                options["backend"] = "omp"
-
-            self.gradient = options["gradient_enhanced"]
-            self.fn_results = options["fn_results"]
-            self.matlab_model = options["matlab_model"]
-            self.backend = options["backend"]
-
-        else:
-            self.gradient = None
-            self.fn_results = None
-            self.matlab_model = False
-            self.backend = "omp"
-
-        self.solver = None
-        self.settings = None
-        self.verbose = True
-
-        self.options = options
-
-    def init_gpc_matrix(self, gradient_idx=None):
-        """
-        Sets self.gpc_matrix and self.gpc_matrix_gradient with given self.basis and self.grid
-
-        Parameters
-        ----------
-        gradient_idx : ndarray of int [gradient_results.shape[0]]
-            Indices of grid points where the gradient in gradient_results is provided
-        """
-
-        if self.gradient_idx is None or gradient_idx is not None:
-            self.gradient_idx = gradient_idx
-
-        self.gpc_matrix = self.create_gpc_matrix(b=self.basis.b,
-                                                 x=self.grid.coords_norm,
-                                                 gradient=False)
-        self.n_grid.append(self.gpc_matrix.shape[0])
-        self.n_basis.append(self.gpc_matrix.shape[1])
-        self.gpc_matrix_coords_id = copy.deepcopy(self.grid.coords_id)
-        self.gpc_matrix_b_id = copy.deepcopy(self.basis.b_id)
-
-        if self.gradient and self.gradient_idx is not None:
-            self.gpc_matrix_gradient = self.create_gpc_matrix(b=self.basis.b,
-                                                              x=self.grid.coords_norm,
-                                                              gradient=True)
-            self.gpc_matrix_gradient = ten2mat(self.gpc_matrix_gradient)
-            self.gpc_matrix_gradient_coords_id = copy.deepcopy(self.grid.coords_id)
-            self.gpc_matrix_gradient_b_id = copy.deepcopy(self.basis.b_id)
-
-    def create_gpc_matrix(self, b, x, gradient=False, gradient_idx=None, weighted=False, verbose=False):
-        """
-        Construct the gPC matrix or its derivative.
-
-        Parameters
-        ----------
-        b : list of BasisFunction object instances [n_basis][n_dim]
-            Parameter wise basis function objects used in gPC (Basis.b)
-            Multiplying all elements in a row at location xi = (x1, x2, ..., x_dim) yields the global basis function.
-        x : ndarray of float [n_x x n_dim]
-            Coordinates of x = (x1, x2, ..., x_dim) where the rows of the gPC matrix are evaluated (normalized [-1, 1])
-        gradient : bool, optional, default: False
-            Determine gradient gPC matrix.
-        gradient_idx : ndarray of int [gradient_results.shape[0]]
-            Indices of grid points where the gradient in gradient_results is provided
-        weighted : bool, optional, default: False
-            Weight gPC matrix with (row 2-norm)^-1
-        verbose : bool, optional, default: False
-            boolean value to determine if to print out the progress into the standard output
-
-        Returns
-        -------
-        gpc_matrix: ndarray of float [n_x x n_basis (x dim)]
-            GPC matrix where the columns correspond to the basis functions and the rows the to the sample coordinates.
-            If gradient_idx!=None, the gradient is returned at the specified sample coordinates point by point.
-        """
-        # overwrite self.gradient_idx if it is provided
-        if gradient_idx is not None:
-            self.gradient_idx = gradient_idx
-
-        iprint('Constructing gPC matrix...', verbose=verbose, tab=0)
-
-        # Python backend
-        if self.backend == "python":
-            if not gradient:
-                gpc_matrix = np.ones([x.shape[0], len(b)])
-                for i_basis in range(len(b)):
-                    for i_dim in range(self.problem.dim):
-                        gpc_matrix[:, i_basis] *= b[i_basis][i_dim](x[:, i_dim])
-            else:
-                gpc_matrix = np.ones([len(self.gradient_idx), len(b), self.problem.dim])
-                for i_dim_gradient in range(self.problem.dim):
-                    for i_basis in range(len(b)):
-                        for i_dim in range(self.problem.dim):
-                            if i_dim == i_dim_gradient:
-                                derivative = True
-                            else:
-                                derivative = False
-                            gpc_matrix[:, i_basis, i_dim_gradient] *= b[i_basis][i_dim](x[self.gradient_idx, i_dim],
-                                                                                        derivative=derivative)
-
-        # CPU backend (CPU single core)
-        elif self.backend == "cpu":
-            if not gradient:
-                # the third dimension is important and should not be removed
-                # otherwise the code could produce undefined behaviour
-                gpc_matrix = np.empty([x.shape[0], len(b), 1])
-                create_gpc_matrix_cpu(x, self.basis.b_array, gpc_matrix)
-                gpc_matrix = np.squeeze(gpc_matrix)
-            else:
-                gpc_matrix = np.empty([len(self.gradient_idx), len(b), self.problem.dim])
-                create_gpc_matrix_cpu(x[self.gradient_idx, :], self.basis.b_array_grad, gpc_matrix)
-
-        # OpenMP backend (CPU multi core)
-        elif self.backend == "omp":
-            if not gradient:
-                # the third dimension is important and should not be removed
-                # otherwise the code could produce undefined behaviour
-                gpc_matrix = np.empty([x.shape[0], len(b), 1])
-                create_gpc_matrix_omp(x, self.basis.b_array, gpc_matrix)
-                gpc_matrix = np.squeeze(gpc_matrix)
-            else:
-                gpc_matrix = np.empty([len(self.gradient_idx), len(b), self.problem.dim])
-                create_gpc_matrix_omp(x[self.gradient_idx, :], self.basis.b_array_grad, gpc_matrix)
-
-        # CUDA backend (GPU multi core)
-        elif self.backend == "cuda":
-            try:
-                from .pygpc_extensions_cuda import create_gpc_matrix_cuda
-            except (ImportError):
-                raise NotImplementedError("The CUDA-extension is not installed. Use the build script to install.")
-            else:
-                if not gradient:
-                    # the third dimension is important and should not be removed
-                    # otherwise the code could produce undefined behaviour
-                    gpc_matrix = np.empty([x.shape[0], len(b), 1])
-                    create_gpc_matrix_cuda(x, self.basis.b_array, gpc_matrix)
-                    gpc_matrix = np.squeeze(gpc_matrix)
-                else:
-                    gpc_matrix = np.empty([len(self.gradient_idx), len(b), self.problem.dim])
-                    create_gpc_matrix_cuda(x[self.gradient_idx, :], self.basis.b_array_grad, gpc_matrix)
-
-        else:
-            raise NotImplementedError
-
-        if gpc_matrix.ndim == 1 and x.shape[0] == 1:
-            gpc_matrix = gpc_matrix[np.newaxis, :]
-        elif gpc_matrix.ndim == 1 and self.basis.n_basis == 1:
-            gpc_matrix = gpc_matrix[:, np.newaxis]
-
-        if weighted:
-            w = np.diag(1/np.linalg.norm(gpc_matrix, axis=1))
-            gpc_matrix = np.matmul(w, gpc_matrix)
-
-        return gpc_matrix
-
-    def get_loocv(self, coeffs, results, gradient_results=None, error_norm="relative"):
-        """
-        Perform leave-one-out cross validation of gPC approximation and add error value to self.relative_error_loocv.
-        The loocv error is calculated analytically after eq. (35) in [1] but omitting the "1 - " term, i.e. it
-        corresponds to 1 - Q^2.
-
-        relative_error_loocv = GPC.loocv(sim_results, coeffs)
-
-        .. math::
-           \\epsilon_{LOOCV} = \\frac{\\frac{1}{N}\sum_{i=1}^N \\left( \\frac{y(\\xi_i) - \hat{y}(\\xi_i)}{1-h_i}
-           \\right)^2}{\\frac{1}{N-1}\sum_{i=1}^N \\left( y(\\xi_i) - \\bar{y} \\right)^2}
-
-        with
-
-        .. math::
-           \\mathbf{h} = \mathrm{diag}(\\mathbf{\\Psi} (\\mathbf{\\Psi}^T \\mathbf{\\Psi})^{-1} \\mathbf{\\Psi}^T)
-
-        Parameters
-        ----------
-        coeffs: ndarray of float [n_basis x n_out]
-            GPC coefficients
-        results: ndarray of float [n_grid x n_out]
-            Results from n_grid simulations with n_out output quantities
-        error_norm: str, optional, default="relative"
-            Decide if error is determined "relative" or "absolute"
-        gradient_results : ndarray of float [n_grid x n_out x dim], optional, default: None
-            Gradient of results in original parameter space (tensor)
-
-        Returns
-        -------
-        relative_error_loocv: float
-            Relative mean error of leave one out cross validation
-
-        Notes
-        -----
-        .. [1] Blatman, G., & Sudret, B. (2010). An adaptive algorithm to build up sparse polynomial chaos expansions
-           for stochastic finite element analysis. Probabilistic Engineering Mechanics, 25(2), 183-197.
-        """
-        # if self.options["gradient_enhanced"]:
-        #     matrix = np.vstack((self.gpc_matrix, self.gpc_matrix_gradient))
-        #
-        #     # transform gradient of results in case of projection
-        #     if self.p_matrix is not None:
-        #         gradient_results = np.matmul(gradient_results,
-        #                                   self.p_matrix.transpose() * self.p_matrix_norm[np.newaxis, :])
-        #
-        #     results_complete = np.vstack((results, ten2mat(gradient_results)))
-        # else:
-        #     matrix = self.gpc_matrix
-        #     results_complete = results
-
-        # matrix = self.gpc_matrix
-        # results_complete = results
-
-        # Analytical error estimation in case of overdetermined systems
-        # if matrix.shape[0] > 2*matrix.shape[1]:
-            # determine Psi (Psi^T Psi)^-1 Psi^T
-            # h = np.matmul(np.matmul(matrix, np.linalg.inv(np.matmul(matrix.transpose(), matrix))), matrix.transpose())
-            #
-            # # determine loocv error
-            # err = np.mean(((results_complete - np.matmul(matrix, coeffs)) /
-            #                (1 - np.diag(h))[:, np.newaxis]) ** 2, axis=0)
-            #
-            # if error_norm == "relative":
-            #     norm = np.var(results_complete, axis=0, ddof=1)
-            # else:
-            #     norm = 1.
-            #
-            # # normalize
-            # relative_error_loocv = np.mean(err / norm)
-
-        # else:
-        # perform manual loocv without gradient
-        matrix = self.gpc_matrix
-        results_complete = results
-
-        n_loocv = 25
-
-        # define number of performed cross validations (max 100)
-        n_loocv_points = np.min((results_complete.shape[0], n_loocv))
-
-        # make list of indices, which are randomly sampled
-        loocv_point_idx = random.sample(list(range(results_complete.shape[0])), n_loocv_points)
-
-        start = time.time()
-        relative_error = np.zeros(n_loocv_points)
-        for i in range(n_loocv_points):
-            # get mask of eliminated row
-            mask = np.arange(results_complete.shape[0]) != loocv_point_idx[i]
-
-            # determine gpc coefficients (this takes a lot of time for large problems)
-            coeffs_loo = self.solve(results=results_complete[mask, :],
-                                    solver=self.options["solver"],
-                                    matrix=matrix[mask, :],
-                                    settings=self.options["settings"],
-                                    verbose=False)
-
-            sim_results_temp = results_complete[loocv_point_idx[i], :]
-
-            if error_norm == "relative":
-                norm = scipy.linalg.norm(sim_results_temp)
-            else:
-                norm = 1.
-
-            relative_error[i] = scipy.linalg.norm(sim_results_temp - np.matmul(matrix[loocv_point_idx[i], :],
-                                                                            coeffs_loo))\
-                                / norm
-            display_fancy_bar("LOOCV", int(i + 1), int(n_loocv_points))
-
-        # store result in relative_error_loocv
-        relative_error_loocv = np.mean(relative_error)
-        iprint("LOOCV computation time: {} sec".format(time.time() - start), tab=0, verbose=True)
-
-        return relative_error_loocv
-
-    def validate(self, coeffs, results=None, gradient_results=None, qoi_idx=None):
-        """
-        Validate gPC approximation using the ValidationSet object contained in the Problem object.
-        Determines the normalized root mean square deviation between the gpc approximation and the
-        original model. Skips this step if no validation set is present
-
-        Parameters
-        ----------
-        coeffs: ndarray of float [n_coeffs x n_out]
-            GPC coefficients
-        results: ndarray of float [n_grid x n_out]
-            Results from n_grid simulations with n_out output quantities
-        gradient_results : ndarray of float [n_grid x n_out x dim], optional, default: None
-            Gradient of results in original parameter space (tensor)
-        qoi_idx : int, optional, default: None
-            Index of QOI to validate (if None, all QOI are considered)
-
-        Returns
-        -------
-        error: float
-            Estimated difference between gPC approximation and original model
-        """
-        if qoi_idx is None:
-            qoi_idx = np.arange(0, results.shape[1])
-
-        # Determine QOIs with NaN in results and exclude them from validation
-        non_nan_mask = np.where(np.all(~np.isnan(results), axis=0))[0]
-        n_nan = results.shape[1] - non_nan_mask.size
-
-        if n_nan > 0:
-            iprint("In {}/{} output quantities NaN's were found.".format(n_nan, results.shape[1]),
-                   tab=0, verbose=self.options["verbose"])
-
-        results = results[:, non_nan_mask]
-
-        if gradient_results is not None:
-            gradient_results = gradient_results[:, non_nan_mask, :]
-
-        # always determine nrmsd if a validation set is present
-        if isinstance(self.validation, ValidationSet):
-
-            gpc_results = self.get_approximation(coeffs, self.validation.grid.coords_norm, output_idx=None)
-
-            if gpc_results.ndim == 1:
-                gpc_results = gpc_results[:, np.newaxis]
-
-            if self.validation.results[:, qoi_idx].ndim == 1:
-                validation_results = self.validation.results[:, qoi_idx][:, np.newaxis]
-            else:
-                validation_results = self.validation.results[:, qoi_idx]
-
-            self.relative_error_nrmsd.append(float(np.mean(nrmsd(gpc_results,
-                                                                 validation_results,
-                                                                 error_norm=self.options["error_norm"],
-                                                                 x_axis=False))))
-
-        if self.options["error_type"] == "nrmsd":
-            self.error.append(self.relative_error_nrmsd[-1])
-
-        elif self.options["error_type"] == "loocv":
-            self.relative_error_loocv.append(self.get_loocv(coeffs=coeffs,
-                                             results=results,
-                                             gradient_results=gradient_results,
-                                             error_norm=self.options["error_norm"]))
-            self.error.append(self.relative_error_loocv[-1])
-
-        elif self.options["error_type"] is None:
-            self.error.append(None)
-
-        return self.error[-1]
-
-    def get_pdf(self, coeffs, n_samples, output_idx=None, filter=True, return_samples=False):
-        """ Determine the estimated pdfs of the output quantities
-
-        pdf_x, pdf_y = SGPC.get_pdf(coeffs, n_samples, output_idx=None)
-
-        Parameters
-        ----------
-        coeffs: ndarray of float [n_coeffs x n_out]
-            GPC coefficients
-        n_samples: int
-            Number of samples used to estimate output pdfs
-        output_idx: ndarray, optional, default=None [1 x n_out]
-            Index of output quantities to consider (if output_idx=None, all output quantities are considered)
-        filter : bool, optional, default: True
-            Use savgol_filter to smooth probability density
-        return_samples : bool, optional, default: False
-            Additionally returns in and output samples with which the pdfs were computed
-
-        Returns
-        -------
-        pdf_x: ndarray of float [100 x n_out]
-            x-coordinates of output pdfs of output quantities
-        pdf_y: ndarray of float [100 x n_out]
-            y-coordinates of output pdfs (probability density of output quantity)
-        samples_in : ndarray of float [n_samples x dim] (optional)
-            Input samples (if return_samples=True)
-        samples_out : ndarray of float [n_samples x n_out] (optional)
-            Output samples (if return_samples=True)
-        """
-
-        # handle (N,) arrays
-        if len(coeffs.shape) == 1:
-            coeffs = coeffs[:, np.newaxis]
-
-        # if output index array is not provided, determine pdfs of all outputs
-        if output_idx is None:
-            output_idx = np.arange(0, coeffs.shape[1])
-            output_idx = output_idx[np.newaxis, :]
-
-        n_out = len(output_idx)
-
-        # sample gPC expansion
-        samples_in, samples_out = self.get_samples(n_samples=n_samples, coeffs=coeffs, output_idx=output_idx)
-
-        # determine kernel density estimates using Gaussian kernel
-        pdf_x = np.zeros([100, n_out])
-        pdf_y = np.zeros([100, n_out])
-
-        for i_out in range(n_out):
-
-            pdf_y[:, i_out], tmp = np.histogram(samples_out[:, i_out], bins=100, density=True)
-            pdf_x[:, i_out] = (tmp[1:] + tmp[0:-1]) / 2.
-
-            if filter:
-                pdf_y[:, i_out] = savgol_filter(pdf_y[:, i_out], 51, 5)
-
-            # kde = scipy.stats.gaussian_kde(samples_out[:, i_out], bw_method=0.1 / samples_out[:, i_out].std(ddof=1))
-            # pdf_y[:, i_out] = kde(pdf_x[:, i_out])
-            # pdf_x[:, i_out] = np.linspace(samples_out[:, i_out].min(), samples_out[:, i_out].max(), 100)
-
-        if return_samples:
-            return pdf_x, pdf_y, samples_in, samples_out
-        else:
-            return pdf_x, pdf_y
-
-    def get_samples(self, coeffs, n_samples, output_idx=None):
-        """
-        Randomly sample gPC expansion.
-
-        x, pce = SGPC.get_pdf_mc(n_samples, coeffs, output_idx=None)
-
-        Parameters
-        ----------
-        coeffs: ndarray of float [n_basis x n_out]
-            GPC coefficients
-        n_samples: int
-            Number of random samples drawn from the respective input pdfs.
-        output_idx: ndarray of int [1 x n_out] optional, default=None
-            Index of output quantities to consider.
-
-        Returns
-        -------
-        x: ndarray of float [n_samples x dim]
-            Generated samples in normalized coordinates [-1, 1].
-        pce: ndarray of float [n_samples x n_out]
-            GPC approximation at points x.
-        """
-
-        # seed the random numbers generator
-        np.random.seed()
-
-        if self.p_matrix is not None:
-            problem = self.problem_original
-        else:
-            problem = self.problem
-
-        # generate temporary grid with random samples for each random input variable [n_samples x dim]
-        grid = Random(parameters_random=problem.parameters_random,
-                      n_grid=n_samples)
-
-        # if output index list is not provided, sample all gpc outputs
-        if output_idx is None:
-            n_out = 1 if coeffs.ndim == 1 else coeffs.shape[1]
-            output_idx = np.arange(n_out)
-            # output_idx = output_idx[np.newaxis, :]
-
-        pce = self.get_approximation(coeffs=coeffs, x=grid.coords_norm, output_idx=output_idx)
-
-        return grid.coords_norm, pce
-
-    def get_approximation(self, coeffs, x, output_idx=None):
-        """
-        Calculates the gPC approximation in points with output_idx and normalized parameters xi (interval: [-1, 1]).
-
-        pce = GPC.get_approximation(coeffs, x, output_idx=None)
-
-        Parameters
-        ----------
-        coeffs: ndarray of float [n_basis x n_out]
-            GPC coefficients for each output variable
-        x: ndarray of float [n_x x n_dim]
-            Coordinates of x = (x1, x2, ..., x_dim) where the rows of the gPC matrix are evaluated (normalized [-1, 1]).
-            The coordinates will be transformed in case of projected gPC.
-        output_idx: ndarray of int, optional, default=None [n_out]
-            Indices of output quantities to consider (Default: all).
-
-        Returns
-        -------
-        pce: ndarray of float [n_x x n_out]
-            GPC approximation at normalized coordinates x.
-        """
-
-        if len(x.shape) == 1:
-            x = x[:, np.newaxis]
-
-        # crop coordinates to gPC boundaries (values outside do not yield meaningful values)
-        for i_dim, key in enumerate(list(self.problem.parameters_random.keys())):
-            xmin = self.problem.parameters_random[key].pdf_limits_norm[0]
-            xmax = self.problem.parameters_random[key].pdf_limits_norm[1]
-            x[x[:, i_dim] < xmin, i_dim] = xmin
-            x[x[:, i_dim] > xmax, i_dim] = xmax
-
-        if output_idx is not None:
-            # convert to 1d array
-            output_idx = np.asarray(output_idx).flatten().astype(int)
-
-            # crop coeffs array if output index is specified
-            coeffs = coeffs[:, output_idx]
-
-        if coeffs.ndim == 1:
-            coeffs = coeffs[:, np.newaxis]
-
-        # transform variables from xi to eta space if gpc model is reduced
-        if self.p_matrix is not None:
-            x = np.matmul(x, self.p_matrix.transpose() / self.p_matrix_norm[np.newaxis, :])
-
-        if self.backend == 'python' or self.backend == 'cpu' or self.backend == 'omp':
-            # determine gPC matrix at coordinates x
-            gpc_matrix = self.create_gpc_matrix(self.basis.b, x, gradient=False)
-
-            # multiply with gPC coeffs
-            pce = np.matmul(gpc_matrix, coeffs)
-
-        elif self.backend == "cuda":
-            try:
-                from .pygpc_extensions_cuda import get_approximation_cuda
-            except ImportError:
-                raise NotImplementedError("The CUDA-extension is not installed. Use the build script to install.")
-            else:
-                pce = np.empty([x.shape[0], coeffs.shape[1]])
-                get_approximation_cuda(x, self.basis.b_array, coeffs, pce)
-        else:
-            raise NotImplementedError
-
-        return pce
-
-    def replace_gpc_matrix_samples(self, idx, seed=None):
-        """
-        Replace distinct sample points from the gPC matrix with new ones.
-
-        GPC.replace_gpc_matrix_samples(idx, seed=None)
-
-        Parameters
-        ----------
-        idx: ndarray of int [n_samples]
-            Array of grid indices of grid.coords[idx, :] which are going to be replaced
-            (rows of gPC matrix will be replaced by new ones)
-        seed: float, optional, default=None
-            Random seeding point
-        """
-
-        # Generate new grid points
-        new_grid_points = Random(parameters_random=self.problem.parameters_random,
-                                 n_grid=idx.size,
-                                 seed=seed)
-
-        # replace old grid points
-        self.grid.coords[idx, :] = new_grid_points.coords
-        self.grid.coords_norm[idx, :] = new_grid_points.coords_norm
-
-        # replace old IDs of grid points with new ones
-        for i in idx:
-            self.grid.coords_id[i] = uuid.uuid4()
-            self.gpc_matrix_coords_id[i] = copy.deepcopy(self.grid.coords_id[i])
-
-        # determine new rows of gpc matrix and overwrite rows of gpc matrix
-        self.gpc_matrix[idx, :] = self.create_gpc_matrix(b=self.basis.b,
-                                                         x=new_grid_points.coords_norm,
-                                                         gradient=False)
-
-    def update_gpc_matrix(self):
-        """
-        Update gPC matrix and gPC matrix gradient according to existing self.grid and self.basis.
-
-        Call this method when self.gpc_matrix does not fit to self.grid and self.basis objects anymore
-        The old gPC matrix with their self.gpc_matrix_b_id and self.gpc_matrix_coords_id is compared
-        to self.basis.b_id and self.grid.coords_id. New rows and columns are computed if differences are found.
-        """
-        self._update_gpc_matrix(gradient=False)
-
-        if self.gradient:
-            self._update_gpc_matrix(gradient=True)
-
-    def _update_gpc_matrix(self, gradient=False):
-        """
-        Update gPC matrix or gPC gradient matrix
-        """
-        if self.backend == "python":
-            # initialize updated matrix and variables
-            if gradient:
-                # reshape gpc gradient matrix from 2D to 3D representation [n_grid x n_basis x n_dim]
-                matrix = mat2ten(mat=self.gpc_matrix_gradient, incr=self.problem.dim)
-                matrix_updated = np.zeros((len(self.gradient_idx), len(self.basis.b_id), self.problem.dim))
-                coords_id = self.gpc_matrix_gradient_coords_id[self.gradient_idx]
-                coords_id_ref = self.grid.coords_gradient_id[self.gradient_idx]
-                b_id = self.gpc_matrix_gradient_b_id
-                b_id_ref = self.basis.b_id
-                coords_norm = self.grid.coords_norm[self.gradient_idx]
-                ge_str = "(gradient)"
-
-            else:
-                matrix = self.gpc_matrix
-                matrix_updated = np.zeros((len(self.grid.coords_id), len(self.basis.b_id)))
-                coords_id = self.gpc_matrix_coords_id
-                coords_id_ref = self.grid.coords_id
-                b_id = self.gpc_matrix_b_id
-                b_id_ref = self.basis.b_id
-                coords_norm = self.grid.coords_norm
-                ge_str = ""
-
-            # # determine indices of new basis functions and grid_points
-            # idx_coords_new = [i for i, _id in enumerate(self.grid.coords_id) if _id not in self.gpc_matrix_coords_id]
-            # idx_basis_new = [i for i, _id in enumerate(self.basis.b_id) if _id not in self.gpc_matrix_b_id]
-
-            # determine indices of old grid points in updated gpc matrix
-            idx_coords_old = np.empty(len(coords_id)) * np.nan
-            for i, coords_id_old in enumerate(coords_id):
-                for j, coords_id_new in enumerate(coords_id_ref):
-                    if coords_id_old == coords_id_new:
-                        idx_coords_old[i] = j
-                        break
-
-            # determine indices of old basis functions in updated gpc matrix
-            idx_b_old = np.empty(len(b_id))*np.nan
-            for i, b_id_old in enumerate(b_id):
-                for j, b_id_new in enumerate(b_id_ref):
-                    if b_id_old == b_id_new:
-                        idx_b_old[i] = j
-                        break
-
-            # filter out non-existent rows and columns
-            matrix = matrix[~np.isnan(idx_coords_old), :, ]
-            matrix = matrix[:, ~np.isnan(idx_b_old), ]
-
-            idx_coords_old = idx_coords_old[~np.isnan(idx_coords_old)].astype(int)
-            idx_b_old = idx_b_old[~np.isnan(idx_b_old)].astype(int)
-
-            # indices of new coords and basis in updated gpc matrix (values have to be computed there)
-            idx_coords_new = np.array(list(set(np.arange(len(coords_id_ref))) - set(idx_coords_old))).astype(int)
-            idx_b_new = np.array(list(set(np.arange(len(b_id_ref))) - set(idx_b_old))).astype(int)
-
-            # write old results at correct location in updated gpc matrix
-            idx = get_cartesian_product([idx_coords_old, idx_b_old]).astype(int)
-            idx_row = np.reshape(idx[:, 0], matrix.shape[:2]).astype(int)
-            idx_col = np.reshape(idx[:, 1], matrix.shape[:2]).astype(int)
-
-            matrix_updated[idx_row, idx_col, ] = matrix
-
-            # determine new columns (new basis functions) with old grid
-            idx = get_cartesian_product([idx_coords_old, idx_b_new]).astype(int)
-            if idx.any():
-                iprint('Adding {} columns to gPC matrix {}...'.format(idx_b_new.size, ge_str), tab=0, verbose=True)
-
-                idx_row = np.reshape(idx[:, 0], (idx_coords_old.size, idx_b_new.size)).astype(int)
-                idx_col = np.reshape(idx[:, 1], (idx_coords_old.size, idx_b_new.size)).astype(int)
-
-                matrix_updated[idx_row, idx_col, ] = self.create_gpc_matrix(b=[self.basis.b[i] for i in idx_b_new],
-                                                                            x=coords_norm[idx_coords_old, :],
-                                                                            gradient=gradient,
-                                                                            verbose=False)
-
-            # determine new rows (new grid points) with all basis functions
-            idx = get_cartesian_product([idx_coords_new, np.arange(len(self.basis.b))]).astype(int)
-            if idx.any():
-                iprint('Adding {} rows to gPC matrix {}...'.format(idx_coords_new.size, ge_str), tab=0, verbose=True)
-
-                idx_row = np.reshape(idx[:, 0], (idx_coords_new.size, len(self.basis.b))).astype(int)
-                idx_col = np.reshape(idx[:, 1], (idx_coords_new.size, len(self.basis.b))).astype(int)
-
-                matrix_updated[idx_row, idx_col, ] = self.create_gpc_matrix(b=self.basis.b,
-                                                                            x=coords_norm[idx_coords_new, :],
-                                                                            gradient=gradient,
-                                                                            verbose=False)
-
-            # overwrite old attributes and append new sizes
-            if gradient:
-                # reshape from 3D to 2D
-                self.gpc_matrix_gradient = ten2mat(matrix_updated)
-                self.gpc_matrix_gradient_coords_id = copy.deepcopy(self.grid.coords_id)
-                self.gpc_matrix_gradient_b_id = copy.deepcopy(self.basis.b_id)
-            else:
-                self.gpc_matrix = matrix_updated
-                self.gpc_matrix_coords_id = copy.deepcopy(self.grid.coords_id)
-                self.gpc_matrix_b_id = copy.deepcopy(self.basis.b_id)
-                self.n_grid.append(self.gpc_matrix.shape[0])
-                self.n_basis.append(self.gpc_matrix.shape[1])
-
-        else:
-            self.init_gpc_matrix()
-
-    def save_gpc_matrix_hdf5(self, hdf5_path_gpc_matrix=None, hdf5_path_gpc_matrix_gradient=None):
-        """
-        Save gPC matrix and gPC gradient matrix in .hdf5 file <"fn_results" + ".hdf5"> under the key "gpc_matrix"
-        and "gpc_matrix_gradient". If matrices are already present, check for equality and save only appended
-        rows and columns.
-
-        Parameters
-        ----------
-        hdf5_path_gpc_matrix : str
-            Path in .hdf5 file, where the gPC matrix is saved in
-        hdf5_path_gpc_matrix_gradient : str
-            Path in .hdf5 file, where the gPC gradient matrix is saved in
-        """
-
-        if hdf5_path_gpc_matrix is None:
-            hdf5_path_gpc_matrix = "gpc_matrix"
-
-        if hdf5_path_gpc_matrix_gradient is None:
-            hdf5_path_gpc_matrix_gradient = "gpc_matrix_gradient"
-
-        with h5py.File(self.fn_results + ".hdf5", "a") as f:
-            try:
-                # write gpc matrix
-                gpc_matrix_hdf5 = f[hdf5_path_gpc_matrix][:]
-                n_rows_hdf5 = gpc_matrix_hdf5.shape[0]
-                n_cols_hdf5 = gpc_matrix_hdf5.shape[1]
-
-                n_rows_current = self.gpc_matrix.shape[0]
-                n_cols_current = self.gpc_matrix.shape[1]
-
-                # save only new rows and cols if current matrix > saved matrix
-                if n_rows_current >= n_rows_hdf5 and n_cols_current >= n_cols_hdf5 and \
-                        (self.gpc_matrix[0:n_rows_hdf5, 0:n_cols_hdf5] == gpc_matrix_hdf5).all():
-                    # resize dataset and save new columns and rows
-                    f[hdf5_path_gpc_matrix].resize(self.gpc_matrix.shape[1], axis=1)
-                    f[hdf5_path_gpc_matrix][:, n_cols_hdf5:] = self.gpc_matrix[0:n_rows_hdf5, n_cols_hdf5:]
-
-                    f[hdf5_path_gpc_matrix].resize(self.gpc_matrix.shape[0], axis=0)
-                    f[hdf5_path_gpc_matrix][n_rows_hdf5:, :] = self.gpc_matrix[n_rows_hdf5:, :]
-
-                else:
-                    del f[hdf5_path_gpc_matrix]
-                    f.create_dataset(hdf5_path_gpc_matrix, (self.gpc_matrix.shape[0],
-                                                            self.gpc_matrix.shape[1]),
-                                     maxshape=(None, None),
-                                     dtype="float64",
-                                     data=self.gpc_matrix)
-
-                # write gpc gradient matrix if available
-                if self.gpc_matrix_gradient is not None:
-                    gpc_matrix_gradient_hdf5 = f[hdf5_path_gpc_matrix_gradient][:]
-                    n_rows_hdf5 = gpc_matrix_gradient_hdf5.shape[0]
-                    n_cols_hdf5 = gpc_matrix_gradient_hdf5.shape[1]
-
-                    n_rows_current = self.gpc_matrix_gradient.shape[0]
-                    n_cols_current = self.gpc_matrix_gradient.shape[1]
-
-                    # save only new rows and cols if current matrix > saved matrix
-                    if n_rows_current >= n_rows_hdf5 and n_cols_current >= n_cols_hdf5 and \
-                            (self.gpc_matrix_gradient[0:n_rows_hdf5, 0:n_cols_hdf5] == gpc_matrix_gradient_hdf5).all():
-                        # resize dataset and save new columns and rows
-                        f[hdf5_path_gpc_matrix_gradient].resize(self.gpc_matrix_gradient.shape[1], axis=1)
-                        f[hdf5_path_gpc_matrix_gradient][:, n_cols_hdf5:] = self.gpc_matrix_gradient[0:n_rows_hdf5,
-                                                                                                     n_cols_hdf5:]
-
-                        f[hdf5_path_gpc_matrix_gradient].resize(self.gpc_matrix_gradient.shape[0], axis=0)
-                        f[hdf5_path_gpc_matrix_gradient][n_rows_hdf5:, :] = self.gpc_matrix_gradient[n_rows_hdf5:, :]
-
-                    else:
-                        del f[hdf5_path_gpc_matrix_gradient]
-                        f.create_dataset(hdf5_path_gpc_matrix_gradient, (self.gpc_matrix_gradient.shape[0],
-                                                                         self.gpc_matrix_gradient.shape[1]),
-                                         maxshape=(None, None),
-                                         dtype="float64",
-                                         data=self.gpc_matrix_gradient)
-
-            except KeyError:
-                # save whole matrix if not existent
-                f.create_dataset(hdf5_path_gpc_matrix, (self.gpc_matrix.shape[0],
-                                                        self.gpc_matrix.shape[1]),
-                                 maxshape=(None, None),
-                                 dtype="float64",
-                                 data=self.gpc_matrix)
-
-                # save whole gradient matrix if not existent and available
-                if self.gpc_matrix_gradient is not None:
-                    f.create_dataset(hdf5_path_gpc_matrix_gradient, (self.gpc_matrix_gradient.shape[0],
-                                                                     self.gpc_matrix_gradient.shape[1]),
-                                     maxshape=(None, None),
-                                     dtype="float64",
-                                     data=self.gpc_matrix_gradient)
-
-    def solve(self, results, gradient_results=None, solver=None, settings=None, matrix=None, verbose=False):
-        """
-        Determines gPC coefficients
-
-        Parameters
-        ----------
-        results : [n_grid x n_out] np.ndarray of float
-            Results from simulations with N_out output quantities
-        gradient_results : ndarray of float [n_gradient x n_out x dim], optional, default: None
-            Gradient of results in original parameter space in specific grid points
-        solver : str
-            Solver to determine the gPC coefficients
-            - 'Moore-Penrose' ... Pseudoinverse of gPC matrix (SGPC.Reg, EGPC)
-            - 'OMP' ... Orthogonal Matching Pursuit, sparse recovery approach (SGPC.Reg, EGPC)
-            - 'LarsLasso' ... Least-Angle Regression using Lasso model (SGPC.Reg, EGPC)
-            - 'NumInt' ... Numerical integration, spectral projection (SGPC.Quad)
-        settings : dict
-            Solver settings
-            - 'Moore-Penrose' ... None
-            - 'OMP' ... {"n_coeffs_sparse": int} Number of gPC coefficients != 0 or "sparsity": float 0...1
-            - 'LarsLasso' ... {"alpha": float 0...1} Regularization parameter
-            - 'NumInt' ... None
-        matrix : ndarray of float, optional, default: self.gpc_matrix or [self.gpc_matrix, self.gpc_matrix_gradient]
-            Matrix to invert. Depending on gradient_enhanced option, this matrix consist of the standard gPC matrix and
-            their derivatives.
-        verbose : bool
-            boolean value to determine if to print out the progress into the standard output
-
-        Returns
-        -------
-        coeffs: ndarray of float [n_coeffs x n_out]
-            gPC coefficients
-        """
-
-        ge_str = ""
-
-        if matrix is None:
-            matrix = self.gpc_matrix
-
-            if self.gradient is False:
-                matrix = self.gpc_matrix
-                ge_str = ""
-            else:
-                if not solver == 'NumInt':
-                    if self.gpc_matrix_gradient is not None:
-                        matrix = np.vstack((self.gpc_matrix, self.gpc_matrix_gradient))
-                    else:
-                        matrix = self.gpc_matrix
-                    ge_str = "(gradient enhanced)"
-                else:
-                    Warning("Gradient enhanced version not applicable in case of numerical integration (quadrature).")
-
-        # use default solver if not specified
-        if solver is None:
-            solver = self.solver
-
-        # use default solver settings if not specified
-        if solver is None:
-            settings = self.settings
-
-        iprint("Determine gPC coefficients using '{}' solver {}...".format(solver, ge_str),
-               tab=0, verbose=verbose)
-
-        # construct results array
-        if not solver == 'NumInt' and gradient_results is not None:
-            # transform gradient of results according to projection
-            if self.p_matrix is not None:
-                gradient_results = np.matmul(gradient_results,
-                                             self.p_matrix.transpose() * self.p_matrix_norm[np.newaxis, :])
-
-            results_complete = np.vstack((results, ten2mat(gradient_results)))
-        else:
-            results_complete = results
-
-        self.coherence_matrix = matrix
-
-        if isinstance(self.grid, CO) or (isinstance(self.grid, L1) and not (["D"] in self.grid.criterion)):
-            w = np.diag(1/np.linalg.norm(matrix, axis=1))
-            matrix = np.matmul(w, matrix)
-            results_complete = np.matmul(w, results_complete)
-
-        #################
-        # Moore-Penrose #
-        #################
-        if solver == 'Moore-Penrose':
-            # determine pseudoinverse of gPC matrix
-            self.matrix_inv = np.linalg.pinv(matrix)
-
-            try:
-                coeffs = np.matmul(self.matrix_inv, results_complete)
-            except ValueError:
-                raise AttributeError("Please check format of parameter sim_results: [n_grid (* dim) x n_out] "
-                                     "np.ndarray.")
-
-        ###############################
-        # Orthogonal Matching Pursuit #
-        ###############################
-        elif solver == 'OMP':
-            # transform gPC matrix to fastmat format
-            matrix_fm = fm.Matrix(matrix)
-
-            if results_complete.ndim == 1:
-                results_complete = results_complete[:, np.newaxis]
-
-            # determine gPC-coefficients of extended basis using OMP
-            if "n_coeffs_sparse" in settings.keys():
-                n_coeffs_sparse = int(settings["n_coeffs_sparse"])
-            elif "sparsity" in settings.keys():
-                n_coeffs_sparse = int(np.ceil(matrix.shape[1]*settings["sparsity"]))
-            else:
-                raise AttributeError("Please specify 'n_coeffs_sparse' or 'sparsity' in solver settings dictionary!")
-
-            coeffs = fm.algs.OMP(matrix_fm, results_complete, n_coeffs_sparse)
-
-        ################################
-        # Least-Angle Regression Lasso #
-        ################################
-        elif solver == 'LarsLasso':
-
-            if results_complete.ndim == 1:
-                results_complete = results_complete[:, np.newaxis]
-
-            # determine gPC-coefficients of extended basis using LarsLasso
-            # from sklearn.preprocessing import normalize
-            # matrix_norm = normalize(matrix, axis=0, return_norm=False)
-            #
-            # reg = linear_model.LassoLars(alpha=settings["alpha"], fit_intercept=False, normalize=False)
-            # reg.fit(matrix_norm, results_complete)
-            # coeffs = reg.coef_
-
-            reg = linear_model.LassoLars(alpha=settings["alpha"], fit_intercept=False, normalize=False)
-            reg.fit(matrix, results_complete)
-            coeffs = reg.coef_
-
-            if coeffs.ndim == 1:
-                coeffs = coeffs[:, np.newaxis]
-            else:
-                coeffs = coeffs.transpose()
-
-        #########################
-        # Numerical Integration #
-        #########################
-        elif solver == 'NumInt':
-            # check if quadrature rule (grid) fits to the probability density distribution (pdf)
-            grid_pdf_fit = True
-            for i_p, p in enumerate(self.problem.parameters_random):
-                if self.problem.parameters_random[p].pdf_type == 'beta':
-                    if not (self.grid.grid_type[i_p] == 'jacobi'):
-                        grid_pdf_fit = False
-                        break
-                elif self.problem.parameters_random[p].pdf_type in ['norm', 'normal']:
-                    if not (self.grid.grid_type[i_p] == 'hermite'):
-                        grid_pdf_fit = False
-                        break
-
-            # if not, calculate joint pdf
-            if not grid_pdf_fit:
-                joint_pdf = np.ones(self.grid.coords_norm.shape)
-
-                for i_p, p in enumerate(self.problem.parameters_random):
-                    joint_pdf[:, i_p] = \
-                        self.problem.parameters_random[p].pdf_norm(x=self.grid.coords_norm[:, i_p])
-
-                joint_pdf = np.array([np.prod(joint_pdf, axis=1)]).transpose()
-
-                # weight sim_results with the joint pdf
-                results_complete = results_complete * joint_pdf * 2 ** self.problem.dim
-
-            # scale rows of gpc matrix with quadrature weights
-            matrix_weighted = np.matmul(np.diag(self.grid.weights), matrix)
-
-            # determine gpc coefficients [n_coeffs x n_output]
-            coeffs = np.matmul(results_complete.transpose(), matrix_weighted).transpose()
-
-        else:
-            raise AttributeError("Unknown solver: '{}'!")
-
-        return coeffs
-
-    def create_validation_set(self, n_samples, n_cpu=1):
-        """
-        Creates a ValidationSet instance (calls the model)
-
-        Parameters
-        ----------
-        n_samples: int
-            Number of sampling points contained in the validation set
-        n_cpu: int
-            Number of parallel function evaluations to evaluate validation set (n_cpu=0 assumes that the
-            model is capable to evaluate all grid points in parallel)
-        """
-        # create set of validation points
-        n_samples = n_samples
-
-        if self.problem_original is not None:
-            problem = self.problem_original
-        else:
-            problem = self.problem
-
-        grid = Random(parameters_random=problem.parameters_random,
-                      n_grid=n_samples,
-                      options={"seed": self.options["seed"]})
-
-        # Evaluate original model at grid points
-        com = Computation(n_cpu=n_cpu, matlab_model=self.matlab_model)
-        results = com.run(model=problem.model, problem=problem, coords=grid.coords)
-
-        if results.ndim == 1:
-            results = results[:, np.newaxis]
-
-        self.validation = ValidationSet(grid=grid, results=results)
+import numpy as np
+import scipy.stats
+import copy
+import h5py
+import time
+import random
+import sys
+from sklearn import linear_model
+from scipy.signal import savgol_filter
+from .misc import get_cartesian_product
+from .misc import display_fancy_bar
+from .misc import nrmsd
+from .misc import mat2ten
+from .misc import ten2mat
+from .pygpc_extensions import create_gpc_matrix_cpu
+from .pygpc_extensions import create_gpc_matrix_omp
+from .ValidationSet import *
+from .Computation import *
+from .Grid import *
+
+
+try:
+    from .pygpc_extensions_cuda import create_gpc_matrix_cuda
+except ImportError:
+    pass
+
+try:
+    import fastmat as fm
+except ImportError:
+    pass
+
+
+class GPC(object):
+    """
+    General gPC base class
+
+    Parameters
+    ----------
+    problem: Problem class instance
+        GPC Problem under investigation
+    options : dict
+        Options of gPC algorithm
+    validation: ValidationSet object (optional)
+        Object containing a set of validation points and corresponding solutions. Can be used
+        to validate gpc approximation setting options["error_type"]="nrmsd".
+        - grid: Grid object containing the validation points (grid.coords, grid.coords_norm)
+        - results: ndarray [n_grid x n_out] results
+
+    Attributes
+    ----------
+    problem: Problem class instance
+        GPC Problem under investigation
+    basis: Basis class instance
+        Basis of the gPC including BasisFunctions
+    grid: Grid class instance
+        Grid of the derived gPC approximation
+    validation: ValidationSet object (optional)
+        Object containing a set of validation points and corresponding solutions. Can be used
+        to validate gpc approximation setting options["error_type"]="nrmsd".
+        - grid: Grid object containing the validation points (grid.coords, grid.coords_norm)
+        - results: ndarray [n_grid x n_out] results
+    gpc_matrix: [N_samples x N_poly] ndarray of float
+        Generalized polynomial chaos matrix
+    gpc_matrix_gradient: [N_samples * dim x N_poly] ndarray of float
+        Derivative of generalized polynomial chaos matrix
+    matrix_inv: [N_poly (+ N_gradient) x N_samples] ndarray of float
+        Pseudo inverse of the generalized polynomial chaos matrix (with or without gradient)
+    p_matrix: [dim_red x dim] ndarray of float
+        Projection matrix to reduce number of efficient dimensions (\\eta = p_matrix * \\xi)
+    p_matrix_norm: [dim_red] ndarray of float
+        Maximal possible length of new axis in \\eta space. Since the projected variables are modelled in
+        the normalized space between [-1, 1], the transformed coordinates need to be scaled.
+    nan_elm: ndarray of int
+        Indices of NaN elements of model output
+    gpc_matrix_coords_id: list of UUID4()
+        UUID4() IDs of grid points the gPC matrix derived with
+    gpc_matrix_b_id: list of UUID4()
+        UUID4() IDs of basis functions the gPC matrix derived with
+    n_basis: int or list of int
+        Number of basis functions (for iterative solvers, this is a list of its history)
+    n_grid: int or list of int
+        Number of grid points (for iterative solvers, this is a list of its history)
+    solver: str
+        Default solver to determine the gPC coefficients (can be chosen during GPC.solve)
+        - 'Moore-Penrose' ... Pseudoinverse of gPC matrix (SGPC.Reg, EGPC)
+        - 'OMP' ... Orthogonal Matching Pursuit, sparse recovery approach (SGPC.Reg, EGPC)
+        - 'LarsLasso' ... {"alpha": float 0...1} Regularization parameter
+        - 'NumInt' ... Numerical integration, spectral projection (SGPC.Quad)
+    verbose: bool
+        Boolean value to determine if to print out the progress into the standard output
+    fn_results : string, optional, default=None
+        If provided, model evaluations are saved in fn_results.hdf5 file and gpc object in fn_results.pkl file
+    relative_error_loocv: list of float
+        Relative error of the leave-one-out-cross-validation
+    relative_error_nrmsd: list of float
+        Normalized root mean square deviation between model and gpc approximation
+    options : dict
+        Options of gPC algorithm
+    """
+
+    def __init__(self, problem, options, validation=None):
+        """
+        Constructor; Initializes GPC class
+        """
+        # objects
+        self.problem = problem
+        self.problem_original = None
+        self.basis = None
+        self.grid = None
+        self.validation = validation
+
+        # arrays
+        self.gpc_matrix = None
+        self.gpc_matrix_gradient = None
+        self.matrix_inv = None
+        self.p_matrix = None
+        self.p_matrix_norm = None
+        self.nan_elm = []
+        self.gpc_matrix_coords_id = None
+        self.gpc_matrix_b_id = None
+        self.gpc_matrix_gradient_coords_id = None
+        self.gpc_matrix_gradient_b_id = None
+        self.n_basis = []
+        self.n_grid = []
+        self.relative_error_nrmsd = []
+        self.relative_error_loocv = []
+        self.error = []
+        self.n_out = []
+        self.gradient_idx = None
+
+        # options
+        if options is not None:
+            if "gradient_enhanced" not in options.keys():
+                options["gradient_enhanced"] = False
+
+            if "fn_results" not in options.keys():
+                options["fn_results"] = None
+
+            if "matlab_model" not in options.keys():
+                options["matlab_model"] = False
+
+            if "backend" not in options.keys():
+                options["backend"] = "omp"
+
+            self.gradient = options["gradient_enhanced"]
+            self.fn_results = options["fn_results"]
+            self.matlab_model = options["matlab_model"]
+            self.backend = options["backend"]
+
+        else:
+            self.gradient = None
+            self.fn_results = None
+            self.matlab_model = False
+            self.backend = "omp"
+
+        self.solver = None
+        self.settings = None
+        self.verbose = True
+
+        self.options = options
+
+    def init_gpc_matrix(self, gradient_idx=None):
+        """
+        Sets self.gpc_matrix and self.gpc_matrix_gradient with given self.basis and self.grid
+
+        Parameters
+        ----------
+        gradient_idx : ndarray of int [gradient_results.shape[0]]
+            Indices of grid points where the gradient in gradient_results is provided
+        """
+
+        if self.gradient_idx is None or gradient_idx is not None:
+            self.gradient_idx = gradient_idx
+
+        self.gpc_matrix = self.create_gpc_matrix(b=self.basis.b,
+                                                 x=self.grid.coords_norm,
+                                                 gradient=False)
+        self.n_grid.append(self.gpc_matrix.shape[0])
+        self.n_basis.append(self.gpc_matrix.shape[1])
+        self.gpc_matrix_coords_id = copy.deepcopy(self.grid.coords_id)
+        self.gpc_matrix_b_id = copy.deepcopy(self.basis.b_id)
+
+        if self.gradient and self.gradient_idx is not None:
+            self.gpc_matrix_gradient = self.create_gpc_matrix(b=self.basis.b,
+                                                              x=self.grid.coords_norm,
+                                                              gradient=True)
+            self.gpc_matrix_gradient = ten2mat(self.gpc_matrix_gradient)
+            self.gpc_matrix_gradient_coords_id = copy.deepcopy(self.grid.coords_id)
+            self.gpc_matrix_gradient_b_id = copy.deepcopy(self.basis.b_id)
+
+    def create_gpc_matrix(self, b, x, gradient=False, gradient_idx=None, weighted=False, verbose=False):
+        """
+        Construct the gPC matrix or its derivative.
+
+        Parameters
+        ----------
+        b : list of BasisFunction object instances [n_basis][n_dim]
+            Parameter wise basis function objects used in gPC (Basis.b)
+            Multiplying all elements in a row at location xi = (x1, x2, ..., x_dim) yields the global basis function.
+        x : ndarray of float [n_x x n_dim]
+            Coordinates of x = (x1, x2, ..., x_dim) where the rows of the gPC matrix are evaluated (normalized [-1, 1])
+        gradient : bool, optional, default: False
+            Determine gradient gPC matrix.
+        gradient_idx : ndarray of int [gradient_results.shape[0]]
+            Indices of grid points where the gradient in gradient_results is provided
+        weighted : bool, optional, default: False
+            Weight gPC matrix with (row 2-norm)^-1
+        verbose : bool, optional, default: False
+            boolean value to determine if to print out the progress into the standard output
+
+        Returns
+        -------
+        gpc_matrix: ndarray of float [n_x x n_basis (x dim)]
+            GPC matrix where the columns correspond to the basis functions and the rows the to the sample coordinates.
+            If gradient_idx!=None, the gradient is returned at the specified sample coordinates point by point.
+        """
+        # overwrite self.gradient_idx if it is provided
+        if gradient_idx is not None:
+            self.gradient_idx = gradient_idx
+
+        iprint('Constructing gPC matrix...', verbose=verbose, tab=0)
+
+        # Python backend
+        if self.backend == "python":
+            if not gradient:
+                gpc_matrix = np.ones([x.shape[0], len(b)])
+                for i_basis in range(len(b)):
+                    for i_dim in range(self.problem.dim):
+                        gpc_matrix[:, i_basis] *= b[i_basis][i_dim](x[:, i_dim])
+            else:
+                gpc_matrix = np.ones([len(self.gradient_idx), len(b), self.problem.dim])
+                for i_dim_gradient in range(self.problem.dim):
+                    for i_basis in range(len(b)):
+                        for i_dim in range(self.problem.dim):
+                            if i_dim == i_dim_gradient:
+                                derivative = True
+                            else:
+                                derivative = False
+                            gpc_matrix[:, i_basis, i_dim_gradient] *= b[i_basis][i_dim](x[self.gradient_idx, i_dim],
+                                                                                        derivative=derivative)
+
+        # CPU backend (CPU single core)
+        elif self.backend == "cpu":
+            if not gradient:
+                # the third dimension is important and should not be removed
+                # otherwise the code could produce undefined behaviour
+                gpc_matrix = np.empty([x.shape[0], len(b), 1])
+                create_gpc_matrix_cpu(x, self.basis.b_array, gpc_matrix)
+                gpc_matrix = np.squeeze(gpc_matrix)
+            else:
+                gpc_matrix = np.empty([len(self.gradient_idx), len(b), self.problem.dim])
+                create_gpc_matrix_cpu(x[self.gradient_idx, :], self.basis.b_array_grad, gpc_matrix)
+
+        # OpenMP backend (CPU multi core)
+        elif self.backend == "omp":
+            if not gradient:
+                # the third dimension is important and should not be removed
+                # otherwise the code could produce undefined behaviour
+                gpc_matrix = np.empty([x.shape[0], len(b), 1])
+                create_gpc_matrix_omp(x, self.basis.b_array, gpc_matrix)
+                gpc_matrix = np.squeeze(gpc_matrix)
+            else:
+                gpc_matrix = np.empty([len(self.gradient_idx), len(b), self.problem.dim])
+                create_gpc_matrix_omp(x[self.gradient_idx, :], self.basis.b_array_grad, gpc_matrix)
+
+        # CUDA backend (GPU multi core)
+        elif self.backend == "cuda":
+            try:
+                from .pygpc_extensions_cuda import create_gpc_matrix_cuda
+            except (ImportError):
+                raise NotImplementedError("The CUDA-extension is not installed. Use the build script to install.")
+            else:
+                if not gradient:
+                    # the third dimension is important and should not be removed
+                    # otherwise the code could produce undefined behaviour
+                    gpc_matrix = np.empty([x.shape[0], len(b), 1])
+                    create_gpc_matrix_cuda(x, self.basis.b_array, gpc_matrix)
+                    gpc_matrix = np.squeeze(gpc_matrix)
+                else:
+                    gpc_matrix = np.empty([len(self.gradient_idx), len(b), self.problem.dim])
+                    create_gpc_matrix_cuda(x[self.gradient_idx, :], self.basis.b_array_grad, gpc_matrix)
+
+        else:
+            raise NotImplementedError
+
+        if gpc_matrix.ndim == 1 and x.shape[0] == 1:
+            gpc_matrix = gpc_matrix[np.newaxis, :]
+        elif gpc_matrix.ndim == 1 and self.basis.n_basis == 1:
+            gpc_matrix = gpc_matrix[:, np.newaxis]
+
+        if weighted:
+            w = np.diag(1/np.linalg.norm(gpc_matrix, axis=1))
+            gpc_matrix = np.matmul(w, gpc_matrix)
+
+        return gpc_matrix
+
+    def get_loocv(self, coeffs, results, gradient_results=None, error_norm="relative"):
+        """
+        Perform leave-one-out cross validation of gPC approximation and add error value to self.relative_error_loocv.
+        The loocv error is calculated analytically after eq. (35) in [1] but omitting the "1 - " term, i.e. it
+        corresponds to 1 - Q^2.
+
+        relative_error_loocv = GPC.loocv(sim_results, coeffs)
+
+        .. math::
+           \\epsilon_{LOOCV} = \\frac{\\frac{1}{N}\sum_{i=1}^N \\left( \\frac{y(\\xi_i) - \hat{y}(\\xi_i)}{1-h_i}
+           \\right)^2}{\\frac{1}{N-1}\sum_{i=1}^N \\left( y(\\xi_i) - \\bar{y} \\right)^2}
+
+        with
+
+        .. math::
+           \\mathbf{h} = \mathrm{diag}(\\mathbf{\\Psi} (\\mathbf{\\Psi}^T \\mathbf{\\Psi})^{-1} \\mathbf{\\Psi}^T)
+
+        Parameters
+        ----------
+        coeffs: ndarray of float [n_basis x n_out]
+            GPC coefficients
+        results: ndarray of float [n_grid x n_out]
+            Results from n_grid simulations with n_out output quantities
+        error_norm: str, optional, default="relative"
+            Decide if error is determined "relative" or "absolute"
+        gradient_results : ndarray of float [n_grid x n_out x dim], optional, default: None
+            Gradient of results in original parameter space (tensor)
+
+        Returns
+        -------
+        relative_error_loocv: float
+            Relative mean error of leave one out cross validation
+
+        Notes
+        -----
+        .. [1] Blatman, G., & Sudret, B. (2010). An adaptive algorithm to build up sparse polynomial chaos expansions
+           for stochastic finite element analysis. Probabilistic Engineering Mechanics, 25(2), 183-197.
+        """
+        # if self.options["gradient_enhanced"]:
+        #     matrix = np.vstack((self.gpc_matrix, self.gpc_matrix_gradient))
+        #
+        #     # transform gradient of results in case of projection
+        #     if self.p_matrix is not None:
+        #         gradient_results = np.matmul(gradient_results,
+        #                                   self.p_matrix.transpose() * self.p_matrix_norm[np.newaxis, :])
+        #
+        #     results_complete = np.vstack((results, ten2mat(gradient_results)))
+        # else:
+        #     matrix = self.gpc_matrix
+        #     results_complete = results
+
+        # matrix = self.gpc_matrix
+        # results_complete = results
+
+        # Analytical error estimation in case of overdetermined systems
+        # if matrix.shape[0] > 2*matrix.shape[1]:
+            # determine Psi (Psi^T Psi)^-1 Psi^T
+            # h = np.matmul(np.matmul(matrix, np.linalg.inv(np.matmul(matrix.transpose(), matrix))), matrix.transpose())
+            #
+            # # determine loocv error
+            # err = np.mean(((results_complete - np.matmul(matrix, coeffs)) /
+            #                (1 - np.diag(h))[:, np.newaxis]) ** 2, axis=0)
+            #
+            # if error_norm == "relative":
+            #     norm = np.var(results_complete, axis=0, ddof=1)
+            # else:
+            #     norm = 1.
+            #
+            # # normalize
+            # relative_error_loocv = np.mean(err / norm)
+
+        # else:
+        # perform manual loocv without gradient
+        matrix = self.gpc_matrix
+        results_complete = results
+
+        n_loocv = 25
+
+        # define number of performed cross validations (max 100)
+        n_loocv_points = np.min((results_complete.shape[0], n_loocv))
+
+        # make list of indices, which are randomly sampled
+        loocv_point_idx = random.sample(list(range(results_complete.shape[0])), n_loocv_points)
+
+        start = time.time()
+        relative_error = np.zeros(n_loocv_points)
+        for i in range(n_loocv_points):
+            # get mask of eliminated row
+            mask = np.arange(results_complete.shape[0]) != loocv_point_idx[i]
+
+            # determine gpc coefficients (this takes a lot of time for large problems)
+            coeffs_loo = self.solve(results=results_complete[mask, :],
+                                    solver=self.options["solver"],
+                                    matrix=matrix[mask, :],
+                                    settings=self.options["settings"],
+                                    verbose=False)
+
+            sim_results_temp = results_complete[loocv_point_idx[i], :]
+
+            if error_norm == "relative":
+                norm = scipy.linalg.norm(sim_results_temp)
+            else:
+                norm = 1.
+
+            relative_error[i] = scipy.linalg.norm(sim_results_temp - np.matmul(matrix[loocv_point_idx[i], :],
+                                                                            coeffs_loo))\
+                                / norm
+            display_fancy_bar("LOOCV", int(i + 1), int(n_loocv_points))
+
+        # store result in relative_error_loocv
+        relative_error_loocv = np.mean(relative_error)
+        iprint("LOOCV computation time: {} sec".format(time.time() - start), tab=0, verbose=True)
+
+        return relative_error_loocv
+
+    def validate(self, coeffs, results=None, gradient_results=None, qoi_idx=None):
+        """
+        Validate gPC approximation using the ValidationSet object contained in the Problem object.
+        Determines the normalized root mean square deviation between the gpc approximation and the
+        original model. Skips this step if no validation set is present
+
+        Parameters
+        ----------
+        coeffs: ndarray of float [n_coeffs x n_out]
+            GPC coefficients
+        results: ndarray of float [n_grid x n_out]
+            Results from n_grid simulations with n_out output quantities
+        gradient_results : ndarray of float [n_grid x n_out x dim], optional, default: None
+            Gradient of results in original parameter space (tensor)
+        qoi_idx : int, optional, default: None
+            Index of QOI to validate (if None, all QOI are considered)
+
+        Returns
+        -------
+        error: float
+            Estimated difference between gPC approximation and original model
+        """
+        if qoi_idx is None:
+            qoi_idx = np.arange(0, results.shape[1])
+
+        # Determine QOIs with NaN in results and exclude them from validation
+        non_nan_mask = np.where(np.all(~np.isnan(results), axis=0))[0]
+        n_nan = results.shape[1] - non_nan_mask.size
+
+        if n_nan > 0:
+            iprint("In {}/{} output quantities NaN's were found.".format(n_nan, results.shape[1]),
+                   tab=0, verbose=self.options["verbose"])
+
+        results = results[:, non_nan_mask]
+
+        if gradient_results is not None:
+            gradient_results = gradient_results[:, non_nan_mask, :]
+
+        # always determine nrmsd if a validation set is present
+        if isinstance(self.validation, ValidationSet):
+
+            gpc_results = self.get_approximation(coeffs, self.validation.grid.coords_norm, output_idx=None)
+
+            if gpc_results.ndim == 1:
+                gpc_results = gpc_results[:, np.newaxis]
+
+            if self.validation.results[:, qoi_idx].ndim == 1:
+                validation_results = self.validation.results[:, qoi_idx][:, np.newaxis]
+            else:
+                validation_results = self.validation.results[:, qoi_idx]
+
+            self.relative_error_nrmsd.append(float(np.mean(nrmsd(gpc_results,
+                                                                 validation_results,
+                                                                 error_norm=self.options["error_norm"],
+                                                                 x_axis=False))))
+
+        if self.options["error_type"] == "nrmsd":
+            self.error.append(self.relative_error_nrmsd[-1])
+
+        elif self.options["error_type"] == "loocv":
+            self.relative_error_loocv.append(self.get_loocv(coeffs=coeffs,
+                                             results=results,
+                                             gradient_results=gradient_results,
+                                             error_norm=self.options["error_norm"]))
+            self.error.append(self.relative_error_loocv[-1])
+
+        elif self.options["error_type"] is None:
+            self.error.append(None)
+
+        return self.error[-1]
+
+    def get_pdf(self, coeffs, n_samples, output_idx=None, filter=True, return_samples=False):
+        """ Determine the estimated pdfs of the output quantities
+
+        pdf_x, pdf_y = SGPC.get_pdf(coeffs, n_samples, output_idx=None)
+
+        Parameters
+        ----------
+        coeffs: ndarray of float [n_coeffs x n_out]
+            GPC coefficients
+        n_samples: int
+            Number of samples used to estimate output pdfs
+        output_idx: ndarray, optional, default=None [1 x n_out]
+            Index of output quantities to consider (if output_idx=None, all output quantities are considered)
+        filter : bool, optional, default: True
+            Use savgol_filter to smooth probability density
+        return_samples : bool, optional, default: False
+            Additionally returns in and output samples with which the pdfs were computed
+
+        Returns
+        -------
+        pdf_x: ndarray of float [100 x n_out]
+            x-coordinates of output pdfs of output quantities
+        pdf_y: ndarray of float [100 x n_out]
+            y-coordinates of output pdfs (probability density of output quantity)
+        samples_in : ndarray of float [n_samples x dim] (optional)
+            Input samples (if return_samples=True)
+        samples_out : ndarray of float [n_samples x n_out] (optional)
+            Output samples (if return_samples=True)
+        """
+
+        # handle (N,) arrays
+        if len(coeffs.shape) == 1:
+            coeffs = coeffs[:, np.newaxis]
+
+        # if output index array is not provided, determine pdfs of all outputs
+        if output_idx is None:
+            output_idx = np.arange(0, coeffs.shape[1])
+            output_idx = output_idx[np.newaxis, :]
+
+        n_out = len(output_idx)
+
+        # sample gPC expansion
+        samples_in, samples_out = self.get_samples(n_samples=n_samples, coeffs=coeffs, output_idx=output_idx)
+
+        # determine kernel density estimates using Gaussian kernel
+        pdf_x = np.zeros([100, n_out])
+        pdf_y = np.zeros([100, n_out])
+
+        for i_out in range(n_out):
+
+            pdf_y[:, i_out], tmp = np.histogram(samples_out[:, i_out], bins=100, density=True)
+            pdf_x[:, i_out] = (tmp[1:] + tmp[0:-1]) / 2.
+
+            if filter:
+                pdf_y[:, i_out] = savgol_filter(pdf_y[:, i_out], 51, 5)
+
+            # kde = scipy.stats.gaussian_kde(samples_out[:, i_out], bw_method=0.1 / samples_out[:, i_out].std(ddof=1))
+            # pdf_y[:, i_out] = kde(pdf_x[:, i_out])
+            # pdf_x[:, i_out] = np.linspace(samples_out[:, i_out].min(), samples_out[:, i_out].max(), 100)
+
+        if return_samples:
+            return pdf_x, pdf_y, samples_in, samples_out
+        else:
+            return pdf_x, pdf_y
+
+    def get_samples(self, coeffs, n_samples, output_idx=None):
+        """
+        Randomly sample gPC expansion.
+
+        x, pce = SGPC.get_pdf_mc(n_samples, coeffs, output_idx=None)
+
+        Parameters
+        ----------
+        coeffs: ndarray of float [n_basis x n_out]
+            GPC coefficients
+        n_samples: int
+            Number of random samples drawn from the respective input pdfs.
+        output_idx: ndarray of int [1 x n_out] optional, default=None
+            Index of output quantities to consider.
+
+        Returns
+        -------
+        x: ndarray of float [n_samples x dim]
+            Generated samples in normalized coordinates [-1, 1].
+        pce: ndarray of float [n_samples x n_out]
+            GPC approximation at points x.
+        """
+
+        # seed the random numbers generator
+        np.random.seed()
+
+        if self.p_matrix is not None:
+            problem = self.problem_original
+        else:
+            problem = self.problem
+
+        # generate temporary grid with random samples for each random input variable [n_samples x dim]
+        grid = Random(parameters_random=problem.parameters_random,
+                      n_grid=n_samples)
+
+        # if output index list is not provided, sample all gpc outputs
+        if output_idx is None:
+            n_out = 1 if coeffs.ndim == 1 else coeffs.shape[1]
+            output_idx = np.arange(n_out)
+            # output_idx = output_idx[np.newaxis, :]
+
+        pce = self.get_approximation(coeffs=coeffs, x=grid.coords_norm, output_idx=output_idx)
+
+        return grid.coords_norm, pce
+
+    def get_approximation(self, coeffs, x, output_idx=None):
+        """
+        Calculates the gPC approximation in points with output_idx and normalized parameters xi (interval: [-1, 1]).
+
+        pce = GPC.get_approximation(coeffs, x, output_idx=None)
+
+        Parameters
+        ----------
+        coeffs: ndarray of float [n_basis x n_out]
+            GPC coefficients for each output variable
+        x: ndarray of float [n_x x n_dim]
+            Coordinates of x = (x1, x2, ..., x_dim) where the rows of the gPC matrix are evaluated (normalized [-1, 1]).
+            The coordinates will be transformed in case of projected gPC.
+        output_idx: ndarray of int, optional, default=None [n_out]
+            Indices of output quantities to consider (Default: all).
+
+        Returns
+        -------
+        pce: ndarray of float [n_x x n_out]
+            GPC approximation at normalized coordinates x.
+        """
+
+        if len(x.shape) == 1:
+            x = x[:, np.newaxis]
+
+        # crop coordinates to gPC boundaries (values outside do not yield meaningful values)
+        for i_dim, key in enumerate(list(self.problem.parameters_random.keys())):
+            xmin = self.problem.parameters_random[key].pdf_limits_norm[0]
+            xmax = self.problem.parameters_random[key].pdf_limits_norm[1]
+            x[x[:, i_dim] < xmin, i_dim] = xmin
+            x[x[:, i_dim] > xmax, i_dim] = xmax
+
+        if output_idx is not None:
+            # convert to 1d array
+            output_idx = np.asarray(output_idx).flatten().astype(int)
+
+            # crop coeffs array if output index is specified
+            coeffs = coeffs[:, output_idx]
+
+        if coeffs.ndim == 1:
+            coeffs = coeffs[:, np.newaxis]
+
+        # transform variables from xi to eta space if gpc model is reduced
+        if self.p_matrix is not None:
+            x = np.matmul(x, self.p_matrix.transpose() / self.p_matrix_norm[np.newaxis, :])
+
+        if self.backend == 'python' or self.backend == 'cpu' or self.backend == 'omp':
+            # determine gPC matrix at coordinates x
+            gpc_matrix = self.create_gpc_matrix(self.basis.b, x, gradient=False)
+
+            # multiply with gPC coeffs
+            pce = np.matmul(gpc_matrix, coeffs)
+
+        elif self.backend == "cuda":
+            try:
+                from .pygpc_extensions_cuda import get_approximation_cuda
+            except ImportError:
+                raise NotImplementedError("The CUDA-extension is not installed. Use the build script to install.")
+            else:
+                pce = np.empty([x.shape[0], coeffs.shape[1]])
+                get_approximation_cuda(x, self.basis.b_array, coeffs, pce)
+        else:
+            raise NotImplementedError
+
+        return pce
+
+    def replace_gpc_matrix_samples(self, idx, seed=None):
+        """
+        Replace distinct sample points from the gPC matrix with new ones.
+
+        GPC.replace_gpc_matrix_samples(idx, seed=None)
+
+        Parameters
+        ----------
+        idx: ndarray of int [n_samples]
+            Array of grid indices of grid.coords[idx, :] which are going to be replaced
+            (rows of gPC matrix will be replaced by new ones)
+        seed: float, optional, default=None
+            Random seeding point
+        """
+
+        # Generate new grid points
+        new_grid_points = Random(parameters_random=self.problem.parameters_random,
+                                 n_grid=idx.size,
+                                 seed=seed)
+
+        # replace old grid points
+        self.grid.coords[idx, :] = new_grid_points.coords
+        self.grid.coords_norm[idx, :] = new_grid_points.coords_norm
+
+        # replace old IDs of grid points with new ones
+        for i in idx:
+            self.grid.coords_id[i] = uuid.uuid4()
+            self.gpc_matrix_coords_id[i] = copy.deepcopy(self.grid.coords_id[i])
+
+        # determine new rows of gpc matrix and overwrite rows of gpc matrix
+        self.gpc_matrix[idx, :] = self.create_gpc_matrix(b=self.basis.b,
+                                                         x=new_grid_points.coords_norm,
+                                                         gradient=False)
+
+    def update_gpc_matrix(self):
+        """
+        Update gPC matrix and gPC matrix gradient according to existing self.grid and self.basis.
+
+        Call this method when self.gpc_matrix does not fit to self.grid and self.basis objects anymore
+        The old gPC matrix with their self.gpc_matrix_b_id and self.gpc_matrix_coords_id is compared
+        to self.basis.b_id and self.grid.coords_id. New rows and columns are computed if differences are found.
+        """
+        self._update_gpc_matrix(gradient=False)
+
+        if self.gradient:
+            self._update_gpc_matrix(gradient=True)
+
+    def _update_gpc_matrix(self, gradient=False):
+        """
+        Update gPC matrix or gPC gradient matrix
+        """
+        if self.backend == "python":
+            # initialize updated matrix and variables
+            if gradient:
+                # reshape gpc gradient matrix from 2D to 3D representation [n_grid x n_basis x n_dim]
+                matrix = mat2ten(mat=self.gpc_matrix_gradient, incr=self.problem.dim)
+                matrix_updated = np.zeros((len(self.gradient_idx), len(self.basis.b_id), self.problem.dim))
+                coords_id = self.gpc_matrix_gradient_coords_id[self.gradient_idx]
+                coords_id_ref = self.grid.coords_gradient_id[self.gradient_idx]
+                b_id = self.gpc_matrix_gradient_b_id
+                b_id_ref = self.basis.b_id
+                coords_norm = self.grid.coords_norm[self.gradient_idx]
+                ge_str = "(gradient)"
+
+            else:
+                matrix = self.gpc_matrix
+                matrix_updated = np.zeros((len(self.grid.coords_id), len(self.basis.b_id)))
+                coords_id = self.gpc_matrix_coords_id
+                coords_id_ref = self.grid.coords_id
+                b_id = self.gpc_matrix_b_id
+                b_id_ref = self.basis.b_id
+                coords_norm = self.grid.coords_norm
+                ge_str = ""
+
+            # # determine indices of new basis functions and grid_points
+            # idx_coords_new = [i for i, _id in enumerate(self.grid.coords_id) if _id not in self.gpc_matrix_coords_id]
+            # idx_basis_new = [i for i, _id in enumerate(self.basis.b_id) if _id not in self.gpc_matrix_b_id]
+
+            # determine indices of old grid points in updated gpc matrix
+            idx_coords_old = np.empty(len(coords_id)) * np.nan
+            for i, coords_id_old in enumerate(coords_id):
+                for j, coords_id_new in enumerate(coords_id_ref):
+                    if coords_id_old == coords_id_new:
+                        idx_coords_old[i] = j
+                        break
+
+            # determine indices of old basis functions in updated gpc matrix
+            idx_b_old = np.empty(len(b_id))*np.nan
+            for i, b_id_old in enumerate(b_id):
+                for j, b_id_new in enumerate(b_id_ref):
+                    if b_id_old == b_id_new:
+                        idx_b_old[i] = j
+                        break
+
+            # filter out non-existent rows and columns
+            matrix = matrix[~np.isnan(idx_coords_old), :, ]
+            matrix = matrix[:, ~np.isnan(idx_b_old), ]
+
+            idx_coords_old = idx_coords_old[~np.isnan(idx_coords_old)].astype(int)
+            idx_b_old = idx_b_old[~np.isnan(idx_b_old)].astype(int)
+
+            # indices of new coords and basis in updated gpc matrix (values have to be computed there)
+            idx_coords_new = np.array(list(set(np.arange(len(coords_id_ref))) - set(idx_coords_old))).astype(int)
+            idx_b_new = np.array(list(set(np.arange(len(b_id_ref))) - set(idx_b_old))).astype(int)
+
+            # write old results at correct location in updated gpc matrix
+            idx = get_cartesian_product([idx_coords_old, idx_b_old]).astype(int)
+            idx_row = np.reshape(idx[:, 0], matrix.shape[:2]).astype(int)
+            idx_col = np.reshape(idx[:, 1], matrix.shape[:2]).astype(int)
+
+            matrix_updated[idx_row, idx_col, ] = matrix
+
+            # determine new columns (new basis functions) with old grid
+            idx = get_cartesian_product([idx_coords_old, idx_b_new]).astype(int)
+            if idx.any():
+                iprint('Adding {} columns to gPC matrix {}...'.format(idx_b_new.size, ge_str), tab=0, verbose=True)
+
+                idx_row = np.reshape(idx[:, 0], (idx_coords_old.size, idx_b_new.size)).astype(int)
+                idx_col = np.reshape(idx[:, 1], (idx_coords_old.size, idx_b_new.size)).astype(int)
+
+                matrix_updated[idx_row, idx_col, ] = self.create_gpc_matrix(b=[self.basis.b[i] for i in idx_b_new],
+                                                                            x=coords_norm[idx_coords_old, :],
+                                                                            gradient=gradient,
+                                                                            verbose=False)
+
+            # determine new rows (new grid points) with all basis functions
+            idx = get_cartesian_product([idx_coords_new, np.arange(len(self.basis.b))]).astype(int)
+            if idx.any():
+                iprint('Adding {} rows to gPC matrix {}...'.format(idx_coords_new.size, ge_str), tab=0, verbose=True)
+
+                idx_row = np.reshape(idx[:, 0], (idx_coords_new.size, len(self.basis.b))).astype(int)
+                idx_col = np.reshape(idx[:, 1], (idx_coords_new.size, len(self.basis.b))).astype(int)
+
+                matrix_updated[idx_row, idx_col, ] = self.create_gpc_matrix(b=self.basis.b,
+                                                                            x=coords_norm[idx_coords_new, :],
+                                                                            gradient=gradient,
+                                                                            verbose=False)
+
+            # overwrite old attributes and append new sizes
+            if gradient:
+                # reshape from 3D to 2D
+                self.gpc_matrix_gradient = ten2mat(matrix_updated)
+                self.gpc_matrix_gradient_coords_id = copy.deepcopy(self.grid.coords_id)
+                self.gpc_matrix_gradient_b_id = copy.deepcopy(self.basis.b_id)
+            else:
+                self.gpc_matrix = matrix_updated
+                self.gpc_matrix_coords_id = copy.deepcopy(self.grid.coords_id)
+                self.gpc_matrix_b_id = copy.deepcopy(self.basis.b_id)
+                self.n_grid.append(self.gpc_matrix.shape[0])
+                self.n_basis.append(self.gpc_matrix.shape[1])
+
+        else:
+            self.init_gpc_matrix()
+
+    def save_gpc_matrix_hdf5(self, hdf5_path_gpc_matrix=None, hdf5_path_gpc_matrix_gradient=None):
+        """
+        Save gPC matrix and gPC gradient matrix in .hdf5 file <"fn_results" + ".hdf5"> under the key "gpc_matrix"
+        and "gpc_matrix_gradient". If matrices are already present, check for equality and save only appended
+        rows and columns.
+
+        Parameters
+        ----------
+        hdf5_path_gpc_matrix : str
+            Path in .hdf5 file, where the gPC matrix is saved in
+        hdf5_path_gpc_matrix_gradient : str
+            Path in .hdf5 file, where the gPC gradient matrix is saved in
+        """
+
+        if hdf5_path_gpc_matrix is None:
+            hdf5_path_gpc_matrix = "gpc_matrix"
+
+        if hdf5_path_gpc_matrix_gradient is None:
+            hdf5_path_gpc_matrix_gradient = "gpc_matrix_gradient"
+
+        with h5py.File(self.fn_results + ".hdf5", "a") as f:
+            try:
+                # write gpc matrix
+                gpc_matrix_hdf5 = f[hdf5_path_gpc_matrix][:]
+                n_rows_hdf5 = gpc_matrix_hdf5.shape[0]
+                n_cols_hdf5 = gpc_matrix_hdf5.shape[1]
+
+                n_rows_current = self.gpc_matrix.shape[0]
+                n_cols_current = self.gpc_matrix.shape[1]
+
+                # save only new rows and cols if current matrix > saved matrix
+                if n_rows_current >= n_rows_hdf5 and n_cols_current >= n_cols_hdf5 and \
+                        (self.gpc_matrix[0:n_rows_hdf5, 0:n_cols_hdf5] == gpc_matrix_hdf5).all():
+                    # resize dataset and save new columns and rows
+                    f[hdf5_path_gpc_matrix].resize(self.gpc_matrix.shape[1], axis=1)
+                    f[hdf5_path_gpc_matrix][:, n_cols_hdf5:] = self.gpc_matrix[0:n_rows_hdf5, n_cols_hdf5:]
+
+                    f[hdf5_path_gpc_matrix].resize(self.gpc_matrix.shape[0], axis=0)
+                    f[hdf5_path_gpc_matrix][n_rows_hdf5:, :] = self.gpc_matrix[n_rows_hdf5:, :]
+
+                else:
+                    del f[hdf5_path_gpc_matrix]
+                    f.create_dataset(hdf5_path_gpc_matrix, (self.gpc_matrix.shape[0],
+                                                            self.gpc_matrix.shape[1]),
+                                     maxshape=(None, None),
+                                     dtype="float64",
+                                     data=self.gpc_matrix)
+
+                # write gpc gradient matrix if available
+                if self.gpc_matrix_gradient is not None:
+                    gpc_matrix_gradient_hdf5 = f[hdf5_path_gpc_matrix_gradient][:]
+                    n_rows_hdf5 = gpc_matrix_gradient_hdf5.shape[0]
+                    n_cols_hdf5 = gpc_matrix_gradient_hdf5.shape[1]
+
+                    n_rows_current = self.gpc_matrix_gradient.shape[0]
+                    n_cols_current = self.gpc_matrix_gradient.shape[1]
+
+                    # save only new rows and cols if current matrix > saved matrix
+                    if n_rows_current >= n_rows_hdf5 and n_cols_current >= n_cols_hdf5 and \
+                            (self.gpc_matrix_gradient[0:n_rows_hdf5, 0:n_cols_hdf5] == gpc_matrix_gradient_hdf5).all():
+                        # resize dataset and save new columns and rows
+                        f[hdf5_path_gpc_matrix_gradient].resize(self.gpc_matrix_gradient.shape[1], axis=1)
+                        f[hdf5_path_gpc_matrix_gradient][:, n_cols_hdf5:] = self.gpc_matrix_gradient[0:n_rows_hdf5,
+                                                                                                     n_cols_hdf5:]
+
+                        f[hdf5_path_gpc_matrix_gradient].resize(self.gpc_matrix_gradient.shape[0], axis=0)
+                        f[hdf5_path_gpc_matrix_gradient][n_rows_hdf5:, :] = self.gpc_matrix_gradient[n_rows_hdf5:, :]
+
+                    else:
+                        del f[hdf5_path_gpc_matrix_gradient]
+                        f.create_dataset(hdf5_path_gpc_matrix_gradient, (self.gpc_matrix_gradient.shape[0],
+                                                                         self.gpc_matrix_gradient.shape[1]),
+                                         maxshape=(None, None),
+                                         dtype="float64",
+                                         data=self.gpc_matrix_gradient)
+
+            except KeyError:
+                # save whole matrix if not existent
+                f.create_dataset(hdf5_path_gpc_matrix, (self.gpc_matrix.shape[0],
+                                                        self.gpc_matrix.shape[1]),
+                                 maxshape=(None, None),
+                                 dtype="float64",
+                                 data=self.gpc_matrix)
+
+                # save whole gradient matrix if not existent and available
+                if self.gpc_matrix_gradient is not None:
+                    f.create_dataset(hdf5_path_gpc_matrix_gradient, (self.gpc_matrix_gradient.shape[0],
+                                                                     self.gpc_matrix_gradient.shape[1]),
+                                     maxshape=(None, None),
+                                     dtype="float64",
+                                     data=self.gpc_matrix_gradient)
+
+    def solve(self, results, gradient_results=None, solver=None, settings=None, matrix=None, verbose=False):
+        """
+        Determines gPC coefficients
+
+        Parameters
+        ----------
+        results : [n_grid x n_out] np.ndarray of float
+            Results from simulations with N_out output quantities
+        gradient_results : ndarray of float [n_gradient x n_out x dim], optional, default: None
+            Gradient of results in original parameter space in specific grid points
+        solver : str
+            Solver to determine the gPC coefficients
+            - 'Moore-Penrose' ... Pseudoinverse of gPC matrix (SGPC.Reg, EGPC)
+            - 'OMP' ... Orthogonal Matching Pursuit, sparse recovery approach (SGPC.Reg, EGPC)
+            - 'LarsLasso' ... Least-Angle Regression using Lasso model (SGPC.Reg, EGPC)
+            - 'NumInt' ... Numerical integration, spectral projection (SGPC.Quad)
+        settings : dict
+            Solver settings
+            - 'Moore-Penrose' ... None
+            - 'OMP' ... {"n_coeffs_sparse": int} Number of gPC coefficients != 0 or "sparsity": float 0...1
+            - 'LarsLasso' ... {"alpha": float 0...1} Regularization parameter
+            - 'NumInt' ... None
+        matrix : ndarray of float, optional, default: self.gpc_matrix or [self.gpc_matrix, self.gpc_matrix_gradient]
+            Matrix to invert. Depending on gradient_enhanced option, this matrix consist of the standard gPC matrix and
+            their derivatives.
+        verbose : bool
+            boolean value to determine if to print out the progress into the standard output
+
+        Returns
+        -------
+        coeffs: ndarray of float [n_coeffs x n_out]
+            gPC coefficients
+        """
+
+        ge_str = ""
+
+        if matrix is None:
+            matrix = self.gpc_matrix
+
+            if self.gradient is False:
+                matrix = self.gpc_matrix
+                ge_str = ""
+            else:
+                if not solver == 'NumInt':
+                    if self.gpc_matrix_gradient is not None:
+                        matrix = np.vstack((self.gpc_matrix, self.gpc_matrix_gradient))
+                    else:
+                        matrix = self.gpc_matrix
+                    ge_str = "(gradient enhanced)"
+                else:
+                    Warning("Gradient enhanced version not applicable in case of numerical integration (quadrature).")
+
+        # use default solver if not specified
+        if solver is None:
+            solver = self.solver
+
+        # use default solver settings if not specified
+        if solver is None:
+            settings = self.settings
+
+        iprint("Determine gPC coefficients using '{}' solver {}...".format(solver, ge_str),
+               tab=0, verbose=verbose)
+
+        # construct results array
+        if not solver == 'NumInt' and gradient_results is not None:
+            # transform gradient of results according to projection
+            if self.p_matrix is not None:
+                gradient_results = np.matmul(gradient_results,
+                                             self.p_matrix.transpose() * self.p_matrix_norm[np.newaxis, :])
+
+            results_complete = np.vstack((results, ten2mat(gradient_results)))
+        else:
+            results_complete = results
+
+        self.coherence_matrix = matrix
+
+        if isinstance(self.grid, CO) or (isinstance(self.grid, L1) and not (["D"] in self.grid.criterion)):
+            w = np.diag(1/np.linalg.norm(matrix, axis=1))
+            matrix = np.matmul(w, matrix)
+            results_complete = np.matmul(w, results_complete)
+
+        #################
+        # Moore-Penrose #
+        #################
+        if solver == 'Moore-Penrose':
+            # determine pseudoinverse of gPC matrix
+            self.matrix_inv = np.linalg.pinv(matrix)
+
+            try:
+                coeffs = np.matmul(self.matrix_inv, results_complete)
+            except ValueError:
+                raise AttributeError("Please check format of parameter sim_results: [n_grid (* dim) x n_out] "
+                                     "np.ndarray.")
+
+        ###############################
+        # Orthogonal Matching Pursuit #
+        ###############################
+        elif solver == 'OMP':
+            # transform gPC matrix to fastmat format
+            matrix_fm = fm.Matrix(matrix)
+
+            if results_complete.ndim == 1:
+                results_complete = results_complete[:, np.newaxis]
+
+            # determine gPC-coefficients of extended basis using OMP
+            if "n_coeffs_sparse" in settings.keys():
+                n_coeffs_sparse = int(settings["n_coeffs_sparse"])
+            elif "sparsity" in settings.keys():
+                n_coeffs_sparse = int(np.ceil(matrix.shape[1]*settings["sparsity"]))
+            else:
+                raise AttributeError("Please specify 'n_coeffs_sparse' or 'sparsity' in solver settings dictionary!")
+
+            coeffs = fm.algs.OMP(matrix_fm, results_complete, n_coeffs_sparse)
+
+        ################################
+        # Least-Angle Regression Lasso #
+        ################################
+        elif solver == 'LarsLasso':
+
+            if results_complete.ndim == 1:
+                results_complete = results_complete[:, np.newaxis]
+
+            # determine gPC-coefficients of extended basis using LarsLasso
+            # from sklearn.preprocessing import normalize
+            # matrix_norm = normalize(matrix, axis=0, return_norm=False)
+            #
+            # reg = linear_model.LassoLars(alpha=settings["alpha"], fit_intercept=False, normalize=False)
+            # reg.fit(matrix_norm, results_complete)
+            # coeffs = reg.coef_
+
+            # reg = linear_model.LassoLars(alpha=settings["alpha"], fit_intercept=False, normalize=False)
+            reg = linear_model.LassoLars(alpha=settings["alpha"], fit_intercept=False)
+            reg.fit(matrix, results_complete)
+            coeffs = reg.coef_
+
+            if coeffs.ndim == 1:
+                coeffs = coeffs[:, np.newaxis]
+            else:
+                coeffs = coeffs.transpose()
+
+        #########################
+        # Numerical Integration #
+        #########################
+        elif solver == 'NumInt':
+            # check if quadrature rule (grid) fits to the probability density distribution (pdf)
+            grid_pdf_fit = True
+            for i_p, p in enumerate(self.problem.parameters_random):
+                if self.problem.parameters_random[p].pdf_type == 'beta':
+                    if not (self.grid.grid_type[i_p] == 'jacobi'):
+                        grid_pdf_fit = False
+                        break
+                elif self.problem.parameters_random[p].pdf_type in ['norm', 'normal']:
+                    if not (self.grid.grid_type[i_p] == 'hermite'):
+                        grid_pdf_fit = False
+                        break
+
+            # if not, calculate joint pdf
+            if not grid_pdf_fit:
+                joint_pdf = np.ones(self.grid.coords_norm.shape)
+
+                for i_p, p in enumerate(self.problem.parameters_random):
+                    joint_pdf[:, i_p] = \
+                        self.problem.parameters_random[p].pdf_norm(x=self.grid.coords_norm[:, i_p])
+
+                joint_pdf = np.array([np.prod(joint_pdf, axis=1)]).transpose()
+
+                # weight sim_results with the joint pdf
+                results_complete = results_complete * joint_pdf * 2 ** self.problem.dim
+
+            # scale rows of gpc matrix with quadrature weights
+            matrix_weighted = np.matmul(np.diag(self.grid.weights), matrix)
+
+            # determine gpc coefficients [n_coeffs x n_output]
+            coeffs = np.matmul(results_complete.transpose(), matrix_weighted).transpose()
+
+        else:
+            raise AttributeError("Unknown solver: '{}'!")
+
+        return coeffs
+
+    def create_validation_set(self, n_samples, n_cpu=1):
+        """
+        Creates a ValidationSet instance (calls the model)
+
+        Parameters
+        ----------
+        n_samples: int
+            Number of sampling points contained in the validation set
+        n_cpu: int
+            Number of parallel function evaluations to evaluate validation set (n_cpu=0 assumes that the
+            model is capable to evaluate all grid points in parallel)
+        """
+        # create set of validation points
+        n_samples = n_samples
+
+        if self.problem_original is not None:
+            problem = self.problem_original
+        else:
+            problem = self.problem
+
+        grid = Random(parameters_random=problem.parameters_random,
+                      n_grid=n_samples,
+                      options={"seed": self.options["seed"]})
+
+        # Evaluate original model at grid points
+        com = Computation(n_cpu=n_cpu, matlab_model=self.matlab_model)
+        results = com.run(model=problem.model, problem=problem, coords=grid.coords)
+
+        if results.ndim == 1:
+            results = results[:, np.newaxis]
+
+        self.validation = ValidationSet(grid=grid, results=results)
```

## pygpc/Gradient.py

 * *Ordering differences only*

```diff
@@ -1,390 +1,390 @@
-import numpy as np
-from .misc import ten2mat
-from .misc import mat2ten
-from .misc import get_all_combinations
-
-
-def get_gradient(model, problem, grid, results, com,  method="FD_fwd",
-                 gradient_results_present=None, gradient_idx_skip=None,
-                 i_iter=None, i_subiter=None, print_func_time=False,
-                 dx=1e-3, distance_weight=-1, verbose=False):
-    """
-    Determines the gradient of the model function in the grid points (self.grid.coords).
-    The method to determine the gradient can be specified in self.options["gradient_calculation"].
-    The new gradients and their indices are appended to the old results given in gradient_results_present and
-    gradient_idx_skip.
-
-    Parameters
-    ----------
-    model: Model object
-        Model object instance of model to investigate (derived from AbstractModel class, implemented by user)
-    problem: Problem class instance
-        GPC Problem under investigation
-    grid : Grid object
-        Grid object
-    results : ndarray of float [n_grid x n_out]
-        Results of model function in grid points
-    com : Computation class instance
-        Computation class instance to run the computations
-    method : str, optional, default: "FD_fwd"
-        Gradient calculation method:
-        - "FD_fwd": Finite difference forward approximation of the gradient using n_grid x dim additional sampling
-        points stored in self.grid.coords_gradient and self.grid.coords_gradient_norm [n_grid x dim x dim].
-        - "FD_1st": Finite difference approximation of 1st order accuracy using only the available samples [1]
-        - "FD_2nd": Finite difference approximation of 2nd order accuracy using only the available samples [1]
-        - "FD_1st2nd": Finite difference approximation of 1st and (where possible) 2nd order accuracy
-        using only the available samples [1]
-    gradient_results_present : ndarray of float [n_grid_old x n_out x dim], optional, default: None
-        Gradient of model function in grid points, already determined in previous calculations.
-        Those values will not be updated!
-    gradient_idx_skip: ndarray of int [n_gradient_results.shape[0]]
-        Indices of grid points where the gradient was already computed and is provided in gradient_results.
-        Those grid points will be skipped.
-    i_iter : int (optional, default: None)
-        Current iteration
-    i_subiter : int (optional, default: None)
-        Current sub-iteration
-    dx : float, optional, default: 1e-3
-        Distance parameter, depending on applied method:
-        - "FW_fwd": Distance of new grid-points in each dim from orig. grid points to compute forward approximation
-        - "FW_1st": Radius around grid points to include adjacent grid-points in 1st order gradient approximation
-        - "FW_2nd": Radius around grid points to include adjacent grid-points in 1st order gradient approximation
-    distance_weight : float, optional, default: 1
-        Distance weight factor (exponent) for methods "FD_1st" and "FD_2nd".
-        Defines the importance of the adjacent grid points to estimate the gradient by their distance.
-    verbose : bool, optional, default: False
-        Print progress
-
-    Returns
-    -------
-    gradient_results : ndarray of float [n_grid x n_out x dim]
-        Gradient of model function in grid points
-    gradient_results_idx : ndarray of int [n_grid]
-        Indices of grid points where the gradient was evaluated
-
-    Notes
-    -----
-    .. [1] Belward J, Turner IW, Ilic M, On derivative estimation and the solution of least squares problems,
-       Journal of Computational and Applied Mathematics 2008, vol. 222, pp. 511-523.
-    """
-    gradient_results_new = None
-
-    if gradient_results_present is not None:
-        n_gradient_results = gradient_results_present.shape[0]
-    else:
-        n_gradient_results = 0
-
-    if gradient_idx_skip is None:
-        gradient_idx_skip = np.array([])
-
-    gradient_idx_compute = np.arange(grid.coords.shape[0])
-
-    if gradient_idx_skip is not None:
-        gradient_idx_compute = np.delete(gradient_idx_compute, gradient_idx_skip.astype(int))
-
-    if n_gradient_results < results.shape[0]:
-        #########################################
-        # Standard forward gradient calculation #
-        #########################################
-        if method == "FD_fwd":
-
-            # add new grid points for gradient calculation in grid.coords_gradient and grid.coords_gradient_norm
-            grid.create_gradient_grid(delta=dx)
-
-            # determine model solutions at new grid points
-            results_gradient_tmp = com.run(model=model,
-                                           problem=problem,
-                                           coords=ten2mat(grid.coords_gradient[gradient_idx_compute, :, :]),
-                                           coords_norm=ten2mat(grid.coords_gradient_norm[gradient_idx_compute, :, :]),
-                                           i_iter=i_iter,
-                                           i_subiter=i_subiter,
-                                           fn_results=None,
-                                           print_func_time=print_func_time,
-                                           increment_grid=False,
-                                           verbose=verbose)
-
-            # distance tensor
-            delta = np.repeat(np.linalg.norm(
-                ten2mat(grid.coords_gradient_norm[gradient_idx_compute, :, :]) - \
-                ten2mat(np.repeat(grid.coords_norm[gradient_idx_compute, :, np.newaxis], problem.dim, axis=2)),
-                axis=1)[:, np.newaxis], results_gradient_tmp.shape[1], axis=1)
-
-            # determine gradient
-            gradient_results_new = (ten2mat(np.repeat(results[gradient_idx_compute, :, np.newaxis],
-                                                      problem.dim, axis=2)) - results_gradient_tmp) / delta
-
-            gradient_results_new = mat2ten(mat=gradient_results_new, incr=problem.dim)
-
-            gradient_results_idx = np.hstack((gradient_idx_skip, gradient_idx_compute)).astype(int)
-
-        #########################################################
-        # Finite difference approximation (1st order accuracy)  #
-        #########################################################
-        elif method == "FD_1st":
-            delta = dx
-
-            # number of sampling points to sacrifice for 2nd order accuracy
-            gradient_results_idx_can_compute = []
-
-            for i, x0 in enumerate(grid.coords_norm):
-
-                # determine neighbors within radius delta
-                mask = np.linalg.norm(grid.coords_norm-x0, axis=1) < delta
-                mask[i] = False
-
-                # only determine gradient if we have enough neighboring sampling points
-                # and if it was not computed previously
-                if np.sum(mask) >= problem.dim and i in gradient_idx_compute:
-                    gradient_results_idx_can_compute.append(i)
-
-            # determine gradient not in skipped points
-            gradient_results_idx_can_compute = np.array(gradient_results_idx_can_compute)
-
-            if gradient_results_idx_can_compute.any():
-                gradient_results_new = FD_1st(coords_norm=grid.coords_norm,
-                                              coord_idx=gradient_results_idx_can_compute,
-                                              results=results,
-                                              dx=dx,
-                                              distance_weight=distance_weight)
-
-            gradient_results_idx = np.hstack((gradient_idx_skip, gradient_results_idx_can_compute)).astype(int)
-
-        #########################################################
-        # Finite difference approximation (2nd order accuracy)  #
-        #########################################################
-        elif method == "FD_2nd":
-            delta = dx
-
-            # number of sampling points to sacrifice for 2nd order accuracy
-            n_2nd_order = np.sum(np.arange(problem.dim+1))
-            gradient_results_idx_can_compute = []
-
-            for i, x0 in enumerate(grid.coords_norm):
-
-                # determine neighbors within radius delta
-                mask = np.linalg.norm(grid.coords_norm-x0, axis=1) < delta
-                mask[i] = False
-
-                # only determine gradient if we have enough neighboring sampling points
-                # and if it was not computed previously
-                if np.sum(mask) >= (n_2nd_order + problem.dim) and i in gradient_idx_compute:
-                    gradient_results_idx_can_compute.append(i)
-
-            # determine gradient not in skipped points
-            gradient_results_idx_can_compute = np.array(gradient_results_idx_can_compute)
-
-            if gradient_results_idx_can_compute.any():
-                gradient_results_new = FD_2nd(coords_norm=grid.coords_norm,
-                                              coord_idx=gradient_results_idx_can_compute,
-                                              results=results,
-                                              dx=dx,
-                                              distance_weight=distance_weight)
-
-            gradient_results_idx = np.hstack((gradient_idx_skip, gradient_results_idx_can_compute)).astype(int)
-
-        #################################################################
-        # Finite difference approximation (1st and 2nd order accuracy)  #
-        #################################################################
-        elif method == "FD_1st2nd":
-            delta = dx
-
-            # number of sampling points to sacrifice for 2nd order accuracy
-            n_2nd_order = np.sum(np.arange(problem.dim+1))
-            coord_idx_1st = []
-            coord_idx_2nd = []
-
-            for i, x0 in enumerate(grid.coords_norm):
-
-                # determine neighbors within radius delta
-                mask = np.linalg.norm(grid.coords_norm-x0, axis=1) < delta
-                mask[i] = False
-
-                # choose method depending on number of neighboring sampling points
-                # and if it was not computed previously
-                if np.sum(mask) >= (n_2nd_order + problem.dim) and i in gradient_idx_compute:
-                    coord_idx_2nd.append(i)
-                elif np.sum(mask) >= problem.dim and i in gradient_idx_compute:
-                    coord_idx_1st.append(i)
-
-            coord_idx_1st = np.array(coord_idx_1st)
-            coord_idx_2nd = np.array(coord_idx_2nd)
-
-            # estimate gradients with 1st order accuracy
-            gradient_results_1st = None
-            if coord_idx_1st.any():
-                gradient_results_1st = FD_1st(coords_norm=grid.coords_norm,
-                                              coord_idx=coord_idx_1st,
-                                              results=results,
-                                              dx=dx,
-                                              distance_weight=distance_weight)
-
-            # estimate gradients with 2nd order accuracy
-            gradient_results_2nd = None
-            if coord_idx_2nd.any():
-                gradient_results_2nd = FD_2nd(coords_norm=grid.coords_norm,
-                                              coord_idx=coord_idx_2nd,
-                                              results=results,
-                                              dx=dx,
-                                              distance_weight=distance_weight)
-
-            # concatenate results
-            if gradient_results_1st is not None and gradient_results_2nd is not None:
-                gradient_results_new = np.vstack((gradient_results_1st, gradient_results_2nd))
-            elif gradient_results_1st is not None and gradient_results_2nd is None:
-                gradient_results_new = gradient_results_1st
-            elif gradient_results_1st is not None and gradient_results_2nd is None:
-                gradient_results_new = gradient_results_2nd
-
-            gradient_results_idx = np.hstack((gradient_idx_skip, coord_idx_1st, coord_idx_2nd)).astype(int)
-
-        else:
-            raise NotImplementedError("Please provide a valid gradient estimation method!")
-
-    # concatenate old with new results
-    if gradient_results_present is not None and gradient_results_new is not None:
-        gradient_results = np.vstack((gradient_results_present, gradient_results_new))
-    elif gradient_results_present is None and gradient_results_new is not None:
-        gradient_results = gradient_results_new
-    elif gradient_results_present is not None and gradient_results_new is None:
-        gradient_results = gradient_results_present
-    else:
-        gradient_results = None
-
-    if gradient_results_idx.size == 0:
-        gradient_results_idx = None
-
-    return gradient_results, gradient_results_idx
-
-
-def FD_1st(coords_norm, coord_idx, results, dx, distance_weight):
-    """
-    Determines the gradients of "results" in coords_norm[coords_idx, :] using a finite difference
-    regression approach of first order accuracy.
-
-    Parameters
-    ----------
-    coords_norm : ndarray of float [n_grid x dim]
-        Normalized coordinates xi
-    coord_idx : ndarray of int [n_coords_idx]
-        Indices of coordinates (row idx in coords_norm) where the gradient has to be computed
-    results : ndarray of float [n_grid x n_qoi]
-        QOI results of the model at grid points
-    dx : float, optional, default: 1e-3
-        Radius around grid points to include adjacent grid-points in gradient approximation
-    distance_weight : float, optional, default: 1
-        Distance weight factor (exponent) adjacent grid points
-
-    Returns
-    -------
-    gradient_results : ndarray of float [n_coords_idx x n_qoi x dim]
-        Gradient of model function in grid points
-    """
-
-    n_dim = coords_norm.shape[1]
-    gradient_results = np.zeros((len(coord_idx), results.shape[1], n_dim))*np.nan
-
-    for i, i_c in enumerate(coord_idx):
-        x0 = coords_norm[i_c, :]
-
-        # determine neighbors within radius dx
-        mask = np.linalg.norm(coords_norm-x0, axis=1) < dx
-        mask[i_c] = False
-
-        coords_norm_selected = coords_norm[mask, ]
-
-        # distance matrix (1st order)
-        D = coords_norm_selected-x0
-
-        # rhs
-        df = results[mask, ]-results[i_c, ]
-
-        # weight matrix (distance**distance_weight)
-        W = np.diag(np.linalg.norm(D, axis=1)**distance_weight)
-
-        # apply weight matrix
-        D = np.matmul(W, D)
-        df = np.matmul(W, df)
-
-        # gradient [n_grid x n_out x dim]
-        gradient_results[i, :, :] = np.matmul(np.linalg.pinv(D), df).transpose()
-
-    return gradient_results
-
-
-def FD_2nd(coords_norm, coord_idx, results, dx, distance_weight):
-    """
-    Determines the gradients of "results" in coords_norm[coords_idx, :] using a finite difference
-    regression approach of second order accuracy.
-
-    Parameters
-    ----------
-    coords_norm : ndarray of float [n_grid x dim]
-        Normalized coordinates xi
-    coord_idx : ndarray of int [n_coords_idx]
-        Indices of coordinates (row idx in coords_norm) where the gradient has to be computed
-    results : ndarray of float [n_grid x n_qoi]
-        QOI results of the model at grid points
-    dx : float, optional, default: 1e-3
-        Radius around grid points to include adjacent grid-points in gradient approximation
-    distance_weight : float, optional, default: 1
-        Distance weight factor (exponent) adjacent grid points.
-
-    Returns
-    -------
-    gradient_results : ndarray of float [n_coords_idx x n_qoi x dim]
-        Gradient of model function in grid points
-    """
-    n_dim = coords_norm.shape[1]
-    gradient_results = np.zeros((len(coord_idx), results.shape[1], n_dim))*np.nan
-
-    # number of sampling points to sacrifice for 2nd order accuracy
-    n_2nd_order = np.sum(np.arange(coords_norm.shape[1]+1))
-
-    for i, i_c in enumerate(coord_idx):
-        x0 = coords_norm[i_c, :]
-
-        # determine neighbors within radius dx
-        mask = np.linalg.norm(coords_norm-x0, axis=1) < dx
-        mask[i_c] = False
-
-        coords_norm_selected = coords_norm[mask, ]
-
-        # distance matrix (1st order)
-        D = coords_norm_selected-x0
-
-        # distance matrix (2nd order)
-        M = np.zeros((coords_norm_selected.shape[0], n_2nd_order))
-
-        # quadratic terms
-        for i_dim in range(n_dim):
-            M[:, i_dim] = 0.5 * (coords_norm_selected[:, i_dim]-x0[i_dim])**2
-
-        # mixed linear terms
-        idx = get_all_combinations(np.arange(n_dim), 2)
-
-        for j, idx_row in enumerate(idx):
-            M[:, j+n_dim] = (coords_norm_selected[:, idx_row[0]] - x0[idx_row[0]]) * \
-                            (coords_norm_selected[:, idx_row[1]] - x0[idx_row[1]])
-
-        # rhs
-        df = results[mask, ]-results[i_c, ]
-
-        # weight matrix (distance**distance_weight)
-        W = np.diag(np.linalg.norm(D, axis=1)**distance_weight)
-
-        # apply weight matrix
-        D = np.matmul(W, D)
-        M = np.matmul(W, M)
-        df = np.matmul(W, df)
-
-        # derive orthogonal reduction of M
-        Q, T = np.linalg.qr(M, mode="complete")
-
-        # gradient [n_grid x n_out x dim]
-        QtD_inv = np.linalg.pinv(np.matmul(Q.transpose(), D)[n_2nd_order:, ])
-
-        rhs = np.matmul(Q.transpose(), df)[n_2nd_order:, ]
-
-        gradient_results[i, :, :] = np.matmul(QtD_inv, rhs).transpose()
-
-    return gradient_results
+import numpy as np
+from .misc import ten2mat
+from .misc import mat2ten
+from .misc import get_all_combinations
+
+
+def get_gradient(model, problem, grid, results, com,  method="FD_fwd",
+                 gradient_results_present=None, gradient_idx_skip=None,
+                 i_iter=None, i_subiter=None, print_func_time=False,
+                 dx=1e-3, distance_weight=-1, verbose=False):
+    """
+    Determines the gradient of the model function in the grid points (self.grid.coords).
+    The method to determine the gradient can be specified in self.options["gradient_calculation"].
+    The new gradients and their indices are appended to the old results given in gradient_results_present and
+    gradient_idx_skip.
+
+    Parameters
+    ----------
+    model: Model object
+        Model object instance of model to investigate (derived from AbstractModel class, implemented by user)
+    problem: Problem class instance
+        GPC Problem under investigation
+    grid : Grid object
+        Grid object
+    results : ndarray of float [n_grid x n_out]
+        Results of model function in grid points
+    com : Computation class instance
+        Computation class instance to run the computations
+    method : str, optional, default: "FD_fwd"
+        Gradient calculation method:
+        - "FD_fwd": Finite difference forward approximation of the gradient using n_grid x dim additional sampling
+        points stored in self.grid.coords_gradient and self.grid.coords_gradient_norm [n_grid x dim x dim].
+        - "FD_1st": Finite difference approximation of 1st order accuracy using only the available samples [1]
+        - "FD_2nd": Finite difference approximation of 2nd order accuracy using only the available samples [1]
+        - "FD_1st2nd": Finite difference approximation of 1st and (where possible) 2nd order accuracy
+        using only the available samples [1]
+    gradient_results_present : ndarray of float [n_grid_old x n_out x dim], optional, default: None
+        Gradient of model function in grid points, already determined in previous calculations.
+        Those values will not be updated!
+    gradient_idx_skip: ndarray of int [n_gradient_results.shape[0]]
+        Indices of grid points where the gradient was already computed and is provided in gradient_results.
+        Those grid points will be skipped.
+    i_iter : int (optional, default: None)
+        Current iteration
+    i_subiter : int (optional, default: None)
+        Current sub-iteration
+    dx : float, optional, default: 1e-3
+        Distance parameter, depending on applied method:
+        - "FW_fwd": Distance of new grid-points in each dim from orig. grid points to compute forward approximation
+        - "FW_1st": Radius around grid points to include adjacent grid-points in 1st order gradient approximation
+        - "FW_2nd": Radius around grid points to include adjacent grid-points in 1st order gradient approximation
+    distance_weight : float, optional, default: 1
+        Distance weight factor (exponent) for methods "FD_1st" and "FD_2nd".
+        Defines the importance of the adjacent grid points to estimate the gradient by their distance.
+    verbose : bool, optional, default: False
+        Print progress
+
+    Returns
+    -------
+    gradient_results : ndarray of float [n_grid x n_out x dim]
+        Gradient of model function in grid points
+    gradient_results_idx : ndarray of int [n_grid]
+        Indices of grid points where the gradient was evaluated
+
+    Notes
+    -----
+    .. [1] Belward J, Turner IW, Ilic M, On derivative estimation and the solution of least squares problems,
+       Journal of Computational and Applied Mathematics 2008, vol. 222, pp. 511-523.
+    """
+    gradient_results_new = None
+
+    if gradient_results_present is not None:
+        n_gradient_results = gradient_results_present.shape[0]
+    else:
+        n_gradient_results = 0
+
+    if gradient_idx_skip is None:
+        gradient_idx_skip = np.array([])
+
+    gradient_idx_compute = np.arange(grid.coords.shape[0])
+
+    if gradient_idx_skip is not None:
+        gradient_idx_compute = np.delete(gradient_idx_compute, gradient_idx_skip.astype(int))
+
+    if n_gradient_results < results.shape[0]:
+        #########################################
+        # Standard forward gradient calculation #
+        #########################################
+        if method == "FD_fwd":
+
+            # add new grid points for gradient calculation in grid.coords_gradient and grid.coords_gradient_norm
+            grid.create_gradient_grid(delta=dx)
+
+            # determine model solutions at new grid points
+            results_gradient_tmp = com.run(model=model,
+                                           problem=problem,
+                                           coords=ten2mat(grid.coords_gradient[gradient_idx_compute, :, :]),
+                                           coords_norm=ten2mat(grid.coords_gradient_norm[gradient_idx_compute, :, :]),
+                                           i_iter=i_iter,
+                                           i_subiter=i_subiter,
+                                           fn_results=None,
+                                           print_func_time=print_func_time,
+                                           increment_grid=False,
+                                           verbose=verbose)
+
+            # distance tensor
+            delta = np.repeat(np.linalg.norm(
+                ten2mat(grid.coords_gradient_norm[gradient_idx_compute, :, :]) - \
+                ten2mat(np.repeat(grid.coords_norm[gradient_idx_compute, :, np.newaxis], problem.dim, axis=2)),
+                axis=1)[:, np.newaxis], results_gradient_tmp.shape[1], axis=1)
+
+            # determine gradient
+            gradient_results_new = (ten2mat(np.repeat(results[gradient_idx_compute, :, np.newaxis],
+                                                      problem.dim, axis=2)) - results_gradient_tmp) / delta
+
+            gradient_results_new = mat2ten(mat=gradient_results_new, incr=problem.dim)
+
+            gradient_results_idx = np.hstack((gradient_idx_skip, gradient_idx_compute)).astype(int)
+
+        #########################################################
+        # Finite difference approximation (1st order accuracy)  #
+        #########################################################
+        elif method == "FD_1st":
+            delta = dx
+
+            # number of sampling points to sacrifice for 2nd order accuracy
+            gradient_results_idx_can_compute = []
+
+            for i, x0 in enumerate(grid.coords_norm):
+
+                # determine neighbors within radius delta
+                mask = np.linalg.norm(grid.coords_norm-x0, axis=1) < delta
+                mask[i] = False
+
+                # only determine gradient if we have enough neighboring sampling points
+                # and if it was not computed previously
+                if np.sum(mask) >= problem.dim and i in gradient_idx_compute:
+                    gradient_results_idx_can_compute.append(i)
+
+            # determine gradient not in skipped points
+            gradient_results_idx_can_compute = np.array(gradient_results_idx_can_compute)
+
+            if gradient_results_idx_can_compute.any():
+                gradient_results_new = FD_1st(coords_norm=grid.coords_norm,
+                                              coord_idx=gradient_results_idx_can_compute,
+                                              results=results,
+                                              dx=dx,
+                                              distance_weight=distance_weight)
+
+            gradient_results_idx = np.hstack((gradient_idx_skip, gradient_results_idx_can_compute)).astype(int)
+
+        #########################################################
+        # Finite difference approximation (2nd order accuracy)  #
+        #########################################################
+        elif method == "FD_2nd":
+            delta = dx
+
+            # number of sampling points to sacrifice for 2nd order accuracy
+            n_2nd_order = np.sum(np.arange(problem.dim+1))
+            gradient_results_idx_can_compute = []
+
+            for i, x0 in enumerate(grid.coords_norm):
+
+                # determine neighbors within radius delta
+                mask = np.linalg.norm(grid.coords_norm-x0, axis=1) < delta
+                mask[i] = False
+
+                # only determine gradient if we have enough neighboring sampling points
+                # and if it was not computed previously
+                if np.sum(mask) >= (n_2nd_order + problem.dim) and i in gradient_idx_compute:
+                    gradient_results_idx_can_compute.append(i)
+
+            # determine gradient not in skipped points
+            gradient_results_idx_can_compute = np.array(gradient_results_idx_can_compute)
+
+            if gradient_results_idx_can_compute.any():
+                gradient_results_new = FD_2nd(coords_norm=grid.coords_norm,
+                                              coord_idx=gradient_results_idx_can_compute,
+                                              results=results,
+                                              dx=dx,
+                                              distance_weight=distance_weight)
+
+            gradient_results_idx = np.hstack((gradient_idx_skip, gradient_results_idx_can_compute)).astype(int)
+
+        #################################################################
+        # Finite difference approximation (1st and 2nd order accuracy)  #
+        #################################################################
+        elif method == "FD_1st2nd":
+            delta = dx
+
+            # number of sampling points to sacrifice for 2nd order accuracy
+            n_2nd_order = np.sum(np.arange(problem.dim+1))
+            coord_idx_1st = []
+            coord_idx_2nd = []
+
+            for i, x0 in enumerate(grid.coords_norm):
+
+                # determine neighbors within radius delta
+                mask = np.linalg.norm(grid.coords_norm-x0, axis=1) < delta
+                mask[i] = False
+
+                # choose method depending on number of neighboring sampling points
+                # and if it was not computed previously
+                if np.sum(mask) >= (n_2nd_order + problem.dim) and i in gradient_idx_compute:
+                    coord_idx_2nd.append(i)
+                elif np.sum(mask) >= problem.dim and i in gradient_idx_compute:
+                    coord_idx_1st.append(i)
+
+            coord_idx_1st = np.array(coord_idx_1st)
+            coord_idx_2nd = np.array(coord_idx_2nd)
+
+            # estimate gradients with 1st order accuracy
+            gradient_results_1st = None
+            if coord_idx_1st.any():
+                gradient_results_1st = FD_1st(coords_norm=grid.coords_norm,
+                                              coord_idx=coord_idx_1st,
+                                              results=results,
+                                              dx=dx,
+                                              distance_weight=distance_weight)
+
+            # estimate gradients with 2nd order accuracy
+            gradient_results_2nd = None
+            if coord_idx_2nd.any():
+                gradient_results_2nd = FD_2nd(coords_norm=grid.coords_norm,
+                                              coord_idx=coord_idx_2nd,
+                                              results=results,
+                                              dx=dx,
+                                              distance_weight=distance_weight)
+
+            # concatenate results
+            if gradient_results_1st is not None and gradient_results_2nd is not None:
+                gradient_results_new = np.vstack((gradient_results_1st, gradient_results_2nd))
+            elif gradient_results_1st is not None and gradient_results_2nd is None:
+                gradient_results_new = gradient_results_1st
+            elif gradient_results_1st is not None and gradient_results_2nd is None:
+                gradient_results_new = gradient_results_2nd
+
+            gradient_results_idx = np.hstack((gradient_idx_skip, coord_idx_1st, coord_idx_2nd)).astype(int)
+
+        else:
+            raise NotImplementedError("Please provide a valid gradient estimation method!")
+
+    # concatenate old with new results
+    if gradient_results_present is not None and gradient_results_new is not None:
+        gradient_results = np.vstack((gradient_results_present, gradient_results_new))
+    elif gradient_results_present is None and gradient_results_new is not None:
+        gradient_results = gradient_results_new
+    elif gradient_results_present is not None and gradient_results_new is None:
+        gradient_results = gradient_results_present
+    else:
+        gradient_results = None
+
+    if gradient_results_idx.size == 0:
+        gradient_results_idx = None
+
+    return gradient_results, gradient_results_idx
+
+
+def FD_1st(coords_norm, coord_idx, results, dx, distance_weight):
+    """
+    Determines the gradients of "results" in coords_norm[coords_idx, :] using a finite difference
+    regression approach of first order accuracy.
+
+    Parameters
+    ----------
+    coords_norm : ndarray of float [n_grid x dim]
+        Normalized coordinates xi
+    coord_idx : ndarray of int [n_coords_idx]
+        Indices of coordinates (row idx in coords_norm) where the gradient has to be computed
+    results : ndarray of float [n_grid x n_qoi]
+        QOI results of the model at grid points
+    dx : float, optional, default: 1e-3
+        Radius around grid points to include adjacent grid-points in gradient approximation
+    distance_weight : float, optional, default: 1
+        Distance weight factor (exponent) adjacent grid points
+
+    Returns
+    -------
+    gradient_results : ndarray of float [n_coords_idx x n_qoi x dim]
+        Gradient of model function in grid points
+    """
+
+    n_dim = coords_norm.shape[1]
+    gradient_results = np.zeros((len(coord_idx), results.shape[1], n_dim))*np.nan
+
+    for i, i_c in enumerate(coord_idx):
+        x0 = coords_norm[i_c, :]
+
+        # determine neighbors within radius dx
+        mask = np.linalg.norm(coords_norm-x0, axis=1) < dx
+        mask[i_c] = False
+
+        coords_norm_selected = coords_norm[mask, ]
+
+        # distance matrix (1st order)
+        D = coords_norm_selected-x0
+
+        # rhs
+        df = results[mask, ]-results[i_c, ]
+
+        # weight matrix (distance**distance_weight)
+        W = np.diag(np.linalg.norm(D, axis=1)**distance_weight)
+
+        # apply weight matrix
+        D = np.matmul(W, D)
+        df = np.matmul(W, df)
+
+        # gradient [n_grid x n_out x dim]
+        gradient_results[i, :, :] = np.matmul(np.linalg.pinv(D), df).transpose()
+
+    return gradient_results
+
+
+def FD_2nd(coords_norm, coord_idx, results, dx, distance_weight):
+    """
+    Determines the gradients of "results" in coords_norm[coords_idx, :] using a finite difference
+    regression approach of second order accuracy.
+
+    Parameters
+    ----------
+    coords_norm : ndarray of float [n_grid x dim]
+        Normalized coordinates xi
+    coord_idx : ndarray of int [n_coords_idx]
+        Indices of coordinates (row idx in coords_norm) where the gradient has to be computed
+    results : ndarray of float [n_grid x n_qoi]
+        QOI results of the model at grid points
+    dx : float, optional, default: 1e-3
+        Radius around grid points to include adjacent grid-points in gradient approximation
+    distance_weight : float, optional, default: 1
+        Distance weight factor (exponent) adjacent grid points.
+
+    Returns
+    -------
+    gradient_results : ndarray of float [n_coords_idx x n_qoi x dim]
+        Gradient of model function in grid points
+    """
+    n_dim = coords_norm.shape[1]
+    gradient_results = np.zeros((len(coord_idx), results.shape[1], n_dim))*np.nan
+
+    # number of sampling points to sacrifice for 2nd order accuracy
+    n_2nd_order = np.sum(np.arange(coords_norm.shape[1]+1))
+
+    for i, i_c in enumerate(coord_idx):
+        x0 = coords_norm[i_c, :]
+
+        # determine neighbors within radius dx
+        mask = np.linalg.norm(coords_norm-x0, axis=1) < dx
+        mask[i_c] = False
+
+        coords_norm_selected = coords_norm[mask, ]
+
+        # distance matrix (1st order)
+        D = coords_norm_selected-x0
+
+        # distance matrix (2nd order)
+        M = np.zeros((coords_norm_selected.shape[0], n_2nd_order))
+
+        # quadratic terms
+        for i_dim in range(n_dim):
+            M[:, i_dim] = 0.5 * (coords_norm_selected[:, i_dim]-x0[i_dim])**2
+
+        # mixed linear terms
+        idx = get_all_combinations(np.arange(n_dim), 2)
+
+        for j, idx_row in enumerate(idx):
+            M[:, j+n_dim] = (coords_norm_selected[:, idx_row[0]] - x0[idx_row[0]]) * \
+                            (coords_norm_selected[:, idx_row[1]] - x0[idx_row[1]])
+
+        # rhs
+        df = results[mask, ]-results[i_c, ]
+
+        # weight matrix (distance**distance_weight)
+        W = np.diag(np.linalg.norm(D, axis=1)**distance_weight)
+
+        # apply weight matrix
+        D = np.matmul(W, D)
+        M = np.matmul(W, M)
+        df = np.matmul(W, df)
+
+        # derive orthogonal reduction of M
+        Q, T = np.linalg.qr(M, mode="complete")
+
+        # gradient [n_grid x n_out x dim]
+        QtD_inv = np.linalg.pinv(np.matmul(Q.transpose(), D)[n_2nd_order:, ])
+
+        rhs = np.matmul(Q.transpose(), df)[n_2nd_order:, ]
+
+        gradient_results[i, :, :] = np.matmul(QtD_inv, rhs).transpose()
+
+    return gradient_results
```

## pygpc/Grid.py

 * *Ordering differences only*

```diff
@@ -1,3882 +1,3882 @@
-import uuid
-import copy
-import warnings
-import scipy.stats
-import numpy as np
-from tqdm import tqdm
-from .io import iprint
-from .Quadrature import *
-from scipy.special import gamma
-from scipy.optimize import minimize
-from .RandomParameter import Beta
-from .RandomParameter import Norm
-from .misc import compute_chunks
-from .misc import mutual_coherence
-from .misc import get_multi_indices
-from .misc import get_cartesian_product
-from .misc import squared_exponential_kernel
-from .misc import t_averaged_mutual_coherence
-from .misc import average_cross_correlation_gram
-from .misc import get_different_rows_from_matrices
-
-import multiprocessing.pool
-from _functools import partial
-
-warnings.filterwarnings('ignore')
-
-class Grid(object):
-    """
-    Grid class
-
-    Parameters
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    weights: ndarray of float [n_grid x dim]
-        Weights of the grid (all)
-    coords: ndarray of float [n_grid x dim]
-        Denormalized coordinates xi
-    coords_norm: ndarray of float [n_grid x dim]
-        Normalized coordinates xi
-    coords_gradient: ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm: ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id: list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-
-    Attributes
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    _weights: ndarray of float [n_grid x dim]
-        Weights of the grid (all)
-    _coords: ndarray of float [n_grid x dim]
-        Denormalized coordinates xi
-    _coords_norm: ndarray of float [n_grid x dim]
-        Normalized coordinates xi
-    _domains: ndarray of float [n_grid]
-        Domain IDs of grid points for multi-element gPC
-    _coords_gradient: ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    _coords_gradient_norm: ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id: list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    n_grid: int
-        Total number of nodes in grid.
-    """
-    def __init__(self, parameters_random, coords=None, coords_norm=None,
-                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None,
-                 grid_pre=None):
-        """
-        Constructor; Initialize Grid class
-        """
-        self._coords = coords                         # Coordinates of gpc model calculation in the system space
-        self._coords_norm = coords_norm               # Coordinates of gpc model calculation in the gpc space
-        self.coords_id = coords_id                    # Unique IDs of grid points
-        self.coords_gradient_id = coords_gradient_id  # Unique IDs of grid gradient points
-        self._weights = None                          # Weights for numerical integration
-        self.parameters_random = parameters_random    # OrderedDict of RandomParameter instances
-        self.dim = len(self.parameters_random)        # Number of random variables
-        self._coords_gradient = coords_gradient       # Shifted coordinates for gradient calculation in the system space
-        self._coords_gradient_norm = coords_gradient_norm  # Normalized coordinates for gradient calculation
-        self.grid_pre = grid_pre                      # Previous grid the new grid is based on
-
-        if coords is not None:
-            self.n_grid = self.coords.shape[0]                    # Total number of grid points
-
-        if coords_gradient is not None:
-            self.n_grid_gradient = self.coords_gradient.shape[0]  # Total number of grid points for gradient calculation
-
-        if coords_id is None and coords is not None:
-            self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
-            self.n_grid = self._coords.shape[0]
-
-        if coords_gradient_id is None and coords_gradient is not None:
-            self.coords_gradient_id = [uuid.uuid4() for _ in range(self.n_grid)]
-            self.n_grid_gradient = self._coords_gradient.shape[0]
-
-        if coords is not None and coords_norm is None:
-            self.coords_norm = self.get_normalized_coordinates(self.coords)
-
-    @property
-    def coords(self):
-        return self._coords
-
-    @coords.setter
-    def coords(self, value):
-        if value.ndim == 1:
-            value = value[np.newaxis, :]
-
-        self._coords = value
-
-        if value is not None:
-            self.n_grid = self._coords.shape[0]
-
-            # Generate unique IDs of grid points
-            if self.coords_id is None:
-                self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
-
-    @property
-    def coords_norm(self):
-        return self._coords_norm
-
-    @coords_norm.setter
-    def coords_norm(self, value):
-        if value.ndim == 1:
-            value = value[np.newaxis, :]
-
-        self._coords_norm = value
-
-        if value is not None:
-            self.n_grid = self._coords_norm.shape[0]
-
-            # Generate unique IDs of grid points
-            if self.coords_id is None:
-                self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
-
-    @property
-    def coords_gradient(self):
-        return self._coords_gradient
-
-    @coords_gradient.setter
-    def coords_gradient(self, value):
-        assert value.ndim == 3, "Specify coords_gradient as 3D tensor of shape [n_grid x dim x dim]"
-
-        self._coords_gradient = value
-
-        if value is not None:
-            self.n_grid_gradient = self._coords_gradient.shape[0]
-
-            # Generate unique IDs of grid gradient points
-            if self.coords_gradient_id is None:
-                self.coords_gradient_id = [uuid.uuid4() for _ in range(self.n_grid_gradient)]
-
-    @property
-    def coords_gradient_norm(self):
-        return self._coords_gradient_norm
-
-    @coords_gradient_norm.setter
-    def coords_gradient_norm(self, value):
-        assert value.ndim == 3, "Specify coords_gradient_norm as 3D tensor of shape [n_grid x dim x dim]"
-        self._coords_gradient_norm = value
-
-        if value is not None:
-            self.n_grid_gradient = self._coords_gradient_norm.shape[0]
-
-            # Generate unique IDs of grid gradient points
-            if self.coords_gradient_id is None:
-                self.coords_gradient_id = [uuid.uuid4() for _ in range(self.n_grid_gradient)]
-
-    @property
-    def weights(self):
-        return self._weights
-
-    @weights.setter
-    def weights(self, value):
-        self._weights = value
-
-    def get_denormalized_coordinates(self, coords_norm):
-        """
-        Denormalize grid from normalized to original parameter space for simulations.
-
-        coords = Grid.get_denormalized_coordinates(coords_norm)
-
-        Parameters
-        ----------
-        coords_norm: [N_samples x dim] np.ndarray
-            Normalized coordinates xi
-
-        Returns
-        -------
-        coords: [N_samples x dim] np.ndarray
-            Denormalized coordinates xi
-        """
-        coords = np.zeros(coords_norm.shape)
-
-        for i_p, p in enumerate(self.parameters_random):
-
-            if self.parameters_random[p].pdf_type == "beta":
-                coords[:, i_p, ] = (coords_norm[:, i_p, ] + 1) / \
-                                   2 * (self.parameters_random[p].pdf_limits[1] -
-                                        self.parameters_random[p].pdf_limits[0]) \
-                                   + self.parameters_random[p].pdf_limits[0]
-
-            if self.parameters_random[p].pdf_type in ["norm", "normal"]:
-                coords[:, i_p, ] = coords_norm[:, i_p, ] * self.parameters_random[p].pdf_shape[1] + \
-                                   self.parameters_random[p].pdf_shape[0]
-
-            if self.parameters_random[p].pdf_type in ["gamma"]:
-                coords[:, i_p, ] = coords_norm[:, i_p, ] / self.parameters_random[p].pdf_shape[1] + \
-                                   self.parameters_random[p].pdf_shape[2]
-
-        return coords
-
-    def get_normalized_coordinates(self, coords):
-        """
-        Normalize grid from original parameter to normalized space for simulations.
-
-        coords_norm = Grid.get_normalized_coordinates(coords)
-
-        Parameters
-        ----------
-        coords : [N_samples x dim] np.ndarray
-            Denormalized coordinates xi in original parameter space
-
-        Returns
-        -------
-        coords_norm : [N_samples x dim] np.ndarray
-            Normalized coordinates xi
-        """
-        coords_norm = np.zeros(coords.shape)
-
-        for i_p, p in enumerate(self.parameters_random):
-
-            if self.parameters_random[p].pdf_type == "beta":
-                coords_norm[:, i_p] = (coords[:, i_p] - self.parameters_random[p].pdf_limits[0])
-                coords_norm[:, i_p] = coords_norm[:, i_p] / \
-                                      (self.parameters_random[p].pdf_limits[1] -
-                                       self.parameters_random[p].pdf_limits[0]) * \
-                                      2.0 - 1
-
-            if self.parameters_random[p].pdf_type in ["norm", "normal"]:
-                coords_norm[:, i_p] = (coords[:, i_p] - self.parameters_random[p].pdf_shape[0]) / \
-                                      self.parameters_random[p].pdf_shape[1]
-
-            if self.parameters_random[p].pdf_type in ["gamma"]:
-                coords_norm[:, i_p] = (coords[:, i_p] - self.parameters_random[p].pdf_shape[2]) * \
-                                      self.parameters_random[p].pdf_shape[1]
-
-        return coords_norm
-
-    def create_gradient_grid(self, delta=1e-3):
-        """
-        Creates new grid points to determine gradient of model function.
-        Adds or updates self.coords_gradient, self.coords_gradient_norm and self.coords_gradient_id.
-
-        Parameters
-        ----------
-        delta : float, optional, default: 1e-3
-            Shift of grid-points along axes in normalized parameter space
-        """
-        # shift of gradient grid in normalized space
-        delta = delta * np.eye(self.dim)
-
-        # Create or update the gradient grid [n_grid x dim x dim]
-        if self.coords_gradient is not None:
-            n_grid_gradient = self.coords_gradient_norm.shape[0]
-            self.coords_gradient = np.vstack((self.coords_gradient,
-                                              np.zeros((self.n_grid-n_grid_gradient, self.dim, self.dim))))
-            self.coords_gradient_norm = np.vstack((self.coords_gradient_norm,
-                                                   np.zeros((self.n_grid-n_grid_gradient, self.dim, self.dim))))
-        else:
-            n_grid_gradient = 0
-            self.coords_gradient = np.zeros((self.n_grid, self.dim, self.dim))
-            self.coords_gradient_norm = np.zeros((self.n_grid, self.dim, self.dim))
-
-        if n_grid_gradient < self.coords_gradient.shape[0]:
-            # shift the grid
-            for i_dim in range(self.dim):
-                self.coords_gradient_norm[n_grid_gradient:, :, i_dim] = self.coords_norm[n_grid_gradient:, ] - \
-                                                                        delta[i_dim, :]
-
-            # determine coordinates in original parameter space
-            self.coords_gradient[n_grid_gradient:, :, :] = \
-                self.get_denormalized_coordinates(self.coords_gradient_norm[n_grid_gradient:, :, :])
-
-            # total number of grid points
-            self.n_grid_gradient = self.coords_gradient.shape[0]*self.coords_gradient.shape[2]
-
-            # Generate unique IDs of grid points [n_grid]
-            self.coords_gradient_id = copy.deepcopy(self.coords_id)
-
-
-class TensorGrid(Grid):
-    """
-    Generate TensorGrid object instance.
-
-    Parameters
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    options: dict
-        Grid options
-        - parameters["grid_type"] ... list of str [dim]: type of grid ('jacobi', 'hermite', 'cc', 'fejer2')
-        - parameters["n_dim"] ... list of int [dim]: Number of nodes in each dimension
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    knots_dim_list : list of float [dim][n_knots]
-        Knots of polynomials in each dimension
-    weights_dim_list : list of float [dim][n_knots]
-         Weights of polynomials in each dimension
-    weights : ndarray of float [n_grid]
-        Quadrature weights for each grid point
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> pygpc.TensorGrid(parameters_random, options={"grid_type": ["hermite", "jacobi"], "n_dim": [5, 6]})
-
-    Attributes
-    ----------
-    grid_type : [N_vars] list of str
-        Type of quadrature used to construct tensor grid ('jacobi', 'hermite', 'clenshaw_curtis', 'fejer2')
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    options: dict
-        Grid options
-        - parameters["grid_type"] ... list of str [dim]: type of grid ('jacobi', 'hermite', 'cc', 'fejer2')
-        - parameters["n_dim"] ... list of int [dim]: Number of nodes in each dimension
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    knots_dim_list : list of float [dim][n_knots]
-        Knots of polynomials in each dimension
-    weights_dim_list : list of float [dim][n_knots]
-         Weights of polynomials in each dimension
-    weights : ndarray of float [n_grid]
-        Quadrature weights for each grid point
-    """
-
-    def __init__(self, parameters_random, options, coords=None, coords_norm=None,
-                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None,
-                 knots_dim_list=None, weights_dim_list=None, weights=None):
-        """
-        Constructor; Initializes TensorGrid object instance; Generates grid
-        """
-        super(TensorGrid, self).__init__(parameters_random,
-                                         coords=coords,
-                                         coords_norm=coords_norm,
-                                         coords_gradient=coords_gradient,
-                                         coords_gradient_norm=coords_gradient_norm,
-                                         coords_id=coords_id,
-                                         coords_gradient_id=coords_gradient_id)
-        self.options = options
-        self.grid_type = options["grid_type"]
-        self.n_dim = options["n_dim"]
-
-        if coords is not None and coords_norm is not None:
-            grid_present = True
-
-            self.knots_dim_list = knots_dim_list
-            self.weights_dim_list = weights_dim_list
-            self.weights = weights
-
-        else:
-            grid_present = False
-
-        if not grid_present:
-
-            # get knots and weights of polynomials in each dimension
-            self.knots_dim_list = []
-            self.weights_dim_list = []
-
-            for i_p, p in enumerate(self.parameters_random):
-
-                # Jacobi polynomials
-                if self.grid_type[i_p] == 'jacobi':
-                    knots, weights = get_quadrature_jacobi_1d(self.n_dim[i_p],
-                                                              self.parameters_random[p].pdf_shape[0] - 1,
-                                                              self.parameters_random[p].pdf_shape[1] - 1,)
-
-                # Hermite polynomials
-                elif self.grid_type[i_p] == 'hermite':
-                    knots, weights = get_quadrature_hermite_1d(self.n_dim[i_p])
-
-                # Clenshaw Curtis
-                elif self.grid_type[i_p] in ['clenshaw_curtis' or 'cc']:
-                    knots, weights = get_quadrature_clenshaw_curtis_1d(self.n_dim[i_p])
-
-                # Fejer type 2 (Clenshaw Curtis without boundary nodes)
-                elif self.grid_type[i_p] == 'fejer2':
-                    knots, weights = get_quadrature_fejer2_1d(self.n_dim[i_p])
-
-                # Gauss-Patterson (Nested Legendre rule)
-                elif self.grid_type[i_p] == 'patterson':
-                    knots, weights = get_quadrature_patterson_1d(self.n_dim[i_p])
-
-                else:
-                    knots = []
-                    weights = []
-                    AttributeError("Specified grid_type {} not implemented!".format(self.grid_type[i_p]))
-
-                self.knots_dim_list.append(knots)
-                self.weights_dim_list.append(weights)
-
-            # combine coordinates to full tensor grid (all combinations)
-            # self.coords_norm = cartesian(self.knots_dim_list)
-            self.coords_norm = get_cartesian_product(self.knots_dim_list)
-
-            # rescale normalized coordinates in case of normal distributions and "fejer2" or "cc" grids
-            # +- 0.675 * sigma -> 50%
-            # +- 1.645 * sigma -> 90%
-            # +- 1.960 * sigma -> 95%
-            # +- 2.576 * sigma -> 99%
-            # +- 3.000 * sigma -> 99.73%
-            for i_p, p in enumerate(self.parameters_random):
-
-                if self.parameters_random[p].pdf_type in ["norm", "normal"] and (not(self.grid_type[i_p] == "hermite")):
-                    self.coords_norm[:, i_p] = self.coords_norm[:, i_p] * 1.960
-
-            # determine combined weights of Gauss quadrature
-            self.weights = np.prod(get_cartesian_product(self.weights_dim_list), axis=1) / (2.0 ** self.dim)
-
-            # denormalize grid to original parameter space
-            self.coords = self.get_denormalized_coordinates(self.coords_norm)
-
-            # Total number of nodes in grid
-            self.n_grid = self.coords.shape[0]
-
-            # Generate and append unique IDs of grid points
-            self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
-
-
-class SparseGrid(Grid):
-    """
-    SparseGrid object instance.
-
-    Parameters
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    options: dict
-        Grid parameters
-        - grid_type ([N_vars] list of str) ... Type of quadrature rule used to construct sparse grid
-          ('jacobi', 'hermite', 'clenshaw_curtis', 'fejer2', 'patterson')
-        - level ([N_vars] list of int) ... Number of levels in each dimension
-        - level_max (int) ... Global combined level maximum
-        - interaction_order (int) ...Interaction order of parameters and grid, i.e. the grid points are lying
-          between this number of dimensions
-        - order_sequence_type (str) ... Type of order sequence ('lin', 'exp') common: 'exp'
-        - make_grid (boolean, optional, default=True) ... Boolean value to determine if to generate grid
-          during initialization
-        - verbose (bool, optional, default=True) ... Print output messages into stdout
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    level_sequence: list of int
-        Integer sequence of levels
-    order_sequence: list of int
-        Integer sequence of polynomial order of levels
-    weights : ndarray of float [n_grid]
-        Quadrature weights for each grid point
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> grid = pygpc.SparseGrid(parameters_random=parameters_random,
-    >>>                         options={"grid_type": ["jacobi", "jacobi"],
-    >>>                                  "level": [3, 3],
-    >>>                                  "level_max": 3,
-    >>>                                  "interaction_order": 2,
-    >>>                                  "order_sequence_type": "exp"})
-
-    Attributes
-    ----------
-    grid_type: [N_vars] list of str
-        specify type of quadrature used to construct sparse grid ('jacobi', 'hermite', 'cc', 'fejer2')
-    level: [N_vars] list of int
-        number of levels in each dimension
-    level_max: int
-        global combined level maximum
-    level_sequence: list of int
-        list containing the levels
-    interaction_order: int
-        interaction order of parameters and grid, i.e. the grid points are lying between this number of dimensions
-    order_sequence_type: str
-        type of order sequence ('lin', 'exp') common: 'exp'
-    order_sequence: list of int
-        list containing the polynomial order of the levels
-    coords : ndarray of float [n_grid_add x dim]
-            Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    weights : ndarray of float [n_grid]
-            Quadrature weights for each grid point
-    verbose: bool
-        boolean value to determine if to print out the progress into the standard output
-    """
-
-    def __init__(self, parameters_random, options, coords=None, coords_norm=None,
-                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None,
-                 level_sequence=None, order_sequence=None, weights=None):
-        """
-        Constructor; Initializes SparseGrid class; Generates grid
-        """
-
-        super(SparseGrid, self).__init__(parameters_random,
-                                         coords=coords,
-                                         coords_norm=coords_norm,
-                                         coords_gradient=coords_gradient,
-                                         coords_gradient_norm=coords_gradient_norm,
-                                         coords_id=coords_id,
-                                         coords_gradient_id=coords_gradient_id)
-
-        self.grid_type = options["grid_type"]    # Quadrature rule ('jacobi', 'hermite', 'clenshaw_curtis', 'fejer2')
-        self.level = options["level"]            # Number of levels in each dimension [dim x 1]
-        self.level_max = options["level_max"]    # Global combined level maximum
-        self.interaction_order = options["interaction_order"]        # Interaction order of parameters and grid
-        self.order_sequence_type = options["order_sequence_type"]    # Order sequence ('lin', 'exp' (common))
-        self.level_sequence = []  # Integer sequence of levels
-        self.order_sequence = []  # Integer sequence of polynomial order of levels
-
-        # output while grid generation on/off
-        if "verbose" not in options.keys():
-            self.verbose = False
-
-        # Generate grid if not specified
-        if coords is not None and coords_norm is not None:
-            grid_present = True
-
-            self.level_sequence = level_sequence
-            self.order_sequence = order_sequence
-            self.weights = weights
-
-        else:
-            grid_present = False
-
-        # Grid is generated during initialization or coords, coords_norm and weights are added manually
-        if not grid_present:
-            self.calc_multi_indices()
-            self.calc_coords_weights()
-
-            # Determine total number of grid points
-            self.n_grid = self.coords.shape[0]
-
-            # Generate unique IDs of grid points
-            self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
-
-    def calc_multi_indices(self):
-        """
-        Calculate the multi index list needed for the calculation of the SparseGrid.
-        """
-        for i_p, p in enumerate(self.parameters_random):
-
-            if self.grid_type[i_p] == 'fejer2':
-                self.level_sequence.append([element for element in range(1, self.level[i_p] + 1)])
-
-            else:
-                self.level_sequence.append([element for element in range(self.level[i_p] + 1)])
-
-            if self.order_sequence_type == 'exp':         # order = 2**level + 1
-
-                if self.grid_type[i_p] == 'fejer2':       # start with order = 1 @ level = 1
-                    self.order_sequence.append((np.power(2, np.arange(1, self.level[i_p])) - 1).tolist())
-                    self.order_sequence[i_p][0] = 1
-
-                elif self.grid_type[i_p] == 'patterson':  # start with order = 1 @ level = 0 [1,3,7,15,31,...]
-                    self.order_sequence.append((np.power(2, np.arange(0, self.level[i_p])) + 1).tolist())
-
-                else:                                     # start with order = 1 @ level = 0
-                    self.order_sequence.append(
-                        (2 ** np.linspace(0, self.level[i_p], self.level[i_p] + 1) + 1).tolist())
-                    self.order_sequence[i_p][0] = 1
-
-            elif self.order_sequence_type == 'lin':       # order = level
-                if self.grid_type[i_p] == 'fejer2':       # start with level = 1 @ order = 1
-                    self.order_sequence.append(np.linspace(1, self.level[i_p] + 1, self.level[i_p] + 1).tolist())
-
-                elif self.grid_type[i_p] == 'patterson':  # start with order = 1 @ level = 0 [1,3,7,15,31,...]
-                    iprint("Not possible in case of Gauss-Patterson grid.", tab=0, verbose=self.verbose)
-
-                else:                                       # start with
-                    self.order_sequence.append(np.linspace(1, self.level[i_p] + 1, self.level[i_p] + 1).tolist())
-
-    def calc_l_level(self):
-        """
-        Calculate the l-level needed for the Fejer grid type 2.
-
-        l_level = calc_l_level()
-
-        Returns
-        -------
-        l_level: np.ndarray
-            Multi indices filtered by level capacity and interaction order
-        """
-        if "fejer2" in self.grid_type:
-            if self.dim == 1:
-                l_level = np.array([np.linspace(1, self.level_max, self.level_max)]).transpose()
-            else:
-                l_level = get_multi_indices(self.dim, self.level_max - self.dim)
-                l_level = l_level + 1
-        else:
-            if self.dim == 1:
-                l_level = np.array([np.linspace(0, self.level_max, self.level_max + 1)]).transpose()
-            else:
-                l_level = get_multi_indices(order=[self.level_max] * self.dim,
-                                            order_max=self.level_max,
-                                            interaction_order=self.dim,
-                                            order_max_norm=1.,
-                                            interaction_order_current=None)
-
-        # filter out rows exceeding the individual level cap
-        for i_p in range(self.dim):
-            l_level = l_level[l_level[:, i_p] <= self.level[i_p]]
-
-        # Consider interaction order (filter out multi-indices exceeding it)
-        if self.interaction_order < self.dim:
-            if any("fejer2" in s for s in self.grid_type):
-                l_level = l_level[np.sum(l_level > 1, axis=1) <= self.interaction_order, :]
-            else:
-                l_level = l_level[np.sum(l_level > 0, axis=1) <= self.interaction_order, :]
-
-        return l_level
-
-    def calc_grid(self):
-        """
-        Calculate a cubature lookup table for knots and weights.
-
-        dl_k, dl_w = calc_grid()
-
-        Returns
-        -------
-        dl_k: list of list of float
-            Cubature lookup table for knots
-        dl_w: list of list of float
-            Cubature lookup table for weights
-        """
-        # make cubature lookup table for knots (dl_k) and weights (dl_w) [max(l) x dim]
-        iprint("Generating difference grids...", tab=0, verbose=self.verbose)
-        dl_k = [[0 for _ in range(self.dim)] for _ in range(int(np.amax(self.level) + 1))]
-        dl_w = [[0 for _ in range(self.dim)] for _ in range(int(np.amax(self.level) + 1))]
-        knots_l, weights_l, knots_l_1, weights_l_1 = 0, 0, 0, 0
-
-        for i_p, p in enumerate(self.parameters_random):
-
-            for i_level in self.level_sequence[i_p]:
-
-                # Jacobi polynomials
-                if self.grid_type[i_p] == 'jacobi':
-                    knots_l, weights_l = get_quadrature_jacobi_1d(self.order_sequence[i_p][i_level],
-                                                                  self.parameters_random[p].pdf_shape[0] - 1,
-                                                                  self.parameters_random[p].pdf_shape[1] - 1)
-                    knots_l_1, weights_l_1 = get_quadrature_jacobi_1d(self.order_sequence[i_p][i_level - 1],
-                                                                      self.parameters_random[p].pdf_shape[0] - 1,
-                                                                      self.parameters_random[p].pdf_shape[1] - 1)
-
-                # Hermite polynomials
-                if self.grid_type[i_p] == 'hermite':
-                    knots_l, weights_l = get_quadrature_hermite_1d(
-                        self.order_sequence[i_p][i_level])
-                    knots_l_1, weights_l_1 = get_quadrature_hermite_1d(
-                        self.order_sequence[i_p][i_level - 1])
-
-                # Gauss-Patterson
-                if self.grid_type[i_p] == 'patterson':
-                    knots_l, weights_l = get_quadrature_patterson_1d(
-                        self.order_sequence[i_p][i_level])
-                    knots_l_1, weights_l_1 = get_quadrature_patterson_1d(
-                        self.order_sequence[i_p][i_level - 1])
-
-                # Clenshaw Curtis
-                if self.grid_type[i_p] == 'clenshaw_curtis':
-                    knots_l, weights_l = get_quadrature_clenshaw_curtis_1d(
-                        self.order_sequence[i_p][i_level])
-                    knots_l_1, weights_l_1 = get_quadrature_clenshaw_curtis_1d(
-                        self.order_sequence[i_p][i_level - 1])
-
-                # Fejer type 2
-                if self.grid_type[i_p] == 'fejer2':
-                    knots_l, weights_l = get_quadrature_fejer2_1d(
-                        self.order_sequence[i_p][i_level - 1])
-                    knots_l_1, weights_l_1 = get_quadrature_fejer2_1d(
-                        self.order_sequence[i_p][i_level - 2])
-
-                if (i_level == 0 and not self.grid_type[i_p] == 'fejer2') or \
-                        (i_level == 1 and (self.grid_type[i_p] == 'fejer2')):
-                    dl_k[i_level][i_p] = knots_l
-                    dl_w[i_level][i_p] = weights_l
-                else:
-                    # noinspection PyTypeChecker
-                    dl_k[i_level][i_p] = np.hstack((knots_l, knots_l_1))
-                    # noinspection PyTypeChecker
-                    dl_w[i_level][i_p] = np.hstack((weights_l, -weights_l_1))
-
-        return dl_k, dl_w
-
-    def calc_tensor_products(self):
-        """
-        Calculate the tensor products of the knots and the weights.
-
-        dll_k, dll_w = calc_tensor_products()
-
-        Returns
-        -------
-        dll_k: np.ndarray
-            Tensor product of knots
-        dll_w: np.ndarray
-            Tensor product of weights
-        """
-        # make list of all tensor products according to multi-index list "l"
-        iprint("Generating sub-grids...", tab=0, verbose=self.verbose)
-        dl_k, dl_w = self.calc_grid()
-        l_level = self.calc_l_level()
-        dll_k = []
-        dll_w = []
-
-        for i_l_level in range(l_level.shape[0]):
-
-            knots = []
-            weights = []
-
-            for i_p in range(self.dim):
-                knots.append(np.asarray(dl_k[int(l_level[i_l_level, i_p])][i_p], dtype=float))
-                weights.append(np.asarray(dl_w[int(l_level[i_l_level, i_p])][i_p], dtype=float))
-
-            # tensor product of knots
-            dll_k.append(get_cartesian_product(knots))
-
-            # tensor product of weights
-            dll_w.append(np.prod(get_cartesian_product(weights), axis=1))
-
-        dll_w = np.hstack(dll_w)
-        dll_k = np.vstack(dll_k)
-
-        return dll_k, dll_w
-
-    def calc_coords_weights(self):
-        """
-        Determine coords and weights of sparse grid by generating, merging and subtracting sub-grids.
-        """
-        # find similar points in grid and formulate Point list
-        dll_k, dll_w = self.calc_tensor_products()
-        point_number_list = np.zeros(dll_w.shape[0]) - 1
-        point_no = 0
-        epsilon_k = 1E-6
-        coords_norm = []
-
-        iprint("Merging sub-grids...", tab=0, verbose=self.verbose)
-
-        while any(point_number_list < 0):
-            not_found = point_number_list < 0
-            dll_k_nf = dll_k[not_found]
-            point_temp = np.zeros(dll_k_nf.shape[0]) - 1
-            point_temp[np.sum(np.abs(dll_k_nf - dll_k_nf[0]), axis=1) < epsilon_k] = point_no
-            point_number_list[not_found] = point_temp
-            point_no = point_no + 1
-            coords_norm.append(dll_k_nf[0, :])
-
-        coords_norm = np.array(coords_norm)
-        point_number_list = np.asarray(point_number_list, dtype=int)
-
-        weights = np.zeros(np.amax(point_number_list) + 1) - 999
-
-        for i_point in range(np.amax(point_number_list) + 1):
-            weights[i_point] = np.sum(dll_w[point_number_list == i_point])
-
-        # filter for very small weights
-        iprint("Filter grid for very small weights...", tab=0, verbose=self.verbose)
-        epsilon_w = 1E-8 / self.dim
-        keep_point = np.abs(weights) > epsilon_w
-        self.weights = weights[keep_point] / 2 ** self.dim
-        coords_norm = coords_norm[keep_point]
-
-        # rescale normalized coordinates in case of normal distributions and "fejer2" or "clenshaw_curtis" grids
-        # +- 0.675 * sigma -> 50%
-        # +- 1.645 * sigma -> 90%
-        # +- 1.960 * sigma -> 95%
-        # +- 2.576 * sigma -> 99%
-        # +- 3.000 * sigma -> 99.73%
-        for i_p, p in enumerate(self.parameters_random):
-            if self.parameters_random[p].pdf_type in ["norm", "normal"] and (not(self.grid_type[i_p] == "hermite")):
-                coords_norm[:, i_p] = coords_norm[:, i_p] * 1.960
-
-        # denormalize grid to original parameter space
-        iprint("Denormalizing grid for computations...", tab=0, verbose=self.verbose)
-        self.coords_norm = coords_norm
-        self.coords = self.get_denormalized_coordinates(coords_norm)
-
-
-class RandomGrid(Grid):
-    """
-    RandomGrid object
-
-    Parameters
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    n_grid: int
-        Number of random samples in grid
-    seed : float, optional, default=None
-        Seeding point to replicate random grid
-    options : dict, optional, default=None
-        RandomGrid options depending on the grid type
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> grid = pygpc.RandomGrid(parameters_random=parameters_random, n_grid=100, options=None)
-
-    Attributes
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    n_grid: int
-        Number of random samples in grid
-    seed : float, optional, default=None
-        Seeding point to replicate random grid
-    options : dict, optional, default=None
-        RandomGrid options depending on the grid type
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    """
-
-    def __init__(self, parameters_random, n_grid=None, options=None, coords=None, coords_norm=None,
-                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None,
-                 grid_pre=None):
-        """
-        Constructor; Initializes RandomGrid instance; Generates grid
-        """
-        super(RandomGrid, self).__init__(parameters_random,
-                                         coords=coords,
-                                         coords_norm=coords_norm,
-                                         coords_gradient=coords_gradient,
-                                         coords_gradient_norm=coords_gradient_norm,
-                                         coords_id=coords_id,
-                                         coords_gradient_id=coords_gradient_id,
-                                         grid_pre=grid_pre)
-
-        if n_grid is not None:
-            self.n_grid = int(n_grid)
-
-        self.options = options
-        self.seed = None
-
-        if self.options is None:
-            self.options = dict()
-
-        if "seed" in self.options.keys():
-            self.seed = self.options["seed"]
-
-            # Seed of random grid (if necessary to reproduce random grid)
-            np.random.seed(self.seed)
-
-    def resample(self, idx, classifier=None, domain=None, gradient=False, results=None, type=None):
-        """
-        Replace grid points specified by index. Modifies grid object in place.
-
-        Parameters
-        ----------
-        idx : np.ndarray of int [n_grid_points_replace]
-            Indices of grid points to replace by resampling.
-        classifier : Classifier object, optional, default: None
-            Classifier
-        domain : int, optional, default: None
-            Adds grid points only in specified domain (needs Classifier object including a predict() method)
-        gradient : bool, optional, default: False
-            Add corresponding gradient grid points
-        results : np.ndarray of float [n_grid x n_qoi]
-            Results computed so far before adding additional grid points
-        type : str, optional, default: None
-            Type of adding new grid points
-            - "GP": Gaussian process regression (points are added where the uncertainty of sampling is very high).
-            Does only work for Random, LHS, and GP grids.
-            - None: grid points are added according to the grid type.
-        """
-        # create temporary grid
-        grid_tmp = copy.deepcopy(self)
-        n_grid = self.n_grid
-
-        # extend grid by number of grid points to resample
-        grid_tmp.extend_random_grid(n_grid_new=self.n_grid + len(idx),
-                                    classifier=classifier,
-                                    domain=domain,
-                                    gradient=gradient,
-                                    results=results,
-                                    type=type)
-
-        # copy options (seed increment)
-        self.options = copy.deepcopy(grid_tmp.options)
-
-        # overwrite grid points to resample in original grid with new grid points from temporary grid
-        self.coords[idx, ] = grid_tmp.coords[n_grid:, ]
-        self.coords_norm[idx, ] = grid_tmp.coords_norm[n_grid:, ]
-
-        # generate and replace unique IDs of new grid points
-        for _idx in idx:
-            self.coords_id[_idx] = uuid.uuid4()
-
-        # create new gradient grid points if required
-        if self.coords_gradient is not None:
-            self._coords_gradient = None
-            self._coords_gradient_norm = None
-            self.n_grid_gradient = None
-            self.create_gradient_grid()
-
-    def delete(self, idx):
-        """
-        Delete grid points by index. Modifies grid object in place.
-
-        Parameters
-        ----------
-        idx : int or np.ndarray of int
-            Indices of grid points to delete.
-        """
-
-        if type(idx) in [int, float, np.ndarray, list]:
-            idx = np.array(idx)
-
-        # delete grid points
-        self.coords = np.delete(self.coords, idx, axis=0)
-        self.coords_norm = np.delete(self.coords_norm, idx, axis=0)
-
-        # remove unique IDs of grid points
-        self.coords_id = [self.coords_id[i] for i in range(self.n_grid) if i not in idx]
-
-        # delete gradient grid points
-        if self.coords_gradient is not None:
-            self.coords_gradient = np.delete(self.coords_gradient, idx, axis=0)
-            self.coords_gradient_norm = np.delete(self.coords_gradient_norm, idx, axis=0)
-
-    def extend_random_grid(self, n_grid_new=None, coords=None, coords_norm=None, classifier=None, domain=None,
-                           gradient=False, results=None, type=None):
-        """
-        Add sample points according to input pdfs to grid (old points are kept). Define either the new total number of
-        grid points with "n_grid_new" or add grid-points manually by providing "coords" and "coords_norm".
-
-        extend_random_grid(n_grid_new, coords=None, coords_norm=None, seed=None, classifier=None, domain=None):
-
-        Parameters
-        ----------
-        n_grid_new : float
-            Total number of grid points in extended random grid (old points are kept)
-            (n_grid_add = n_grid_new - n_grid_old)
-        coords : ndarray of float [n_grid_add x dim]
-            Grid points to add (model space)
-        coords_norm : ndarray of float [n_grid_add x dim]
-            Grid points to add (normalized space)
-        classifier : Classifier object, optional, default: None
-            Classifier
-        domain : int, optional, default: None
-            Adds grid points only in specified domain (needs Classifier object including a predict() method)
-        gradient : bool, optional, default: False
-            Add corresponding gradient grid points
-        results : np.ndarray of float [n_grid x n_qoi]
-            Results computed so far before adding additional grid points
-        type : str, optional, default: None
-            Type of adding new grid points
-            - "GP": Gaussian process regression (points are added where the uncertainty of sampling is very high).
-            Does only work for Random, LHS, and GP grids.
-            - None: grid points are added according to the grid type.
-        """
-
-        # increase seed if needed to avoid creation of same grid points
-        if "seed" in self.options.keys() and self.options["seed"] is not None:
-            self.options["seed"] += 1
-            self.seed = self.options["seed"]
-
-        if isinstance(self, GP):
-            type = "GP"
-
-        if n_grid_new is not None:
-            # Number of new grid points
-            n_grid_add = int(n_grid_new - self.n_grid)
-
-            if n_grid_add > 0:
-                # Generate new grid points
-                if classifier is None:
-                    if isinstance(self, Random) or isinstance(self, GP):
-                        if type is None:
-                            new_grid = Random(parameters_random=self.parameters_random,
-                                              n_grid=n_grid_add,
-                                              options=self.options)
-
-                            # append points to existing grid
-                            self.coords = np.vstack([self.coords, new_grid.coords])
-                            self.coords_norm = np.vstack([self.coords_norm, new_grid.coords_norm])
-
-                        elif type == "GP":
-                            if "n_pool" not in list(self.options.keys()):
-                                self.options["n_pool"] = 1000
-
-                            # If results are given, determine optimal hyperparameters for Gaussian Process Regression
-                            if results is not None:
-                                self.options["lengthscale"], self.options["variance"] = \
-                                    get_parameters_gaussian_process(Xtrain=self.coords_norm,
-                                                                    ytrain=results[:, 0])
-
-                            if (self.n_grid + 1) == n_grid_new:
-                                tqdm.write(f"Adding GP grid point #{self.n_grid + 1}")
-                            else:
-                                tqdm.write(f"Adding GP grid points #{self.n_grid + 1} ... #{n_grid_new}")
-
-                            for _ in tqdm(range(n_grid_add)):
-                                # Determine new grid points where uncertainty of output is highest
-                                new_grid = self.get_coords_gaussian_process(n_grid_add=1,
-                                                                            lengthscale=self.options["lengthscale"],
-                                                                            variance=self.options["variance"],
-                                                                            n_pool=self.options["n_pool"])
-
-                                # append points to existing grid
-                                self.coords = np.vstack([self.coords, new_grid.coords])
-                                self.coords_norm = np.vstack([self.coords_norm, new_grid.coords_norm])
-                            tqdm._instances.clear()
-
-                    elif isinstance(self, LHS):
-                        grid_pre = copy.deepcopy(self)
-
-                        if type is None:
-                            new_grid = LHS(parameters_random=self.parameters_random,
-                                           n_grid=n_grid_add,
-                                           grid_pre=grid_pre,
-                                           options=self.options)
-
-                            # append points to existing grid
-                            self.coords = np.vstack([self.coords, new_grid.coords])
-                            self.coords_norm = np.vstack([self.coords_norm, new_grid.coords_norm])
-
-                        elif type == "GP":
-                            if "n_pool" not in list(self.options.keys()):
-                                self.options["n_pool"] = 1000
-
-                            # If results are given, determine optimal hyperparameters for Gaussian Process Regression
-                            if results is not None:
-                                self.options["lengthscale"], self.options["variance"] = \
-                                    get_parameters_gaussian_process(Xtrain=self.coords_norm,
-                                                                    ytrain=results[:, 0])
-
-                            if (self.n_grid + 1) == n_grid_new:
-                                tqdm.write(f"Adding GP grid point #{self.n_grid + 1}")
-                            else:
-                                tqdm.write(f"Adding GP grid points #{self.n_grid + 1} ... #{n_grid_new}")
-
-                            for _ in tqdm(range(n_grid_add)):
-                                # Determine new grid points where uncertainty of output is highest
-                                new_grid = self.get_coords_gaussian_process(n_grid_add=1,
-                                                                            lengthscale=self.options["lengthscale"],
-                                                                            variance=self.options["variance"],
-                                                                            n_pool=self.options["n_pool"])
-
-                                # append points to existing grid
-                                self.coords = np.vstack([self.coords, new_grid.coords])
-                                self.coords_norm = np.vstack([self.coords_norm, new_grid.coords_norm])
-                            tqdm._instances.clear()
-
-                    elif isinstance(self, L1) or isinstance(self, L1_LHS) or isinstance(self, LHS_L1) \
-                            or isinstance(self, CO) or isinstance(self, FIM):
-                        grid_pre = copy.deepcopy(self)
-                        new_grid = self.__class__(parameters_random=self.parameters_random,
-                                                  n_grid=n_grid_new,
-                                                  grid_pre=grid_pre,
-                                                  gpc=self.gpc,
-                                                  options=self.options)
-
-                        self.coords = new_grid.coords
-                        self.coords_norm = new_grid.coords_norm
-
-                else:
-                    coords = np.zeros((n_grid_add, len(self.parameters_random)))
-                    coords_norm = np.zeros((n_grid_add, len(self.parameters_random)))
-
-                    # add grid points one by one because we are looking for samples in the right domain
-                    for i in range(n_grid_add):
-                        resample = True
-                        while resample:
-                            if isinstance(self, Random):
-                                new_grid = Random(parameters_random=self.parameters_random,
-                                                  n_grid=1,
-                                                  options=self.options)
-
-                                # test if grid point lies in right domain
-                                if classifier.predict(new_grid.coords_norm)[0] == domain:
-                                    coords[i, :] = new_grid.coords
-                                    coords_norm[i, :] = new_grid.coords_norm
-                                    resample = False
-
-                            elif isinstance(self, LHS):
-                                # check if gridpoint exceeds sampling reservoir
-                                # if self.n_grid > max(10000, self.n_grid_lhs * 10)
-                                # coords.np.append(pygpc.LSH( seed=seed+1))
-                                coords_norm_test = self.lhs_extend(self.coords_norm_reservoir, 1)
-                                # test if next grid point lies in right domain
-                                if classifier.predict(coords_norm_test[len(coords_norm_test) - 1]) == domain:
-                                    self.coords_norm_reservoir = coords_norm_test
-                                    coords[i, :] = self.coords_reservoir[self.n_grid]
-                                    coords_norm[i, :] = self.coords_norm_reservoir[self.n_grid]
-                                    self.n_grid += 1
-                                    resample = False
-
-                    # append points to existing grid
-                    self.coords = np.vstack([self.coords, coords])
-                    self.coords_norm = np.vstack([self.coords_norm, coords_norm])
-
-        elif coords is not None or coords_norm is not None:
-            # append points to existing grid
-            if coords_norm is None and coords is not None:
-                coords_norm = self.get_normalized_coordinates(coords=coords)
-            if coords is None and coords_norm is not None:
-                coords = self.get_denormalized_coordinates(coords_norm=coords_norm)
-
-            # Number of new grid points
-            n_grid_add = coords.shape[0]
-
-            # check if specified points are lying in right domain
-            if classifier is not None:
-                if not (classifier.predict(coords_norm) == domain).all():
-                    raise AssertionError("Specified coordinates are not lying in right domain!")
-
-            self.coords = np.vstack([self.coords, coords])
-            self.coords_norm = np.vstack([self.coords_norm, coords_norm])
-
-        else:
-            raise ValueError("Specify either n_grid_new or coords or coords_norm")
-
-        # Generate and append unique IDs of new grid points
-        self.coords_id = self.coords_id + [uuid.uuid4() for _ in range(n_grid_add)]
-
-        self.n_grid = self.coords.shape[0]
-
-        if gradient:
-            self.create_gradient_grid()
-
-    def lhs_extend(self, array, n_extend):
-        """
-        Add sample points to already existing LHS samples
-
-        Parameters
-        ----------
-        array: ndarray of float [m x n]
-            Existing LHS samples with m samples points per n dimensions
-        n_extend: int
-            Number of new rows of samples needed
-
-        Returns
-        -------
-        coords_norm : ndarray of float [m + n_extend x n]
-            Existing LHS samples with added new samples
-        """
-
-        dim = np.shape(array)[1]
-        n_old = np.shape(array)[0]
-        n_new = n_old + n_extend
-        i = 1
-        n_new_loop = n_new
-        np.random.seed(seed=self.seed)
-
-        while i > 0:
-            a_new = np.zeros([n_new_loop, dim]) - 1
-            u = np.random.rand(n_new_loop, dim)
-
-            for d in range(dim):
-                k = 0
-                for j in range(n_new_loop - 1):
-                    if not (float(j / n_new_loop) < float(np.sort(array[:, d])[min(j, len(array) - 1)]) < float((j + 1) / n_new_loop)) \
-                            and (float((j + 1) / n_new_loop) <= float(np.sort(array[:, d])[min((j + 2), len(array) - 1)])):
-
-                        k = k + 1
-                        if k is np.shape(a_new)[0] + 1:
-                            k = 1
-                        a_new[k - 1, d] = float((j + u[j, d]) / n_new_loop)
-
-            a_new = a_new[(a_new != -1).all(axis=1), :]
-
-            if n_extend > np.min((a_new.shape[0], n_new)):
-                i = 1
-                n_new_loop = n_new_loop * 2
-
-            else:
-                i = 0
-                for d in range(dim):
-                    np.random.shuffle(a_new[:, d])
-
-                a_extend = a_new[np.random.choice(a_new.shape[0], size=n_extend, replace=False), :]
-
-        coords_ = np.insert(array, n_old, a_extend, axis=0)
-
-        return coords_
-
-    def get_coords_gaussian_process(self, n_grid_add, lengthscale=0.2, variance=1., n_pool=10000):
-        """
-        Determine coordinates at highest variance determined by Gaussian Process Regression
-
-        Parameters
-        ----------
-        n_grid_add : int
-            Number of grid points to add
-        lengthscale : float, optional, default: 1.
-            Lengthscale parameter
-        variance : float, optional, default: 1.
-            Output variance
-        n_pool : int, optional, default: None
-            Poolsize of random sampling points the best are selected from.
-
-        Returns
-        -------
-        grid_new : RandomGrid object
-            RandomGrid object which contains the new grid points in grid_new.coords and grid_new.coords_norm
-        """
-
-        n_test = np.max((n_pool, 2 * self.n_grid))
-
-        # create test grid
-        grid_test = Random(parameters_random=self.parameters_random, n_grid=n_test, options={"seed": self.seed})
-
-        # kernels
-        K = squared_exponential_kernel(x=self.coords_norm, y=self.coords_norm,
-                                       lengthscale=lengthscale, variance=variance)  # n_train x n_train
-        Ks = squared_exponential_kernel(x=self.coords_norm, y=grid_test.coords_norm,
-                                        lengthscale=lengthscale, variance=variance)  # n_train x n_test
-        Kss = squared_exponential_kernel(x=grid_test.coords_norm, y=grid_test.coords_norm,
-                                         lengthscale=lengthscale, variance=variance)  # n_test x n_test
-
-        try:
-            # cholesky decomposition
-            L = np.linalg.cholesky(K)
-
-            # compute v
-            v = np.linalg.solve(L, Ks)
-
-        except np.linalg.LinAlgError:
-            print(
-                "Warning: Cholesky decomposition of K* matrix did not converge ... using Moore-Penrose pseudo inverse.")
-            v = np.linalg.pinv(K) @ Ks
-
-        # alpha
-        # alpha = np.linalg.solve(L.T, np.linalg.solve(L, results))
-
-        # compute the mean function
-        # mu = Ks.T @ alpha
-
-        # compute the covariance
-        covariance = Kss - (v.T @ v)
-
-        # we get the standard deviation from the covariance matrix
-        std = np.sqrt(np.diag(covariance))
-
-        if np.isnan(std).all():
-            print("Warning: GP failed, adding random grid points instead.")
-
-            # take random samples if GP failed
-            coords = grid_test.coords[:n_grid_add, :]
-            coords_norm = grid_test.coords_norm[:n_grid_add, :]
-        else:
-            # weight std with joint probability
-            joint_pdf = np.ones(n_pool)
-            for i_p, p in enumerate(self.parameters_random):
-                _, tmp = self.parameters_random[p].pdf_norm(x=grid_test.coords_norm[:, i_p])
-                joint_pdf *= tmp
-            std_weighted = std * joint_pdf
-
-            idx_sorted = np.flip(np.argsort(std_weighted))
-            idx_sorted = idx_sorted[~np.isnan(std_weighted[idx_sorted])]
-
-            coords = grid_test.coords[idx_sorted[:n_grid_add], :]
-            coords_norm = grid_test.coords_norm[idx_sorted[:n_grid_add], :]
-
-        grid_new = Random(coords=coords, coords_norm=coords_norm, parameters_random=self.parameters_random)
-
-        return grid_new
-
-
-class Random(RandomGrid):
-    """
-    Random grid object
-
-    Parameters
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    n_grid : int or float
-        Number of random samples in grid
-    seed : float, optional, default=None
-        Seeding point to replicate random grid
-    options : dict, optional, default=None
-        RandomGrid options depending on the grid type
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> grid = pygpc.Random(parameters_random=parameters_random, n_grid=100)
-
-    Attributes
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    n_grid : int or float
-        Number of random samples in grid
-    seed : float, optional, default=None
-        Seeding point to replicate random grid
-    options : dict, optional, default=None
-        RandomGrid options depending on the grid type
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    """
-
-    def __init__(self, parameters_random, n_grid=None, options=None, coords=None, coords_norm=None,
-                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None,
-                 grid_pre=None):
-        """
-        Constructor; Initializes RandomGrid instance; Generates grid or copies provided content
-        """
-        if n_grid is not None:
-            n_grid = int(n_grid)
-
-        super(Random, self).__init__(parameters_random,
-                                     n_grid=n_grid,
-                                     options=options,
-                                     coords=coords,
-                                     coords_norm=coords_norm,
-                                     coords_gradient=coords_gradient,
-                                     coords_gradient_norm=coords_gradient_norm,
-                                     coords_id=coords_id,
-                                     coords_gradient_id=coords_gradient_id,
-                                     grid_pre=grid_pre)
-
-        if coords is not None or coords_norm is not None:
-            grid_present = True
-        else:
-            grid_present = False
-
-        if not grid_present:
-
-            # Generate random samples for each random input variable [n_grid x dim]
-            self.coords_norm = np.zeros([self.n_grid, self.dim])
-
-            if self.grid_pre is not None:
-                self.coords_norm[:self.grid_pre.n_grid, :] = self.grid_pre.coords_norm
-                n_grid_add = n_grid - self.grid_pre.n_grid
-                n_grid_start = self.grid_pre.n_grid
-            else:
-                n_grid_add = n_grid
-                n_grid_start = 0
-
-            # in case of seeding, the random grid is constructed element wise (same grid-points when n_grid differs)
-            if self.seed:
-                for i_grid in range(n_grid_start, n_grid):
-                    for i_p, p in enumerate(self.parameters_random):
-
-                        if self.parameters_random[p].pdf_type == "beta":
-                            self.coords_norm[i_grid, i_p] = np.random.beta(self.parameters_random[p].pdf_shape[0],
-                                                                           self.parameters_random[p].pdf_shape[1],
-                                                                           1) * 2.0 - 1
-
-                        if self.parameters_random[p].pdf_type in ["norm", "normal"]:
-
-                            resample = True
-
-                            while resample:
-                                self.coords_norm[i_grid, i_p] = np.random.normal(loc=0,
-                                                                                 scale=1,
-                                                                                 size=1)
-                                resample = self.coords_norm[i_grid, i_p] < self.parameters_random[p].x_perc_norm[0] or \
-                                           self.coords_norm[i_grid, i_p] > self.parameters_random[p].x_perc_norm[1]
-
-                        if self.parameters_random[p].pdf_type in ["gamma"]:
-
-                            resample = True
-
-                            while resample:
-                                self.coords_norm[i_grid, i_p] = np.random.gamma(
-                                    shape=self.parameters_random[p].pdf_shape[0],
-                                    scale=1.0,
-                                    size=1)
-                                resample = self.coords_norm[i_grid, i_p] > self.parameters_random[p].x_perc_norm
-
-            else:
-                for i_p, p in enumerate(self.parameters_random):
-
-                    if self.parameters_random[p].pdf_type == "beta":
-                        self.coords_norm[n_grid_start:, i_p] = (np.random.beta(self.parameters_random[p].pdf_shape[0],
-                                                                               self.parameters_random[p].pdf_shape[1],
-                                                                               [n_grid_add, 1]) * 2.0 - 1)[:, 0]
-
-                    if self.parameters_random[p].pdf_type in ["norm", "normal"]:
-                        resample = True
-                        if self.grid_pre is not None:
-                            outlier_mask = np.hstack((np.zeros(self.grid_pre.n_grid, dtype=bool),
-                                                     np.ones(n_grid_add, dtype=bool)))
-                        else:
-                            outlier_mask = np.ones(self.n_grid, dtype=bool)
-
-                        while resample:
-                            self.coords_norm[outlier_mask, i_p] = (np.random.normal(loc=0,
-                                                                                    scale=1,
-                                                                                    size=[np.sum(outlier_mask), 1]))[:, 0]
-
-                            outlier_mask = np.logical_or(
-                                self.coords_norm[:, i_p] < self.parameters_random[p].x_perc_norm[0],
-                                self.coords_norm[:, i_p] > self.parameters_random[p].x_perc_norm[1])
-
-                            resample = outlier_mask.any()
-
-                    if self.parameters_random[p].pdf_type in ["gamma"]:
-                        resample = True
-                        outlier_mask = np.ones(self.n_grid, dtype=bool)
-                        j = 0
-                        while resample:
-                            # print("Iteration: {}".format(j + 1))
-                            self.coords_norm[outlier_mask, i_p] = (np.random.gamma(
-                                shape=self.parameters_random[p].pdf_shape[0],
-                                scale=1.0,
-                                size=[np.sum(outlier_mask), 1]))[:, 0]
-
-                            outlier_mask = np.array(self.coords_norm[:, i_p] > self.parameters_random[p].x_perc_norm)
-
-                            resample = outlier_mask.any()
-
-                            j += 1
-
-            # Denormalize grid to original parameter space
-            self.coords = self.get_denormalized_coordinates(self.coords_norm)
-
-            # Generate unique IDs of grid points
-            self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
-
-        else:
-            # self.coords = coords
-            # self.coords_norm = coords_norm
-            #
-            # self.coords_gradient = coords_gradient
-            # self.coords_gradient_norm = coords_gradient_norm
-            #
-            # self.coords_id = coords_id
-            # self.coords_gradient_id = coords_gradient_id
-
-            if self.coords is None:
-                # Denormalize grid to original parameter space
-                self.coords = self.get_denormalized_coordinates(self.coords_norm)
-
-            if self.coords_norm is None:
-                # Normalize grid to original parameter space
-                self.coords = self.get_normalized_coordinates(self.coords)
-
-            if self.coords_gradient is None and self.coords_gradient_norm is not None:
-                # Denormalize grid to original parameter space
-                self.coords_gradient = self.get_denormalized_coordinates(self.coords_gradient_norm)
-
-            if self.coords_gradient_norm is None and self.coords_gradient is not None:
-                # Normalize grid to original parameter space
-                self.coords_gradient_norm = self.get_normalized_coordinates(self.coords_gradient)
-
-
-class GP(RandomGrid):
-    """
-    Gaussian Process grid object
-
-    Parameters
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    n_grid : int or float
-        Number of random samples in grid
-    seed : float, optional, default=None
-        Seeding point to replicate random grid
-    options : dict, optional, default=None
-        RandomGrid options depending on the grid type
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> grid = pygpc.GP(parameters_random=parameters_random, n_grid=100)
-
-    Attributes
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    n_grid : int or float
-        Number of random samples in grid
-    seed : float, optional, default=None
-        Seeding point to replicate random grid
-    options : dict, optional, default=None
-        RandomGrid options depending on the grid type
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    """
-
-    def __init__(self, parameters_random, n_grid=None, options=None, coords=None, coords_norm=None,
-                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None,
-                 grid_pre=None):
-        """
-        Constructor; Initializes RandomGrid instance; Generates grid or copies provided content
-        """
-        if n_grid is not None:
-            n_grid = int(n_grid)
-
-        super(GP, self).__init__(parameters_random,
-                                 n_grid=n_grid,
-                                 options=options,
-                                 coords=coords,
-                                 coords_norm=coords_norm,
-                                 coords_gradient=coords_gradient,
-                                 coords_gradient_norm=coords_gradient_norm,
-                                 coords_id=coords_id,
-                                 coords_gradient_id=coords_gradient_id,
-                                 grid_pre=grid_pre)
-
-        if coords is not None or coords_norm is not None:
-            grid_present = True
-        else:
-            grid_present = False
-
-        if self.options is None:
-            self.options["variance"] = 1.
-            self.options["lengthscale"] = 0.2
-            self.options["n_pool"] = 10000
-
-        if "variance" not in self.options.keys():
-            self.options["variance"] = 1.
-
-        if "lengthscale" not in self.options.keys():
-            self.options["lengthscale"] = 0.2
-
-        if "n_pool" not in self.options.keys():
-            self.options["n_pool"] = 10000
-
-        if not grid_present:
-            if self.grid_pre is not None:
-                self.coords_norm = self.grid_pre.coords_norm
-                n_grid_start = self.grid_pre.n_grid
-            else:
-                self.coords_norm = np.zeros((1, self.dim))
-                self.coords = self.get_denormalized_coordinates(self.coords_norm)
-                n_grid_start = 1
-
-            self.extend_random_grid(n_grid_new=n_grid, coords_norm=self.coords_norm, coords=self.coords, type="GP")
-
-            # Denormalize grid to original parameter space
-            self.coords = self.get_denormalized_coordinates(self.coords_norm)
-
-            # Generate unique IDs of grid points
-            self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
-
-        else:
-            if self.coords is None:
-                # Denormalize grid to original parameter space
-                self.coords = self.get_denormalized_coordinates(self.coords_norm)
-
-            if self.coords_norm is None:
-                # Normalize grid to original parameter space
-                self.coords = self.get_normalized_coordinates(self.coords)
-
-            if self.coords_gradient is None and self.coords_gradient_norm is not None:
-                # Denormalize grid to original parameter space
-                self.coords_gradient = self.get_denormalized_coordinates(self.coords_gradient_norm)
-
-            if self.coords_gradient_norm is None and self.coords_gradient is not None:
-                # Normalize grid to original parameter space
-                self.coords_gradient_norm = self.get_normalized_coordinates(self.coords_gradient)
-
-
-class LHS(RandomGrid):
-    """
-    LHS grid object
-
-    Parameters
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    n_grid: int
-        Number of random samples to generate
-    options: dict, optional, default=None
-        Grid options:
-        - criterion :
-            - 'corr'            : optimizes design points in their spearman correlation coefficients
-            - 'maximin' or 'm'  : optimizes design points in their maximum minimal distance using the Phi-P criterion
-            - 'ese'             : uses an enhanced evolutionary algorithm to optimize the Phi-P criterion
-        - seed : Seeding point to replicate random grids
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> grid = pygpc.LHS(parameters_random=parameters_random, n_grid=100, options={"seed": None, "criterion": "ese"})
-
-    Attributes
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    n_grid : int or float
-        Number of random samples in grid
-    seed : float, optional, default=None
-        Seeding point to replicate random grid
-    options : dict, optional, default=None
-        - 'corr'            : optimizes design points in their spearman correlation coefficients
-        - 'maximin' or 'm'  : optimizes design points in their maximum minimal distance using the Phi-P criterion
-        - 'ese'             : uses an enhanced evolutionary algorithm to optimize the Phi-P criterion
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    """
-
-    def __init__(self, parameters_random, n_grid=None, options=None, coords=None, coords_norm=None,
-                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None,
-                 grid_pre=None):
-        """
-        Constructor; Initializes RandomGrid instance; Generates grid or copies provided content
-        """
-
-        self.coords_norm_lhs = None
-        self.perc_mask = None
-        self.coords_reservoir = None
-        self.coords_norm_reservoir = None
-        self.grid_pre = grid_pre
-        self.options = options
-        self.criterion = None
-        self.method = None
-        self.coords_norm_reservoir_perced = None
-
-        if type(self.options) is dict:
-            if "criterion" in self.options.keys():
-                self.criterion = options["criterion"]
-            else:
-                self.criterion = ["ese"]
-            if "method" in self.options.keys():
-                self.method = options["method"]
-            else:
-                self.criterion = ["standard"]
-
-        if type(self.criterion) is not list:
-            self.criterion = [self.criterion]
-
-        super(LHS, self).__init__(parameters_random,
-                                  n_grid=n_grid,
-                                  options=options,
-                                  coords=coords,
-                                  coords_norm=coords_norm,
-                                  coords_gradient=coords_gradient,
-                                  coords_gradient_norm=coords_gradient_norm,
-                                  coords_id=coords_id,
-                                  coords_gradient_id=coords_gradient_id)
-
-        self.shift_outer = False
-
-        # if self.criterion == ["ese"]:
-        #     for p in parameters_random:
-        #         if parameters_random[p].p_perc is None:
-        #             self.shift_outer = True
-
-        if coords is not None and coords_norm is not None:
-            grid_present = True
-        else:
-            grid_present = False
-
-        if not grid_present:
-            if self.n_grid > 0:
-                self.sample_init(self.n_grid)
-
-    def sample_init(self, n_grid):
-        """
-        Initialises all parameters for Latin Hypercube Sampling and creates a new design
-        if there is at least one sampling point needed
-
-        Parameters
-        ----------
-        n_grid : ndarray of float [n]
-            The number of needed sampling points
-
-        Returns
-        -------
-        coords : ndarray of float [n_grid_add x dim]
-            Grid points to add (model space)
-        coords_norm : ndarray of float [n_grid_add x dim]
-            Grid points to add (normalized space)
-        coords_id : list of UUID objects (version 4) [n_grid]
-            Unique IDs of grid points
-        """
-
-        if n_grid > 0:
-            if n_grid == 1:
-                random_grid = Random(parameters_random=self.parameters_random,
-                                     n_grid=self.n_grid,
-                                     options=self.options)
-                self.coords_norm = random_grid.coords_norm
-
-            else:
-                if self.grid_pre is None:
-                    n_grid_lhs = self.n_grid
-                else:
-                    n_grid_lhs = self.n_grid + self.grid_pre.n_grid
-
-                self.perc_mask = np.zeros((n_grid_lhs, self.dim)).astype(bool)
-                self.coords_norm_reservoir = np.zeros([n_grid_lhs, self.dim])
-
-                # generate LHS coordinates
-                self.get_lhs_grid()
-
-        # Denormalize grid to original parameter space
-        self.coords = self.get_denormalized_coordinates(self.coords_norm)
-
-        # Generate unique IDs of grid points
-        self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
-
-    def CL2(self, array):
-        """
-        Calculate the L2 discrepancy of the design
-        The discrepancy is a measure of the difference between the empirical cumulative distribution function
-        of an experimental design and the uniform cumulative distribution function [1].
-
-        Parameters
-        ----------
-        array : ndarray of float [m x n]
-            Array with n rows of samples and m columns of variables/dimensions
-
-        Returns
-        -------
-        cl2d_crit : float
-            criterion for centered L2 discrepancy
-
-        Notes
-        -----
-        .. [1] Hickernell, F. (1998). A generalized discrepancy and quadrature error bound.
-           Mathematics of computation, 67(221), 299-322.
-        """
-        subtract = np.ones([np.shape(array)[0], np.shape(array)[1]])
-        array = array - 0.5 * subtract
-        prod_array_1 = np.zeros(np.shape(array)[0])
-        for n in range(0, np.shape(array)[0]):
-            prod_array_1[n] = (np.ones(np.shape(array)[1]) + (1 / 2 * (np.abs(array[n, :]))) - (
-                    1 / 2 * ((array[n, :]) ** 2))).prod()
-        prod_array_2 = np.zeros([np.shape(array)[0], np.shape(array)[0]])
-        for i in range(0, np.shape(array)[0]):
-            for j in range(0, np.shape(array)[0]):
-                prod_array_2[i, j] = (np.ones(np.shape(array)[1]) + (1 / 2 * (np.abs(array[i, :]))) - (
-                        1 / 2 * np.abs(array[j, :]) - 1 / 2 * np.abs(array[i, :] - array[j, :]))).prod()
-        cl2d_crit = ((13 / 12) ** 2) - (2 / (np.shape(array)[0]) * prod_array_1.sum()) + (1 / (
-                np.shape(array)[0] ** 2) * prod_array_2.sum())
-        # centered L2 discrepancy criteria
-        return cl2d_crit
-
-    def log_R(self, array):
-        """
-        Determines the Log(R) Entropy Criterion[1]
-
-        Parameters
-        ----------
-        array : ndarray of float [m x n]
-            Array
-
-        Returns
-        -------
-        log_R : float
-            Log(R) Entropy Criterion
-        Notes
-        -----
-        .. [1] Koehler, J.R., Owen, A.B., 1996. Computer experiments. in: Ghosh, S., Rao, C.R. (Eds.),
-           Handbook of Statistics. Elsevier Science, New York, pp.261-308
-        """
-        # R will be [m x m]
-        R = np.corrcoef(array.T)
-        for i in range(0, np.shape(array)[1]):
-            for j in range(0, np.shape(array)[1]):
-                R[i, j] = np.exp((R[i, :] * np.abs(array[i, :] - array[j, :]) ** 2).sum())
-        log_R = np.log(np.linalg.norm(R))
-
-        return (log_R)
-
-    def PhiP(self, x, p=10):
-        """
-        Calculates the Phi-p criterion of the design x with power p [1].
-
-        Parameters
-        ----------
-        x : ndarray of float [n x m]
-            The design to calculate Phi-p for
-        p : int, optional, default: 10
-            The power used for the calculation of PhiP
-
-        Returns
-        -------
-        phip : float
-            Phi-p criterion
-
-        Notes
-        -----
-        .. [1] Morris, M. D., & Mitchell, T. J. (1995). Exploratory designs for computational experiments.
-           Journal of statistical planning and inference, 43(3), 381-402.
-        """
-        m, n = x.shape
-        dist = np.zeros((m * (m - 1)) // 2, dtype=np.double)
-        k = 0
-        if self.method == "standard" or None:
-            for i in range(0, m - 1):
-                for j in range(i + 1, m):
-                    dist[k] = np.linalg.norm(x[i] - x[j])
-                    k = k + 1
-
-            phip = ((dist ** (-p)).sum()) ** (1.0 / p)
-        elif self.method == "periodic":
-            for i in range(0, m - 1):
-                for j in range(i + 1, m):
-                    periodic_dist = np.sqrt(np.sum(np.square(np.min(np.abs(x[i]-x[j])), 1 - np.abs(x[i]-x[j]))))
-                    dist[k] = periodic_dist
-                    k = k + 1
-
-            phip = ((dist ** (-p)).sum()) ** (1.0 / p)
-        return phip
-
-    def PhiP_exchange(self, P, k, Phi, p, fixed_index):
-        """
-        Performes a row exchange and return the altered design.
-
-        Parameters
-        ----------
-        P : ndarray of float [m x n]
-            The design to perform the exchange on
-        k : int
-            modulus of the iteration divided by the dimension to pick a row of the design repeating through the
-            dimensions of the design
-        Phi: float
-            the PhiP criterion of the current best Design
-        p: int
-            The power used for the calculation of PhiP
-        fixed_index: list
-            an empty list to check if variables are assigned a value
-
-        Returns
-        -------
-        phip : float
-            Phi-p criterion
-        """
-        # Choose two (different) random rows to perform the exchange
-        er = P.shape
-        i1 = np.random.randint(P.shape[0])
-        while i1 in fixed_index:
-            i1 = np.random.randint(P.shape[0])
-
-        i2 = np.random.randint(P.shape[0])
-        while i2 == i1 or i2 in fixed_index:
-            i2 = np.random.randint(P.shape[0])
-
-        P_= np.delete(P, [i1, i2], axis=0)
-
-        dist1 = scipy.spatial.distance.cdist([P[i1, :]], P_)
-        dist2 = scipy.spatial.distance.cdist([P[i2, :]], P_)
-        d1 = np.sqrt(dist1 ** 2 + (P[i2, k] - P_[:, k]) ** 2 - (P[i1, k] - P_[:, k]) ** 2)
-        d2 = np.sqrt(dist2 ** 2 - (P[i2, k] - P_[:, k]) ** 2 + (P[i1, k] - P_[:, k]) ** 2)
-
-        res = (Phi ** p + (d1 ** (-p) - dist1 ** (-p) + d2 ** (-p) - dist2 ** (-p)).sum()) ** (1.0 / p)
-
-        P[i1, k], P[i2, k] = P[i2, k], P[i1, k]
-        return res
-
-    def get_lhs_grid(self):
-        """
-        Create samples in an m*n matrix using Latin Hypercube Sampling [1].
-
-        Notes
-        -----
-        .. [1] McKay, M. D., Beckman, R. J., & Conover, W. J. (2000). A comparison of three methods for selecting
-           values of input variables in the analysis of output from a computer code. Technometrics, 42(1), 55-61.
-        """
-
-        # create sample points in icdf space using specified criteria
-        if self.criterion[0] == 'corr':
-            self.coords_norm_lhs = self.lhs_corr()
-        elif self.criterion[0] == 'maximin' or self.criterion == 'm':
-            self.coords_norm_lhs = self.lhs_maximin()
-        elif self.criterion[0] == 'ese':
-            self.coords_norm_lhs = self.lhs_ese()
-        else:
-            self.coords_norm_lhs = self.lhs_initial()
-
-        # transform sample points from icdf to pdf space
-        for i_p, p in enumerate(self.parameters_random):
-            self.coords_norm_reservoir[:, i_p] = self.parameters_random[p].icdf(self.coords_norm_lhs[:, i_p])
-
-        if self.grid_pre is not None:
-            self.coords_norm_reservoir = get_different_rows_from_matrices(self.grid_pre.coords_norm,
-                                                                          self.coords_norm_reservoir)
-
-        self.coords_norm = self.coords_norm_reservoir[0:self.n_grid, :]
-
-    def lhs_initial(self):
-        """
-        Construct an initial LHS grid.
-
-        Returns
-        -------
-        design : ndarray of float [n, n_dim]
-            LHS grid points
-        """
-
-        if self.grid_pre is not None:
-            # transform normalized coordinates back to LHS-Space (0, 1)
-            pre_coords_lhs = np.zeros(self.grid_pre.coords_norm.shape)
-
-            for i, p in enumerate(self.parameters_random):
-                pre_coords_lhs[:, i] = self.parameters_random[p].cdf_norm(self.grid_pre.coords_norm[:, i])
-
-            return self.lhs_extend(pre_coords_lhs, self.n_grid)
-
-        else:
-            design = np.zeros([self.n_grid, self.dim])
-
-            # u = matrix of uniform (0,1) that vary in n subareas
-            u = np.random.rand(self.n_grid, self.dim)
-
-            for i in range(0, self.dim):
-                for j in range(0, self.n_grid):
-
-                    if self.shift_outer:
-                        if j == 0:
-                            design[j, i] = j + 1
-                            u[j, i] = 1 - 1/4 * u[j, i]
-                        elif (j + 1) == self.n_grid:
-                            design[j, i] = j + 1
-                            u[j, i] = 1/4 * u[j, i]
-                        elif j <= self.n_grid/2:
-                            design[j, i] = j + 1 - ((j*3/4) / ((self.n_grid - 2) * self.n_grid))
-                        elif j > self.n_grid/2:
-                            design[j, i] = j + 1 + ((j*3/4) / ((self.n_grid - 2) * self.n_grid))
-                    else:
-                        design[j, i] = j + 1
-
-            for i in range(0, self.dim):
-                for j in range(0, self.n_grid):
-                    design[j, i] = (design[j, i] - u[j, i]) / self.n_grid
-
-                np.random.shuffle(design[:, i])
-
-            return design
-
-    def lhs_corr(self):
-        """
-        Create a correlation optimized LHS grid
-
-        Parameters
-        ----------
-        dim : int
-            Number of random variables
-        n : int
-            Number of sampling points
-        iterations : int
-            Number of iterations to optimize
-
-        Returns
-        -------
-        design : ndarray of float [n, n_dim]
-            LHS grid points
-        """
-        mincorr = np.inf
-
-        # Minimize the components correlation coefficients
-        for i in range(100):
-            # Generate a random LHS
-            test = self.lhs_initial()
-            R = scipy.stats.spearmanr(test)[0]
-
-            if np.max(np.abs(R)) < mincorr:
-                mincorr = np.max(np.abs(R))
-                design = test.copy()
-
-        return design
-
-    def lhs_maximin(self):
-        """
-        Create an optimized LHS grid with maximal minimal distance
-
-        Parameters
-        ----------
-        dim : int
-            Number of random variables
-        n : int
-            Number of sampling points
-        iterations : int
-            Number of iterations to optimize
-
-        Returns
-        -------
-        design : ndarray of float [n, n_dim]
-            LHS grid points
-        """
-        phi_best = max(1000, self.n_grid * 100)
-
-        # Maximize the minimum distance between points
-        for i in range(100):
-            test = self.lhs_initial()
-            phi = self.PhiP(test)
-            if phi_best > phi:
-                phi_best = phi
-                design = test.copy()
-
-        return design
-
-    def lhs_ese(self):
-        """
-        Create optimized LHS grid using a enhanced stochastic evolutionary algorithm for the PhiP Maximin criterion [1]
-
-        Returns
-        -------
-        design : ndarray of float [n, n_dim]
-            With ESE Algorithm for minimal Phi-P optimized grid points
-
-        Notes
-        -----
-        .. [1] Jin, R., Chen, W., & Sudjianto, A. (2005). An efficient algorithm for constructing optimal
-           design of computer experiments. Journal of statistical planning and inference, 134(1), 268-287.
-        """
-
-        # Parameters
-        t0 = None
-        P0 = self.lhs_initial()
-        J = 25
-        tol = 1e-3
-        p = 10
-        outer_loop = min(int(1.5 * self.dim), 30)
-        inner_loop = min(20 * self.dim, 100)
-
-        if self.coords_norm_reservoir_perced is not None:
-            fixed_index = [*range(self.coords_norm_reservoir_perced.shape[0])]
-        elif self.grid_pre is not None:
-            fixed_index = [*range(self.grid_pre.coords_norm.shape[0])]
-        else:
-            fixed_index = []
-
-        if t0 is None:
-            t0 = 0.005 * self.PhiP(P0, p=p)
-
-        T = t0
-        P_ = P0[:]  # copy of initial design
-        P_best = P_[:]
-        Phi = self.PhiP(P_best, p=p)
-        Phi_best = Phi
-
-        # Outer loop
-        for z in range(outer_loop):
-            Phi_oldbest = Phi_best
-            n_acpt = 0
-            n_imp = 0
-
-            # Inner loop
-            for i in range(inner_loop):
-                modulo = (i + 1) % self.dim
-                l_P = list()
-                l_Phi = list()
-
-                # Build J different designs with a single exchanged row
-                # See PhiP_exchange
-                for j in range(J):
-                    l_P.append(P_.copy())
-                    l_Phi.append(self.PhiP_exchange(l_P[j], k=modulo, Phi=Phi, p=p, fixed_index=fixed_index))
-
-                l_Phi = np.asarray(l_Phi)
-                k = np.argmin(l_Phi)
-                Phi_try = l_Phi[k]
-
-                # Threshold of acceptance
-                if Phi_try - Phi <= T * np.random.rand(1)[0]:
-                    Phi = Phi_try
-                    n_acpt = n_acpt + 1
-                    P_ = l_P[k]
-
-                    # Best design retained
-                    if Phi < Phi_best:
-                        P_best = P_
-                        Phi_best = Phi
-                        n_imp = n_imp + 1
-
-            p_accpt = float(n_acpt) / inner_loop  # probability of acceptance
-            p_imp = float(n_imp) / inner_loop  # probability of improvement
-
-            if Phi_best - Phi_oldbest < tol:
-                # flag_imp = 1
-                if p_accpt >= 0.1 and p_imp < p_accpt:
-                    T = 0.8 * T
-                elif p_accpt >= 0.1 and p_imp == p_accpt:
-                    pass
-                else:
-                    T = T / 0.8
-            else:
-                # flag_imp = 0
-                if p_accpt <= 0.1:
-                    T = T / 0.7
-                else:
-                    T = 0.9 * T
-
-        return P_best
-
-
-class CO(RandomGrid):
-    """
-    Coherence Optimal grid object
-
-    Parameters
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    n_grid: int
-        Number of random samples to generate
-    options: dict, optional, default=None
-        Grid options:
-        - 'seed'            : Seeding point
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> grid = pygpc.CO(parameters_random=parameters_random, n_grid=100, options={"seed": None})
-
-    Attributes
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    n_grid : int or float
-        Number of random samples in grid
-    seed : float, optional, default=None
-        Seeding point to replicate random grid
-    options: dict, optional, default=None
-        Grid options:
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    """
-
-    def __init__(self, parameters_random, gpc, n_grid=None, options=None, coords=None, coords_norm=None,
-                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None,
-                 grid_pre=None):
-        """
-        Constructor; Initializes CO instance; Generates grid or copies provided content
-        """
-        if options is None:
-            options = dict()
-
-        if "seed" not in options.keys():
-            options["seed"] = None
-
-        if "n_warmup" not in options.keys():
-            options["n_warmup"] = max(200, n_grid*2)
-        else:
-            options["n_warmup"] = max(options["n_warmup"], n_grid * 2)
-
-        if "n_pool" not in options.keys():
-            if 1000 > 2 * n_grid:
-                options["n_pool"] = 1000
-            else:
-                options["n_pool"] = 2*n_grid
-
-        self.gpc = gpc
-        self.grid_pre = grid_pre
-        self.coords_pool = []
-        self.gpc_matrix_pool = []
-        self.b2_pool = []
-        self.g_pool = []
-        self.f_pool = []
-        self.n_pool = options["n_pool"]
-        self.all_norm = []
-
-        super(CO, self).__init__(parameters_random,
-                                 n_grid=n_grid,
-                                 options=options,
-                                 coords=coords,
-                                 coords_norm=coords_norm,
-                                 coords_gradient=coords_gradient,
-                                 coords_gradient_norm=coords_gradient_norm,
-                                 coords_id=coords_id,
-                                 coords_gradient_id=coords_gradient_id,
-                                 grid_pre=grid_pre)
-        if n_grid == 0:
-            pass
-        else:
-            self.ball_volume = self.calc_ball_volume(dim=self.dim, radius=np.sqrt(2) * np.sqrt(2*self.gpc.order_max+1))
-            pdf_type = [self.parameters_random[rv].pdf_type for rv in self.parameters_random]
-            self.all_norm = np.array([p == "norm" for p in pdf_type]).all()
-            any_norm = np.array([True for p in pdf_type if p == "norm"]).any() and not self.all_norm
-
-            if any_norm:
-                raise AssertionError("Mixed distributions of beta and normal for CO grids not implemented..."
-                                     "All variables have to be either normal or beta distributed!")
-
-            # create proposal distributed random variables
-            self.parameters_random_proposal = dict()
-            for rv in self.parameters_random:
-                # check the order > dimension criteria
-                if gpc.order_max > self.dim:
-
-                    # uniform distributed random variables -> Chebyshev distribution
-                    if self.parameters_random[rv].pdf_type == "beta" and \
-                            (self.parameters_random[rv].pdf_shape == [1, 1]).all():
-                        self.parameters_random_proposal[rv] = Beta(pdf_shape=[0.5, 0.5],
-                                                                   pdf_limits=[-1, 1])
-
-                    # normal distributed random variables -> sample uniformly from the d-dimensional ball of radius r
-                    # here a standard normal distribution is created, the uniform sampling from the ball is considered in
-                    # the method "create_pool"
-                    elif self.parameters_random[rv].pdf_type == "norm":
-                        self.parameters_random_proposal[rv] = Norm(pdf_shape=[0, 1],
-                                                                   p_perc=self.parameters_random[rv].p_perc)
-
-                    else:
-                        NotImplementedError("Coherence optimal sampling is only possible for uniform and normal "
-                                            "distributed random variables")
-                else:
-                    self.parameters_random_proposal[rv] = self.parameters_random[rv]
-            #define number of warmup-samples
-            self.n_warmup = options["n_warmup"]
-
-            # # draw sample pool for warmup
-            # self.create_pool(n_samples=2*options["n_warmup"])
-            #
-            # # warmup
-            # self.warmup(n_warmup=options["n_warmup"])
-
-            # draw sample pool for actual sampling
-            self.create_pool(n_samples=self.n_pool + self.n_warmup)
-
-            # get coherence optimal samples
-            self.coords_norm = self.get_coherence_optimal_samples(n_grid=self.n_grid, n_warmup=self.n_warmup)
-
-            # Denormalize grid to original parameter space
-            self.coords = self.get_denormalized_coordinates(self.coords_norm)
-
-    def create_pool(self, n_samples):
-        """
-        Creates a pool of samples together with the corresponding gPC matrix.
-
-        Parameters
-        ----------
-        n_samples : int
-            Number of samples
-        """
-
-        self.n_pool = n_samples
-        self.coords_pool = np.zeros((n_samples, self.dim))
-
-        for i_rv, rv in enumerate(self.parameters_random_proposal):
-            self.coords_pool[:, i_rv] = self.parameters_random_proposal[rv].sample(n_samples=int(self.n_pool))
-
-        if self.all_norm:
-            # sample from d-dimensional ball of radius r (Hampton et al. 2015, pp. 369)
-            r = np.sqrt(2)*np.sqrt(2*self.gpc.order_max+1)
-            self.coords_pool = self.coords_pool / (np.linalg.norm(self.coords_pool, axis=1))[:, np.newaxis] * \
-                               r * np.random.rand(1) ** (1/self.dim)
-
-        self.gpc_matrix_pool = self.gpc.create_gpc_matrix(b=self.gpc.basis.b, x=self.coords_pool)
-
-        self.b2_pool = np.linalg.norm(self.gpc_matrix_pool, axis=1)**2
-        self.g_pool = self.joint_pdf(x=self.coords_pool, parameters_random=self.parameters_random_proposal)
-        self.f_pool = self.joint_pdf(x=self.coords_pool, parameters_random=self.parameters_random)
-
-    @staticmethod
-    def calc_ball_volume(dim, radius):
-        """
-        Volume of n-dimensional ball.
-
-        Parameters
-        ----------
-        dim : int
-            Number of random variables
-        radius : float
-            Radius
-
-        Returns
-        -------
-        vol : float
-            Volume of n-dimensional ball
-        """
-        vol = radius**dim * np.pi**(dim/2) / gamma(dim/2 + 1)
-
-        return vol
-
-    def joint_pdf(self, x, parameters_random):
-        """
-        Joint probability density function of random variables
-
-        Parameters
-        ----------
-        x : ndarray of float [n_samples x n_dim]
-            Samples of random variables
-        parameters_random : dict of RandomVariable instances
-            Random variables of proposal distribution
-
-        Returns
-        -------
-        f : float
-            Joint probability density
-        """
-        f = np.ones(x.shape[0])
-
-        if np.array([True for p in parameters_random if parameters_random[p].pdf_type == "norm"]).all():
-            f *= 1/self.ball_volume
-        else:
-            for i_rv, rv in enumerate(parameters_random):
-                f *= parameters_random[rv].pdf_norm(x=x[:, i_rv])[1]
-
-        return f
-
-    def acceptance_rate(self, idx1, idx2):
-        """
-        Calculate acceptance rate of Metropolis Hastings algorithm
-
-        Parameters
-        ----------
-        idx1 : int
-            Index of sampling points of previous sample
-        idx2 : int
-            Index of sampling points of current sample
-
-        Returns
-        -------
-        rho : float
-            Acceptance rate
-        """
-
-        rho = np.min((1.,
-                     (self.g_pool[idx1]*self.f_pool[idx2]*self.b2_pool[idx2]) /
-                     (self.g_pool[idx2]*self.f_pool[idx1]*self.b2_pool[idx1])))
-
-        return rho
-
-    def warmup(self, n_warmup):
-        """
-        Warmup phase
-
-        Parameters
-        ----------
-        n_warmup : int
-            Number of warmup samples
-
-        Returns
-        -------
-        coords_norm_opt : ndarray of float [n_warmup x n_dim]
-            Optimal coordinates determined during warmup phase
-        """
-
-        coords_norm_opt = self.get_coherence_optimal_samples(n_grid=n_warmup)
-
-        return coords_norm_opt
-
-    def get_coherence_optimal_samples(self, n_grid, n_warmup):
-        """
-        Determine coherence optimal samples with Monte Carlo Markov Chain - Metropolis Hastings algorithm
-
-        Parameters
-        ----------
-        n_grid : int
-            Number of grid points
-        n_warmup: int
-            Number of warmup samples
-
-        Returns
-        -------
-        coords_norm : ndarray of float [n_grid x n_dim]
-            Coherence optimal samples
-        """
-        coords_norm_opt = np.zeros((n_grid, self.dim))
-        coords_norm_opt[0, :] = self.coords_pool[0, :][np.newaxis, :]
-
-        if self.grid_pre is not None:
-            coords_norm_opt[:self.grid_pre.n_grid, :] = self.grid_pre.coords_norm
-            i_grid_start = self.grid_pre.n_grid
-        else:
-            i_grid_start = 0
-
-        # init grid_index at -n_warmup, then the number of warmup-samples are automatically drawn,
-        # before index 0 is reached
-        i_grid = -(n_warmup - i_grid_start)
-        idx1 = 0
-        idx2 = 1
-
-        if self.all_norm:
-            x_perc_norm = np.zeros(len(self.parameters_random))
-            for i_rv, rv in enumerate(self.parameters_random):
-                x_perc_norm[i_rv] = self.parameters_random[rv].x_perc_norm[1]
-
-        while i_grid < n_grid:
-            # create a new pool if it is empty
-            if idx2 >= self.n_pool:
-                self.create_pool(2*n_grid)
-                idx1 = 0
-                idx2 = 1
-
-            # determine acceptance rate
-            rho = self.acceptance_rate(idx1=idx1, idx2=idx2)
-
-            # add point if acceptance rate is high
-            if rho > np.random.rand(1):
-                    if self.all_norm:
-                        if (np.abs(self.coords_pool[idx2, :]) < x_perc_norm).all():
-                            if i_grid > (i_grid_start-1):
-                                coords_norm_opt[i_grid, :] = self.coords_pool[idx2, :]
-                            i_grid += 1
-                            idx1 = idx2
-                    else:
-                        if i_grid > (i_grid_start-1):
-                            coords_norm_opt[i_grid, :] = self.coords_pool[idx2, :]
-                        i_grid += 1
-                        idx1 = idx2
-
-            idx2 += 1
-
-        return coords_norm_opt
-
-
-class L1(RandomGrid):
-    """
-    L1 optimized grid object
-
-    Parameters
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    n_grid: int
-        Number of random samples to generate
-    options: dict, optional, default=None
-        Grid options:
-        - method: "greedy", "iteration"
-        - criterion: ["mc"], ["tmc", "cc"], ["D"], ["D-coh"]
-        - weights: [1], [0.5, 0.5], [1]
-        - n_pool: size of samples in pool to choose greedy results from
-        - n_iter: number of iterations
-        - seed: random seed
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    gpc : GPC object instance
-        GPC object
-    grid_pre : Grid object instance, optional, default: None
-        Existent grid, which will be extended.
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> grid = pygpc.L1(parameters_random=parameters_random,
-    >>>                 n_grid=100,
-    >>>                 options={"method": "greedy",
-    >>>                          "criterion": ["mc"],
-    >>>                          "weights": [1],
-    >>>                          "n_pool": 1000,
-    >>>                          "seed": None})
-
-    Attributes
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    n_grid : int or float
-        Number of random samples in grid
-    seed : float, optional, default=None
-        Seeding point to replicate random grid
-    options: dict, optional, default=None
-        Grid options:
-        - method: "greedy", "iteration"
-        - criterion: ["mc"], ["tmc", "cc"], ["D"], ["D-coh"]
-        - weights: [1], [0.5, 0.5], [1]
-        - n_pool: size of samples in pool to choose greedy results from
-        - n_iter: number of iterations
-        - seed: random seed
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    gpc : GPC Object instance
-        GPC object
-    grid_pre : Grid object instance, optional, default: None
-        Existent grid, which will be extended.
-    """
-
-    def __init__(self, parameters_random, n_grid=None, options=None, coords=None, coords_norm=None,
-                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None, gpc=None,
-                 grid_pre=None):
-        """
-        Constructor; Initializes Grid instance; Generates grid or copies provided content
-        """
-        if options is None:
-            options = dict()
-
-        if type(options) is dict:
-            if "method" not in options.keys():
-                options["method"] = "greedy"
-
-            if "n_pool" not in options.keys():
-                options["n_pool"] = 10000
-
-            if "n_iter" not in options.keys():
-                options["n_iter"] = 1000
-
-            if "seed" not in options.keys():
-                options["seed"] = None
-
-            if "criterion" not in options.keys():
-                options["criterion"] = ["mc"]
-
-            if "weights" not in options.keys() or options["weights"] is None:
-                options["weights"] = (np.ones(len(options["criterion"])) / len(options["criterion"])).tolist()
-
-        self.n_pool = options["n_pool"]
-        self.n_iter = options["n_iter"]
-        self.gpc = gpc
-        self.seed = options["seed"]
-        self.method = options["method"]
-        self.criterion = options["criterion"]
-        self.coords_norm_perced = None
-        self.perc_mask = None
-
-        if type(self.criterion) is not list:
-            self.criterion = [self.criterion]
-
-        super(L1, self).__init__(parameters_random,
-                                 n_grid=n_grid,
-                                 options=options,
-                                 coords=coords,
-                                 coords_norm=coords_norm,
-                                 coords_gradient=coords_gradient,
-                                 coords_gradient_norm=coords_gradient_norm,
-                                 coords_id=coords_id,
-                                 coords_gradient_id=coords_gradient_id,
-                                 grid_pre=grid_pre)
-
-        self.weights = options["weights"]
-
-        if self.method == "greedy" and self.n_grid > 0 and self.coords is None:
-            self.coords_norm = self.get_optimal_mu_greedy()
-
-        elif (self.method == 'iteration' or self.method == 'iter') and self.n_grid > 0 and self.coords is None:
-            self.coords_norm = self.get_optimal_mu_iteration()
-
-        if self.n_grid > 0:
-            # Denormalize grid to original parameter space
-            self.coords = self.get_denormalized_coordinates(self.coords_norm)
-
-            # Generate unique IDs of grid points
-            self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
-
-    def get_optimal_mu_greedy(self):
-        """
-        This function computes a set of grid points with minimal mutual coherence using a greedy approach.
-
-        Returns
-        -------
-        coords_norm : ndarray of float [n_grid x dim]
-            Normalized sample coordinates in range [-1, 1]
-        """
-        n_cpu = np.min((1, multiprocessing.cpu_count()))
-
-        # create pool (Standard random grid for D-optimal grids and CO else)
-        if "D" in self.criterion:
-            random_pool = Random(parameters_random=self.parameters_random,
-                                 n_grid=self.n_pool,
-                                 options=self.options)
-        else:
-            random_pool = CO(parameters_random=self.parameters_random,
-                             n_grid=self.n_pool,
-                             gpc=self.gpc,
-                             options=self.options)
-            # full gpc matrix is needed for w_matrix, maybe build a function that creates weighted pools
-            # based of the coordinates
-            # self.gpc.get_weight_matrix()
-            # w_matrix = self.gpc.w
-        index_list = []
-
-        # project grid in case of projection approach
-        if self.gpc.p_matrix is not None:
-            # weight argument in create gpc matrix
-            random_pool_trans = project_grid(grid=random_pool, p_matrix=self.gpc.p_matrix, mode="reduce")
-            psy_pool = self.gpc.create_gpc_matrix(b=self.gpc.basis.b, x=random_pool_trans.coords_norm, gradient=False,
-                                                  weighted=True)
-        else:
-            psy_pool = self.gpc.create_gpc_matrix(b=self.gpc.basis.b, x=random_pool.coords_norm, gradient=False,
-                                                  weighted=True)
-
-        m = int(self.n_grid)
-        m_p = int(np.shape(psy_pool)[0])
-
-        # set up multiprocessing
-        pool = multiprocessing.Pool(n_cpu)
-
-        # set starting point for iteration
-        if self.grid_pre is None or self.grid_pre.n_grid == 0:
-            # get random row of psy to start
-            idx = np.random.randint(m_p)
-            index_list.append(idx)
-            index_list_remaining = [k for k in range(self.n_pool) if k not in index_list]
-            psy_opt = np.zeros((1, psy_pool.shape[1]))
-            psy_opt[0, :] = psy_pool[idx, :]
-            i_start = 1
-
-        else:
-            # project grid in case of projection approach
-            if self.gpc.p_matrix is not None:
-                grid_pre_trans = project_grid(grid=self.grid_pre, p_matrix=self.gpc.p_matrix, mode="reduce")
-                psy_opt = self.gpc.create_gpc_matrix(b=self.gpc.basis.b, x=grid_pre_trans.coords_norm, gradient=False,
-                                                     weighted=True)
-            else:
-                psy_opt = self.gpc.create_gpc_matrix(b=self.gpc.basis.b, x=self.grid_pre.coords_norm, gradient=False,
-                                                     weighted=True)
-
-            index_list = []
-            index_list_remaining = [k for k in range(self.n_pool) if k not in index_list]
-            i_start = self.grid_pre.n_grid
-
-        # loop over grid points
-        for i in range(i_start, m):
-            crit = np.ones((self.n_pool, len(self.criterion))) * 1e6
-
-            workhorse_partial = partial(workhorse_greedy, psy_opt=psy_opt, psy_pool=psy_pool, criterion=self.criterion)
-            idx_list_chunks = compute_chunks(index_list_remaining, n_cpu)
-
-            crit_tmp = pool.map(workhorse_partial, idx_list_chunks)
-
-            if "D" not in self.criterion and "D-coh" not in self.criterion:
-                crit_tmp = np.concatenate(crit_tmp)
-
-            else:
-                sign = []
-                neg_logdet = []
-
-                for res in crit_tmp:
-                    sign.append(res[0])
-                    neg_logdet.append(res[1])
-
-                sign = np.concatenate(sign)
-                neg_logdet = np.concatenate(neg_logdet)
-                neg_logdet_norm = neg_logdet / np.nan_to_num(np.max(np.abs(neg_logdet)))
-                crit_tmp = sign * np.nan_to_num(np.exp(neg_logdet_norm))
-
-            crit[index_list_remaining, :] = crit_tmp
-
-            # set 1e6 dummy values to max values
-            if "D" not in self.criterion and "D-coh" not in self.criterion:
-                for k in range(crit.shape[1]):
-                    crit[crit[:, k] == 1e6, k] = np.max(crit[crit[:, k] != 1e6, k])
-
-            # normalize optimality criteria to [0, 1]
-            crit = np.nan_to_num(crit)
-            crit = (crit - np.nanmin(crit, axis=0)) / np.nan_to_num((np.nanmax(crit, axis=0) - np.nanmin(crit, axis=0)))
-
-            # apply weights
-            crit = np.sum(crit**2 * np.array(self.weights), axis=1)
-
-            # find best index
-            try:
-                index_list.append(np.nanargmin(crit))
-            # in very rare cases there the optimal grid point can not be determined (all nan), in this case the first
-            # grid point of the remaining indices is chosen
-            except ValueError:
-                index_list.append(index_list_remaining[0])
-
-            # add row with best minimal coherence and cross correlation properties to the matrix
-            psy_opt = np.vstack((psy_opt, psy_pool[index_list[-1], :]))
-
-            # create list of remaining indices
-            index_list_remaining = [k for k in range(self.n_pool) if k not in index_list]
-
-        coords_norm = random_pool.coords_norm[index_list, :]
-
-        pool.close()
-        pool.join()
-
-        if self.grid_pre is not None:
-            coords_norm = np.vstack((self.grid_pre.coords_norm, coords_norm))
-
-        return coords_norm
-
-    def get_optimal_mu_iteration(self):
-        """
-        This function computes a set of grid points with minimal mutual coherence using an iterative approach.
-
-        Returns
-        -------
-        coords_norm : ndarray of float [n_grid x dim]
-            Normalized sample coordinates in range [-1, 1]
-        """
-        n_cpu = np.min((1, multiprocessing.cpu_count()))
-        coords_norm_list = []
-        crit = np.ones((self.n_iter, len(self.criterion))) * 1e6
-
-        # set up multiprocessing
-        pool = multiprocessing.Pool(n_cpu)
-        workhorse_partial = partial(workhorse_iteration,
-                                    gpc=self.gpc,
-                                    n_grid=self.n_grid,
-                                    criterion=self.criterion,
-                                    grid_pre=self.grid_pre,
-                                    options={"seed": self.seed})
-        idx_list_chunks = compute_chunks([k for k in range(self.n_iter)], n_cpu)
-
-        res = pool.map(workhorse_partial, idx_list_chunks)
-
-        for j in range(len(res)):
-            if j == 0:
-                if "D" not in self.criterion and "D-coh" not in self.criterion:
-                    crit = res[j][0]
-                    coords_norm_list = res[j][1]
-                else:
-                    sign = res[j][0]
-                    neg_logdet = res[j][1]
-                    neg_logdet_norm = neg_logdet / np.max(np.abs(neg_logdet))
-                    crit = sign * np.exp(neg_logdet_norm)
-                    coords_norm_list = res[j][2]
-            else:
-                if "D" not in self.criterion and "D-coh" not in self.criterion:
-                    crit = np.vstack((crit, res[j][0]))
-                    coords_norm_list = coords_norm_list + res[j][1]
-                else:
-                    sign = res[j][0]
-                    neg_logdet = res[j][1]
-                    neg_logdet_norm = neg_logdet / np.max(np.abs(neg_logdet))
-                    crit = np.vstack((crit, sign * np.exp(neg_logdet_norm)))
-                    coords_norm_list = coords_norm_list + res[j][2]
-
-        # normalize optimality criteria to [0, 1]
-        crit = (crit - np.min(crit, axis=0)) / np.nan_to_num((np.max(crit, axis=0) - np.min(crit, axis=0)))
-
-        # apply weights
-        crit = np.sum(crit**2 * np.array(self.weights), axis=1)
-
-        coords_norm = coords_norm_list[np.argmin(crit)]
-
-        pool.close()
-
-        return coords_norm
-
-
-class FIM(RandomGrid):
-    """
-    FIM D-optimal grid object
-
-    Parameters
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    n_grid: int
-        Number of random samples to generate
-    seed: float
-        Seeding point to replicate random grids
-    options: dict, optional, default=None
-        Grid options:
-        - 'n_pool'   : number of random samples to determine next optimal grid point
-        - 'seed'     : random seed
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> grid = pygpc.FIM(parameters_random=parameters_random,
-    >>>                  n_grid=100,
-    >>>                  options={"n_pool": 1000,
-    >>>                           "seed": None})
-
-    Attributes
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    n_grid : int or float
-        Number of random samples in grid
-    seed : float, optional, default=None
-        Seeding point to replicate random grid
-    options: dict, optional, default=None
-        Grid options:
-        - method: "greedy", "iteration"
-        - criterion: ["mc"], ["tmc", "cc"]
-        - weights: [1], [0.5, 0.5]
-        - n_pool: size of samples in pool to choose greedy results from
-        - n_iter: number of iterations
-        - seed: random seed
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    """
-
-    def __init__(self, parameters_random, n_grid=None, options=None, coords=None, coords_norm=None,
-                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None, gpc=None,
-                 grid_pre=None):
-        """
-        Constructor; Initializes Grid instance; Generates grid or copies provided content
-        """
-        if options is None:
-            options = dict()
-
-        if type(options) is dict:
-
-            if "n_pool" not in options.keys():
-                options["n_pool"] = 1000
-
-            if "seed" not in options.keys():
-                options["seed"] = None
-
-        self.n_pool = options["n_pool"]
-        self.gpc = copy.deepcopy(gpc)
-
-        super(FIM, self).__init__(parameters_random,
-                                  n_grid=n_grid,
-                                  options=options,
-                                  coords=coords,
-                                  coords_norm=coords_norm,
-                                  coords_gradient=coords_gradient,
-                                  coords_gradient_norm=coords_gradient_norm,
-                                  coords_id=coords_id,
-                                  coords_gradient_id=coords_gradient_id,
-                                  grid_pre=grid_pre)
-
-        if coords_norm is not None:
-            self.gpc.grid = Random(parameters_random=parameters_random,
-                                   coords_norm=coords_norm,
-                                   coords=coords,
-                                   options=self.options)
-            n_grid_add = self.gpc.grid.n_grid
-
-            if self.gpc.p_matrix is not None:
-                self.gpc.gpc_matrix = self.gpc.create_gpc_matrix(b=self.gpc.basis.b,
-                                                                 x=np.matmul(coords_norm,
-                                                                             self.gpc.p_matrix.transpose() /
-                                                                             self.gpc.p_matrix_norm[np.newaxis, :]),
-                                                                 gradient=False)
-            else:
-                self.gpc.gpc_matrix = self.gpc.create_gpc_matrix(b=self.gpc.basis.b,
-                                                                 x=coords_norm,
-                                                                 gradient=False)
-        elif self.grid_pre is not None:
-            self.gpc.grid = self.grid_pre
-            n_grid_add = self.n_grid - self.grid_pre.n_grid
-
-            if n_grid_add < 0:
-                raise RuntimeError(f"Number of grid points to add has to be >= 0 (it is {n_grid_add}")
-
-            if self.gpc.p_matrix is not None:
-                self.gpc.gpc_matrix = self.gpc.create_gpc_matrix(b=self.gpc.basis.b,
-                                                                 x=np.matmul(self.grid_pre.coords_norm,
-                                                                             self.gpc.p_matrix.transpose() /
-                                                                             self.gpc.p_matrix_norm[np.newaxis, :]),
-                                                                 gradient=False)
-            else:
-                self.gpc.gpc_matrix = self.gpc.create_gpc_matrix(b=self.gpc.basis.b,
-                                                                 x=self.grid_pre.coords_norm,
-                                                                 gradient=False)
-        else:
-            n_grid_add = self.n_grid
-
-        # add FIM optimal grid points (eventually to existing grid)
-        self.coords_norm = self.add_fim_optiomal_grid_points(parameters_random=parameters_random,
-                                                             n_grid_add=n_grid_add)
-
-        # Denormalize grid to original parameter space
-        self.coords = self.get_denormalized_coordinates(self.coords_norm)
-
-        # Generate unique IDs of grid points
-        self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
-
-    def add_fim_optiomal_grid_points(self, parameters_random, n_grid_add):
-        """
-        This function adds grid points (one by one) to the set of points by maximizing the Fisher-information matrix
-        in a D-optimal sense.
-
-        Parameters
-        ----------
-        parameters_random : OrderedDict of RandomParameter [dim]
-            Random parameters (in case of projection, provide the original random parameters)
-        n_grid_add : int
-            Number of grid points to add
-
-        Returns
-        -------
-        coords_norm : ndarray of float [n_grid x dim]
-            Normalized sample coordinates in range [-1, 1]
-        """
-
-        # coords_norm_opt = np.zeros((n_grid_add, self.dim))
-        #
-        # for i in range(n_grid_add):
-        #     fim_matrix = self.calc_fim_matrix()
-        #     grid_test = Random(parameters_random=self.gpc.problem.parameters_random,
-        #                        n_grid=self.n_pool,
-        #                        options=self.options)
-        #
-        #     det = np.zeros(grid_test.coords_norm.shape[0])
-        #
-        #     for i_c, c in enumerate(grid_test.coords_norm):
-        #         det[i_c] = self.get_det_updated_fim_matrix(fim_matrix=fim_matrix, coords_norm=c)
-        #
-        #     coords_norm_opt[i, :] = grid_test.coords_norm[np.argmax(det), :]
-        #
-        # return coords_norm_opt
-
-        coords_norm_opt = np.zeros((n_grid_add, self.dim))
-        n_cpu = multiprocessing.cpu_count()
-        pool = multiprocessing.Pool(n_cpu)
-
-        grid_pool = Random(parameters_random=parameters_random,
-                           n_grid=self.n_pool,
-                           options={"seed": self.seed})
-
-        if self.gpc.p_matrix is not None:
-            gpc_matrix_pool = self.gpc.create_gpc_matrix(b=self.gpc.basis.b,
-                                                         x=np.matmul(self.grid_pool.coords_norm,
-                                                                     self.gpc.p_matrix.transpose() /
-                                                                     self.gpc.p_matrix_norm[np.newaxis, :]),
-                                                         gradient=False)
-        else:
-            gpc_matrix_pool = self.gpc.create_gpc_matrix(b=self.gpc.basis.b,
-                                                         x=grid_pool.coords_norm,
-                                                         gradient=False)
-
-        if self.gpc.gpc_matrix is not None:
-            fim_matrix = self.calc_fim_matrix()
-        else:
-            fim_matrix = None
-
-        index_list = []
-
-        for i in range(n_grid_add):
-            det = np.zeros((self.n_pool))
-
-            if self.seed is not None:
-                self.seed += 1
-                self.options["seed"] += 1
-
-            # select random starting point
-            if self.gpc.gpc_matrix is None:
-                coords_opt = grid_pool.coords_norm[0, :][np.newaxis, ]
-                self.gpc.grid = Random(parameters_random=parameters_random,
-                                       options={"seed": self.seed},
-                                       coords_norm=coords_opt)
-
-                self.gpc.gpc_matrix = self.gpc.create_gpc_matrix(b=self.gpc.basis.b,
-                                                                 x=self.gpc.grid.coords_norm[-1, :][np.newaxis, ],
-                                                                 gradient=False)
-
-                index_list.append(0)
-
-            else:
-                index_list_remaining = [k for k in range(self.n_pool) if k not in index_list]
-                index_list_chunks = compute_chunks(index_list_remaining, n_cpu)
-
-                n_basis_limit = np.min((self.gpc.grid.n_grid, self.gpc.basis.n_basis))
-                workhorse_partial = partial(workhorse_get_det_updated_fim_matrix,
-                                            gpc_matrix_pool=gpc_matrix_pool,
-                                            fim_matrix=fim_matrix,
-                                            n_basis_limit=n_basis_limit)
-
-                res = pool.map(workhorse_partial, index_list_chunks)
-
-                sign = []
-                logdet = []
-
-                for r in res:
-                    sign.append(r[0])
-                    logdet.append(r[1])
-
-                sign = np.concatenate(sign)
-                logdet = np.concatenate(logdet)
-
-                logdet_norm = logdet / np.max(np.abs(logdet))
-                det[index_list_remaining] = (sign * np.exp(logdet_norm)).flatten()
-                index_list.append(np.nanargmax(det))
-
-                coords_opt = grid_pool.coords_norm[index_list[-1], :]
-
-                # add optimal grid point
-                self.gpc.grid.coords_norm = np.vstack((self.gpc.grid.coords_norm, coords_opt))
-
-                # update gpc matrix
-                self.gpc.gpc_matrix = np.vstack((self.gpc.gpc_matrix,
-                                                 self.gpc.create_gpc_matrix(b=self.gpc.basis.b,
-                                                                            x=self.gpc.grid.coords_norm[-1, :][np.newaxis, ],
-                                                                            gradient=False)))
-
-            # update FIM matrix
-            n_basis_limit = np.min((self.gpc.grid.n_grid, self.gpc.basis.n_basis))
-
-            if n_basis_limit == (self.gpc.basis.n_basis+1):
-                fim_matrix = self.update_fim_matrix(fim_matrix=fim_matrix,
-                                                    gpc_matrix_new_rows=self.gpc.gpc_matrix[-1, :][np.newaxis, ])
-            else:
-                fim_matrix = self.calc_fim_matrix(n_basis_limit=n_basis_limit)
-
-        pool.close()
-
-        return self.gpc.grid.coords_norm
-
-    def calc_fim_matrix(self, n_basis_limit=None):
-        """
-        Calculates Fisher-Information matrix based on the present grid.
-
-        Parameters
-        ----------
-        n_basis_limit : int
-            Index of column the FIM matrix is calculated
-
-        Returns
-        -------
-        fim_matrix : ndarray of float [n_basis x n_basis]
-            Fisher information matrix
-        """
-        if n_basis_limit is None:
-            n_basis_limit = self.gpc.gpc_matrix.shape[1]
-
-        fim_matrix = np.zeros((n_basis_limit, n_basis_limit))
-
-        for row in self.gpc.gpc_matrix:
-            fim_matrix += np.outer(row[:n_basis_limit], row[:n_basis_limit])
-
-        return fim_matrix
-
-    @staticmethod
-    def update_fim_matrix(fim_matrix, gpc_matrix_new_rows):
-        """
-        Updates Fisher-Information matrix based on the present grid.
-
-        Parameters
-        ----------
-        fim_matrix : ndarray of float [n_basis x n_basis]
-            Fisher information matrix
-        gpc_matrix_new_rows : ndarray of float [n_new_rows x n_basis]
-            New rows of gpc matrix to add to FIM matrix
-
-        Returns
-        -------
-        fim_matrix : ndarray of float [n_basis x n_basis]
-            Updated Fisher information matrix
-        """
-        if fim_matrix is None:
-            fim_matrix = np.zeros((gpc_matrix_new_rows.shape[1], gpc_matrix_new_rows.shape[1]))
-
-        for row in gpc_matrix_new_rows:
-            fim_matrix += np.outer(row, row)
-
-        return fim_matrix
-
-    def get_det_updated_fim_matrix(self, fim_matrix, coords_norm):
-        """
-        Calculates Fisher-Information matrix based on the present grid and determined determinant.
-
-        Parameters
-        ----------
-        fim_matrix : ndarray of float [n_basis x n_basis]
-            Fisher information matrix
-        coords_norm : ndarray of float [1 x dim]
-            Candidate grid point
-
-        Returns
-        -------
-        det : float
-            Determinant of updated Fisher Information matrix
-        """
-        new_row = self.gpc.create_gpc_matrix(b=self.gpc.basis.b, x=coords_norm, gradient=False)
-        fim_matrix += np.outer(new_row, new_row)
-
-        return np.linalg.det(fim_matrix)
-
-
-class L1_LHS(RandomGrid):
-    """
-    L1-LHS optimized grid object
-
-    Parameters
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    n_grid: int
-        Number of random samples to generate
-    seed: float
-        Seeding point to replicate random grids
-    options: dict, optional, default=None
-        Grid options:
-        - 'corr'            : optimizes design points in their spearman correlation coefficients
-        - 'maximin' or 'm'  : optimizes design points in their maximum minimal distance using the Phi-P criterion
-        - 'ese'             : uses an enhanced evolutionary algorithm to optimize the Phi-P criterion
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> grid = pygpc.L1_LHS(parameters_random=parameters_random,
-    >>>                     n_grid=100,
-    >>>                     gpc=gpc,
-    >>>                     options={"method": "greedy",
-    >>>                              "criterion": ["mc"],
-    >>>                              "weights_L1": [1],
-    >>>                              "weights": [0.25, 0.75],
-    >>>                              "n_pool": 1000,
-    >>>                              "seed": None})
-
-    Attributes
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    n_grid : int or float
-        Number of random samples in grid
-    seed : float, optional, default=None
-        Seeding point to replicate random grid
-    options: dict, optional, default=None
-        Grid options:
-        - method: "greedy", "iteration"
-        - criterion: ["mc"], ["tmc", "cc"]
-        - weights: [1], [0.5, 0.5]
-        - n_pool: size of samples in pool to choose greedy results from
-        - n_iter: number of iterations
-        - seed: random seed
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space), if coords are provided, no grid is generated
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space), if coords are provided, no grid is generated
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    """
-
-    def __init__(self, parameters_random, n_grid=None, options=None, coords=None, coords_norm=None,
-                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None, gpc=None,
-                 grid_pre=None):
-        """
-        Constructor; Initializes Grid instance; Generates grid or copies provided content
-        """
-        if options is None:
-            options = dict()
-
-        if type(options) is dict:
-            if "weights" not in options.keys():
-                options["weights"] = [0.5, 0.5]
-
-            if "method" not in options.keys():
-                options["method"] = "iteration"
-
-            if "n_pool" not in options.keys():
-                options["n_pool"] = 10000
-
-            if "n_iter" not in options.keys():
-                options["n_iter"] = 1000
-
-            if "seed" not in options.keys():
-                options["seed"] = None
-
-            if "criterion" not in options.keys():
-                options["criterion"] = ["mc"]
-
-            if "weights_L1" not in options.keys() or options["weights_L1"] is None:
-                options["weights_L1"] = (np.ones(len(options["criterion"])) / len(options["criterion"])).tolist()
-
-        self.n_pool = options["n_pool"]
-        self.n_iter = options["n_iter"]
-        self.gpc = gpc
-        self.seed = options["seed"]
-        self.method = options["method"]
-        self.criterion = options["criterion"]
-        self.weights_L1 = options["weights_L1"]
-        self.grid_L1 = None
-        self.grid_LHS = None
-        self.grid_pre = grid_pre
-
-        if type(self.criterion) is not list:
-            self.criterion = [self.criterion]
-
-        super(L1_LHS, self).__init__(parameters_random,
-                                     n_grid=n_grid,
-                                     options=options,
-                                     coords=coords,
-                                     coords_norm=coords_norm,
-                                     coords_gradient=coords_gradient,
-                                     coords_gradient_norm=coords_gradient_norm,
-                                     coords_id=coords_id,
-                                     coords_gradient_id=coords_gradient_id)
-
-        self.weights = options["weights"]
-
-        if coords_norm is None:
-            self.n_grid_L1 = int(np.round(self.n_grid * self.weights[0]))
-            self.n_grid_LHS = self.n_grid - self.n_grid_L1
-        else:
-            self.n_grid_L1 = None
-            self.n_grid_LHS = None
-
-        # create L1 grid
-        if coords_norm is None and self.n_grid_L1 > 0:
-            self.grid_L1 = L1(parameters_random=parameters_random,
-                              n_grid=self.n_grid_L1,
-                              gpc=gpc,
-                              grid_pre=grid_pre,
-                              options={"method": self.method,
-                                       "criterion": self.criterion,
-                                       "weights": self.weights_L1,
-                                       "n_pool": self.n_pool,
-                                       "n_iter": self.n_iter,
-                                       "seed": self.seed})
-
-            if self.grid_pre is not None:
-                self.grid_pre.coords_norm = np.vstack((self.grid_pre.coords_norm, self.grid_L1.coords_norm))
-                self.grid_pre.coords = np.vstack((self.grid_pre.coords, self.grid_L1.coords))
-                self.grid_pre.n_grid = self.grid_pre.coords_norm.shape[0]
-            else:
-                self.grid_pre = self.grid_L1
-
-        # create LHS (ese) grid
-        if coords_norm is None and self.n_grid_LHS > 0:
-            self.grid_LHS = LHS(parameters_random=parameters_random,
-                                n_grid=self.n_grid_LHS,
-                                grid_pre=self.grid_pre,
-                                options={"criterion": ["ese"],
-                                         "seed": self.seed})
-
-        if self.grid_L1 is None and self.grid_LHS is not None:
-            self.coords_norm = self.grid_LHS.coords_norm
-        elif self.n_grid_L1 is not None and self.grid_LHS is None:
-            self.coords_norm = self.grid_L1.coords_norm
-        elif self.n_grid_L1 is not None and self.grid_LHS is not None:
-            self.coords_norm = np.vstack((self.grid_L1.coords_norm, self.grid_LHS.coords_norm))
-
-        # Denormalize grid to original parameter space
-        self.coords = self.get_denormalized_coordinates(self.coords_norm)
-
-        # Generate unique IDs of grid points
-        self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
-
-
-class LHS_L1(RandomGrid):
-    """
-    LHS-L1 optimized grid object
-
-    Parameters
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    n_grid: int
-        Number of random samples to generate
-    options: dict, optional, default=None
-        Grid options:
-        - 'corr'            : optimizes design points in their spearman correlation coefficients
-        - 'maximin' or 'm'  : optimizes design points in their maximum minimal distance using the Phi-P criterion
-        - 'ese'             : uses an enhanced evolutionary algorithm to optimize the Phi-P criterion
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> grid = pygpc.LHS_L1(parameters_random=parameters_random,
-    >>>                     n_grid=100,
-    >>>                     gpc=gpc,
-    >>>                     options={"method": "greedy",
-    >>>                              "criterion": ["mc"],
-    >>>                              "weights_L1": [1],
-    >>>                              "weights": [0.25, 0.75],
-    >>>                              "n_pool": 1000,
-    >>>                              "seed": None})
-
-    Attributes
-    ----------
-    parameters_random : OrderedDict of RandomParameter instances
-        OrderedDict containing the RandomParameter instances the grids are generated for
-    n_grid : int or float
-        Number of random samples in grid
-    seed : float, optional, default=None
-        Seeding point to replicate random grid
-    options: dict, optional, default=None
-        Grid options:
-        - method: "greedy", "iteration"
-        - criterion: ["mc"], ["tmc", "cc"]
-        - weights: [1], [0.5, 0.5]
-        - n_pool: size of samples in pool to choose greedy results from
-        - n_iter: number of iterations
-        - seed: random seed
-    coords : ndarray of float [n_grid_add x dim]
-        Grid points to add (model space)
-    coords_norm : ndarray of float [n_grid_add x dim]
-        Grid points to add (normalized space)
-    coords_gradient : ndarray of float [n_grid x dim x dim]
-        Denormalized coordinates xi
-    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
-        Normalized coordinates xi
-    coords_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    coords_gradient_id : list of UUID objects (version 4) [n_grid]
-        Unique IDs of grid points
-    """
-
-    def __init__(self, parameters_random, gpc, n_grid=None, options=None, coords=None, coords_norm=None,
-                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None,
-                 grid_pre=None):
-        """
-        Constructor; Initializes Grid instance; Generates grid or copies provided content
-        """
-        if options is None:
-            options = dict()
-
-        if type(options) is dict:
-            if "weights" not in options.keys():
-                options["weights"] = [0.5, 0.5]
-
-            if "method" not in options.keys():
-                options["method"] = "iteration"
-
-            if "n_pool" not in options.keys():
-                options["n_pool"] = 10000
-
-            if "n_iter" not in options.keys():
-                options["n_iter"] = 1000
-
-            if "seed" not in options.keys():
-                options["seed"] = None
-
-            if "criterion" not in options.keys():
-                options["criterion"] = ["mc"]
-
-            if "weights_L1" not in options.keys() or options["weights_L1"] is None:
-                options["weights_L1"] = (np.ones(len(options["criterion"])) / len(options["criterion"])).tolist()
-
-        self.n_pool = options["n_pool"]
-        self.n_iter = options["n_iter"]
-        self.gpc = gpc
-        self.seed = options["seed"]
-        self.method = options["method"]
-        self.criterion = options["criterion"]
-        self.weights_L1 = options["weights_L1"]
-        self.grid_L1 = None
-        self.grid_LHS = None
-        self.grid_pre = grid_pre
-
-        if type(self.criterion) is not list:
-            self.criterion = [self.criterion]
-
-        super(LHS_L1, self).__init__(parameters_random,
-                                     n_grid=n_grid,
-                                     options=options,
-                                     coords=coords,
-                                     coords_norm=coords_norm,
-                                     coords_gradient=coords_gradient,
-                                     coords_gradient_norm=coords_gradient_norm,
-                                     coords_id=coords_id,
-                                     coords_gradient_id=coords_gradient_id)
-
-        self.weights = options["weights"]
-
-        if coords_norm is None:
-            self.n_grid_LHS = int(np.round(self.n_grid * self.weights[0]))
-            self.n_grid_L1 = self.n_grid - self.n_grid_LHS
-        else:
-            self.n_grid_LHS = None
-            self.n_grid_L1 = None
-
-        # create LHS (ese) grid
-        if coords_norm is None and self.n_grid_LHS > 0:
-            self.grid_LHS = LHS(parameters_random=parameters_random,
-                                n_grid=self.n_grid_LHS,
-                                grid_pre=grid_pre,
-                                options={"criterion": ["ese"],
-                                         "seed": self.seed})
-
-            if self.grid_pre is not None:
-                self.grid_pre.coords_norm = np.vstack((self.grid_pre.coords_norm, self.grid_LHS.coords_norm))
-                self.grid_pre.coords = np.vstack((self.grid_pre.coords, self.grid_LHS.coords))
-                self.grid_pre.n_grid = self.grid_pre.coords_norm.shape[0]
-            else:
-                self.grid_pre = self.grid_LHS
-
-        # create L1 grid
-        if coords_norm is None and self.n_grid_L1 > 0:
-            self.grid_L1 = L1(parameters_random=parameters_random,
-                              n_grid=self.n_grid_L1,
-                              grid_pre=self.grid_pre,
-                              gpc=gpc,
-                              options={"method": self.method,
-                                       "criterion": self.criterion,
-                                       "weights": self.weights_L1,
-                                       "n_pool": self.n_pool,
-                                       "n_iter": self.n_iter,
-                                       "seed": self.seed})
-
-        if self.grid_L1 is None and self.grid_LHS is not None:
-            self.coords_norm = self.grid_LHS.coords_norm
-        elif self.n_grid_L1 is not None and self.grid_LHS is None:
-            self.coords_norm = self.grid_L1.coords_norm
-        elif self.n_grid_L1 is not None and self.grid_LHS is not None:
-            self.coords_norm = np.vstack((self.grid_LHS.coords_norm, self.grid_L1.coords_norm))
-
-        # Denormalize grid to original parameter space
-        self.coords = self.get_denormalized_coordinates(self.coords_norm)
-
-        # Generate unique IDs of grid points
-        self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
-
-
-def project_grid(grid, p_matrix, mode="reduce"):
-    """
-    Transforms grid from original to reduced parameter space or vice versa.
-
-    Parameters
-    ----------
-    grid : Grid object
-        Grid object to transform
-    p_matrix : ndarray of float [n_reduced, n_original]
-        Projection matrix
-    mode : str
-        Direction of transformation ("reduce", "expand")
-
-    Returns
-    -------
-    grid_trans : Grid object
-        Transformed grid object
-    """
-    grid_trans = copy.deepcopy(grid)
-    p_matrix_norm = np.sum(np.abs(p_matrix), axis=1)
-
-    if mode == "reduce":
-        p = p_matrix.transpose()
-        p_n = p / p_matrix_norm[np.newaxis, :]
-    elif mode == "expand":
-        p = p_matrix
-        p_n = p / p_matrix_norm[:, np.newaxis]
-    else:
-        raise ValueError("Specified mode not implemented... ('reduce', 'expand')")
-
-    # transform variables of original grid to reduced parameter space
-    grid_trans.coords = np.matmul(grid.coords, p)
-    grid_trans.coords_norm = np.matmul(grid.coords_norm, p_n)
-
-    return grid_trans
-
-
-def workhorse_greedy(idx_list, psy_opt, psy_pool, criterion):
-    """
-    Workhorse for coherence calculation (greedy algorithm)
-
-    Parameters
-    ----------
-    idx_list : list of int [n_idx]
-        Indices of rows of pool matrix the coherence is calculated for
-    psy_opt : ndarray of float [n_grid_current, n_basis]
-        GPC matrix of previous iteration
-    psy_pool : ndarray of float [n_pool, n_basis]
-        GPC matrix of pool
-    criterion : list of str
-        Optimality criteria
-
-    Returns
-    -------
-    crit : ndarray of float [n_idx, n_criterion]
-        Optimality measures
-    """
-
-    crit = np.ones((len(idx_list), len(criterion))) * 1e6
-
-    # determine gram matrix of psy_opt
-    psy_opt_gram = np.matmul(psy_opt.T, psy_opt)
-
-    if "D" in criterion or "D-coh" in criterion:
-        sign = np.zeros((len(idx_list), 1))
-        logdet = np.zeros((len(idx_list), 1))
-
-    for j in range(len(idx_list)):
-        psy_test = np.vstack((psy_opt, psy_pool[idx_list[j], :]))
-
-        # update gram matrix
-        psy_test_gram = psy_opt_gram + np.outer(psy_test[-1, :], psy_test[-1, :])
-
-        if "mc" in criterion:
-            crit[j, criterion.index("mc")] = mutual_coherence(psy_test)
-
-        if "tmc" in criterion:
-            crit[j, criterion.index("tmc")] = t_averaged_mutual_coherence(psy_test_gram)
-
-        if "cc" in criterion:
-            crit[j, criterion.index("cc")] = average_cross_correlation_gram(psy_test_gram)
-
-        if "D" in criterion or "D-coh" in criterion:
-            # for n_grid < n_basis only consider the first n_grid basis functions because of determinant
-            n_basis_det = np.min((psy_test.shape[0], psy_test.shape[1]))
-
-            # determinant of inverse of Gram is the inverse of the determinant
-            sign[j], logdet[j] = np.linalg.slogdet(psy_test_gram[:n_basis_det, :n_basis_det])
-            #sign[j], logdet[j] = np.linalg.slogdet(np.matmul(psy_test[:, :n_basis_det].T, psy_test[:, :n_basis_det]))
-            logdet[j] = -logdet[j]
-
-    if "D" not in criterion and "D-coh" not in criterion:
-        return crit
-    else:
-        return sign, logdet
-
-
-def workhorse_iteration(idx_list, gpc, n_grid, criterion, grid_pre=None, options=None):
-    """
-    Workhorse for coherence calculation (iterative algorithm)
-
-    Parameters
-    ----------
-    idx_list : list of int [n_idx]
-        Indices of iterations
-    gpc : GPC object
-        GPC object
-    n_grid : int
-        Number of grid points
-    criterion : list of str
-        Optimality criteria
-    grid_pre : Grid object, optional, default: None
-        Grid object, which is going to be extended.
-    options : dict, optional, default: False
-        Dictionary containing the grid options
-
-    Returns
-    -------
-    crit : ndarray of float [n_idx, n_criterion]
-        Optimality measures
-    coords_norm_list : list [n_idx] of ndarray [n_grid x dim]
-        Normalized grid coordinates of grid realizations
-    """
-    coords_norm_list = []
-    crit = np.ones((len(idx_list), len(criterion))) * 1e6
-    backend_backup = gpc.backend
-    gpc.backend = "cpu"
-
-    if "D" in criterion or "D-coh" in criterion:
-        sign = np.zeros((len(idx_list), 1))
-        neg_logdet = np.zeros((len(idx_list), 1))
-
-    if grid_pre is not None and grid_pre.n_grid > 0:
-        psy_pool_pre = gpc.create_gpc_matrix(b=gpc.basis.b, x=grid_pre.coords_norm, gradient=False)
-    else:
-        psy_pool_pre = None
-
-    for i in range(len(idx_list)):
-        # print(f"idx_list iteration: {i}")
-        if gpc.p_matrix is not None:
-            if "D-coh" in criterion:
-                test_grid = CO(parameters_random=gpc.problem_original.parameters_random,
-                               n_grid=n_grid,
-                               grid_pre=grid_pre,
-                               gpc=gpc,
-                               options=options)
-            else:
-                test_grid = Random(parameters_random=gpc.problem_original.parameters_random,
-                                   n_grid=n_grid,
-                                   grid_pre=grid_pre,
-                                   options={"seed": options["seed"]})
-        else:
-            if "D-coh" in criterion:
-                test_grid = CO(parameters_random=gpc.problem.parameters_random,
-                               n_grid=n_grid,
-                               grid_pre=grid_pre,
-                               gpc=gpc,
-                               options=options)
-            else:
-                test_grid = Random(parameters_random=gpc.problem.parameters_random,
-                                   n_grid=n_grid,
-                                   grid_pre=grid_pre,
-                                   options={"seed": options["seed"]})
-
-        coords_norm = test_grid.coords_norm
-
-        # save current coords norm
-        coords_norm_list.append(coords_norm)
-
-        # get the normalized gpc matrix
-        if gpc.p_matrix is not None:
-            psy_pool = gpc.create_gpc_matrix(b=gpc.basis.b,
-                                             x=np.matmul(coords_norm, gpc.p_matrix.transpose() /
-                                                         gpc.p_matrix_norm[np.newaxis, :]),
-                                             gradient=False)
-        else:
-            psy_pool = gpc.create_gpc_matrix(b=gpc.basis.b, x=coords_norm, gradient=False)
-
-        if psy_pool_pre is not None:
-            psy_pool = np.vstack((psy_pool_pre, psy_pool))
-
-        psy_pool_norm = psy_pool / np.abs(psy_pool).max(axis=0)
-
-        # test current matrix
-        if "mc" in criterion:
-            crit[i, criterion.index("mc")] = mutual_coherence(psy_pool_norm)
-
-        if "tmc" in criterion:
-            crit[i, criterion.index("tmc")] = t_averaged_mutual_coherence(np.matmul(psy_pool_norm.T, psy_pool_norm))
-
-        if "cc" in criterion:
-            crit[i, criterion.index("cc")] = average_cross_correlation_gram(np.matmul(psy_pool_norm.T, psy_pool_norm))
-
-        if "D" in criterion or "D-coh" in criterion:
-            # for n_grid < n_basis only consider the first n_grid basis functions because of determinant
-            n_basis_det = np.min((n_grid, gpc.basis.n_basis))
-
-            # determinant of inverse of Gram is the inverse of the determinant
-            sign[i], neg_logdet[i] = np.linalg.slogdet(np.matmul(psy_pool_norm[:, :n_basis_det].T, psy_pool_norm[:, :n_basis_det]))
-            neg_logdet[i] = -neg_logdet[i]
-
-    gpc.backend = backend_backup
-
-    if "D" not in criterion and "D-coh" not in criterion:
-        return crit, coords_norm_list
-    else:
-        return sign, neg_logdet, coords_norm_list
-
-
-def workhorse_get_det_updated_fim_matrix(index_list, gpc_matrix_pool, fim_matrix, n_basis_limit):
-    """
-    Workhorse to determine the determinant of the Fisher Information matrix
-
-    Parameters
-    ----------
-    index_list : list of int
-        Indices of coordinates to test
-    gpc_matrix_pool : ndarray of float [n_grid_pool x n_basis]
-        Gpc matrix of large pool
-    fim_matrix : ndarray of float [n_basis x n_basis]
-        Fisher information matrix
-
-    Returns
-    -------
-    det : float
-        Determinant of updated Fisher Information matrix
-    """
-    sign = np.zeros(len(index_list))
-    logdet = np.zeros(len(index_list))
-
-    for i, idx in enumerate(index_list):
-        fim_matrix_test = fim_matrix + np.outer(gpc_matrix_pool[idx, :n_basis_limit],
-                                                gpc_matrix_pool[idx, :n_basis_limit])
-        sign[i], logdet[i] = np.linalg.slogdet(fim_matrix_test)
-
-    return sign, logdet
-
-
-def compute_neg_loglik(parameters, Xtrain, ytrain):
-    """
-    Computes the negative log likelihood of the hyperparameters of the Gaussian Process Regression.
-
-    Parameters
-    ----------
-    parameters : np.ndarray of float [2]
-        Hyperparameters (lengthscale, variance)
-    Xtrain : np.ndarray of float [N_train x dim]
-        Coordinates of the training data
-    ytrain : np.ndarray of float [N_train]
-        Function values at the training data points
-
-    Returns
-    -------
-    log_likelihood : float
-        Negative log likelihood
-    """
-    lengthscale, variance = parameters
-    K = squared_exponential_kernel(Xtrain, Xtrain, lengthscale, variance)  # n_train x n_train
-
-    try:
-        L = np.linalg.cholesky(K)
-    except np.linalg.LinAlgError:
-        return 0
-
-    alpha = np.linalg.solve(L.T, np.linalg.solve(L, ytrain))
-    log_likelihood = - 0.5 * ytrain.T @ alpha - np.log(np.diag(L)).sum() - len(ytrain) / 2 * np.log(2 * np.pi)
-
-    return - log_likelihood.squeeze()
-
-
-def get_parameters_gaussian_process(Xtrain, ytrain):
-    """
-    Determine optimal hyperparameters for Gaussian Process Regression (lengthscale, variance), without noise.
-
-    Parameters
-    ----------
-    Xtrain : np.ndarray of float [N_train x dim]
-        Coordinates of the training data
-    ytrain : np.ndarray of float [N_train]
-        Function values at the training data points
-
-    Returns
-    -------
-    lengthscale : float, optional, default: 1.
-        Lengthscale parameter
-    variance : float, optional, default: 1.
-        Output variance
-    """
-    lengthscale = .2
-    kernel_variance = 1
-    bounds = ((1e-3, 1e2), (1e-3, 1e2))
-    initial_parameters = np.array([lengthscale, kernel_variance])
-    args = (Xtrain, ytrain)
-    result = minimize(compute_neg_loglik, initial_parameters, args, method='l-bfgs-b', bounds=bounds)
-    lengthscale = result.x[0]
-    variance = result.x[1]
-
-    return lengthscale, variance
+import uuid
+import copy
+import warnings
+import scipy.stats
+import numpy as np
+from tqdm import tqdm
+from .io import iprint
+from .Quadrature import *
+from scipy.special import gamma
+from scipy.optimize import minimize
+from .RandomParameter import Beta
+from .RandomParameter import Norm
+from .misc import compute_chunks
+from .misc import mutual_coherence
+from .misc import get_multi_indices
+from .misc import get_cartesian_product
+from .misc import squared_exponential_kernel
+from .misc import t_averaged_mutual_coherence
+from .misc import average_cross_correlation_gram
+from .misc import get_different_rows_from_matrices
+
+import multiprocessing.pool
+from _functools import partial
+
+warnings.filterwarnings('ignore')
+
+class Grid(object):
+    """
+    Grid class
+
+    Parameters
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    weights: ndarray of float [n_grid x dim]
+        Weights of the grid (all)
+    coords: ndarray of float [n_grid x dim]
+        Denormalized coordinates xi
+    coords_norm: ndarray of float [n_grid x dim]
+        Normalized coordinates xi
+    coords_gradient: ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm: ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id: list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+
+    Attributes
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    _weights: ndarray of float [n_grid x dim]
+        Weights of the grid (all)
+    _coords: ndarray of float [n_grid x dim]
+        Denormalized coordinates xi
+    _coords_norm: ndarray of float [n_grid x dim]
+        Normalized coordinates xi
+    _domains: ndarray of float [n_grid]
+        Domain IDs of grid points for multi-element gPC
+    _coords_gradient: ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    _coords_gradient_norm: ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id: list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    n_grid: int
+        Total number of nodes in grid.
+    """
+    def __init__(self, parameters_random, coords=None, coords_norm=None,
+                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None,
+                 grid_pre=None):
+        """
+        Constructor; Initialize Grid class
+        """
+        self._coords = coords                         # Coordinates of gpc model calculation in the system space
+        self._coords_norm = coords_norm               # Coordinates of gpc model calculation in the gpc space
+        self.coords_id = coords_id                    # Unique IDs of grid points
+        self.coords_gradient_id = coords_gradient_id  # Unique IDs of grid gradient points
+        self._weights = None                          # Weights for numerical integration
+        self.parameters_random = parameters_random    # OrderedDict of RandomParameter instances
+        self.dim = len(self.parameters_random)        # Number of random variables
+        self._coords_gradient = coords_gradient       # Shifted coordinates for gradient calculation in the system space
+        self._coords_gradient_norm = coords_gradient_norm  # Normalized coordinates for gradient calculation
+        self.grid_pre = grid_pre                      # Previous grid the new grid is based on
+
+        if coords is not None:
+            self.n_grid = self.coords.shape[0]                    # Total number of grid points
+
+        if coords_gradient is not None:
+            self.n_grid_gradient = self.coords_gradient.shape[0]  # Total number of grid points for gradient calculation
+
+        if coords_id is None and coords is not None:
+            self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
+            self.n_grid = self._coords.shape[0]
+
+        if coords_gradient_id is None and coords_gradient is not None:
+            self.coords_gradient_id = [uuid.uuid4() for _ in range(self.n_grid)]
+            self.n_grid_gradient = self._coords_gradient.shape[0]
+
+        if coords is not None and coords_norm is None:
+            self.coords_norm = self.get_normalized_coordinates(self.coords)
+
+    @property
+    def coords(self):
+        return self._coords
+
+    @coords.setter
+    def coords(self, value):
+        if value.ndim == 1:
+            value = value[np.newaxis, :]
+
+        self._coords = value
+
+        if value is not None:
+            self.n_grid = self._coords.shape[0]
+
+            # Generate unique IDs of grid points
+            if self.coords_id is None:
+                self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
+
+    @property
+    def coords_norm(self):
+        return self._coords_norm
+
+    @coords_norm.setter
+    def coords_norm(self, value):
+        if value.ndim == 1:
+            value = value[np.newaxis, :]
+
+        self._coords_norm = value
+
+        if value is not None:
+            self.n_grid = self._coords_norm.shape[0]
+
+            # Generate unique IDs of grid points
+            if self.coords_id is None:
+                self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
+
+    @property
+    def coords_gradient(self):
+        return self._coords_gradient
+
+    @coords_gradient.setter
+    def coords_gradient(self, value):
+        assert value.ndim == 3, "Specify coords_gradient as 3D tensor of shape [n_grid x dim x dim]"
+
+        self._coords_gradient = value
+
+        if value is not None:
+            self.n_grid_gradient = self._coords_gradient.shape[0]
+
+            # Generate unique IDs of grid gradient points
+            if self.coords_gradient_id is None:
+                self.coords_gradient_id = [uuid.uuid4() for _ in range(self.n_grid_gradient)]
+
+    @property
+    def coords_gradient_norm(self):
+        return self._coords_gradient_norm
+
+    @coords_gradient_norm.setter
+    def coords_gradient_norm(self, value):
+        assert value.ndim == 3, "Specify coords_gradient_norm as 3D tensor of shape [n_grid x dim x dim]"
+        self._coords_gradient_norm = value
+
+        if value is not None:
+            self.n_grid_gradient = self._coords_gradient_norm.shape[0]
+
+            # Generate unique IDs of grid gradient points
+            if self.coords_gradient_id is None:
+                self.coords_gradient_id = [uuid.uuid4() for _ in range(self.n_grid_gradient)]
+
+    @property
+    def weights(self):
+        return self._weights
+
+    @weights.setter
+    def weights(self, value):
+        self._weights = value
+
+    def get_denormalized_coordinates(self, coords_norm):
+        """
+        Denormalize grid from normalized to original parameter space for simulations.
+
+        coords = Grid.get_denormalized_coordinates(coords_norm)
+
+        Parameters
+        ----------
+        coords_norm: [N_samples x dim] np.ndarray
+            Normalized coordinates xi
+
+        Returns
+        -------
+        coords: [N_samples x dim] np.ndarray
+            Denormalized coordinates xi
+        """
+        coords = np.zeros(coords_norm.shape)
+
+        for i_p, p in enumerate(self.parameters_random):
+
+            if self.parameters_random[p].pdf_type == "beta":
+                coords[:, i_p, ] = (coords_norm[:, i_p, ] + 1) / \
+                                   2 * (self.parameters_random[p].pdf_limits[1] -
+                                        self.parameters_random[p].pdf_limits[0]) \
+                                   + self.parameters_random[p].pdf_limits[0]
+
+            if self.parameters_random[p].pdf_type in ["norm", "normal"]:
+                coords[:, i_p, ] = coords_norm[:, i_p, ] * self.parameters_random[p].pdf_shape[1] + \
+                                   self.parameters_random[p].pdf_shape[0]
+
+            if self.parameters_random[p].pdf_type in ["gamma"]:
+                coords[:, i_p, ] = coords_norm[:, i_p, ] / self.parameters_random[p].pdf_shape[1] + \
+                                   self.parameters_random[p].pdf_shape[2]
+
+        return coords
+
+    def get_normalized_coordinates(self, coords):
+        """
+        Normalize grid from original parameter to normalized space for simulations.
+
+        coords_norm = Grid.get_normalized_coordinates(coords)
+
+        Parameters
+        ----------
+        coords : [N_samples x dim] np.ndarray
+            Denormalized coordinates xi in original parameter space
+
+        Returns
+        -------
+        coords_norm : [N_samples x dim] np.ndarray
+            Normalized coordinates xi
+        """
+        coords_norm = np.zeros(coords.shape)
+
+        for i_p, p in enumerate(self.parameters_random):
+
+            if self.parameters_random[p].pdf_type == "beta":
+                coords_norm[:, i_p] = (coords[:, i_p] - self.parameters_random[p].pdf_limits[0])
+                coords_norm[:, i_p] = coords_norm[:, i_p] / \
+                                      (self.parameters_random[p].pdf_limits[1] -
+                                       self.parameters_random[p].pdf_limits[0]) * \
+                                      2.0 - 1
+
+            if self.parameters_random[p].pdf_type in ["norm", "normal"]:
+                coords_norm[:, i_p] = (coords[:, i_p] - self.parameters_random[p].pdf_shape[0]) / \
+                                      self.parameters_random[p].pdf_shape[1]
+
+            if self.parameters_random[p].pdf_type in ["gamma"]:
+                coords_norm[:, i_p] = (coords[:, i_p] - self.parameters_random[p].pdf_shape[2]) * \
+                                      self.parameters_random[p].pdf_shape[1]
+
+        return coords_norm
+
+    def create_gradient_grid(self, delta=1e-3):
+        """
+        Creates new grid points to determine gradient of model function.
+        Adds or updates self.coords_gradient, self.coords_gradient_norm and self.coords_gradient_id.
+
+        Parameters
+        ----------
+        delta : float, optional, default: 1e-3
+            Shift of grid-points along axes in normalized parameter space
+        """
+        # shift of gradient grid in normalized space
+        delta = delta * np.eye(self.dim)
+
+        # Create or update the gradient grid [n_grid x dim x dim]
+        if self.coords_gradient is not None:
+            n_grid_gradient = self.coords_gradient_norm.shape[0]
+            self.coords_gradient = np.vstack((self.coords_gradient,
+                                              np.zeros((self.n_grid-n_grid_gradient, self.dim, self.dim))))
+            self.coords_gradient_norm = np.vstack((self.coords_gradient_norm,
+                                                   np.zeros((self.n_grid-n_grid_gradient, self.dim, self.dim))))
+        else:
+            n_grid_gradient = 0
+            self.coords_gradient = np.zeros((self.n_grid, self.dim, self.dim))
+            self.coords_gradient_norm = np.zeros((self.n_grid, self.dim, self.dim))
+
+        if n_grid_gradient < self.coords_gradient.shape[0]:
+            # shift the grid
+            for i_dim in range(self.dim):
+                self.coords_gradient_norm[n_grid_gradient:, :, i_dim] = self.coords_norm[n_grid_gradient:, ] - \
+                                                                        delta[i_dim, :]
+
+            # determine coordinates in original parameter space
+            self.coords_gradient[n_grid_gradient:, :, :] = \
+                self.get_denormalized_coordinates(self.coords_gradient_norm[n_grid_gradient:, :, :])
+
+            # total number of grid points
+            self.n_grid_gradient = self.coords_gradient.shape[0]*self.coords_gradient.shape[2]
+
+            # Generate unique IDs of grid points [n_grid]
+            self.coords_gradient_id = copy.deepcopy(self.coords_id)
+
+
+class TensorGrid(Grid):
+    """
+    Generate TensorGrid object instance.
+
+    Parameters
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    options: dict
+        Grid options
+        - parameters["grid_type"] ... list of str [dim]: type of grid ('jacobi', 'hermite', 'cc', 'fejer2')
+        - parameters["n_dim"] ... list of int [dim]: Number of nodes in each dimension
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    knots_dim_list : list of float [dim][n_knots]
+        Knots of polynomials in each dimension
+    weights_dim_list : list of float [dim][n_knots]
+         Weights of polynomials in each dimension
+    weights : ndarray of float [n_grid]
+        Quadrature weights for each grid point
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> pygpc.TensorGrid(parameters_random, options={"grid_type": ["hermite", "jacobi"], "n_dim": [5, 6]})
+
+    Attributes
+    ----------
+    grid_type : [N_vars] list of str
+        Type of quadrature used to construct tensor grid ('jacobi', 'hermite', 'clenshaw_curtis', 'fejer2')
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    options: dict
+        Grid options
+        - parameters["grid_type"] ... list of str [dim]: type of grid ('jacobi', 'hermite', 'cc', 'fejer2')
+        - parameters["n_dim"] ... list of int [dim]: Number of nodes in each dimension
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    knots_dim_list : list of float [dim][n_knots]
+        Knots of polynomials in each dimension
+    weights_dim_list : list of float [dim][n_knots]
+         Weights of polynomials in each dimension
+    weights : ndarray of float [n_grid]
+        Quadrature weights for each grid point
+    """
+
+    def __init__(self, parameters_random, options, coords=None, coords_norm=None,
+                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None,
+                 knots_dim_list=None, weights_dim_list=None, weights=None):
+        """
+        Constructor; Initializes TensorGrid object instance; Generates grid
+        """
+        super(TensorGrid, self).__init__(parameters_random,
+                                         coords=coords,
+                                         coords_norm=coords_norm,
+                                         coords_gradient=coords_gradient,
+                                         coords_gradient_norm=coords_gradient_norm,
+                                         coords_id=coords_id,
+                                         coords_gradient_id=coords_gradient_id)
+        self.options = options
+        self.grid_type = options["grid_type"]
+        self.n_dim = options["n_dim"]
+
+        if coords is not None and coords_norm is not None:
+            grid_present = True
+
+            self.knots_dim_list = knots_dim_list
+            self.weights_dim_list = weights_dim_list
+            self.weights = weights
+
+        else:
+            grid_present = False
+
+        if not grid_present:
+
+            # get knots and weights of polynomials in each dimension
+            self.knots_dim_list = []
+            self.weights_dim_list = []
+
+            for i_p, p in enumerate(self.parameters_random):
+
+                # Jacobi polynomials
+                if self.grid_type[i_p] == 'jacobi':
+                    knots, weights = get_quadrature_jacobi_1d(self.n_dim[i_p],
+                                                              self.parameters_random[p].pdf_shape[0] - 1,
+                                                              self.parameters_random[p].pdf_shape[1] - 1,)
+
+                # Hermite polynomials
+                elif self.grid_type[i_p] == 'hermite':
+                    knots, weights = get_quadrature_hermite_1d(self.n_dim[i_p])
+
+                # Clenshaw Curtis
+                elif self.grid_type[i_p] in ['clenshaw_curtis' or 'cc']:
+                    knots, weights = get_quadrature_clenshaw_curtis_1d(self.n_dim[i_p])
+
+                # Fejer type 2 (Clenshaw Curtis without boundary nodes)
+                elif self.grid_type[i_p] == 'fejer2':
+                    knots, weights = get_quadrature_fejer2_1d(self.n_dim[i_p])
+
+                # Gauss-Patterson (Nested Legendre rule)
+                elif self.grid_type[i_p] == 'patterson':
+                    knots, weights = get_quadrature_patterson_1d(self.n_dim[i_p])
+
+                else:
+                    knots = []
+                    weights = []
+                    AttributeError("Specified grid_type {} not implemented!".format(self.grid_type[i_p]))
+
+                self.knots_dim_list.append(knots)
+                self.weights_dim_list.append(weights)
+
+            # combine coordinates to full tensor grid (all combinations)
+            # self.coords_norm = cartesian(self.knots_dim_list)
+            self.coords_norm = get_cartesian_product(self.knots_dim_list)
+
+            # rescale normalized coordinates in case of normal distributions and "fejer2" or "cc" grids
+            # +- 0.675 * sigma -> 50%
+            # +- 1.645 * sigma -> 90%
+            # +- 1.960 * sigma -> 95%
+            # +- 2.576 * sigma -> 99%
+            # +- 3.000 * sigma -> 99.73%
+            for i_p, p in enumerate(self.parameters_random):
+
+                if self.parameters_random[p].pdf_type in ["norm", "normal"] and (not(self.grid_type[i_p] == "hermite")):
+                    self.coords_norm[:, i_p] = self.coords_norm[:, i_p] * 1.960
+
+            # determine combined weights of Gauss quadrature
+            self.weights = np.prod(get_cartesian_product(self.weights_dim_list), axis=1) / (2.0 ** self.dim)
+
+            # denormalize grid to original parameter space
+            self.coords = self.get_denormalized_coordinates(self.coords_norm)
+
+            # Total number of nodes in grid
+            self.n_grid = self.coords.shape[0]
+
+            # Generate and append unique IDs of grid points
+            self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
+
+
+class SparseGrid(Grid):
+    """
+    SparseGrid object instance.
+
+    Parameters
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    options: dict
+        Grid parameters
+        - grid_type ([N_vars] list of str) ... Type of quadrature rule used to construct sparse grid
+          ('jacobi', 'hermite', 'clenshaw_curtis', 'fejer2', 'patterson')
+        - level ([N_vars] list of int) ... Number of levels in each dimension
+        - level_max (int) ... Global combined level maximum
+        - interaction_order (int) ...Interaction order of parameters and grid, i.e. the grid points are lying
+          between this number of dimensions
+        - order_sequence_type (str) ... Type of order sequence ('lin', 'exp') common: 'exp'
+        - make_grid (boolean, optional, default=True) ... Boolean value to determine if to generate grid
+          during initialization
+        - verbose (bool, optional, default=True) ... Print output messages into stdout
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    level_sequence: list of int
+        Integer sequence of levels
+    order_sequence: list of int
+        Integer sequence of polynomial order of levels
+    weights : ndarray of float [n_grid]
+        Quadrature weights for each grid point
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> grid = pygpc.SparseGrid(parameters_random=parameters_random,
+    >>>                         options={"grid_type": ["jacobi", "jacobi"],
+    >>>                                  "level": [3, 3],
+    >>>                                  "level_max": 3,
+    >>>                                  "interaction_order": 2,
+    >>>                                  "order_sequence_type": "exp"})
+
+    Attributes
+    ----------
+    grid_type: [N_vars] list of str
+        specify type of quadrature used to construct sparse grid ('jacobi', 'hermite', 'cc', 'fejer2')
+    level: [N_vars] list of int
+        number of levels in each dimension
+    level_max: int
+        global combined level maximum
+    level_sequence: list of int
+        list containing the levels
+    interaction_order: int
+        interaction order of parameters and grid, i.e. the grid points are lying between this number of dimensions
+    order_sequence_type: str
+        type of order sequence ('lin', 'exp') common: 'exp'
+    order_sequence: list of int
+        list containing the polynomial order of the levels
+    coords : ndarray of float [n_grid_add x dim]
+            Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    weights : ndarray of float [n_grid]
+            Quadrature weights for each grid point
+    verbose: bool
+        boolean value to determine if to print out the progress into the standard output
+    """
+
+    def __init__(self, parameters_random, options, coords=None, coords_norm=None,
+                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None,
+                 level_sequence=None, order_sequence=None, weights=None):
+        """
+        Constructor; Initializes SparseGrid class; Generates grid
+        """
+
+        super(SparseGrid, self).__init__(parameters_random,
+                                         coords=coords,
+                                         coords_norm=coords_norm,
+                                         coords_gradient=coords_gradient,
+                                         coords_gradient_norm=coords_gradient_norm,
+                                         coords_id=coords_id,
+                                         coords_gradient_id=coords_gradient_id)
+
+        self.grid_type = options["grid_type"]    # Quadrature rule ('jacobi', 'hermite', 'clenshaw_curtis', 'fejer2')
+        self.level = options["level"]            # Number of levels in each dimension [dim x 1]
+        self.level_max = options["level_max"]    # Global combined level maximum
+        self.interaction_order = options["interaction_order"]        # Interaction order of parameters and grid
+        self.order_sequence_type = options["order_sequence_type"]    # Order sequence ('lin', 'exp' (common))
+        self.level_sequence = []  # Integer sequence of levels
+        self.order_sequence = []  # Integer sequence of polynomial order of levels
+
+        # output while grid generation on/off
+        if "verbose" not in options.keys():
+            self.verbose = False
+
+        # Generate grid if not specified
+        if coords is not None and coords_norm is not None:
+            grid_present = True
+
+            self.level_sequence = level_sequence
+            self.order_sequence = order_sequence
+            self.weights = weights
+
+        else:
+            grid_present = False
+
+        # Grid is generated during initialization or coords, coords_norm and weights are added manually
+        if not grid_present:
+            self.calc_multi_indices()
+            self.calc_coords_weights()
+
+            # Determine total number of grid points
+            self.n_grid = self.coords.shape[0]
+
+            # Generate unique IDs of grid points
+            self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
+
+    def calc_multi_indices(self):
+        """
+        Calculate the multi index list needed for the calculation of the SparseGrid.
+        """
+        for i_p, p in enumerate(self.parameters_random):
+
+            if self.grid_type[i_p] == 'fejer2':
+                self.level_sequence.append([element for element in range(1, self.level[i_p] + 1)])
+
+            else:
+                self.level_sequence.append([element for element in range(self.level[i_p] + 1)])
+
+            if self.order_sequence_type == 'exp':         # order = 2**level + 1
+
+                if self.grid_type[i_p] == 'fejer2':       # start with order = 1 @ level = 1
+                    self.order_sequence.append((np.power(2, np.arange(1, self.level[i_p])) - 1).tolist())
+                    self.order_sequence[i_p][0] = 1
+
+                elif self.grid_type[i_p] == 'patterson':  # start with order = 1 @ level = 0 [1,3,7,15,31,...]
+                    self.order_sequence.append((np.power(2, np.arange(0, self.level[i_p])) + 1).tolist())
+
+                else:                                     # start with order = 1 @ level = 0
+                    self.order_sequence.append(
+                        (2 ** np.linspace(0, self.level[i_p], self.level[i_p] + 1) + 1).tolist())
+                    self.order_sequence[i_p][0] = 1
+
+            elif self.order_sequence_type == 'lin':       # order = level
+                if self.grid_type[i_p] == 'fejer2':       # start with level = 1 @ order = 1
+                    self.order_sequence.append(np.linspace(1, self.level[i_p] + 1, self.level[i_p] + 1).tolist())
+
+                elif self.grid_type[i_p] == 'patterson':  # start with order = 1 @ level = 0 [1,3,7,15,31,...]
+                    iprint("Not possible in case of Gauss-Patterson grid.", tab=0, verbose=self.verbose)
+
+                else:                                       # start with
+                    self.order_sequence.append(np.linspace(1, self.level[i_p] + 1, self.level[i_p] + 1).tolist())
+
+    def calc_l_level(self):
+        """
+        Calculate the l-level needed for the Fejer grid type 2.
+
+        l_level = calc_l_level()
+
+        Returns
+        -------
+        l_level: np.ndarray
+            Multi indices filtered by level capacity and interaction order
+        """
+        if "fejer2" in self.grid_type:
+            if self.dim == 1:
+                l_level = np.array([np.linspace(1, self.level_max, self.level_max)]).transpose()
+            else:
+                l_level = get_multi_indices(self.dim, self.level_max - self.dim)
+                l_level = l_level + 1
+        else:
+            if self.dim == 1:
+                l_level = np.array([np.linspace(0, self.level_max, self.level_max + 1)]).transpose()
+            else:
+                l_level = get_multi_indices(order=[self.level_max] * self.dim,
+                                            order_max=self.level_max,
+                                            interaction_order=self.dim,
+                                            order_max_norm=1.,
+                                            interaction_order_current=None)
+
+        # filter out rows exceeding the individual level cap
+        for i_p in range(self.dim):
+            l_level = l_level[l_level[:, i_p] <= self.level[i_p]]
+
+        # Consider interaction order (filter out multi-indices exceeding it)
+        if self.interaction_order < self.dim:
+            if any("fejer2" in s for s in self.grid_type):
+                l_level = l_level[np.sum(l_level > 1, axis=1) <= self.interaction_order, :]
+            else:
+                l_level = l_level[np.sum(l_level > 0, axis=1) <= self.interaction_order, :]
+
+        return l_level
+
+    def calc_grid(self):
+        """
+        Calculate a cubature lookup table for knots and weights.
+
+        dl_k, dl_w = calc_grid()
+
+        Returns
+        -------
+        dl_k: list of list of float
+            Cubature lookup table for knots
+        dl_w: list of list of float
+            Cubature lookup table for weights
+        """
+        # make cubature lookup table for knots (dl_k) and weights (dl_w) [max(l) x dim]
+        iprint("Generating difference grids...", tab=0, verbose=self.verbose)
+        dl_k = [[0 for _ in range(self.dim)] for _ in range(int(np.amax(self.level) + 1))]
+        dl_w = [[0 for _ in range(self.dim)] for _ in range(int(np.amax(self.level) + 1))]
+        knots_l, weights_l, knots_l_1, weights_l_1 = 0, 0, 0, 0
+
+        for i_p, p in enumerate(self.parameters_random):
+
+            for i_level in self.level_sequence[i_p]:
+
+                # Jacobi polynomials
+                if self.grid_type[i_p] == 'jacobi':
+                    knots_l, weights_l = get_quadrature_jacobi_1d(self.order_sequence[i_p][i_level],
+                                                                  self.parameters_random[p].pdf_shape[0] - 1,
+                                                                  self.parameters_random[p].pdf_shape[1] - 1)
+                    knots_l_1, weights_l_1 = get_quadrature_jacobi_1d(self.order_sequence[i_p][i_level - 1],
+                                                                      self.parameters_random[p].pdf_shape[0] - 1,
+                                                                      self.parameters_random[p].pdf_shape[1] - 1)
+
+                # Hermite polynomials
+                if self.grid_type[i_p] == 'hermite':
+                    knots_l, weights_l = get_quadrature_hermite_1d(
+                        self.order_sequence[i_p][i_level])
+                    knots_l_1, weights_l_1 = get_quadrature_hermite_1d(
+                        self.order_sequence[i_p][i_level - 1])
+
+                # Gauss-Patterson
+                if self.grid_type[i_p] == 'patterson':
+                    knots_l, weights_l = get_quadrature_patterson_1d(
+                        self.order_sequence[i_p][i_level])
+                    knots_l_1, weights_l_1 = get_quadrature_patterson_1d(
+                        self.order_sequence[i_p][i_level - 1])
+
+                # Clenshaw Curtis
+                if self.grid_type[i_p] == 'clenshaw_curtis':
+                    knots_l, weights_l = get_quadrature_clenshaw_curtis_1d(
+                        self.order_sequence[i_p][i_level])
+                    knots_l_1, weights_l_1 = get_quadrature_clenshaw_curtis_1d(
+                        self.order_sequence[i_p][i_level - 1])
+
+                # Fejer type 2
+                if self.grid_type[i_p] == 'fejer2':
+                    knots_l, weights_l = get_quadrature_fejer2_1d(
+                        self.order_sequence[i_p][i_level - 1])
+                    knots_l_1, weights_l_1 = get_quadrature_fejer2_1d(
+                        self.order_sequence[i_p][i_level - 2])
+
+                if (i_level == 0 and not self.grid_type[i_p] == 'fejer2') or \
+                        (i_level == 1 and (self.grid_type[i_p] == 'fejer2')):
+                    dl_k[i_level][i_p] = knots_l
+                    dl_w[i_level][i_p] = weights_l
+                else:
+                    # noinspection PyTypeChecker
+                    dl_k[i_level][i_p] = np.hstack((knots_l, knots_l_1))
+                    # noinspection PyTypeChecker
+                    dl_w[i_level][i_p] = np.hstack((weights_l, -weights_l_1))
+
+        return dl_k, dl_w
+
+    def calc_tensor_products(self):
+        """
+        Calculate the tensor products of the knots and the weights.
+
+        dll_k, dll_w = calc_tensor_products()
+
+        Returns
+        -------
+        dll_k: np.ndarray
+            Tensor product of knots
+        dll_w: np.ndarray
+            Tensor product of weights
+        """
+        # make list of all tensor products according to multi-index list "l"
+        iprint("Generating sub-grids...", tab=0, verbose=self.verbose)
+        dl_k, dl_w = self.calc_grid()
+        l_level = self.calc_l_level()
+        dll_k = []
+        dll_w = []
+
+        for i_l_level in range(l_level.shape[0]):
+
+            knots = []
+            weights = []
+
+            for i_p in range(self.dim):
+                knots.append(np.asarray(dl_k[int(l_level[i_l_level, i_p])][i_p], dtype=float))
+                weights.append(np.asarray(dl_w[int(l_level[i_l_level, i_p])][i_p], dtype=float))
+
+            # tensor product of knots
+            dll_k.append(get_cartesian_product(knots))
+
+            # tensor product of weights
+            dll_w.append(np.prod(get_cartesian_product(weights), axis=1))
+
+        dll_w = np.hstack(dll_w)
+        dll_k = np.vstack(dll_k)
+
+        return dll_k, dll_w
+
+    def calc_coords_weights(self):
+        """
+        Determine coords and weights of sparse grid by generating, merging and subtracting sub-grids.
+        """
+        # find similar points in grid and formulate Point list
+        dll_k, dll_w = self.calc_tensor_products()
+        point_number_list = np.zeros(dll_w.shape[0]) - 1
+        point_no = 0
+        epsilon_k = 1E-6
+        coords_norm = []
+
+        iprint("Merging sub-grids...", tab=0, verbose=self.verbose)
+
+        while any(point_number_list < 0):
+            not_found = point_number_list < 0
+            dll_k_nf = dll_k[not_found]
+            point_temp = np.zeros(dll_k_nf.shape[0]) - 1
+            point_temp[np.sum(np.abs(dll_k_nf - dll_k_nf[0]), axis=1) < epsilon_k] = point_no
+            point_number_list[not_found] = point_temp
+            point_no = point_no + 1
+            coords_norm.append(dll_k_nf[0, :])
+
+        coords_norm = np.array(coords_norm)
+        point_number_list = np.asarray(point_number_list, dtype=int)
+
+        weights = np.zeros(np.amax(point_number_list) + 1) - 999
+
+        for i_point in range(np.amax(point_number_list) + 1):
+            weights[i_point] = np.sum(dll_w[point_number_list == i_point])
+
+        # filter for very small weights
+        iprint("Filter grid for very small weights...", tab=0, verbose=self.verbose)
+        epsilon_w = 1E-8 / self.dim
+        keep_point = np.abs(weights) > epsilon_w
+        self.weights = weights[keep_point] / 2 ** self.dim
+        coords_norm = coords_norm[keep_point]
+
+        # rescale normalized coordinates in case of normal distributions and "fejer2" or "clenshaw_curtis" grids
+        # +- 0.675 * sigma -> 50%
+        # +- 1.645 * sigma -> 90%
+        # +- 1.960 * sigma -> 95%
+        # +- 2.576 * sigma -> 99%
+        # +- 3.000 * sigma -> 99.73%
+        for i_p, p in enumerate(self.parameters_random):
+            if self.parameters_random[p].pdf_type in ["norm", "normal"] and (not(self.grid_type[i_p] == "hermite")):
+                coords_norm[:, i_p] = coords_norm[:, i_p] * 1.960
+
+        # denormalize grid to original parameter space
+        iprint("Denormalizing grid for computations...", tab=0, verbose=self.verbose)
+        self.coords_norm = coords_norm
+        self.coords = self.get_denormalized_coordinates(coords_norm)
+
+
+class RandomGrid(Grid):
+    """
+    RandomGrid object
+
+    Parameters
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    n_grid: int
+        Number of random samples in grid
+    seed : float, optional, default=None
+        Seeding point to replicate random grid
+    options : dict, optional, default=None
+        RandomGrid options depending on the grid type
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> grid = pygpc.RandomGrid(parameters_random=parameters_random, n_grid=100, options=None)
+
+    Attributes
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    n_grid: int
+        Number of random samples in grid
+    seed : float, optional, default=None
+        Seeding point to replicate random grid
+    options : dict, optional, default=None
+        RandomGrid options depending on the grid type
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    """
+
+    def __init__(self, parameters_random, n_grid=None, options=None, coords=None, coords_norm=None,
+                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None,
+                 grid_pre=None):
+        """
+        Constructor; Initializes RandomGrid instance; Generates grid
+        """
+        super(RandomGrid, self).__init__(parameters_random,
+                                         coords=coords,
+                                         coords_norm=coords_norm,
+                                         coords_gradient=coords_gradient,
+                                         coords_gradient_norm=coords_gradient_norm,
+                                         coords_id=coords_id,
+                                         coords_gradient_id=coords_gradient_id,
+                                         grid_pre=grid_pre)
+
+        if n_grid is not None:
+            self.n_grid = int(n_grid)
+
+        self.options = options
+        self.seed = None
+
+        if self.options is None:
+            self.options = dict()
+
+        if "seed" in self.options.keys():
+            self.seed = self.options["seed"]
+
+            # Seed of random grid (if necessary to reproduce random grid)
+            np.random.seed(self.seed)
+
+    def resample(self, idx, classifier=None, domain=None, gradient=False, results=None, type=None):
+        """
+        Replace grid points specified by index. Modifies grid object in place.
+
+        Parameters
+        ----------
+        idx : np.ndarray of int [n_grid_points_replace]
+            Indices of grid points to replace by resampling.
+        classifier : Classifier object, optional, default: None
+            Classifier
+        domain : int, optional, default: None
+            Adds grid points only in specified domain (needs Classifier object including a predict() method)
+        gradient : bool, optional, default: False
+            Add corresponding gradient grid points
+        results : np.ndarray of float [n_grid x n_qoi]
+            Results computed so far before adding additional grid points
+        type : str, optional, default: None
+            Type of adding new grid points
+            - "GP": Gaussian process regression (points are added where the uncertainty of sampling is very high).
+            Does only work for Random, LHS, and GP grids.
+            - None: grid points are added according to the grid type.
+        """
+        # create temporary grid
+        grid_tmp = copy.deepcopy(self)
+        n_grid = self.n_grid
+
+        # extend grid by number of grid points to resample
+        grid_tmp.extend_random_grid(n_grid_new=self.n_grid + len(idx),
+                                    classifier=classifier,
+                                    domain=domain,
+                                    gradient=gradient,
+                                    results=results,
+                                    type=type)
+
+        # copy options (seed increment)
+        self.options = copy.deepcopy(grid_tmp.options)
+
+        # overwrite grid points to resample in original grid with new grid points from temporary grid
+        self.coords[idx, ] = grid_tmp.coords[n_grid:, ]
+        self.coords_norm[idx, ] = grid_tmp.coords_norm[n_grid:, ]
+
+        # generate and replace unique IDs of new grid points
+        for _idx in idx:
+            self.coords_id[_idx] = uuid.uuid4()
+
+        # create new gradient grid points if required
+        if self.coords_gradient is not None:
+            self._coords_gradient = None
+            self._coords_gradient_norm = None
+            self.n_grid_gradient = None
+            self.create_gradient_grid()
+
+    def delete(self, idx):
+        """
+        Delete grid points by index. Modifies grid object in place.
+
+        Parameters
+        ----------
+        idx : int or np.ndarray of int
+            Indices of grid points to delete.
+        """
+
+        if type(idx) in [int, float, np.ndarray, list]:
+            idx = np.array(idx)
+
+        # delete grid points
+        self.coords = np.delete(self.coords, idx, axis=0)
+        self.coords_norm = np.delete(self.coords_norm, idx, axis=0)
+
+        # remove unique IDs of grid points
+        self.coords_id = [self.coords_id[i] for i in range(self.n_grid) if i not in idx]
+
+        # delete gradient grid points
+        if self.coords_gradient is not None:
+            self.coords_gradient = np.delete(self.coords_gradient, idx, axis=0)
+            self.coords_gradient_norm = np.delete(self.coords_gradient_norm, idx, axis=0)
+
+    def extend_random_grid(self, n_grid_new=None, coords=None, coords_norm=None, classifier=None, domain=None,
+                           gradient=False, results=None, type=None):
+        """
+        Add sample points according to input pdfs to grid (old points are kept). Define either the new total number of
+        grid points with "n_grid_new" or add grid-points manually by providing "coords" and "coords_norm".
+
+        extend_random_grid(n_grid_new, coords=None, coords_norm=None, seed=None, classifier=None, domain=None):
+
+        Parameters
+        ----------
+        n_grid_new : float
+            Total number of grid points in extended random grid (old points are kept)
+            (n_grid_add = n_grid_new - n_grid_old)
+        coords : ndarray of float [n_grid_add x dim]
+            Grid points to add (model space)
+        coords_norm : ndarray of float [n_grid_add x dim]
+            Grid points to add (normalized space)
+        classifier : Classifier object, optional, default: None
+            Classifier
+        domain : int, optional, default: None
+            Adds grid points only in specified domain (needs Classifier object including a predict() method)
+        gradient : bool, optional, default: False
+            Add corresponding gradient grid points
+        results : np.ndarray of float [n_grid x n_qoi]
+            Results computed so far before adding additional grid points
+        type : str, optional, default: None
+            Type of adding new grid points
+            - "GP": Gaussian process regression (points are added where the uncertainty of sampling is very high).
+            Does only work for Random, LHS, and GP grids.
+            - None: grid points are added according to the grid type.
+        """
+
+        # increase seed if needed to avoid creation of same grid points
+        if "seed" in self.options.keys() and self.options["seed"] is not None:
+            self.options["seed"] += 1
+            self.seed = self.options["seed"]
+
+        if isinstance(self, GP):
+            type = "GP"
+
+        if n_grid_new is not None:
+            # Number of new grid points
+            n_grid_add = int(n_grid_new - self.n_grid)
+
+            if n_grid_add > 0:
+                # Generate new grid points
+                if classifier is None:
+                    if isinstance(self, Random) or isinstance(self, GP):
+                        if type is None:
+                            new_grid = Random(parameters_random=self.parameters_random,
+                                              n_grid=n_grid_add,
+                                              options=self.options)
+
+                            # append points to existing grid
+                            self.coords = np.vstack([self.coords, new_grid.coords])
+                            self.coords_norm = np.vstack([self.coords_norm, new_grid.coords_norm])
+
+                        elif type == "GP":
+                            if "n_pool" not in list(self.options.keys()):
+                                self.options["n_pool"] = 1000
+
+                            # If results are given, determine optimal hyperparameters for Gaussian Process Regression
+                            if results is not None:
+                                self.options["lengthscale"], self.options["variance"] = \
+                                    get_parameters_gaussian_process(Xtrain=self.coords_norm,
+                                                                    ytrain=results[:, 0])
+
+                            if (self.n_grid + 1) == n_grid_new:
+                                tqdm.write(f"Adding GP grid point #{self.n_grid + 1}")
+                            else:
+                                tqdm.write(f"Adding GP grid points #{self.n_grid + 1} ... #{n_grid_new}")
+
+                            for _ in tqdm(range(n_grid_add)):
+                                # Determine new grid points where uncertainty of output is highest
+                                new_grid = self.get_coords_gaussian_process(n_grid_add=1,
+                                                                            lengthscale=self.options["lengthscale"],
+                                                                            variance=self.options["variance"],
+                                                                            n_pool=self.options["n_pool"])
+
+                                # append points to existing grid
+                                self.coords = np.vstack([self.coords, new_grid.coords])
+                                self.coords_norm = np.vstack([self.coords_norm, new_grid.coords_norm])
+                            tqdm._instances.clear()
+
+                    elif isinstance(self, LHS):
+                        grid_pre = copy.deepcopy(self)
+
+                        if type is None:
+                            new_grid = LHS(parameters_random=self.parameters_random,
+                                           n_grid=n_grid_add,
+                                           grid_pre=grid_pre,
+                                           options=self.options)
+
+                            # append points to existing grid
+                            self.coords = np.vstack([self.coords, new_grid.coords])
+                            self.coords_norm = np.vstack([self.coords_norm, new_grid.coords_norm])
+
+                        elif type == "GP":
+                            if "n_pool" not in list(self.options.keys()):
+                                self.options["n_pool"] = 1000
+
+                            # If results are given, determine optimal hyperparameters for Gaussian Process Regression
+                            if results is not None:
+                                self.options["lengthscale"], self.options["variance"] = \
+                                    get_parameters_gaussian_process(Xtrain=self.coords_norm,
+                                                                    ytrain=results[:, 0])
+
+                            if (self.n_grid + 1) == n_grid_new:
+                                tqdm.write(f"Adding GP grid point #{self.n_grid + 1}")
+                            else:
+                                tqdm.write(f"Adding GP grid points #{self.n_grid + 1} ... #{n_grid_new}")
+
+                            for _ in tqdm(range(n_grid_add)):
+                                # Determine new grid points where uncertainty of output is highest
+                                new_grid = self.get_coords_gaussian_process(n_grid_add=1,
+                                                                            lengthscale=self.options["lengthscale"],
+                                                                            variance=self.options["variance"],
+                                                                            n_pool=self.options["n_pool"])
+
+                                # append points to existing grid
+                                self.coords = np.vstack([self.coords, new_grid.coords])
+                                self.coords_norm = np.vstack([self.coords_norm, new_grid.coords_norm])
+                            tqdm._instances.clear()
+
+                    elif isinstance(self, L1) or isinstance(self, L1_LHS) or isinstance(self, LHS_L1) \
+                            or isinstance(self, CO) or isinstance(self, FIM):
+                        grid_pre = copy.deepcopy(self)
+                        new_grid = self.__class__(parameters_random=self.parameters_random,
+                                                  n_grid=n_grid_new,
+                                                  grid_pre=grid_pre,
+                                                  gpc=self.gpc,
+                                                  options=self.options)
+
+                        self.coords = new_grid.coords
+                        self.coords_norm = new_grid.coords_norm
+
+                else:
+                    coords = np.zeros((n_grid_add, len(self.parameters_random)))
+                    coords_norm = np.zeros((n_grid_add, len(self.parameters_random)))
+
+                    # add grid points one by one because we are looking for samples in the right domain
+                    for i in range(n_grid_add):
+                        resample = True
+                        while resample:
+                            if isinstance(self, Random):
+                                new_grid = Random(parameters_random=self.parameters_random,
+                                                  n_grid=1,
+                                                  options=self.options)
+
+                                # test if grid point lies in right domain
+                                if classifier.predict(new_grid.coords_norm)[0] == domain:
+                                    coords[i, :] = new_grid.coords
+                                    coords_norm[i, :] = new_grid.coords_norm
+                                    resample = False
+
+                            elif isinstance(self, LHS):
+                                # check if gridpoint exceeds sampling reservoir
+                                # if self.n_grid > max(10000, self.n_grid_lhs * 10)
+                                # coords.np.append(pygpc.LSH( seed=seed+1))
+                                coords_norm_test = self.lhs_extend(self.coords_norm_reservoir, 1)
+                                # test if next grid point lies in right domain
+                                if classifier.predict(coords_norm_test[len(coords_norm_test) - 1]) == domain:
+                                    self.coords_norm_reservoir = coords_norm_test
+                                    coords[i, :] = self.coords_reservoir[self.n_grid]
+                                    coords_norm[i, :] = self.coords_norm_reservoir[self.n_grid]
+                                    self.n_grid += 1
+                                    resample = False
+
+                    # append points to existing grid
+                    self.coords = np.vstack([self.coords, coords])
+                    self.coords_norm = np.vstack([self.coords_norm, coords_norm])
+
+        elif coords is not None or coords_norm is not None:
+            # append points to existing grid
+            if coords_norm is None and coords is not None:
+                coords_norm = self.get_normalized_coordinates(coords=coords)
+            if coords is None and coords_norm is not None:
+                coords = self.get_denormalized_coordinates(coords_norm=coords_norm)
+
+            # Number of new grid points
+            n_grid_add = coords.shape[0]
+
+            # check if specified points are lying in right domain
+            if classifier is not None:
+                if not (classifier.predict(coords_norm) == domain).all():
+                    raise AssertionError("Specified coordinates are not lying in right domain!")
+
+            self.coords = np.vstack([self.coords, coords])
+            self.coords_norm = np.vstack([self.coords_norm, coords_norm])
+
+        else:
+            raise ValueError("Specify either n_grid_new or coords or coords_norm")
+
+        # Generate and append unique IDs of new grid points
+        self.coords_id = self.coords_id + [uuid.uuid4() for _ in range(n_grid_add)]
+
+        self.n_grid = self.coords.shape[0]
+
+        if gradient:
+            self.create_gradient_grid()
+
+    def lhs_extend(self, array, n_extend):
+        """
+        Add sample points to already existing LHS samples
+
+        Parameters
+        ----------
+        array: ndarray of float [m x n]
+            Existing LHS samples with m samples points per n dimensions
+        n_extend: int
+            Number of new rows of samples needed
+
+        Returns
+        -------
+        coords_norm : ndarray of float [m + n_extend x n]
+            Existing LHS samples with added new samples
+        """
+
+        dim = np.shape(array)[1]
+        n_old = np.shape(array)[0]
+        n_new = n_old + n_extend
+        i = 1
+        n_new_loop = n_new
+        np.random.seed(seed=self.seed)
+
+        while i > 0:
+            a_new = np.zeros([n_new_loop, dim]) - 1
+            u = np.random.rand(n_new_loop, dim)
+
+            for d in range(dim):
+                k = 0
+                for j in range(n_new_loop - 1):
+                    if not (float(j / n_new_loop) < float(np.sort(array[:, d])[min(j, len(array) - 1)]) < float((j + 1) / n_new_loop)) \
+                            and (float((j + 1) / n_new_loop) <= float(np.sort(array[:, d])[min((j + 2), len(array) - 1)])):
+
+                        k = k + 1
+                        if k is np.shape(a_new)[0] + 1:
+                            k = 1
+                        a_new[k - 1, d] = float((j + u[j, d]) / n_new_loop)
+
+            a_new = a_new[(a_new != -1).all(axis=1), :]
+
+            if n_extend > np.min((a_new.shape[0], n_new)):
+                i = 1
+                n_new_loop = n_new_loop * 2
+
+            else:
+                i = 0
+                for d in range(dim):
+                    np.random.shuffle(a_new[:, d])
+
+                a_extend = a_new[np.random.choice(a_new.shape[0], size=n_extend, replace=False), :]
+
+        coords_ = np.insert(array, n_old, a_extend, axis=0)
+
+        return coords_
+
+    def get_coords_gaussian_process(self, n_grid_add, lengthscale=0.2, variance=1., n_pool=10000):
+        """
+        Determine coordinates at highest variance determined by Gaussian Process Regression
+
+        Parameters
+        ----------
+        n_grid_add : int
+            Number of grid points to add
+        lengthscale : float, optional, default: 1.
+            Lengthscale parameter
+        variance : float, optional, default: 1.
+            Output variance
+        n_pool : int, optional, default: None
+            Poolsize of random sampling points the best are selected from.
+
+        Returns
+        -------
+        grid_new : RandomGrid object
+            RandomGrid object which contains the new grid points in grid_new.coords and grid_new.coords_norm
+        """
+
+        n_test = np.max((n_pool, 2 * self.n_grid))
+
+        # create test grid
+        grid_test = Random(parameters_random=self.parameters_random, n_grid=n_test, options={"seed": self.seed})
+
+        # kernels
+        K = squared_exponential_kernel(x=self.coords_norm, y=self.coords_norm,
+                                       lengthscale=lengthscale, variance=variance)  # n_train x n_train
+        Ks = squared_exponential_kernel(x=self.coords_norm, y=grid_test.coords_norm,
+                                        lengthscale=lengthscale, variance=variance)  # n_train x n_test
+        Kss = squared_exponential_kernel(x=grid_test.coords_norm, y=grid_test.coords_norm,
+                                         lengthscale=lengthscale, variance=variance)  # n_test x n_test
+
+        try:
+            # cholesky decomposition
+            L = np.linalg.cholesky(K)
+
+            # compute v
+            v = np.linalg.solve(L, Ks)
+
+        except np.linalg.LinAlgError:
+            print(
+                "Warning: Cholesky decomposition of K* matrix did not converge ... using Moore-Penrose pseudo inverse.")
+            v = np.linalg.pinv(K) @ Ks
+
+        # alpha
+        # alpha = np.linalg.solve(L.T, np.linalg.solve(L, results))
+
+        # compute the mean function
+        # mu = Ks.T @ alpha
+
+        # compute the covariance
+        covariance = Kss - (v.T @ v)
+
+        # we get the standard deviation from the covariance matrix
+        std = np.sqrt(np.diag(covariance))
+
+        if np.isnan(std).all():
+            print("Warning: GP failed, adding random grid points instead.")
+
+            # take random samples if GP failed
+            coords = grid_test.coords[:n_grid_add, :]
+            coords_norm = grid_test.coords_norm[:n_grid_add, :]
+        else:
+            # weight std with joint probability
+            joint_pdf = np.ones(n_pool)
+            for i_p, p in enumerate(self.parameters_random):
+                _, tmp = self.parameters_random[p].pdf_norm(x=grid_test.coords_norm[:, i_p])
+                joint_pdf *= tmp
+            std_weighted = std * joint_pdf
+
+            idx_sorted = np.flip(np.argsort(std_weighted))
+            idx_sorted = idx_sorted[~np.isnan(std_weighted[idx_sorted])]
+
+            coords = grid_test.coords[idx_sorted[:n_grid_add], :]
+            coords_norm = grid_test.coords_norm[idx_sorted[:n_grid_add], :]
+
+        grid_new = Random(coords=coords, coords_norm=coords_norm, parameters_random=self.parameters_random)
+
+        return grid_new
+
+
+class Random(RandomGrid):
+    """
+    Random grid object
+
+    Parameters
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    n_grid : int or float
+        Number of random samples in grid
+    seed : float, optional, default=None
+        Seeding point to replicate random grid
+    options : dict, optional, default=None
+        RandomGrid options depending on the grid type
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> grid = pygpc.Random(parameters_random=parameters_random, n_grid=100)
+
+    Attributes
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    n_grid : int or float
+        Number of random samples in grid
+    seed : float, optional, default=None
+        Seeding point to replicate random grid
+    options : dict, optional, default=None
+        RandomGrid options depending on the grid type
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    """
+
+    def __init__(self, parameters_random, n_grid=None, options=None, coords=None, coords_norm=None,
+                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None,
+                 grid_pre=None):
+        """
+        Constructor; Initializes RandomGrid instance; Generates grid or copies provided content
+        """
+        if n_grid is not None:
+            n_grid = int(n_grid)
+
+        super(Random, self).__init__(parameters_random,
+                                     n_grid=n_grid,
+                                     options=options,
+                                     coords=coords,
+                                     coords_norm=coords_norm,
+                                     coords_gradient=coords_gradient,
+                                     coords_gradient_norm=coords_gradient_norm,
+                                     coords_id=coords_id,
+                                     coords_gradient_id=coords_gradient_id,
+                                     grid_pre=grid_pre)
+
+        if coords is not None or coords_norm is not None:
+            grid_present = True
+        else:
+            grid_present = False
+
+        if not grid_present:
+
+            # Generate random samples for each random input variable [n_grid x dim]
+            self.coords_norm = np.zeros([self.n_grid, self.dim])
+
+            if self.grid_pre is not None:
+                self.coords_norm[:self.grid_pre.n_grid, :] = self.grid_pre.coords_norm
+                n_grid_add = n_grid - self.grid_pre.n_grid
+                n_grid_start = self.grid_pre.n_grid
+            else:
+                n_grid_add = n_grid
+                n_grid_start = 0
+
+            # in case of seeding, the random grid is constructed element wise (same grid-points when n_grid differs)
+            if self.seed:
+                for i_grid in range(n_grid_start, n_grid):
+                    for i_p, p in enumerate(self.parameters_random):
+
+                        if self.parameters_random[p].pdf_type == "beta":
+                            self.coords_norm[i_grid, i_p] = np.random.beta(self.parameters_random[p].pdf_shape[0],
+                                                                           self.parameters_random[p].pdf_shape[1],
+                                                                           1) * 2.0 - 1
+
+                        if self.parameters_random[p].pdf_type in ["norm", "normal"]:
+
+                            resample = True
+
+                            while resample:
+                                self.coords_norm[i_grid, i_p] = np.random.normal(loc=0,
+                                                                                 scale=1,
+                                                                                 size=1)
+                                resample = self.coords_norm[i_grid, i_p] < self.parameters_random[p].x_perc_norm[0] or \
+                                           self.coords_norm[i_grid, i_p] > self.parameters_random[p].x_perc_norm[1]
+
+                        if self.parameters_random[p].pdf_type in ["gamma"]:
+
+                            resample = True
+
+                            while resample:
+                                self.coords_norm[i_grid, i_p] = np.random.gamma(
+                                    shape=self.parameters_random[p].pdf_shape[0],
+                                    scale=1.0,
+                                    size=1)
+                                resample = self.coords_norm[i_grid, i_p] > self.parameters_random[p].x_perc_norm
+
+            else:
+                for i_p, p in enumerate(self.parameters_random):
+
+                    if self.parameters_random[p].pdf_type == "beta":
+                        self.coords_norm[n_grid_start:, i_p] = (np.random.beta(self.parameters_random[p].pdf_shape[0],
+                                                                               self.parameters_random[p].pdf_shape[1],
+                                                                               [n_grid_add, 1]) * 2.0 - 1)[:, 0]
+
+                    if self.parameters_random[p].pdf_type in ["norm", "normal"]:
+                        resample = True
+                        if self.grid_pre is not None:
+                            outlier_mask = np.hstack((np.zeros(self.grid_pre.n_grid, dtype=bool),
+                                                     np.ones(n_grid_add, dtype=bool)))
+                        else:
+                            outlier_mask = np.ones(self.n_grid, dtype=bool)
+
+                        while resample:
+                            self.coords_norm[outlier_mask, i_p] = (np.random.normal(loc=0,
+                                                                                    scale=1,
+                                                                                    size=[np.sum(outlier_mask), 1]))[:, 0]
+
+                            outlier_mask = np.logical_or(
+                                self.coords_norm[:, i_p] < self.parameters_random[p].x_perc_norm[0],
+                                self.coords_norm[:, i_p] > self.parameters_random[p].x_perc_norm[1])
+
+                            resample = outlier_mask.any()
+
+                    if self.parameters_random[p].pdf_type in ["gamma"]:
+                        resample = True
+                        outlier_mask = np.ones(self.n_grid, dtype=bool)
+                        j = 0
+                        while resample:
+                            # print("Iteration: {}".format(j + 1))
+                            self.coords_norm[outlier_mask, i_p] = (np.random.gamma(
+                                shape=self.parameters_random[p].pdf_shape[0],
+                                scale=1.0,
+                                size=[np.sum(outlier_mask), 1]))[:, 0]
+
+                            outlier_mask = np.array(self.coords_norm[:, i_p] > self.parameters_random[p].x_perc_norm)
+
+                            resample = outlier_mask.any()
+
+                            j += 1
+
+            # Denormalize grid to original parameter space
+            self.coords = self.get_denormalized_coordinates(self.coords_norm)
+
+            # Generate unique IDs of grid points
+            self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
+
+        else:
+            # self.coords = coords
+            # self.coords_norm = coords_norm
+            #
+            # self.coords_gradient = coords_gradient
+            # self.coords_gradient_norm = coords_gradient_norm
+            #
+            # self.coords_id = coords_id
+            # self.coords_gradient_id = coords_gradient_id
+
+            if self.coords is None:
+                # Denormalize grid to original parameter space
+                self.coords = self.get_denormalized_coordinates(self.coords_norm)
+
+            if self.coords_norm is None:
+                # Normalize grid to original parameter space
+                self.coords = self.get_normalized_coordinates(self.coords)
+
+            if self.coords_gradient is None and self.coords_gradient_norm is not None:
+                # Denormalize grid to original parameter space
+                self.coords_gradient = self.get_denormalized_coordinates(self.coords_gradient_norm)
+
+            if self.coords_gradient_norm is None and self.coords_gradient is not None:
+                # Normalize grid to original parameter space
+                self.coords_gradient_norm = self.get_normalized_coordinates(self.coords_gradient)
+
+
+class GP(RandomGrid):
+    """
+    Gaussian Process grid object
+
+    Parameters
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    n_grid : int or float
+        Number of random samples in grid
+    seed : float, optional, default=None
+        Seeding point to replicate random grid
+    options : dict, optional, default=None
+        RandomGrid options depending on the grid type
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> grid = pygpc.GP(parameters_random=parameters_random, n_grid=100)
+
+    Attributes
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    n_grid : int or float
+        Number of random samples in grid
+    seed : float, optional, default=None
+        Seeding point to replicate random grid
+    options : dict, optional, default=None
+        RandomGrid options depending on the grid type
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    """
+
+    def __init__(self, parameters_random, n_grid=None, options=None, coords=None, coords_norm=None,
+                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None,
+                 grid_pre=None):
+        """
+        Constructor; Initializes RandomGrid instance; Generates grid or copies provided content
+        """
+        if n_grid is not None:
+            n_grid = int(n_grid)
+
+        super(GP, self).__init__(parameters_random,
+                                 n_grid=n_grid,
+                                 options=options,
+                                 coords=coords,
+                                 coords_norm=coords_norm,
+                                 coords_gradient=coords_gradient,
+                                 coords_gradient_norm=coords_gradient_norm,
+                                 coords_id=coords_id,
+                                 coords_gradient_id=coords_gradient_id,
+                                 grid_pre=grid_pre)
+
+        if coords is not None or coords_norm is not None:
+            grid_present = True
+        else:
+            grid_present = False
+
+        if self.options is None:
+            self.options["variance"] = 1.
+            self.options["lengthscale"] = 0.2
+            self.options["n_pool"] = 10000
+
+        if "variance" not in self.options.keys():
+            self.options["variance"] = 1.
+
+        if "lengthscale" not in self.options.keys():
+            self.options["lengthscale"] = 0.2
+
+        if "n_pool" not in self.options.keys():
+            self.options["n_pool"] = 10000
+
+        if not grid_present:
+            if self.grid_pre is not None:
+                self.coords_norm = self.grid_pre.coords_norm
+                n_grid_start = self.grid_pre.n_grid
+            else:
+                self.coords_norm = np.zeros((1, self.dim))
+                self.coords = self.get_denormalized_coordinates(self.coords_norm)
+                n_grid_start = 1
+
+            self.extend_random_grid(n_grid_new=n_grid, coords_norm=self.coords_norm, coords=self.coords, type="GP")
+
+            # Denormalize grid to original parameter space
+            self.coords = self.get_denormalized_coordinates(self.coords_norm)
+
+            # Generate unique IDs of grid points
+            self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
+
+        else:
+            if self.coords is None:
+                # Denormalize grid to original parameter space
+                self.coords = self.get_denormalized_coordinates(self.coords_norm)
+
+            if self.coords_norm is None:
+                # Normalize grid to original parameter space
+                self.coords = self.get_normalized_coordinates(self.coords)
+
+            if self.coords_gradient is None and self.coords_gradient_norm is not None:
+                # Denormalize grid to original parameter space
+                self.coords_gradient = self.get_denormalized_coordinates(self.coords_gradient_norm)
+
+            if self.coords_gradient_norm is None and self.coords_gradient is not None:
+                # Normalize grid to original parameter space
+                self.coords_gradient_norm = self.get_normalized_coordinates(self.coords_gradient)
+
+
+class LHS(RandomGrid):
+    """
+    LHS grid object
+
+    Parameters
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    n_grid: int
+        Number of random samples to generate
+    options: dict, optional, default=None
+        Grid options:
+        - criterion :
+            - 'corr'            : optimizes design points in their spearman correlation coefficients
+            - 'maximin' or 'm'  : optimizes design points in their maximum minimal distance using the Phi-P criterion
+            - 'ese'             : uses an enhanced evolutionary algorithm to optimize the Phi-P criterion
+        - seed : Seeding point to replicate random grids
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> grid = pygpc.LHS(parameters_random=parameters_random, n_grid=100, options={"seed": None, "criterion": "ese"})
+
+    Attributes
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    n_grid : int or float
+        Number of random samples in grid
+    seed : float, optional, default=None
+        Seeding point to replicate random grid
+    options : dict, optional, default=None
+        - 'corr'            : optimizes design points in their spearman correlation coefficients
+        - 'maximin' or 'm'  : optimizes design points in their maximum minimal distance using the Phi-P criterion
+        - 'ese'             : uses an enhanced evolutionary algorithm to optimize the Phi-P criterion
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    """
+
+    def __init__(self, parameters_random, n_grid=None, options=None, coords=None, coords_norm=None,
+                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None,
+                 grid_pre=None):
+        """
+        Constructor; Initializes RandomGrid instance; Generates grid or copies provided content
+        """
+
+        self.coords_norm_lhs = None
+        self.perc_mask = None
+        self.coords_reservoir = None
+        self.coords_norm_reservoir = None
+        self.grid_pre = grid_pre
+        self.options = options
+        self.criterion = None
+        self.method = None
+        self.coords_norm_reservoir_perced = None
+
+        if type(self.options) is dict:
+            if "criterion" in self.options.keys():
+                self.criterion = options["criterion"]
+            else:
+                self.criterion = ["ese"]
+            if "method" in self.options.keys():
+                self.method = options["method"]
+            else:
+                self.criterion = ["standard"]
+
+        if type(self.criterion) is not list:
+            self.criterion = [self.criterion]
+
+        super(LHS, self).__init__(parameters_random,
+                                  n_grid=n_grid,
+                                  options=options,
+                                  coords=coords,
+                                  coords_norm=coords_norm,
+                                  coords_gradient=coords_gradient,
+                                  coords_gradient_norm=coords_gradient_norm,
+                                  coords_id=coords_id,
+                                  coords_gradient_id=coords_gradient_id)
+
+        self.shift_outer = False
+
+        # if self.criterion == ["ese"]:
+        #     for p in parameters_random:
+        #         if parameters_random[p].p_perc is None:
+        #             self.shift_outer = True
+
+        if coords is not None and coords_norm is not None:
+            grid_present = True
+        else:
+            grid_present = False
+
+        if not grid_present:
+            if self.n_grid > 0:
+                self.sample_init(self.n_grid)
+
+    def sample_init(self, n_grid):
+        """
+        Initialises all parameters for Latin Hypercube Sampling and creates a new design
+        if there is at least one sampling point needed
+
+        Parameters
+        ----------
+        n_grid : ndarray of float [n]
+            The number of needed sampling points
+
+        Returns
+        -------
+        coords : ndarray of float [n_grid_add x dim]
+            Grid points to add (model space)
+        coords_norm : ndarray of float [n_grid_add x dim]
+            Grid points to add (normalized space)
+        coords_id : list of UUID objects (version 4) [n_grid]
+            Unique IDs of grid points
+        """
+
+        if n_grid > 0:
+            if n_grid == 1:
+                random_grid = Random(parameters_random=self.parameters_random,
+                                     n_grid=self.n_grid,
+                                     options=self.options)
+                self.coords_norm = random_grid.coords_norm
+
+            else:
+                if self.grid_pre is None:
+                    n_grid_lhs = self.n_grid
+                else:
+                    n_grid_lhs = self.n_grid + self.grid_pre.n_grid
+
+                self.perc_mask = np.zeros((n_grid_lhs, self.dim)).astype(bool)
+                self.coords_norm_reservoir = np.zeros([n_grid_lhs, self.dim])
+
+                # generate LHS coordinates
+                self.get_lhs_grid()
+
+        # Denormalize grid to original parameter space
+        self.coords = self.get_denormalized_coordinates(self.coords_norm)
+
+        # Generate unique IDs of grid points
+        self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
+
+    def CL2(self, array):
+        """
+        Calculate the L2 discrepancy of the design
+        The discrepancy is a measure of the difference between the empirical cumulative distribution function
+        of an experimental design and the uniform cumulative distribution function [1].
+
+        Parameters
+        ----------
+        array : ndarray of float [m x n]
+            Array with n rows of samples and m columns of variables/dimensions
+
+        Returns
+        -------
+        cl2d_crit : float
+            criterion for centered L2 discrepancy
+
+        Notes
+        -----
+        .. [1] Hickernell, F. (1998). A generalized discrepancy and quadrature error bound.
+           Mathematics of computation, 67(221), 299-322.
+        """
+        subtract = np.ones([np.shape(array)[0], np.shape(array)[1]])
+        array = array - 0.5 * subtract
+        prod_array_1 = np.zeros(np.shape(array)[0])
+        for n in range(0, np.shape(array)[0]):
+            prod_array_1[n] = (np.ones(np.shape(array)[1]) + (1 / 2 * (np.abs(array[n, :]))) - (
+                    1 / 2 * ((array[n, :]) ** 2))).prod()
+        prod_array_2 = np.zeros([np.shape(array)[0], np.shape(array)[0]])
+        for i in range(0, np.shape(array)[0]):
+            for j in range(0, np.shape(array)[0]):
+                prod_array_2[i, j] = (np.ones(np.shape(array)[1]) + (1 / 2 * (np.abs(array[i, :]))) - (
+                        1 / 2 * np.abs(array[j, :]) - 1 / 2 * np.abs(array[i, :] - array[j, :]))).prod()
+        cl2d_crit = ((13 / 12) ** 2) - (2 / (np.shape(array)[0]) * prod_array_1.sum()) + (1 / (
+                np.shape(array)[0] ** 2) * prod_array_2.sum())
+        # centered L2 discrepancy criteria
+        return cl2d_crit
+
+    def log_R(self, array):
+        """
+        Determines the Log(R) Entropy Criterion[1]
+
+        Parameters
+        ----------
+        array : ndarray of float [m x n]
+            Array
+
+        Returns
+        -------
+        log_R : float
+            Log(R) Entropy Criterion
+        Notes
+        -----
+        .. [1] Koehler, J.R., Owen, A.B., 1996. Computer experiments. in: Ghosh, S., Rao, C.R. (Eds.),
+           Handbook of Statistics. Elsevier Science, New York, pp.261-308
+        """
+        # R will be [m x m]
+        R = np.corrcoef(array.T)
+        for i in range(0, np.shape(array)[1]):
+            for j in range(0, np.shape(array)[1]):
+                R[i, j] = np.exp((R[i, :] * np.abs(array[i, :] - array[j, :]) ** 2).sum())
+        log_R = np.log(np.linalg.norm(R))
+
+        return (log_R)
+
+    def PhiP(self, x, p=10):
+        """
+        Calculates the Phi-p criterion of the design x with power p [1].
+
+        Parameters
+        ----------
+        x : ndarray of float [n x m]
+            The design to calculate Phi-p for
+        p : int, optional, default: 10
+            The power used for the calculation of PhiP
+
+        Returns
+        -------
+        phip : float
+            Phi-p criterion
+
+        Notes
+        -----
+        .. [1] Morris, M. D., & Mitchell, T. J. (1995). Exploratory designs for computational experiments.
+           Journal of statistical planning and inference, 43(3), 381-402.
+        """
+        m, n = x.shape
+        dist = np.zeros((m * (m - 1)) // 2, dtype=np.double)
+        k = 0
+        if self.method == "standard" or None:
+            for i in range(0, m - 1):
+                for j in range(i + 1, m):
+                    dist[k] = np.linalg.norm(x[i] - x[j])
+                    k = k + 1
+
+            phip = ((dist ** (-p)).sum()) ** (1.0 / p)
+        elif self.method == "periodic":
+            for i in range(0, m - 1):
+                for j in range(i + 1, m):
+                    periodic_dist = np.sqrt(np.sum(np.square(np.min(np.abs(x[i]-x[j])), 1 - np.abs(x[i]-x[j]))))
+                    dist[k] = periodic_dist
+                    k = k + 1
+
+            phip = ((dist ** (-p)).sum()) ** (1.0 / p)
+        return phip
+
+    def PhiP_exchange(self, P, k, Phi, p, fixed_index):
+        """
+        Performes a row exchange and return the altered design.
+
+        Parameters
+        ----------
+        P : ndarray of float [m x n]
+            The design to perform the exchange on
+        k : int
+            modulus of the iteration divided by the dimension to pick a row of the design repeating through the
+            dimensions of the design
+        Phi: float
+            the PhiP criterion of the current best Design
+        p: int
+            The power used for the calculation of PhiP
+        fixed_index: list
+            an empty list to check if variables are assigned a value
+
+        Returns
+        -------
+        phip : float
+            Phi-p criterion
+        """
+        # Choose two (different) random rows to perform the exchange
+        er = P.shape
+        i1 = np.random.randint(P.shape[0])
+        while i1 in fixed_index:
+            i1 = np.random.randint(P.shape[0])
+
+        i2 = np.random.randint(P.shape[0])
+        while i2 == i1 or i2 in fixed_index:
+            i2 = np.random.randint(P.shape[0])
+
+        P_= np.delete(P, [i1, i2], axis=0)
+
+        dist1 = scipy.spatial.distance.cdist([P[i1, :]], P_)
+        dist2 = scipy.spatial.distance.cdist([P[i2, :]], P_)
+        d1 = np.sqrt(dist1 ** 2 + (P[i2, k] - P_[:, k]) ** 2 - (P[i1, k] - P_[:, k]) ** 2)
+        d2 = np.sqrt(dist2 ** 2 - (P[i2, k] - P_[:, k]) ** 2 + (P[i1, k] - P_[:, k]) ** 2)
+
+        res = (Phi ** p + (d1 ** (-p) - dist1 ** (-p) + d2 ** (-p) - dist2 ** (-p)).sum()) ** (1.0 / p)
+
+        P[i1, k], P[i2, k] = P[i2, k], P[i1, k]
+        return res
+
+    def get_lhs_grid(self):
+        """
+        Create samples in an m*n matrix using Latin Hypercube Sampling [1].
+
+        Notes
+        -----
+        .. [1] McKay, M. D., Beckman, R. J., & Conover, W. J. (2000). A comparison of three methods for selecting
+           values of input variables in the analysis of output from a computer code. Technometrics, 42(1), 55-61.
+        """
+
+        # create sample points in icdf space using specified criteria
+        if self.criterion[0] == 'corr':
+            self.coords_norm_lhs = self.lhs_corr()
+        elif self.criterion[0] == 'maximin' or self.criterion == 'm':
+            self.coords_norm_lhs = self.lhs_maximin()
+        elif self.criterion[0] == 'ese':
+            self.coords_norm_lhs = self.lhs_ese()
+        else:
+            self.coords_norm_lhs = self.lhs_initial()
+
+        # transform sample points from icdf to pdf space
+        for i_p, p in enumerate(self.parameters_random):
+            self.coords_norm_reservoir[:, i_p] = self.parameters_random[p].icdf(self.coords_norm_lhs[:, i_p])
+
+        if self.grid_pre is not None:
+            self.coords_norm_reservoir = get_different_rows_from_matrices(self.grid_pre.coords_norm,
+                                                                          self.coords_norm_reservoir)
+
+        self.coords_norm = self.coords_norm_reservoir[0:self.n_grid, :]
+
+    def lhs_initial(self):
+        """
+        Construct an initial LHS grid.
+
+        Returns
+        -------
+        design : ndarray of float [n, n_dim]
+            LHS grid points
+        """
+
+        if self.grid_pre is not None:
+            # transform normalized coordinates back to LHS-Space (0, 1)
+            pre_coords_lhs = np.zeros(self.grid_pre.coords_norm.shape)
+
+            for i, p in enumerate(self.parameters_random):
+                pre_coords_lhs[:, i] = self.parameters_random[p].cdf_norm(self.grid_pre.coords_norm[:, i])
+
+            return self.lhs_extend(pre_coords_lhs, self.n_grid)
+
+        else:
+            design = np.zeros([self.n_grid, self.dim])
+
+            # u = matrix of uniform (0,1) that vary in n subareas
+            u = np.random.rand(self.n_grid, self.dim)
+
+            for i in range(0, self.dim):
+                for j in range(0, self.n_grid):
+
+                    if self.shift_outer:
+                        if j == 0:
+                            design[j, i] = j + 1
+                            u[j, i] = 1 - 1/4 * u[j, i]
+                        elif (j + 1) == self.n_grid:
+                            design[j, i] = j + 1
+                            u[j, i] = 1/4 * u[j, i]
+                        elif j <= self.n_grid/2:
+                            design[j, i] = j + 1 - ((j*3/4) / ((self.n_grid - 2) * self.n_grid))
+                        elif j > self.n_grid/2:
+                            design[j, i] = j + 1 + ((j*3/4) / ((self.n_grid - 2) * self.n_grid))
+                    else:
+                        design[j, i] = j + 1
+
+            for i in range(0, self.dim):
+                for j in range(0, self.n_grid):
+                    design[j, i] = (design[j, i] - u[j, i]) / self.n_grid
+
+                np.random.shuffle(design[:, i])
+
+            return design
+
+    def lhs_corr(self):
+        """
+        Create a correlation optimized LHS grid
+
+        Parameters
+        ----------
+        dim : int
+            Number of random variables
+        n : int
+            Number of sampling points
+        iterations : int
+            Number of iterations to optimize
+
+        Returns
+        -------
+        design : ndarray of float [n, n_dim]
+            LHS grid points
+        """
+        mincorr = np.inf
+
+        # Minimize the components correlation coefficients
+        for i in range(100):
+            # Generate a random LHS
+            test = self.lhs_initial()
+            R = scipy.stats.spearmanr(test)[0]
+
+            if np.max(np.abs(R)) < mincorr:
+                mincorr = np.max(np.abs(R))
+                design = test.copy()
+
+        return design
+
+    def lhs_maximin(self):
+        """
+        Create an optimized LHS grid with maximal minimal distance
+
+        Parameters
+        ----------
+        dim : int
+            Number of random variables
+        n : int
+            Number of sampling points
+        iterations : int
+            Number of iterations to optimize
+
+        Returns
+        -------
+        design : ndarray of float [n, n_dim]
+            LHS grid points
+        """
+        phi_best = max(1000, self.n_grid * 100)
+
+        # Maximize the minimum distance between points
+        for i in range(100):
+            test = self.lhs_initial()
+            phi = self.PhiP(test)
+            if phi_best > phi:
+                phi_best = phi
+                design = test.copy()
+
+        return design
+
+    def lhs_ese(self):
+        """
+        Create optimized LHS grid using a enhanced stochastic evolutionary algorithm for the PhiP Maximin criterion [1]
+
+        Returns
+        -------
+        design : ndarray of float [n, n_dim]
+            With ESE Algorithm for minimal Phi-P optimized grid points
+
+        Notes
+        -----
+        .. [1] Jin, R., Chen, W., & Sudjianto, A. (2005). An efficient algorithm for constructing optimal
+           design of computer experiments. Journal of statistical planning and inference, 134(1), 268-287.
+        """
+
+        # Parameters
+        t0 = None
+        P0 = self.lhs_initial()
+        J = 25
+        tol = 1e-3
+        p = 10
+        outer_loop = min(int(1.5 * self.dim), 30)
+        inner_loop = min(20 * self.dim, 100)
+
+        if self.coords_norm_reservoir_perced is not None:
+            fixed_index = [*range(self.coords_norm_reservoir_perced.shape[0])]
+        elif self.grid_pre is not None:
+            fixed_index = [*range(self.grid_pre.coords_norm.shape[0])]
+        else:
+            fixed_index = []
+
+        if t0 is None:
+            t0 = 0.005 * self.PhiP(P0, p=p)
+
+        T = t0
+        P_ = P0[:]  # copy of initial design
+        P_best = P_[:]
+        Phi = self.PhiP(P_best, p=p)
+        Phi_best = Phi
+
+        # Outer loop
+        for z in range(outer_loop):
+            Phi_oldbest = Phi_best
+            n_acpt = 0
+            n_imp = 0
+
+            # Inner loop
+            for i in range(inner_loop):
+                modulo = (i + 1) % self.dim
+                l_P = list()
+                l_Phi = list()
+
+                # Build J different designs with a single exchanged row
+                # See PhiP_exchange
+                for j in range(J):
+                    l_P.append(P_.copy())
+                    l_Phi.append(self.PhiP_exchange(l_P[j], k=modulo, Phi=Phi, p=p, fixed_index=fixed_index))
+
+                l_Phi = np.asarray(l_Phi)
+                k = np.argmin(l_Phi)
+                Phi_try = l_Phi[k]
+
+                # Threshold of acceptance
+                if Phi_try - Phi <= T * np.random.rand(1)[0]:
+                    Phi = Phi_try
+                    n_acpt = n_acpt + 1
+                    P_ = l_P[k]
+
+                    # Best design retained
+                    if Phi < Phi_best:
+                        P_best = P_
+                        Phi_best = Phi
+                        n_imp = n_imp + 1
+
+            p_accpt = float(n_acpt) / inner_loop  # probability of acceptance
+            p_imp = float(n_imp) / inner_loop  # probability of improvement
+
+            if Phi_best - Phi_oldbest < tol:
+                # flag_imp = 1
+                if p_accpt >= 0.1 and p_imp < p_accpt:
+                    T = 0.8 * T
+                elif p_accpt >= 0.1 and p_imp == p_accpt:
+                    pass
+                else:
+                    T = T / 0.8
+            else:
+                # flag_imp = 0
+                if p_accpt <= 0.1:
+                    T = T / 0.7
+                else:
+                    T = 0.9 * T
+
+        return P_best
+
+
+class CO(RandomGrid):
+    """
+    Coherence Optimal grid object
+
+    Parameters
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    n_grid: int
+        Number of random samples to generate
+    options: dict, optional, default=None
+        Grid options:
+        - 'seed'            : Seeding point
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> grid = pygpc.CO(parameters_random=parameters_random, n_grid=100, options={"seed": None})
+
+    Attributes
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    n_grid : int or float
+        Number of random samples in grid
+    seed : float, optional, default=None
+        Seeding point to replicate random grid
+    options: dict, optional, default=None
+        Grid options:
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    """
+
+    def __init__(self, parameters_random, gpc, n_grid=None, options=None, coords=None, coords_norm=None,
+                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None,
+                 grid_pre=None):
+        """
+        Constructor; Initializes CO instance; Generates grid or copies provided content
+        """
+        if options is None:
+            options = dict()
+
+        if "seed" not in options.keys():
+            options["seed"] = None
+
+        if "n_warmup" not in options.keys():
+            options["n_warmup"] = max(200, n_grid*2)
+        else:
+            options["n_warmup"] = max(options["n_warmup"], n_grid * 2)
+
+        if "n_pool" not in options.keys():
+            if 1000 > 2 * n_grid:
+                options["n_pool"] = 1000
+            else:
+                options["n_pool"] = 2*n_grid
+
+        self.gpc = gpc
+        self.grid_pre = grid_pre
+        self.coords_pool = []
+        self.gpc_matrix_pool = []
+        self.b2_pool = []
+        self.g_pool = []
+        self.f_pool = []
+        self.n_pool = options["n_pool"]
+        self.all_norm = []
+
+        super(CO, self).__init__(parameters_random,
+                                 n_grid=n_grid,
+                                 options=options,
+                                 coords=coords,
+                                 coords_norm=coords_norm,
+                                 coords_gradient=coords_gradient,
+                                 coords_gradient_norm=coords_gradient_norm,
+                                 coords_id=coords_id,
+                                 coords_gradient_id=coords_gradient_id,
+                                 grid_pre=grid_pre)
+        if n_grid == 0:
+            pass
+        else:
+            self.ball_volume = self.calc_ball_volume(dim=self.dim, radius=np.sqrt(2) * np.sqrt(2*self.gpc.order_max+1))
+            pdf_type = [self.parameters_random[rv].pdf_type for rv in self.parameters_random]
+            self.all_norm = np.array([p == "norm" for p in pdf_type]).all()
+            any_norm = np.array([True for p in pdf_type if p == "norm"]).any() and not self.all_norm
+
+            if any_norm:
+                raise AssertionError("Mixed distributions of beta and normal for CO grids not implemented..."
+                                     "All variables have to be either normal or beta distributed!")
+
+            # create proposal distributed random variables
+            self.parameters_random_proposal = dict()
+            for rv in self.parameters_random:
+                # check the order > dimension criteria
+                if gpc.order_max > self.dim:
+
+                    # uniform distributed random variables -> Chebyshev distribution
+                    if self.parameters_random[rv].pdf_type == "beta" and \
+                            (self.parameters_random[rv].pdf_shape == [1, 1]).all():
+                        self.parameters_random_proposal[rv] = Beta(pdf_shape=[0.5, 0.5],
+                                                                   pdf_limits=[-1, 1])
+
+                    # normal distributed random variables -> sample uniformly from the d-dimensional ball of radius r
+                    # here a standard normal distribution is created, the uniform sampling from the ball is considered in
+                    # the method "create_pool"
+                    elif self.parameters_random[rv].pdf_type == "norm":
+                        self.parameters_random_proposal[rv] = Norm(pdf_shape=[0, 1],
+                                                                   p_perc=self.parameters_random[rv].p_perc)
+
+                    else:
+                        NotImplementedError("Coherence optimal sampling is only possible for uniform and normal "
+                                            "distributed random variables")
+                else:
+                    self.parameters_random_proposal[rv] = self.parameters_random[rv]
+            #define number of warmup-samples
+            self.n_warmup = options["n_warmup"]
+
+            # # draw sample pool for warmup
+            # self.create_pool(n_samples=2*options["n_warmup"])
+            #
+            # # warmup
+            # self.warmup(n_warmup=options["n_warmup"])
+
+            # draw sample pool for actual sampling
+            self.create_pool(n_samples=self.n_pool + self.n_warmup)
+
+            # get coherence optimal samples
+            self.coords_norm = self.get_coherence_optimal_samples(n_grid=self.n_grid, n_warmup=self.n_warmup)
+
+            # Denormalize grid to original parameter space
+            self.coords = self.get_denormalized_coordinates(self.coords_norm)
+
+    def create_pool(self, n_samples):
+        """
+        Creates a pool of samples together with the corresponding gPC matrix.
+
+        Parameters
+        ----------
+        n_samples : int
+            Number of samples
+        """
+
+        self.n_pool = n_samples
+        self.coords_pool = np.zeros((n_samples, self.dim))
+
+        for i_rv, rv in enumerate(self.parameters_random_proposal):
+            self.coords_pool[:, i_rv] = self.parameters_random_proposal[rv].sample(n_samples=int(self.n_pool))
+
+        if self.all_norm:
+            # sample from d-dimensional ball of radius r (Hampton et al. 2015, pp. 369)
+            r = np.sqrt(2)*np.sqrt(2*self.gpc.order_max+1)
+            self.coords_pool = self.coords_pool / (np.linalg.norm(self.coords_pool, axis=1))[:, np.newaxis] * \
+                               r * np.random.rand(1) ** (1/self.dim)
+
+        self.gpc_matrix_pool = self.gpc.create_gpc_matrix(b=self.gpc.basis.b, x=self.coords_pool)
+
+        self.b2_pool = np.linalg.norm(self.gpc_matrix_pool, axis=1)**2
+        self.g_pool = self.joint_pdf(x=self.coords_pool, parameters_random=self.parameters_random_proposal)
+        self.f_pool = self.joint_pdf(x=self.coords_pool, parameters_random=self.parameters_random)
+
+    @staticmethod
+    def calc_ball_volume(dim, radius):
+        """
+        Volume of n-dimensional ball.
+
+        Parameters
+        ----------
+        dim : int
+            Number of random variables
+        radius : float
+            Radius
+
+        Returns
+        -------
+        vol : float
+            Volume of n-dimensional ball
+        """
+        vol = radius**dim * np.pi**(dim/2) / gamma(dim/2 + 1)
+
+        return vol
+
+    def joint_pdf(self, x, parameters_random):
+        """
+        Joint probability density function of random variables
+
+        Parameters
+        ----------
+        x : ndarray of float [n_samples x n_dim]
+            Samples of random variables
+        parameters_random : dict of RandomVariable instances
+            Random variables of proposal distribution
+
+        Returns
+        -------
+        f : float
+            Joint probability density
+        """
+        f = np.ones(x.shape[0])
+
+        if np.array([True for p in parameters_random if parameters_random[p].pdf_type == "norm"]).all():
+            f *= 1/self.ball_volume
+        else:
+            for i_rv, rv in enumerate(parameters_random):
+                f *= parameters_random[rv].pdf_norm(x=x[:, i_rv])[1]
+
+        return f
+
+    def acceptance_rate(self, idx1, idx2):
+        """
+        Calculate acceptance rate of Metropolis Hastings algorithm
+
+        Parameters
+        ----------
+        idx1 : int
+            Index of sampling points of previous sample
+        idx2 : int
+            Index of sampling points of current sample
+
+        Returns
+        -------
+        rho : float
+            Acceptance rate
+        """
+
+        rho = np.min((1.,
+                     (self.g_pool[idx1]*self.f_pool[idx2]*self.b2_pool[idx2]) /
+                     (self.g_pool[idx2]*self.f_pool[idx1]*self.b2_pool[idx1])))
+
+        return rho
+
+    def warmup(self, n_warmup):
+        """
+        Warmup phase
+
+        Parameters
+        ----------
+        n_warmup : int
+            Number of warmup samples
+
+        Returns
+        -------
+        coords_norm_opt : ndarray of float [n_warmup x n_dim]
+            Optimal coordinates determined during warmup phase
+        """
+
+        coords_norm_opt = self.get_coherence_optimal_samples(n_grid=n_warmup)
+
+        return coords_norm_opt
+
+    def get_coherence_optimal_samples(self, n_grid, n_warmup):
+        """
+        Determine coherence optimal samples with Monte Carlo Markov Chain - Metropolis Hastings algorithm
+
+        Parameters
+        ----------
+        n_grid : int
+            Number of grid points
+        n_warmup: int
+            Number of warmup samples
+
+        Returns
+        -------
+        coords_norm : ndarray of float [n_grid x n_dim]
+            Coherence optimal samples
+        """
+        coords_norm_opt = np.zeros((n_grid, self.dim))
+        coords_norm_opt[0, :] = self.coords_pool[0, :][np.newaxis, :]
+
+        if self.grid_pre is not None:
+            coords_norm_opt[:self.grid_pre.n_grid, :] = self.grid_pre.coords_norm
+            i_grid_start = self.grid_pre.n_grid
+        else:
+            i_grid_start = 0
+
+        # init grid_index at -n_warmup, then the number of warmup-samples are automatically drawn,
+        # before index 0 is reached
+        i_grid = -(n_warmup - i_grid_start)
+        idx1 = 0
+        idx2 = 1
+
+        if self.all_norm:
+            x_perc_norm = np.zeros(len(self.parameters_random))
+            for i_rv, rv in enumerate(self.parameters_random):
+                x_perc_norm[i_rv] = self.parameters_random[rv].x_perc_norm[1]
+
+        while i_grid < n_grid:
+            # create a new pool if it is empty
+            if idx2 >= self.n_pool:
+                self.create_pool(2*n_grid)
+                idx1 = 0
+                idx2 = 1
+
+            # determine acceptance rate
+            rho = self.acceptance_rate(idx1=idx1, idx2=idx2)
+
+            # add point if acceptance rate is high
+            if rho > np.random.rand(1):
+                    if self.all_norm:
+                        if (np.abs(self.coords_pool[idx2, :]) < x_perc_norm).all():
+                            if i_grid > (i_grid_start-1):
+                                coords_norm_opt[i_grid, :] = self.coords_pool[idx2, :]
+                            i_grid += 1
+                            idx1 = idx2
+                    else:
+                        if i_grid > (i_grid_start-1):
+                            coords_norm_opt[i_grid, :] = self.coords_pool[idx2, :]
+                        i_grid += 1
+                        idx1 = idx2
+
+            idx2 += 1
+
+        return coords_norm_opt
+
+
+class L1(RandomGrid):
+    """
+    L1 optimized grid object
+
+    Parameters
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    n_grid: int
+        Number of random samples to generate
+    options: dict, optional, default=None
+        Grid options:
+        - method: "greedy", "iteration"
+        - criterion: ["mc"], ["tmc", "cc"], ["D"], ["D-coh"]
+        - weights: [1], [0.5, 0.5], [1]
+        - n_pool: size of samples in pool to choose greedy results from
+        - n_iter: number of iterations
+        - seed: random seed
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    gpc : GPC object instance
+        GPC object
+    grid_pre : Grid object instance, optional, default: None
+        Existent grid, which will be extended.
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> grid = pygpc.L1(parameters_random=parameters_random,
+    >>>                 n_grid=100,
+    >>>                 options={"method": "greedy",
+    >>>                          "criterion": ["mc"],
+    >>>                          "weights": [1],
+    >>>                          "n_pool": 1000,
+    >>>                          "seed": None})
+
+    Attributes
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    n_grid : int or float
+        Number of random samples in grid
+    seed : float, optional, default=None
+        Seeding point to replicate random grid
+    options: dict, optional, default=None
+        Grid options:
+        - method: "greedy", "iteration"
+        - criterion: ["mc"], ["tmc", "cc"], ["D"], ["D-coh"]
+        - weights: [1], [0.5, 0.5], [1]
+        - n_pool: size of samples in pool to choose greedy results from
+        - n_iter: number of iterations
+        - seed: random seed
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    gpc : GPC Object instance
+        GPC object
+    grid_pre : Grid object instance, optional, default: None
+        Existent grid, which will be extended.
+    """
+
+    def __init__(self, parameters_random, n_grid=None, options=None, coords=None, coords_norm=None,
+                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None, gpc=None,
+                 grid_pre=None):
+        """
+        Constructor; Initializes Grid instance; Generates grid or copies provided content
+        """
+        if options is None:
+            options = dict()
+
+        if type(options) is dict:
+            if "method" not in options.keys():
+                options["method"] = "greedy"
+
+            if "n_pool" not in options.keys():
+                options["n_pool"] = 10000
+
+            if "n_iter" not in options.keys():
+                options["n_iter"] = 1000
+
+            if "seed" not in options.keys():
+                options["seed"] = None
+
+            if "criterion" not in options.keys():
+                options["criterion"] = ["mc"]
+
+            if "weights" not in options.keys() or options["weights"] is None:
+                options["weights"] = (np.ones(len(options["criterion"])) / len(options["criterion"])).tolist()
+
+        self.n_pool = options["n_pool"]
+        self.n_iter = options["n_iter"]
+        self.gpc = gpc
+        self.seed = options["seed"]
+        self.method = options["method"]
+        self.criterion = options["criterion"]
+        self.coords_norm_perced = None
+        self.perc_mask = None
+
+        if type(self.criterion) is not list:
+            self.criterion = [self.criterion]
+
+        super(L1, self).__init__(parameters_random,
+                                 n_grid=n_grid,
+                                 options=options,
+                                 coords=coords,
+                                 coords_norm=coords_norm,
+                                 coords_gradient=coords_gradient,
+                                 coords_gradient_norm=coords_gradient_norm,
+                                 coords_id=coords_id,
+                                 coords_gradient_id=coords_gradient_id,
+                                 grid_pre=grid_pre)
+
+        self.weights = options["weights"]
+
+        if self.method == "greedy" and self.n_grid > 0 and self.coords is None:
+            self.coords_norm = self.get_optimal_mu_greedy()
+
+        elif (self.method == 'iteration' or self.method == 'iter') and self.n_grid > 0 and self.coords is None:
+            self.coords_norm = self.get_optimal_mu_iteration()
+
+        if self.n_grid > 0:
+            # Denormalize grid to original parameter space
+            self.coords = self.get_denormalized_coordinates(self.coords_norm)
+
+            # Generate unique IDs of grid points
+            self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
+
+    def get_optimal_mu_greedy(self):
+        """
+        This function computes a set of grid points with minimal mutual coherence using a greedy approach.
+
+        Returns
+        -------
+        coords_norm : ndarray of float [n_grid x dim]
+            Normalized sample coordinates in range [-1, 1]
+        """
+        n_cpu = np.min((1, multiprocessing.cpu_count()))
+
+        # create pool (Standard random grid for D-optimal grids and CO else)
+        if "D" in self.criterion:
+            random_pool = Random(parameters_random=self.parameters_random,
+                                 n_grid=self.n_pool,
+                                 options=self.options)
+        else:
+            random_pool = CO(parameters_random=self.parameters_random,
+                             n_grid=self.n_pool,
+                             gpc=self.gpc,
+                             options=self.options)
+            # full gpc matrix is needed for w_matrix, maybe build a function that creates weighted pools
+            # based of the coordinates
+            # self.gpc.get_weight_matrix()
+            # w_matrix = self.gpc.w
+        index_list = []
+
+        # project grid in case of projection approach
+        if self.gpc.p_matrix is not None:
+            # weight argument in create gpc matrix
+            random_pool_trans = project_grid(grid=random_pool, p_matrix=self.gpc.p_matrix, mode="reduce")
+            psy_pool = self.gpc.create_gpc_matrix(b=self.gpc.basis.b, x=random_pool_trans.coords_norm, gradient=False,
+                                                  weighted=True)
+        else:
+            psy_pool = self.gpc.create_gpc_matrix(b=self.gpc.basis.b, x=random_pool.coords_norm, gradient=False,
+                                                  weighted=True)
+
+        m = int(self.n_grid)
+        m_p = int(np.shape(psy_pool)[0])
+
+        # set up multiprocessing
+        pool = multiprocessing.Pool(n_cpu)
+
+        # set starting point for iteration
+        if self.grid_pre is None or self.grid_pre.n_grid == 0:
+            # get random row of psy to start
+            idx = np.random.randint(m_p)
+            index_list.append(idx)
+            index_list_remaining = [k for k in range(self.n_pool) if k not in index_list]
+            psy_opt = np.zeros((1, psy_pool.shape[1]))
+            psy_opt[0, :] = psy_pool[idx, :]
+            i_start = 1
+
+        else:
+            # project grid in case of projection approach
+            if self.gpc.p_matrix is not None:
+                grid_pre_trans = project_grid(grid=self.grid_pre, p_matrix=self.gpc.p_matrix, mode="reduce")
+                psy_opt = self.gpc.create_gpc_matrix(b=self.gpc.basis.b, x=grid_pre_trans.coords_norm, gradient=False,
+                                                     weighted=True)
+            else:
+                psy_opt = self.gpc.create_gpc_matrix(b=self.gpc.basis.b, x=self.grid_pre.coords_norm, gradient=False,
+                                                     weighted=True)
+
+            index_list = []
+            index_list_remaining = [k for k in range(self.n_pool) if k not in index_list]
+            i_start = self.grid_pre.n_grid
+
+        # loop over grid points
+        for i in range(i_start, m):
+            crit = np.ones((self.n_pool, len(self.criterion))) * 1e6
+
+            workhorse_partial = partial(workhorse_greedy, psy_opt=psy_opt, psy_pool=psy_pool, criterion=self.criterion)
+            idx_list_chunks = compute_chunks(index_list_remaining, n_cpu)
+
+            crit_tmp = pool.map(workhorse_partial, idx_list_chunks)
+
+            if "D" not in self.criterion and "D-coh" not in self.criterion:
+                crit_tmp = np.concatenate(crit_tmp)
+
+            else:
+                sign = []
+                neg_logdet = []
+
+                for res in crit_tmp:
+                    sign.append(res[0])
+                    neg_logdet.append(res[1])
+
+                sign = np.concatenate(sign)
+                neg_logdet = np.concatenate(neg_logdet)
+                neg_logdet_norm = neg_logdet / np.nan_to_num(np.max(np.abs(neg_logdet)))
+                crit_tmp = sign * np.nan_to_num(np.exp(neg_logdet_norm))
+
+            crit[index_list_remaining, :] = crit_tmp
+
+            # set 1e6 dummy values to max values
+            if "D" not in self.criterion and "D-coh" not in self.criterion:
+                for k in range(crit.shape[1]):
+                    crit[crit[:, k] == 1e6, k] = np.max(crit[crit[:, k] != 1e6, k])
+
+            # normalize optimality criteria to [0, 1]
+            crit = np.nan_to_num(crit)
+            crit = (crit - np.nanmin(crit, axis=0)) / np.nan_to_num((np.nanmax(crit, axis=0) - np.nanmin(crit, axis=0)))
+
+            # apply weights
+            crit = np.sum(crit**2 * np.array(self.weights), axis=1)
+
+            # find best index
+            try:
+                index_list.append(np.nanargmin(crit))
+            # in very rare cases there the optimal grid point can not be determined (all nan), in this case the first
+            # grid point of the remaining indices is chosen
+            except ValueError:
+                index_list.append(index_list_remaining[0])
+
+            # add row with best minimal coherence and cross correlation properties to the matrix
+            psy_opt = np.vstack((psy_opt, psy_pool[index_list[-1], :]))
+
+            # create list of remaining indices
+            index_list_remaining = [k for k in range(self.n_pool) if k not in index_list]
+
+        coords_norm = random_pool.coords_norm[index_list, :]
+
+        pool.close()
+        pool.join()
+
+        if self.grid_pre is not None:
+            coords_norm = np.vstack((self.grid_pre.coords_norm, coords_norm))
+
+        return coords_norm
+
+    def get_optimal_mu_iteration(self):
+        """
+        This function computes a set of grid points with minimal mutual coherence using an iterative approach.
+
+        Returns
+        -------
+        coords_norm : ndarray of float [n_grid x dim]
+            Normalized sample coordinates in range [-1, 1]
+        """
+        n_cpu = np.min((1, multiprocessing.cpu_count()))
+        coords_norm_list = []
+        crit = np.ones((self.n_iter, len(self.criterion))) * 1e6
+
+        # set up multiprocessing
+        pool = multiprocessing.Pool(n_cpu)
+        workhorse_partial = partial(workhorse_iteration,
+                                    gpc=self.gpc,
+                                    n_grid=self.n_grid,
+                                    criterion=self.criterion,
+                                    grid_pre=self.grid_pre,
+                                    options={"seed": self.seed})
+        idx_list_chunks = compute_chunks([k for k in range(self.n_iter)], n_cpu)
+
+        res = pool.map(workhorse_partial, idx_list_chunks)
+
+        for j in range(len(res)):
+            if j == 0:
+                if "D" not in self.criterion and "D-coh" not in self.criterion:
+                    crit = res[j][0]
+                    coords_norm_list = res[j][1]
+                else:
+                    sign = res[j][0]
+                    neg_logdet = res[j][1]
+                    neg_logdet_norm = neg_logdet / np.max(np.abs(neg_logdet))
+                    crit = sign * np.exp(neg_logdet_norm)
+                    coords_norm_list = res[j][2]
+            else:
+                if "D" not in self.criterion and "D-coh" not in self.criterion:
+                    crit = np.vstack((crit, res[j][0]))
+                    coords_norm_list = coords_norm_list + res[j][1]
+                else:
+                    sign = res[j][0]
+                    neg_logdet = res[j][1]
+                    neg_logdet_norm = neg_logdet / np.max(np.abs(neg_logdet))
+                    crit = np.vstack((crit, sign * np.exp(neg_logdet_norm)))
+                    coords_norm_list = coords_norm_list + res[j][2]
+
+        # normalize optimality criteria to [0, 1]
+        crit = (crit - np.min(crit, axis=0)) / np.nan_to_num((np.max(crit, axis=0) - np.min(crit, axis=0)))
+
+        # apply weights
+        crit = np.sum(crit**2 * np.array(self.weights), axis=1)
+
+        coords_norm = coords_norm_list[np.argmin(crit)]
+
+        pool.close()
+
+        return coords_norm
+
+
+class FIM(RandomGrid):
+    """
+    FIM D-optimal grid object
+
+    Parameters
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    n_grid: int
+        Number of random samples to generate
+    seed: float
+        Seeding point to replicate random grids
+    options: dict, optional, default=None
+        Grid options:
+        - 'n_pool'   : number of random samples to determine next optimal grid point
+        - 'seed'     : random seed
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> grid = pygpc.FIM(parameters_random=parameters_random,
+    >>>                  n_grid=100,
+    >>>                  options={"n_pool": 1000,
+    >>>                           "seed": None})
+
+    Attributes
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    n_grid : int or float
+        Number of random samples in grid
+    seed : float, optional, default=None
+        Seeding point to replicate random grid
+    options: dict, optional, default=None
+        Grid options:
+        - method: "greedy", "iteration"
+        - criterion: ["mc"], ["tmc", "cc"]
+        - weights: [1], [0.5, 0.5]
+        - n_pool: size of samples in pool to choose greedy results from
+        - n_iter: number of iterations
+        - seed: random seed
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    """
+
+    def __init__(self, parameters_random, n_grid=None, options=None, coords=None, coords_norm=None,
+                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None, gpc=None,
+                 grid_pre=None):
+        """
+        Constructor; Initializes Grid instance; Generates grid or copies provided content
+        """
+        if options is None:
+            options = dict()
+
+        if type(options) is dict:
+
+            if "n_pool" not in options.keys():
+                options["n_pool"] = 1000
+
+            if "seed" not in options.keys():
+                options["seed"] = None
+
+        self.n_pool = options["n_pool"]
+        self.gpc = copy.deepcopy(gpc)
+
+        super(FIM, self).__init__(parameters_random,
+                                  n_grid=n_grid,
+                                  options=options,
+                                  coords=coords,
+                                  coords_norm=coords_norm,
+                                  coords_gradient=coords_gradient,
+                                  coords_gradient_norm=coords_gradient_norm,
+                                  coords_id=coords_id,
+                                  coords_gradient_id=coords_gradient_id,
+                                  grid_pre=grid_pre)
+
+        if coords_norm is not None:
+            self.gpc.grid = Random(parameters_random=parameters_random,
+                                   coords_norm=coords_norm,
+                                   coords=coords,
+                                   options=self.options)
+            n_grid_add = self.gpc.grid.n_grid
+
+            if self.gpc.p_matrix is not None:
+                self.gpc.gpc_matrix = self.gpc.create_gpc_matrix(b=self.gpc.basis.b,
+                                                                 x=np.matmul(coords_norm,
+                                                                             self.gpc.p_matrix.transpose() /
+                                                                             self.gpc.p_matrix_norm[np.newaxis, :]),
+                                                                 gradient=False)
+            else:
+                self.gpc.gpc_matrix = self.gpc.create_gpc_matrix(b=self.gpc.basis.b,
+                                                                 x=coords_norm,
+                                                                 gradient=False)
+        elif self.grid_pre is not None:
+            self.gpc.grid = self.grid_pre
+            n_grid_add = self.n_grid - self.grid_pre.n_grid
+
+            if n_grid_add < 0:
+                raise RuntimeError(f"Number of grid points to add has to be >= 0 (it is {n_grid_add}")
+
+            if self.gpc.p_matrix is not None:
+                self.gpc.gpc_matrix = self.gpc.create_gpc_matrix(b=self.gpc.basis.b,
+                                                                 x=np.matmul(self.grid_pre.coords_norm,
+                                                                             self.gpc.p_matrix.transpose() /
+                                                                             self.gpc.p_matrix_norm[np.newaxis, :]),
+                                                                 gradient=False)
+            else:
+                self.gpc.gpc_matrix = self.gpc.create_gpc_matrix(b=self.gpc.basis.b,
+                                                                 x=self.grid_pre.coords_norm,
+                                                                 gradient=False)
+        else:
+            n_grid_add = self.n_grid
+
+        # add FIM optimal grid points (eventually to existing grid)
+        self.coords_norm = self.add_fim_optiomal_grid_points(parameters_random=parameters_random,
+                                                             n_grid_add=n_grid_add)
+
+        # Denormalize grid to original parameter space
+        self.coords = self.get_denormalized_coordinates(self.coords_norm)
+
+        # Generate unique IDs of grid points
+        self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
+
+    def add_fim_optiomal_grid_points(self, parameters_random, n_grid_add):
+        """
+        This function adds grid points (one by one) to the set of points by maximizing the Fisher-information matrix
+        in a D-optimal sense.
+
+        Parameters
+        ----------
+        parameters_random : OrderedDict of RandomParameter [dim]
+            Random parameters (in case of projection, provide the original random parameters)
+        n_grid_add : int
+            Number of grid points to add
+
+        Returns
+        -------
+        coords_norm : ndarray of float [n_grid x dim]
+            Normalized sample coordinates in range [-1, 1]
+        """
+
+        # coords_norm_opt = np.zeros((n_grid_add, self.dim))
+        #
+        # for i in range(n_grid_add):
+        #     fim_matrix = self.calc_fim_matrix()
+        #     grid_test = Random(parameters_random=self.gpc.problem.parameters_random,
+        #                        n_grid=self.n_pool,
+        #                        options=self.options)
+        #
+        #     det = np.zeros(grid_test.coords_norm.shape[0])
+        #
+        #     for i_c, c in enumerate(grid_test.coords_norm):
+        #         det[i_c] = self.get_det_updated_fim_matrix(fim_matrix=fim_matrix, coords_norm=c)
+        #
+        #     coords_norm_opt[i, :] = grid_test.coords_norm[np.argmax(det), :]
+        #
+        # return coords_norm_opt
+
+        coords_norm_opt = np.zeros((n_grid_add, self.dim))
+        n_cpu = multiprocessing.cpu_count()
+        pool = multiprocessing.Pool(n_cpu)
+
+        grid_pool = Random(parameters_random=parameters_random,
+                           n_grid=self.n_pool,
+                           options={"seed": self.seed})
+
+        if self.gpc.p_matrix is not None:
+            gpc_matrix_pool = self.gpc.create_gpc_matrix(b=self.gpc.basis.b,
+                                                         x=np.matmul(self.grid_pool.coords_norm,
+                                                                     self.gpc.p_matrix.transpose() /
+                                                                     self.gpc.p_matrix_norm[np.newaxis, :]),
+                                                         gradient=False)
+        else:
+            gpc_matrix_pool = self.gpc.create_gpc_matrix(b=self.gpc.basis.b,
+                                                         x=grid_pool.coords_norm,
+                                                         gradient=False)
+
+        if self.gpc.gpc_matrix is not None:
+            fim_matrix = self.calc_fim_matrix()
+        else:
+            fim_matrix = None
+
+        index_list = []
+
+        for i in range(n_grid_add):
+            det = np.zeros((self.n_pool))
+
+            if self.seed is not None:
+                self.seed += 1
+                self.options["seed"] += 1
+
+            # select random starting point
+            if self.gpc.gpc_matrix is None:
+                coords_opt = grid_pool.coords_norm[0, :][np.newaxis, ]
+                self.gpc.grid = Random(parameters_random=parameters_random,
+                                       options={"seed": self.seed},
+                                       coords_norm=coords_opt)
+
+                self.gpc.gpc_matrix = self.gpc.create_gpc_matrix(b=self.gpc.basis.b,
+                                                                 x=self.gpc.grid.coords_norm[-1, :][np.newaxis, ],
+                                                                 gradient=False)
+
+                index_list.append(0)
+
+            else:
+                index_list_remaining = [k for k in range(self.n_pool) if k not in index_list]
+                index_list_chunks = compute_chunks(index_list_remaining, n_cpu)
+
+                n_basis_limit = np.min((self.gpc.grid.n_grid, self.gpc.basis.n_basis))
+                workhorse_partial = partial(workhorse_get_det_updated_fim_matrix,
+                                            gpc_matrix_pool=gpc_matrix_pool,
+                                            fim_matrix=fim_matrix,
+                                            n_basis_limit=n_basis_limit)
+
+                res = pool.map(workhorse_partial, index_list_chunks)
+
+                sign = []
+                logdet = []
+
+                for r in res:
+                    sign.append(r[0])
+                    logdet.append(r[1])
+
+                sign = np.concatenate(sign)
+                logdet = np.concatenate(logdet)
+
+                logdet_norm = logdet / np.max(np.abs(logdet))
+                det[index_list_remaining] = (sign * np.exp(logdet_norm)).flatten()
+                index_list.append(np.nanargmax(det))
+
+                coords_opt = grid_pool.coords_norm[index_list[-1], :]
+
+                # add optimal grid point
+                self.gpc.grid.coords_norm = np.vstack((self.gpc.grid.coords_norm, coords_opt))
+
+                # update gpc matrix
+                self.gpc.gpc_matrix = np.vstack((self.gpc.gpc_matrix,
+                                                 self.gpc.create_gpc_matrix(b=self.gpc.basis.b,
+                                                                            x=self.gpc.grid.coords_norm[-1, :][np.newaxis, ],
+                                                                            gradient=False)))
+
+            # update FIM matrix
+            n_basis_limit = np.min((self.gpc.grid.n_grid, self.gpc.basis.n_basis))
+
+            if n_basis_limit == (self.gpc.basis.n_basis+1):
+                fim_matrix = self.update_fim_matrix(fim_matrix=fim_matrix,
+                                                    gpc_matrix_new_rows=self.gpc.gpc_matrix[-1, :][np.newaxis, ])
+            else:
+                fim_matrix = self.calc_fim_matrix(n_basis_limit=n_basis_limit)
+
+        pool.close()
+
+        return self.gpc.grid.coords_norm
+
+    def calc_fim_matrix(self, n_basis_limit=None):
+        """
+        Calculates Fisher-Information matrix based on the present grid.
+
+        Parameters
+        ----------
+        n_basis_limit : int
+            Index of column the FIM matrix is calculated
+
+        Returns
+        -------
+        fim_matrix : ndarray of float [n_basis x n_basis]
+            Fisher information matrix
+        """
+        if n_basis_limit is None:
+            n_basis_limit = self.gpc.gpc_matrix.shape[1]
+
+        fim_matrix = np.zeros((n_basis_limit, n_basis_limit))
+
+        for row in self.gpc.gpc_matrix:
+            fim_matrix += np.outer(row[:n_basis_limit], row[:n_basis_limit])
+
+        return fim_matrix
+
+    @staticmethod
+    def update_fim_matrix(fim_matrix, gpc_matrix_new_rows):
+        """
+        Updates Fisher-Information matrix based on the present grid.
+
+        Parameters
+        ----------
+        fim_matrix : ndarray of float [n_basis x n_basis]
+            Fisher information matrix
+        gpc_matrix_new_rows : ndarray of float [n_new_rows x n_basis]
+            New rows of gpc matrix to add to FIM matrix
+
+        Returns
+        -------
+        fim_matrix : ndarray of float [n_basis x n_basis]
+            Updated Fisher information matrix
+        """
+        if fim_matrix is None:
+            fim_matrix = np.zeros((gpc_matrix_new_rows.shape[1], gpc_matrix_new_rows.shape[1]))
+
+        for row in gpc_matrix_new_rows:
+            fim_matrix += np.outer(row, row)
+
+        return fim_matrix
+
+    def get_det_updated_fim_matrix(self, fim_matrix, coords_norm):
+        """
+        Calculates Fisher-Information matrix based on the present grid and determined determinant.
+
+        Parameters
+        ----------
+        fim_matrix : ndarray of float [n_basis x n_basis]
+            Fisher information matrix
+        coords_norm : ndarray of float [1 x dim]
+            Candidate grid point
+
+        Returns
+        -------
+        det : float
+            Determinant of updated Fisher Information matrix
+        """
+        new_row = self.gpc.create_gpc_matrix(b=self.gpc.basis.b, x=coords_norm, gradient=False)
+        fim_matrix += np.outer(new_row, new_row)
+
+        return np.linalg.det(fim_matrix)
+
+
+class L1_LHS(RandomGrid):
+    """
+    L1-LHS optimized grid object
+
+    Parameters
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    n_grid: int
+        Number of random samples to generate
+    seed: float
+        Seeding point to replicate random grids
+    options: dict, optional, default=None
+        Grid options:
+        - 'corr'            : optimizes design points in their spearman correlation coefficients
+        - 'maximin' or 'm'  : optimizes design points in their maximum minimal distance using the Phi-P criterion
+        - 'ese'             : uses an enhanced evolutionary algorithm to optimize the Phi-P criterion
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> grid = pygpc.L1_LHS(parameters_random=parameters_random,
+    >>>                     n_grid=100,
+    >>>                     gpc=gpc,
+    >>>                     options={"method": "greedy",
+    >>>                              "criterion": ["mc"],
+    >>>                              "weights_L1": [1],
+    >>>                              "weights": [0.25, 0.75],
+    >>>                              "n_pool": 1000,
+    >>>                              "seed": None})
+
+    Attributes
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    n_grid : int or float
+        Number of random samples in grid
+    seed : float, optional, default=None
+        Seeding point to replicate random grid
+    options: dict, optional, default=None
+        Grid options:
+        - method: "greedy", "iteration"
+        - criterion: ["mc"], ["tmc", "cc"]
+        - weights: [1], [0.5, 0.5]
+        - n_pool: size of samples in pool to choose greedy results from
+        - n_iter: number of iterations
+        - seed: random seed
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space), if coords are provided, no grid is generated
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space), if coords are provided, no grid is generated
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    """
+
+    def __init__(self, parameters_random, n_grid=None, options=None, coords=None, coords_norm=None,
+                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None, gpc=None,
+                 grid_pre=None):
+        """
+        Constructor; Initializes Grid instance; Generates grid or copies provided content
+        """
+        if options is None:
+            options = dict()
+
+        if type(options) is dict:
+            if "weights" not in options.keys():
+                options["weights"] = [0.5, 0.5]
+
+            if "method" not in options.keys():
+                options["method"] = "iteration"
+
+            if "n_pool" not in options.keys():
+                options["n_pool"] = 10000
+
+            if "n_iter" not in options.keys():
+                options["n_iter"] = 1000
+
+            if "seed" not in options.keys():
+                options["seed"] = None
+
+            if "criterion" not in options.keys():
+                options["criterion"] = ["mc"]
+
+            if "weights_L1" not in options.keys() or options["weights_L1"] is None:
+                options["weights_L1"] = (np.ones(len(options["criterion"])) / len(options["criterion"])).tolist()
+
+        self.n_pool = options["n_pool"]
+        self.n_iter = options["n_iter"]
+        self.gpc = gpc
+        self.seed = options["seed"]
+        self.method = options["method"]
+        self.criterion = options["criterion"]
+        self.weights_L1 = options["weights_L1"]
+        self.grid_L1 = None
+        self.grid_LHS = None
+        self.grid_pre = grid_pre
+
+        if type(self.criterion) is not list:
+            self.criterion = [self.criterion]
+
+        super(L1_LHS, self).__init__(parameters_random,
+                                     n_grid=n_grid,
+                                     options=options,
+                                     coords=coords,
+                                     coords_norm=coords_norm,
+                                     coords_gradient=coords_gradient,
+                                     coords_gradient_norm=coords_gradient_norm,
+                                     coords_id=coords_id,
+                                     coords_gradient_id=coords_gradient_id)
+
+        self.weights = options["weights"]
+
+        if coords_norm is None:
+            self.n_grid_L1 = int(np.round(self.n_grid * self.weights[0]))
+            self.n_grid_LHS = self.n_grid - self.n_grid_L1
+        else:
+            self.n_grid_L1 = None
+            self.n_grid_LHS = None
+
+        # create L1 grid
+        if coords_norm is None and self.n_grid_L1 > 0:
+            self.grid_L1 = L1(parameters_random=parameters_random,
+                              n_grid=self.n_grid_L1,
+                              gpc=gpc,
+                              grid_pre=grid_pre,
+                              options={"method": self.method,
+                                       "criterion": self.criterion,
+                                       "weights": self.weights_L1,
+                                       "n_pool": self.n_pool,
+                                       "n_iter": self.n_iter,
+                                       "seed": self.seed})
+
+            if self.grid_pre is not None:
+                self.grid_pre.coords_norm = np.vstack((self.grid_pre.coords_norm, self.grid_L1.coords_norm))
+                self.grid_pre.coords = np.vstack((self.grid_pre.coords, self.grid_L1.coords))
+                self.grid_pre.n_grid = self.grid_pre.coords_norm.shape[0]
+            else:
+                self.grid_pre = self.grid_L1
+
+        # create LHS (ese) grid
+        if coords_norm is None and self.n_grid_LHS > 0:
+            self.grid_LHS = LHS(parameters_random=parameters_random,
+                                n_grid=self.n_grid_LHS,
+                                grid_pre=self.grid_pre,
+                                options={"criterion": ["ese"],
+                                         "seed": self.seed})
+
+        if self.grid_L1 is None and self.grid_LHS is not None:
+            self.coords_norm = self.grid_LHS.coords_norm
+        elif self.n_grid_L1 is not None and self.grid_LHS is None:
+            self.coords_norm = self.grid_L1.coords_norm
+        elif self.n_grid_L1 is not None and self.grid_LHS is not None:
+            self.coords_norm = np.vstack((self.grid_L1.coords_norm, self.grid_LHS.coords_norm))
+
+        # Denormalize grid to original parameter space
+        self.coords = self.get_denormalized_coordinates(self.coords_norm)
+
+        # Generate unique IDs of grid points
+        self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
+
+
+class LHS_L1(RandomGrid):
+    """
+    LHS-L1 optimized grid object
+
+    Parameters
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    n_grid: int
+        Number of random samples to generate
+    options: dict, optional, default=None
+        Grid options:
+        - 'corr'            : optimizes design points in their spearman correlation coefficients
+        - 'maximin' or 'm'  : optimizes design points in their maximum minimal distance using the Phi-P criterion
+        - 'ese'             : uses an enhanced evolutionary algorithm to optimize the Phi-P criterion
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> grid = pygpc.LHS_L1(parameters_random=parameters_random,
+    >>>                     n_grid=100,
+    >>>                     gpc=gpc,
+    >>>                     options={"method": "greedy",
+    >>>                              "criterion": ["mc"],
+    >>>                              "weights_L1": [1],
+    >>>                              "weights": [0.25, 0.75],
+    >>>                              "n_pool": 1000,
+    >>>                              "seed": None})
+
+    Attributes
+    ----------
+    parameters_random : OrderedDict of RandomParameter instances
+        OrderedDict containing the RandomParameter instances the grids are generated for
+    n_grid : int or float
+        Number of random samples in grid
+    seed : float, optional, default=None
+        Seeding point to replicate random grid
+    options: dict, optional, default=None
+        Grid options:
+        - method: "greedy", "iteration"
+        - criterion: ["mc"], ["tmc", "cc"]
+        - weights: [1], [0.5, 0.5]
+        - n_pool: size of samples in pool to choose greedy results from
+        - n_iter: number of iterations
+        - seed: random seed
+    coords : ndarray of float [n_grid_add x dim]
+        Grid points to add (model space)
+    coords_norm : ndarray of float [n_grid_add x dim]
+        Grid points to add (normalized space)
+    coords_gradient : ndarray of float [n_grid x dim x dim]
+        Denormalized coordinates xi
+    coords_gradient_norm : ndarray of float [n_grid x dim x dim]
+        Normalized coordinates xi
+    coords_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    coords_gradient_id : list of UUID objects (version 4) [n_grid]
+        Unique IDs of grid points
+    """
+
+    def __init__(self, parameters_random, gpc, n_grid=None, options=None, coords=None, coords_norm=None,
+                 coords_gradient=None, coords_gradient_norm=None, coords_id=None, coords_gradient_id=None,
+                 grid_pre=None):
+        """
+        Constructor; Initializes Grid instance; Generates grid or copies provided content
+        """
+        if options is None:
+            options = dict()
+
+        if type(options) is dict:
+            if "weights" not in options.keys():
+                options["weights"] = [0.5, 0.5]
+
+            if "method" not in options.keys():
+                options["method"] = "iteration"
+
+            if "n_pool" not in options.keys():
+                options["n_pool"] = 10000
+
+            if "n_iter" not in options.keys():
+                options["n_iter"] = 1000
+
+            if "seed" not in options.keys():
+                options["seed"] = None
+
+            if "criterion" not in options.keys():
+                options["criterion"] = ["mc"]
+
+            if "weights_L1" not in options.keys() or options["weights_L1"] is None:
+                options["weights_L1"] = (np.ones(len(options["criterion"])) / len(options["criterion"])).tolist()
+
+        self.n_pool = options["n_pool"]
+        self.n_iter = options["n_iter"]
+        self.gpc = gpc
+        self.seed = options["seed"]
+        self.method = options["method"]
+        self.criterion = options["criterion"]
+        self.weights_L1 = options["weights_L1"]
+        self.grid_L1 = None
+        self.grid_LHS = None
+        self.grid_pre = grid_pre
+
+        if type(self.criterion) is not list:
+            self.criterion = [self.criterion]
+
+        super(LHS_L1, self).__init__(parameters_random,
+                                     n_grid=n_grid,
+                                     options=options,
+                                     coords=coords,
+                                     coords_norm=coords_norm,
+                                     coords_gradient=coords_gradient,
+                                     coords_gradient_norm=coords_gradient_norm,
+                                     coords_id=coords_id,
+                                     coords_gradient_id=coords_gradient_id)
+
+        self.weights = options["weights"]
+
+        if coords_norm is None:
+            self.n_grid_LHS = int(np.round(self.n_grid * self.weights[0]))
+            self.n_grid_L1 = self.n_grid - self.n_grid_LHS
+        else:
+            self.n_grid_LHS = None
+            self.n_grid_L1 = None
+
+        # create LHS (ese) grid
+        if coords_norm is None and self.n_grid_LHS > 0:
+            self.grid_LHS = LHS(parameters_random=parameters_random,
+                                n_grid=self.n_grid_LHS,
+                                grid_pre=grid_pre,
+                                options={"criterion": ["ese"],
+                                         "seed": self.seed})
+
+            if self.grid_pre is not None:
+                self.grid_pre.coords_norm = np.vstack((self.grid_pre.coords_norm, self.grid_LHS.coords_norm))
+                self.grid_pre.coords = np.vstack((self.grid_pre.coords, self.grid_LHS.coords))
+                self.grid_pre.n_grid = self.grid_pre.coords_norm.shape[0]
+            else:
+                self.grid_pre = self.grid_LHS
+
+        # create L1 grid
+        if coords_norm is None and self.n_grid_L1 > 0:
+            self.grid_L1 = L1(parameters_random=parameters_random,
+                              n_grid=self.n_grid_L1,
+                              grid_pre=self.grid_pre,
+                              gpc=gpc,
+                              options={"method": self.method,
+                                       "criterion": self.criterion,
+                                       "weights": self.weights_L1,
+                                       "n_pool": self.n_pool,
+                                       "n_iter": self.n_iter,
+                                       "seed": self.seed})
+
+        if self.grid_L1 is None and self.grid_LHS is not None:
+            self.coords_norm = self.grid_LHS.coords_norm
+        elif self.n_grid_L1 is not None and self.grid_LHS is None:
+            self.coords_norm = self.grid_L1.coords_norm
+        elif self.n_grid_L1 is not None and self.grid_LHS is not None:
+            self.coords_norm = np.vstack((self.grid_LHS.coords_norm, self.grid_L1.coords_norm))
+
+        # Denormalize grid to original parameter space
+        self.coords = self.get_denormalized_coordinates(self.coords_norm)
+
+        # Generate unique IDs of grid points
+        self.coords_id = [uuid.uuid4() for _ in range(self.n_grid)]
+
+
+def project_grid(grid, p_matrix, mode="reduce"):
+    """
+    Transforms grid from original to reduced parameter space or vice versa.
+
+    Parameters
+    ----------
+    grid : Grid object
+        Grid object to transform
+    p_matrix : ndarray of float [n_reduced, n_original]
+        Projection matrix
+    mode : str
+        Direction of transformation ("reduce", "expand")
+
+    Returns
+    -------
+    grid_trans : Grid object
+        Transformed grid object
+    """
+    grid_trans = copy.deepcopy(grid)
+    p_matrix_norm = np.sum(np.abs(p_matrix), axis=1)
+
+    if mode == "reduce":
+        p = p_matrix.transpose()
+        p_n = p / p_matrix_norm[np.newaxis, :]
+    elif mode == "expand":
+        p = p_matrix
+        p_n = p / p_matrix_norm[:, np.newaxis]
+    else:
+        raise ValueError("Specified mode not implemented... ('reduce', 'expand')")
+
+    # transform variables of original grid to reduced parameter space
+    grid_trans.coords = np.matmul(grid.coords, p)
+    grid_trans.coords_norm = np.matmul(grid.coords_norm, p_n)
+
+    return grid_trans
+
+
+def workhorse_greedy(idx_list, psy_opt, psy_pool, criterion):
+    """
+    Workhorse for coherence calculation (greedy algorithm)
+
+    Parameters
+    ----------
+    idx_list : list of int [n_idx]
+        Indices of rows of pool matrix the coherence is calculated for
+    psy_opt : ndarray of float [n_grid_current, n_basis]
+        GPC matrix of previous iteration
+    psy_pool : ndarray of float [n_pool, n_basis]
+        GPC matrix of pool
+    criterion : list of str
+        Optimality criteria
+
+    Returns
+    -------
+    crit : ndarray of float [n_idx, n_criterion]
+        Optimality measures
+    """
+
+    crit = np.ones((len(idx_list), len(criterion))) * 1e6
+
+    # determine gram matrix of psy_opt
+    psy_opt_gram = np.matmul(psy_opt.T, psy_opt)
+
+    if "D" in criterion or "D-coh" in criterion:
+        sign = np.zeros((len(idx_list), 1))
+        logdet = np.zeros((len(idx_list), 1))
+
+    for j in range(len(idx_list)):
+        psy_test = np.vstack((psy_opt, psy_pool[idx_list[j], :]))
+
+        # update gram matrix
+        psy_test_gram = psy_opt_gram + np.outer(psy_test[-1, :], psy_test[-1, :])
+
+        if "mc" in criterion:
+            crit[j, criterion.index("mc")] = mutual_coherence(psy_test)
+
+        if "tmc" in criterion:
+            crit[j, criterion.index("tmc")] = t_averaged_mutual_coherence(psy_test_gram)
+
+        if "cc" in criterion:
+            crit[j, criterion.index("cc")] = average_cross_correlation_gram(psy_test_gram)
+
+        if "D" in criterion or "D-coh" in criterion:
+            # for n_grid < n_basis only consider the first n_grid basis functions because of determinant
+            n_basis_det = np.min((psy_test.shape[0], psy_test.shape[1]))
+
+            # determinant of inverse of Gram is the inverse of the determinant
+            sign[j], logdet[j] = np.linalg.slogdet(psy_test_gram[:n_basis_det, :n_basis_det])
+            #sign[j], logdet[j] = np.linalg.slogdet(np.matmul(psy_test[:, :n_basis_det].T, psy_test[:, :n_basis_det]))
+            logdet[j] = -logdet[j]
+
+    if "D" not in criterion and "D-coh" not in criterion:
+        return crit
+    else:
+        return sign, logdet
+
+
+def workhorse_iteration(idx_list, gpc, n_grid, criterion, grid_pre=None, options=None):
+    """
+    Workhorse for coherence calculation (iterative algorithm)
+
+    Parameters
+    ----------
+    idx_list : list of int [n_idx]
+        Indices of iterations
+    gpc : GPC object
+        GPC object
+    n_grid : int
+        Number of grid points
+    criterion : list of str
+        Optimality criteria
+    grid_pre : Grid object, optional, default: None
+        Grid object, which is going to be extended.
+    options : dict, optional, default: False
+        Dictionary containing the grid options
+
+    Returns
+    -------
+    crit : ndarray of float [n_idx, n_criterion]
+        Optimality measures
+    coords_norm_list : list [n_idx] of ndarray [n_grid x dim]
+        Normalized grid coordinates of grid realizations
+    """
+    coords_norm_list = []
+    crit = np.ones((len(idx_list), len(criterion))) * 1e6
+    backend_backup = gpc.backend
+    gpc.backend = "cpu"
+
+    if "D" in criterion or "D-coh" in criterion:
+        sign = np.zeros((len(idx_list), 1))
+        neg_logdet = np.zeros((len(idx_list), 1))
+
+    if grid_pre is not None and grid_pre.n_grid > 0:
+        psy_pool_pre = gpc.create_gpc_matrix(b=gpc.basis.b, x=grid_pre.coords_norm, gradient=False)
+    else:
+        psy_pool_pre = None
+
+    for i in range(len(idx_list)):
+        # print(f"idx_list iteration: {i}")
+        if gpc.p_matrix is not None:
+            if "D-coh" in criterion:
+                test_grid = CO(parameters_random=gpc.problem_original.parameters_random,
+                               n_grid=n_grid,
+                               grid_pre=grid_pre,
+                               gpc=gpc,
+                               options=options)
+            else:
+                test_grid = Random(parameters_random=gpc.problem_original.parameters_random,
+                                   n_grid=n_grid,
+                                   grid_pre=grid_pre,
+                                   options={"seed": options["seed"]})
+        else:
+            if "D-coh" in criterion:
+                test_grid = CO(parameters_random=gpc.problem.parameters_random,
+                               n_grid=n_grid,
+                               grid_pre=grid_pre,
+                               gpc=gpc,
+                               options=options)
+            else:
+                test_grid = Random(parameters_random=gpc.problem.parameters_random,
+                                   n_grid=n_grid,
+                                   grid_pre=grid_pre,
+                                   options={"seed": options["seed"]})
+
+        coords_norm = test_grid.coords_norm
+
+        # save current coords norm
+        coords_norm_list.append(coords_norm)
+
+        # get the normalized gpc matrix
+        if gpc.p_matrix is not None:
+            psy_pool = gpc.create_gpc_matrix(b=gpc.basis.b,
+                                             x=np.matmul(coords_norm, gpc.p_matrix.transpose() /
+                                                         gpc.p_matrix_norm[np.newaxis, :]),
+                                             gradient=False)
+        else:
+            psy_pool = gpc.create_gpc_matrix(b=gpc.basis.b, x=coords_norm, gradient=False)
+
+        if psy_pool_pre is not None:
+            psy_pool = np.vstack((psy_pool_pre, psy_pool))
+
+        psy_pool_norm = psy_pool / np.abs(psy_pool).max(axis=0)
+
+        # test current matrix
+        if "mc" in criterion:
+            crit[i, criterion.index("mc")] = mutual_coherence(psy_pool_norm)
+
+        if "tmc" in criterion:
+            crit[i, criterion.index("tmc")] = t_averaged_mutual_coherence(np.matmul(psy_pool_norm.T, psy_pool_norm))
+
+        if "cc" in criterion:
+            crit[i, criterion.index("cc")] = average_cross_correlation_gram(np.matmul(psy_pool_norm.T, psy_pool_norm))
+
+        if "D" in criterion or "D-coh" in criterion:
+            # for n_grid < n_basis only consider the first n_grid basis functions because of determinant
+            n_basis_det = np.min((n_grid, gpc.basis.n_basis))
+
+            # determinant of inverse of Gram is the inverse of the determinant
+            sign[i], neg_logdet[i] = np.linalg.slogdet(np.matmul(psy_pool_norm[:, :n_basis_det].T, psy_pool_norm[:, :n_basis_det]))
+            neg_logdet[i] = -neg_logdet[i]
+
+    gpc.backend = backend_backup
+
+    if "D" not in criterion and "D-coh" not in criterion:
+        return crit, coords_norm_list
+    else:
+        return sign, neg_logdet, coords_norm_list
+
+
+def workhorse_get_det_updated_fim_matrix(index_list, gpc_matrix_pool, fim_matrix, n_basis_limit):
+    """
+    Workhorse to determine the determinant of the Fisher Information matrix
+
+    Parameters
+    ----------
+    index_list : list of int
+        Indices of coordinates to test
+    gpc_matrix_pool : ndarray of float [n_grid_pool x n_basis]
+        Gpc matrix of large pool
+    fim_matrix : ndarray of float [n_basis x n_basis]
+        Fisher information matrix
+
+    Returns
+    -------
+    det : float
+        Determinant of updated Fisher Information matrix
+    """
+    sign = np.zeros(len(index_list))
+    logdet = np.zeros(len(index_list))
+
+    for i, idx in enumerate(index_list):
+        fim_matrix_test = fim_matrix + np.outer(gpc_matrix_pool[idx, :n_basis_limit],
+                                                gpc_matrix_pool[idx, :n_basis_limit])
+        sign[i], logdet[i] = np.linalg.slogdet(fim_matrix_test)
+
+    return sign, logdet
+
+
+def compute_neg_loglik(parameters, Xtrain, ytrain):
+    """
+    Computes the negative log likelihood of the hyperparameters of the Gaussian Process Regression.
+
+    Parameters
+    ----------
+    parameters : np.ndarray of float [2]
+        Hyperparameters (lengthscale, variance)
+    Xtrain : np.ndarray of float [N_train x dim]
+        Coordinates of the training data
+    ytrain : np.ndarray of float [N_train]
+        Function values at the training data points
+
+    Returns
+    -------
+    log_likelihood : float
+        Negative log likelihood
+    """
+    lengthscale, variance = parameters
+    K = squared_exponential_kernel(Xtrain, Xtrain, lengthscale, variance)  # n_train x n_train
+
+    try:
+        L = np.linalg.cholesky(K)
+    except np.linalg.LinAlgError:
+        return 0
+
+    alpha = np.linalg.solve(L.T, np.linalg.solve(L, ytrain))
+    log_likelihood = - 0.5 * ytrain.T @ alpha - np.log(np.diag(L)).sum() - len(ytrain) / 2 * np.log(2 * np.pi)
+
+    return - log_likelihood.squeeze()
+
+
+def get_parameters_gaussian_process(Xtrain, ytrain):
+    """
+    Determine optimal hyperparameters for Gaussian Process Regression (lengthscale, variance), without noise.
+
+    Parameters
+    ----------
+    Xtrain : np.ndarray of float [N_train x dim]
+        Coordinates of the training data
+    ytrain : np.ndarray of float [N_train]
+        Function values at the training data points
+
+    Returns
+    -------
+    lengthscale : float, optional, default: 1.
+        Lengthscale parameter
+    variance : float, optional, default: 1.
+        Output variance
+    """
+    lengthscale = .2
+    kernel_variance = 1
+    bounds = ((1e-3, 1e2), (1e-3, 1e2))
+    initial_parameters = np.array([lengthscale, kernel_variance])
+    args = (Xtrain, ytrain)
+    result = minimize(compute_neg_loglik, initial_parameters, args, method='l-bfgs-b', bounds=bounds)
+    lengthscale = result.x[0]
+    variance = result.x[1]
+
+    return lengthscale, variance
```

## pygpc/MEGPC.py

```diff
@@ -1,910 +1,913 @@
-import numpy as np
-import fastmat as fm
-import scipy.stats
-import copy
-import h5py
-import time
-import random
-from sklearn import linear_model
-from .misc import get_cartesian_product
-from .misc import get_gradient_idx_domain
-from .misc import display_fancy_bar
-from .misc import nrmsd
-from .misc import mat2ten
-from .misc import ten2mat
-from .misc import increment_basis
-from .Gradient import get_gradient
-from .ValidationSet import *
-from .Computation import *
-from .Classifier import *
-from .Grid import *
-from .SGPC import *
-
-
-class MEGPC(object):
-    """
-    General Multi-Element gPC base class
-
-    Parameters
-    ----------
-    problem: Problem class instance
-        GPC Problem under investigation
-    options : dict
-        Options of gPC algorithm
-    validation: ValidationSet object (optional)
-        Object containing a set of validation points and corresponding solutions. Can be used
-        to validate gpc approximation setting options["error_type"]="nrmsd".
-        - grid: Grid object containing the validation points (grid.coords, grid.coords_norm)
-        - results: ndarray [n_grid x n_out] results
-
-    Attributes
-    ----------
-    problem: Problem class instance
-        GPC Problem under investigation
-    grid: Grid class instance
-        Grid of the derived gPC approximation
-    validation: ValidationSet object (optional)
-        Object containing a set of validation points and corresponding solutions. Can be used
-        to validate gpc approximation setting options["error_type"]="nrmsd".
-        - grid: Grid object containing the validation points (grid.coords, grid.coords_norm)
-        - results: ndarray [n_grid x n_out] results
-    n_grid: int or list of int
-        Number of grid points (for iterative solvers, this is a list of its history)
-    solver: str
-        Default solver to determine the gPC coefficients (can be chosen during GPC.solve)
-        - 'Moore-Penrose' ... Pseudoinverse of gPC matrix (SGPC.Reg, EGPC)
-        - 'OMP' ... Orthogonal Matching Pursuit, sparse recovery approach (SGPC.Reg, EGPC)
-        - 'LarsLasso' ... {"alpha": float 0...1} Regularization parameter
-        - 'NumInt' ... Numerical integration, spectral projection (SGPC.Quad)
-    verbose: bool
-        boolean value to determine if to print out the progress into the standard output
-    fn_results : string, optional, default=None
-        If provided, model evaluations are saved in fn_results.hdf5 file and gpc object in fn_results.pkl file
-    options : dict
-        Options of gPC algorithm
-    """
-
-    def __init__(self, problem, options, validation=None):
-        """
-        Constructor; Initializes MEGPC class
-        """
-
-        # objects
-        self.problem = problem
-        # self.sub_problems = None
-        self.grid = None
-        self.validation = validation
-        self.gpc = None
-        self.classifier = None
-        self.domains = None
-
-        # arrays
-        self.n_grid = []
-        self.n_out = []
-        self.n_gpc = None
-        self.relative_error_loocv = []
-        self.relative_error_nrmsd = []
-        self.error = []
-        self.gradient_idx = None
-
-        # options
-        self.gradient = options["gradient_enhanced"]
-        self.solver = None
-        self.settings = None
-        self.verbose = True
-        if "fn_results" not in options.keys():
-            options["fn_results"] = None
-        self.fn_results = options["fn_results"]
-        self.options = options
-        self.matlab_model = options["matlab_model"]
-
-    def init_classifier(self, coords, results, algorithm, options):
-        """
-        Initializes Classifier object in MEGPC class
-
-        Parameters
-        ----------
-        coords : ndarray of float [n_grid, n_dim]
-            Set of n_grid parameter combinations
-        results : ndarray [n_grid x n_out]
-            Results of the model evaluation
-        algorithm : str, optional, default: "learning"
-            Algorithm to classify grid points
-            - "learning" ... 2-step procedure with unsupervised and supervised learning
-            - ...
-        options : dict, optional, default=None
-            Classifier options
-        """
-        self.classifier = Classifier(coords=coords,
-                                     results=results,
-                                     algorithm=algorithm,
-                                     options=options)
-
-        self.domains = self.classifier.domains
-        self.n_gpc = len(np.unique(self.domains))
-
-    def update_classifier(self, coords, results):
-        """
-        Updates self.classifier and keeps the existing class labels
-
-        Parameters
-        ----------
-        coords : ndarray of float [n_grid, n_dim]
-            Set of n_grid parameter combinations
-        results : ndarray [n_grid x n_out]
-            Results of the model evaluation
-        """
-        self.classifier.update(coords=coords, results=results)
-        self.domains = self.classifier.domains
-        self.n_gpc = len(np.unique(self.domains))
-
-    def add_sub_gpc(self, problem, order, order_max, order_max_norm, interaction_order,
-                    interaction_order_current, options, domain, validation=None):
-        """
-        Add sub-gPC
-        """
-        if self.gpc is None:
-            if self.n_gpc is not None:
-                self.gpc = [None for _ in range(self.n_gpc)]
-            else:
-                self.gpc = [0 for _ in range(domain)]
-        elif len(self.gpc) < domain:
-            self.gpc = self.gpc + [None for _ in range(domain - len(self.gpc))]
-
-        # create sub-gpc objects
-        self.gpc[domain] = Reg(problem=problem,
-                               order=order,
-                               order_max=order_max,
-                               order_max_norm=order_max_norm,
-                               interaction_order=interaction_order,
-                               interaction_order_current=interaction_order_current,
-                               options=options,
-                               validation=validation)
-
-    def init_gpc_matrices(self):
-        """
-        Sets self.gpc_matrix with given self.basis and self.grid
-        The gradient_idx of the sub-gPCs are already assigned in assign_grids()
-        """
-
-        for gpc in self.gpc:
-            gpc.init_gpc_matrix()
-
-    def assign_grids(self, gradient_idx=None):
-        """
-        Assign sub-grids to sub-gPCs
-        (including transformation in case of projection and gradient_idx)
-
-        Parameters
-        ----------
-        gradient_idx : ndarray of int [gradient_results.shape[0]]
-            Indices of grid points where the gradient in gradient_results is provided
-        """
-
-        self.gradient_idx = gradient_idx
-
-        # update domain indices if grid points were added
-        if len(self.domains) != self.grid.coords_norm.shape[0]:
-            self.domains = self.classifier.predict(self.grid.coords_norm)
-
-        for d in np.unique(self.domains):
-            coords = self.grid.coords[self.domains == d, :]
-            coords_norm = self.grid.coords_norm[self.domains == d, :]
-            coords_id = np.array(self.grid.coords_id)[self.domains == d].tolist()
-
-            # transform variables of original grid to reduced parameter space
-            if self.gpc[d].p_matrix is not None:
-                coords = np.matmul(coords, self.gpc[d].p_matrix.transpose())
-                coords_norm = np.matmul(coords_norm, self.gpc[d].p_matrix.transpose() /
-                                        self.gpc[d].p_matrix_norm[np.newaxis, :])
-
-            if self.grid.coords_gradient is not None:
-                coords_gradient = self.grid.coords_gradient[self.domains == d, :, :]
-                coords_gradient_norm = self.grid.coords_gradient_norm[self.domains == d, :, :]
-                coords_gradient_id = np.array(self.grid.coords_gradient_id)[self.domains == d].tolist()
-            else:
-                coords_gradient = None
-                coords_gradient_norm = None
-                coords_gradient_id = None
-
-            self.gpc[d].grid = Grid(parameters_random=self.problem.parameters_random,
-                                    coords=coords,
-                                    coords_norm=coords_norm,
-                                    coords_gradient=coords_gradient,
-                                    coords_gradient_norm=coords_gradient_norm,
-                                    coords_id=coords_id,
-                                    coords_gradient_id=coords_gradient_id)
-
-            # assign gradient_idx for sub-gPCs
-            if self.gradient_idx is not None:
-                self.gpc[d].gradient_idx = get_gradient_idx_domain(domains=self.domains,
-                                                                   d=d,
-                                                                   gradient_idx=self.gradient_idx)
-
-    def loocv(self, results, error_norm="relative", domain=None):
-        """
-        Perform leave-one-out cross validation of gPC approximation and add error value to self.relative_error_loocv.
-        The loocv error is calculated analytically after eq. (35) in [1] but omitting the "1 - " term, i.e. it
-        corresponds to 1 - Q^2.
-
-        relative_error_loocv = GPC.loocv(sim_results, coeffs)
-
-        .. math::
-           \\epsilon_{LOOCV} = \\frac{\\frac{1}{N}\sum_{i=1}^N \\left( \\frac{y(\\xi_i) - \hat{y}(\\xi_i)}{1-h_i}
-           \\right)^2}{\\frac{1}{N-1}\sum_{i=1}^N \\left( y(\\xi_i) - \\bar{y} \\right)^2}
-
-        with
-
-        .. math::
-           \\mathbf{h} = \mathrm{diag}(\\mathbf{\\Psi} (\\mathbf{\\Psi}^T \\mathbf{\\Psi})^{-1} \\mathbf{\\Psi}^T)
-
-        Parameters
-        ----------
-        results : ndarray of float [n_grid x n_out]
-            Results from n_grid simulations with n_out output quantities
-        error_norm : str, optional, default="relative"
-            Decide if error is determined "relative" or "absolute"
-        domain : int, optional, default: None
-            Determine error in specified domain only. Default: None (all domains)
-
-        Returns
-        -------
-        relative_error_loocv : float
-            Relative mean error of leave one out cross validation
-
-        Notes
-        -----
-        .. [1] Blatman, G., & Sudret, B. (2010). An adaptive algorithm to build up sparse polynomial chaos expansions
-           for stochastic finite element analysis. Probabilistic Engineering Mechanics, 25(2), 183-197.
-        """
-
-        n_loocv = 25
-
-        if domain is not None:
-            results_domain = copy.deepcopy(results[self.domains == domain, :])
-            domain_idx = copy.deepcopy(domain)
-        else:
-            results_domain = copy.deepcopy(results)
-
-        # define number of performed cross validations (max 25)
-        n_loocv_points = np.min((results_domain.shape[0], n_loocv))
-
-        # make list of indices, which are randomly sampled (this index is w.r.t. to all points if domain is None)
-        loocv_point_idx = random.sample(list(range(results_domain.shape[0])), n_loocv_points)
-
-        start = time.time()
-        relative_error = np.zeros(n_loocv_points)
-
-        for i in range(n_loocv_points):
-
-            if domain is None:
-                # determine domain of loocv point
-                domain_idx = int(self.classifier.predict(self.grid.coords_norm[loocv_point_idx[i]][np.newaxis, :]))
-                results_domain = results[self.domains == domain_idx, ]
-
-            # determine row in sub-gPC matrix of loocv point
-            loocv_point_idx_domain = np.sum(np.array(self.domains == domain_idx)[0:loocv_point_idx[i]])
-
-            # get mask of eliminated row
-            mask = np.arange(results_domain.shape[0]) != loocv_point_idx_domain
-
-            # select right gpc matrix
-            matrix = self.gpc[domain_idx].gpc_matrix
-
-            # determine gpc coefficients (this takes a lot of time for large problems)
-            coeffs_loo = self.gpc[domain_idx].solve(results=results_domain[mask, :],
-                                                    solver=self.options["solver"],
-                                                    matrix=matrix[mask, :],
-                                                    settings=self.options["settings"],
-                                                    verbose=False)
-
-            sim_results_temp = results_domain[loocv_point_idx_domain, :]
-
-            if error_norm == "relative":
-                norm = scipy.linalg.norm(sim_results_temp)
-            else:
-                norm = 1.
-
-            # determine error
-            relative_error[i] = scipy.linalg.norm(sim_results_temp - np.matmul(matrix[loocv_point_idx_domain, :],
-                                                                            coeffs_loo)) \
-                                / norm
-            display_fancy_bar("LOOCV", int(i + 1), int(n_loocv_points))
-
-        # store result in relative_error_loocv
-        relative_error_loocv = np.mean(relative_error)
-        iprint("LOOCV computation time: {} sec".format(time.time() - start), tab=0, verbose=True)
-
-        return relative_error_loocv
-
-    def validate(self, coeffs, results=None, gradient_results=None, domain=None, output_idx=None):
-        """
-        Validate gPC approximation using the ValidationSet object contained in the Problem object.
-        Determines the normalized root mean square deviation between the gpc approximation and the
-        original model. Skips this step if no validation set is present
-
-        Parameters
-        ----------
-        coeffs: list of ndarray of float [n_gpc][n_coeffs x n_out]
-            GPC coefficients
-        results: ndarray of float [n_grid x n_out]
-            Results from n_grid simulations with n_out output quantities
-        gradient_results : ndarray of float [n_grid x n_out x dim], optional, default: None
-            Gradient of results in original parameter space (tensor)
-        domain : int, optional, default: None
-            Determine error in specified domain only. Default: None (all domains)
-        output_idx : int or list of int
-            Index of the QOI the provided coeffs and results are referring to. The correct QOI will be
-            selected from the validation set in case of nrmsd error.
-
-        Returns
-        -------
-        error: float
-            Estimated difference between gPC approximation and original model
-        """
-        if output_idx is None:
-            output_idx = np.arange(results.shape[1])
-        if type(output_idx) is list:
-            output_idx = np.array(output_idx)
-        if type(output_idx) is not np.ndarray:
-            output_idx = np.array([output_idx])
-
-        if domain is None:
-            domain_idx = np.arange(len(coeffs))
-        else:
-            domain_idx = domain
-
-        # Determine QOIs with NaN in results and exclude them from validation
-        non_nan_mask = np.where(np.all(~np.isnan(results), axis=0))[0]
-        n_nan = results.shape[1] - non_nan_mask.size
-
-        if n_nan > 0:
-            iprint("In {}/{} output quantities NaN's were found.".format(n_nan, results.shape[1]),
-                   tab=0, verbose=self.options["verbose"])
-
-        results = results[:, non_nan_mask]
-
-        # always determine nrmsd if a validation set is present
-        if isinstance(self.validation, ValidationSet):
-
-            if domain is None:
-                mask_domain = np.ones(self.validation.grid.coords_norm.shape[0]).astype(bool)
-                gpc_results = self.get_approximation(coeffs, self.validation.grid.coords_norm, output_idx=None)
-            else:
-                mask_domain = self.classifier.predict(self.validation.grid.coords_norm) == domain
-                coords_domain = self.validation.grid.coords_norm[mask_domain, ]
-                gpc_results = self.gpc[domain].get_approximation(coeffs[domain],
-                                                                 coords_domain,
-                                                                 output_idx=None)
-
-            if gpc_results.ndim == 1:
-                gpc_results = gpc_results[:, np.newaxis]
-
-            validation_results_passed = self.validation.results[np.argwhere(mask_domain), output_idx]
-
-            if validation_results_passed.ndim == 1:
-                validation_results_passed = validation_results_passed[:, np.newaxis]
-
-            error_nrmsd = float(np.mean(nrmsd(gpc_results,
-                                              validation_results_passed,
-                                              error_norm=self.options["error_norm"],
-                                              x_axis=False)))
-
-            if domain is None:
-                self.relative_error_nrmsd.append(error_nrmsd)
-
-        if self.options["error_type"] == "nrmsd":
-            if domain is None:
-                self.error.append(self.relative_error_nrmsd[-1])
-
-        elif self.options["error_type"] == "loocv":
-            error_loocv = self.loocv(results=results,
-                                     error_norm=self.options["error_norm"],
-                                     domain=domain)
-
-            if domain is None:
-                self.relative_error_loocv.append(error_loocv)
-                self.error.append(self.relative_error_loocv[-1])
-
-        if domain is None:
-            return self.error[-1]
-        else:
-            if self.options["error_type"] == "nrmsd":
-                return error_nrmsd
-            elif self.options["error_type"] == "loocv":
-                return error_loocv
-
-    def get_pdf(self, coeffs, n_samples, output_idx=None):
-        """ Determine the estimated pdfs of the output quantities
-
-        pdf_x, pdf_y = MEGPC.get_pdf(coeffs, n_samples, output_idx=None)
-
-        Parameters
-        ----------
-        coeffs: list of ndarray of float [n_gpc][n_coeffs x n_out]
-            GPC coefficients
-        n_samples: int
-            Number of samples used to estimate output pdfs
-        output_idx: ndarray, optional, default=None [1 x n_out]
-            Index of output quantities to consider (if output_idx=None, all output quantities are considered)
-
-        Returns
-        -------
-        pdf_x: ndarray of float [100 x n_out]
-            x-coordinates of output pdfs of output quantities
-        pdf_y: ndarray of float [100 x n_out]
-            y-coordinates of output pdfs (probability density of output quantity)
-        """
-
-        # handle (N,) arrays
-        if len(coeffs[0].shape) == 1:
-            n_out = 1
-        else:
-            n_out = coeffs[0].shape[1]
-
-        # if output index array is not provided, determine pdfs of all outputs
-        if output_idx is None:
-            output_idx = np.linspace(0, n_out - 1, n_out)
-            output_idx = output_idx[np.newaxis, :]
-
-        # sample gPC expansion
-        samples_in, samples_out = self.get_samples(n_samples=n_samples, coeffs=coeffs, output_idx=output_idx)
-
-        # determine kernel density estimates using Gaussian kernel
-        pdf_x = np.zeros([100, n_out])
-        pdf_y = np.zeros([100, n_out])
-
-        for i_out in range(n_out):
-            pdf_y[:, i_out], tmp = np.histogram(samples_out, bins=100, density=True)
-            pdf_x[:, i_out] = (tmp[1:] + tmp[0:-1])/2.
-
-            # kde = scipy.stats.gaussian_kde(samples_out[:, i_out], bw_method=0.1 / samples_out[:, i_out].std(ddof=1))
-            # pdf_y[:, i_out] = kde(pdf_x[:, i_out])
-            # pdf_x[:, i_out] = np.linspace(samples_out[:, i_out].min(), samples_out[:, i_out].max(), 100)
-
-        return pdf_x, pdf_y
-
-    def get_samples(self, coeffs, n_samples, output_idx=None):
-        """
-        Randomly sample gPC expansion.
-
-        x, pce = SGPC.get_pdf_mc(n_samples, coeffs, output_idx=None)
-
-        Parameters
-        ----------
-        coeffs: list of ndarray of float [n_gpc][n_basis x n_out]
-            GPC coefficients for each sub-domain
-        n_samples: int
-            Number of random samples drawn from the respective input pdfs.
-        output_idx: ndarray of int [1 x n_out] optional, default=None
-            Index of output quantities to consider.
-
-        Returns
-        -------
-        x: ndarray of float [n_samples x dim]
-            Generated samples in normalized coordinates [-1, 1]. (original parameter space)
-        pce: ndarray of float [n_samples x n_out]
-            GPC approximation at points x.
-        """
-
-        # seed the random numbers generator
-        np.random.seed()
-
-        # generate temporary grid with random samples for each random input variable [n_samples x dim]
-        grid = Random(parameters_random=self.problem.parameters_random,
-                      n_grid=n_samples,
-                      options=None)
-
-        # if output index list is not provided, sample all gpc outputs
-        if output_idx is None:
-            n_out = 1 if coeffs[0].ndim == 1 else coeffs[0].shape[1]
-            output_idx = np.arange(n_out)
-
-        pce = self.get_approximation(coeffs=coeffs, x=grid.coords_norm, output_idx=output_idx)
-
-        return grid.coords_norm, pce
-
-    def get_approximation(self, coeffs, x, output_idx=None):
-        """
-        Calculates the gPC approximation in points with output_idx and normalized parameters xi (interval: [-1, 1]).
-
-        pce = MEGPC.get_approximation(coeffs, x, output_idx=None)
-
-        Parameters
-        ----------
-        coeffs: list of ndarray of float [n_gpc][n_basis x n_out]
-            GPC coefficients for each output variable of each sub-domain
-        x: ndarray of float [n_x x n_dim]
-            Normalized coordinates, where the gPC approximation is calculated (original parameter space)
-        output_idx: ndarray of int, optional, default=None [n_out]
-            Indices of output quantities to consider (Default: all).
-
-        Returns
-        -------
-        pce: ndarray of float [n_x x n_out]
-            GPC approximation at normalized coordinates x.
-        """
-        if type(output_idx) is list:
-            output_idx = np.array(output_idx)
-        elif type(output_idx) != np.ndarray and output_idx is not None:
-            output_idx = np.array([output_idx])
-        else:
-            if type(coeffs) is list:
-                output_idx = np.arange(coeffs[0].shape[1])
-            else:
-                output_idx = np.arange(coeffs.shape[1])
-
-        pce = np.zeros((x.shape[0], len(output_idx)))
-
-        # get classes of grid-points
-        domains = self.classifier.predict(x)
-
-        # determine gPC approximation for sub-domains
-        for d in np.unique(domains):
-            pce[domains == d, :] = self.gpc[d].get_approximation(coeffs=coeffs[d],
-                                                                 x=x[(domains == d).flatten(), :],
-                                                                 output_idx=output_idx)
-
-        return pce
-
-    def update_gpc_matrices(self, gradient=False):
-        """
-        Update gPC matrix according to existing self.grid and self.basis.
-
-        Call this method when self.gpc_matrix does not fit to self.grid and self.basis objects anymore
-        The old gPC matrix with their self.gpc_matrix_b_id and self.gpc_matrix_coords_id is compared
-        to self.basis.b_id and self.grid.coords_id. New rows and columns are computed when differences are found.
-        """
-        for i, gpc in enumerate(self.gpc):
-            gpc.update_gpc_matrix(gradient=gradient)
-
-    def save_gpc_matrices_hdf5(self):
-        """
-        Save gPC matrix and gPC gradient matrix in .hdf5 file <"fn_results" + ".hdf5"> under the key "gpc_matrix/dom_x"
-        and "gpc_matrix_gradient/dom_x". If matrices are already present, check for equality and save only appended
-        rows and columns.
-        """
-        for i, gpc in enumerate(self.gpc):
-            gpc.save_gpc_matrix_hdf5(hdf5_path_gpc_matrix="gpc_matrix/dom_" + str(i),
-                                     hdf5_path_gpc_matrix_gradient="gpc_matrix_gradient/dom_" + str(i))
-
-    def solve(self, results, gradient_results=None, solver=None, settings=None, verbose=False):
-        """
-        Determines gPC coefficients of sub-gPCs
-
-        Parameters
-        ----------
-        results : ndarray of float [n_grid x n_out]
-            Results from simulations with n_out output quantities
-        gradient_results : ndarray of float [n_gradient x n_out x dim], optional, default: None
-            Gradient of results in original parameter space in specific grid points
-        solver : str
-            Solver to determine the gPC coefficients
-            - 'Moore-Penrose' ... Pseudoinverse of gPC matrix (SGPC.Reg, EGPC)
-            - 'OMP' ... Orthogonal Matching Pursuit, sparse recovery approach (SGPC.Reg, EGPC)
-            - 'LarsLasso' ... Least-Angle Regression using Lasso model (SGPC.Reg, EGPC)
-            - 'NumInt' ... Numerical integration, spectral projection (SGPC.Quad)
-        settings : dict
-            Solver settings
-            - 'Moore-Penrose' ... None
-            - 'OMP' ... {"n_coeffs_sparse": int} Number of gPC coefficients != 0 or "sparsity": float 0...1
-            - 'LarsLasso' ... {"alpha": float 0...1} Regularization parameter
-            - 'NumInt' ... None
-        verbose : bool
-            boolean value to determine if to print out the progress into the standard output
-
-        Returns
-        -------
-        coeffs: list of ndarray of float [n_gpc][n_coeffs x n_out]
-            gPC coefficients
-        """
-
-        # use default solver if not specified
-        if solver is None:
-            solver = self.solver
-
-        # use default solver settings if not specified
-        if solver is None:
-            settings = self.settings
-
-        coeffs = [0 for _ in range(self.n_gpc)]
-
-        # determine coeffs of sub-gPCs
-        for d in np.unique(self.domains):
-            if gradient_results is not None:
-                gradient_results_passed = gradient_results[self.domains[self.gradient_idx] == d, :, :]
-            else:
-                gradient_results_passed = None
-
-            coeffs[d] = self.gpc[d].solve(results=results[self.domains == d, :],
-                                          gradient_results=gradient_results_passed,
-                                          solver=solver,
-                                          settings=settings,
-                                          verbose=verbose)
-
-        return coeffs
-
-    # def extract_domain(self, data, domain):
-    #     """
-    #     Extract data from dataset of specified domain
-    #
-    #     Parameters
-    #     ----------
-    #     data : ndarray of float [n_data x m]
-    #         Dataset
-    #     domain : int
-    #         Domain index to extract
-    #     """
-    #     mask_results = self.domains == domain
-    #
-    #     # determine mask
-    #     if self.gpc[domain].gpc_matrix_gradient is not None:
-    #         mask_gradient = np.zeros((self.grid.coords_norm.shape[0], 1, self.problem.dim)).astype(bool)
-    #         mask_gradient[mask_results, :, :] = True
-    #         mask = np.vstack((mask_results[:, np.newaxis], ten2mat(mask_gradient)))
-    #
-    #     else:
-    #         mask = np.zeros((data.shape[0], 1)).astype(bool)
-    #         mask[mask_results, :] = True
-    #
-    #     return data[mask.flatten(), :]
-
-    def create_validation_set(self, n_samples, n_cpu=1, gradient=False):
-        """
-        Creates a ValidationSet instance (calls the model)
-
-        Parameters
-        ----------
-        n_samples : int
-            Number of sampling points contained in the validation set
-        n_cpu : int
-            Number of parallel function evaluations to evaluate validation set (n_cpu=0 assumes that the
-            model is capable to evaluate all grid points in parallel)
-        gradient : bool, optional, default: False
-            Determine gradient of results in each grid points
-        """
-        # create set of validation points
-        n_samples = n_samples
-
-        grid = Random(parameters_random=self.problem.parameters_random,
-                      n_grid=n_samples,
-                      options={"seed": self.options["seed"]})
-
-        # Evaluate original model at grid points
-        com = Computation(n_cpu=n_cpu, matlab_model=self.matlab_model)
-        results = com.run(model=self.problem.model, problem=self.problem, coords=grid.coords)
-
-        if results.ndim == 1:
-            results = results[:, np.newaxis]
-
-        # Determine gradient of results at grid points
-        if gradient:
-            gradient_results, gradient_idx = get_gradient(model=self.problem.model,
-                                                          problem=self.problem,
-                                                          grid=grid,
-                                                          results=results,
-                                                          com=com,
-                                                          method="FD_fwd",
-                                                          gradient_results_present=None,
-                                                          gradient_idx_skip=None,
-                                                          i_iter=None,
-                                                          i_subiter=None,
-                                                          print_func_time=False,
-                                                          dx=1e-3,
-                                                          distance_weight=None)
-        else:
-            gradient_results = None
-            gradient_idx = None
-
-        self.validation = ValidationSet(grid=grid,
-                                        results=results,
-                                        gradient_results=gradient_results,
-                                        gradient_idx=gradient_idx)
-
-    @staticmethod
-    def get_mean(samples):
-        """
-        Calculate the expected value.
-
-        mean = MEGPC.get_mean(samples)
-
-        Parameters
-        ----------
-        samples : ndarray of float [n_x x n_out], optional, default: None
-            Model evaluations from MEGPC approximation
-
-        Returns
-        -------
-        mean: ndarray of float [1 x n_out]
-            Expected value of output quantities
-        """
-        mean = np.mean(samples, axis=0)
-        mean = mean[np.newaxis, :]
-
-        return mean
-
-    @staticmethod
-    def get_std(samples=None):
-        """
-        Calculate the standard deviation.
-
-        std = MEGPC.get_std(samples)
-
-        Parameters
-        ----------
-        samples : ndarray of float [n_samples x n_out], optional, default: None
-            Model evaluations from MEGPC approximation
-
-        Returns
-        -------
-        std: ndarray of float [1 x n_out]
-            Standard deviation of output quantities
-        """
-        std = np.std(samples, axis=0)
-        std = std[np.newaxis, :]
-
-        return std
-
-    # noinspection PyTypeChecker
-    def get_sobol_indices(self, coeffs, n_samples=1e4):
-        """
-        Calculate the available sobol indices from the gPC coefficients by sampling up to second order.
-
-        sobol, sobol_idx, sobol_idx_bool = MEGPC.get_sobol_indices(coeffs, n_samples=1e4)
-
-        Parameters
-        ----------
-        coeffs:  list of ndarray of float [n_gpc][n_basis x n_out]
-            GPC coefficients
-        n_samples : int, optional, default: 1e4
-            Number of samples to determine Sobol indices by sampling. The efficient number of samples
-            increases to n_samples * (2*dim + 2) in Saltelli's Sobol sampling sequence.
-
-        Returns
-        -------
-        sobol: ndarray of float [n_sobol x n_out]
-            Normalized Sobol indices w.r.t. total variance
-        sobol_idx: list of ndarray of int [n_sobol x (n_sobol_included)]
-            Parameter combinations in rows of sobol.
-        sobol_idx_bool: ndarray of bool [n_sobol x dim]
-            Boolean mask which contains unique multi indices.
-
-        Notes
-        -----
-        .. [1] Sobol, I. M. (2001).  "Global sensitivity indices for nonlinear
-               mathematical models and their Monte Carlo estimates."  Mathematics
-               and Computers in Simulation, 55(1-3):271-280,
-               doi:10.1016/S0378-4754(00)00270-6.
-        .. [2] Saltelli, A. (2002).  "Making best use of model evaluations to
-               compute sensitivity indices."  Computer Physics Communications,
-               145(2):280-297, doi:10.1016/S0010-4655(02)00280-1.
-        .. [3] Saltelli, A., P. Annoni, I. Azzini, F. Campolongo, M. Ratto, and
-               S. Tarantola (2010).  "Variance based sensitivity analysis of model
-               output.  Design and estimator for the total sensitivity index."
-               Computer Physics Communications, 181(2):259-270,
-               doi:10.1016/j.cpc.2009.09.018.
-        """
-
-        # iprint("Determining Sobol indices...", tab=0)
-        dim = self.problem.dim
-
-        problem_original = self.problem
-
-        # generate uniform distributed sobol sequence (parameter space [0, 1])
-        coords_norm_01 = saltelli_sampling(n_samples=n_samples, dim=dim, calc_second_order=True)
-        coords_norm = np.zeros(coords_norm_01.shape)
-
-        # transform to respective input pdfs using inverse cdfs
-        for i_key, key in enumerate(problem_original.parameters_random.keys()):
-            coords_norm[:, i_key] = problem_original.parameters_random[key].icdf(coords_norm_01[:, i_key])
-
-        # run model evaluations
-        res = self.get_approximation(coeffs=coeffs, x=coords_norm)
-
-        # determine sobol indices
-        sobol, sobol_idx, sobol_idx_bool = get_sobol_indices_saltelli(y=res,
-                                                                      dim=dim,
-                                                                      calc_second_order=True,
-                                                                      num_resamples=100,
-                                                                      conf_level=0.95)
-
-        # sort
-        idx = np.flip(np.argsort(sobol[:, 0], axis=0))
-        sobol = sobol[idx, :]
-        sobol_idx = [sobol_idx[i] for i in idx]
-        sobol_idx_bool = sobol_idx_bool[idx, :]
-
-        return sobol, sobol_idx, sobol_idx_bool
-
-    # noinspection PyTypeChecker
-    def get_global_sens(self, coeffs, n_samples=1e5):
-        """
-        Determine the global derivative based sensitivity coefficients after Xiu (2009) [1].
-
-        global_sens = MEGPC.get_global_sens(coeffs, n_samples=1e5)
-
-        Parameters
-        ----------
-        coeffs: list of ndarray of float [n_gpc][n_basis x n_out], optional, default: None
-            GPC coefficients
-        n_samples : int, optional, default: 1e4
-            Number of samples
-
-        Returns
-        -------
-        global_sens: ndarray [dim x n_out]
-            Global derivative based sensitivity coefficients
-
-        Notes
-        -----
-        .. [1] D. Xiu, Fast Numerical Methods for Stochastic Computations: A Review,
-           Commun. Comput. Phys., 5 (2009), pp. 242-272 eq. (3.14) page 255
-        """
-
-        # generate sample coordinates (original parameter space)
-        grid = Random(parameters_random=self.problem.parameters_random,
-                      n_grid=n_samples,
-                      options=None)
-
-        local_sens = self.get_local_sens(coeffs, grid.coords_norm)
-
-        # average the results and reshape [dim x n_out]
-        global_sens = np.mean(local_sens, axis=0).transpose()
-
-        return global_sens
-
-    # noinspection PyTypeChecker
-    def get_local_sens(self, coeffs, x=None):
-        """
-        Determine the local derivative based sensitivity coefficients in the point of interest x
-        (normalized coordinates [-1, 1]).
-
-        local_sens = MEGPC.calc_localsens(coeffs, x)
-
-        Parameters
-        ----------
-        coeffs: list of ndarray of float [n_gpc][n_basis x n_out]
-            GPC coefficients
-        x: ndarray of float [n_points x dim], optional, default: center of parameter space
-            Points in variable space to evaluate local sensitivity in (normalized coordinates [-1, 1])
-            (original parameter space)
-
-        Returns
-        -------
-        local_sens: ndarray [n_points x n_out x dim]
-            Local sensitivity of output quantities in point x
-        """
-
-        if x is None:
-            x = np.zeros(self.problem.dim)[np.newaxis, :]
-
-        # classify coordinates
-        domains = self.classifier.predict(x)
-
-        local_sens = np.zeros((x.shape[0], coeffs[0].shape[1], self.problem.dim))
-
-        for d in np.unique(domains):
-            # project coordinate to reduced parameter space if necessary
-            if self.gpc[d].p_matrix is not None:
-                x_passed = np.matmul(x[domains == d, :], self.gpc[d].p_matrix.transpose() /
-                                     self.gpc[d].p_matrix_norm[np.newaxis, :])
-            else:
-                x_passed = x[domains == d, :]
-
-            # construct gPC gradient matrix [n_samples x n_basis x dim(_red)]
-            gpc_matrix_gradient = self.gpc[d].create_gpc_matrix(b=self.gpc[d].basis.b,
-                                                                x=x_passed,
-                                                                gradient=True,
-                                                                gradient_idx=np.arange(x_passed.shape[0]))
-
-            local_sens_domain = np.matmul(gpc_matrix_gradient.transpose(2, 0, 1), coeffs[d]).transpose(1, 2, 0)
-
-            # project the gradient back to the original space if necessary
-            if self.gpc[d].p_matrix is not None:
-                local_sens_domain = np.matmul(local_sens_domain, self.gpc[d].p_matrix /
-                                              self.gpc[d].p_matrix_norm[:, np.newaxis])
-
-            local_sens[domains == d, :, :] = local_sens_domain
-
-        return local_sens
-
+import numpy as np
+import scipy.stats
+import copy
+import h5py
+import time
+import random
+from sklearn import linear_model
+from .misc import get_cartesian_product
+from .misc import get_gradient_idx_domain
+from .misc import display_fancy_bar
+from .misc import nrmsd
+from .misc import mat2ten
+from .misc import ten2mat
+from .misc import increment_basis
+from .Gradient import get_gradient
+from .ValidationSet import *
+from .Computation import *
+from .Classifier import *
+from .Grid import *
+from .SGPC import *
+
+try:
+    import fastmat as fm
+except ImportError:
+    pass
+
+class MEGPC(object):
+    """
+    General Multi-Element gPC base class
+
+    Parameters
+    ----------
+    problem: Problem class instance
+        GPC Problem under investigation
+    options : dict
+        Options of gPC algorithm
+    validation: ValidationSet object (optional)
+        Object containing a set of validation points and corresponding solutions. Can be used
+        to validate gpc approximation setting options["error_type"]="nrmsd".
+        - grid: Grid object containing the validation points (grid.coords, grid.coords_norm)
+        - results: ndarray [n_grid x n_out] results
+
+    Attributes
+    ----------
+    problem: Problem class instance
+        GPC Problem under investigation
+    grid: Grid class instance
+        Grid of the derived gPC approximation
+    validation: ValidationSet object (optional)
+        Object containing a set of validation points and corresponding solutions. Can be used
+        to validate gpc approximation setting options["error_type"]="nrmsd".
+        - grid: Grid object containing the validation points (grid.coords, grid.coords_norm)
+        - results: ndarray [n_grid x n_out] results
+    n_grid: int or list of int
+        Number of grid points (for iterative solvers, this is a list of its history)
+    solver: str
+        Default solver to determine the gPC coefficients (can be chosen during GPC.solve)
+        - 'Moore-Penrose' ... Pseudoinverse of gPC matrix (SGPC.Reg, EGPC)
+        - 'OMP' ... Orthogonal Matching Pursuit, sparse recovery approach (SGPC.Reg, EGPC)
+        - 'LarsLasso' ... {"alpha": float 0...1} Regularization parameter
+        - 'NumInt' ... Numerical integration, spectral projection (SGPC.Quad)
+    verbose: bool
+        boolean value to determine if to print out the progress into the standard output
+    fn_results : string, optional, default=None
+        If provided, model evaluations are saved in fn_results.hdf5 file and gpc object in fn_results.pkl file
+    options : dict
+        Options of gPC algorithm
+    """
+
+    def __init__(self, problem, options, validation=None):
+        """
+        Constructor; Initializes MEGPC class
+        """
+
+        # objects
+        self.problem = problem
+        # self.sub_problems = None
+        self.grid = None
+        self.validation = validation
+        self.gpc = None
+        self.classifier = None
+        self.domains = None
+
+        # arrays
+        self.n_grid = []
+        self.n_out = []
+        self.n_gpc = None
+        self.relative_error_loocv = []
+        self.relative_error_nrmsd = []
+        self.error = []
+        self.gradient_idx = None
+
+        # options
+        self.gradient = options["gradient_enhanced"]
+        self.solver = None
+        self.settings = None
+        self.verbose = True
+        if "fn_results" not in options.keys():
+            options["fn_results"] = None
+        self.fn_results = options["fn_results"]
+        self.options = options
+        self.matlab_model = options["matlab_model"]
+
+    def init_classifier(self, coords, results, algorithm, options):
+        """
+        Initializes Classifier object in MEGPC class
+
+        Parameters
+        ----------
+        coords : ndarray of float [n_grid, n_dim]
+            Set of n_grid parameter combinations
+        results : ndarray [n_grid x n_out]
+            Results of the model evaluation
+        algorithm : str, optional, default: "learning"
+            Algorithm to classify grid points
+            - "learning" ... 2-step procedure with unsupervised and supervised learning
+            - ...
+        options : dict, optional, default=None
+            Classifier options
+        """
+        self.classifier = Classifier(coords=coords,
+                                     results=results,
+                                     algorithm=algorithm,
+                                     options=options)
+
+        self.domains = self.classifier.domains
+        self.n_gpc = len(np.unique(self.domains))
+
+    def update_classifier(self, coords, results):
+        """
+        Updates self.classifier and keeps the existing class labels
+
+        Parameters
+        ----------
+        coords : ndarray of float [n_grid, n_dim]
+            Set of n_grid parameter combinations
+        results : ndarray [n_grid x n_out]
+            Results of the model evaluation
+        """
+        self.classifier.update(coords=coords, results=results)
+        self.domains = self.classifier.domains
+        self.n_gpc = len(np.unique(self.domains))
+
+    def add_sub_gpc(self, problem, order, order_max, order_max_norm, interaction_order,
+                    interaction_order_current, options, domain, validation=None):
+        """
+        Add sub-gPC
+        """
+        if self.gpc is None:
+            if self.n_gpc is not None:
+                self.gpc = [None for _ in range(self.n_gpc)]
+            else:
+                self.gpc = [0 for _ in range(domain)]
+        elif len(self.gpc) < domain:
+            self.gpc = self.gpc + [None for _ in range(domain - len(self.gpc))]
+
+        # create sub-gpc objects
+        self.gpc[domain] = Reg(problem=problem,
+                               order=order,
+                               order_max=order_max,
+                               order_max_norm=order_max_norm,
+                               interaction_order=interaction_order,
+                               interaction_order_current=interaction_order_current,
+                               options=options,
+                               validation=validation)
+
+    def init_gpc_matrices(self):
+        """
+        Sets self.gpc_matrix with given self.basis and self.grid
+        The gradient_idx of the sub-gPCs are already assigned in assign_grids()
+        """
+
+        for gpc in self.gpc:
+            gpc.init_gpc_matrix()
+
+    def assign_grids(self, gradient_idx=None):
+        """
+        Assign sub-grids to sub-gPCs
+        (including transformation in case of projection and gradient_idx)
+
+        Parameters
+        ----------
+        gradient_idx : ndarray of int [gradient_results.shape[0]]
+            Indices of grid points where the gradient in gradient_results is provided
+        """
+
+        self.gradient_idx = gradient_idx
+
+        # update domain indices if grid points were added
+        if len(self.domains) != self.grid.coords_norm.shape[0]:
+            self.domains = self.classifier.predict(self.grid.coords_norm)
+
+        for d in np.unique(self.domains):
+            coords = self.grid.coords[self.domains == d, :]
+            coords_norm = self.grid.coords_norm[self.domains == d, :]
+            coords_id = np.array(self.grid.coords_id)[self.domains == d].tolist()
+
+            # transform variables of original grid to reduced parameter space
+            if self.gpc[d].p_matrix is not None:
+                coords = np.matmul(coords, self.gpc[d].p_matrix.transpose())
+                coords_norm = np.matmul(coords_norm, self.gpc[d].p_matrix.transpose() /
+                                        self.gpc[d].p_matrix_norm[np.newaxis, :])
+
+            if self.grid.coords_gradient is not None:
+                coords_gradient = self.grid.coords_gradient[self.domains == d, :, :]
+                coords_gradient_norm = self.grid.coords_gradient_norm[self.domains == d, :, :]
+                coords_gradient_id = np.array(self.grid.coords_gradient_id)[self.domains == d].tolist()
+            else:
+                coords_gradient = None
+                coords_gradient_norm = None
+                coords_gradient_id = None
+
+            self.gpc[d].grid = Grid(parameters_random=self.problem.parameters_random,
+                                    coords=coords,
+                                    coords_norm=coords_norm,
+                                    coords_gradient=coords_gradient,
+                                    coords_gradient_norm=coords_gradient_norm,
+                                    coords_id=coords_id,
+                                    coords_gradient_id=coords_gradient_id)
+
+            # assign gradient_idx for sub-gPCs
+            if self.gradient_idx is not None:
+                self.gpc[d].gradient_idx = get_gradient_idx_domain(domains=self.domains,
+                                                                   d=d,
+                                                                   gradient_idx=self.gradient_idx)
+
+    def loocv(self, results, error_norm="relative", domain=None):
+        """
+        Perform leave-one-out cross validation of gPC approximation and add error value to self.relative_error_loocv.
+        The loocv error is calculated analytically after eq. (35) in [1] but omitting the "1 - " term, i.e. it
+        corresponds to 1 - Q^2.
+
+        relative_error_loocv = GPC.loocv(sim_results, coeffs)
+
+        .. math::
+           \\epsilon_{LOOCV} = \\frac{\\frac{1}{N}\sum_{i=1}^N \\left( \\frac{y(\\xi_i) - \hat{y}(\\xi_i)}{1-h_i}
+           \\right)^2}{\\frac{1}{N-1}\sum_{i=1}^N \\left( y(\\xi_i) - \\bar{y} \\right)^2}
+
+        with
+
+        .. math::
+           \\mathbf{h} = \mathrm{diag}(\\mathbf{\\Psi} (\\mathbf{\\Psi}^T \\mathbf{\\Psi})^{-1} \\mathbf{\\Psi}^T)
+
+        Parameters
+        ----------
+        results : ndarray of float [n_grid x n_out]
+            Results from n_grid simulations with n_out output quantities
+        error_norm : str, optional, default="relative"
+            Decide if error is determined "relative" or "absolute"
+        domain : int, optional, default: None
+            Determine error in specified domain only. Default: None (all domains)
+
+        Returns
+        -------
+        relative_error_loocv : float
+            Relative mean error of leave one out cross validation
+
+        Notes
+        -----
+        .. [1] Blatman, G., & Sudret, B. (2010). An adaptive algorithm to build up sparse polynomial chaos expansions
+           for stochastic finite element analysis. Probabilistic Engineering Mechanics, 25(2), 183-197.
+        """
+
+        n_loocv = 25
+
+        if domain is not None:
+            results_domain = copy.deepcopy(results[self.domains == domain, :])
+            domain_idx = copy.deepcopy(domain)
+        else:
+            results_domain = copy.deepcopy(results)
+
+        # define number of performed cross validations (max 25)
+        n_loocv_points = np.min((results_domain.shape[0], n_loocv))
+
+        # make list of indices, which are randomly sampled (this index is w.r.t. to all points if domain is None)
+        loocv_point_idx = random.sample(list(range(results_domain.shape[0])), n_loocv_points)
+
+        start = time.time()
+        relative_error = np.zeros(n_loocv_points)
+
+        for i in range(n_loocv_points):
+
+            if domain is None:
+                # determine domain of loocv point
+                domain_idx = int(self.classifier.predict(self.grid.coords_norm[loocv_point_idx[i]][np.newaxis, :]))
+                results_domain = results[self.domains == domain_idx, ]
+
+            # determine row in sub-gPC matrix of loocv point
+            loocv_point_idx_domain = np.sum(np.array(self.domains == domain_idx)[0:loocv_point_idx[i]])
+
+            # get mask of eliminated row
+            mask = np.arange(results_domain.shape[0]) != loocv_point_idx_domain
+
+            # select right gpc matrix
+            matrix = self.gpc[domain_idx].gpc_matrix
+
+            # determine gpc coefficients (this takes a lot of time for large problems)
+            coeffs_loo = self.gpc[domain_idx].solve(results=results_domain[mask, :],
+                                                    solver=self.options["solver"],
+                                                    matrix=matrix[mask, :],
+                                                    settings=self.options["settings"],
+                                                    verbose=False)
+
+            sim_results_temp = results_domain[loocv_point_idx_domain, :]
+
+            if error_norm == "relative":
+                norm = scipy.linalg.norm(sim_results_temp)
+            else:
+                norm = 1.
+
+            # determine error
+            relative_error[i] = scipy.linalg.norm(sim_results_temp - np.matmul(matrix[loocv_point_idx_domain, :],
+                                                                            coeffs_loo)) \
+                                / norm
+            display_fancy_bar("LOOCV", int(i + 1), int(n_loocv_points))
+
+        # store result in relative_error_loocv
+        relative_error_loocv = np.mean(relative_error)
+        iprint("LOOCV computation time: {} sec".format(time.time() - start), tab=0, verbose=True)
+
+        return relative_error_loocv
+
+    def validate(self, coeffs, results=None, gradient_results=None, domain=None, output_idx=None):
+        """
+        Validate gPC approximation using the ValidationSet object contained in the Problem object.
+        Determines the normalized root mean square deviation between the gpc approximation and the
+        original model. Skips this step if no validation set is present
+
+        Parameters
+        ----------
+        coeffs: list of ndarray of float [n_gpc][n_coeffs x n_out]
+            GPC coefficients
+        results: ndarray of float [n_grid x n_out]
+            Results from n_grid simulations with n_out output quantities
+        gradient_results : ndarray of float [n_grid x n_out x dim], optional, default: None
+            Gradient of results in original parameter space (tensor)
+        domain : int, optional, default: None
+            Determine error in specified domain only. Default: None (all domains)
+        output_idx : int or list of int
+            Index of the QOI the provided coeffs and results are referring to. The correct QOI will be
+            selected from the validation set in case of nrmsd error.
+
+        Returns
+        -------
+        error: float
+            Estimated difference between gPC approximation and original model
+        """
+        if output_idx is None:
+            output_idx = np.arange(results.shape[1])
+        if type(output_idx) is list:
+            output_idx = np.array(output_idx)
+        if type(output_idx) is not np.ndarray:
+            output_idx = np.array([output_idx])
+
+        if domain is None:
+            domain_idx = np.arange(len(coeffs))
+        else:
+            domain_idx = domain
+
+        # Determine QOIs with NaN in results and exclude them from validation
+        non_nan_mask = np.where(np.all(~np.isnan(results), axis=0))[0]
+        n_nan = results.shape[1] - non_nan_mask.size
+
+        if n_nan > 0:
+            iprint("In {}/{} output quantities NaN's were found.".format(n_nan, results.shape[1]),
+                   tab=0, verbose=self.options["verbose"])
+
+        results = results[:, non_nan_mask]
+
+        # always determine nrmsd if a validation set is present
+        if isinstance(self.validation, ValidationSet):
+
+            if domain is None:
+                mask_domain = np.ones(self.validation.grid.coords_norm.shape[0]).astype(bool)
+                gpc_results = self.get_approximation(coeffs, self.validation.grid.coords_norm, output_idx=None)
+            else:
+                mask_domain = self.classifier.predict(self.validation.grid.coords_norm) == domain
+                coords_domain = self.validation.grid.coords_norm[mask_domain, ]
+                gpc_results = self.gpc[domain].get_approximation(coeffs[domain],
+                                                                 coords_domain,
+                                                                 output_idx=None)
+
+            if gpc_results.ndim == 1:
+                gpc_results = gpc_results[:, np.newaxis]
+
+            validation_results_passed = self.validation.results[np.argwhere(mask_domain), output_idx]
+
+            if validation_results_passed.ndim == 1:
+                validation_results_passed = validation_results_passed[:, np.newaxis]
+
+            error_nrmsd = float(np.mean(nrmsd(gpc_results,
+                                              validation_results_passed,
+                                              error_norm=self.options["error_norm"],
+                                              x_axis=False)))
+
+            if domain is None:
+                self.relative_error_nrmsd.append(error_nrmsd)
+
+        if self.options["error_type"] == "nrmsd":
+            if domain is None:
+                self.error.append(self.relative_error_nrmsd[-1])
+
+        elif self.options["error_type"] == "loocv":
+            error_loocv = self.loocv(results=results,
+                                     error_norm=self.options["error_norm"],
+                                     domain=domain)
+
+            if domain is None:
+                self.relative_error_loocv.append(error_loocv)
+                self.error.append(self.relative_error_loocv[-1])
+
+        if domain is None:
+            return self.error[-1]
+        else:
+            if self.options["error_type"] == "nrmsd":
+                return error_nrmsd
+            elif self.options["error_type"] == "loocv":
+                return error_loocv
+
+    def get_pdf(self, coeffs, n_samples, output_idx=None):
+        """ Determine the estimated pdfs of the output quantities
+
+        pdf_x, pdf_y = MEGPC.get_pdf(coeffs, n_samples, output_idx=None)
+
+        Parameters
+        ----------
+        coeffs: list of ndarray of float [n_gpc][n_coeffs x n_out]
+            GPC coefficients
+        n_samples: int
+            Number of samples used to estimate output pdfs
+        output_idx: ndarray, optional, default=None [1 x n_out]
+            Index of output quantities to consider (if output_idx=None, all output quantities are considered)
+
+        Returns
+        -------
+        pdf_x: ndarray of float [100 x n_out]
+            x-coordinates of output pdfs of output quantities
+        pdf_y: ndarray of float [100 x n_out]
+            y-coordinates of output pdfs (probability density of output quantity)
+        """
+
+        # handle (N,) arrays
+        if len(coeffs[0].shape) == 1:
+            n_out = 1
+        else:
+            n_out = coeffs[0].shape[1]
+
+        # if output index array is not provided, determine pdfs of all outputs
+        if output_idx is None:
+            output_idx = np.linspace(0, n_out - 1, n_out)
+            output_idx = output_idx[np.newaxis, :]
+
+        # sample gPC expansion
+        samples_in, samples_out = self.get_samples(n_samples=n_samples, coeffs=coeffs, output_idx=output_idx)
+
+        # determine kernel density estimates using Gaussian kernel
+        pdf_x = np.zeros([100, n_out])
+        pdf_y = np.zeros([100, n_out])
+
+        for i_out in range(n_out):
+            pdf_y[:, i_out], tmp = np.histogram(samples_out, bins=100, density=True)
+            pdf_x[:, i_out] = (tmp[1:] + tmp[0:-1])/2.
+
+            # kde = scipy.stats.gaussian_kde(samples_out[:, i_out], bw_method=0.1 / samples_out[:, i_out].std(ddof=1))
+            # pdf_y[:, i_out] = kde(pdf_x[:, i_out])
+            # pdf_x[:, i_out] = np.linspace(samples_out[:, i_out].min(), samples_out[:, i_out].max(), 100)
+
+        return pdf_x, pdf_y
+
+    def get_samples(self, coeffs, n_samples, output_idx=None):
+        """
+        Randomly sample gPC expansion.
+
+        x, pce = SGPC.get_pdf_mc(n_samples, coeffs, output_idx=None)
+
+        Parameters
+        ----------
+        coeffs: list of ndarray of float [n_gpc][n_basis x n_out]
+            GPC coefficients for each sub-domain
+        n_samples: int
+            Number of random samples drawn from the respective input pdfs.
+        output_idx: ndarray of int [1 x n_out] optional, default=None
+            Index of output quantities to consider.
+
+        Returns
+        -------
+        x: ndarray of float [n_samples x dim]
+            Generated samples in normalized coordinates [-1, 1]. (original parameter space)
+        pce: ndarray of float [n_samples x n_out]
+            GPC approximation at points x.
+        """
+
+        # seed the random numbers generator
+        np.random.seed()
+
+        # generate temporary grid with random samples for each random input variable [n_samples x dim]
+        grid = Random(parameters_random=self.problem.parameters_random,
+                      n_grid=n_samples,
+                      options=None)
+
+        # if output index list is not provided, sample all gpc outputs
+        if output_idx is None:
+            n_out = 1 if coeffs[0].ndim == 1 else coeffs[0].shape[1]
+            output_idx = np.arange(n_out)
+
+        pce = self.get_approximation(coeffs=coeffs, x=grid.coords_norm, output_idx=output_idx)
+
+        return grid.coords_norm, pce
+
+    def get_approximation(self, coeffs, x, output_idx=None):
+        """
+        Calculates the gPC approximation in points with output_idx and normalized parameters xi (interval: [-1, 1]).
+
+        pce = MEGPC.get_approximation(coeffs, x, output_idx=None)
+
+        Parameters
+        ----------
+        coeffs: list of ndarray of float [n_gpc][n_basis x n_out]
+            GPC coefficients for each output variable of each sub-domain
+        x: ndarray of float [n_x x n_dim]
+            Normalized coordinates, where the gPC approximation is calculated (original parameter space)
+        output_idx: ndarray of int, optional, default=None [n_out]
+            Indices of output quantities to consider (Default: all).
+
+        Returns
+        -------
+        pce: ndarray of float [n_x x n_out]
+            GPC approximation at normalized coordinates x.
+        """
+        if type(output_idx) is list:
+            output_idx = np.array(output_idx)
+        elif type(output_idx) != np.ndarray and output_idx is not None:
+            output_idx = np.array([output_idx])
+        else:
+            if type(coeffs) is list:
+                output_idx = np.arange(coeffs[0].shape[1])
+            else:
+                output_idx = np.arange(coeffs.shape[1])
+
+        pce = np.zeros((x.shape[0], len(output_idx)))
+
+        # get classes of grid-points
+        domains = self.classifier.predict(x)
+
+        # determine gPC approximation for sub-domains
+        for d in np.unique(domains):
+            pce[domains == d, :] = self.gpc[d].get_approximation(coeffs=coeffs[d],
+                                                                 x=x[(domains == d).flatten(), :],
+                                                                 output_idx=output_idx)
+
+        return pce
+
+    def update_gpc_matrices(self, gradient=False):
+        """
+        Update gPC matrix according to existing self.grid and self.basis.
+
+        Call this method when self.gpc_matrix does not fit to self.grid and self.basis objects anymore
+        The old gPC matrix with their self.gpc_matrix_b_id and self.gpc_matrix_coords_id is compared
+        to self.basis.b_id and self.grid.coords_id. New rows and columns are computed when differences are found.
+        """
+        for i, gpc in enumerate(self.gpc):
+            gpc.update_gpc_matrix(gradient=gradient)
+
+    def save_gpc_matrices_hdf5(self):
+        """
+        Save gPC matrix and gPC gradient matrix in .hdf5 file <"fn_results" + ".hdf5"> under the key "gpc_matrix/dom_x"
+        and "gpc_matrix_gradient/dom_x". If matrices are already present, check for equality and save only appended
+        rows and columns.
+        """
+        for i, gpc in enumerate(self.gpc):
+            gpc.save_gpc_matrix_hdf5(hdf5_path_gpc_matrix="gpc_matrix/dom_" + str(i),
+                                     hdf5_path_gpc_matrix_gradient="gpc_matrix_gradient/dom_" + str(i))
+
+    def solve(self, results, gradient_results=None, solver=None, settings=None, verbose=False):
+        """
+        Determines gPC coefficients of sub-gPCs
+
+        Parameters
+        ----------
+        results : ndarray of float [n_grid x n_out]
+            Results from simulations with n_out output quantities
+        gradient_results : ndarray of float [n_gradient x n_out x dim], optional, default: None
+            Gradient of results in original parameter space in specific grid points
+        solver : str
+            Solver to determine the gPC coefficients
+            - 'Moore-Penrose' ... Pseudoinverse of gPC matrix (SGPC.Reg, EGPC)
+            - 'OMP' ... Orthogonal Matching Pursuit, sparse recovery approach (SGPC.Reg, EGPC)
+            - 'LarsLasso' ... Least-Angle Regression using Lasso model (SGPC.Reg, EGPC)
+            - 'NumInt' ... Numerical integration, spectral projection (SGPC.Quad)
+        settings : dict
+            Solver settings
+            - 'Moore-Penrose' ... None
+            - 'OMP' ... {"n_coeffs_sparse": int} Number of gPC coefficients != 0 or "sparsity": float 0...1
+            - 'LarsLasso' ... {"alpha": float 0...1} Regularization parameter
+            - 'NumInt' ... None
+        verbose : bool
+            boolean value to determine if to print out the progress into the standard output
+
+        Returns
+        -------
+        coeffs: list of ndarray of float [n_gpc][n_coeffs x n_out]
+            gPC coefficients
+        """
+
+        # use default solver if not specified
+        if solver is None:
+            solver = self.solver
+
+        # use default solver settings if not specified
+        if solver is None:
+            settings = self.settings
+
+        coeffs = [0 for _ in range(self.n_gpc)]
+
+        # determine coeffs of sub-gPCs
+        for d in np.unique(self.domains):
+            if gradient_results is not None:
+                gradient_results_passed = gradient_results[self.domains[self.gradient_idx] == d, :, :]
+            else:
+                gradient_results_passed = None
+
+            coeffs[d] = self.gpc[d].solve(results=results[self.domains == d, :],
+                                          gradient_results=gradient_results_passed,
+                                          solver=solver,
+                                          settings=settings,
+                                          verbose=verbose)
+
+        return coeffs
+
+    # def extract_domain(self, data, domain):
+    #     """
+    #     Extract data from dataset of specified domain
+    #
+    #     Parameters
+    #     ----------
+    #     data : ndarray of float [n_data x m]
+    #         Dataset
+    #     domain : int
+    #         Domain index to extract
+    #     """
+    #     mask_results = self.domains == domain
+    #
+    #     # determine mask
+    #     if self.gpc[domain].gpc_matrix_gradient is not None:
+    #         mask_gradient = np.zeros((self.grid.coords_norm.shape[0], 1, self.problem.dim)).astype(bool)
+    #         mask_gradient[mask_results, :, :] = True
+    #         mask = np.vstack((mask_results[:, np.newaxis], ten2mat(mask_gradient)))
+    #
+    #     else:
+    #         mask = np.zeros((data.shape[0], 1)).astype(bool)
+    #         mask[mask_results, :] = True
+    #
+    #     return data[mask.flatten(), :]
+
+    def create_validation_set(self, n_samples, n_cpu=1, gradient=False):
+        """
+        Creates a ValidationSet instance (calls the model)
+
+        Parameters
+        ----------
+        n_samples : int
+            Number of sampling points contained in the validation set
+        n_cpu : int
+            Number of parallel function evaluations to evaluate validation set (n_cpu=0 assumes that the
+            model is capable to evaluate all grid points in parallel)
+        gradient : bool, optional, default: False
+            Determine gradient of results in each grid points
+        """
+        # create set of validation points
+        n_samples = n_samples
+
+        grid = Random(parameters_random=self.problem.parameters_random,
+                      n_grid=n_samples,
+                      options={"seed": self.options["seed"]})
+
+        # Evaluate original model at grid points
+        com = Computation(n_cpu=n_cpu, matlab_model=self.matlab_model)
+        results = com.run(model=self.problem.model, problem=self.problem, coords=grid.coords)
+
+        if results.ndim == 1:
+            results = results[:, np.newaxis]
+
+        # Determine gradient of results at grid points
+        if gradient:
+            gradient_results, gradient_idx = get_gradient(model=self.problem.model,
+                                                          problem=self.problem,
+                                                          grid=grid,
+                                                          results=results,
+                                                          com=com,
+                                                          method="FD_fwd",
+                                                          gradient_results_present=None,
+                                                          gradient_idx_skip=None,
+                                                          i_iter=None,
+                                                          i_subiter=None,
+                                                          print_func_time=False,
+                                                          dx=1e-3,
+                                                          distance_weight=None)
+        else:
+            gradient_results = None
+            gradient_idx = None
+
+        self.validation = ValidationSet(grid=grid,
+                                        results=results,
+                                        gradient_results=gradient_results,
+                                        gradient_idx=gradient_idx)
+
+    @staticmethod
+    def get_mean(samples):
+        """
+        Calculate the expected value.
+
+        mean = MEGPC.get_mean(samples)
+
+        Parameters
+        ----------
+        samples : ndarray of float [n_x x n_out], optional, default: None
+            Model evaluations from MEGPC approximation
+
+        Returns
+        -------
+        mean: ndarray of float [1 x n_out]
+            Expected value of output quantities
+        """
+        mean = np.mean(samples, axis=0)
+        mean = mean[np.newaxis, :]
+
+        return mean
+
+    @staticmethod
+    def get_std(samples=None):
+        """
+        Calculate the standard deviation.
+
+        std = MEGPC.get_std(samples)
+
+        Parameters
+        ----------
+        samples : ndarray of float [n_samples x n_out], optional, default: None
+            Model evaluations from MEGPC approximation
+
+        Returns
+        -------
+        std: ndarray of float [1 x n_out]
+            Standard deviation of output quantities
+        """
+        std = np.std(samples, axis=0)
+        std = std[np.newaxis, :]
+
+        return std
+
+    # noinspection PyTypeChecker
+    def get_sobol_indices(self, coeffs, n_samples=1e4):
+        """
+        Calculate the available sobol indices from the gPC coefficients by sampling up to second order.
+
+        sobol, sobol_idx, sobol_idx_bool = MEGPC.get_sobol_indices(coeffs, n_samples=1e4)
+
+        Parameters
+        ----------
+        coeffs:  list of ndarray of float [n_gpc][n_basis x n_out]
+            GPC coefficients
+        n_samples : int, optional, default: 1e4
+            Number of samples to determine Sobol indices by sampling. The efficient number of samples
+            increases to n_samples * (2*dim + 2) in Saltelli's Sobol sampling sequence.
+
+        Returns
+        -------
+        sobol: ndarray of float [n_sobol x n_out]
+            Normalized Sobol indices w.r.t. total variance
+        sobol_idx: list of ndarray of int [n_sobol x (n_sobol_included)]
+            Parameter combinations in rows of sobol.
+        sobol_idx_bool: ndarray of bool [n_sobol x dim]
+            Boolean mask which contains unique multi indices.
+
+        Notes
+        -----
+        .. [1] Sobol, I. M. (2001).  "Global sensitivity indices for nonlinear
+               mathematical models and their Monte Carlo estimates."  Mathematics
+               and Computers in Simulation, 55(1-3):271-280,
+               doi:10.1016/S0378-4754(00)00270-6.
+        .. [2] Saltelli, A. (2002).  "Making best use of model evaluations to
+               compute sensitivity indices."  Computer Physics Communications,
+               145(2):280-297, doi:10.1016/S0010-4655(02)00280-1.
+        .. [3] Saltelli, A., P. Annoni, I. Azzini, F. Campolongo, M. Ratto, and
+               S. Tarantola (2010).  "Variance based sensitivity analysis of model
+               output.  Design and estimator for the total sensitivity index."
+               Computer Physics Communications, 181(2):259-270,
+               doi:10.1016/j.cpc.2009.09.018.
+        """
+
+        # iprint("Determining Sobol indices...", tab=0)
+        dim = self.problem.dim
+
+        problem_original = self.problem
+
+        # generate uniform distributed sobol sequence (parameter space [0, 1])
+        coords_norm_01 = saltelli_sampling(n_samples=n_samples, dim=dim, calc_second_order=True)
+        coords_norm = np.zeros(coords_norm_01.shape)
+
+        # transform to respective input pdfs using inverse cdfs
+        for i_key, key in enumerate(problem_original.parameters_random.keys()):
+            coords_norm[:, i_key] = problem_original.parameters_random[key].icdf(coords_norm_01[:, i_key])
+
+        # run model evaluations
+        res = self.get_approximation(coeffs=coeffs, x=coords_norm)
+
+        # determine sobol indices
+        sobol, sobol_idx, sobol_idx_bool = get_sobol_indices_saltelli(y=res,
+                                                                      dim=dim,
+                                                                      calc_second_order=True,
+                                                                      num_resamples=100,
+                                                                      conf_level=0.95)
+
+        # sort
+        idx = np.flip(np.argsort(sobol[:, 0], axis=0))
+        sobol = sobol[idx, :]
+        sobol_idx = [sobol_idx[i] for i in idx]
+        sobol_idx_bool = sobol_idx_bool[idx, :]
+
+        return sobol, sobol_idx, sobol_idx_bool
+
+    # noinspection PyTypeChecker
+    def get_global_sens(self, coeffs, n_samples=1e5):
+        """
+        Determine the global derivative based sensitivity coefficients after Xiu (2009) [1].
+
+        global_sens = MEGPC.get_global_sens(coeffs, n_samples=1e5)
+
+        Parameters
+        ----------
+        coeffs: list of ndarray of float [n_gpc][n_basis x n_out], optional, default: None
+            GPC coefficients
+        n_samples : int, optional, default: 1e4
+            Number of samples
+
+        Returns
+        -------
+        global_sens: ndarray [dim x n_out]
+            Global derivative based sensitivity coefficients
+
+        Notes
+        -----
+        .. [1] D. Xiu, Fast Numerical Methods for Stochastic Computations: A Review,
+           Commun. Comput. Phys., 5 (2009), pp. 242-272 eq. (3.14) page 255
+        """
+
+        # generate sample coordinates (original parameter space)
+        grid = Random(parameters_random=self.problem.parameters_random,
+                      n_grid=n_samples,
+                      options=None)
+
+        local_sens = self.get_local_sens(coeffs, grid.coords_norm)
+
+        # average the results and reshape [dim x n_out]
+        global_sens = np.mean(local_sens, axis=0).transpose()
+
+        return global_sens
+
+    # noinspection PyTypeChecker
+    def get_local_sens(self, coeffs, x=None):
+        """
+        Determine the local derivative based sensitivity coefficients in the point of interest x
+        (normalized coordinates [-1, 1]).
+
+        local_sens = MEGPC.calc_localsens(coeffs, x)
+
+        Parameters
+        ----------
+        coeffs: list of ndarray of float [n_gpc][n_basis x n_out]
+            GPC coefficients
+        x: ndarray of float [n_points x dim], optional, default: center of parameter space
+            Points in variable space to evaluate local sensitivity in (normalized coordinates [-1, 1])
+            (original parameter space)
+
+        Returns
+        -------
+        local_sens: ndarray [n_points x n_out x dim]
+            Local sensitivity of output quantities in point x
+        """
+
+        if x is None:
+            x = np.zeros(self.problem.dim)[np.newaxis, :]
+
+        # classify coordinates
+        domains = self.classifier.predict(x)
+
+        local_sens = np.zeros((x.shape[0], coeffs[0].shape[1], self.problem.dim))
+
+        for d in np.unique(domains):
+            # project coordinate to reduced parameter space if necessary
+            if self.gpc[d].p_matrix is not None:
+                x_passed = np.matmul(x[domains == d, :], self.gpc[d].p_matrix.transpose() /
+                                     self.gpc[d].p_matrix_norm[np.newaxis, :])
+            else:
+                x_passed = x[domains == d, :]
+
+            # construct gPC gradient matrix [n_samples x n_basis x dim(_red)]
+            gpc_matrix_gradient = self.gpc[d].create_gpc_matrix(b=self.gpc[d].basis.b,
+                                                                x=x_passed,
+                                                                gradient=True,
+                                                                gradient_idx=np.arange(x_passed.shape[0]))
+
+            local_sens_domain = np.matmul(gpc_matrix_gradient.transpose(2, 0, 1), coeffs[d]).transpose(1, 2, 0)
+
+            # project the gradient back to the original space if necessary
+            if self.gpc[d].p_matrix is not None:
+                local_sens_domain = np.matmul(local_sens_domain, self.gpc[d].p_matrix /
+                                              self.gpc[d].p_matrix_norm[:, np.newaxis])
+
+            local_sens[domains == d, :, :] = local_sens_domain
+
+        return local_sens
+
```

## pygpc/Problem.py

 * *Ordering differences only*

```diff
@@ -1,109 +1,109 @@
-from collections import OrderedDict
-from .RandomParameter import *
-from .ValidationSet import *
-from .Grid import *
-from .Computation import *
-
-
-class Problem:
-    """
-    Data wrapper for the gpc problem containing the model to investigate and the associated parameters.
-
-    Parameters
-    ----------
-    model: Model object
-        Model object instance of model to investigate (derived from AbstractModel class, implemented by user)
-    parameters: OrderedDict
-        Dictionary containing the model parameters as keys:
-        - constants: values (floats, lists, ndarray)
-        - random parameters: RandomParameter instances
-
-    Notes
-    -----
-    Add Attributes:
-
-    random_vars: [dim] list of str
-        String labels of the random variables
-    N_out: int
-        Number of output coefficients
-    dim: int
-        Number of uncertain parameters to process
-    pdf_type: [dim] list of str
-        Type of pdf 'beta' or 'norm'
-    pdf_shape: list of list of float
-        Shape parameters of pdfs
-        beta-dist:   [[], ... [alpha, beta], ..., []]
-        normal-dist: [[], ... [mean, std], ..., []]
-    pdf_limits: list of list of float
-        upper and lower bounds of random variables
-        beta-dist:   [[], ... [min, max], ..., []]
-        normal-dist: [[], ... [0, 0], ..., []] (not used)
-
-    Examples
-    --------
-    Setup model and specify parameters of gPC problem
-
-    >>> import pygpc
-    >>> from collections import OrderedDict
-    >>>
-    >>> # Define model
-    >>> model = pygpc.testfunctions.SphereModel
-    >>>
-    >>> # Define Problem
-    >>> parameters = OrderedDict()  # we must use an ordered dict form the start, otherwise the order will be mixed
-    >>> parameters["R"] = [80, 90, 100]                                                 # constant parameter
-    >>> parameters["phi_electrode"] = 15                                                #       "
-    >>> parameters["N_points"] = 201                                                    #       "
-    >>> parameters["sigma_1"] = pygpc.RandomParameter.Beta(pdf_shape=[5, 5], pdf_limits=[0.15, 0.45])  # random variable
-    >>> parameters["sigma_2"] = pygpc.RandomParameter.Beta(pdf_shape=[1, 3], pdf_limits=[0.01, 0.02])  #       "
-    >>> parameters["sigma_3"] = pygpc.RandomParameter.Norm(pdf_shape=[2, 2])                           #       "
-    >>> problem = pygpc.Problem(model, parameters)
-    """
-    def __init__(self, model, parameters):
-        """
-        Constructor; Initializes Problem instance
-        """
-        assert(isinstance(parameters, OrderedDict))
-
-        self.model = model                              # Model class instance
-        self.parameters = parameters                    # OrderedDict of parameters (constants and random)
-        self.parameters_random = OrderedDict()          # OrderedDict of parameters (random)
-        self.parameters_keys = []                       # Keys of parameters (saved for sorting)
-
-        # extract random parameters
-        for p in self.parameters:
-            self.parameters_keys.append(p)
-
-            if isinstance(self.parameters[p], RandomParameter):
-                self.parameters_random[p] = self.parameters[p]
-
-        self.dim = len(self.parameters_random)
-
-        # test problem definition
-        self.validate()
-
-    def validate(self):
-        """
-        Verifies the problem, by testing if the parameters including the random variables are defined appropriate.
-        In cases, the model may not run correctly for some parameter combinations, the user may change the definition
-        of the random parameters or the constants in model.validate.
-
-        calls model.validate
-
-        overwrites parameters
-        """
-
-        # initialize temporal model object
-        m = self.model.set_parameters(p=self.parameters, context=None)
-
-        # call model/problem validation
-        parameters_corrected = m.validate()
-
-        # update parameters and parameters_random in self
-        if parameters_corrected is not None:
-            self.parameters = parameters_corrected
-            self.parameters_random = OrderedDict()
-
-            for p in self.parameters:
-                if isinstance(self.parameters[p], RandomParameter):
-                    self.parameters_random[p] = self.parameters[p]
+from collections import OrderedDict
+from .RandomParameter import *
+from .ValidationSet import *
+from .Grid import *
+from .Computation import *
+
+
+class Problem:
+    """
+    Data wrapper for the gpc problem containing the model to investigate and the associated parameters.
+
+    Parameters
+    ----------
+    model: Model object
+        Model object instance of model to investigate (derived from AbstractModel class, implemented by user)
+    parameters: OrderedDict
+        Dictionary containing the model parameters as keys:
+        - constants: values (floats, lists, ndarray)
+        - random parameters: RandomParameter instances
+
+    Notes
+    -----
+    Add Attributes:
+
+    random_vars: [dim] list of str
+        String labels of the random variables
+    N_out: int
+        Number of output coefficients
+    dim: int
+        Number of uncertain parameters to process
+    pdf_type: [dim] list of str
+        Type of pdf 'beta' or 'norm'
+    pdf_shape: list of list of float
+        Shape parameters of pdfs
+        beta-dist:   [[], ... [alpha, beta], ..., []]
+        normal-dist: [[], ... [mean, std], ..., []]
+    pdf_limits: list of list of float
+        upper and lower bounds of random variables
+        beta-dist:   [[], ... [min, max], ..., []]
+        normal-dist: [[], ... [0, 0], ..., []] (not used)
+
+    Examples
+    --------
+    Setup model and specify parameters of gPC problem
+
+    >>> import pygpc
+    >>> from collections import OrderedDict
+    >>>
+    >>> # Define model
+    >>> model = pygpc.testfunctions.SphereModel
+    >>>
+    >>> # Define Problem
+    >>> parameters = OrderedDict()  # we must use an ordered dict form the start, otherwise the order will be mixed
+    >>> parameters["R"] = [80, 90, 100]                                                 # constant parameter
+    >>> parameters["phi_electrode"] = 15                                                #       "
+    >>> parameters["N_points"] = 201                                                    #       "
+    >>> parameters["sigma_1"] = pygpc.RandomParameter.Beta(pdf_shape=[5, 5], pdf_limits=[0.15, 0.45])  # random variable
+    >>> parameters["sigma_2"] = pygpc.RandomParameter.Beta(pdf_shape=[1, 3], pdf_limits=[0.01, 0.02])  #       "
+    >>> parameters["sigma_3"] = pygpc.RandomParameter.Norm(pdf_shape=[2, 2])                           #       "
+    >>> problem = pygpc.Problem(model, parameters)
+    """
+    def __init__(self, model, parameters):
+        """
+        Constructor; Initializes Problem instance
+        """
+        assert(isinstance(parameters, OrderedDict))
+
+        self.model = model                              # Model class instance
+        self.parameters = parameters                    # OrderedDict of parameters (constants and random)
+        self.parameters_random = OrderedDict()          # OrderedDict of parameters (random)
+        self.parameters_keys = []                       # Keys of parameters (saved for sorting)
+
+        # extract random parameters
+        for p in self.parameters:
+            self.parameters_keys.append(p)
+
+            if isinstance(self.parameters[p], RandomParameter):
+                self.parameters_random[p] = self.parameters[p]
+
+        self.dim = len(self.parameters_random)
+
+        # test problem definition
+        self.validate()
+
+    def validate(self):
+        """
+        Verifies the problem, by testing if the parameters including the random variables are defined appropriate.
+        In cases, the model may not run correctly for some parameter combinations, the user may change the definition
+        of the random parameters or the constants in model.validate.
+
+        calls model.validate
+
+        overwrites parameters
+        """
+
+        # initialize temporal model object
+        m = self.model.set_parameters(p=self.parameters, context=None)
+
+        # call model/problem validation
+        parameters_corrected = m.validate()
+
+        # update parameters and parameters_random in self
+        if parameters_corrected is not None:
+            self.parameters = parameters_corrected
+            self.parameters_random = OrderedDict()
+
+            for p in self.parameters:
+                if isinstance(self.parameters[p], RandomParameter):
+                    self.parameters_random[p] = self.parameters[p]
```

## pygpc/Quadrature.py

 * *Ordering differences only*

```diff
@@ -1,437 +1,437 @@
-import numpy as np
-from scipy.fftpack import ifft
-from scipy.special import roots_genlaguerre
-
-
-def get_quadrature_jacobi_1d(n, p, q):
-    """
-    Get knots and weights of Jacobi polynomials.
-
-    knots, weights = Grid.get_quadrature_jacobi_1d(n, p, q)
-
-    Parameters
-    ----------
-    n: int
-        Number of knots
-    p: float
-        First shape parameter
-    q: float
-        Second shape parameter
-
-    Returns
-    -------
-    knots: np.ndarray
-        Knots of the grid
-    weights: np.ndarray
-        Weights of the grid
-    """
-
-    # make array to count N: 0, 1, ..., N-1
-    n_arr = np.arange(1, n)
-
-    # compose diagonals for companion matrix
-    t01 = 1.0 * (p - q) / (2 + q + p)
-    t02 = 1.0 * ((p - q) * (q + p)) / ((2 * n_arr + q + p) * (2 * n_arr + 2 + q + p))
-    t1 = np.append(t01, t02)
-    t2 = np.sqrt((4.0 * n_arr * (n_arr + q) * (n_arr + p) * (n_arr + q + p)) / (
-            (2 * n_arr - 1 + q + p) * (2 * n_arr + q + p) ** 2 * (2 * n_arr + 1 + q + p)))
-
-    # compose companion matrix
-    t = np.diag(t1) + np.diag(t2, 1) + np.diag(t2, -1)
-
-    # evaluate roots of polynomials (the abscissas are the roots of the
-    # characteristic polynomial, i.d. the eigenvalues of the companion matrix)
-    # the weights can be derived from the corresponding eigenvectors.
-    eigvals, eigvecs = np.linalg.eig(t)
-    idx_sorted = np.argsort(eigvals)
-    eigvals_sorted = eigvals[idx_sorted]
-
-    weights = 2.0 * eigvecs[0, idx_sorted] ** 2
-    knots = eigvals_sorted
-
-    return knots, weights
-
-
-def get_quadrature_hermite_1d(n):
-    """
-    Get knots and weights of Hermite polynomials (normal distribution).
-
-    knots, weights = Grid.get_quadrature_hermite_1d(n)
-
-    Parameters
-    ----------
-    n: int
-        number of knots
-
-    Returns
-    -------
-    knots: np.ndarray
-        knots of the grid
-    weights: np.ndarray
-        weights of the grid
-    """
-    n = int(n)
-    knots, weights = np.polynomial.hermite_e.hermegauss(n)
-    weights = np.array(list(2.0 * weights / np.sum(weights)))
-
-    return knots, weights
-
-
-def get_quadrature_laguerre_1d(n, alpha):
-    """
-    Get knots and weights of Laguerre polynomials (gamma distribution).
-
-    knots, weights = Grid.get_quadrature_laguerre_1d(n)
-
-    Parameters
-    ----------
-    n: int
-        number of knots
-    alpha: float
-        Parameter of Laguerre polynomial
-
-    Returns
-    -------
-    knots: np.ndarray
-        knots of the grid
-    weights: np.ndarray
-        weights of the grid
-    """
-    n = int(n)
-    knots, weights = roots_genlaguerre(n=n, alpha=alpha)
-
-    return knots, weights
-
-
-# TODO: review this
-def get_quadrature_clenshaw_curtis_1d(n):
-    """
-    Get the Clenshaw Curtis nodes and weights.
-
-    knots, weights = Grid.get_quadrature_clenshaw_curtis_1d(n)
-
-    Parameters
-    ----------
-    n: int
-        Number of knots
-
-    Returns
-    -------
-    knots: np.ndarray
-        Knots of the grid
-    weights: np.ndarray
-        Weights of the grid
-    """
-    n = int(n)
-
-    if n == 1:
-        knots = 0
-        weights = 2
-    else:
-        n = n - 1
-        c = np.zeros((n, 2))
-        k = 2 * (1 + np.arange(np.floor(n / 2)))
-        c[::2, 0] = 2 / np.hstack((1, 1 - k * k))
-        c[1, 1] = -n
-        v = np.vstack((c, np.flipud(c[1:n, :])))
-        f = np.real(ifft(v, n=None, axis=0))
-        knots = f[0:n, 1]
-        weights = np.hstack((f[0, 0], 2 * f[1:n, 0], f[n, 0]))
-
-    return knots, weights
-
-
-def get_quadrature_fejer1_1d(n):
-    """
-    Computes the Fejer type 1 nodes and weights.
-
-    This method uses a direct approach after Davis and Rabinowitz (2007) [1] and Gautschi (1967) [2].
-    The paper by Waldvogel (2006) [3] exhibits a more efficient approach using Fourier transforms.
-
-    knots, weights = Grid.get_quadrature_fejer1_1d(n)
-
-    Parameters
-    ----------
-    n: int
-        Number of knots
-
-    Returns
-    -------
-    knots: ndarray
-        Knots of the grid
-    weights: ndarray
-        Weights of the grid
-
-    Notes
-    -----
-    .. [1] Davis, P. J., Rabinowitz, P. (2007). Methods of numerical integration.
-       Courier Corporation, second edition, ISBN: 0486453391.
-
-    .. [2] Gautschi, W. (1967). Numerical quadrature in the presence of a singularity.
-       SIAM Journal on Numerical Analysis, 4(3), 357-362.
-
-    .. [3] Waldvogel, J. (2006). Fast construction of the Fejer and Clenshaw-Curtis quadrature rules.
-       BIT Numerical Mathematics, 46(1), 195-202.
-    """
-    n = int(n)
-
-    theta = np.zeros(n)
-
-    for i in range(0, n):
-        theta[i] = float(2 * n - 1 - 2 * i) * np.pi / float(2 * n)
-
-    knots = np.zeros(n)
-
-    for i in range(0, n):
-        knots[i] = np.cos(theta[i])
-
-    weights = np.zeros(n)
-
-    for i in range(0, n):
-        weights[i] = 1.0
-        jhi = (n // 2)
-        for j in range(0, jhi):
-            angle = 2.0 * float(j + 1) * theta[i]
-            weights[i] = weights[i] - 2.0 * np.cos(angle) / float(4 * (j + 1) ** 2 - 1)
-
-    for i in range(0, n):
-        weights[i] = 2.0 * weights[i] / float(n)
-
-    return knots, weights
-
-
-def get_quadrature_fejer2_1d(n):
-    """
-    Computes the Fejer type 2 nodes and weights (Clenshaw Curtis without boundary nodes).
-
-    This method uses a direct approach after Davis and Rabinowitz (2007) [1] and Gautschi (1967) [2].
-    The paper by Waldvogel (2006) [3] exhibits a more efficient approach using Fourier transforms.
-
-    knots, weights = Grid.get_quadrature_fejer2_1d(n)
-
-    Parameters
-    ----------
-    n: int
-        Number of knots
-
-    Returns
-    -------
-    knots: np.ndarray
-        Knots of the grid
-    weights: np.ndarray
-        Weights of the grid
-
-    Notes
-    -----
-    .. [1] Davis, P. J., Rabinowitz, P. (2007). Methods of numerical integration.
-       Courier Corporation, second edition, ISBN: 0486453391.
-
-    .. [2] Gautschi, W. (1967). Numerical quadrature in the presence of a singularity.
-       SIAM Journal on Numerical Analysis, 4(3), 357-362.
-
-    .. [3] Waldvogel, J. (2006). Fast construction of the Fejer and Clenshaw–Curtis quadrature rules.
-       BIT Numerical Mathematics, 46(1), 195-202.
-    """
-    n = int(n)
-
-    if n == 1:
-        knots = np.array([0.0])
-        weights = np.array([2.0])
-
-    elif n == 2:
-        knots = np.array([-0.5, +0.5])
-        weights = np.array([1.0, 1.0])
-
-    else:
-        theta = np.zeros(n)
-        p = 1
-
-        for i in range(0, n):
-            theta[i] = float(n - i) * np.pi / float(n + 1)
-
-        knots = np.zeros(n)
-
-        for i in range(0, n):
-            knots[i] = np.cos(theta[i])
-
-        weights = np.zeros(n)
-
-        for i in range(0, n):
-            weights[i] = 1.0
-            jhi = ((n - 1) // 2)
-
-            for j in range(0, jhi):
-                angle = 2.0 * float(j + 1) * theta[i]
-                weights[i] = weights[i] - 2.0 * np.cos(angle) / float(4 * (j + 1) ** 2 - 1)
-                p = 2 * ((n + 1) // 2) - 1
-
-            weights[i] = weights[i] - np.cos(float(p + 1) * theta[i]) / float(p)
-
-        for i in range(0, n):
-            weights[i] = 2.0 * weights[i] / float(n + 1)
-
-    return knots, weights
-
-
-def get_quadrature_patterson_1d(n):
-    """
-    Computes the nested Gauss-Patterson nodes and weights for n = 1,3,7,15,31 nodes.
-
-    knots, weights = Grid.get_quadrature_patterson_1d(n)
-
-    Parameters
-    ----------
-    n: int
-        Number of knots (possible values: 1, 3, 7, 15, 31)
-
-    Returns
-    -------
-    knots: np.ndarray
-        Knots of the grid
-    weights: np.ndarray
-        Weights of the grid
-    """
-    x = np.zeros(n)
-    w = np.zeros(n)
-
-    if n == 1:
-
-        x = 0.0
-
-        w = 2.0
-
-    elif n == 3:
-
-        x[0] = -0.77459666924148337704
-        x[1] = 0.0
-        x[2] = 0.77459666924148337704
-
-        w[0] = 0.555555555555555555556
-        w[1] = 0.888888888888888888889
-        w[2] = 0.555555555555555555556
-
-    elif n == 7:
-
-        x[0] = -0.96049126870802028342
-        x[1] = -0.77459666924148337704
-        x[2] = -0.43424374934680255800
-        x[3] = 0.0
-        x[4] = 0.43424374934680255800
-        x[5] = 0.77459666924148337704
-        x[6] = 0.96049126870802028342
-
-        w[0] = 0.104656226026467265194
-        w[1] = 0.268488089868333440729
-        w[2] = 0.401397414775962222905
-        w[3] = 0.450916538658474142345
-        w[4] = 0.401397414775962222905
-        w[5] = 0.268488089868333440729
-        w[6] = 0.104656226026467265194
-
-    elif n == 15:
-
-        x[0] = -0.99383196321275502221
-        x[1] = -0.96049126870802028342
-        x[2] = -0.88845923287225699889
-        x[3] = -0.77459666924148337704
-        x[4] = -0.62110294673722640294
-        x[5] = -0.43424374934680255800
-        x[6] = -0.22338668642896688163
-        x[7] = 0.0
-        x[8] = 0.22338668642896688163
-        x[9] = 0.43424374934680255800
-        x[10] = 0.62110294673722640294
-        x[11] = 0.77459666924148337704
-        x[12] = 0.88845923287225699889
-        x[13] = 0.96049126870802028342
-        x[14] = 0.99383196321275502221
-
-        w[0] = 0.0170017196299402603390
-        w[1] = 0.0516032829970797396969
-        w[2] = 0.0929271953151245376859
-        w[3] = 0.134415255243784220360
-        w[4] = 0.171511909136391380787
-        w[5] = 0.200628529376989021034
-        w[6] = 0.219156858401587496404
-        w[7] = 0.225510499798206687386
-        w[8] = 0.219156858401587496404
-        w[9] = 0.200628529376989021034
-        w[10] = 0.171511909136391380787
-        w[11] = 0.134415255243784220360
-        w[12] = 0.0929271953151245376859
-        w[13] = 0.0516032829970797396969
-        w[14] = 0.0170017196299402603390
-
-    elif n == 31:
-
-        x[0] = -0.99909812496766759766
-        x[1] = -0.99383196321275502221
-        x[2] = -0.98153114955374010687
-        x[3] = -0.96049126870802028342
-        x[4] = -0.92965485742974005667
-        x[5] = -0.88845923287225699889
-        x[6] = -0.83672593816886873550
-        x[7] = -0.77459666924148337704
-        x[8] = -0.70249620649152707861
-        x[9] = -0.62110294673722640294
-        x[10] = -0.53131974364437562397
-        x[11] = -0.43424374934680255800
-        x[12] = -0.33113539325797683309
-        x[13] = -0.22338668642896688163
-        x[14] = -0.11248894313318662575
-        x[15] = 0.0
-        x[16] = 0.11248894313318662575
-        x[17] = 0.22338668642896688163
-        x[18] = 0.33113539325797683309
-        x[19] = 0.43424374934680255800
-        x[20] = 0.53131974364437562397
-        x[21] = 0.62110294673722640294
-        x[22] = 0.70249620649152707861
-        x[23] = 0.77459666924148337704
-        x[24] = 0.83672593816886873550
-        x[25] = 0.88845923287225699889
-        x[26] = 0.92965485742974005667
-        x[27] = 0.96049126870802028342
-        x[28] = 0.98153114955374010687
-        x[29] = 0.99383196321275502221
-        x[30] = 0.99909812496766759766
-
-        w[0] = 0.00254478079156187441540
-        w[1] = 0.00843456573932110624631
-        w[2] = 0.0164460498543878109338
-        w[3] = 0.0258075980961766535646
-        w[4] = 0.0359571033071293220968
-        w[5] = 0.0464628932617579865414
-        w[6] = 0.0569795094941233574122
-        w[7] = 0.0672077542959907035404
-        w[8] = 0.0768796204990035310427
-        w[9] = 0.0857559200499903511542
-        w[10] = 0.0936271099812644736167
-        w[11] = 0.100314278611795578771
-        w[12] = 0.105669893580234809744
-        w[13] = 0.109578421055924638237
-        w[14] = 0.111956873020953456880
-        w[15] = 0.112755256720768691607
-        w[16] = 0.111956873020953456880
-        w[17] = 0.109578421055924638237
-        w[18] = 0.105669893580234809744
-        w[19] = 0.100314278611795578771
-        w[20] = 0.0936271099812644736167
-        w[21] = 0.0857559200499903511542
-        w[22] = 0.0768796204990035310427
-        w[23] = 0.0672077542959907035404
-        w[24] = 0.0569795094941233574122
-        w[25] = 0.0464628932617579865414
-        w[26] = 0.0359571033071293220968
-        w[27] = 0.0258075980961766535646
-        w[28] = 0.0164460498543878109338
-        w[29] = 0.00843456573932110624631
-        w[30] = 0.00254478079156187441540
-    else:
-        print("Number of points does not match Gauss-Patterson quadrature rule.")
-        raise NotImplementedError
-
-    knots = x
-    weights = w
-
-    return knots, weights
+import numpy as np
+from scipy.fftpack import ifft
+from scipy.special import roots_genlaguerre
+
+
+def get_quadrature_jacobi_1d(n, p, q):
+    """
+    Get knots and weights of Jacobi polynomials.
+
+    knots, weights = Grid.get_quadrature_jacobi_1d(n, p, q)
+
+    Parameters
+    ----------
+    n: int
+        Number of knots
+    p: float
+        First shape parameter
+    q: float
+        Second shape parameter
+
+    Returns
+    -------
+    knots: np.ndarray
+        Knots of the grid
+    weights: np.ndarray
+        Weights of the grid
+    """
+
+    # make array to count N: 0, 1, ..., N-1
+    n_arr = np.arange(1, n)
+
+    # compose diagonals for companion matrix
+    t01 = 1.0 * (p - q) / (2 + q + p)
+    t02 = 1.0 * ((p - q) * (q + p)) / ((2 * n_arr + q + p) * (2 * n_arr + 2 + q + p))
+    t1 = np.append(t01, t02)
+    t2 = np.sqrt((4.0 * n_arr * (n_arr + q) * (n_arr + p) * (n_arr + q + p)) / (
+            (2 * n_arr - 1 + q + p) * (2 * n_arr + q + p) ** 2 * (2 * n_arr + 1 + q + p)))
+
+    # compose companion matrix
+    t = np.diag(t1) + np.diag(t2, 1) + np.diag(t2, -1)
+
+    # evaluate roots of polynomials (the abscissas are the roots of the
+    # characteristic polynomial, i.d. the eigenvalues of the companion matrix)
+    # the weights can be derived from the corresponding eigenvectors.
+    eigvals, eigvecs = np.linalg.eig(t)
+    idx_sorted = np.argsort(eigvals)
+    eigvals_sorted = eigvals[idx_sorted]
+
+    weights = 2.0 * eigvecs[0, idx_sorted] ** 2
+    knots = eigvals_sorted
+
+    return knots, weights
+
+
+def get_quadrature_hermite_1d(n):
+    """
+    Get knots and weights of Hermite polynomials (normal distribution).
+
+    knots, weights = Grid.get_quadrature_hermite_1d(n)
+
+    Parameters
+    ----------
+    n: int
+        number of knots
+
+    Returns
+    -------
+    knots: np.ndarray
+        knots of the grid
+    weights: np.ndarray
+        weights of the grid
+    """
+    n = int(n)
+    knots, weights = np.polynomial.hermite_e.hermegauss(n)
+    weights = np.array(list(2.0 * weights / np.sum(weights)))
+
+    return knots, weights
+
+
+def get_quadrature_laguerre_1d(n, alpha):
+    """
+    Get knots and weights of Laguerre polynomials (gamma distribution).
+
+    knots, weights = Grid.get_quadrature_laguerre_1d(n)
+
+    Parameters
+    ----------
+    n: int
+        number of knots
+    alpha: float
+        Parameter of Laguerre polynomial
+
+    Returns
+    -------
+    knots: np.ndarray
+        knots of the grid
+    weights: np.ndarray
+        weights of the grid
+    """
+    n = int(n)
+    knots, weights = roots_genlaguerre(n=n, alpha=alpha)
+
+    return knots, weights
+
+
+# TODO: review this
+def get_quadrature_clenshaw_curtis_1d(n):
+    """
+    Get the Clenshaw Curtis nodes and weights.
+
+    knots, weights = Grid.get_quadrature_clenshaw_curtis_1d(n)
+
+    Parameters
+    ----------
+    n: int
+        Number of knots
+
+    Returns
+    -------
+    knots: np.ndarray
+        Knots of the grid
+    weights: np.ndarray
+        Weights of the grid
+    """
+    n = int(n)
+
+    if n == 1:
+        knots = 0
+        weights = 2
+    else:
+        n = n - 1
+        c = np.zeros((n, 2))
+        k = 2 * (1 + np.arange(np.floor(n / 2)))
+        c[::2, 0] = 2 / np.hstack((1, 1 - k * k))
+        c[1, 1] = -n
+        v = np.vstack((c, np.flipud(c[1:n, :])))
+        f = np.real(ifft(v, n=None, axis=0))
+        knots = f[0:n, 1]
+        weights = np.hstack((f[0, 0], 2 * f[1:n, 0], f[n, 0]))
+
+    return knots, weights
+
+
+def get_quadrature_fejer1_1d(n):
+    """
+    Computes the Fejer type 1 nodes and weights.
+
+    This method uses a direct approach after Davis and Rabinowitz (2007) [1] and Gautschi (1967) [2].
+    The paper by Waldvogel (2006) [3] exhibits a more efficient approach using Fourier transforms.
+
+    knots, weights = Grid.get_quadrature_fejer1_1d(n)
+
+    Parameters
+    ----------
+    n: int
+        Number of knots
+
+    Returns
+    -------
+    knots: ndarray
+        Knots of the grid
+    weights: ndarray
+        Weights of the grid
+
+    Notes
+    -----
+    .. [1] Davis, P. J., Rabinowitz, P. (2007). Methods of numerical integration.
+       Courier Corporation, second edition, ISBN: 0486453391.
+
+    .. [2] Gautschi, W. (1967). Numerical quadrature in the presence of a singularity.
+       SIAM Journal on Numerical Analysis, 4(3), 357-362.
+
+    .. [3] Waldvogel, J. (2006). Fast construction of the Fejer and Clenshaw-Curtis quadrature rules.
+       BIT Numerical Mathematics, 46(1), 195-202.
+    """
+    n = int(n)
+
+    theta = np.zeros(n)
+
+    for i in range(0, n):
+        theta[i] = float(2 * n - 1 - 2 * i) * np.pi / float(2 * n)
+
+    knots = np.zeros(n)
+
+    for i in range(0, n):
+        knots[i] = np.cos(theta[i])
+
+    weights = np.zeros(n)
+
+    for i in range(0, n):
+        weights[i] = 1.0
+        jhi = (n // 2)
+        for j in range(0, jhi):
+            angle = 2.0 * float(j + 1) * theta[i]
+            weights[i] = weights[i] - 2.0 * np.cos(angle) / float(4 * (j + 1) ** 2 - 1)
+
+    for i in range(0, n):
+        weights[i] = 2.0 * weights[i] / float(n)
+
+    return knots, weights
+
+
+def get_quadrature_fejer2_1d(n):
+    """
+    Computes the Fejer type 2 nodes and weights (Clenshaw Curtis without boundary nodes).
+
+    This method uses a direct approach after Davis and Rabinowitz (2007) [1] and Gautschi (1967) [2].
+    The paper by Waldvogel (2006) [3] exhibits a more efficient approach using Fourier transforms.
+
+    knots, weights = Grid.get_quadrature_fejer2_1d(n)
+
+    Parameters
+    ----------
+    n: int
+        Number of knots
+
+    Returns
+    -------
+    knots: np.ndarray
+        Knots of the grid
+    weights: np.ndarray
+        Weights of the grid
+
+    Notes
+    -----
+    .. [1] Davis, P. J., Rabinowitz, P. (2007). Methods of numerical integration.
+       Courier Corporation, second edition, ISBN: 0486453391.
+
+    .. [2] Gautschi, W. (1967). Numerical quadrature in the presence of a singularity.
+       SIAM Journal on Numerical Analysis, 4(3), 357-362.
+
+    .. [3] Waldvogel, J. (2006). Fast construction of the Fejer and Clenshaw–Curtis quadrature rules.
+       BIT Numerical Mathematics, 46(1), 195-202.
+    """
+    n = int(n)
+
+    if n == 1:
+        knots = np.array([0.0])
+        weights = np.array([2.0])
+
+    elif n == 2:
+        knots = np.array([-0.5, +0.5])
+        weights = np.array([1.0, 1.0])
+
+    else:
+        theta = np.zeros(n)
+        p = 1
+
+        for i in range(0, n):
+            theta[i] = float(n - i) * np.pi / float(n + 1)
+
+        knots = np.zeros(n)
+
+        for i in range(0, n):
+            knots[i] = np.cos(theta[i])
+
+        weights = np.zeros(n)
+
+        for i in range(0, n):
+            weights[i] = 1.0
+            jhi = ((n - 1) // 2)
+
+            for j in range(0, jhi):
+                angle = 2.0 * float(j + 1) * theta[i]
+                weights[i] = weights[i] - 2.0 * np.cos(angle) / float(4 * (j + 1) ** 2 - 1)
+                p = 2 * ((n + 1) // 2) - 1
+
+            weights[i] = weights[i] - np.cos(float(p + 1) * theta[i]) / float(p)
+
+        for i in range(0, n):
+            weights[i] = 2.0 * weights[i] / float(n + 1)
+
+    return knots, weights
+
+
+def get_quadrature_patterson_1d(n):
+    """
+    Computes the nested Gauss-Patterson nodes and weights for n = 1,3,7,15,31 nodes.
+
+    knots, weights = Grid.get_quadrature_patterson_1d(n)
+
+    Parameters
+    ----------
+    n: int
+        Number of knots (possible values: 1, 3, 7, 15, 31)
+
+    Returns
+    -------
+    knots: np.ndarray
+        Knots of the grid
+    weights: np.ndarray
+        Weights of the grid
+    """
+    x = np.zeros(n)
+    w = np.zeros(n)
+
+    if n == 1:
+
+        x = 0.0
+
+        w = 2.0
+
+    elif n == 3:
+
+        x[0] = -0.77459666924148337704
+        x[1] = 0.0
+        x[2] = 0.77459666924148337704
+
+        w[0] = 0.555555555555555555556
+        w[1] = 0.888888888888888888889
+        w[2] = 0.555555555555555555556
+
+    elif n == 7:
+
+        x[0] = -0.96049126870802028342
+        x[1] = -0.77459666924148337704
+        x[2] = -0.43424374934680255800
+        x[3] = 0.0
+        x[4] = 0.43424374934680255800
+        x[5] = 0.77459666924148337704
+        x[6] = 0.96049126870802028342
+
+        w[0] = 0.104656226026467265194
+        w[1] = 0.268488089868333440729
+        w[2] = 0.401397414775962222905
+        w[3] = 0.450916538658474142345
+        w[4] = 0.401397414775962222905
+        w[5] = 0.268488089868333440729
+        w[6] = 0.104656226026467265194
+
+    elif n == 15:
+
+        x[0] = -0.99383196321275502221
+        x[1] = -0.96049126870802028342
+        x[2] = -0.88845923287225699889
+        x[3] = -0.77459666924148337704
+        x[4] = -0.62110294673722640294
+        x[5] = -0.43424374934680255800
+        x[6] = -0.22338668642896688163
+        x[7] = 0.0
+        x[8] = 0.22338668642896688163
+        x[9] = 0.43424374934680255800
+        x[10] = 0.62110294673722640294
+        x[11] = 0.77459666924148337704
+        x[12] = 0.88845923287225699889
+        x[13] = 0.96049126870802028342
+        x[14] = 0.99383196321275502221
+
+        w[0] = 0.0170017196299402603390
+        w[1] = 0.0516032829970797396969
+        w[2] = 0.0929271953151245376859
+        w[3] = 0.134415255243784220360
+        w[4] = 0.171511909136391380787
+        w[5] = 0.200628529376989021034
+        w[6] = 0.219156858401587496404
+        w[7] = 0.225510499798206687386
+        w[8] = 0.219156858401587496404
+        w[9] = 0.200628529376989021034
+        w[10] = 0.171511909136391380787
+        w[11] = 0.134415255243784220360
+        w[12] = 0.0929271953151245376859
+        w[13] = 0.0516032829970797396969
+        w[14] = 0.0170017196299402603390
+
+    elif n == 31:
+
+        x[0] = -0.99909812496766759766
+        x[1] = -0.99383196321275502221
+        x[2] = -0.98153114955374010687
+        x[3] = -0.96049126870802028342
+        x[4] = -0.92965485742974005667
+        x[5] = -0.88845923287225699889
+        x[6] = -0.83672593816886873550
+        x[7] = -0.77459666924148337704
+        x[8] = -0.70249620649152707861
+        x[9] = -0.62110294673722640294
+        x[10] = -0.53131974364437562397
+        x[11] = -0.43424374934680255800
+        x[12] = -0.33113539325797683309
+        x[13] = -0.22338668642896688163
+        x[14] = -0.11248894313318662575
+        x[15] = 0.0
+        x[16] = 0.11248894313318662575
+        x[17] = 0.22338668642896688163
+        x[18] = 0.33113539325797683309
+        x[19] = 0.43424374934680255800
+        x[20] = 0.53131974364437562397
+        x[21] = 0.62110294673722640294
+        x[22] = 0.70249620649152707861
+        x[23] = 0.77459666924148337704
+        x[24] = 0.83672593816886873550
+        x[25] = 0.88845923287225699889
+        x[26] = 0.92965485742974005667
+        x[27] = 0.96049126870802028342
+        x[28] = 0.98153114955374010687
+        x[29] = 0.99383196321275502221
+        x[30] = 0.99909812496766759766
+
+        w[0] = 0.00254478079156187441540
+        w[1] = 0.00843456573932110624631
+        w[2] = 0.0164460498543878109338
+        w[3] = 0.0258075980961766535646
+        w[4] = 0.0359571033071293220968
+        w[5] = 0.0464628932617579865414
+        w[6] = 0.0569795094941233574122
+        w[7] = 0.0672077542959907035404
+        w[8] = 0.0768796204990035310427
+        w[9] = 0.0857559200499903511542
+        w[10] = 0.0936271099812644736167
+        w[11] = 0.100314278611795578771
+        w[12] = 0.105669893580234809744
+        w[13] = 0.109578421055924638237
+        w[14] = 0.111956873020953456880
+        w[15] = 0.112755256720768691607
+        w[16] = 0.111956873020953456880
+        w[17] = 0.109578421055924638237
+        w[18] = 0.105669893580234809744
+        w[19] = 0.100314278611795578771
+        w[20] = 0.0936271099812644736167
+        w[21] = 0.0857559200499903511542
+        w[22] = 0.0768796204990035310427
+        w[23] = 0.0672077542959907035404
+        w[24] = 0.0569795094941233574122
+        w[25] = 0.0464628932617579865414
+        w[26] = 0.0359571033071293220968
+        w[27] = 0.0258075980961766535646
+        w[28] = 0.0164460498543878109338
+        w[29] = 0.00843456573932110624631
+        w[30] = 0.00254478079156187441540
+    else:
+        print("Number of points does not match Gauss-Patterson quadrature rule.")
+        raise NotImplementedError
+
+    knots = x
+    weights = w
+
+    return knots, weights
```

## pygpc/RandomParameter.py

```diff
@@ -1,702 +1,706 @@
-import scipy.special
-import scipy.stats
-import numpy as np
-import matplotlib.pyplot as plt
-from .BasisFunction import *
-
-
-class RandomParameter(object):
-    """
-    RandomParameter class
-
-    Parameters
-    ----------
-    pdf_type : str
-        Distribution type of random variable ('beta', 'norm', 'gamma')
-    pdf_shape : list of float [2]
-        Shape parameters
-    pdf_limits : list of float [2]
-        Lower and upper bounds of random variable (if applicable)
-
-    Attributes
-    ----------
-    pdf_type : str
-        Distribution type of random variable ('beta', 'norm', 'gamma')
-    pdf_shape : list of float [2]
-        Shape parameters of beta distributed random variable [p, q]
-    pdf_limits : list of float [2]
-        Lower and upper bounds of random variable [min, max]
-    mean : float
-        Mean value
-    std : float
-        Standard deviation
-    var : float
-        Variance
-    """
-    def __init__(self, pdf_type=None, pdf_shape=None, pdf_limits=None):
-        """
-        Constructor; Initializes random parameter;
-        """
-
-        self.pdf_type = pdf_type
-        self.pdf_shape = np.array(pdf_shape).astype(float)
-        self.pdf_limits = np.array(pdf_limits).astype(float)
-        self.pdf_limits_norm = None
-        self.mean = None
-        self.std = None
-        self.var = None
-        self.p_perc = None
-
-    def pdf(self, x=None):
-        pass
-
-    def pdf_norm(self, x=None):
-        pass
-
-    def icdf(self, p):
-        pass
-
-    def plot_pdf(self, legend_str=None, norm=False):
-        """
-        Plots probability density function
-
-        Parameters
-        ----------
-        legend_str : str, optional, default: None
-            Legend string
-        norm : boolean, optional, default: False
-            Plot pdfs in normalized space [-1, 1]
-        """
-
-        if not norm:
-            # delta = self.pdf_limits[1] - self.pdf_limits[0]
-            # x = np.linspace(self.pdf_limits[0] - 0.0 * delta,
-            #                 self.pdf_limits[1] + 0.0 * delta, 200)
-            x, y = self.pdf()
-        else:
-            delta = 2.
-            # x = np.linspace(-1. - 0.0 * delta,
-            #                 +1. + 0.0 * delta, 200)
-            x, y = self.pdf_norm()
-
-        plt.plot(x, y)
-        plt.xlabel("x")
-        plt.ylabel("p(x)")
-        plt.grid(True)
-
-        if legend_str is not None:
-
-            if type(legend_str) is not list:
-                legend_str = [legend_str]
-
-            plt.legend(legend_str)
-
-        return plt
-
-
-class Beta(RandomParameter):
-    """
-    Beta distributed random variable sub-class
-
-    Parameters
-    ----------
-    pdf_shape: list of float [2]
-        Shape parameters of beta distributed random variable [p, q]
-    pdf_limits: list of float [2]
-        Lower and upper bounds of random variable [min, max]
-
-    Notes
-    -----
-    Probability density function:
-
-    .. math::
-
-       p(x) = \\left(\\frac{\\Gamma(p)\\Gamma(q)}{\\Gamma(p+q)}(b-a)^{(p+q-1)}\\right)^{-1} (x-a)^{(p-1)} (b-x)^{(q-1)}
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> pygpc.RandomParameter.Beta(pdf_shape=[5, 2], pdf_limits=[1.2, 2])
-    """
-
-    def __init__(self, pdf_shape, pdf_limits):
-        """
-        Constructor; Initializes beta distributed random variable
-        """
-
-        super(Beta, self).__init__(pdf_type='beta', pdf_shape=pdf_shape, pdf_limits=pdf_limits)
-
-        self.mean = float(self.pdf_shape[0]) / (self.pdf_shape[0] + self.pdf_shape[1]) * \
-                    (self.pdf_limits[1] - self.pdf_limits[0]) + self.pdf_limits[0]
-
-        self.std = np.sqrt(self.pdf_shape[0] * self.pdf_shape[1] / \
-                           ((self.pdf_shape[0] + self.pdf_shape[1] + 1) *
-                            (self.pdf_shape[0] + self.pdf_shape[1])**2)) * \
-                   (self.pdf_limits[1] - self.pdf_limits[0])
-
-        self.var = self.std**2
-        self.rv = scipy.stats.beta(a=self.pdf_shape[0], b=self.pdf_shape[1])
-
-        self.pdf_limits_norm = [-1, 1]
-
-    def sample(self, n_samples, normalized=True):
-        """
-        Samples random variable
-
-        Parameters
-        ----------
-        n_samples : int
-            Number of samples to draw
-        normalized : bool, optional, default: True
-            Return normalized value
-
-        Returns
-        -------
-        sample : ndarray of float [n_sample]
-            Sampling points
-        """
-        samples = 2 * self.rv.rvs(size=n_samples) - 1
-
-        if not normalized:
-            samples = (samples + 1) / 2 * (self.pdf_limits[1] - self.pdf_limits[0]) + self.pdf_limits[0]
-
-        return samples
-
-    def init_basis_function(self, order):
-        """
-        Initializes Jacobi BasisFunction of Beta RandomParameter
-
-        Parameters
-        ----------
-        order: int
-            Order of basis function
-        """
-        return Jacobi({"i": order, "p": self.pdf_shape[0], "q": self.pdf_shape[1]})
-
-    def pdf(self, x=None, a=None, b=None):
-        """
-        Calculate the probability density function of the beta distributed random variable.
-
-        Parameters
-        ----------
-        x: ndarray of float [n_x]
-            Values of random variable
-        a: float
-            Lower limit of beta distribution
-        b: float
-            Upper limit of beta distribution
-
-        Returns
-        -------
-        pdf: ndarray of float [n_x]
-            Probability density at values x
-        """
-
-        p = self.pdf_shape[0]
-        q = self.pdf_shape[1]
-
-        if a is None:
-            a = self.pdf_limits[0]
-
-        if b is None:
-            b = self.pdf_limits[1]
-
-        if x is None:
-            x = np.linspace(a, b, 200)
-
-        y = np.zeros(x.shape)
-
-        mask = np.logical_and(a < x, x < b)
-
-        y[mask] = (scipy.special.gamma(p) * scipy.special.gamma(q) / scipy.special.gamma(p + q)
-                   * (b - a) ** (p + q - 1)) ** (-1) * (x[mask] - a) ** (p - 1) * (b - x[mask]) ** (q - 1)
-
-        return x, y
-
-    def pdf_norm(self, x=None):
-        """
-        Calculate the probability density function of the normalized beta distributed random variable in interval
-        [-1, 1].
-
-        pdf = Beta.pdf_norm(x)
-
-        Parameters
-        ----------
-        x: ndarray of float [n_x]
-            Values of random variable
-
-        Returns
-        -------
-        pdf: ndarray of float [n_x]
-            Probability density at values x
-        """
-
-        if x is None:
-            x = np.linspace(-1, 1, 200)
-
-        x, y = self.pdf(x, a=-1., b=1.)
-
-        return x, y
-
-    def icdf(self, p):
-        """
-        Inverse cumulative density function [0, 1]
-
-        Parameters
-        ----------
-        p: ndarray of float [n_p]
-            Cumulative probability
-
-        Returns
-        -------
-        x: ndarray of float [n_p]
-            Sample value of the random variable such that the probability of the variable being less than or equal
-            to that value equals the given probability.
-        """
-        x = 2 * self.rv.ppf(p.flatten()) - 1
-
-        return x
-
-    def cdf_norm(self, x):
-        """
-        Cumulative density function defined in normalized parameter space [-1, 1].
-
-        Parameters
-        ----------
-        x: ndarray of float [n_x]
-            Values of random variable (normalized) [-1, 1]
-
-        Returns
-        -------
-        cdf: ndarray of float [n_x]
-            Cumulative density at values x [0, 1]
-        """
-        c = self.rv.cdf((x.flatten() + 1) / 2)
-
-        return c
-
-    def cdf(self, x):
-        """
-        Cumulative density function.
-
-        Parameters
-        ----------
-        x: ndarray of float [n_x]
-            Values of random variable
-
-        Returns
-        -------
-        cdf: ndarray of float [n_x]
-            Cumulative density at values x [0, 1]
-        """
-        c = self.rv.cdf((x.flatten() - self.pdf_limits[0]) / (self.pdf_limits[1] - self.pdf_limits[0]))
-
-        return c
-
-
-class Norm(RandomParameter):
-    """
-    Normal distributed random variable sub-class
-
-    Parameters
-    ----------
-    pdf_shape: list of float [2]
-        Shape parameters of normal distributed random variable [mean, std]
-    p_perc: float, optional, default=0.9973
-        Probability of percentile, where infinite distributions are cut off
-        (default value corresponds to 6 sigma)
-
-    Notes
-    -----
-    Probability density function
-
-    .. math::
-
-       p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left({-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\right)
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> pygpc.RandomParameter.Norm(pdf_shape=[0.1, 0.15])
-    """
-
-    def __init__(self, pdf_shape, p_perc=0.9973):
-        """
-        Constructor; Initializes normal distributed random variable
-        """
-
-        self.x_perc = [None, None]
-        self.x_perc[0] = scipy.stats.norm().ppf(0.5*(1-p_perc)) * pdf_shape[1] + pdf_shape[0]
-        self.x_perc[1] = scipy.stats.norm().ppf(0.5*(1+p_perc)) * pdf_shape[1] + pdf_shape[0]
-
-        self.x_perc_norm = [None, None]
-        self.x_perc_norm[0] = scipy.stats.norm().ppf(0.5 * (1 - p_perc))
-        self.x_perc_norm[1] = scipy.stats.norm().ppf(0.5 * (1 + p_perc))
-
-        super(Norm, self).__init__(pdf_type='norm',
-                                   pdf_shape=pdf_shape,
-                                   pdf_limits=[self.x_perc[0], self.x_perc[1]])
-
-        self.p_perc = p_perc
-        self.mean = self.pdf_shape[0]
-        self.std = self.pdf_shape[1]
-        self.var = self.std ** 2
-        self.pdf_limits_norm = [self.x_perc_norm[0], self.x_perc_norm[1]]
-        self.rv = scipy.stats.norm()
-
-    def sample(self, n_samples, normalized=True):
-        """
-        Samples random variable
-
-        Parameters
-        ----------
-        n_samples : int
-            Number of samples to draw
-        normalized : bool, optional, default: True
-            Return normalized value
-
-        Returns
-        -------
-        sample : ndarray of float [n_sample]
-            Sampling points
-        """
-        samples = self.rv.rvs(size=n_samples)
-
-        if not normalized:
-            samples = samples * self.pdf_shape[1] + self.pdf_shape[0]
-
-        return samples
-
-    @staticmethod
-    def init_basis_function(order):
-        """
-        Initializes Hermite BasisFunction of Norm RandomParameter
-
-        Parameters
-        ----------
-        order: int
-            Order of basis function
-        """
-        return Hermite({"i": order})
-
-    def pdf(self, x=None):
-        """
-        Calculate the probability density function of the normal distributed random variable.
-
-        pdf = Norm.pdf(x)
-
-        Parameters
-        ----------
-        x: ndarray of float [n_x]
-            Values of random variable
-
-        Returns
-        -------
-        pdf: ndarray of float [n_x]
-            Probability density
-        """
-        if x is None:
-            x = np.linspace(self.x_perc[0], self.x_perc[1], 200)
-
-        y = scipy.stats.norm.pdf(x, loc=self.pdf_shape[0], scale=self.pdf_shape[1])
-
-        return x, y
-
-    def pdf_norm(self, x=None):
-        """
-        Calculate the probability density function of the normalized normal distributed random variable
-        (zero mean, std 1).
-
-        pdf = Norm.pdf_norm(x)
-
-        Parameters
-        ----------
-        x: ndarray of float [n_x]
-            Values of random variable in interval [-1, 1]
-
-        Returns
-        -------
-        pdf: ndarray of float [n_x]
-            Probability density
-        """
-        if x is None:
-            x = np.linspace(self.x_perc_norm[0], self.x_perc_norm[1], 200)
-
-        y = scipy.stats.norm.pdf(x, loc=0, scale=1.)
-
-        return x, y
-
-    def icdf(self, p):
-        """
-        Inverse cumulative density function [0, 1]
-
-        Parameters
-        ----------
-        p: ndarray of float [n_p]
-            Cumulative probability
-
-        Returns
-        -------
-        x: ndarray of float [n_p]
-            Sample value of the random variable such that the probability of the variable being less than or equal
-            to that value equals the given probability.
-        """
-        # transform probabilities to perc constraint
-        p = self.p_perc * p + (1 - self.p_perc)/2
-
-        # icdf
-        x = self.rv.ppf(p.flatten())
-
-        return x
-
-    def cdf_norm(self, x):
-        """
-        Cumulative density function defined in normalized parameter space (mean=0, std=1).
-
-        Parameters
-        ----------
-        x: ndarray of float [n_x]
-            Values of random variable (normalized, mean=0, std=1)
-
-        Returns
-        -------
-        cdf: ndarray of float [n_x]
-            Cumulative density at values x [0, 1]
-        """
-        c = self.rv.cdf(x.flatten())
-
-        return c
-
-    def cdf(self, x):
-        """
-        Cumulative density function.
-
-        Parameters
-        ----------
-        x: ndarray of float [n_x]
-            Values of random variable
-
-        Returns
-        -------
-        cdf: ndarray of float [n_x]
-            Cumulative density at values x [0, 1]
-        """
-        n = scipy.stats.norm(loc=self.pdf_shape[0], scale=self.pdf_shape[1])
-        c = n.cdf(x.flatten())
-
-        return c
-
-
-class Gamma(RandomParameter):
-    """
-    Gamma distributed random variable sub-class
-
-    Parameters
-    ----------
-    pdf_shape: list of float [3]
-        Shape parameters of gamma distributed random variable [shape, rate, loc] (=[alpha, beta, location])
-    p_perc: float, optional, default=0.9973
-        Probability of percentile, where infinite distributions are cut off
-        (default value corresponds to 6 sigma from normal distribution)
-
-    Notes
-    -----
-    Probability density function:
-
-    .. math::
-
-       p(x) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}x^{\\alpha-1}e^{\\beta x}
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> pygpc.RandomParameter.Gamma(pdf_shape=[5, 2, 1.2])
-    """
-    def __init__(self, pdf_shape, p_perc=0.9973):
-        """
-        Constructor; Initializes gamma distributed random variable
-        """
-
-        self.x_perc = scipy.stats.gamma.ppf(p_perc,
-                                            a=pdf_shape[0],
-                                            loc=pdf_shape[2],
-                                            scale=1 / pdf_shape[1])
-
-        self.x_perc_norm = scipy.stats.gamma.ppf(p_perc,
-                                                 a=pdf_shape[0],
-                                                 loc=0.,
-                                                 scale=1.)
-
-        super(Gamma, self).__init__(pdf_type='gamma',
-                                    pdf_shape=pdf_shape,
-                                    pdf_limits=[pdf_shape[2], self.x_perc])
-
-        self.p_perc = p_perc
-
-        self.mean = self.pdf_shape[0] / self.pdf_shape[1] + self.pdf_shape[2]
-
-        self.std = np.sqrt(self.pdf_shape[0] / self.pdf_shape[1]**2)
-
-        self.var = self.std**2
-
-        self.pdf_limits_norm = [0, self.x_perc_norm]
-
-    def sample(self, n_samples, normalized=True):
-        """
-        Samples random variable
-
-        Parameters
-        ----------
-        n_samples : int
-            Number of samples to draw
-        normalized : bool, optional, default: True
-            Return normalized value
-
-        Returns
-        -------
-        sample : ndarray of float [n_sample]
-            Sampling points
-        """
-
-        samples = scipy.stats.gamma.rvs(size=n_samples,
-                                        a=self.pdf_shape[0],
-                                        loc=0.,
-                                        scale=1.)
-
-        if not normalized:
-            samples = samples + self.pdf_shape[2]
-
-        return samples
-
-    def init_basis_function(self, order):
-        """
-        Initializes Jacobi BasisFunction of Beta RandomParameter
-
-        Parameters
-        ----------
-        order: int
-            Order of basis function
-        """
-        return Laguerre({"i": order, "alpha": self.pdf_shape[0]-1, "beta": self.pdf_shape[1]})
-
-    def pdf(self, x=None):
-        """
-        Calculate the probability density function of the beta distributed random variable.
-
-        pdf = Gamma.pdf(x)
-
-        Parameters
-        ----------
-        x: ndarray of float [n_x]
-            Values of random variable
-
-        Returns
-        -------
-        pdf: ndarray of float [n_x]
-            Probability density at values x
-        """
-
-        a = self.pdf_shape[0]
-        b = self.pdf_shape[1]
-        loc = self.pdf_shape[2]
-
-        if x is None:
-            x = np.linspace(0, self.x_perc, 200)
-
-        y = scipy.stats.gamma.pdf(x, a=a, loc=loc, scale=1/b)
-        # y = b**a/scipy.special.gamma(a) * (x-loc)**(a-1) * np.exp(-b*(x-loc))
-
-        return x, y
-
-    def pdf_norm(self, x=None):
-        """
-        Calculate the probability density function of the normalized gamma distributed random variable in interval
-        [-1, 1].
-
-        pdf = Gamma.pdf_norm(x)
-
-        Parameters
-        ----------
-        x: ndarray of float [n_x]
-            Values of random variable in interval [-1, 1]
-
-        Returns
-        -------
-        pdf: ndarray of float [n_x]
-            Probability density at values x
-        """
-        if x is None:
-            x = np.linspace(0, self.x_perc_norm, 200)
-
-        y = scipy.stats.gamma.pdf(x, a=self.pdf_shape[0], loc=0, scale=1.)
-
-        return x, y
-
-    def icdf(self, p):
-        """
-        Inverse cumulative density function [0, 1]
-
-        Parameters
-        ----------
-        p: ndarray of float [n_p]
-            Cumulative probability
-
-        Returns
-        -------
-        x: ndarray of float [n_p]
-            Sample value of the random variable such that the probability of the variable being less than or equal
-            to that value equals the given probability.
-        """
-
-        # transform probabilities to perc constraint
-        p = self.p_perc * p
-
-        # icdf
-        x = scipy.stats.gamma.ppf(p.flatten(),
-                                  a=self.pdf_shape[0],
-                                  loc=0.,
-                                  scale=1.)
-
-        return x
-
-    def cdf_norm(self, x):
-        """
-        Cumulative density function defined in normalized parameter space [0, inf].
-
-        Parameters
-        ----------
-        x: ndarray of float [n_x]
-            Values of random variable (normalized) [0, inf]
-
-        Returns
-        -------
-        cdf: ndarray of float [n_x]
-            Cumulative density at values x [0, 1]
-        """
-        c = scipy.stats.gamma.cdf(x.flatten(),
-                                  a=self.pdf_shape[0],
-                                  loc=0.,
-                                  scale=1.)
-
-        return c
-
-    def cdf(self, x):
-        """
-        Cumulative density function.
-
-        Parameters
-        ----------
-        x: ndarray of float [n_x]
-            Values of random variable
-
-        Returns
-        -------
-        cdf: ndarray of float [n_x]
-            Cumulative density at values x [0, 1]
-        """
-        c = scipy.stats.gamma.cdf(x.flatten(),
-                                  a=self.pdf_shape[0],
-                                  scale=1/self.pdf_shape[1],
-                                  loc=self.pdf_shape[2])
-
-        return c
+import scipy.special
+import scipy.stats
+import numpy as np
+from .BasisFunction import *
+
+try:
+    import matplotlib.pyplot as plt
+except ImportError:
+    pass
+
+
+class RandomParameter(object):
+    """
+    RandomParameter class
+
+    Parameters
+    ----------
+    pdf_type : str
+        Distribution type of random variable ('beta', 'norm', 'gamma')
+    pdf_shape : list of float [2]
+        Shape parameters
+    pdf_limits : list of float [2]
+        Lower and upper bounds of random variable (if applicable)
+
+    Attributes
+    ----------
+    pdf_type : str
+        Distribution type of random variable ('beta', 'norm', 'gamma')
+    pdf_shape : list of float [2]
+        Shape parameters of beta distributed random variable [p, q]
+    pdf_limits : list of float [2]
+        Lower and upper bounds of random variable [min, max]
+    mean : float
+        Mean value
+    std : float
+        Standard deviation
+    var : float
+        Variance
+    """
+    def __init__(self, pdf_type=None, pdf_shape=None, pdf_limits=None):
+        """
+        Constructor; Initializes random parameter;
+        """
+
+        self.pdf_type = pdf_type
+        self.pdf_shape = np.array(pdf_shape).astype(float)
+        self.pdf_limits = np.array(pdf_limits).astype(float)
+        self.pdf_limits_norm = None
+        self.mean = None
+        self.std = None
+        self.var = None
+        self.p_perc = None
+
+    def pdf(self, x=None):
+        pass
+
+    def pdf_norm(self, x=None):
+        pass
+
+    def icdf(self, p):
+        pass
+
+    def plot_pdf(self, legend_str=None, norm=False):
+        """
+        Plots probability density function
+
+        Parameters
+        ----------
+        legend_str : str, optional, default: None
+            Legend string
+        norm : boolean, optional, default: False
+            Plot pdfs in normalized space [-1, 1]
+        """
+
+        if not norm:
+            # delta = self.pdf_limits[1] - self.pdf_limits[0]
+            # x = np.linspace(self.pdf_limits[0] - 0.0 * delta,
+            #                 self.pdf_limits[1] + 0.0 * delta, 200)
+            x, y = self.pdf()
+        else:
+            delta = 2.
+            # x = np.linspace(-1. - 0.0 * delta,
+            #                 +1. + 0.0 * delta, 200)
+            x, y = self.pdf_norm()
+
+        plt.plot(x, y)
+        plt.xlabel("x")
+        plt.ylabel("p(x)")
+        plt.grid(True)
+
+        if legend_str is not None:
+
+            if type(legend_str) is not list:
+                legend_str = [legend_str]
+
+            plt.legend(legend_str)
+
+        return plt
+
+
+class Beta(RandomParameter):
+    """
+    Beta distributed random variable sub-class
+
+    Parameters
+    ----------
+    pdf_shape: list of float [2]
+        Shape parameters of beta distributed random variable [p, q]
+    pdf_limits: list of float [2]
+        Lower and upper bounds of random variable [min, max]
+
+    Notes
+    -----
+    Probability density function:
+
+    .. math::
+
+       p(x) = \\left(\\frac{\\Gamma(p)\\Gamma(q)}{\\Gamma(p+q)}(b-a)^{(p+q-1)}\\right)^{-1} (x-a)^{(p-1)} (b-x)^{(q-1)}
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> pygpc.RandomParameter.Beta(pdf_shape=[5, 2], pdf_limits=[1.2, 2])
+    """
+
+    def __init__(self, pdf_shape, pdf_limits):
+        """
+        Constructor; Initializes beta distributed random variable
+        """
+
+        super(Beta, self).__init__(pdf_type='beta', pdf_shape=pdf_shape, pdf_limits=pdf_limits)
+
+        self.mean = float(self.pdf_shape[0]) / (self.pdf_shape[0] + self.pdf_shape[1]) * \
+                    (self.pdf_limits[1] - self.pdf_limits[0]) + self.pdf_limits[0]
+
+        self.std = np.sqrt(self.pdf_shape[0] * self.pdf_shape[1] / \
+                           ((self.pdf_shape[0] + self.pdf_shape[1] + 1) *
+                            (self.pdf_shape[0] + self.pdf_shape[1])**2)) * \
+                   (self.pdf_limits[1] - self.pdf_limits[0])
+
+        self.var = self.std**2
+        self.rv = scipy.stats.beta(a=self.pdf_shape[0], b=self.pdf_shape[1])
+
+        self.pdf_limits_norm = [-1, 1]
+
+    def sample(self, n_samples, normalized=True):
+        """
+        Samples random variable
+
+        Parameters
+        ----------
+        n_samples : int
+            Number of samples to draw
+        normalized : bool, optional, default: True
+            Return normalized value
+
+        Returns
+        -------
+        sample : ndarray of float [n_sample]
+            Sampling points
+        """
+        samples = 2 * self.rv.rvs(size=n_samples) - 1
+
+        if not normalized:
+            samples = (samples + 1) / 2 * (self.pdf_limits[1] - self.pdf_limits[0]) + self.pdf_limits[0]
+
+        return samples
+
+    def init_basis_function(self, order):
+        """
+        Initializes Jacobi BasisFunction of Beta RandomParameter
+
+        Parameters
+        ----------
+        order: int
+            Order of basis function
+        """
+        return Jacobi({"i": order, "p": self.pdf_shape[0], "q": self.pdf_shape[1]})
+
+    def pdf(self, x=None, a=None, b=None):
+        """
+        Calculate the probability density function of the beta distributed random variable.
+
+        Parameters
+        ----------
+        x: ndarray of float [n_x]
+            Values of random variable
+        a: float
+            Lower limit of beta distribution
+        b: float
+            Upper limit of beta distribution
+
+        Returns
+        -------
+        pdf: ndarray of float [n_x]
+            Probability density at values x
+        """
+
+        p = self.pdf_shape[0]
+        q = self.pdf_shape[1]
+
+        if a is None:
+            a = self.pdf_limits[0]
+
+        if b is None:
+            b = self.pdf_limits[1]
+
+        if x is None:
+            x = np.linspace(a, b, 200)
+
+        y = np.zeros(x.shape)
+
+        mask = np.logical_and(a < x, x < b)
+
+        y[mask] = (scipy.special.gamma(p) * scipy.special.gamma(q) / scipy.special.gamma(p + q)
+                   * (b - a) ** (p + q - 1)) ** (-1) * (x[mask] - a) ** (p - 1) * (b - x[mask]) ** (q - 1)
+
+        return x, y
+
+    def pdf_norm(self, x=None):
+        """
+        Calculate the probability density function of the normalized beta distributed random variable in interval
+        [-1, 1].
+
+        pdf = Beta.pdf_norm(x)
+
+        Parameters
+        ----------
+        x: ndarray of float [n_x]
+            Values of random variable
+
+        Returns
+        -------
+        pdf: ndarray of float [n_x]
+            Probability density at values x
+        """
+
+        if x is None:
+            x = np.linspace(-1, 1, 200)
+
+        x, y = self.pdf(x, a=-1., b=1.)
+
+        return x, y
+
+    def icdf(self, p):
+        """
+        Inverse cumulative density function [0, 1]
+
+        Parameters
+        ----------
+        p: ndarray of float [n_p]
+            Cumulative probability
+
+        Returns
+        -------
+        x: ndarray of float [n_p]
+            Sample value of the random variable such that the probability of the variable being less than or equal
+            to that value equals the given probability.
+        """
+        x = 2 * self.rv.ppf(p.flatten()) - 1
+
+        return x
+
+    def cdf_norm(self, x):
+        """
+        Cumulative density function defined in normalized parameter space [-1, 1].
+
+        Parameters
+        ----------
+        x: ndarray of float [n_x]
+            Values of random variable (normalized) [-1, 1]
+
+        Returns
+        -------
+        cdf: ndarray of float [n_x]
+            Cumulative density at values x [0, 1]
+        """
+        c = self.rv.cdf((x.flatten() + 1) / 2)
+
+        return c
+
+    def cdf(self, x):
+        """
+        Cumulative density function.
+
+        Parameters
+        ----------
+        x: ndarray of float [n_x]
+            Values of random variable
+
+        Returns
+        -------
+        cdf: ndarray of float [n_x]
+            Cumulative density at values x [0, 1]
+        """
+        c = self.rv.cdf((x.flatten() - self.pdf_limits[0]) / (self.pdf_limits[1] - self.pdf_limits[0]))
+
+        return c
+
+
+class Norm(RandomParameter):
+    """
+    Normal distributed random variable sub-class
+
+    Parameters
+    ----------
+    pdf_shape: list of float [2]
+        Shape parameters of normal distributed random variable [mean, std]
+    p_perc: float, optional, default=0.9973
+        Probability of percentile, where infinite distributions are cut off
+        (default value corresponds to 6 sigma)
+
+    Notes
+    -----
+    Probability density function
+
+    .. math::
+
+       p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left({-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\right)
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> pygpc.RandomParameter.Norm(pdf_shape=[0.1, 0.15])
+    """
+
+    def __init__(self, pdf_shape, p_perc=0.9973):
+        """
+        Constructor; Initializes normal distributed random variable
+        """
+
+        self.x_perc = [None, None]
+        self.x_perc[0] = scipy.stats.norm().ppf(0.5*(1-p_perc)) * pdf_shape[1] + pdf_shape[0]
+        self.x_perc[1] = scipy.stats.norm().ppf(0.5*(1+p_perc)) * pdf_shape[1] + pdf_shape[0]
+
+        self.x_perc_norm = [None, None]
+        self.x_perc_norm[0] = scipy.stats.norm().ppf(0.5 * (1 - p_perc))
+        self.x_perc_norm[1] = scipy.stats.norm().ppf(0.5 * (1 + p_perc))
+
+        super(Norm, self).__init__(pdf_type='norm',
+                                   pdf_shape=pdf_shape,
+                                   pdf_limits=[self.x_perc[0], self.x_perc[1]])
+
+        self.p_perc = p_perc
+        self.mean = self.pdf_shape[0]
+        self.std = self.pdf_shape[1]
+        self.var = self.std ** 2
+        self.pdf_limits_norm = [self.x_perc_norm[0], self.x_perc_norm[1]]
+        self.rv = scipy.stats.norm()
+
+    def sample(self, n_samples, normalized=True):
+        """
+        Samples random variable
+
+        Parameters
+        ----------
+        n_samples : int
+            Number of samples to draw
+        normalized : bool, optional, default: True
+            Return normalized value
+
+        Returns
+        -------
+        sample : ndarray of float [n_sample]
+            Sampling points
+        """
+        samples = self.rv.rvs(size=n_samples)
+
+        if not normalized:
+            samples = samples * self.pdf_shape[1] + self.pdf_shape[0]
+
+        return samples
+
+    @staticmethod
+    def init_basis_function(order):
+        """
+        Initializes Hermite BasisFunction of Norm RandomParameter
+
+        Parameters
+        ----------
+        order: int
+            Order of basis function
+        """
+        return Hermite({"i": order})
+
+    def pdf(self, x=None):
+        """
+        Calculate the probability density function of the normal distributed random variable.
+
+        pdf = Norm.pdf(x)
+
+        Parameters
+        ----------
+        x: ndarray of float [n_x]
+            Values of random variable
+
+        Returns
+        -------
+        pdf: ndarray of float [n_x]
+            Probability density
+        """
+        if x is None:
+            x = np.linspace(self.x_perc[0], self.x_perc[1], 200)
+
+        y = scipy.stats.norm.pdf(x, loc=self.pdf_shape[0], scale=self.pdf_shape[1])
+
+        return x, y
+
+    def pdf_norm(self, x=None):
+        """
+        Calculate the probability density function of the normalized normal distributed random variable
+        (zero mean, std 1).
+
+        pdf = Norm.pdf_norm(x)
+
+        Parameters
+        ----------
+        x: ndarray of float [n_x]
+            Values of random variable in interval [-1, 1]
+
+        Returns
+        -------
+        pdf: ndarray of float [n_x]
+            Probability density
+        """
+        if x is None:
+            x = np.linspace(self.x_perc_norm[0], self.x_perc_norm[1], 200)
+
+        y = scipy.stats.norm.pdf(x, loc=0, scale=1.)
+
+        return x, y
+
+    def icdf(self, p):
+        """
+        Inverse cumulative density function [0, 1]
+
+        Parameters
+        ----------
+        p: ndarray of float [n_p]
+            Cumulative probability
+
+        Returns
+        -------
+        x: ndarray of float [n_p]
+            Sample value of the random variable such that the probability of the variable being less than or equal
+            to that value equals the given probability.
+        """
+        # transform probabilities to perc constraint
+        p = self.p_perc * p + (1 - self.p_perc)/2
+
+        # icdf
+        x = self.rv.ppf(p.flatten())
+
+        return x
+
+    def cdf_norm(self, x):
+        """
+        Cumulative density function defined in normalized parameter space (mean=0, std=1).
+
+        Parameters
+        ----------
+        x: ndarray of float [n_x]
+            Values of random variable (normalized, mean=0, std=1)
+
+        Returns
+        -------
+        cdf: ndarray of float [n_x]
+            Cumulative density at values x [0, 1]
+        """
+        c = self.rv.cdf(x.flatten())
+
+        return c
+
+    def cdf(self, x):
+        """
+        Cumulative density function.
+
+        Parameters
+        ----------
+        x: ndarray of float [n_x]
+            Values of random variable
+
+        Returns
+        -------
+        cdf: ndarray of float [n_x]
+            Cumulative density at values x [0, 1]
+        """
+        n = scipy.stats.norm(loc=self.pdf_shape[0], scale=self.pdf_shape[1])
+        c = n.cdf(x.flatten())
+
+        return c
+
+
+class Gamma(RandomParameter):
+    """
+    Gamma distributed random variable sub-class
+
+    Parameters
+    ----------
+    pdf_shape: list of float [3]
+        Shape parameters of gamma distributed random variable [shape, rate, loc] (=[alpha, beta, location])
+    p_perc: float, optional, default=0.9973
+        Probability of percentile, where infinite distributions are cut off
+        (default value corresponds to 6 sigma from normal distribution)
+
+    Notes
+    -----
+    Probability density function:
+
+    .. math::
+
+       p(x) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}x^{\\alpha-1}e^{\\beta x}
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> pygpc.RandomParameter.Gamma(pdf_shape=[5, 2, 1.2])
+    """
+    def __init__(self, pdf_shape, p_perc=0.9973):
+        """
+        Constructor; Initializes gamma distributed random variable
+        """
+
+        self.x_perc = scipy.stats.gamma.ppf(p_perc,
+                                            a=pdf_shape[0],
+                                            loc=pdf_shape[2],
+                                            scale=1 / pdf_shape[1])
+
+        self.x_perc_norm = scipy.stats.gamma.ppf(p_perc,
+                                                 a=pdf_shape[0],
+                                                 loc=0.,
+                                                 scale=1.)
+
+        super(Gamma, self).__init__(pdf_type='gamma',
+                                    pdf_shape=pdf_shape,
+                                    pdf_limits=[pdf_shape[2], self.x_perc])
+
+        self.p_perc = p_perc
+
+        self.mean = self.pdf_shape[0] / self.pdf_shape[1] + self.pdf_shape[2]
+
+        self.std = np.sqrt(self.pdf_shape[0] / self.pdf_shape[1]**2)
+
+        self.var = self.std**2
+
+        self.pdf_limits_norm = [0, self.x_perc_norm]
+
+    def sample(self, n_samples, normalized=True):
+        """
+        Samples random variable
+
+        Parameters
+        ----------
+        n_samples : int
+            Number of samples to draw
+        normalized : bool, optional, default: True
+            Return normalized value
+
+        Returns
+        -------
+        sample : ndarray of float [n_sample]
+            Sampling points
+        """
+
+        samples = scipy.stats.gamma.rvs(size=n_samples,
+                                        a=self.pdf_shape[0],
+                                        loc=0.,
+                                        scale=1.)
+
+        if not normalized:
+            samples = samples + self.pdf_shape[2]
+
+        return samples
+
+    def init_basis_function(self, order):
+        """
+        Initializes Jacobi BasisFunction of Beta RandomParameter
+
+        Parameters
+        ----------
+        order: int
+            Order of basis function
+        """
+        return Laguerre({"i": order, "alpha": self.pdf_shape[0]-1, "beta": self.pdf_shape[1]})
+
+    def pdf(self, x=None):
+        """
+        Calculate the probability density function of the beta distributed random variable.
+
+        pdf = Gamma.pdf(x)
+
+        Parameters
+        ----------
+        x: ndarray of float [n_x]
+            Values of random variable
+
+        Returns
+        -------
+        pdf: ndarray of float [n_x]
+            Probability density at values x
+        """
+
+        a = self.pdf_shape[0]
+        b = self.pdf_shape[1]
+        loc = self.pdf_shape[2]
+
+        if x is None:
+            x = np.linspace(0, self.x_perc, 200)
+
+        y = scipy.stats.gamma.pdf(x, a=a, loc=loc, scale=1/b)
+        # y = b**a/scipy.special.gamma(a) * (x-loc)**(a-1) * np.exp(-b*(x-loc))
+
+        return x, y
+
+    def pdf_norm(self, x=None):
+        """
+        Calculate the probability density function of the normalized gamma distributed random variable in interval
+        [-1, 1].
+
+        pdf = Gamma.pdf_norm(x)
+
+        Parameters
+        ----------
+        x: ndarray of float [n_x]
+            Values of random variable in interval [-1, 1]
+
+        Returns
+        -------
+        pdf: ndarray of float [n_x]
+            Probability density at values x
+        """
+        if x is None:
+            x = np.linspace(0, self.x_perc_norm, 200)
+
+        y = scipy.stats.gamma.pdf(x, a=self.pdf_shape[0], loc=0, scale=1.)
+
+        return x, y
+
+    def icdf(self, p):
+        """
+        Inverse cumulative density function [0, 1]
+
+        Parameters
+        ----------
+        p: ndarray of float [n_p]
+            Cumulative probability
+
+        Returns
+        -------
+        x: ndarray of float [n_p]
+            Sample value of the random variable such that the probability of the variable being less than or equal
+            to that value equals the given probability.
+        """
+
+        # transform probabilities to perc constraint
+        p = self.p_perc * p
+
+        # icdf
+        x = scipy.stats.gamma.ppf(p.flatten(),
+                                  a=self.pdf_shape[0],
+                                  loc=0.,
+                                  scale=1.)
+
+        return x
+
+    def cdf_norm(self, x):
+        """
+        Cumulative density function defined in normalized parameter space [0, inf].
+
+        Parameters
+        ----------
+        x: ndarray of float [n_x]
+            Values of random variable (normalized) [0, inf]
+
+        Returns
+        -------
+        cdf: ndarray of float [n_x]
+            Cumulative density at values x [0, 1]
+        """
+        c = scipy.stats.gamma.cdf(x.flatten(),
+                                  a=self.pdf_shape[0],
+                                  loc=0.,
+                                  scale=1.)
+
+        return c
+
+    def cdf(self, x):
+        """
+        Cumulative density function.
+
+        Parameters
+        ----------
+        x: ndarray of float [n_x]
+            Values of random variable
+
+        Returns
+        -------
+        cdf: ndarray of float [n_x]
+            Cumulative density at values x [0, 1]
+        """
+        c = scipy.stats.gamma.cdf(x.flatten(),
+                                  a=self.pdf_shape[0],
+                                  scale=1/self.pdf_shape[1],
+                                  loc=self.pdf_shape[2])
+
+        return c
```

## pygpc/SGPC.py

 * *Ordering differences only*

```diff
@@ -1,617 +1,617 @@
-import time
-import random
-import numpy as np
-import scipy.stats
-from scipy.special import binom
-from .sobol_saltelli import get_sobol_indices_saltelli
-from .sobol_saltelli import saltelli_sampling
-from .io import iprint, wprint
-from .misc import display_fancy_bar
-from .misc import get_array_unique_rows
-from .GPC import *
-from .Basis import *
-
-
-class SGPC(GPC):
-    """
-    Sub-class for standard gPC (SGPC)
-
-    Parameters
-    ----------
-    problem: Problem class instance
-        GPC Problem under investigation
-    order: list of int [dim]
-        Maximum individual expansion order [order_1, order_2, ..., order_dim].
-        Generates individual polynomials also if maximum expansion order in order_max is exceeded
-    order_max: int
-        Maximum global expansion order.
-        The maximum expansion order considers the sum of the orders of combined polynomials together with the
-        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
-        monomial orders.
-    order_max_norm: float
-        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
-        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
-        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
-        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
-    interaction_order: int
-        Number of random variables, which can interact with each other.
-        All polynomials are ignored, which have an interaction order greater than the specified
-    interaction_order_current: int, optional, default: interaction_order
-        Number of random variables currently interacting with respect to the highest order.
-        (interaction_order_current <= interaction_order)
-        The parameters for lower orders are all interacting with "interaction order".
-    options : dict
-        Options of gPC
-    validation: ValidationSet object (optional)
-        Object containing a set of validation points and corresponding solutions. Can be used
-        to validate gpc approximation setting options["error_type"]="nrmsd".
-        - grid: Grid object containing the validation points (grid.coords, grid.coords_norm)
-        - results: ndarray [n_grid x n_out] results
-
-    Notes
-    -----
-    .. [1] Blatman, G., & Sudret, B. (2011). Adaptive sparse polynomial chaos expansion based on least angle
-       regression. Journal of Computational Physics, 230(6), 2345-2367.
-
-    Attributes
-    ----------
-    order: list of int [dim]
-        Maximum individual expansion order [order_1, order_2, ..., order_dim].
-        Generates individual polynomials also if maximum expansion order in order_max is exceeded
-    order_max: int
-        Maximum global expansion order.
-        The maximum expansion order considers the sum of the orders of combined polynomials together with the
-        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
-        monomial orders.
-    order_max_norm: float
-            Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
-            of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
-            is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
-            where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
-    interaction_order: int
-        Number of random variables, which can interact with each other.
-        All polynomials are ignored, which have an interaction order greater than the specified
-    interaction_order_current: int
-        Number of random variables currently interacting with respect to the highest order.
-        (interaction_order_current <= interaction_order)
-        The parameters for lower orders are all interacting with "interaction order".
-    options : dict
-        Options of gPC
-    validation: ValidationSet object (optional)
-        Object containing a set of validation points and corresponding solutions. Can be used
-        to validate gpc approximation setting options["error_type"]="nrmsd".
-        - grid: Grid object containing the validation points (grid.coords, grid.coords_norm)
-        - results: ndarray [n_grid x n_out] results
-    """
-
-    def __init__(self, problem, order_max, interaction_order=None,
-                 order=None, options=None, order_max_norm=1.0, interaction_order_current=None, validation=None):
-        """
-        Constructor; Initializes the SGPC class
-        """
-        super(SGPC, self).__init__(problem, options, validation)
-
-        if order is None:
-            order = [order_max] * problem.dim
-
-        if interaction_order is None:
-            interaction_order = problem.dim
-
-        self.order = order
-        self.order_max = order_max
-        self.order_max_norm = order_max_norm
-        self.interaction_order = interaction_order
-
-        if interaction_order_current is None:
-            self.interaction_order_current = interaction_order
-        else:
-            self.interaction_order_current = interaction_order_current
-
-        self.basis = Basis()
-        self.basis.init_basis_sgpc(problem=problem,
-                                   order=order,
-                                   order_max=order_max,
-                                   order_max_norm=order_max_norm,
-                                   interaction_order=interaction_order,
-                                   interaction_order_current=interaction_order_current)
-
-    @staticmethod
-    def get_mean(coeffs=None, samples=None):
-        """
-        Calculate the expected mean value. Provide either gPC coeffs or a certain number of samples.
-
-        mean = SGPC.get_mean(coeffs)
-
-        Parameters
-        ----------
-        coeffs : ndarray of float [n_basis x n_out], optional, default: None
-            GPC coefficients
-        samples : ndarray of float [n_samples x n_out], optional, default: None
-            Model evaluations from gPC approximation
-
-        Returns
-        -------
-        mean: ndarray of float [1 x n_out]
-            Expected value of output quantities
-        """
-        if coeffs is not None:
-            mean = coeffs[0, ]
-
-        elif samples is not None:
-            mean = np.mean(samples, axis=0)
-
-        else:
-            raise AssertionError("Provide either ""coeffs"" or ""samples"" to determine mean!")
-
-        # mean = mean[np.newaxis, :]
-
-        return mean
-
-    @staticmethod
-    def get_std(coeffs=None, samples=None):
-        """
-        Calculate the standard deviation. Provide either gPC coeffs or a certain number of samples.
-
-        std = SGPC.get_std(coeffs)
-
-        Parameters
-        ----------
-        coeffs: ndarray of float [n_basis x n_out], optional, default: None
-            GPC coefficients
-        samples : ndarray of float [n_samples x n_out], optional, default: None
-            Model evaluations from gPC approximation
-
-        Returns
-        -------
-        std: ndarray of float [1 x n_out]
-            Standard deviation of output quantities
-        """
-        if coeffs is not None:
-            std = np.sqrt(np.sum(np.square(coeffs[1:]), axis=0))
-
-        elif samples is not None:
-            std = np.std(samples, axis=0)
-
-        else:
-            raise AssertionError("Provide either ""coeffs"" or ""samples"" to determine standard deviation!")
-
-        # std = std[np.newaxis, :]
-
-        return std
-
-    # noinspection PyTypeChecker
-    def get_sobol_indices(self, coeffs, algorithm="standard", n_samples=1e4):
-        """
-        Calculate the available sobol indices from the gPC coefficients (standard) or by sampling.
-        In case of sampling, the Sobol indices are calculated up to second order.
-
-        sobol, sobol_idx, sobol_idx_bool = SGPC.get_sobol_indices(coeffs, algorithm="standard", n_samples=1e4)
-
-        Parameters
-        ----------
-        coeffs:  ndarray of float [n_basis x n_out]
-            GPC coefficients
-        algorithm : str, optional, default: "standard"
-            Algorithm to determine the Sobol indices
-            - "standard": Sobol indices are determined from the gPC coefficients
-            - "sampling": Sobol indices are determined from sampling using Saltelli's Sobol sampling sequence [1, 2, 3]
-        n_samples : int, optional, default: 1e4
-            Number of samples to determine Sobol indices by sampling. The efficient number of samples
-            increases to n_samples * (2*dim + 2) in Saltelli's Sobol sampling sequence.
-
-        Returns
-        -------
-        sobol: ndarray of float [n_sobol x n_out]
-            Normalized Sobol indices w.r.t. total variance
-        sobol_idx: list of ndarray of int [n_sobol x (n_sobol_included)]
-            Parameter combinations in rows of sobol.
-        sobol_idx_bool: ndarray of bool [n_sobol x dim]
-            Boolean mask which contains unique multi indices.
-
-        Notes
-        -----
-        .. [1] Sobol, I. M. (2001).  "Global sensitivity indices for nonlinear
-               mathematical models and their Monte Carlo estimates."  Mathematics
-               and Computers in Simulation, 55(1-3):271-280,
-               doi:10.1016/S0378-4754(00)00270-6.
-        .. [2] Saltelli, A. (2002).  "Making best use of model evaluations to
-               compute sensitivity indices."  Computer Physics Communications,
-               145(2):280-297, doi:10.1016/S0010-4655(02)00280-1.
-        .. [3] Saltelli, A., P. Annoni, I. Azzini, F. Campolongo, M. Ratto, and
-               S. Tarantola (2010).  "Variance based sensitivity analysis of model
-               output.  Design and estimator for the total sensitivity index."
-               Computer Physics Communications, 181(2):259-270,
-               doi:10.1016/j.cpc.2009.09.018.
-        """
-
-        # iprint("Determining Sobol indices...", tab=0)
-
-        if algorithm == "standard":
-            if self.p_matrix is not None:
-                raise NotImplementedError("Please use algorithm='sampling' in case of reduced gPC (projection).")
-
-            # handle (N,) arrays
-            if len(coeffs.shape) == 1:
-                n_out = 1
-            else:
-                n_out = coeffs.shape[1]
-
-            n_coeffs = coeffs.shape[0]
-
-            if n_coeffs == 1:
-                raise Exception('Number of coefficients is 1 ... no Sobol indices to calculate ...')
-
-            # Generate boolean matrix of all basis functions where order > 0 = True
-            # size: [n_basis x dim]
-            multi_indices = np.array([list(map(lambda _b:_b.p["i"], b_row)) for b_row in self.basis.b])
-            sobol_mask = multi_indices != 0
-
-            # look for unique combinations (i.e. available sobol combinations)
-            # size: [N_sobol x dim]
-            sobol_idx_bool = get_array_unique_rows(sobol_mask)
-
-            # delete the first row where all polynomials are order 0 (no sensitivity)
-            sobol_idx_bool = np.delete(sobol_idx_bool, [0], axis=0)
-            n_sobol_available = sobol_idx_bool.shape[0]
-
-            # check which basis functions contribute to which sobol coefficient set
-            # True for specific coeffs if it contributes to sobol coefficient
-            # size: [N_coeffs x N_sobol]
-            sobol_poly_idx = np.zeros([n_coeffs, n_sobol_available])
-
-            for i_sobol in range(n_sobol_available):
-                sobol_poly_idx[:, i_sobol] = np.all(sobol_mask == sobol_idx_bool[i_sobol], axis=1)
-
-            # calculate sobol coefficients matrix by summing up the individual
-            # contributions to the respective sobol coefficients
-            # size [N_sobol x N_points]
-            sobol = np.zeros([n_sobol_available, n_out])
-
-            for i_sobol in range(n_sobol_available):
-                sobol[i_sobol] = np.sum(np.square(coeffs[sobol_poly_idx[:, i_sobol] == 1]), axis=0)
-
-            # sort sobol coefficients in descending order (w.r.t. first output only ...)
-            idx_sort_descend_1st = np.argsort(sobol[:, 0], axis=0)[::-1]
-            sobol = sobol[idx_sort_descend_1st, :]
-            sobol_idx_bool = sobol_idx_bool[idx_sort_descend_1st]
-
-            # get list of sobol indices
-            sobol_idx = [0 for _ in range(sobol_idx_bool.shape[0])]
-
-            for i_sobol in range(sobol_idx_bool.shape[0]):
-                sobol_idx[i_sobol] = np.array([i for i, x in enumerate(sobol_idx_bool[i_sobol, :]) if x])
-
-            var = self.get_std(coeffs=coeffs) ** 2
-
-            sobol = sobol / var
-
-        elif algorithm == "sampling":
-
-            if self.p_matrix is None:
-                dim = self.problem.dim
-            else:
-                dim = self.problem_original.dim
-
-            if self.problem_original is None:
-                problem_original = self.problem
-            else:
-                problem_original = self.problem_original
-
-            # generate uniform distributed sobol sequence (parameter space [0, 1])
-            coords_norm_01 = saltelli_sampling(n_samples=n_samples, dim=dim, calc_second_order=True)
-            coords_norm = np.zeros(coords_norm_01.shape)
-
-            # transform to respective input pdfs using inverse cdfs
-            for i_key, key in enumerate(problem_original.parameters_random.keys()):
-                coords_norm[:, i_key] = problem_original.parameters_random[key].icdf(coords_norm_01[:, i_key])
-
-            # run model evaluations
-            res = self.get_approximation(coeffs=coeffs, x=coords_norm)
-
-            # determine sobol indices
-            sobol, sobol_idx, sobol_idx_bool = get_sobol_indices_saltelli(y=res,
-                                                                          dim=dim,
-                                                                          calc_second_order=True,
-                                                                          num_resamples=100,
-                                                                          conf_level=0.95)
-
-            # sort
-            idx = np.flip(np.argsort(sobol[:, 0], axis=0))
-            sobol = sobol[idx, :]
-            sobol_idx = [sobol_idx[i] for i in idx]
-            sobol_idx_bool = sobol_idx_bool[idx, :]
-
-        else:
-            raise AssertionError("Please provide valid algorithm argument (""standard"" or ""sampling"")")
-
-        return sobol, sobol_idx, sobol_idx_bool
-
-    # noinspection PyTypeChecker
-    def get_global_sens(self, coeffs, algorithm="standard", n_samples=1e5):
-        """
-        Determine the global derivative based sensitivity coefficients after Xiu (2009) [1]
-        from the gPC coefficients (standard) or by sampling.
-
-        global_sens = SGPC.get_global_sens(coeffs, algorithm="standard", n_samples=1e5)
-
-        Parameters
-        ----------
-        coeffs: ndarray of float [n_basis x n_out], optional, default: None
-            GPC coefficients
-        algorithm : str, optional, default: "standard"
-            Algorithm to determine the Sobol indices
-            - "standard": Sobol indices are determined from the gPC coefficients
-            - "sampling": Sobol indices are determined from sampling using Saltelli's Sobol sampling sequence [1, 2, 3]
-        n_samples : int, optional, default: 1e4
-            Number of samples
-
-        Returns
-        -------
-        global_sens: ndarray [dim x n_out]
-            Global derivative based sensitivity coefficients
-
-        Notes
-        -----
-        .. [1] D. Xiu, Fast Numerical Methods for Stochastic Computations: A Review,
-           Commun. Comput. Phys., 5 (2009), pp. 242-272 eq. (3.14) page 255
-        """
-
-        if algorithm == "standard":
-            b_int_global = np.zeros([self.problem.dim, self.basis.n_basis])
-
-            # construct matrix with integral expressions [n_basis x dim]
-            b_int = np.array([list(map(lambda _b: _b.fun_int, b_row)) for b_row in self.basis.b])
-            b_int_der = np.array([list(map(lambda _b: _b.fun_der_int, b_row)) for b_row in self.basis.b])
-
-            for i_sens in range(self.problem.dim):
-                # replace column with integral expressions from derivative of parameter[i_dim]
-                tmp = copy.deepcopy(b_int)
-                tmp[:, i_sens] = b_int_der[:, i_sens]
-
-                # determine global integral expression
-                b_int_global[i_sens, :] = np.prod(tmp, axis=1)
-
-            global_sens = np.matmul(b_int_global, coeffs) / (2 ** self.problem.dim)
-            # global_sens = np.matmul(b_int_global, coeffs)
-
-        elif algorithm == "sampling":
-            # generate sample coordinates (original parameter space)
-            if self.p_matrix is not None:
-                grid = Random(parameters_random=self.problem_original.parameters_random,
-                              n_grid=n_samples,
-                              options=None)
-            else:
-                grid = Random(parameters_random=self.problem.parameters_random,
-                              n_grid=n_samples,
-                              options=None)
-
-            local_sens = self.get_local_sens(coeffs, grid.coords_norm)
-
-            # # transform the coordinates to the reduced parameter space
-            # coords_norm = np.matmul(coords_norm, self.p_matrix.transpose() / self.p_matrix_norm[np.newaxis, :])
-            #
-            # # construct gPC gradient matrix [n_samples x n_basis x dim_red]
-            # gpc_matrix_gradient = self.calc_gpc_matrix(b=self.basis.b, x=coords_norm, gradient=True)
-            #
-            # # determine gradient in each sampling point [n_samples x n_out x dim_red]
-            # grad_samples_projected = np.matmul(gpc_matrix_gradient.transpose(2, 0, 1), coeffs).transpose(1, 2, 0)
-            #
-            # # project the gradient back to the original parameter space if necessary [n_samples x n_out x dim]
-            # grad_samples = np.matmul(grad_samples_projected, self.p_matrix / self.p_matrix_norm[:, np.newaxis])
-
-            # average the results and reshape [dim x n_out]
-            global_sens = np.mean(local_sens, axis=0).transpose()
-
-        else:
-            raise AssertionError("Please provide valid algorithm argument (""standard"" or ""sampling"")")
-
-        return global_sens
-
-    # noinspection PyTypeChecker
-    def get_local_sens(self, coeffs, x=None):
-        """
-        Determine the local derivative based sensitivity coefficients in the point of interest x
-        (normalized coordinates [-1, 1]).
-
-        local_sens = SGPC.calc_localsens(coeffs, x)
-
-        Parameters
-        ----------
-        coeffs: ndarray of float [n_basis x n_out]
-            GPC coefficients
-        x: ndarray of float [dim], optional, default: center of parameter space
-            Point in variable space to evaluate local sensitivity in (normalized coordinates [-1, 1])
-
-        Returns
-        -------
-        local_sens: ndarray [dim x n_out]
-            Local sensitivity of output quantities in point x
-        """
-
-        if x is None:
-            x = np.zeros(self.problem.dim)[np.newaxis, :]
-
-        # project coordinate to reduced parameter space if necessary
-        if self.p_matrix is not None:
-            x = np.matmul(x, self.p_matrix.transpose() / self.p_matrix_norm[np.newaxis, :])
-
-        # construct gPC gradient matrix [n_samples x n_basis x dim(_red)]
-        gpc_matrix_gradient = self.create_gpc_matrix(b=self.basis.b,
-                                                     x=x,
-                                                     gradient=True,
-                                                     gradient_idx=np.arange(x.shape[0]))
-
-        local_sens = np.matmul(gpc_matrix_gradient.transpose(2, 0, 1), coeffs).transpose(1, 2, 0)
-
-        # project the gradient back to the original space if necessary
-        if self.p_matrix is not None:
-            local_sens = np.matmul(local_sens, self.p_matrix / self.p_matrix_norm[:, np.newaxis])
-
-        return local_sens
-
-
-class Reg(SGPC):
-    """
-    Regression gPC subclass
-
-    Parameters
-    ----------
-    problem: Problem class instance
-        GPC Problem under investigation
-    order: list of int [dim]
-        Maximum individual expansion order [order_1, order_2, ..., order_dim].
-        Generates individual polynomials also if maximum expansion order in order_max is exceeded
-    order_max: int
-        Maximum global expansion order.
-        The maximum expansion order considers the sum of the orders of combined polynomials together with the
-        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
-        monomial orders.
-    order_max_norm: float
-        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
-        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
-        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
-        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
-    interaction_order: int
-        Number of random variables, which can interact with each other.
-        All polynomials are ignored, which have an interaction order greater than the specified
-    interaction_order_current: int, optional, default: interaction_order
-        Number of random variables currently interacting with respect to the highest order.
-        (interaction_order_current <= interaction_order)
-        The parameters for lower orders are all interacting with "interaction order".
-    options : dict
-        Options of gPC
-    validation: ValidationSet object (optional)
-        Object containing a set of validation points and corresponding solutions. Can be used
-        to validate gpc approximation setting options["error_type"]="nrmsd".
-        - grid: Grid object containing the validation points (grid.coords, grid.coords_norm)
-        - results: ndarray [n_grid x n_out] results
-
-    Notes
-    -----
-    .. [1] Blatman, G., & Sudret, B. (2011). Adaptive sparse polynomial chaos expansion based on least angle
-       regression. Journal of Computational Physics, 230(6), 2345-2367.
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> gpc = pygpc.Reg(problem=problem,
-    >>>                 order=[7, 6],
-    >>>                 order_max=5,
-    >>>                 order_max_norm=1,
-    >>>                 interaction_order=2,
-    >>>                 interaction_order_current=1
-    >>>                 fn_results="/tmp/my_results")
-
-    Attributes
-    ----------
-    solver: str
-        Solver to determine the gPC coefficients
-        - 'Moore-Penrose' ... Pseudoinverse of gPC matrix (SGPC.Reg, EGPC)
-        - 'OMP' ... Orthogonal Matching Pursuit, sparse recovery approach (SGPC.Reg, EGPC)
-        - 'NumInt' ... Numerical integration, spectral projection (SGPC.Quad)
-    settings: dict
-        Solver settings
-        - 'Moore-Penrose' ... None
-        - 'OMP' ... {"n_coeffs_sparse": int} Number of gPC coefficients != 0
-        - 'NumInt' ... None
-    """
-
-    def __init__(self, problem, order_max, order=None, order_max_norm=1.0,
-                 interaction_order=None, options=None, interaction_order_current=None, validation=None):
-        """
-        Constructor; Initializes Regression SGPC class
-        """
-
-        if interaction_order_current is None:
-            self.interaction_order_current = interaction_order
-        else:
-            self.interaction_order_current = interaction_order_current
-
-        super(Reg, self).__init__(problem=problem,
-                                  order=order,
-                                  order_max=order_max,
-                                  order_max_norm=order_max_norm,
-                                  interaction_order=interaction_order,
-                                  interaction_order_current=interaction_order_current,
-                                  options=options,
-                                  validation=validation)
-
-        self.solver = 'Moore-Penrose'   # Default solver
-        self.settings = None            # Default Solver settings
-
-
-class Quad(SGPC):
-    """
-    Quadrature SGPC sub-class
-
-    Parameters
-    ----------
-    problem: Problem class instance
-        GPC Problem under investigation
-    order: list of int [dim]
-        Maximum individual expansion order [order_1, order_2, ..., order_dim].
-        Generates individual polynomials also if maximum expansion order in order_max is exceeded
-    order_max: int
-        Maximum global expansion order.
-        The maximum expansion order considers the sum of the orders of combined polynomials together with the
-        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
-        monomial orders.
-    order_max_norm: float
-        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
-        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
-        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
-        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
-    interaction_order: int
-        Number of random variables, which can interact with each other.
-        All polynomials are ignored, which have an interaction order greater than the specified
-    interaction_order_current: int, optional, default: interaction_order
-        Number of random variables currently interacting with respect to the highest order.
-        (interaction_order_current <= interaction_order)
-        The parameters for lower orders are all interacting with "interaction order".
-    options : dict
-        Options of gPC
-    validation: ValidationSet object (optional)
-        Object containing a set of validation points and corresponding solutions. Can be used
-        to validate gpc approximation setting options["error_type"]="nrmsd".
-        - grid: Grid object containing the validation points (grid.coords, grid.coords_norm)
-        - results: ndarray [n_grid x n_out] results
-
-    Notes
-    -----
-    .. [1] Blatman, G., & Sudret, B. (2011). Adaptive sparse polynomial chaos expansion based on least angle
-       regression. Journal of Computational Physics, 230(6), 2345-2367.
-
-    Examples
-    --------
-    >>> import pygpc
-    >>> gpc = pygpc.Quad(problem=problem,
-    >>>                  order=[7, 6],
-    >>>                  order_max=5,
-    >>>                  order_max_norm=1,
-    >>>                  interaction_order=2,
-    >>>                  interaction_order_current=1,
-    >>>                  fn_results="/tmp/my_results")
-    """
-
-    def __init__(self, problem, order, order_max, order_max_norm, interaction_order, options,
-                 interaction_order_current=None, validation=None):
-        """
-        Constructor; Initializes Quadrature SGPC sub-class
-        """
-
-        if interaction_order_current is None:
-            self.interaction_order_current = interaction_order
-        else:
-            self.interaction_order_current = interaction_order_current
-
-        super(Quad, self).__init__(problem=problem,
-                                   order=order,
-                                   order_max=order_max,
-                                   order_max_norm=order_max_norm,
-                                   interaction_order=interaction_order,
-                                   interaction_order_current=interaction_order_current,
-                                   options=options,
-                                   validation=validation)
-
-        self.solver = 'NumInt'  # Default solver
-        self.settings = None    # Default solver settings
+import time
+import random
+import numpy as np
+import scipy.stats
+from scipy.special import binom
+from .sobol_saltelli import get_sobol_indices_saltelli
+from .sobol_saltelli import saltelli_sampling
+from .io import iprint, wprint
+from .misc import display_fancy_bar
+from .misc import get_array_unique_rows
+from .GPC import *
+from .Basis import *
+
+
+class SGPC(GPC):
+    """
+    Sub-class for standard gPC (SGPC)
+
+    Parameters
+    ----------
+    problem: Problem class instance
+        GPC Problem under investigation
+    order: list of int [dim]
+        Maximum individual expansion order [order_1, order_2, ..., order_dim].
+        Generates individual polynomials also if maximum expansion order in order_max is exceeded
+    order_max: int
+        Maximum global expansion order.
+        The maximum expansion order considers the sum of the orders of combined polynomials together with the
+        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
+        monomial orders.
+    order_max_norm: float
+        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
+        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
+        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
+        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
+    interaction_order: int
+        Number of random variables, which can interact with each other.
+        All polynomials are ignored, which have an interaction order greater than the specified
+    interaction_order_current: int, optional, default: interaction_order
+        Number of random variables currently interacting with respect to the highest order.
+        (interaction_order_current <= interaction_order)
+        The parameters for lower orders are all interacting with "interaction order".
+    options : dict
+        Options of gPC
+    validation: ValidationSet object (optional)
+        Object containing a set of validation points and corresponding solutions. Can be used
+        to validate gpc approximation setting options["error_type"]="nrmsd".
+        - grid: Grid object containing the validation points (grid.coords, grid.coords_norm)
+        - results: ndarray [n_grid x n_out] results
+
+    Notes
+    -----
+    .. [1] Blatman, G., & Sudret, B. (2011). Adaptive sparse polynomial chaos expansion based on least angle
+       regression. Journal of Computational Physics, 230(6), 2345-2367.
+
+    Attributes
+    ----------
+    order: list of int [dim]
+        Maximum individual expansion order [order_1, order_2, ..., order_dim].
+        Generates individual polynomials also if maximum expansion order in order_max is exceeded
+    order_max: int
+        Maximum global expansion order.
+        The maximum expansion order considers the sum of the orders of combined polynomials together with the
+        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
+        monomial orders.
+    order_max_norm: float
+            Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
+            of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
+            is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
+            where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
+    interaction_order: int
+        Number of random variables, which can interact with each other.
+        All polynomials are ignored, which have an interaction order greater than the specified
+    interaction_order_current: int
+        Number of random variables currently interacting with respect to the highest order.
+        (interaction_order_current <= interaction_order)
+        The parameters for lower orders are all interacting with "interaction order".
+    options : dict
+        Options of gPC
+    validation: ValidationSet object (optional)
+        Object containing a set of validation points and corresponding solutions. Can be used
+        to validate gpc approximation setting options["error_type"]="nrmsd".
+        - grid: Grid object containing the validation points (grid.coords, grid.coords_norm)
+        - results: ndarray [n_grid x n_out] results
+    """
+
+    def __init__(self, problem, order_max, interaction_order=None,
+                 order=None, options=None, order_max_norm=1.0, interaction_order_current=None, validation=None):
+        """
+        Constructor; Initializes the SGPC class
+        """
+        super(SGPC, self).__init__(problem, options, validation)
+
+        if order is None:
+            order = [order_max] * problem.dim
+
+        if interaction_order is None:
+            interaction_order = problem.dim
+
+        self.order = order
+        self.order_max = order_max
+        self.order_max_norm = order_max_norm
+        self.interaction_order = interaction_order
+
+        if interaction_order_current is None:
+            self.interaction_order_current = interaction_order
+        else:
+            self.interaction_order_current = interaction_order_current
+
+        self.basis = Basis()
+        self.basis.init_basis_sgpc(problem=problem,
+                                   order=order,
+                                   order_max=order_max,
+                                   order_max_norm=order_max_norm,
+                                   interaction_order=interaction_order,
+                                   interaction_order_current=interaction_order_current)
+
+    @staticmethod
+    def get_mean(coeffs=None, samples=None):
+        """
+        Calculate the expected mean value. Provide either gPC coeffs or a certain number of samples.
+
+        mean = SGPC.get_mean(coeffs)
+
+        Parameters
+        ----------
+        coeffs : ndarray of float [n_basis x n_out], optional, default: None
+            GPC coefficients
+        samples : ndarray of float [n_samples x n_out], optional, default: None
+            Model evaluations from gPC approximation
+
+        Returns
+        -------
+        mean: ndarray of float [1 x n_out]
+            Expected value of output quantities
+        """
+        if coeffs is not None:
+            mean = coeffs[0, ]
+
+        elif samples is not None:
+            mean = np.mean(samples, axis=0)
+
+        else:
+            raise AssertionError("Provide either ""coeffs"" or ""samples"" to determine mean!")
+
+        # mean = mean[np.newaxis, :]
+
+        return mean
+
+    @staticmethod
+    def get_std(coeffs=None, samples=None):
+        """
+        Calculate the standard deviation. Provide either gPC coeffs or a certain number of samples.
+
+        std = SGPC.get_std(coeffs)
+
+        Parameters
+        ----------
+        coeffs: ndarray of float [n_basis x n_out], optional, default: None
+            GPC coefficients
+        samples : ndarray of float [n_samples x n_out], optional, default: None
+            Model evaluations from gPC approximation
+
+        Returns
+        -------
+        std: ndarray of float [1 x n_out]
+            Standard deviation of output quantities
+        """
+        if coeffs is not None:
+            std = np.sqrt(np.sum(np.square(coeffs[1:]), axis=0))
+
+        elif samples is not None:
+            std = np.std(samples, axis=0)
+
+        else:
+            raise AssertionError("Provide either ""coeffs"" or ""samples"" to determine standard deviation!")
+
+        # std = std[np.newaxis, :]
+
+        return std
+
+    # noinspection PyTypeChecker
+    def get_sobol_indices(self, coeffs, algorithm="standard", n_samples=1e4):
+        """
+        Calculate the available sobol indices from the gPC coefficients (standard) or by sampling.
+        In case of sampling, the Sobol indices are calculated up to second order.
+
+        sobol, sobol_idx, sobol_idx_bool = SGPC.get_sobol_indices(coeffs, algorithm="standard", n_samples=1e4)
+
+        Parameters
+        ----------
+        coeffs:  ndarray of float [n_basis x n_out]
+            GPC coefficients
+        algorithm : str, optional, default: "standard"
+            Algorithm to determine the Sobol indices
+            - "standard": Sobol indices are determined from the gPC coefficients
+            - "sampling": Sobol indices are determined from sampling using Saltelli's Sobol sampling sequence [1, 2, 3]
+        n_samples : int, optional, default: 1e4
+            Number of samples to determine Sobol indices by sampling. The efficient number of samples
+            increases to n_samples * (2*dim + 2) in Saltelli's Sobol sampling sequence.
+
+        Returns
+        -------
+        sobol: ndarray of float [n_sobol x n_out]
+            Normalized Sobol indices w.r.t. total variance
+        sobol_idx: list of ndarray of int [n_sobol x (n_sobol_included)]
+            Parameter combinations in rows of sobol.
+        sobol_idx_bool: ndarray of bool [n_sobol x dim]
+            Boolean mask which contains unique multi indices.
+
+        Notes
+        -----
+        .. [1] Sobol, I. M. (2001).  "Global sensitivity indices for nonlinear
+               mathematical models and their Monte Carlo estimates."  Mathematics
+               and Computers in Simulation, 55(1-3):271-280,
+               doi:10.1016/S0378-4754(00)00270-6.
+        .. [2] Saltelli, A. (2002).  "Making best use of model evaluations to
+               compute sensitivity indices."  Computer Physics Communications,
+               145(2):280-297, doi:10.1016/S0010-4655(02)00280-1.
+        .. [3] Saltelli, A., P. Annoni, I. Azzini, F. Campolongo, M. Ratto, and
+               S. Tarantola (2010).  "Variance based sensitivity analysis of model
+               output.  Design and estimator for the total sensitivity index."
+               Computer Physics Communications, 181(2):259-270,
+               doi:10.1016/j.cpc.2009.09.018.
+        """
+
+        # iprint("Determining Sobol indices...", tab=0)
+
+        if algorithm == "standard":
+            if self.p_matrix is not None:
+                raise NotImplementedError("Please use algorithm='sampling' in case of reduced gPC (projection).")
+
+            # handle (N,) arrays
+            if len(coeffs.shape) == 1:
+                n_out = 1
+            else:
+                n_out = coeffs.shape[1]
+
+            n_coeffs = coeffs.shape[0]
+
+            if n_coeffs == 1:
+                raise Exception('Number of coefficients is 1 ... no Sobol indices to calculate ...')
+
+            # Generate boolean matrix of all basis functions where order > 0 = True
+            # size: [n_basis x dim]
+            multi_indices = np.array([list(map(lambda _b:_b.p["i"], b_row)) for b_row in self.basis.b])
+            sobol_mask = multi_indices != 0
+
+            # look for unique combinations (i.e. available sobol combinations)
+            # size: [N_sobol x dim]
+            sobol_idx_bool = get_array_unique_rows(sobol_mask)
+
+            # delete the first row where all polynomials are order 0 (no sensitivity)
+            sobol_idx_bool = np.delete(sobol_idx_bool, [0], axis=0)
+            n_sobol_available = sobol_idx_bool.shape[0]
+
+            # check which basis functions contribute to which sobol coefficient set
+            # True for specific coeffs if it contributes to sobol coefficient
+            # size: [N_coeffs x N_sobol]
+            sobol_poly_idx = np.zeros([n_coeffs, n_sobol_available])
+
+            for i_sobol in range(n_sobol_available):
+                sobol_poly_idx[:, i_sobol] = np.all(sobol_mask == sobol_idx_bool[i_sobol], axis=1)
+
+            # calculate sobol coefficients matrix by summing up the individual
+            # contributions to the respective sobol coefficients
+            # size [N_sobol x N_points]
+            sobol = np.zeros([n_sobol_available, n_out])
+
+            for i_sobol in range(n_sobol_available):
+                sobol[i_sobol] = np.sum(np.square(coeffs[sobol_poly_idx[:, i_sobol] == 1]), axis=0)
+
+            # sort sobol coefficients in descending order (w.r.t. first output only ...)
+            idx_sort_descend_1st = np.argsort(sobol[:, 0], axis=0)[::-1]
+            sobol = sobol[idx_sort_descend_1st, :]
+            sobol_idx_bool = sobol_idx_bool[idx_sort_descend_1st]
+
+            # get list of sobol indices
+            sobol_idx = [0 for _ in range(sobol_idx_bool.shape[0])]
+
+            for i_sobol in range(sobol_idx_bool.shape[0]):
+                sobol_idx[i_sobol] = np.array([i for i, x in enumerate(sobol_idx_bool[i_sobol, :]) if x])
+
+            var = self.get_std(coeffs=coeffs) ** 2
+
+            sobol = sobol / var
+
+        elif algorithm == "sampling":
+
+            if self.p_matrix is None:
+                dim = self.problem.dim
+            else:
+                dim = self.problem_original.dim
+
+            if self.problem_original is None:
+                problem_original = self.problem
+            else:
+                problem_original = self.problem_original
+
+            # generate uniform distributed sobol sequence (parameter space [0, 1])
+            coords_norm_01 = saltelli_sampling(n_samples=n_samples, dim=dim, calc_second_order=True)
+            coords_norm = np.zeros(coords_norm_01.shape)
+
+            # transform to respective input pdfs using inverse cdfs
+            for i_key, key in enumerate(problem_original.parameters_random.keys()):
+                coords_norm[:, i_key] = problem_original.parameters_random[key].icdf(coords_norm_01[:, i_key])
+
+            # run model evaluations
+            res = self.get_approximation(coeffs=coeffs, x=coords_norm)
+
+            # determine sobol indices
+            sobol, sobol_idx, sobol_idx_bool = get_sobol_indices_saltelli(y=res,
+                                                                          dim=dim,
+                                                                          calc_second_order=True,
+                                                                          num_resamples=100,
+                                                                          conf_level=0.95)
+
+            # sort
+            idx = np.flip(np.argsort(sobol[:, 0], axis=0))
+            sobol = sobol[idx, :]
+            sobol_idx = [sobol_idx[i] for i in idx]
+            sobol_idx_bool = sobol_idx_bool[idx, :]
+
+        else:
+            raise AssertionError("Please provide valid algorithm argument (""standard"" or ""sampling"")")
+
+        return sobol, sobol_idx, sobol_idx_bool
+
+    # noinspection PyTypeChecker
+    def get_global_sens(self, coeffs, algorithm="standard", n_samples=1e5):
+        """
+        Determine the global derivative based sensitivity coefficients after Xiu (2009) [1]
+        from the gPC coefficients (standard) or by sampling.
+
+        global_sens = SGPC.get_global_sens(coeffs, algorithm="standard", n_samples=1e5)
+
+        Parameters
+        ----------
+        coeffs: ndarray of float [n_basis x n_out], optional, default: None
+            GPC coefficients
+        algorithm : str, optional, default: "standard"
+            Algorithm to determine the Sobol indices
+            - "standard": Sobol indices are determined from the gPC coefficients
+            - "sampling": Sobol indices are determined from sampling using Saltelli's Sobol sampling sequence [1, 2, 3]
+        n_samples : int, optional, default: 1e4
+            Number of samples
+
+        Returns
+        -------
+        global_sens: ndarray [dim x n_out]
+            Global derivative based sensitivity coefficients
+
+        Notes
+        -----
+        .. [1] D. Xiu, Fast Numerical Methods for Stochastic Computations: A Review,
+           Commun. Comput. Phys., 5 (2009), pp. 242-272 eq. (3.14) page 255
+        """
+
+        if algorithm == "standard":
+            b_int_global = np.zeros([self.problem.dim, self.basis.n_basis])
+
+            # construct matrix with integral expressions [n_basis x dim]
+            b_int = np.array([list(map(lambda _b: _b.fun_int, b_row)) for b_row in self.basis.b])
+            b_int_der = np.array([list(map(lambda _b: _b.fun_der_int, b_row)) for b_row in self.basis.b])
+
+            for i_sens in range(self.problem.dim):
+                # replace column with integral expressions from derivative of parameter[i_dim]
+                tmp = copy.deepcopy(b_int)
+                tmp[:, i_sens] = b_int_der[:, i_sens]
+
+                # determine global integral expression
+                b_int_global[i_sens, :] = np.prod(tmp, axis=1)
+
+            global_sens = np.matmul(b_int_global, coeffs) / (2 ** self.problem.dim)
+            # global_sens = np.matmul(b_int_global, coeffs)
+
+        elif algorithm == "sampling":
+            # generate sample coordinates (original parameter space)
+            if self.p_matrix is not None:
+                grid = Random(parameters_random=self.problem_original.parameters_random,
+                              n_grid=n_samples,
+                              options=None)
+            else:
+                grid = Random(parameters_random=self.problem.parameters_random,
+                              n_grid=n_samples,
+                              options=None)
+
+            local_sens = self.get_local_sens(coeffs, grid.coords_norm)
+
+            # # transform the coordinates to the reduced parameter space
+            # coords_norm = np.matmul(coords_norm, self.p_matrix.transpose() / self.p_matrix_norm[np.newaxis, :])
+            #
+            # # construct gPC gradient matrix [n_samples x n_basis x dim_red]
+            # gpc_matrix_gradient = self.calc_gpc_matrix(b=self.basis.b, x=coords_norm, gradient=True)
+            #
+            # # determine gradient in each sampling point [n_samples x n_out x dim_red]
+            # grad_samples_projected = np.matmul(gpc_matrix_gradient.transpose(2, 0, 1), coeffs).transpose(1, 2, 0)
+            #
+            # # project the gradient back to the original parameter space if necessary [n_samples x n_out x dim]
+            # grad_samples = np.matmul(grad_samples_projected, self.p_matrix / self.p_matrix_norm[:, np.newaxis])
+
+            # average the results and reshape [dim x n_out]
+            global_sens = np.mean(local_sens, axis=0).transpose()
+
+        else:
+            raise AssertionError("Please provide valid algorithm argument (""standard"" or ""sampling"")")
+
+        return global_sens
+
+    # noinspection PyTypeChecker
+    def get_local_sens(self, coeffs, x=None):
+        """
+        Determine the local derivative based sensitivity coefficients in the point of interest x
+        (normalized coordinates [-1, 1]).
+
+        local_sens = SGPC.calc_localsens(coeffs, x)
+
+        Parameters
+        ----------
+        coeffs: ndarray of float [n_basis x n_out]
+            GPC coefficients
+        x: ndarray of float [dim], optional, default: center of parameter space
+            Point in variable space to evaluate local sensitivity in (normalized coordinates [-1, 1])
+
+        Returns
+        -------
+        local_sens: ndarray [dim x n_out]
+            Local sensitivity of output quantities in point x
+        """
+
+        if x is None:
+            x = np.zeros(self.problem.dim)[np.newaxis, :]
+
+        # project coordinate to reduced parameter space if necessary
+        if self.p_matrix is not None:
+            x = np.matmul(x, self.p_matrix.transpose() / self.p_matrix_norm[np.newaxis, :])
+
+        # construct gPC gradient matrix [n_samples x n_basis x dim(_red)]
+        gpc_matrix_gradient = self.create_gpc_matrix(b=self.basis.b,
+                                                     x=x,
+                                                     gradient=True,
+                                                     gradient_idx=np.arange(x.shape[0]))
+
+        local_sens = np.matmul(gpc_matrix_gradient.transpose(2, 0, 1), coeffs).transpose(1, 2, 0)
+
+        # project the gradient back to the original space if necessary
+        if self.p_matrix is not None:
+            local_sens = np.matmul(local_sens, self.p_matrix / self.p_matrix_norm[:, np.newaxis])
+
+        return local_sens
+
+
+class Reg(SGPC):
+    """
+    Regression gPC subclass
+
+    Parameters
+    ----------
+    problem: Problem class instance
+        GPC Problem under investigation
+    order: list of int [dim]
+        Maximum individual expansion order [order_1, order_2, ..., order_dim].
+        Generates individual polynomials also if maximum expansion order in order_max is exceeded
+    order_max: int
+        Maximum global expansion order.
+        The maximum expansion order considers the sum of the orders of combined polynomials together with the
+        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
+        monomial orders.
+    order_max_norm: float
+        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
+        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
+        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
+        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
+    interaction_order: int
+        Number of random variables, which can interact with each other.
+        All polynomials are ignored, which have an interaction order greater than the specified
+    interaction_order_current: int, optional, default: interaction_order
+        Number of random variables currently interacting with respect to the highest order.
+        (interaction_order_current <= interaction_order)
+        The parameters for lower orders are all interacting with "interaction order".
+    options : dict
+        Options of gPC
+    validation: ValidationSet object (optional)
+        Object containing a set of validation points and corresponding solutions. Can be used
+        to validate gpc approximation setting options["error_type"]="nrmsd".
+        - grid: Grid object containing the validation points (grid.coords, grid.coords_norm)
+        - results: ndarray [n_grid x n_out] results
+
+    Notes
+    -----
+    .. [1] Blatman, G., & Sudret, B. (2011). Adaptive sparse polynomial chaos expansion based on least angle
+       regression. Journal of Computational Physics, 230(6), 2345-2367.
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> gpc = pygpc.Reg(problem=problem,
+    >>>                 order=[7, 6],
+    >>>                 order_max=5,
+    >>>                 order_max_norm=1,
+    >>>                 interaction_order=2,
+    >>>                 interaction_order_current=1
+    >>>                 fn_results="/tmp/my_results")
+
+    Attributes
+    ----------
+    solver: str
+        Solver to determine the gPC coefficients
+        - 'Moore-Penrose' ... Pseudoinverse of gPC matrix (SGPC.Reg, EGPC)
+        - 'OMP' ... Orthogonal Matching Pursuit, sparse recovery approach (SGPC.Reg, EGPC)
+        - 'NumInt' ... Numerical integration, spectral projection (SGPC.Quad)
+    settings: dict
+        Solver settings
+        - 'Moore-Penrose' ... None
+        - 'OMP' ... {"n_coeffs_sparse": int} Number of gPC coefficients != 0
+        - 'NumInt' ... None
+    """
+
+    def __init__(self, problem, order_max, order=None, order_max_norm=1.0,
+                 interaction_order=None, options=None, interaction_order_current=None, validation=None):
+        """
+        Constructor; Initializes Regression SGPC class
+        """
+
+        if interaction_order_current is None:
+            self.interaction_order_current = interaction_order
+        else:
+            self.interaction_order_current = interaction_order_current
+
+        super(Reg, self).__init__(problem=problem,
+                                  order=order,
+                                  order_max=order_max,
+                                  order_max_norm=order_max_norm,
+                                  interaction_order=interaction_order,
+                                  interaction_order_current=interaction_order_current,
+                                  options=options,
+                                  validation=validation)
+
+        self.solver = 'Moore-Penrose'   # Default solver
+        self.settings = None            # Default Solver settings
+
+
+class Quad(SGPC):
+    """
+    Quadrature SGPC sub-class
+
+    Parameters
+    ----------
+    problem: Problem class instance
+        GPC Problem under investigation
+    order: list of int [dim]
+        Maximum individual expansion order [order_1, order_2, ..., order_dim].
+        Generates individual polynomials also if maximum expansion order in order_max is exceeded
+    order_max: int
+        Maximum global expansion order.
+        The maximum expansion order considers the sum of the orders of combined polynomials together with the
+        chosen norm "order_max_norm". Typically this norm is 1 such that the maximum order is the sum of all
+        monomial orders.
+    order_max_norm: float
+        Norm for which the maximum global expansion order is defined [0, 1]. Values < 1 decrease the total number
+        of polynomials in the expansion such that interaction terms are penalized more. This truncation scheme
+        is also referred to "hyperbolic polynomial chaos expansion" such that sum(a_i^q)^1/q <= p,
+        where p is order_max and q is order_max_norm (for more details see eq. (27) in [1]).
+    interaction_order: int
+        Number of random variables, which can interact with each other.
+        All polynomials are ignored, which have an interaction order greater than the specified
+    interaction_order_current: int, optional, default: interaction_order
+        Number of random variables currently interacting with respect to the highest order.
+        (interaction_order_current <= interaction_order)
+        The parameters for lower orders are all interacting with "interaction order".
+    options : dict
+        Options of gPC
+    validation: ValidationSet object (optional)
+        Object containing a set of validation points and corresponding solutions. Can be used
+        to validate gpc approximation setting options["error_type"]="nrmsd".
+        - grid: Grid object containing the validation points (grid.coords, grid.coords_norm)
+        - results: ndarray [n_grid x n_out] results
+
+    Notes
+    -----
+    .. [1] Blatman, G., & Sudret, B. (2011). Adaptive sparse polynomial chaos expansion based on least angle
+       regression. Journal of Computational Physics, 230(6), 2345-2367.
+
+    Examples
+    --------
+    >>> import pygpc
+    >>> gpc = pygpc.Quad(problem=problem,
+    >>>                  order=[7, 6],
+    >>>                  order_max=5,
+    >>>                  order_max_norm=1,
+    >>>                  interaction_order=2,
+    >>>                  interaction_order_current=1,
+    >>>                  fn_results="/tmp/my_results")
+    """
+
+    def __init__(self, problem, order, order_max, order_max_norm, interaction_order, options,
+                 interaction_order_current=None, validation=None):
+        """
+        Constructor; Initializes Quadrature SGPC sub-class
+        """
+
+        if interaction_order_current is None:
+            self.interaction_order_current = interaction_order
+        else:
+            self.interaction_order_current = interaction_order_current
+
+        super(Quad, self).__init__(problem=problem,
+                                   order=order,
+                                   order_max=order_max,
+                                   order_max_norm=order_max_norm,
+                                   interaction_order=interaction_order,
+                                   interaction_order_current=interaction_order_current,
+                                   options=options,
+                                   validation=validation)
+
+        self.solver = 'NumInt'  # Default solver
+        self.settings = None    # Default solver settings
```

## pygpc/Session.py

 * *Ordering differences only*

```diff
@@ -1,141 +1,141 @@
-import numpy as np
-import pickle
-import __main__ as main
-from .io import write_session
-from .MEGPC import *
-from .SGPC import *
-from .GPC import *
-
-
-class Session(object):
-    """
-    GPC Session class
-
-    Parameters
-    ----------
-    algorithm : Algorithm Object
-        Algorithm object containing the Problem object, the Model object
-    """
-
-    def __init__(self, algorithm):
-        """
-        Constructor; Initializes a gPC Session
-        """
-        self.gpc = None
-        self.grid = None
-        self.model = None
-        self.problem = None
-        self.gpc_type = None
-        self.gradient = None
-        self.validation = None
-        self.projection = None
-        self.qoi_specific = None
-        self.algorithm = algorithm
-        self.model = self.algorithm.problem.model
-        self.n_cpu = self.algorithm.options["n_cpu"]
-        self.matlab_model = self.algorithm.options["matlab_model"]
-
-        if self.algorithm.options["fn_results"] is not None:
-            self.fn_results = os.path.splitext(self.algorithm.options["fn_results"])[0]
-        else:
-            self.fn_results = None
-
-        if self.algorithm.options["fn_session"] is not None:
-            self.fn_session = self.algorithm.options["fn_session"]
-            self.fn_session_folder = self.algorithm.options["fn_session_folder"]
-        else:
-            self.fn_session = None
-            self.fn_session_folder = None
-
-        try:
-            self.fn_script = main.__file__
-        except AttributeError:
-            self.fn_script = "jupter notebook"
-
-        # safe the original problem and random parameters
-        self.problem = self.algorithm.problem
-        self.parameters_random = self.algorithm.problem.parameters_random
-
-    def set_gpc(self, gpc):
-        """
-        Determine and set properties of gPC Object returned from algorithms
-
-        Parameters
-        ----------
-        gpc : MEGPC or SGPC object or list of MEGPC or SGPC objects
-            GPC objects
-        """
-        # if fn_results is not absolute, try if it is relative wrt the path of the executing script
-        if self.fn_results is not None and os.path.isabs(self.fn_results):
-            self.fn_results = os.path.join(os.path.split(self.fn_script)[0], self.fn_results)
-
-        # determine qoi specificity from algorithm
-        self.qoi_specific = self.algorithm.qoi_specific
-
-        # # determine qoi specificity from coeffs structure in results file
-        # with h5py.File(os.path.splitext(self.fn_results)[0] + ".hdf5", "r") as f:
-        #     try:
-        #         if type(f["coeffs"][()]) is np.ndarray:
-        #             self.qoi_specific = False
-        #     except AttributeError:
-        #
-        #         if np.array([True for s in list(f["coeffs/"]) if "qoi" in s]).any():
-        #             self.qoi_specific = True
-        #         else:
-        #             self.qoi_specific = False
-
-        if type(gpc) is list:
-            self.gpc = gpc
-        else:
-            self.gpc = [gpc]
-
-        if isinstance(self.gpc[0], MEGPC):
-            self.gpc_type = "megpc"
-        else:
-            self.gpc_type = "sgpc"
-
-        # check for projection approach
-        if (self.qoi_specific and self.gpc_type == "megpc") or \
-                (not self.qoi_specific and self.gpc_type == "megpc"):
-            if str(type(self.gpc[0].gpc[0].p_matrix)) != "<class 'NoneType'>":
-                self.projection = True
-
-        elif (not self.qoi_specific and not self.gpc_type == "megpc") or \
-                (self.qoi_specific and not self.gpc_type == "megpc"):
-            if str(type(self.gpc[0].p_matrix)) != "<class 'NoneType'>":
-                self.projection = True
-            else:
-                self.projection = False
-        else:
-            self.projection = False
-
-        self.gradient = self.gpc[0].gradient
-
-    def run(self):
-        """
-        Runs the gPC session by calling the algorithm and saves the Session object
-        in .hdf5 results file in the "session/" folder or as .pkl file
-        """
-        gpc, coeffs, results = self.algorithm.run()
-        self.set_gpc(gpc)
-
-        if type(coeffs) is list and not self.qoi_specific:
-            coeffs = coeffs[0]
-
-        if self.gpc[0].validation:
-            self.validation = self.gpc[0].validation
-
-        self.grid = self.gpc[-1].grid
-
-        try:
-            self.grid_original = self.gpc[-1].grid_original
-        except AttributeError:
-            pass
-
-        if self.fn_session is not None:
-            if os.path.splitext(self.fn_session)[1] == ".hdf5":
-                write_session(self, fname=self.fn_session, folder=self.fn_session_folder, overwrite=False)
-            else:
-                write_session(self, fname=self.fn_session, overwrite=True)
-
-        return self, coeffs, results
+import numpy as np
+import pickle
+import __main__ as main
+from .io import write_session
+from .MEGPC import *
+from .SGPC import *
+from .GPC import *
+
+
+class Session(object):
+    """
+    GPC Session class
+
+    Parameters
+    ----------
+    algorithm : Algorithm Object
+        Algorithm object containing the Problem object, the Model object
+    """
+
+    def __init__(self, algorithm):
+        """
+        Constructor; Initializes a gPC Session
+        """
+        self.gpc = None
+        self.grid = None
+        self.model = None
+        self.problem = None
+        self.gpc_type = None
+        self.gradient = None
+        self.validation = None
+        self.projection = None
+        self.qoi_specific = None
+        self.algorithm = algorithm
+        self.model = self.algorithm.problem.model
+        self.n_cpu = self.algorithm.options["n_cpu"]
+        self.matlab_model = self.algorithm.options["matlab_model"]
+
+        if self.algorithm.options["fn_results"] is not None:
+            self.fn_results = os.path.splitext(self.algorithm.options["fn_results"])[0]
+        else:
+            self.fn_results = None
+
+        if self.algorithm.options["fn_session"] is not None:
+            self.fn_session = self.algorithm.options["fn_session"]
+            self.fn_session_folder = self.algorithm.options["fn_session_folder"]
+        else:
+            self.fn_session = None
+            self.fn_session_folder = None
+
+        try:
+            self.fn_script = main.__file__
+        except AttributeError:
+            self.fn_script = "jupter notebook"
+
+        # safe the original problem and random parameters
+        self.problem = self.algorithm.problem
+        self.parameters_random = self.algorithm.problem.parameters_random
+
+    def set_gpc(self, gpc):
+        """
+        Determine and set properties of gPC Object returned from algorithms
+
+        Parameters
+        ----------
+        gpc : MEGPC or SGPC object or list of MEGPC or SGPC objects
+            GPC objects
+        """
+        # if fn_results is not absolute, try if it is relative wrt the path of the executing script
+        if self.fn_results is not None and os.path.isabs(self.fn_results):
+            self.fn_results = os.path.join(os.path.split(self.fn_script)[0], self.fn_results)
+
+        # determine qoi specificity from algorithm
+        self.qoi_specific = self.algorithm.qoi_specific
+
+        # # determine qoi specificity from coeffs structure in results file
+        # with h5py.File(os.path.splitext(self.fn_results)[0] + ".hdf5", "r") as f:
+        #     try:
+        #         if type(f["coeffs"][()]) is np.ndarray:
+        #             self.qoi_specific = False
+        #     except AttributeError:
+        #
+        #         if np.array([True for s in list(f["coeffs/"]) if "qoi" in s]).any():
+        #             self.qoi_specific = True
+        #         else:
+        #             self.qoi_specific = False
+
+        if type(gpc) is list:
+            self.gpc = gpc
+        else:
+            self.gpc = [gpc]
+
+        if isinstance(self.gpc[0], MEGPC):
+            self.gpc_type = "megpc"
+        else:
+            self.gpc_type = "sgpc"
+
+        # check for projection approach
+        if (self.qoi_specific and self.gpc_type == "megpc") or \
+                (not self.qoi_specific and self.gpc_type == "megpc"):
+            if str(type(self.gpc[0].gpc[0].p_matrix)) != "<class 'NoneType'>":
+                self.projection = True
+
+        elif (not self.qoi_specific and not self.gpc_type == "megpc") or \
+                (self.qoi_specific and not self.gpc_type == "megpc"):
+            if str(type(self.gpc[0].p_matrix)) != "<class 'NoneType'>":
+                self.projection = True
+            else:
+                self.projection = False
+        else:
+            self.projection = False
+
+        self.gradient = self.gpc[0].gradient
+
+    def run(self):
+        """
+        Runs the gPC session by calling the algorithm and saves the Session object
+        in .hdf5 results file in the "session/" folder or as .pkl file
+        """
+        gpc, coeffs, results = self.algorithm.run()
+        self.set_gpc(gpc)
+
+        if type(coeffs) is list and not self.qoi_specific:
+            coeffs = coeffs[0]
+
+        if self.gpc[0].validation:
+            self.validation = self.gpc[0].validation
+
+        self.grid = self.gpc[-1].grid
+
+        try:
+            self.grid_original = self.gpc[-1].grid_original
+        except AttributeError:
+            pass
+
+        if self.fn_session is not None:
+            if os.path.splitext(self.fn_session)[1] == ".hdf5":
+                write_session(self, fname=self.fn_session, folder=self.fn_session_folder, overwrite=False)
+            else:
+                write_session(self, fname=self.fn_session, overwrite=True)
+
+        return self, coeffs, results
```

## pygpc/Test.py

 * *Ordering differences only*

```diff
@@ -1,972 +1,972 @@
-from collections import OrderedDict
-from .testfunctions import *
-from .RandomParameter import *
-from .Problem import *
-
-
-class Test(object):
-    """
-    Test function objects
-
-    Parameters
-    ----------
-    dim : int
-        Number of random variables
-    """
-    def __init__(self, dim):
-        """
-        Initializes Test function objects
-        """
-        self.dim = dim
-        self.gpc = None
-
-
-#############################################
-# Low-Dimensional Continuous Testfunctions  #
-#############################################
-
-class BohachevskyFunction1(Test):
-    """
-    BohachevskyFunction1 test function
-    """
-    def __init__(self):
-        """
-        Initializes BohachevskyFunction1 test function
-        """
-        super(BohachevskyFunction1, self).__init__(dim=2)
-
-        # define model
-        self.model = testfunctions.BohachevskyFunction1()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-100., 100.])
-        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-100., 100.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class BoothFunction(Test):
-    """
-    BoothFunction test function
-    """
-    def __init__(self):
-        """
-        Initializes BoothFunction test function
-        """
-        super(BoothFunction, self).__init__(dim=2)
-
-        # define model
-        self.model = testfunctions.BoothFunction()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-10., 10.])
-        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-10., 10.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class BukinFunctionNumber6(Test):
-    """
-    BukinFunctionNumber6 test function
-    """
-    def __init__(self):
-        """
-        Initializes BukinFunctionNumber6 test function
-        """
-        super(BukinFunctionNumber6, self).__init__(dim=2)
-
-        # define model
-        self.model = testfunctions.BukinFunctionNumber6()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-15., -5.])
-        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-3., 3.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class Franke(Test):
-    """
-    Franke test function
-    """
-    def __init__(self):
-        """
-        Initializes Franke test function
-        """
-        super(Franke, self).__init__(dim=2)
-
-        # define model
-        self.model = testfunctions.Franke()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
-        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class Ishigami(Test):
-    """
-    Ishigami test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes Ishigami test function
-        """
-        super(Ishigami, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.Ishigami()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-np.pi, np.pi])
-        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-np.pi, np.pi])
-
-        if dim > 2:
-            self.parameters["x3"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-np.pi, np.pi])
-        else:
-            self.parameters["x3"] = np.array([0.])
-
-        self.parameters["a"] = np.array([7.])
-        self.parameters["b"] = np.array([0.1])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class Lim2002(Test):
-    """
-    Lim2002 test function
-    """
-    def __init__(self):
-        """
-        Initializes Lim2002 test function
-        """
-        super(Lim2002, self).__init__(dim=2)
-
-        # define model
-        self.model = testfunctions.Lim2002()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
-        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class MatyasFunction(Test):
-    """
-    MatyasFunction test function
-    """
-    def __init__(self):
-        """
-        Initializes MatyasFunction test function
-        """
-        super(MatyasFunction, self).__init__(dim=2)
-
-        # define model
-        self.model = testfunctions.MatyasFunction()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-10., 10.])
-        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-10., 10.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class McCormickFunction(Test):
-    """
-    McCormickFunction test function
-    """
-    def __init__(self):
-        """
-        Initializes McCormickFunction test function
-        """
-        super(McCormickFunction, self).__init__(dim=2)
-
-        # define model
-        self.model = testfunctions.McCormickFunction()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1.5, 4.])
-        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-3., 4.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class Peaks(Test):
-    """
-    Peaks test function
-    """
-    def __init__(self):
-        """
-        Initializes Peaks test function
-        """
-        super(Peaks, self).__init__(dim=2)
-
-        # define model
-        self.model = testfunctions.Peaks()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
-        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
-        self.parameters["x3"] = np.array([0.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class SixHumpCamelFunction(Test):
-    """
-    SixHumpCamelFunction test function
-    """
-    def __init__(self):
-        """
-        Initializes SixHumpCamelFunction test function
-        """
-        super(SixHumpCamelFunction, self).__init__(dim=2)
-
-        # define model
-        self.model = testfunctions.SixHumpCamelFunction()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-3., 3.])
-        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-2., 2.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-##########################################
-# N-Dimensional Continuous Testfunctions #
-##########################################
-
-class DixonPriceFunction(Test):
-    """
-    DixonPriceFunction test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes DixonPriceFunction test function
-        """
-        super(DixonPriceFunction, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.DixonPriceFunction()
-
-        # define parameters
-        self.parameters = OrderedDict()
-
-        for i in range(dim):
-            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-10., 10.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class GenzContinuous(Test):
-    """
-    GenzContinuous test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes GenzContinuous test function
-        """
-        super(GenzContinuous, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.GenzContinuous()
-
-        # define parameters
-        self.parameters = OrderedDict()
-
-        for i in range(dim):
-            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class GenzCornerPeak(Test):
-    """
-    GenzCornerPeak test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes GenzCornerPeak test function
-        """
-        super(GenzCornerPeak, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.GenzContinuous()
-
-        # define parameters
-        self.parameters = OrderedDict()
-
-        for i in range(dim):
-            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class GenzGaussianPeak(Test):
-    """
-    GenzGaussianPeak test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes GenzGaussianPeak test function
-        """
-        super(GenzGaussianPeak, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.GenzGaussianPeak()
-
-        # define parameters
-        self.parameters = OrderedDict()
-
-        for i in range(dim):
-            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class GenzOscillatory(Test):
-    """
-    GenzOscillatory test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes GenzOscillatory test function
-        """
-        super(GenzOscillatory, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.GenzOscillatory()
-
-        # define parameters
-        self.parameters = OrderedDict()
-
-        for i in range(dim):
-            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class GenzProductPeak(Test):
-    """
-    GenzProductPeak test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes GenzProductPeak test function
-        """
-        super(GenzProductPeak, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.GenzProductPeak()
-
-        # define parameters
-        self.parameters = OrderedDict()
-
-        for i in range(dim):
-            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class GFunction(Test):
-    """
-    GFunction test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes GFunction test function
-        """
-        super(GFunction, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.GFunction()
-
-        # define parameters
-        self.parameters = OrderedDict()
-
-        for i in range(dim):
-            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
-
-        self.parameters["a"] = (np.arange(dim) + 1 - 2.) / 2
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class ManufactureDecay(Test):
-    """
-    ManufactureDecay test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes ManufactureDecay test function
-        """
-        super(ManufactureDecay, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.ManufactureDecay()
-
-        # define parameters
-        self.parameters = OrderedDict()
-
-        for i in range(dim):
-            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class OakleyOhagan2004(Test):
-    """
-    OakleyOhagan2004 test function
-    """
-    def __init__(self):
-        """
-        Initializes OakleyOhagan2004 test function
-        """
-        super(OakleyOhagan2004, self).__init__(dim=15)
-
-        # define model
-        self.model = testfunctions.OakleyOhagan2004()
-
-        # define parameters
-        self.parameters = OrderedDict()
-
-        for i in range(self.dim):
-            self.parameters["x{}".format(i)] = Norm(pdf_shape=[0., 1.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class PermFunction(Test):
-    """
-    PermFunction test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes PermFunction test function
-        """
-        super(PermFunction, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.PermFunction()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["b"] = 10.
-
-        for i in range(dim):
-            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-dim, dim])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class Ridge(Test):
-    """
-    Ridge test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes Ridge test function
-        """
-        super(Ridge, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.Ridge()
-
-        # define parameters
-        self.parameters = OrderedDict()
-
-        for i in range(dim):
-            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-4., 4.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class RosenbrockFunction(Test):
-    """
-    RosenbrockFunction test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes RosenbrockFunction test function
-        """
-        super(RosenbrockFunction, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.RosenbrockFunction()
-
-        # define parameters
-        self.parameters = OrderedDict()
-
-        for i in range(dim):
-            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-5., 10.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class RotatedHyperEllipsoid(Test):
-    """
-    RotatedHyperEllipsoid test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes RotatedHyperEllipsoid test function
-        """
-        super(RotatedHyperEllipsoid, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.RotatedHyperEllipsoid()
-
-        # define parameters
-        self.parameters = OrderedDict()
-
-        for i in range(dim):
-            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-60., 60.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class SphereFunction(Test):
-    """
-    SphereFunction test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes SphereFunction test function
-        """
-        super(SphereFunction, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.SphereFunction()
-
-        # define parameters
-        self.parameters = OrderedDict()
-
-        for i in range(dim):
-            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class SumOfDifferentPowersFunction(Test):
-    """
-    SumOfDifferentPowersFunction test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes SphereFun test function
-        """
-        super(SumOfDifferentPowersFunction, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.SumOfDifferentPowersFunction()
-
-        # define parameters
-        self.parameters = OrderedDict()
-
-        for i in range(dim):
-            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class Welch1992(Test):
-    """
-    Welch1992 test function
-    """
-    def __init__(self):
-        """
-        Initializes Welch1992 test function
-        """
-        super(Welch1992, self).__init__(dim=20)
-
-        # define model
-        self.model = testfunctions.Welch1992()
-
-        # define parameters
-        self.parameters = OrderedDict()
-
-        for i in range(self.dim):
-            self.parameters["x{}".format(i+1)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-0.5, 0.5])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class WingWeight(Test):
-    """
-    WingWeight test function
-    """
-    def __init__(self):
-        """
-        Initializes WingWeight test function
-        """
-        super(WingWeight, self).__init__(dim=10)
-
-        # define model
-        self.model = testfunctions.WingWeight()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[150., 200.])
-        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[220., 300.])
-        self.parameters["x3"] = Beta(pdf_shape=[1., 1.], pdf_limits=[6., 10.])
-        self.parameters["x4"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-10., 10.])
-        self.parameters["x5"] = Beta(pdf_shape=[1., 1.], pdf_limits=[16., 45.])
-        self.parameters["x6"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0.5, 1.])
-        self.parameters["x7"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0.08, 0.18])
-        self.parameters["x8"] = Beta(pdf_shape=[1., 1.], pdf_limits=[2.5, 6.])
-        self.parameters["x9"] = Beta(pdf_shape=[1., 1.], pdf_limits=[1700., 2500.])
-        self.parameters["x10"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0.025, 0.08])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class ZakharovFunction(Test):
-    """
-    ZakharovFunction test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes ZakharovFunction test function
-        """
-        super(ZakharovFunction, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.ZakharovFunction()
-
-        # define parameters
-        self.parameters = OrderedDict()
-
-        for i in range(dim):
-            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-4., 10.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-###############################################
-# Low Dimensional Discontinuous Testfunctions #
-###############################################
-
-class Cluster3Simple(Test):
-    """
-    Cluster3Simple test function
-    """
-    def __init__(self):
-        """
-        Initializes Cluster3Simple test function
-        """
-        super(Cluster3Simple, self).__init__(dim=2)
-
-        # define model
-        self.model = testfunctions.Cluster3Simple()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
-        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class DeJongFunctionFive(Test):
-    """
-    DeJongFunctionFive test function
-    """
-    def __init__(self):
-        """
-        Initializes DeJongFunctionFive test function
-        """
-        super(DeJongFunctionFive, self).__init__(dim=2)
-
-        # define model
-        self.model = testfunctions.DeJongFunctionFive()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-65.536, 65.536])
-        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-65.536, 65.536])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class HyperbolicTangent(Test):
-    """
-    HyperbolicTangent test function
-    """
-    def __init__(self):
-        """
-        Initializes HyperbolicTangent test function
-        """
-        super(HyperbolicTangent, self).__init__(dim=2)
-
-        # define model
-        self.model = testfunctions.HyperbolicTangent()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
-        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class MovingParticleFrictionForce(Test):
-    """
-    MovingParticleFrictionForce test function
-    """
-    def __init__(self):
-        """
-        Initializes MovingParticleFrictionForce test function
-        """
-        super(MovingParticleFrictionForce, self).__init__(dim=1)
-
-        # define model
-        self.model = testfunctions.MovingParticleFrictionForce()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["xi"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class SurfaceCoverageSpecies(Test):
-    """
-    SurfaceCoverageSpecies test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes SurfaceCoverageSpecies test function
-        """
-        super(SurfaceCoverageSpecies, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.SurfaceCoverageSpecies()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["rho_0"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
-        self.parameters["beta"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 20.])
-
-        if dim > 2:
-            self.parameters["alpha"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0.1, 2.])
-        else:
-            self.parameters["alpha"] = np.array([1.])
-
-            # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-#############################################
-# N-Dimensional Discontinuous Testfunctions #
-#############################################
-class GenzDiscontinuous(Test):
-    """
-    GenzDiscontinuous test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes GenzDiscontinuous test function
-        """
-        super(GenzDiscontinuous, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.GenzDiscontinuous()
-
-        # define parameters
-        self.parameters = OrderedDict()
-
-        for i in range(dim):
-            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class MichalewiczFunction(Test):
-    """
-    MichalewiczFunction test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes MichalewiczFunction test function
-        """
-        super(MichalewiczFunction, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.MichalewiczFunction()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["m"] = 10.
-
-        for i in range(dim):
-            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., np.pi])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-########################################
-# Low-Dimensional Noisy Testfunctions  #
-########################################
-
-class CrossinTrayFunction(Test):
-    """
-    CrossinTrayFunction test function
-    """
-    def __init__(self):
-        """
-        Initializes CrossinTrayFunction test function
-        """
-        super(CrossinTrayFunction, self).__init__(dim=2)
-
-        # define model
-        self.model = testfunctions.CrossinTrayFunction()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-10., 10.])
-        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-10., 10.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class DropWaveFunction(Test):
-    """
-    DropWaveFunction test function
-    """
-    def __init__(self):
-        """
-        Initializes DropWaveFunction test function
-        """
-        super(DropWaveFunction, self).__init__(dim=2)
-
-        # define model
-        self.model = testfunctions.DropWaveFunction()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-5., 5.])
-        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-5., 5.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class GramacyLeeFunction(Test):
-    """
-    GramacyLeeFunction test function
-    """
-    def __init__(self):
-        """
-        Initializes GramacyLeeFunction test function
-        """
-        super(GramacyLeeFunction, self).__init__(dim=2)
-
-        # define model
-        self.model = testfunctions.GramacyLeeFunction()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[.5, 2.5])
-        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[.5, 2.5])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-class SchafferFunction4(Test):
-    """
-    SchafferFunction4 test function
-    """
-    def __init__(self):
-        """
-        Initializes SchafferFunction4 test function
-        """
-        super(SchafferFunction4, self).__init__(dim=2)
-
-        # define model
-        self.model = testfunctions.SchafferFunction4()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-100., 100.])
-        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-100., 100.])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
-
-
-######################################
-# N-Dimensional Noisy Testfunctions  #
-######################################
-
-class Ackley(Test):
-    """
-    Ackley test function
-    """
-    def __init__(self, dim=2):
-        """
-        Initializes Ackley test function
-        """
-        super(Ackley, self).__init__(dim=dim)
-
-        # define model
-        self.model = testfunctions.Ackley()
-
-        # define parameters
-        self.parameters = OrderedDict()
-        self.parameters["a"] = 20.
-        self.parameters["b"] = 0.2
-        self.parameters["c"] = 0.5 * np.pi
-
-        for i in range(self.dim):
-            self.parameters["x{}".format(i+1)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-32.768, 32.76])
-
-        # define problem
-        self.problem = Problem(self.model, self.parameters)
+from collections import OrderedDict
+from .testfunctions import *
+from .RandomParameter import *
+from .Problem import *
+
+
+class Test(object):
+    """
+    Test function objects
+
+    Parameters
+    ----------
+    dim : int
+        Number of random variables
+    """
+    def __init__(self, dim):
+        """
+        Initializes Test function objects
+        """
+        self.dim = dim
+        self.gpc = None
+
+
+#############################################
+# Low-Dimensional Continuous Testfunctions  #
+#############################################
+
+class BohachevskyFunction1(Test):
+    """
+    BohachevskyFunction1 test function
+    """
+    def __init__(self):
+        """
+        Initializes BohachevskyFunction1 test function
+        """
+        super(BohachevskyFunction1, self).__init__(dim=2)
+
+        # define model
+        self.model = testfunctions.BohachevskyFunction1()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-100., 100.])
+        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-100., 100.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class BoothFunction(Test):
+    """
+    BoothFunction test function
+    """
+    def __init__(self):
+        """
+        Initializes BoothFunction test function
+        """
+        super(BoothFunction, self).__init__(dim=2)
+
+        # define model
+        self.model = testfunctions.BoothFunction()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-10., 10.])
+        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-10., 10.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class BukinFunctionNumber6(Test):
+    """
+    BukinFunctionNumber6 test function
+    """
+    def __init__(self):
+        """
+        Initializes BukinFunctionNumber6 test function
+        """
+        super(BukinFunctionNumber6, self).__init__(dim=2)
+
+        # define model
+        self.model = testfunctions.BukinFunctionNumber6()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-15., -5.])
+        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-3., 3.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class Franke(Test):
+    """
+    Franke test function
+    """
+    def __init__(self):
+        """
+        Initializes Franke test function
+        """
+        super(Franke, self).__init__(dim=2)
+
+        # define model
+        self.model = testfunctions.Franke()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
+        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class Ishigami(Test):
+    """
+    Ishigami test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes Ishigami test function
+        """
+        super(Ishigami, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.Ishigami()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-np.pi, np.pi])
+        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-np.pi, np.pi])
+
+        if dim > 2:
+            self.parameters["x3"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-np.pi, np.pi])
+        else:
+            self.parameters["x3"] = np.array([0.])
+
+        self.parameters["a"] = np.array([7.])
+        self.parameters["b"] = np.array([0.1])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class Lim2002(Test):
+    """
+    Lim2002 test function
+    """
+    def __init__(self):
+        """
+        Initializes Lim2002 test function
+        """
+        super(Lim2002, self).__init__(dim=2)
+
+        # define model
+        self.model = testfunctions.Lim2002()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
+        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class MatyasFunction(Test):
+    """
+    MatyasFunction test function
+    """
+    def __init__(self):
+        """
+        Initializes MatyasFunction test function
+        """
+        super(MatyasFunction, self).__init__(dim=2)
+
+        # define model
+        self.model = testfunctions.MatyasFunction()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-10., 10.])
+        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-10., 10.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class McCormickFunction(Test):
+    """
+    McCormickFunction test function
+    """
+    def __init__(self):
+        """
+        Initializes McCormickFunction test function
+        """
+        super(McCormickFunction, self).__init__(dim=2)
+
+        # define model
+        self.model = testfunctions.McCormickFunction()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1.5, 4.])
+        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-3., 4.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class Peaks(Test):
+    """
+    Peaks test function
+    """
+    def __init__(self):
+        """
+        Initializes Peaks test function
+        """
+        super(Peaks, self).__init__(dim=2)
+
+        # define model
+        self.model = testfunctions.Peaks()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
+        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
+        self.parameters["x3"] = np.array([0.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class SixHumpCamelFunction(Test):
+    """
+    SixHumpCamelFunction test function
+    """
+    def __init__(self):
+        """
+        Initializes SixHumpCamelFunction test function
+        """
+        super(SixHumpCamelFunction, self).__init__(dim=2)
+
+        # define model
+        self.model = testfunctions.SixHumpCamelFunction()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-3., 3.])
+        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-2., 2.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+##########################################
+# N-Dimensional Continuous Testfunctions #
+##########################################
+
+class DixonPriceFunction(Test):
+    """
+    DixonPriceFunction test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes DixonPriceFunction test function
+        """
+        super(DixonPriceFunction, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.DixonPriceFunction()
+
+        # define parameters
+        self.parameters = OrderedDict()
+
+        for i in range(dim):
+            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-10., 10.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class GenzContinuous(Test):
+    """
+    GenzContinuous test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes GenzContinuous test function
+        """
+        super(GenzContinuous, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.GenzContinuous()
+
+        # define parameters
+        self.parameters = OrderedDict()
+
+        for i in range(dim):
+            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class GenzCornerPeak(Test):
+    """
+    GenzCornerPeak test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes GenzCornerPeak test function
+        """
+        super(GenzCornerPeak, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.GenzContinuous()
+
+        # define parameters
+        self.parameters = OrderedDict()
+
+        for i in range(dim):
+            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class GenzGaussianPeak(Test):
+    """
+    GenzGaussianPeak test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes GenzGaussianPeak test function
+        """
+        super(GenzGaussianPeak, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.GenzGaussianPeak()
+
+        # define parameters
+        self.parameters = OrderedDict()
+
+        for i in range(dim):
+            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class GenzOscillatory(Test):
+    """
+    GenzOscillatory test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes GenzOscillatory test function
+        """
+        super(GenzOscillatory, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.GenzOscillatory()
+
+        # define parameters
+        self.parameters = OrderedDict()
+
+        for i in range(dim):
+            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class GenzProductPeak(Test):
+    """
+    GenzProductPeak test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes GenzProductPeak test function
+        """
+        super(GenzProductPeak, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.GenzProductPeak()
+
+        # define parameters
+        self.parameters = OrderedDict()
+
+        for i in range(dim):
+            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class GFunction(Test):
+    """
+    GFunction test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes GFunction test function
+        """
+        super(GFunction, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.GFunction()
+
+        # define parameters
+        self.parameters = OrderedDict()
+
+        for i in range(dim):
+            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
+
+        self.parameters["a"] = (np.arange(dim) + 1 - 2.) / 2
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class ManufactureDecay(Test):
+    """
+    ManufactureDecay test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes ManufactureDecay test function
+        """
+        super(ManufactureDecay, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.ManufactureDecay()
+
+        # define parameters
+        self.parameters = OrderedDict()
+
+        for i in range(dim):
+            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class OakleyOhagan2004(Test):
+    """
+    OakleyOhagan2004 test function
+    """
+    def __init__(self):
+        """
+        Initializes OakleyOhagan2004 test function
+        """
+        super(OakleyOhagan2004, self).__init__(dim=15)
+
+        # define model
+        self.model = testfunctions.OakleyOhagan2004()
+
+        # define parameters
+        self.parameters = OrderedDict()
+
+        for i in range(self.dim):
+            self.parameters["x{}".format(i)] = Norm(pdf_shape=[0., 1.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class PermFunction(Test):
+    """
+    PermFunction test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes PermFunction test function
+        """
+        super(PermFunction, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.PermFunction()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["b"] = 10.
+
+        for i in range(dim):
+            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-dim, dim])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class Ridge(Test):
+    """
+    Ridge test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes Ridge test function
+        """
+        super(Ridge, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.Ridge()
+
+        # define parameters
+        self.parameters = OrderedDict()
+
+        for i in range(dim):
+            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-4., 4.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class RosenbrockFunction(Test):
+    """
+    RosenbrockFunction test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes RosenbrockFunction test function
+        """
+        super(RosenbrockFunction, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.RosenbrockFunction()
+
+        # define parameters
+        self.parameters = OrderedDict()
+
+        for i in range(dim):
+            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-5., 10.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class RotatedHyperEllipsoid(Test):
+    """
+    RotatedHyperEllipsoid test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes RotatedHyperEllipsoid test function
+        """
+        super(RotatedHyperEllipsoid, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.RotatedHyperEllipsoid()
+
+        # define parameters
+        self.parameters = OrderedDict()
+
+        for i in range(dim):
+            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-60., 60.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class SphereFunction(Test):
+    """
+    SphereFunction test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes SphereFunction test function
+        """
+        super(SphereFunction, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.SphereFunction()
+
+        # define parameters
+        self.parameters = OrderedDict()
+
+        for i in range(dim):
+            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class SumOfDifferentPowersFunction(Test):
+    """
+    SumOfDifferentPowersFunction test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes SphereFun test function
+        """
+        super(SumOfDifferentPowersFunction, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.SumOfDifferentPowersFunction()
+
+        # define parameters
+        self.parameters = OrderedDict()
+
+        for i in range(dim):
+            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class Welch1992(Test):
+    """
+    Welch1992 test function
+    """
+    def __init__(self):
+        """
+        Initializes Welch1992 test function
+        """
+        super(Welch1992, self).__init__(dim=20)
+
+        # define model
+        self.model = testfunctions.Welch1992()
+
+        # define parameters
+        self.parameters = OrderedDict()
+
+        for i in range(self.dim):
+            self.parameters["x{}".format(i+1)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-0.5, 0.5])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class WingWeight(Test):
+    """
+    WingWeight test function
+    """
+    def __init__(self):
+        """
+        Initializes WingWeight test function
+        """
+        super(WingWeight, self).__init__(dim=10)
+
+        # define model
+        self.model = testfunctions.WingWeight()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[150., 200.])
+        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[220., 300.])
+        self.parameters["x3"] = Beta(pdf_shape=[1., 1.], pdf_limits=[6., 10.])
+        self.parameters["x4"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-10., 10.])
+        self.parameters["x5"] = Beta(pdf_shape=[1., 1.], pdf_limits=[16., 45.])
+        self.parameters["x6"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0.5, 1.])
+        self.parameters["x7"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0.08, 0.18])
+        self.parameters["x8"] = Beta(pdf_shape=[1., 1.], pdf_limits=[2.5, 6.])
+        self.parameters["x9"] = Beta(pdf_shape=[1., 1.], pdf_limits=[1700., 2500.])
+        self.parameters["x10"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0.025, 0.08])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class ZakharovFunction(Test):
+    """
+    ZakharovFunction test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes ZakharovFunction test function
+        """
+        super(ZakharovFunction, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.ZakharovFunction()
+
+        # define parameters
+        self.parameters = OrderedDict()
+
+        for i in range(dim):
+            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-4., 10.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+###############################################
+# Low Dimensional Discontinuous Testfunctions #
+###############################################
+
+class Cluster3Simple(Test):
+    """
+    Cluster3Simple test function
+    """
+    def __init__(self):
+        """
+        Initializes Cluster3Simple test function
+        """
+        super(Cluster3Simple, self).__init__(dim=2)
+
+        # define model
+        self.model = testfunctions.Cluster3Simple()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
+        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class DeJongFunctionFive(Test):
+    """
+    DeJongFunctionFive test function
+    """
+    def __init__(self):
+        """
+        Initializes DeJongFunctionFive test function
+        """
+        super(DeJongFunctionFive, self).__init__(dim=2)
+
+        # define model
+        self.model = testfunctions.DeJongFunctionFive()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-65.536, 65.536])
+        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-65.536, 65.536])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class HyperbolicTangent(Test):
+    """
+    HyperbolicTangent test function
+    """
+    def __init__(self):
+        """
+        Initializes HyperbolicTangent test function
+        """
+        super(HyperbolicTangent, self).__init__(dim=2)
+
+        # define model
+        self.model = testfunctions.HyperbolicTangent()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
+        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class MovingParticleFrictionForce(Test):
+    """
+    MovingParticleFrictionForce test function
+    """
+    def __init__(self):
+        """
+        Initializes MovingParticleFrictionForce test function
+        """
+        super(MovingParticleFrictionForce, self).__init__(dim=1)
+
+        # define model
+        self.model = testfunctions.MovingParticleFrictionForce()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["xi"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-1., 1.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class SurfaceCoverageSpecies(Test):
+    """
+    SurfaceCoverageSpecies test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes SurfaceCoverageSpecies test function
+        """
+        super(SurfaceCoverageSpecies, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.SurfaceCoverageSpecies()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["rho_0"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
+        self.parameters["beta"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 20.])
+
+        if dim > 2:
+            self.parameters["alpha"] = Beta(pdf_shape=[1., 1.], pdf_limits=[0.1, 2.])
+        else:
+            self.parameters["alpha"] = np.array([1.])
+
+            # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+#############################################
+# N-Dimensional Discontinuous Testfunctions #
+#############################################
+class GenzDiscontinuous(Test):
+    """
+    GenzDiscontinuous test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes GenzDiscontinuous test function
+        """
+        super(GenzDiscontinuous, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.GenzDiscontinuous()
+
+        # define parameters
+        self.parameters = OrderedDict()
+
+        for i in range(dim):
+            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., 1.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class MichalewiczFunction(Test):
+    """
+    MichalewiczFunction test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes MichalewiczFunction test function
+        """
+        super(MichalewiczFunction, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.MichalewiczFunction()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["m"] = 10.
+
+        for i in range(dim):
+            self.parameters["x{}".format(i)] = Beta(pdf_shape=[1., 1.], pdf_limits=[0., np.pi])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+########################################
+# Low-Dimensional Noisy Testfunctions  #
+########################################
+
+class CrossinTrayFunction(Test):
+    """
+    CrossinTrayFunction test function
+    """
+    def __init__(self):
+        """
+        Initializes CrossinTrayFunction test function
+        """
+        super(CrossinTrayFunction, self).__init__(dim=2)
+
+        # define model
+        self.model = testfunctions.CrossinTrayFunction()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-10., 10.])
+        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-10., 10.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class DropWaveFunction(Test):
+    """
+    DropWaveFunction test function
+    """
+    def __init__(self):
+        """
+        Initializes DropWaveFunction test function
+        """
+        super(DropWaveFunction, self).__init__(dim=2)
+
+        # define model
+        self.model = testfunctions.DropWaveFunction()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-5., 5.])
+        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-5., 5.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class GramacyLeeFunction(Test):
+    """
+    GramacyLeeFunction test function
+    """
+    def __init__(self):
+        """
+        Initializes GramacyLeeFunction test function
+        """
+        super(GramacyLeeFunction, self).__init__(dim=2)
+
+        # define model
+        self.model = testfunctions.GramacyLeeFunction()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[.5, 2.5])
+        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[.5, 2.5])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+class SchafferFunction4(Test):
+    """
+    SchafferFunction4 test function
+    """
+    def __init__(self):
+        """
+        Initializes SchafferFunction4 test function
+        """
+        super(SchafferFunction4, self).__init__(dim=2)
+
+        # define model
+        self.model = testfunctions.SchafferFunction4()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["x1"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-100., 100.])
+        self.parameters["x2"] = Beta(pdf_shape=[1., 1.], pdf_limits=[-100., 100.])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
+
+
+######################################
+# N-Dimensional Noisy Testfunctions  #
+######################################
+
+class Ackley(Test):
+    """
+    Ackley test function
+    """
+    def __init__(self, dim=2):
+        """
+        Initializes Ackley test function
+        """
+        super(Ackley, self).__init__(dim=dim)
+
+        # define model
+        self.model = testfunctions.Ackley()
+
+        # define parameters
+        self.parameters = OrderedDict()
+        self.parameters["a"] = 20.
+        self.parameters["b"] = 0.2
+        self.parameters["c"] = 0.5 * np.pi
+
+        for i in range(self.dim):
+            self.parameters["x{}".format(i+1)] = Beta(pdf_shape=[1., 1.], pdf_limits=[-32.768, 32.76])
+
+        # define problem
+        self.problem = Problem(self.model, self.parameters)
```

## pygpc/TestBench.py

 * *Ordering differences only*

```diff
@@ -1,484 +1,484 @@
-import copy
-import glob
-import h5py
-import multiprocessing
-import multiprocessing.pool
-import os
-import pickle
-from _functools import partial
-from collections import OrderedDict
-from .io import write_session_pkl
-from .Algorithm import *
-from .Test import *
-from .misc import *
-from .postprocessing import *
-from .validation import *
-from .Session import *
-
-
-def run_test(session):
-    print("Running: Algorithm: {}   -    Problem: {}".format(type(session).__name__,
-                                                             os.path.split(session.fn_results)[1]))
-    session, coeffs, results = session.run()
-
-    # Post-process gPC
-    get_sensitivities_hdf5(fn_gpc=session.fn_results,
-                           output_idx=None,
-                           calc_sobol=True,
-                           calc_global_sens=True,
-                           calc_pdf=True)
-
-    # Validate gPC vs original model function (2D-surface)
-    if len(list(session.parameters_random.keys())) == 1:
-        random_vars = list(session.parameters_random.keys())
-        n_grid = [101]
-    else:
-        random_vars = list(session.parameters_random.keys())[0:2]
-        n_grid = [51, 51]
-
-    validate_gpc_plot(session=session,
-                      coeffs=coeffs,
-                      random_vars=random_vars,
-                      n_grid=n_grid,
-                      output_idx=0,
-                      fn_out=session.fn_results + "_val",
-                      n_cpu=session.n_cpu)
-
-    return session
-
-
-class TestBench(object):
-    """
-    TestBench for gPC algorithms
-
-    Parameters
-    ----------
-    algorithm : pygpc.Algorithm Object
-        Algorithm to benchmark
-    problem : Dict() or OrderedDict() of pygpc.Problem instances
-        Problem instances to test
-    options : Dict or OrderedDict()
-        Algorithm options
-    repetitions : int (default=1)
-        Number of repeated runs
-    n_cpu : int (default=1)
-        Number of threads to run tests in parallel
-    """
-
-    def __init__(self, algorithm, problem, options, repetitions=1, n_cpu=1):
-        """
-        Initializes the TestBench class object instance
-        """
-        self.session = OrderedDict()
-        self.session_keys = []
-        self.algorithm = OrderedDict()
-        self.algorithm_type = algorithm
-        self.problem = problem
-        self.fn_results = copy.deepcopy(options["fn_results"])
-        self.repetitions = repetitions
-        self.problem_keys = list(problem.keys())
-
-        # Setting up parallelization (setup thread pool)
-        n_cpu_available = multiprocessing.cpu_count()
-        self.n_cpu = min(n_cpu, n_cpu_available)
-        self.pool = multiprocessing.Pool(n_cpu)
-        self.run_test_partial = partial(run_test)
-
-        if "seed" not in list(options.keys()):
-            options["seed"] = None
-
-        for key in self.problem_keys:
-            for rep in range(repetitions):
-
-                self.session_keys.append(key + "_" + str(rep).zfill(4))
-
-                if algorithm == Static:
-                    options["fn_results"] = os.path.join(self.fn_results,
-                                                         key + "_p_{}_".format(options["order"][0]) + str(rep).zfill(4))
-                    options["order"] = [options["order"][0] for _ in range(problem[key].dim)]
-                    n_coeffs = get_num_coeffs_sparse(order_dim_max=options["order"],
-                                                     order_glob_max=options["order_max"],
-                                                     order_inter_max=options["interaction_order"],
-                                                     order_glob_max_norm=options["order_max_norm"],
-                                                     dim=problem[key].dim)
-
-                    grid = options["grid"](parameters_random=problem[key].parameters_random,
-                                           n_grid=options["matrix_ratio"] * n_coeffs,
-                                           seed=options["seed"],
-                                           options=options["grid_options"])
-
-                    self.algorithm[self.session_keys[-1]] = algorithm(problem=problem[key],
-                                                                      options=copy.deepcopy(options),
-                                                                      grid=copy.deepcopy(grid))
-
-                elif algorithm == StaticProjection:
-                    options["fn_results"] = os.path.join(self.fn_results,
-                                                         key + "_p_{}_".format(options["order"][0]) + str(rep).zfill(4))
-
-                    self.algorithm[self.session_keys[-1]] = algorithm(problem=problem[key],
-                                                                      options=copy.deepcopy(options))
-
-                else:
-                    options["fn_results"] = os.path.join(self.fn_results, key + "_" + str(rep).zfill(4))
-                    self.algorithm[self.session_keys[-1]] = algorithm(problem=problem[key],
-                                                                      options=copy.deepcopy(options))
-
-                self.session[self.session_keys[-1]] = Session(algorithm=self.algorithm[self.session_keys[-1]])
-
-    def run(self):
-        """
-        Run algorithms with test problems and save results
-        """
-
-        session_list = [self.session[key] for key in list(self.session.keys())]
-
-        # for session in session_list:
-        #     run_test(session)
-        session_list = self.pool.map(self.run_test_partial, session_list)
-        self.pool.close()
-        self.pool.join()
-
-        # transform session list back to dict
-        for i, key in enumerate(self.session_keys):
-            self.session[key] = session_list[i]
-
-        print("Merging .hdf5 files ...")
-        # merge .hdf5 files of repetitions
-        for key in self.problem_keys:
-
-            # merge gpc files
-            print(key)
-            if isinstance(self.session[key + "_0000"].algorithm, Static) or \
-                    isinstance(self.session[key + "_0000"].algorithm, StaticProjection):
-
-                fn_hdf5 = os.path.join(self.fn_results, key + "_p_{}".format(
-                    self.session[key + "_0000"].gpc[0].options["order"][0])) + ".hdf5"
-            else:
-                fn_hdf5 = os.path.join(self.fn_results, key) + ".hdf5"
-
-            with h5py.File(fn_hdf5, 'w') as f:
-
-                for rep in range(self.repetitions):
-                    f.create_group(str(rep).zfill(4))
-
-                    with h5py.File(self.session[key + "_" + str(rep).zfill(4)].fn_results + ".hdf5", 'r') as g:
-                        for gkey in list(g.keys()):
-                            g.copy(gkey, f[str(rep).zfill(4)])
-
-                    # delete individual .hdf5 files
-                    os.remove(self.session[key + "_" + str(rep).zfill(4)].fn_results + ".hdf5")
-
-            # merge validation files
-            with h5py.File(os.path.join(self.fn_results, key) + "_val.hdf5", 'w') as f:
-                for rep in range(self.repetitions):
-                    f.create_group(str(rep).zfill(4))
-
-                    with h5py.File(os.path.splitext(self.algorithm[key + "_" +
-                                   str(rep).zfill(4)].options["fn_results"])[0] + "_val.hdf5", 'r') as g:
-                        for gkey in list(g.keys()):
-                            g.copy(gkey, f[str(rep).zfill(4)])
-
-                    # delete individual .hdf5 files
-                    os.remove(os.path.splitext(self.algorithm[key +
-                              "_" + str(rep).zfill(4)].options["fn_results"])[0] + "_val.hdf5")
-
-        # delete .pdf files
-        for f in glob.glob(os.path.join(self.fn_results, "*.pdf")):
-            os.remove(f)
-
-        del self.pool
-
-        # save TestBench object
-        print("Saving testbench.pkl object ...")
-        write_session_pkl(self, os.path.join(self.fn_results, "testbench.pkl"))
-
-
-class TestBenchContinuous(TestBench):
-    """
-    TestBenchContinuous
-
-    Parameters
-    ----------
-    algorithm : pygpc.Algorithm Object
-        Algorithm to benchmark
-    options : Dict or OrderedDict()
-        Algorithm options
-    repetitions : int
-        Number of repeated runs
-    n_cpu : int
-        Number of threads to run pygpc.Problems in parallel
-    """
-    def __init__(self, algorithm, options, repetitions, n_cpu=1):
-        """
-        Initializes TestBenchContinuous class. Setting up pygpc.Problem instances.
-        """
-        self.dims = []
-        self.validation = OrderedDict()
-
-        # set up test problems
-        problem = OrderedDict()
-        problem["BohachevskyFunction1"] = BohachevskyFunction1().problem
-        # problem["BoothFunction"] = BoothFunction().problem
-        # problem["BukinFunctionNumber6"] = BukinFunctionNumber6().problem
-        # problem["Franke"] = Franke().problem
-        # problem["Ishigami_2D"] = Ishigami(dim=2).problem
-        # problem["Ishigami_3D"] = Ishigami(dim=3).problem
-        # problem["Lim2002"] = Lim2002().problem
-        # problem["MatyasFunction"] = MatyasFunction().problem
-        problem["McCormickFunction"] = McCormickFunction().problem
-        # problem["Peaks"] = Peaks().problem
-        # problem["SixHumpCamelFunction"] = SixHumpCamelFunction().problem
-
-        # create validation sets
-        for p in problem:
-            gpc = GPC(problem=problem[p], options=None, validation=None)
-            gpc.create_validation_set(n_samples=int(1e4), n_cpu=options["n_cpu"])
-            self.validation[p] = gpc.validation
-
-        super(TestBenchContinuous, self).__init__(algorithm, problem, options, repetitions, n_cpu)
-
-
-class TestBenchContinuousND(TestBench):
-    """
-    TestBenchContinuousND
-
-    Parameters
-    ----------
-    algorithm : pygpc.Algorithm Object
-        Algorithm to benchmark
-    options : Dict or OrderedDict()
-        Algorithm options
-    dims : list of int
-        Number of dimensions
-    repetitions : int
-        Number of repeated runs
-    n_cpu : int
-        Number of threads to run pygpc.Problems in parallel
-    """
-    def __init__(self, algorithm, options, dims, repetitions, n_cpu=1):
-        """
-        Initializes TestBenchContinuousND class. Setting up pygpc.Problem instances.
-        """
-        self.dims = dims
-        self.validation = OrderedDict()
-
-        # set up test problems
-        problem = OrderedDict()
-
-        for d in dims:
-            problem["DixonPriceFunction{}D".format(d)] = DixonPriceFunction(dim=d).problem
-            problem["GenzContinuous_{}D".format(d)] = GenzContinuous(dim=d).problem
-            problem["GenzCornerPeak_{}D".format(d)] = GenzCornerPeak(dim=d).problem
-            problem["GenzGaussianPeak_{}D".format(d)] = GenzGaussianPeak(dim=d).problem
-            problem["GenzOscillatory_{}D".format(d)] = GenzOscillatory(dim=d).problem
-            problem["GenzProductPeak_{}D".format(d)] = GenzProductPeak(dim=d).problem
-            problem["GFunction_{}D".format(d)] = GFunction(dim=d).problem
-            problem["ManufactureDecay_{}D".format(d)] = ManufactureDecay(dim=d).problem
-            problem["PermFunction{}D".format(d)] = PermFunction(dim=d).problem
-            problem["Ridge_{}D".format(d)] = Ridge(dim=d).problem
-            problem["RosenbrockFunction{}D".format(d)] = RosenbrockFunction(dim=d).problem
-            problem["RotatedHyperEllipsoid{}D".format(d)] = RotatedHyperEllipsoid(dim=d).problem
-            problem["SphereFunction{}D".format(d)] = SphereFunction(dim=d).problem
-            problem["SumOfDifferentPowersFunction{}D".format(d)] = SumOfDifferentPowersFunction(dim=d).problem
-            problem["ZakharovFunction{}D".format(d)] = ZakharovFunction(dim=d).problem
-
-        # create validation sets
-        for p in problem:
-            gpc = GPC(problem=problem[p], options=None, validation=None)
-            gpc.create_validation_set(n_samples=int(1e4), n_cpu=options["n_cpu"])
-            self.validation[p] = gpc.validation
-
-        super(TestBenchContinuousND, self).__init__(algorithm, problem, options, repetitions, n_cpu)
-
-
-class TestBenchContinuousHD(TestBench):
-    """
-    TestBenchContinuousHD
-
-    Parameters
-    ----------
-    algorithm : pygpc.Algorithm Object
-        Algorithm to benchmark
-    options : Dict or OrderedDict()
-        Algorithm options
-    repetitions : int
-        Number of repeated runs
-    n_cpu : int
-        Number of threads to run pygpc.Problems in parallel
-    """
-    def __init__(self, algorithm, options, repetitions, n_cpu=1):
-        """
-        Initializes TestBenchContinuousND class. Setting up pygpc.Problem instances.
-        """
-        self.dims = []
-        self.validation = OrderedDict()
-
-        # set up test problems
-        problem = OrderedDict()
-        problem["OakleyOhagan2004"] = OakleyOhagan2004().problem
-        problem["Welch1992"] = Welch1992().problem
-        # problem["WingWeight"] = WingWeight().problem
-
-        # create validation sets
-        for p in problem:
-            gpc = GPC(problem=problem[p], options=None, validation=None)
-            gpc.create_validation_set(n_samples=int(1e4), n_cpu=options["n_cpu"])
-            self.validation[p] = gpc.validation
-
-        super(TestBenchContinuousHD, self).__init__(algorithm, problem, options, repetitions, n_cpu)
-
-
-class TestBenchDiscontinuous(TestBench):
-    """
-    TestBenchDiscontinuous
-
-    Parameters
-    ----------
-    algorithm : pygpc.Algorithm Object
-        Algorithm to benchmark
-    options : Dict or OrderedDict()
-        Algorithm options
-    repetitions : int
-        Number of repeated runs
-    n_cpu : int
-        Number of threads to run pygpc.Problems in parallel
-    """
-    def __init__(self, algorithm, options, repetitions, n_cpu=1):
-        """
-        Initializes TestBenchDiscontinuous class. Setting up pygpc.Problem instances.
-        """
-        self.dims = []
-        self.validation = OrderedDict()
-
-        # set up test problems
-        problem = OrderedDict()
-        problem["Cluster3Simple"] = Cluster3Simple().problem
-        problem["DeJongFunctionFive"] = DeJongFunctionFive().problem
-        problem["HyperbolicTangent"] = HyperbolicTangent().problem
-        problem["MovingParticleFrictionForce"] = MovingParticleFrictionForce().problem
-        problem["SurfaceCoverageSpecies_2D"] = SurfaceCoverageSpecies(dim=2).problem
-        problem["SurfaceCoverageSpecies_3D"] = SurfaceCoverageSpecies(dim=3).problem
-
-        # create validation sets
-        for p in problem:
-            gpc = GPC(problem=problem[p], options=None, validation=None)
-            gpc.create_validation_set(n_samples=int(1e4), n_cpu=options["n_cpu"])
-            self.validation[p] = gpc.validation
-
-        super(TestBenchDiscontinuous, self).__init__(algorithm, problem, options, repetitions, n_cpu)
-
-
-class TestBenchDiscontinuousND(TestBench):
-    """
-    TestBenchDiscontinuousND
-
-    Parameters
-    ----------
-    algorithm : pygpc.Algorithm Object
-        Algorithm to benchmark
-    options : Dict or OrderedDict()
-        Algorithm options
-    dims : list of int
-        Number of dimensions
-    repetitions : int
-        Number of repeated runs
-    n_cpu : int
-        Number of threads to run pygpc.Problems in parallel
-    """
-
-    def __init__(self, algorithm, options, dims, repetitions, n_cpu=1):
-        """
-        Initializes TestBenchDiscontinuousND class. Setting up pygpc.Problem instances.
-        """
-        self.dims = dims
-        self.validation = OrderedDict()
-
-        # set up test problems
-        problem = OrderedDict()
-        for d in dims:
-            problem["GenzDiscontinuous_{}D".format(d)] = GenzDiscontinuous().problem
-            problem["MichalewiczFunction{}D".format(d)] = MichalewiczFunction().problem
-
-        # create validation sets
-        for p in problem:
-            gpc = GPC(problem=problem[p], options=None, validation=None)
-            gpc.create_validation_set(n_samples=int(1e4), n_cpu=options["n_cpu"])
-            self.validation[p] = gpc.validation
-
-        super(TestBenchDiscontinuousND, self).__init__(algorithm, problem, options, repetitions, n_cpu)
-
-
-class TestBenchNoisy(TestBench):
-    """
-    TestBenchNoisy
-
-    Parameters
-    ----------
-    algorithm : pygpc.Algorithm Object
-        Algorithm to benchmark
-    options : Dict or OrderedDict()
-        Algorithm options
-    repetitions : int
-        Number of repeated runs
-    n_cpu : int
-        Number of threads to run pygpc.Problems in parallel
-    """
-    def __init__(self, algorithm, options, repetitions, n_cpu=1):
-        """
-        Initializes TestBenchNoisy class. Setting up pygpc.Problem instances.
-        """
-        self.dims = []
-        self.validation = OrderedDict()
-
-        # set up test problems
-        problem = OrderedDict()
-        problem["CrossinTrayFunction"] = CrossinTrayFunction().problem
-        problem["DropWaveFunction"] = DropWaveFunction().problem
-        problem["GramacyLeeFunction"] = GramacyLeeFunction().problem
-        problem["SchafferFunction4"] = SchafferFunction4().problem
-
-        # create validation sets
-        for p in problem:
-            gpc = GPC(problem=problem[p], options=None, validation=None)
-            gpc.create_validation_set(n_samples=int(1e4), n_cpu=options["n_cpu"])
-            self.validation[p] = gpc.validation
-
-        super(TestBenchNoisy, self).__init__(algorithm, problem, options, repetitions, n_cpu)
-
-
-class TestBenchNoisyND(TestBench):
-    """
-    TestBenchNoisyND
-
-    Parameters
-    ----------
-    algorithm : pygpc.Algorithm Object
-        Algorithm to benchmark
-    options : Dict or OrderedDict()
-        Algorithm options
-    dims : list of int
-        Number of dimensions
-    repetitions : int
-        Number of repeated runs
-    n_cpu : int
-        Number of threads to run pygpc.Problems in parallel
-    """
-    def __init__(self, algorithm, options, dims, repetitions, n_cpu=1):
-        """
-        Initializes TestBenchNoisyND class. Setting up pygpc.Problem instances.
-        """
-        self.dims = dims
-        self.validation = OrderedDict()
-
-        # set up test problems
-        problem = OrderedDict()
-        for d in dims:
-            problem["Ackley{}D".format(d)] = Ackley().problem
-
-        # create validation sets
-        for p in problem:
-            gpc = GPC(problem=problem[p], options=None, validation=None)
-            gpc.create_validation_set(n_samples=int(1e4), n_cpu=options["n_cpu"])
-            self.validation[p] = gpc.validation
-
-        super(TestBenchNoisyND, self).__init__(algorithm, problem, options, repetitions, n_cpu)
+import copy
+import glob
+import h5py
+import multiprocessing
+import multiprocessing.pool
+import os
+import pickle
+from _functools import partial
+from collections import OrderedDict
+from .io import write_session_pkl
+from .Algorithm import *
+from .Test import *
+from .misc import *
+from .postprocessing import *
+from .validation import *
+from .Session import *
+
+
+def run_test(session):
+    print("Running: Algorithm: {}   -    Problem: {}".format(type(session).__name__,
+                                                             os.path.split(session.fn_results)[1]))
+    session, coeffs, results = session.run()
+
+    # Post-process gPC
+    get_sensitivities_hdf5(fn_gpc=session.fn_results,
+                           output_idx=None,
+                           calc_sobol=True,
+                           calc_global_sens=True,
+                           calc_pdf=True)
+
+    # Validate gPC vs original model function (2D-surface)
+    if len(list(session.parameters_random.keys())) == 1:
+        random_vars = list(session.parameters_random.keys())
+        n_grid = [101]
+    else:
+        random_vars = list(session.parameters_random.keys())[0:2]
+        n_grid = [51, 51]
+
+    validate_gpc_plot(session=session,
+                      coeffs=coeffs,
+                      random_vars=random_vars,
+                      n_grid=n_grid,
+                      output_idx=0,
+                      fn_out=session.fn_results + "_val",
+                      n_cpu=session.n_cpu)
+
+    return session
+
+
+class TestBench(object):
+    """
+    TestBench for gPC algorithms
+
+    Parameters
+    ----------
+    algorithm : pygpc.Algorithm Object
+        Algorithm to benchmark
+    problem : Dict() or OrderedDict() of pygpc.Problem instances
+        Problem instances to test
+    options : Dict or OrderedDict()
+        Algorithm options
+    repetitions : int (default=1)
+        Number of repeated runs
+    n_cpu : int (default=1)
+        Number of threads to run tests in parallel
+    """
+
+    def __init__(self, algorithm, problem, options, repetitions=1, n_cpu=1):
+        """
+        Initializes the TestBench class object instance
+        """
+        self.session = OrderedDict()
+        self.session_keys = []
+        self.algorithm = OrderedDict()
+        self.algorithm_type = algorithm
+        self.problem = problem
+        self.fn_results = copy.deepcopy(options["fn_results"])
+        self.repetitions = repetitions
+        self.problem_keys = list(problem.keys())
+
+        # Setting up parallelization (setup thread pool)
+        n_cpu_available = multiprocessing.cpu_count()
+        self.n_cpu = min(n_cpu, n_cpu_available)
+        self.pool = multiprocessing.Pool(n_cpu)
+        self.run_test_partial = partial(run_test)
+
+        if "seed" not in list(options.keys()):
+            options["seed"] = None
+
+        for key in self.problem_keys:
+            for rep in range(repetitions):
+
+                self.session_keys.append(key + "_" + str(rep).zfill(4))
+
+                if algorithm == Static:
+                    options["fn_results"] = os.path.join(self.fn_results,
+                                                         key + "_p_{}_".format(options["order"][0]) + str(rep).zfill(4))
+                    options["order"] = [options["order"][0] for _ in range(problem[key].dim)]
+                    n_coeffs = get_num_coeffs_sparse(order_dim_max=options["order"],
+                                                     order_glob_max=options["order_max"],
+                                                     order_inter_max=options["interaction_order"],
+                                                     order_glob_max_norm=options["order_max_norm"],
+                                                     dim=problem[key].dim)
+
+                    grid = options["grid"](parameters_random=problem[key].parameters_random,
+                                           n_grid=options["matrix_ratio"] * n_coeffs,
+                                           seed=options["seed"],
+                                           options=options["grid_options"])
+
+                    self.algorithm[self.session_keys[-1]] = algorithm(problem=problem[key],
+                                                                      options=copy.deepcopy(options),
+                                                                      grid=copy.deepcopy(grid))
+
+                elif algorithm == StaticProjection:
+                    options["fn_results"] = os.path.join(self.fn_results,
+                                                         key + "_p_{}_".format(options["order"][0]) + str(rep).zfill(4))
+
+                    self.algorithm[self.session_keys[-1]] = algorithm(problem=problem[key],
+                                                                      options=copy.deepcopy(options))
+
+                else:
+                    options["fn_results"] = os.path.join(self.fn_results, key + "_" + str(rep).zfill(4))
+                    self.algorithm[self.session_keys[-1]] = algorithm(problem=problem[key],
+                                                                      options=copy.deepcopy(options))
+
+                self.session[self.session_keys[-1]] = Session(algorithm=self.algorithm[self.session_keys[-1]])
+
+    def run(self):
+        """
+        Run algorithms with test problems and save results
+        """
+
+        session_list = [self.session[key] for key in list(self.session.keys())]
+
+        # for session in session_list:
+        #     run_test(session)
+        session_list = self.pool.map(self.run_test_partial, session_list)
+        self.pool.close()
+        self.pool.join()
+
+        # transform session list back to dict
+        for i, key in enumerate(self.session_keys):
+            self.session[key] = session_list[i]
+
+        print("Merging .hdf5 files ...")
+        # merge .hdf5 files of repetitions
+        for key in self.problem_keys:
+
+            # merge gpc files
+            print(key)
+            if isinstance(self.session[key + "_0000"].algorithm, Static) or \
+                    isinstance(self.session[key + "_0000"].algorithm, StaticProjection):
+
+                fn_hdf5 = os.path.join(self.fn_results, key + "_p_{}".format(
+                    self.session[key + "_0000"].gpc[0].options["order"][0])) + ".hdf5"
+            else:
+                fn_hdf5 = os.path.join(self.fn_results, key) + ".hdf5"
+
+            with h5py.File(fn_hdf5, 'w') as f:
+
+                for rep in range(self.repetitions):
+                    f.create_group(str(rep).zfill(4))
+
+                    with h5py.File(self.session[key + "_" + str(rep).zfill(4)].fn_results + ".hdf5", 'r') as g:
+                        for gkey in list(g.keys()):
+                            g.copy(gkey, f[str(rep).zfill(4)])
+
+                    # delete individual .hdf5 files
+                    os.remove(self.session[key + "_" + str(rep).zfill(4)].fn_results + ".hdf5")
+
+            # merge validation files
+            with h5py.File(os.path.join(self.fn_results, key) + "_val.hdf5", 'w') as f:
+                for rep in range(self.repetitions):
+                    f.create_group(str(rep).zfill(4))
+
+                    with h5py.File(os.path.splitext(self.algorithm[key + "_" +
+                                   str(rep).zfill(4)].options["fn_results"])[0] + "_val.hdf5", 'r') as g:
+                        for gkey in list(g.keys()):
+                            g.copy(gkey, f[str(rep).zfill(4)])
+
+                    # delete individual .hdf5 files
+                    os.remove(os.path.splitext(self.algorithm[key +
+                              "_" + str(rep).zfill(4)].options["fn_results"])[0] + "_val.hdf5")
+
+        # delete .pdf files
+        for f in glob.glob(os.path.join(self.fn_results, "*.pdf")):
+            os.remove(f)
+
+        del self.pool
+
+        # save TestBench object
+        print("Saving testbench.pkl object ...")
+        write_session_pkl(self, os.path.join(self.fn_results, "testbench.pkl"))
+
+
+class TestBenchContinuous(TestBench):
+    """
+    TestBenchContinuous
+
+    Parameters
+    ----------
+    algorithm : pygpc.Algorithm Object
+        Algorithm to benchmark
+    options : Dict or OrderedDict()
+        Algorithm options
+    repetitions : int
+        Number of repeated runs
+    n_cpu : int
+        Number of threads to run pygpc.Problems in parallel
+    """
+    def __init__(self, algorithm, options, repetitions, n_cpu=1):
+        """
+        Initializes TestBenchContinuous class. Setting up pygpc.Problem instances.
+        """
+        self.dims = []
+        self.validation = OrderedDict()
+
+        # set up test problems
+        problem = OrderedDict()
+        problem["BohachevskyFunction1"] = BohachevskyFunction1().problem
+        # problem["BoothFunction"] = BoothFunction().problem
+        # problem["BukinFunctionNumber6"] = BukinFunctionNumber6().problem
+        # problem["Franke"] = Franke().problem
+        # problem["Ishigami_2D"] = Ishigami(dim=2).problem
+        # problem["Ishigami_3D"] = Ishigami(dim=3).problem
+        # problem["Lim2002"] = Lim2002().problem
+        # problem["MatyasFunction"] = MatyasFunction().problem
+        problem["McCormickFunction"] = McCormickFunction().problem
+        # problem["Peaks"] = Peaks().problem
+        # problem["SixHumpCamelFunction"] = SixHumpCamelFunction().problem
+
+        # create validation sets
+        for p in problem:
+            gpc = GPC(problem=problem[p], options=None, validation=None)
+            gpc.create_validation_set(n_samples=int(1e4), n_cpu=options["n_cpu"])
+            self.validation[p] = gpc.validation
+
+        super(TestBenchContinuous, self).__init__(algorithm, problem, options, repetitions, n_cpu)
+
+
+class TestBenchContinuousND(TestBench):
+    """
+    TestBenchContinuousND
+
+    Parameters
+    ----------
+    algorithm : pygpc.Algorithm Object
+        Algorithm to benchmark
+    options : Dict or OrderedDict()
+        Algorithm options
+    dims : list of int
+        Number of dimensions
+    repetitions : int
+        Number of repeated runs
+    n_cpu : int
+        Number of threads to run pygpc.Problems in parallel
+    """
+    def __init__(self, algorithm, options, dims, repetitions, n_cpu=1):
+        """
+        Initializes TestBenchContinuousND class. Setting up pygpc.Problem instances.
+        """
+        self.dims = dims
+        self.validation = OrderedDict()
+
+        # set up test problems
+        problem = OrderedDict()
+
+        for d in dims:
+            problem["DixonPriceFunction{}D".format(d)] = DixonPriceFunction(dim=d).problem
+            problem["GenzContinuous_{}D".format(d)] = GenzContinuous(dim=d).problem
+            problem["GenzCornerPeak_{}D".format(d)] = GenzCornerPeak(dim=d).problem
+            problem["GenzGaussianPeak_{}D".format(d)] = GenzGaussianPeak(dim=d).problem
+            problem["GenzOscillatory_{}D".format(d)] = GenzOscillatory(dim=d).problem
+            problem["GenzProductPeak_{}D".format(d)] = GenzProductPeak(dim=d).problem
+            problem["GFunction_{}D".format(d)] = GFunction(dim=d).problem
+            problem["ManufactureDecay_{}D".format(d)] = ManufactureDecay(dim=d).problem
+            problem["PermFunction{}D".format(d)] = PermFunction(dim=d).problem
+            problem["Ridge_{}D".format(d)] = Ridge(dim=d).problem
+            problem["RosenbrockFunction{}D".format(d)] = RosenbrockFunction(dim=d).problem
+            problem["RotatedHyperEllipsoid{}D".format(d)] = RotatedHyperEllipsoid(dim=d).problem
+            problem["SphereFunction{}D".format(d)] = SphereFunction(dim=d).problem
+            problem["SumOfDifferentPowersFunction{}D".format(d)] = SumOfDifferentPowersFunction(dim=d).problem
+            problem["ZakharovFunction{}D".format(d)] = ZakharovFunction(dim=d).problem
+
+        # create validation sets
+        for p in problem:
+            gpc = GPC(problem=problem[p], options=None, validation=None)
+            gpc.create_validation_set(n_samples=int(1e4), n_cpu=options["n_cpu"])
+            self.validation[p] = gpc.validation
+
+        super(TestBenchContinuousND, self).__init__(algorithm, problem, options, repetitions, n_cpu)
+
+
+class TestBenchContinuousHD(TestBench):
+    """
+    TestBenchContinuousHD
+
+    Parameters
+    ----------
+    algorithm : pygpc.Algorithm Object
+        Algorithm to benchmark
+    options : Dict or OrderedDict()
+        Algorithm options
+    repetitions : int
+        Number of repeated runs
+    n_cpu : int
+        Number of threads to run pygpc.Problems in parallel
+    """
+    def __init__(self, algorithm, options, repetitions, n_cpu=1):
+        """
+        Initializes TestBenchContinuousND class. Setting up pygpc.Problem instances.
+        """
+        self.dims = []
+        self.validation = OrderedDict()
+
+        # set up test problems
+        problem = OrderedDict()
+        problem["OakleyOhagan2004"] = OakleyOhagan2004().problem
+        problem["Welch1992"] = Welch1992().problem
+        # problem["WingWeight"] = WingWeight().problem
+
+        # create validation sets
+        for p in problem:
+            gpc = GPC(problem=problem[p], options=None, validation=None)
+            gpc.create_validation_set(n_samples=int(1e4), n_cpu=options["n_cpu"])
+            self.validation[p] = gpc.validation
+
+        super(TestBenchContinuousHD, self).__init__(algorithm, problem, options, repetitions, n_cpu)
+
+
+class TestBenchDiscontinuous(TestBench):
+    """
+    TestBenchDiscontinuous
+
+    Parameters
+    ----------
+    algorithm : pygpc.Algorithm Object
+        Algorithm to benchmark
+    options : Dict or OrderedDict()
+        Algorithm options
+    repetitions : int
+        Number of repeated runs
+    n_cpu : int
+        Number of threads to run pygpc.Problems in parallel
+    """
+    def __init__(self, algorithm, options, repetitions, n_cpu=1):
+        """
+        Initializes TestBenchDiscontinuous class. Setting up pygpc.Problem instances.
+        """
+        self.dims = []
+        self.validation = OrderedDict()
+
+        # set up test problems
+        problem = OrderedDict()
+        problem["Cluster3Simple"] = Cluster3Simple().problem
+        problem["DeJongFunctionFive"] = DeJongFunctionFive().problem
+        problem["HyperbolicTangent"] = HyperbolicTangent().problem
+        problem["MovingParticleFrictionForce"] = MovingParticleFrictionForce().problem
+        problem["SurfaceCoverageSpecies_2D"] = SurfaceCoverageSpecies(dim=2).problem
+        problem["SurfaceCoverageSpecies_3D"] = SurfaceCoverageSpecies(dim=3).problem
+
+        # create validation sets
+        for p in problem:
+            gpc = GPC(problem=problem[p], options=None, validation=None)
+            gpc.create_validation_set(n_samples=int(1e4), n_cpu=options["n_cpu"])
+            self.validation[p] = gpc.validation
+
+        super(TestBenchDiscontinuous, self).__init__(algorithm, problem, options, repetitions, n_cpu)
+
+
+class TestBenchDiscontinuousND(TestBench):
+    """
+    TestBenchDiscontinuousND
+
+    Parameters
+    ----------
+    algorithm : pygpc.Algorithm Object
+        Algorithm to benchmark
+    options : Dict or OrderedDict()
+        Algorithm options
+    dims : list of int
+        Number of dimensions
+    repetitions : int
+        Number of repeated runs
+    n_cpu : int
+        Number of threads to run pygpc.Problems in parallel
+    """
+
+    def __init__(self, algorithm, options, dims, repetitions, n_cpu=1):
+        """
+        Initializes TestBenchDiscontinuousND class. Setting up pygpc.Problem instances.
+        """
+        self.dims = dims
+        self.validation = OrderedDict()
+
+        # set up test problems
+        problem = OrderedDict()
+        for d in dims:
+            problem["GenzDiscontinuous_{}D".format(d)] = GenzDiscontinuous().problem
+            problem["MichalewiczFunction{}D".format(d)] = MichalewiczFunction().problem
+
+        # create validation sets
+        for p in problem:
+            gpc = GPC(problem=problem[p], options=None, validation=None)
+            gpc.create_validation_set(n_samples=int(1e4), n_cpu=options["n_cpu"])
+            self.validation[p] = gpc.validation
+
+        super(TestBenchDiscontinuousND, self).__init__(algorithm, problem, options, repetitions, n_cpu)
+
+
+class TestBenchNoisy(TestBench):
+    """
+    TestBenchNoisy
+
+    Parameters
+    ----------
+    algorithm : pygpc.Algorithm Object
+        Algorithm to benchmark
+    options : Dict or OrderedDict()
+        Algorithm options
+    repetitions : int
+        Number of repeated runs
+    n_cpu : int
+        Number of threads to run pygpc.Problems in parallel
+    """
+    def __init__(self, algorithm, options, repetitions, n_cpu=1):
+        """
+        Initializes TestBenchNoisy class. Setting up pygpc.Problem instances.
+        """
+        self.dims = []
+        self.validation = OrderedDict()
+
+        # set up test problems
+        problem = OrderedDict()
+        problem["CrossinTrayFunction"] = CrossinTrayFunction().problem
+        problem["DropWaveFunction"] = DropWaveFunction().problem
+        problem["GramacyLeeFunction"] = GramacyLeeFunction().problem
+        problem["SchafferFunction4"] = SchafferFunction4().problem
+
+        # create validation sets
+        for p in problem:
+            gpc = GPC(problem=problem[p], options=None, validation=None)
+            gpc.create_validation_set(n_samples=int(1e4), n_cpu=options["n_cpu"])
+            self.validation[p] = gpc.validation
+
+        super(TestBenchNoisy, self).__init__(algorithm, problem, options, repetitions, n_cpu)
+
+
+class TestBenchNoisyND(TestBench):
+    """
+    TestBenchNoisyND
+
+    Parameters
+    ----------
+    algorithm : pygpc.Algorithm Object
+        Algorithm to benchmark
+    options : Dict or OrderedDict()
+        Algorithm options
+    dims : list of int
+        Number of dimensions
+    repetitions : int
+        Number of repeated runs
+    n_cpu : int
+        Number of threads to run pygpc.Problems in parallel
+    """
+    def __init__(self, algorithm, options, dims, repetitions, n_cpu=1):
+        """
+        Initializes TestBenchNoisyND class. Setting up pygpc.Problem instances.
+        """
+        self.dims = dims
+        self.validation = OrderedDict()
+
+        # set up test problems
+        problem = OrderedDict()
+        for d in dims:
+            problem["Ackley{}D".format(d)] = Ackley().problem
+
+        # create validation sets
+        for p in problem:
+            gpc = GPC(problem=problem[p], options=None, validation=None)
+            gpc.create_validation_set(n_samples=int(1e4), n_cpu=options["n_cpu"])
+            self.validation[p] = gpc.validation
+
+        super(TestBenchNoisyND, self).__init__(algorithm, problem, options, repetitions, n_cpu)
```

## pygpc/ValidationSet.py

 * *Ordering differences only*

```diff
@@ -1,182 +1,182 @@
-import h5py
-import os
-from .misc import ten2mat
-from .misc import mat2ten
-from .Grid import Grid
-from .Grid import Random
-from .Computation import *
-
-
-class ValidationSet(object):
-    """
-    ValidationSet object
-
-    Parameters
-    ----------
-    grid : Grid object
-        Grid object containing the validation points (grid.coords, grid.coords_norm)
-    results : ndarray [n_grid x n_out]
-        Results of the model evaluation
-    gradient_results : ndarray [n_grid x n_out x dim], optional, default=None
-        Gradient of results of the model evaluations
-    gradient_idx : ndarray of int [n_grid]
-        Indices of grid points where the gradient was evaluated
-    problem : Problem instance, optional, default: None
-        GPC problem (needed to create a Validation set without GPC instance)
-    """
-
-    def __init__(self, grid=None, results=None, gradient_results=None, gradient_idx=None, problem=None):
-        """
-        Initializes ValidationSet
-        """
-        self.grid = grid
-        self.results = results
-        self.gradient_results = gradient_results
-        self.gradient_idx = gradient_idx
-        self.problem = problem
-
-    def create(self, grid=None, n_samples=None, n_cpu=1):
-        """
-        Creates a Validation set; Calls model and evaluates results; Provide either grid or number of samples.
-
-        Parameters
-        ----------
-        grid : Grid instance, optional, default: None
-            Grid instance the Validation set is computed with
-        n_samples : int, optional, default: None
-            Number of samples; if grid is provided, the validation set is created using the grid
-        n_cpu : int, optional, default: 1
-            Number of CPU cores to use to create validation set.
-        """
-        if grid is not None:
-            self.grid = grid
-
-        if self.grid is None and n_samples is not None:
-            self.grid = Random(parameters_random=self.problem.parameters_random,
-                               n_grid=n_samples)
-        else:
-            raise ValueError("Provide grid or n_samples to create a validation set.")
-
-        # Evaluate original model at grid points
-        com = Computation(n_cpu=n_cpu, matlab_model=self.problem.model.matlab_model)
-        self.results = com.run(model=self.problem.model, problem=self.problem, coords=self.grid.coords)
-
-        if self.results.ndim == 1:
-            self.results = self.results[:, np.newaxis]
-
-    def write(self, fname, folder=None, overwrite=False):
-        """
-        Save ValidationSet in .hdf5 format
-
-        Parameters
-        ----------
-        fname : str
-            Filename of ValidationSet containing the grid points and the results data
-        folder : str, optional, default: None
-            Path in .hdf5 file containing the validation set
-        overwrite : bool, optional, default: False
-            Overwrite existing validation set
-
-        Returns
-        -------
-        <file> : .hdf5 file
-            File containing the grid points in grid/coords and grid/coords_norm
-            and the corresponding results in model_evaluations/results
-        """
-        if folder is None:
-            folder = ""
-
-        with h5py.File(fname, 'a') as f:
-
-            try:
-                f.create_dataset(folder + "/grid/coords", data=self.grid.coords)
-                f.create_dataset(folder + "/grid/coords_norm", data=self.grid.coords_norm)
-                f.create_dataset(folder + "/model_evaluations/results", data=self.results)
-
-                if self.gradient_results is not None:
-                    f.create_dataset(folder + "/model_evaluations/gradient_results",
-                                     data=ten2mat(self.gradient_results))
-                    f.create_dataset(folder + "/model_evaluations/gradient_results_idx",
-                                     data=self.gradient_idx)
-
-            except RuntimeError:
-                if not overwrite:
-                    pass
-                else:
-                    if folder == "":
-                        folder_read = "/"
-                    for key in f[folder_read].keys():
-                        del f[folder + key]
-
-                    f.create_dataset(folder + "/grid/coords", data=self.grid.coords)
-                    f.create_dataset(folder + "/grid/coords_norm", data=self.grid.coords_norm)
-                    f.create_dataset(folder + "/model_evaluations/results", data=self.results)
-
-                    if self.gradient_results is not None:
-                        f.create_dataset(folder + "/model_evaluations/gradient_results",
-                                         data=ten2mat(self.gradient_results))
-                        f.create_dataset(folder + "/model_evaluations/gradient_results_idx",
-                                         data=self.gradient_idx)
-
-    def read(self, fname, folder=None, coords_key=None, coords_norm_key=None, results_key=None, gradient_results_key=None,
-             gradient_idx_key=None):
-        """ Load Validation set from .hdf5 format
-
-        Parameters
-        ----------
-        fname : str
-            Filename of ValidationSet containing the grid points and the results data
-        folder : str
-            Path in .hdf5 file containing the validation set
-        coords_key : str, optional, default: "grid/coords"
-            Path of coords in .hdf5 file
-        coords_norm_key : str, optional, default: "grid/coords_norm"
-            Path of coords_norm in .hdf5 file
-        results_key : str, optional, default: "model_evaluations/results"
-            Path of results in .hdf5 file
-        gradient_results_key : str, optional, default: "model_evaluations/gradient_results"
-            Path of gradient_results in .hdf5 file
-        gradient_idx_key : str, optional, default: "model_evaluations/gradient_results_idx"
-            Path of gradient_results in .hdf5 file
-
-        Returns
-        -------
-        val : ValidationSet Object
-            ValidationSet object containing the grid points and the results data
-        """
-        if folder is None:
-            folder = ""
-
-        if coords_key is None:
-            coords_key = folder + "/grid/coords"
-
-        if coords_norm_key is None:
-            coords_norm_key = folder + "/grid/coords_norm"
-
-        if results_key is None:
-            results_key = folder + "/model_evaluations/results"
-
-        if gradient_results_key is None:
-            gradient_results_key = folder + "/model_evaluations/gradient_results"
-
-        if gradient_idx_key is None:
-            gradient_idx_key = folder + "/model_evaluations/gradient_results_idx"
-
-        del self.results
-        del self.gradient_results
-        del self.gradient_idx
-
-        with h5py.File(fname, 'r') as f:
-            coords = f[coords_key][:]
-            coords_norm = f[coords_norm_key][:]
-            self.results = f[results_key][:]
-
-            try:
-                self.gradient_results = mat2ten(f[gradient_results_key][:])
-                self.gradient_idx = f[gradient_idx_key]
-            except KeyError:
-                pass
-
-        self.grid = Grid(parameters_random=[None]*coords.shape[1], coords=coords, coords_norm=coords_norm)
-
-        return self
+import h5py
+import os
+from .misc import ten2mat
+from .misc import mat2ten
+from .Grid import Grid
+from .Grid import Random
+from .Computation import *
+
+
+class ValidationSet(object):
+    """
+    ValidationSet object
+
+    Parameters
+    ----------
+    grid : Grid object
+        Grid object containing the validation points (grid.coords, grid.coords_norm)
+    results : ndarray [n_grid x n_out]
+        Results of the model evaluation
+    gradient_results : ndarray [n_grid x n_out x dim], optional, default=None
+        Gradient of results of the model evaluations
+    gradient_idx : ndarray of int [n_grid]
+        Indices of grid points where the gradient was evaluated
+    problem : Problem instance, optional, default: None
+        GPC problem (needed to create a Validation set without GPC instance)
+    """
+
+    def __init__(self, grid=None, results=None, gradient_results=None, gradient_idx=None, problem=None):
+        """
+        Initializes ValidationSet
+        """
+        self.grid = grid
+        self.results = results
+        self.gradient_results = gradient_results
+        self.gradient_idx = gradient_idx
+        self.problem = problem
+
+    def create(self, grid=None, n_samples=None, n_cpu=1):
+        """
+        Creates a Validation set; Calls model and evaluates results; Provide either grid or number of samples.
+
+        Parameters
+        ----------
+        grid : Grid instance, optional, default: None
+            Grid instance the Validation set is computed with
+        n_samples : int, optional, default: None
+            Number of samples; if grid is provided, the validation set is created using the grid
+        n_cpu : int, optional, default: 1
+            Number of CPU cores to use to create validation set.
+        """
+        if grid is not None:
+            self.grid = grid
+
+        if self.grid is None and n_samples is not None:
+            self.grid = Random(parameters_random=self.problem.parameters_random,
+                               n_grid=n_samples)
+        else:
+            raise ValueError("Provide grid or n_samples to create a validation set.")
+
+        # Evaluate original model at grid points
+        com = Computation(n_cpu=n_cpu, matlab_model=self.problem.model.matlab_model)
+        self.results = com.run(model=self.problem.model, problem=self.problem, coords=self.grid.coords)
+
+        if self.results.ndim == 1:
+            self.results = self.results[:, np.newaxis]
+
+    def write(self, fname, folder=None, overwrite=False):
+        """
+        Save ValidationSet in .hdf5 format
+
+        Parameters
+        ----------
+        fname : str
+            Filename of ValidationSet containing the grid points and the results data
+        folder : str, optional, default: None
+            Path in .hdf5 file containing the validation set
+        overwrite : bool, optional, default: False
+            Overwrite existing validation set
+
+        Returns
+        -------
+        <file> : .hdf5 file
+            File containing the grid points in grid/coords and grid/coords_norm
+            and the corresponding results in model_evaluations/results
+        """
+        if folder is None:
+            folder = ""
+
+        with h5py.File(fname, 'a') as f:
+
+            try:
+                f.create_dataset(folder + "/grid/coords", data=self.grid.coords)
+                f.create_dataset(folder + "/grid/coords_norm", data=self.grid.coords_norm)
+                f.create_dataset(folder + "/model_evaluations/results", data=self.results)
+
+                if self.gradient_results is not None:
+                    f.create_dataset(folder + "/model_evaluations/gradient_results",
+                                     data=ten2mat(self.gradient_results))
+                    f.create_dataset(folder + "/model_evaluations/gradient_results_idx",
+                                     data=self.gradient_idx)
+
+            except RuntimeError:
+                if not overwrite:
+                    pass
+                else:
+                    if folder == "":
+                        folder_read = "/"
+                    for key in f[folder_read].keys():
+                        del f[folder + key]
+
+                    f.create_dataset(folder + "/grid/coords", data=self.grid.coords)
+                    f.create_dataset(folder + "/grid/coords_norm", data=self.grid.coords_norm)
+                    f.create_dataset(folder + "/model_evaluations/results", data=self.results)
+
+                    if self.gradient_results is not None:
+                        f.create_dataset(folder + "/model_evaluations/gradient_results",
+                                         data=ten2mat(self.gradient_results))
+                        f.create_dataset(folder + "/model_evaluations/gradient_results_idx",
+                                         data=self.gradient_idx)
+
+    def read(self, fname, folder=None, coords_key=None, coords_norm_key=None, results_key=None, gradient_results_key=None,
+             gradient_idx_key=None):
+        """ Load Validation set from .hdf5 format
+
+        Parameters
+        ----------
+        fname : str
+            Filename of ValidationSet containing the grid points and the results data
+        folder : str
+            Path in .hdf5 file containing the validation set
+        coords_key : str, optional, default: "grid/coords"
+            Path of coords in .hdf5 file
+        coords_norm_key : str, optional, default: "grid/coords_norm"
+            Path of coords_norm in .hdf5 file
+        results_key : str, optional, default: "model_evaluations/results"
+            Path of results in .hdf5 file
+        gradient_results_key : str, optional, default: "model_evaluations/gradient_results"
+            Path of gradient_results in .hdf5 file
+        gradient_idx_key : str, optional, default: "model_evaluations/gradient_results_idx"
+            Path of gradient_results in .hdf5 file
+
+        Returns
+        -------
+        val : ValidationSet Object
+            ValidationSet object containing the grid points and the results data
+        """
+        if folder is None:
+            folder = ""
+
+        if coords_key is None:
+            coords_key = folder + "/grid/coords"
+
+        if coords_norm_key is None:
+            coords_norm_key = folder + "/grid/coords_norm"
+
+        if results_key is None:
+            results_key = folder + "/model_evaluations/results"
+
+        if gradient_results_key is None:
+            gradient_results_key = folder + "/model_evaluations/gradient_results"
+
+        if gradient_idx_key is None:
+            gradient_idx_key = folder + "/model_evaluations/gradient_results_idx"
+
+        del self.results
+        del self.gradient_results
+        del self.gradient_idx
+
+        with h5py.File(fname, 'r') as f:
+            coords = f[coords_key][:]
+            coords_norm = f[coords_norm_key][:]
+            self.results = f[results_key][:]
+
+            try:
+                self.gradient_results = mat2ten(f[gradient_results_key][:])
+                self.gradient_idx = f[gradient_idx_key]
+            except KeyError:
+                pass
+
+        self.grid = Grid(parameters_random=[None]*coords.shape[1], coords=coords, coords_norm=coords_norm)
+
+        return self
```

## pygpc/Visualization.py

```diff
@@ -1,509 +1,513 @@
-import numpy as np
-import os
-import sys
-import scipy.stats
-import matplotlib as mpl
-import matplotlib.pyplot as plt
-
-
-class Visualization:
-    """
-    Creates a new visualization in a new window. Any added sub-charts will be added to this window.
-
-    Visualisation(dims=(10, 10))
-
-    Attributes
-    ----------
-    Visualisation.figure_number: int, begin=0
-        Number of figures that have been created
-    Visualisation.horizontal_padding: float, default=0.4
-        Horizontal padding of plot
-    Visualisation.font_size_label: int, default=12
-        Font size of title
-    Visualisation.font_size_label: int, default=12
-        Font size of label
-    Visualisation.graph_lind_width: int, default 2
-        Line width of graph
-    fig: mpl.figure
-        Handle of figure created by matplotlib.pyplot
-
-    Parameters
-    ----------
-    dims: list of int, optional, default=(10,10)
-        Size of the newly created window
-    """
-
-    figure_number = 0
-    horizontal_padding = 0.4
-    font_size_label = 12
-    font_size_title = 12
-    graph_line_width = 2
-
-    def __init__(self, dims=(10, 10)):
-        self.fig = plt.figure(Visualization.figure_number, figsize=(dims[0], dims[0]), facecolor=[1, 1, 1])
-        Visualization.figure_number += 1
-        # add some horizontal spacing to avoid overlap with labels
-        plt.subplots_adjust(hspace=Visualization.horizontal_padding)
-        mpl.rcParams['text.usetex'] = True
-
-    def create_new_chart(self, layout_id=None):
-        """
-        Add a new subplot to the current visualization, so that multiple graphs can be overlaid onto one chart
-        (e.g. scatterplot over heatmap).
-
-        create_new_chart(layout_id=None)
-
-        Parameters
-        ----------
-        layout_id: (3-digit) int, optional, default=None
-            Denoting the position of the graph in figure (xyn : 'x'=width, 'y'=height of grid, 'n'=position within grid)
-        """
-        self.fig.add_subplot(layout_id)
-
-    def add_line_plot(self, title, labels, data, x_lim=None, y_lim=None):
-        """
-        Draw a 1D line graph into the current figure.
-
-        add_line_plot(title, labels, data, x_lim=None, y_lim=None)
-
-        Parameters
-        ----------
-        title: str
-            Title of the graph
-        labels: {str:str} dict
-            {'x': name of x-axis, 'y': name of y-axis}
-        x_lim: list of float [2], optional, default=None
-            x-limits for the function argument or value
-        y_lim: list of float [2], optional, default=None
-            y-limits for the function argument or value
-        data: ndarray of float
-            Data that should be plotted
-        """
-        self.create_sub_plot(title, labels, x_lim=x_lim, y_lim=y_lim)
-
-        for i in range(len(data['pointSets'])):
-            plt.plot(data['pointSets'][i]['x'], data['pointSets'][i]['y'],
-                     linestyle=data['linestyle'][i],
-                     color=data['color'][i],
-                     linewidth=Visualization.graph_line_width)
-
-        plt.legend(data['names'], loc="upper left")
-        plt.grid()
-
-    def add_heat_map(self, title, labels, grid_points, data_points, v_lim=(None, None),
-                     x_lim=None, y_lim=None, colormap=None):
-        """
-        Draw a 2D heatmap into the current figure.
-
-        add_heat_map(title, labels, grid_points, data_points, v_lim=(None, None), x_lim=None, y_lim=None, colormap=None)
-
-        Parameters
-        ----------
-        title: str
-            Title of the graph
-        labels: {str:str} dict
-            {'x': name of x-axis, 'y': name of y-axis}
-        grid_points: list of ndarray of float [2]
-            Arrays of the x and y positions of the grid points e.g.: [np.array(x_points), np.array(y_points)]
-        data_points: np.ndarray of the data points that are placed into the grid
-        x_lim: list of float [2], optional, default=None
-            x-limits for the function argument or value
-        y_lim: list of float [2], optional, default=None
-            y-limits for the function argument or value
-        v_lim: list of float [2], optional, default=(None,None)
-            Limits of the color scale
-        colormap: str, optional, default=None
-            The colormap to use
-        """
-        self.create_sub_plot(title, labels, x_lim=x_lim, y_lim=y_lim)
-
-        plt.pcolormesh(grid_points[0], grid_points[1], data_points, vmin=v_lim[0], vmax=v_lim[1], cmap=colormap)
-
-        plt.colorbar()
-
-    @staticmethod
-    def add_scatter_plot(shape, plot_size, color_sequence, colormap=None, v_lim=(None, None)):
-        """
-        Draw a scatter plot onto the current chart.
-
-        add_scatter_plot(shape, plot_size, color_sequence, colormap=None, v_lim=(None, None))
-
-        Parameters
-        ----------
-        shape: {str: np.ndarray} dict
-            {'x': positions on x-axis, 'y': positions on y-axis}
-        plot_size: ndarray of float
-            The marker size in the squared number of points
-        color_sequence: str or list of str
-            Marker colors
-        colormap: str, optional, default=None
-            The colormap to use
-        v_lim: list of float [2], optional, default=(None,None)
-            Limits of the color scale
-        """
-        plt.scatter(shape['x'], shape['y'], s=plot_size, c=color_sequence, vmin=v_lim[0], vmax=v_lim[1], cmap=colormap)
-
-    @staticmethod
-    def create_sub_plot(title, labels, x_lim, y_lim):
-        """
-        Set the title, labels and the axis limits of a plot.
-
-        create_sub_plot(title, labels, x_lim, y_lim)
-
-        Parameters
-        ----------
-        title: str
-            Title of the plot
-        labels: {str:str} dict
-            {'x': name of x-axis, 'y': name of y-axis}
-        x_lim: list of float [2]
-            x-limits for the function argument or value
-        y_lim: list of float [2]
-            y-limits for the function argument or value
-        """
-        plt.title(title, fontsize=Visualization.font_size_title)
-        plt.ylabel(labels['y'], fontsize=Visualization.font_size_label)
-        plt.xlabel(labels['x'], fontsize=Visualization.font_size_label)
-
-        ax = plt.gca()
-        if x_lim is not None:
-            ax.set_xlim(x_lim[0], x_lim[1])
-        if y_lim is not None:
-            ax.set_ylim(y_lim[0], y_lim[1])
-
-    @staticmethod
-    def show():
-        """
-        Show plots.
-        """
-        plt.show()
-
-
-def b2rcw(cmin_input, cmax_input):
-    """ Blue, white, and red color map.
-    This function is designed to generate a blue to red colormap. The color of the colorbar is from blue to white and
-    then to red, corresponding to the data values from negative to zero to positive, respectively.
-    The color white always corresponds to value zero. The brightness of blue and red will change according to your
-    setting, so that the brightness of the color corresponded to the color of his opposite number.
-
-    Parameters
-    ----------
-    cmin_input: float
-        Minimum value of data
-    cmax_input: float
-        Maximum value of data
-
-    Returns
-    -------
-    newmap: ndarray of float [N_RGB x 3]
-        Colormap
-
-    Examples
-    --------
-    >>> b2rcw_cmap_1 = make_cmap(b2rcw(-3, 6)) # is from light blue to deep red
-    >>> b2rcw_cmap_2 = make_cmap(b2rcw(-3, 3)) # is from deep blue to deep red
-    """
-
-    # check the input
-    if cmin_input >= cmax_input:
-        raise ValueError('input error, the color range must be from a smaller one to a larger one')
-
-    # color configuration : from blue to light blue to white until to red
-    red_top = np.array([1, 0, 0])
-    white_middle = np.array([1, 1, 1])
-    blue_bottom = np.array([0, 0, 1])
-
-    # color interpolation
-    color_num = 250
-    color_input = np.vstack((blue_bottom, white_middle, red_top))
-    oldsteps = np.array([-1, 0, 1])
-    newsteps = np.linspace(-1, 1, color_num)
-
-    newmap_all = np.zeros((color_num, 3))*np.nan
-
-    for j in range(3):
-        newmap_all[:, j] = np.min(np.vstack((np.max(
-            np.vstack((np.interp(newsteps, oldsteps, color_input[:, j]), np.zeros(color_num))), axis=0),
-                                             np.ones(color_num))), axis=0)
-
-    if (cmin_input < 0) & (cmax_input > 0):
-
-        if np.abs(cmin_input) < cmax_input:
-            #    |--------|---------|--------------------|
-            # -cmax      cmin       0                  cmax         [cmin,cmax]
-
-            start_point = int(np.ceil((cmin_input+cmax_input)/2.0/cmax_input*color_num)-1)
-            newmap = newmap_all[start_point:color_num, :]
-
-        elif np.abs(cmin_input) >= cmax_input:
-            #    |------------------|------|--------------|
-            #   cmin                0     cmax          -cmin         [cmin,cmax]
-
-            end_point = int(np.round((cmax_input-cmin_input)/2.0/np.abs(cmin_input)*color_num)-1)
-            newmap = newmap_all[1:end_point, :]
-
-    elif cmin_input >= 0:
-
-        #   |-----------------|-------|-------------|
-        # -cmax               0      cmin          cmax         [cmin,cmax]
-
-        start_point = int(np.round((cmin_input+cmax_input)/2.0/cmax_input*color_num)-1)
-        newmap = newmap_all[start_point:color_num, :]
-
-    elif cmax_input <= 0:
-        #   |------------|------|--------------------|
-        #  cmin         cmax    0                  -cmin         [cmin,cmax]
-
-        end_point = int(np.round((cmax_input-cmin_input)/2.0/np.abs(cmin_input)*color_num)-1)
-        newmap = newmap_all[1:end_point, :]
-
-    else:
-        newmap = None
-
-    return newmap
-
-
-def make_cmap(colors, position=None, bit=False):
-    """
-    make_cmap takes a list of tuples which contain RGB values. The RGB
-    values may either be in 8-bit [0 to 255] (in which bit must be set to
-    True when called) or arithmetic [0 to 1] (default). make_cmap returns
-    a cmap with equally spaced colors.
-    Arrange your tuples so that the first color is the lowest value for the
-    colorbar and the last is the highest.
-
-
-    Parameters
-    ----------
-    colors: list of 3-tuples [n_rgb]
-        RGB values. The RGB values may either be in 8-bit [0 to 255] (in which bit must be set to True when called)
-        or arithmetic [0 to 1] (default).
-    position: ndarray of float [n_rgb], optional, default=None
-        Contains values from 0 to 1 to dictate the location of each color.
-    bit: boolean, optional, default=False
-        Defines if colors are in 8-bit [0 to 255] (True) or arithmetic [0 to 1] (False)
-
-    Returns
-    -------
-    cmap: mpl.colors instance
-        Colormap
-    """
-
-    bit_rgb = np.linspace(0, 1, 256)
-    if position is None:
-        position = np.linspace(0, 1, len(colors))
-    else:
-        if len(position) != len(colors):
-            sys.exit("position length must be the same as colors")
-        elif position[0] != 0 or position[-1] != 1:
-            sys.exit("position must start with 0 and end with 1")
-    if bit:
-        for i in range(len(colors)):
-            colors[i] = (bit_rgb[colors[i][0]],
-                         bit_rgb[colors[i][1]],
-                         bit_rgb[colors[i][2]])
-    cdict = {'red': [], 'green': [], 'blue': []}
-    for pos, color in zip(position, colors):
-        cdict['red'].append((pos, color[0], color[0]))
-        cdict['green'].append((pos, color[1], color[1]))
-        cdict['blue'].append((pos, color[2], color[2]))
-
-    cmap = mpl.colors.LinearSegmentedColormap('my_colormap',cdict,256)
-    return cmap
-
-
-def plot_sobol_indices(sobol_rel_order_mean, sobol_rel_1st_order_mean, fn_plot, random_vars):
-    """
-    Plot the Sobol indices into different sub-plots.
-
-    plot_sobol_indices(sobol_rel_order_mean, sobol_rel_1st_order_mean, fn_plot, random_vars)
-
-    Parameters
-    ----------
-    sobol_rel_order_mean: ndarray of float [n_sobol]
-        Average proportion of the Sobol indices of the different order to the total variance (1st, 2nd, etc..,)
-        over all output quantities
-    sobol_rel_1st_order_mean: ndarray of float [dim]
-        Average proportion of the random variables of the 1st order Sobol indices to the total variance over all
-        output quantities
-    fn_plot: str
-        Filename of plot
-    random_vars: [dim] list of str
-        String labels of the random variables
-    """
-
-    # combine parameters < "perc_limit_show" in %
-    perc_limit_show = 0.03
-
-    # set the global colors
-    mpl.rcParams['text.color'] = '000000'
-    mpl.rcParams['figure.facecolor'] = '111111'
-
-    # set a global style
-    plt.style.use('seaborn-talk')
-
-    cmap = plt.cm.rainbow
-
-    # make pie plot of order ratios
-    labels = ['order=' + str(i) for i in range(1, len(sobol_rel_order_mean) + 1)]
-    mask = np.where(sobol_rel_order_mean >= perc_limit_show)[0]
-    mask_not = np.where(sobol_rel_order_mean < perc_limit_show)[0]
-    labels = [labels[idx] for idx in mask]
-    if mask_not.any():
-        labels.append('misc.')
-        values = np.hstack((sobol_rel_order_mean[mask], np.sum(sobol_rel_order_mean[mask_not])))
-    else:
-        values = sobol_rel_order_mean
-
-    colors = cmap(np.linspace(0.1, 0.9, len(labels)))
-
-    fig = plt.figure()
-    ax = fig.add_subplot(111, aspect='equal')
-    ax.set_title('Sobol indices (order)')
-    ax.pie(values, labels=labels, colors=colors,
-           autopct='%1.2f%%', shadow=True, explode=[0.1] * len(labels))
-    plt.savefig(os.path.splitext(fn_plot)[0] + '_order.png', facecolor='#ffffff')
-
-    # make pie plot of 1st order parameter ratios
-    mask = np.where(sobol_rel_1st_order_mean >= perc_limit_show)[0]
-    mask_not = np.where(sobol_rel_1st_order_mean < perc_limit_show)[0]
-    labels = [random_vars[idx] for idx in mask]
-    if mask_not.any():
-        labels.append('misc.')
-        values = np.hstack((sobol_rel_1st_order_mean[mask], np.sum(sobol_rel_1st_order_mean[mask_not])))
-    else:
-        values = sobol_rel_1st_order_mean
-
-    colors = cmap(np.linspace(0., 1., len(labels)))
-
-    fig = plt.figure()
-    ax = fig.add_subplot(111, aspect='equal')
-    ax.set_title('Sobol indices 1st order (parameters)')
-    ax.pie(values, labels=labels, colors=colors,
-           autopct='%1.2f%%', shadow=True, explode=[0.1] * len(labels))
-    plt.savefig(os.path.splitext(fn_plot)[0] + '_parameters.png', facecolor='#ffffff')
-
-
-def plot_2d_grid(coords, weights=None, fn_plot=None):
-    """
-    Plot 2D grid and save it as fn_plot.pdf
-
-    Parameters
-    ----------
-    coords: ndarray of float [n_grid, 2]
-        Grid points
-    weights: ndarray of float [n_grid], optional, default=None
-        Integration weights
-    fn_plot: str
-        Filename of plot so save (.pdf)
-
-    Returns
-    -------
-    <file> .pdf file
-        Plot of grid-points
-    """
-
-    if weights is not None:
-        weights = np.abs(weights)
-    else:
-        weights = np.ones(coords.shape[0])
-
-    # mpl.rc('text', usetex=True)
-    mpl.rc('xtick', labelsize=12)
-    mpl.rc('ytick', labelsize=12)
-
-    fig1, ax1 = plt.subplots(nrows=1, ncols=1, squeeze=True, figsize=(5.5, 5))
-    ax1.scatter(coords[:, 0], coords[:, 1], s=weights/np.max(weights)*20)
-    ax1.grid()
-    ax1.set_xlabel('$x_1$', fontsize=16)
-    ax1.set_ylabel('$x_2$', fontsize=16)
-
-    fn = os.path.splitext(fn_plot)[0]
-    plt.tight_layout()
-    plt.savefig(fn, facecolor='#ffffff', format="pdf")
-
-
-def plot_beta_pdf_fit(data, a_beta, b_beta, p_beta, q_beta, a_uni=None, b_uni=None,
-                      interactive=True, fn_plot=None, xlabel="$x$", ylabel="$p(x)$"):
-    """
-    Plot data, fitted beta pdf (and corresponding uniform) distribution
-
-    Parameters
-    ----------
-    data: ndarray of float
-        Data to fit beta distribution on
-    a_beta: float
-        Lower limit of beta distribution
-    b_beta: float
-        Upper limit of beta distribution
-    p_beta: float
-        First shape parameter of beta distribution
-    q_beta: float
-        Second shape parameter of beta distribution
-    a_uni: float (optional)
-        Lower limit of uniform distribution
-    b_uni: float (optional)
-        Upper limit of uniform distribution
-    interactive: bool, default = True
-        Show plot (True/False)
-    fn_plot:
-        Filename of plot so save (as .png and .pdf)
-    xlabel: str (optional)
-        Label of x-axis
-    ylabel: str (optional)
-        Label of y-axis
-
-    Returns
-    -------
-    <file> .png and .pdf files
-        Plots
-    """
-    #if not interactive:
-    #    plt.ioff()
-    #else:
-    #    plt.ion()
-
-    plt.figure(1)
-    plt.clf()
-    plt.rc('text', usetex=False)
-    plt.rc('font', size=18)
-    ax = plt.gca()
-    # legendtext = [r"e-pdf", r"$\beta$-pdf"]
-    legendtext = ["$\\beta$-pdf"]
-
-    # plot histogram of data
-    n, bins, patches = plt.hist(data, bins=16, density=1, color=[1, 1, 0.6], alpha=0.5)
-
-    # plot beta pdf (kernel density estimate)
-    # plt.plot(kde_x, kde_y, 'r--', linewidth=2)
-
-    # plot beta pdf (fitted)
-    beta_x = np.linspace(a_beta, b_beta, 100)
-    beta_y = scipy.stats.beta.pdf(beta_x, p_beta, q_beta, loc=a_beta, scale=b_beta - a_beta)
-
-    plt.plot(beta_x, beta_y, linewidth=2, color=[0, 0, 1])
-
-    # plot uniform pdf
-    uni_y = 0
-    if a_uni is not None and b_uni is not None:
-        uni_x = np.hstack([a_beta, a_uni - 1E-6 * (b_uni - a_uni),
-                           np.linspace(a_uni, b_uni, 100), b_uni + 1E-6 * (b_uni - a_uni), b_beta])
-        uni_y = np.hstack([0, 0, 1.0 / (b_uni - a_uni) * np.ones(100), 0, 0])
-        plt.plot(uni_x, uni_y, linewidth=2, color='r')
-        legendtext.append("u-pdf")
-
-        # configure plot
-    plt.legend(legendtext, fontsize=18, loc="upper left")
-    plt.grid(True)
-    plt.xlabel(xlabel, fontsize=22)
-    plt.ylabel(ylabel, fontsize=22)
-    ax.set_xlim(a_beta - 0.05 * (b_beta - a_beta), b_beta + 0.05 * (b_beta - a_beta))
-    # ax.set_ylim(0, 1.1 * max([max(n), max(beta_y[np.logical_not(beta_y == np.inf)]), max(uni_y)]))
-
-    if interactive > 0:
-        plt.show()
-
-    # save plot
-    if fn_plot is not None:
-        plt.savefig(fn_plot + ".pdf", format='pdf', bbox_inches='tight', pad_inches=0.01 * 4)
-        plt.savefig(fn_plot + ".png", format='png', bbox_inches='tight', pad_inches=0.01 * 4, dpi=600)
+import numpy as np
+import os
+import sys
+import scipy.stats
+
+try:
+    import matplotlib as mpl
+    import matplotlib.pyplot as plt
+except ImportError:
+    pass
+
+
+class Visualization:
+    """
+    Creates a new visualization in a new window. Any added sub-charts will be added to this window.
+
+    Visualisation(dims=(10, 10))
+
+    Attributes
+    ----------
+    Visualisation.figure_number: int, begin=0
+        Number of figures that have been created
+    Visualisation.horizontal_padding: float, default=0.4
+        Horizontal padding of plot
+    Visualisation.font_size_label: int, default=12
+        Font size of title
+    Visualisation.font_size_label: int, default=12
+        Font size of label
+    Visualisation.graph_lind_width: int, default 2
+        Line width of graph
+    fig: mpl.figure
+        Handle of figure created by matplotlib.pyplot
+
+    Parameters
+    ----------
+    dims: list of int, optional, default=(10,10)
+        Size of the newly created window
+    """
+
+    figure_number = 0
+    horizontal_padding = 0.4
+    font_size_label = 12
+    font_size_title = 12
+    graph_line_width = 2
+
+    def __init__(self, dims=(10, 10)):
+        self.fig = plt.figure(Visualization.figure_number, figsize=(dims[0], dims[0]), facecolor=[1, 1, 1])
+        Visualization.figure_number += 1
+        # add some horizontal spacing to avoid overlap with labels
+        plt.subplots_adjust(hspace=Visualization.horizontal_padding)
+        mpl.rcParams['text.usetex'] = True
+
+    def create_new_chart(self, layout_id=None):
+        """
+        Add a new subplot to the current visualization, so that multiple graphs can be overlaid onto one chart
+        (e.g. scatterplot over heatmap).
+
+        create_new_chart(layout_id=None)
+
+        Parameters
+        ----------
+        layout_id: (3-digit) int, optional, default=None
+            Denoting the position of the graph in figure (xyn : 'x'=width, 'y'=height of grid, 'n'=position within grid)
+        """
+        self.fig.add_subplot(layout_id)
+
+    def add_line_plot(self, title, labels, data, x_lim=None, y_lim=None):
+        """
+        Draw a 1D line graph into the current figure.
+
+        add_line_plot(title, labels, data, x_lim=None, y_lim=None)
+
+        Parameters
+        ----------
+        title: str
+            Title of the graph
+        labels: {str:str} dict
+            {'x': name of x-axis, 'y': name of y-axis}
+        x_lim: list of float [2], optional, default=None
+            x-limits for the function argument or value
+        y_lim: list of float [2], optional, default=None
+            y-limits for the function argument or value
+        data: ndarray of float
+            Data that should be plotted
+        """
+        self.create_sub_plot(title, labels, x_lim=x_lim, y_lim=y_lim)
+
+        for i in range(len(data['pointSets'])):
+            plt.plot(data['pointSets'][i]['x'], data['pointSets'][i]['y'],
+                     linestyle=data['linestyle'][i],
+                     color=data['color'][i],
+                     linewidth=Visualization.graph_line_width)
+
+        plt.legend(data['names'], loc="upper left")
+        plt.grid()
+
+    def add_heat_map(self, title, labels, grid_points, data_points, v_lim=(None, None),
+                     x_lim=None, y_lim=None, colormap=None):
+        """
+        Draw a 2D heatmap into the current figure.
+
+        add_heat_map(title, labels, grid_points, data_points, v_lim=(None, None), x_lim=None, y_lim=None, colormap=None)
+
+        Parameters
+        ----------
+        title: str
+            Title of the graph
+        labels: {str:str} dict
+            {'x': name of x-axis, 'y': name of y-axis}
+        grid_points: list of ndarray of float [2]
+            Arrays of the x and y positions of the grid points e.g.: [np.array(x_points), np.array(y_points)]
+        data_points: np.ndarray of the data points that are placed into the grid
+        x_lim: list of float [2], optional, default=None
+            x-limits for the function argument or value
+        y_lim: list of float [2], optional, default=None
+            y-limits for the function argument or value
+        v_lim: list of float [2], optional, default=(None,None)
+            Limits of the color scale
+        colormap: str, optional, default=None
+            The colormap to use
+        """
+        self.create_sub_plot(title, labels, x_lim=x_lim, y_lim=y_lim)
+
+        plt.pcolormesh(grid_points[0], grid_points[1], data_points, vmin=v_lim[0], vmax=v_lim[1], cmap=colormap)
+
+        plt.colorbar()
+
+    @staticmethod
+    def add_scatter_plot(shape, plot_size, color_sequence, colormap=None, v_lim=(None, None)):
+        """
+        Draw a scatter plot onto the current chart.
+
+        add_scatter_plot(shape, plot_size, color_sequence, colormap=None, v_lim=(None, None))
+
+        Parameters
+        ----------
+        shape: {str: np.ndarray} dict
+            {'x': positions on x-axis, 'y': positions on y-axis}
+        plot_size: ndarray of float
+            The marker size in the squared number of points
+        color_sequence: str or list of str
+            Marker colors
+        colormap: str, optional, default=None
+            The colormap to use
+        v_lim: list of float [2], optional, default=(None,None)
+            Limits of the color scale
+        """
+        plt.scatter(shape['x'], shape['y'], s=plot_size, c=color_sequence, vmin=v_lim[0], vmax=v_lim[1], cmap=colormap)
+
+    @staticmethod
+    def create_sub_plot(title, labels, x_lim, y_lim):
+        """
+        Set the title, labels and the axis limits of a plot.
+
+        create_sub_plot(title, labels, x_lim, y_lim)
+
+        Parameters
+        ----------
+        title: str
+            Title of the plot
+        labels: {str:str} dict
+            {'x': name of x-axis, 'y': name of y-axis}
+        x_lim: list of float [2]
+            x-limits for the function argument or value
+        y_lim: list of float [2]
+            y-limits for the function argument or value
+        """
+        plt.title(title, fontsize=Visualization.font_size_title)
+        plt.ylabel(labels['y'], fontsize=Visualization.font_size_label)
+        plt.xlabel(labels['x'], fontsize=Visualization.font_size_label)
+
+        ax = plt.gca()
+        if x_lim is not None:
+            ax.set_xlim(x_lim[0], x_lim[1])
+        if y_lim is not None:
+            ax.set_ylim(y_lim[0], y_lim[1])
+
+    @staticmethod
+    def show():
+        """
+        Show plots.
+        """
+        plt.show()
+
+
+def b2rcw(cmin_input, cmax_input):
+    """ Blue, white, and red color map.
+    This function is designed to generate a blue to red colormap. The color of the colorbar is from blue to white and
+    then to red, corresponding to the data values from negative to zero to positive, respectively.
+    The color white always corresponds to value zero. The brightness of blue and red will change according to your
+    setting, so that the brightness of the color corresponded to the color of his opposite number.
+
+    Parameters
+    ----------
+    cmin_input: float
+        Minimum value of data
+    cmax_input: float
+        Maximum value of data
+
+    Returns
+    -------
+    newmap: ndarray of float [N_RGB x 3]
+        Colormap
+
+    Examples
+    --------
+    >>> b2rcw_cmap_1 = make_cmap(b2rcw(-3, 6)) # is from light blue to deep red
+    >>> b2rcw_cmap_2 = make_cmap(b2rcw(-3, 3)) # is from deep blue to deep red
+    """
+
+    # check the input
+    if cmin_input >= cmax_input:
+        raise ValueError('input error, the color range must be from a smaller one to a larger one')
+
+    # color configuration : from blue to light blue to white until to red
+    red_top = np.array([1, 0, 0])
+    white_middle = np.array([1, 1, 1])
+    blue_bottom = np.array([0, 0, 1])
+
+    # color interpolation
+    color_num = 250
+    color_input = np.vstack((blue_bottom, white_middle, red_top))
+    oldsteps = np.array([-1, 0, 1])
+    newsteps = np.linspace(-1, 1, color_num)
+
+    newmap_all = np.zeros((color_num, 3))*np.nan
+
+    for j in range(3):
+        newmap_all[:, j] = np.min(np.vstack((np.max(
+            np.vstack((np.interp(newsteps, oldsteps, color_input[:, j]), np.zeros(color_num))), axis=0),
+                                             np.ones(color_num))), axis=0)
+
+    if (cmin_input < 0) & (cmax_input > 0):
+
+        if np.abs(cmin_input) < cmax_input:
+            #    |--------|---------|--------------------|
+            # -cmax      cmin       0                  cmax         [cmin,cmax]
+
+            start_point = int(np.ceil((cmin_input+cmax_input)/2.0/cmax_input*color_num)-1)
+            newmap = newmap_all[start_point:color_num, :]
+
+        elif np.abs(cmin_input) >= cmax_input:
+            #    |------------------|------|--------------|
+            #   cmin                0     cmax          -cmin         [cmin,cmax]
+
+            end_point = int(np.round((cmax_input-cmin_input)/2.0/np.abs(cmin_input)*color_num)-1)
+            newmap = newmap_all[1:end_point, :]
+
+    elif cmin_input >= 0:
+
+        #   |-----------------|-------|-------------|
+        # -cmax               0      cmin          cmax         [cmin,cmax]
+
+        start_point = int(np.round((cmin_input+cmax_input)/2.0/cmax_input*color_num)-1)
+        newmap = newmap_all[start_point:color_num, :]
+
+    elif cmax_input <= 0:
+        #   |------------|------|--------------------|
+        #  cmin         cmax    0                  -cmin         [cmin,cmax]
+
+        end_point = int(np.round((cmax_input-cmin_input)/2.0/np.abs(cmin_input)*color_num)-1)
+        newmap = newmap_all[1:end_point, :]
+
+    else:
+        newmap = None
+
+    return newmap
+
+
+def make_cmap(colors, position=None, bit=False):
+    """
+    make_cmap takes a list of tuples which contain RGB values. The RGB
+    values may either be in 8-bit [0 to 255] (in which bit must be set to
+    True when called) or arithmetic [0 to 1] (default). make_cmap returns
+    a cmap with equally spaced colors.
+    Arrange your tuples so that the first color is the lowest value for the
+    colorbar and the last is the highest.
+
+
+    Parameters
+    ----------
+    colors: list of 3-tuples [n_rgb]
+        RGB values. The RGB values may either be in 8-bit [0 to 255] (in which bit must be set to True when called)
+        or arithmetic [0 to 1] (default).
+    position: ndarray of float [n_rgb], optional, default=None
+        Contains values from 0 to 1 to dictate the location of each color.
+    bit: boolean, optional, default=False
+        Defines if colors are in 8-bit [0 to 255] (True) or arithmetic [0 to 1] (False)
+
+    Returns
+    -------
+    cmap: mpl.colors instance
+        Colormap
+    """
+
+    bit_rgb = np.linspace(0, 1, 256)
+    if position is None:
+        position = np.linspace(0, 1, len(colors))
+    else:
+        if len(position) != len(colors):
+            sys.exit("position length must be the same as colors")
+        elif position[0] != 0 or position[-1] != 1:
+            sys.exit("position must start with 0 and end with 1")
+    if bit:
+        for i in range(len(colors)):
+            colors[i] = (bit_rgb[colors[i][0]],
+                         bit_rgb[colors[i][1]],
+                         bit_rgb[colors[i][2]])
+    cdict = {'red': [], 'green': [], 'blue': []}
+    for pos, color in zip(position, colors):
+        cdict['red'].append((pos, color[0], color[0]))
+        cdict['green'].append((pos, color[1], color[1]))
+        cdict['blue'].append((pos, color[2], color[2]))
+
+    cmap = mpl.colors.LinearSegmentedColormap('my_colormap',cdict,256)
+    return cmap
+
+
+def plot_sobol_indices(sobol_rel_order_mean, sobol_rel_1st_order_mean, fn_plot, random_vars):
+    """
+    Plot the Sobol indices into different sub-plots.
+
+    plot_sobol_indices(sobol_rel_order_mean, sobol_rel_1st_order_mean, fn_plot, random_vars)
+
+    Parameters
+    ----------
+    sobol_rel_order_mean: ndarray of float [n_sobol]
+        Average proportion of the Sobol indices of the different order to the total variance (1st, 2nd, etc..,)
+        over all output quantities
+    sobol_rel_1st_order_mean: ndarray of float [dim]
+        Average proportion of the random variables of the 1st order Sobol indices to the total variance over all
+        output quantities
+    fn_plot: str
+        Filename of plot
+    random_vars: [dim] list of str
+        String labels of the random variables
+    """
+
+    # combine parameters < "perc_limit_show" in %
+    perc_limit_show = 0.03
+
+    # set the global colors
+    mpl.rcParams['text.color'] = '000000'
+    mpl.rcParams['figure.facecolor'] = '111111'
+
+    # set a global style
+    plt.style.use('seaborn-talk')
+
+    cmap = plt.cm.rainbow
+
+    # make pie plot of order ratios
+    labels = ['order=' + str(i) for i in range(1, len(sobol_rel_order_mean) + 1)]
+    mask = np.where(sobol_rel_order_mean >= perc_limit_show)[0]
+    mask_not = np.where(sobol_rel_order_mean < perc_limit_show)[0]
+    labels = [labels[idx] for idx in mask]
+    if mask_not.any():
+        labels.append('misc.')
+        values = np.hstack((sobol_rel_order_mean[mask], np.sum(sobol_rel_order_mean[mask_not])))
+    else:
+        values = sobol_rel_order_mean
+
+    colors = cmap(np.linspace(0.1, 0.9, len(labels)))
+
+    fig = plt.figure()
+    ax = fig.add_subplot(111, aspect='equal')
+    ax.set_title('Sobol indices (order)')
+    ax.pie(values, labels=labels, colors=colors,
+           autopct='%1.2f%%', shadow=True, explode=[0.1] * len(labels))
+    plt.savefig(os.path.splitext(fn_plot)[0] + '_order.png', facecolor='#ffffff')
+
+    # make pie plot of 1st order parameter ratios
+    mask = np.where(sobol_rel_1st_order_mean >= perc_limit_show)[0]
+    mask_not = np.where(sobol_rel_1st_order_mean < perc_limit_show)[0]
+    labels = [random_vars[idx] for idx in mask]
+    if mask_not.any():
+        labels.append('misc.')
+        values = np.hstack((sobol_rel_1st_order_mean[mask], np.sum(sobol_rel_1st_order_mean[mask_not])))
+    else:
+        values = sobol_rel_1st_order_mean
+
+    colors = cmap(np.linspace(0., 1., len(labels)))
+
+    fig = plt.figure()
+    ax = fig.add_subplot(111, aspect='equal')
+    ax.set_title('Sobol indices 1st order (parameters)')
+    ax.pie(values, labels=labels, colors=colors,
+           autopct='%1.2f%%', shadow=True, explode=[0.1] * len(labels))
+    plt.savefig(os.path.splitext(fn_plot)[0] + '_parameters.png', facecolor='#ffffff')
+
+
+def plot_2d_grid(coords, weights=None, fn_plot=None):
+    """
+    Plot 2D grid and save it as fn_plot.pdf
+
+    Parameters
+    ----------
+    coords: ndarray of float [n_grid, 2]
+        Grid points
+    weights: ndarray of float [n_grid], optional, default=None
+        Integration weights
+    fn_plot: str
+        Filename of plot so save (.pdf)
+
+    Returns
+    -------
+    <file> .pdf file
+        Plot of grid-points
+    """
+
+    if weights is not None:
+        weights = np.abs(weights)
+    else:
+        weights = np.ones(coords.shape[0])
+
+    # mpl.rc('text', usetex=True)
+    mpl.rc('xtick', labelsize=12)
+    mpl.rc('ytick', labelsize=12)
+
+    fig1, ax1 = plt.subplots(nrows=1, ncols=1, squeeze=True, figsize=(5.5, 5))
+    ax1.scatter(coords[:, 0], coords[:, 1], s=weights/np.max(weights)*20)
+    ax1.grid()
+    ax1.set_xlabel('$x_1$', fontsize=16)
+    ax1.set_ylabel('$x_2$', fontsize=16)
+
+    fn = os.path.splitext(fn_plot)[0]
+    plt.tight_layout()
+    plt.savefig(fn, facecolor='#ffffff', format="pdf")
+
+
+def plot_beta_pdf_fit(data, a_beta, b_beta, p_beta, q_beta, a_uni=None, b_uni=None,
+                      interactive=True, fn_plot=None, xlabel="$x$", ylabel="$p(x)$"):
+    """
+    Plot data, fitted beta pdf (and corresponding uniform) distribution
+
+    Parameters
+    ----------
+    data: ndarray of float
+        Data to fit beta distribution on
+    a_beta: float
+        Lower limit of beta distribution
+    b_beta: float
+        Upper limit of beta distribution
+    p_beta: float
+        First shape parameter of beta distribution
+    q_beta: float
+        Second shape parameter of beta distribution
+    a_uni: float (optional)
+        Lower limit of uniform distribution
+    b_uni: float (optional)
+        Upper limit of uniform distribution
+    interactive: bool, default = True
+        Show plot (True/False)
+    fn_plot:
+        Filename of plot so save (as .png and .pdf)
+    xlabel: str (optional)
+        Label of x-axis
+    ylabel: str (optional)
+        Label of y-axis
+
+    Returns
+    -------
+    <file> .png and .pdf files
+        Plots
+    """
+    #if not interactive:
+    #    plt.ioff()
+    #else:
+    #    plt.ion()
+
+    plt.figure(1)
+    plt.clf()
+    plt.rc('text', usetex=False)
+    plt.rc('font', size=18)
+    ax = plt.gca()
+    # legendtext = [r"e-pdf", r"$\beta$-pdf"]
+    legendtext = ["$\\beta$-pdf"]
+
+    # plot histogram of data
+    n, bins, patches = plt.hist(data, bins=16, density=1, color=[1, 1, 0.6], alpha=0.5)
+
+    # plot beta pdf (kernel density estimate)
+    # plt.plot(kde_x, kde_y, 'r--', linewidth=2)
+
+    # plot beta pdf (fitted)
+    beta_x = np.linspace(a_beta, b_beta, 100)
+    beta_y = scipy.stats.beta.pdf(beta_x, p_beta, q_beta, loc=a_beta, scale=b_beta - a_beta)
+
+    plt.plot(beta_x, beta_y, linewidth=2, color=[0, 0, 1])
+
+    # plot uniform pdf
+    uni_y = 0
+    if a_uni is not None and b_uni is not None:
+        uni_x = np.hstack([a_beta, a_uni - 1E-6 * (b_uni - a_uni),
+                           np.linspace(a_uni, b_uni, 100), b_uni + 1E-6 * (b_uni - a_uni), b_beta])
+        uni_y = np.hstack([0, 0, 1.0 / (b_uni - a_uni) * np.ones(100), 0, 0])
+        plt.plot(uni_x, uni_y, linewidth=2, color='r')
+        legendtext.append("u-pdf")
+
+        # configure plot
+    plt.legend(legendtext, fontsize=18, loc="upper left")
+    plt.grid(True)
+    plt.xlabel(xlabel, fontsize=22)
+    plt.ylabel(ylabel, fontsize=22)
+    ax.set_xlim(a_beta - 0.05 * (b_beta - a_beta), b_beta + 0.05 * (b_beta - a_beta))
+    # ax.set_ylim(0, 1.1 * max([max(n), max(beta_y[np.logical_not(beta_y == np.inf)]), max(uni_y)]))
+
+    if interactive > 0:
+        plt.show()
+
+    # save plot
+    if fn_plot is not None:
+        plt.savefig(fn_plot + ".pdf", format='pdf', bbox_inches='tight', pad_inches=0.01 * 4)
+        plt.savefig(fn_plot + ".png", format='png', bbox_inches='tight', pad_inches=0.01 * 4, dpi=600)
```

## pygpc/Worker.py

 * *Ordering differences only*

```diff
@@ -1,124 +1,124 @@
-import time
-import numpy as np
-from .misc import list2dict
-
-
-def init(queue):
-    """
-    This is a wrapper script to be called by the 'multiprocessing.map' function
-    to calculate the model functions in parallel.
-
-    This function will be called upon initialization of the process.
-    It sets a global variable denoting the ID of this process that can
-    be read by any function of this process
-
-    Parameters
-    ----------
-    queue : multiprocessing.Queue
-             the queue object that manages the unique IDs of the process pool
-    """
-    global process_id
-    process_id = queue.get()
-
-
-def run(obj, matlab_engine=None):
-    """
-    This is the main worker function of the process.
-    Methods of the provided object will be called here.
-
-    Parameters
-    ----------
-    obj : any callable object
-           The object that
-                a) handles the simulation work
-                b) reading previous results
-                c) writing the calculated result fields
-                d) printing global process
-    matlab_engine : Matlab engine object, optional, default: None
-        Matlab engine object to run Matlab functions
-    """
-    global process_id
-
-    if 'process_id' not in globals():
-        process_id = 0
-
-    if process_id is None:
-        process_id = 0
-
-    res = obj.read_previous_results(obj.coords)
-
-    start_time = 0
-    end_time = 0
-    skip_sim = True
-
-    # skip if there was no data row for that i_grid or if it was prematurely inserted (= all zero)
-    if res is None or not np.any(res):
-        start_time = time.time()
-        out = obj.simulate(process_id, matlab_engine)
-
-        # dictionary containing the results, the coords and (optionally) the additional data
-        data_dict = dict()
-        data_dict["grid/coords"] = obj.coords
-        data_dict["grid/coords_norm"] = obj.coords_norm
-        n_sim = obj.coords.shape[0]
-
-        if type(out) is tuple:
-            # results (nparray)
-            res = out[0]
-
-            # additional data (dict)
-            if len(out) == 2:
-                # in case of function parallelization transform list of dict to dict containing the lists
-                if type(out[1]) is list:
-                    additional_data = list2dict(out[1])
-                else:
-                    additional_data = out[1]
-
-                for o in additional_data:
-                    # make entries of additional data to list of list [n_grid][n_data[o]]
-
-                    # make single entries to list
-                    if type(additional_data[o]) is not list and type(additional_data[o]) is not np.ndarray:
-                        additional_data[o] = [[additional_data[o]]]
-
-                    if n_sim == 1:
-                        if type(additional_data[o][0]) is not list:
-                            additional_data[o] = [additional_data[o]]
-                    else:
-                        if type(additional_data[o][0]) is not list:
-                            additional_data[o] = [[k] for k in additional_data[o]]
-
-                    data_dict[o] = np.array(additional_data[o])
-
-                    if n_sim == 1 and data_dict[o].shape[0] != 1:
-                        data_dict[o] = data_dict[o].transpose()
-        else:
-            # results (nparray), no additional data
-            res = out
-
-        # make res to a 2D ndarray [n_sim x n_out]
-        if n_sim == 1 and res.ndim == 1:
-            res = res[np.newaxis, :]
-        elif n_sim == 1 and res.shape[0] > 1 and res.ndim == 2:
-            res = res.transpose()
-
-        # add results to data_dict
-        data_dict["model_evaluations/results"] = res
-
-        end_time = time.time()
-
-        obj.write_results(data_dict=data_dict)
-        skip_sim = False
-
-    obj.increment_ctr()
-
-    # determine function time
-    if obj.print_func_time:
-        func_time = end_time - start_time
-    else:
-        func_time = None
-
-    if obj.verbose:
-        obj.print_progress(func_time=func_time, read_from_file=skip_sim, )
-
-    return obj.get_seq_number(), res
+import time
+import numpy as np
+from .misc import list2dict
+
+
+def init(queue):
+    """
+    This is a wrapper script to be called by the 'multiprocessing.map' function
+    to calculate the model functions in parallel.
+
+    This function will be called upon initialization of the process.
+    It sets a global variable denoting the ID of this process that can
+    be read by any function of this process
+
+    Parameters
+    ----------
+    queue : multiprocessing.Queue
+             the queue object that manages the unique IDs of the process pool
+    """
+    global process_id
+    process_id = queue.get()
+
+
+def run(obj, matlab_engine=None):
+    """
+    This is the main worker function of the process.
+    Methods of the provided object will be called here.
+
+    Parameters
+    ----------
+    obj : any callable object
+           The object that
+                a) handles the simulation work
+                b) reading previous results
+                c) writing the calculated result fields
+                d) printing global process
+    matlab_engine : Matlab engine object, optional, default: None
+        Matlab engine object to run Matlab functions
+    """
+    global process_id
+
+    if 'process_id' not in globals():
+        process_id = 0
+
+    if process_id is None:
+        process_id = 0
+
+    res = obj.read_previous_results(obj.coords)
+
+    start_time = 0
+    end_time = 0
+    skip_sim = True
+
+    # skip if there was no data row for that i_grid or if it was prematurely inserted (= all zero)
+    if res is None or not np.any(res):
+        start_time = time.time()
+        out = obj.simulate(process_id, matlab_engine)
+
+        # dictionary containing the results, the coords and (optionally) the additional data
+        data_dict = dict()
+        data_dict["grid/coords"] = obj.coords
+        data_dict["grid/coords_norm"] = obj.coords_norm
+        n_sim = obj.coords.shape[0]
+
+        if type(out) is tuple:
+            # results (nparray)
+            res = out[0]
+
+            # additional data (dict)
+            if len(out) == 2:
+                # in case of function parallelization transform list of dict to dict containing the lists
+                if type(out[1]) is list:
+                    additional_data = list2dict(out[1])
+                else:
+                    additional_data = out[1]
+
+                for o in additional_data:
+                    # make entries of additional data to list of list [n_grid][n_data[o]]
+
+                    # make single entries to list
+                    if type(additional_data[o]) is not list and type(additional_data[o]) is not np.ndarray:
+                        additional_data[o] = [[additional_data[o]]]
+
+                    if n_sim == 1:
+                        if type(additional_data[o][0]) is not list:
+                            additional_data[o] = [additional_data[o]]
+                    else:
+                        if type(additional_data[o][0]) is not list:
+                            additional_data[o] = [[k] for k in additional_data[o]]
+
+                    data_dict[o] = np.array(additional_data[o])
+
+                    if n_sim == 1 and data_dict[o].shape[0] != 1:
+                        data_dict[o] = data_dict[o].transpose()
+        else:
+            # results (nparray), no additional data
+            res = out
+
+        # make res to a 2D ndarray [n_sim x n_out]
+        if n_sim == 1 and res.ndim == 1:
+            res = res[np.newaxis, :]
+        elif n_sim == 1 and res.shape[0] > 1 and res.ndim == 2:
+            res = res.transpose()
+
+        # add results to data_dict
+        data_dict["model_evaluations/results"] = res
+
+        end_time = time.time()
+
+        obj.write_results(data_dict=data_dict)
+        skip_sim = False
+
+    obj.increment_ctr()
+
+    # determine function time
+    if obj.print_func_time:
+        func_time = end_time - start_time
+    else:
+        func_time = None
+
+    if obj.verbose:
+        obj.print_progress(func_time=func_time, read_from_file=skip_sim, )
+
+    return obj.get_seq_number(), res
```

## pygpc/__init__.py

 * *Ordering differences only*

```diff
@@ -1,21 +1,21 @@
-import pygpc.GPC
-import pygpc.SGPC
-import pygpc.testfunctions
-import pygpc.AbstractModel
-import pygpc.Basis
-import pygpc.BasisFunction
-import pygpc.Worker
-import pygpc.Grid
-import pygpc.sobol_saltelli
-from .io import *
-from .misc import *
-from .Problem import *
-from .Algorithm import *
-from .TestBench import *
-from .validation import *
-from .Visualization import *
-from .postprocessing import *
-from .RandomParameter import *
-from .test_utils import *
-from .Session import *
-from .Gradient import *
+import pygpc.GPC
+import pygpc.SGPC
+import pygpc.testfunctions
+import pygpc.AbstractModel
+import pygpc.Basis
+import pygpc.BasisFunction
+import pygpc.Worker
+import pygpc.Grid
+import pygpc.sobol_saltelli
+from .io import *
+from .misc import *
+from .Problem import *
+from .Algorithm import *
+from .TestBench import *
+from .validation import *
+from .Visualization import *
+from .postprocessing import *
+from .RandomParameter import *
+from .test_utils import *
+from .Session import *
+from .Gradient import *
```

## pygpc/io.py

 * *Ordering differences only*

```diff
@@ -1,1339 +1,1339 @@
-import os
-import re
-import sys
-import h5py
-import uuid
-import pickle
-import inspect
-import logging
-import numpy as np
-from .misc import is_instance
-from collections import OrderedDict
-from importlib import import_module
-
-
-def write_session(obj, fname, folder="session", overwrite=True):
-    """
-    Saves a gpc session in pickle or hdf5 file formal depending on the
-    file extension in fname (.pkl or .hdf5)
-
-    Parameters
-    ----------
-    obj : Session object
-        Session class instance containing the gPC information
-    fname : str
-        Path to output file (.pkl or .hdf5)
-    folder : str, optional, default: "session"
-        Path in .hdf5 file (for .hdf5 format only)
-    overwrite : bool, optional, default: True
-        Overwrite existing file
-
-    Returns
-    -------
-    <file>: .hdf5 or .pkl file
-        .hdf5 or .pkl file containing the gpc session
-    """
-
-    file_format = os.path.splitext(fname)[1]
-
-    if file_format == ".pkl":
-        write_session_pkl(obj, fname, overwrite=overwrite)
-
-    elif file_format == ".hdf5":
-        write_session_hdf5(obj, fname, folder, overwrite=overwrite)
-
-    else:
-        raise IOError("Session can only be saved in .pkl or .hdf5 format.")
-
-
-def write_session_pkl(obj, fname, overwrite=True):
-    """
-    Write Session object including information about the Basis, Problem and Model as pickle file.
-
-    Parameters
-    ----------
-    obj: GPC or derived class
-        Class instance containing the gPC information
-    fname: str
-        Path to output file
-    overwrite : bool, optional, default: True
-        Overwrite existing file
-
-    Returns
-    -------
-    <file>: .pkl file
-        File containing the GPC object
-    """
-    if not overwrite and os.path.exists(fname):
-        Warning("File already exists.")
-    else:
-        with open(fname, 'wb') as f:
-            pickle.dump(obj, f, -1)
-
-
-def write_session_hdf5(obj, fname, folder="session", overwrite=True):
-    """
-    Write Session object including information about the Basis, Problem and Model as .hdf5 file.
-
-    Parameters
-    ----------
-    obj : Session object
-        Session class instance containing the gPC information
-    fname : str
-        Path to output file
-    folder : str, optional, default: "session"
-        Path in .hdf5 file
-    overwrite : bool, optional, default: True
-        Overwrite existing file
-
-    Returns
-    -------
-    <file>: .hdf5 file
-        .hdf5 file containing the gpc session
-    """
-
-    if overwrite and os.path.exists(fname):
-        os.remove(fname)
-
-    write_dict_to_hdf5(fn_hdf5=fname, data=obj.__dict__, folder=folder)
-
-
-def read_session(fname, folder=None):
-    """
-    Reads a gpc session in pickle or hdf5 file formal depending on the
-    file extension in fname (.pkl or .hdf5)
-
-    Parameters
-    ----------
-    fname : str
-        path to input file
-    folder : str, optional, default: None
-        Path in .hdf5 file
-
-    Returns
-    -------
-    obj : Session Object
-        Session object containing instances of Basis, Problem and Model etc.
-    """
-
-    file_format = os.path.splitext(fname)[1]
-
-    if file_format == ".pkl":
-        obj = read_session_pkl(fname)
-
-    elif file_format == ".hdf5":
-        obj = read_session_hdf5(fname=fname, folder=folder)
-
-    else:
-        raise IOError("Session can only be read from .pkl or .hdf5 files.")
-
-    return obj
-
-
-def read_session_pkl(fname):
-    """
-    Read Session object in pickle format.
-
-    Parameters
-    ----------
-    fname: str
-        path to input file
-
-    Returns
-    -------
-    obj: Session Object
-        Session object containing instances of Basis, Problem and Model etc.
-    """
-
-    with open(fname, 'rb') as f:
-        obj = pickle.load(f)
-
-    return obj
-
-
-def read_session_hdf5(fname, folder="session", verbose=False):
-    """
-    Read gPC object including information about input pdfs, polynomials, grid etc.
-
-    object = read_gpc_obj(fname)
-
-    Parameters
-    ----------
-    fname : str
-        path to input file
-    folder : str, optional, default: "session"
-        Path in .hdf5 file
-    verbose : bool, optional, default: False
-        Print output info
-
-    Returns
-    -------
-    obj: GPC Object
-        GPC object containing instances of Basis, Problem and Model.
-    """
-    from .Problem import Problem
-    from .Session import Session
-    from .RandomParameter import RandomParameter
-
-    # model
-    try:
-        model = read_model_from_hdf5(fn_hdf5=fname, folder=folder + "/model", verbose=verbose)
-    except KeyError:
-        model = None
-
-    # parameters
-    parameters_unsorted = read_parameters_from_hdf5(fn_hdf5=fname, folder=folder + "/problem/parameters",
-                                                    verbose=verbose)
-
-    problem_dict = read_group_from_hdf5(fn_hdf5=fname, folder=folder + "/problem", verbose=verbose)
-
-    parameters = OrderedDict()
-    parameters_random = OrderedDict()
-
-    for p in problem_dict["parameters_keys"]:
-        parameters[p] = parameters_unsorted[p]
-
-        if isinstance(parameters_unsorted[p], RandomParameter):
-            parameters_random[p] = parameters_unsorted[p]
-
-    # problem(model, parameters)
-    problem = Problem(model, parameters)
-
-    # options
-    options = read_group_from_hdf5(fn_hdf5=fname, folder=folder + "/algorithm/options")
-
-    # validation
-    try:
-        validation = read_validation_from_hdf5(fn_hdf5=fname, folder=folder + "/validation", verbose=verbose)
-    except KeyError:
-        validation = None
-
-    # grid
-    grid = read_grid_from_hdf5(fn_hdf5=fname, folder=folder + "/grid", verbose=verbose)
-
-    # algorithm
-    module = import_module(".Algorithm", package="pygpc")
-    algorithm_dict = read_group_from_hdf5(fn_hdf5=fname, folder=folder + "/algorithm", verbose=verbose)
-    alg = getattr(module, algorithm_dict["attrs"]["dtype"].split(".")[-1])
-    args = inspect.getfullargspec(alg).args[1:]
-
-    args_dict = dict()
-    args = [a for a in args if a != "gpc"]
-    for a in args:
-        args_dict[a] = locals()[a]
-
-    algorithm = alg(**args_dict)
-
-    # gpc
-    gpc_raw_list = read_group_from_hdf5(fn_hdf5=fname, folder=folder + "/gpc", verbose=verbose)
-    module = import_module(".Algorithm", package="pygpc")
-
-    gpc_list = [0 for _ in range(len(gpc_raw_list))]
-    for i_gpc, gpc_raw in enumerate(gpc_raw_list):
-
-        # read and initialize classifier if present
-        if "classifier" in gpc_raw.keys():
-            classifier = read_classifier_from_hdf5(fn_hdf5=fname,
-                                                   folder=folder + "/gpc/{}/classifier".format(i_gpc),
-                                                   verbose=verbose)
-
-        # read SGPC object if present (sub-gpc)
-        if "gpc" in gpc_raw.keys():
-            gpc = read_sgpc_from_hdf5(fn_hdf5=fname,
-                                      folder=folder + "/gpc/{}/gpc".format(i_gpc),
-                                      verbose=verbose)
-
-        # get gpc class (SGPC or MEGPC)
-        g = getattr(module, gpc_raw["attrs"]["dtype"].rsplit(".", 1)[1])
-        del gpc_raw["attrs"]
-
-        # SGPC
-        if "SGPC" in g.__module__:
-            gpc_list = read_sgpc_from_hdf5(fn_hdf5=fname,
-                                           folder=folder + "/gpc/{}".format(i_gpc),
-                                           verbose=verbose)
-        # MEGPC with sub-gpcs
-        else:
-            # get input parameters of gpc
-            args = inspect.getfullargspec(g).args[1:]
-
-            args_dict = dict()
-            for a in args:
-                args_dict[a] = locals()[a]
-
-            # initialize gpc
-            gpc_list[i_gpc] = g(**args_dict)
-
-            # loop over entries and save in self (if we have it in locals() we take this,
-            # e.g. gpc, grid, validation etc)
-            for key in gpc_raw:
-                if key in locals():
-                    setattr(gpc_list[i_gpc], key, locals()[key])
-                else:
-                    setattr(gpc_list[i_gpc], key, gpc_raw[key])
-
-    # session(algorithm)
-    session = Session(algorithm=algorithm)
-
-    # read session hdf5 content
-    session_dict = read_group_from_hdf5(fn_hdf5=fname, folder=folder, verbose=verbose)
-
-    for key in session_dict:
-        if key in locals():
-            setattr(session, key, locals()[key])
-        else:
-            setattr(session, key, session_dict[key])
-
-    # add path of .hdf5 script to python which generated the session (needed in case of relative imports)
-    sys.path.append(os.path.split(session_dict["fn_script"])[0])
-
-    # set gpc type in session
-    session.set_gpc(gpc_list)
-
-    return session
-
-
-def read_problem_from_hdf5(fn_hdf5, folder, verbose=False):
-    """
-    Reads problem from hdf5 file
-
-    Parameters
-    ----------
-    fn_hdf5 : str
-        Filename of .hdf5 file to write in
-    folder : str
-        Folder inside .hdf5 file where dict is saved
-    verbose : bool, optional, default: False
-        Print output info
-
-    Returns
-    -------
-    problem : Problem object
-        Problem
-    """
-    from .Problem import Problem
-
-    # read content of problem
-    problem_dict = read_group_from_hdf5(fn_hdf5=fn_hdf5, folder=folder, verbose=verbose)
-
-    # model
-    model = read_model_from_hdf5(fn_hdf5=fn_hdf5, folder=folder + "/model", verbose=verbose)
-
-    # parameters
-    parameters_unsorted = read_parameters_from_hdf5(fn_hdf5=fn_hdf5, folder=folder + "/parameters", verbose=False)
-
-    # sort parameters
-    parameters = OrderedDict()
-
-    for p in problem_dict["parameters_keys"]:
-        parameters[p] = parameters_unsorted[p]
-
-    # initialize problem
-    problem = Problem(model, parameters)
-
-    return problem
-
-
-def read_classifier_from_hdf5(fn_hdf5, folder, verbose=False):
-    """
-    Reads classifier from hdf5 file
-
-    Parameters
-    ----------
-    fn_hdf5 : str
-        Filename of .hdf5 file to write in
-    folder : str
-        Folder inside .hdf5 file where dict is saved
-    verbose : bool, optional, default: False
-        Print output info
-
-    Returns
-    -------
-    classifier : classifier object
-        Classifier
-    """
-    classifier_dict = read_group_from_hdf5(fn_hdf5=fn_hdf5, folder=folder, verbose=verbose)
-    module = import_module(".Classifier", package="pygpc")
-    c = getattr(module, classifier_dict["attrs"]["dtype"].rsplit(".", 1)[1])
-
-    # get input parameters of classifier
-    args = inspect.getfullargspec(c).args[1:]
-
-    args_dict = dict()
-    for a in args:
-        args_dict[a] = classifier_dict[a]
-
-    init_classifier = True
-
-    # for some reason the domains may be swapped in very rare cases so we do the init again
-    while init_classifier:
-        # initialize classifier
-        classifier = c(**args_dict)
-
-        # ensure that domains are not swapped
-        classifier.domains = classifier_dict["domains"]
-        classifier.update(coords=classifier_dict["coords"],
-                          results=classifier_dict["results"])
-
-        if np.sum(classifier.predict(coords=classifier_dict["coords"]) == classifier_dict["domains"])/ \
-                len(classifier_dict["domains"]) > 0.95:
-            init_classifier = False
-
-    return classifier
-
-
-def read_basis_from_hdf5(fn_hdf5, folder, verbose=False):
-    """
-    Reads Basis from hdf5 file
-
-    Parameters
-    ----------
-    fn_hdf5 : str
-        Filename of .hdf5 file to write in
-    folder : str
-        Folder inside .hdf5 file where dict is saved
-    verbose : bool, optional, default: False
-        Print output info
-
-    Returns
-    -------
-    basis : Basis object
-        basis
-    """
-
-    basis_dict = read_group_from_hdf5(fn_hdf5=fn_hdf5, folder=folder, verbose=verbose)
-    module_basis = import_module(".Basis", package="pygpc")
-    module_basis_function = import_module(".BasisFunction", package="pygpc")
-    b = getattr(module_basis, basis_dict["attrs"]["dtype"].rsplit(".", 1)[1])
-
-    # get arguments to initialize basis
-    args = inspect.getfullargspec(b).args[1:]
-
-    # collect arguments from hdf5 file content
-    args_dict = dict()
-    for a in args:
-        args_dict[a] = basis_dict[a]
-
-    # initialize basis
-    basis = b(**args_dict)
-
-    # write content in self
-    for key in basis_dict:
-        if key != "b":
-            setattr(basis, key,  basis_dict[key])
-
-    b = [[0 for _ in range(basis_dict["dim"])] for _ in range(basis_dict["n_basis"])]
-    for i_basis, b_lst in enumerate(basis_dict["b"]):
-        for i_dim, b_ in enumerate(b_lst):
-            # get type of basis function
-            bf = getattr(module_basis_function, b_["attrs"]["dtype"].rsplit(".", 1)[1])
-
-            # read content of hdf5
-            bf_dict = read_group_from_hdf5(fn_hdf5=fn_hdf5,
-                                           folder=folder + "/b/{}/{}".format(i_basis, i_dim),
-                                           verbose=verbose)
-
-            # get arguments to initialize basis function
-            args = inspect.getfullargspec(bf).args[1:]
-
-            # collect arguments from hdf5 file content
-            args_dict = dict()
-            for a in args:
-                args_dict[a] = bf_dict[a]
-
-            # initialize basis function
-            b[i_basis][i_dim] = bf(**args_dict)
-
-    # extend basis
-    basis.extend_basis(b)
-
-    return basis
-
-
-def read_sgpc_from_hdf5(fn_hdf5, folder, verbose=False):
-    """
-    Reads SGPC from hdf5 file
-
-    Parameters
-    ----------
-    fn_hdf5 : str
-        Filename of .hdf5 file to write in
-    folder : str
-        Folder inside .hdf5 file where dict is saved
-    verbose : bool, optional, default: False
-        Print output info
-
-    Returns
-    -------
-    sgpc : SGPC object or list of SGPC objects
-        SGPC
-    """
-
-    sgpc_raw_list = read_group_from_hdf5(fn_hdf5=fn_hdf5, folder=folder, verbose=verbose)
-    module = import_module(".SGPC", package="pygpc")
-
-    if type(sgpc_raw_list) is not list:
-        sgpc_raw_list = [sgpc_raw_list]
-        sub_gpc = False
-    else:
-        sub_gpc = True
-
-    sgpc_list = [0 for _ in range(len(sgpc_raw_list))]
-
-    for i_gpc, sgpc_raw in enumerate(sgpc_raw_list):
-        if sub_gpc:
-            hdf5_loc = "/{}/".format(i_gpc)
-        else:
-            hdf5_loc = "/"
-
-        # get gpc by type
-        g = getattr(module, sgpc_raw["attrs"]["dtype"].rsplit(".", 1)[1])
-
-        # get input parameters of classifier
-        args = inspect.getfullargspec(g).args[1:]
-
-        args_dict = dict()
-        for a in args:
-            if a == "problem":
-                args_dict[a] = read_problem_from_hdf5(fn_hdf5=fn_hdf5,
-                                                      folder=folder + hdf5_loc + a,
-                                                      verbose=verbose)
-            elif a == "validation":
-                args_dict[a] = read_validation_from_hdf5(fn_hdf5=fn_hdf5,
-                                                         folder=folder + hdf5_loc + a,
-                                                         verbose=verbose)
-            else:
-                args_dict[a] = sgpc_raw[a]
-
-        # initialize SGPC object
-        sgpc_list[i_gpc] = g(**args_dict)
-
-        # write objects in self
-        for key in sgpc_raw:
-            try:
-                dtype = sgpc_raw[key]["attrs"]["dtype"]
-
-                if "pygpc.Basis" in dtype:
-                    basis = read_basis_from_hdf5(fn_hdf5=fn_hdf5,
-                                                 folder=folder + hdf5_loc + key,
-                                                 verbose=verbose)
-                    setattr(sgpc_list[i_gpc], key, basis)
-
-                elif "pygpc.Grid" in dtype:
-                    grid = read_grid_from_hdf5(fn_hdf5=fn_hdf5,
-                                               folder=folder + hdf5_loc + key,
-                                               verbose=verbose)
-                    setattr(sgpc_list[i_gpc], key, grid)
-
-                elif "pygpc.Problem" in dtype:
-                    problem = read_problem_from_hdf5(fn_hdf5=fn_hdf5,
-                                                     folder=folder + hdf5_loc + key,
-                                                     verbose=verbose)
-                    setattr(sgpc_list[i_gpc], key, problem)
-
-                else:
-                    setattr(sgpc_list[i_gpc], key, sgpc_raw[key])
-
-            except (KeyError, IndexError, TypeError):
-                setattr(sgpc_list[i_gpc], key, sgpc_raw[key])
-
-    return sgpc_list
-
-
-def read_model_from_hdf5(fn_hdf5, folder, verbose=False):
-    """
-    Reads model from hdf5 file
-
-    Parameters
-    ----------
-    fn_hdf5 : str
-        Filename of .hdf5 file to write in
-    folder : str
-        Folder inside .hdf5 file where dict is saved
-    verbose : bool, optional, default: False
-        Print output info
-
-    Returns
-    -------
-    model : Model object
-        Model
-    """
-
-    model_dict = read_group_from_hdf5(fn_hdf5=fn_hdf5, folder=folder, verbose=verbose)
-    sys.path.append(os.path.split(model_dict["fname"])[0])
-    module = import_module(os.path.splitext(os.path.split(model_dict["fname"])[1])[0])
-    model = getattr(module, model_dict["attrs"]["dtype"].rsplit(".", 1)[1])()
-
-    return model
-
-
-def read_parameters_from_hdf5(fn_hdf5, folder, verbose=False):
-    """
-    Reads parameters from hdf5 file
-
-    Parameters
-    ----------
-    fn_hdf5 : str
-        Filename of .hdf5 file to write in
-    folder : str
-        Folder inside .hdf5 file where dict is saved
-    verbose : bool, optional, default: False
-        Print output info
-
-    Returns
-    -------
-    parameters : OrderedDict
-        OrdererDict containing the parameters (random and deterministic)
-    """
-    parameters = OrderedDict()
-    parameters_dict = read_group_from_hdf5(fn_hdf5=fn_hdf5, folder=folder, verbose=verbose)
-    module = import_module(".RandomParameter", package="pygpc")
-
-    for p in parameters_dict:
-        if (type(parameters_dict[p]) is dict or type(parameters_dict[p]) is OrderedDict) and \
-                "RandomParameter" in parameters_dict[p]["attrs"]["dtype"]:
-            rp = getattr(module, parameters_dict[p]["attrs"]["dtype"].split(".")[-1])
-            args = inspect.getfullargspec(rp).args[1:]
-
-            args_dict = dict()
-            for a in args:
-                args_dict[a] = parameters_dict[p][a]
-
-            parameters[p] = rp(**args_dict)
-
-        else:
-            parameters[p] = parameters_dict[p]
-
-    return parameters
-
-
-def read_grid_from_hdf5(fn_hdf5, folder, verbose=False):
-    """
-    Reads and initializes grid from hdf5 file
-
-    Parameters
-    ----------
-    fn_hdf5 : str
-        Filename of .hdf5 file to write in
-    folder : str
-        Folder inside .hdf5 file where dict is saved
-    verbose : bool, optional, default: False
-        Print output info
-
-    Returns
-    -------
-    grid : Grid object
-        Grid
-    """
-
-    grid_dict = read_group_from_hdf5(fn_hdf5=fn_hdf5, folder=folder, verbose=verbose)
-
-    module = import_module(".Grid", package="pygpc")
-    g = getattr(module, grid_dict["attrs"]["dtype"].split(".")[-1])
-
-    # get arguments of grid function
-    args = inspect.getfullargspec(g).args[1:]
-
-    # read content of hdf5 and relate to arguments
-    args_dict = dict()
-    for a in args:
-        if a in ["coords", "coords_norm", "coords_gradient", "coords_gradient_norm", "weights"]:
-            args_dict[a] = grid_dict["_" + a]
-        elif a == "parameters_random":
-            parameters_random = read_parameters_from_hdf5(fn_hdf5=fn_hdf5,
-                                                          folder=folder + "/parameters_random",
-                                                          verbose=verbose)
-            args_dict[a] = parameters_random
-        else:
-            args_dict[a] = grid_dict[a]
-
-    # regenerate unique grid IDs
-    args_dict["coords_id"] = [uuid.uuid4() for _ in range(grid_dict["n_grid"])]
-
-    if args_dict["coords_gradient"] is not None:
-        args_dict["coords_gradient_id"] = args_dict["coords_id"]
-
-    grid = g(**args_dict)
-
-    return grid
-
-
-def read_validation_from_hdf5(fn_hdf5, folder, verbose=False):
-    """
-    Reads and initializes ValidatioSet from hdf5 file
-
-    Parameters
-    ----------
-    fn_hdf5 : str
-        Filename of .hdf5 file to write in
-    folder : str
-        Folder inside .hdf5 file where dict is saved
-    verbose : bool, optional, default: False
-        Print output info
-
-    Returns
-    -------
-    validation : ValidationSet object
-        ValidationSet
-    """
-    from .ValidationSet import ValidationSet
-    validation_dict = read_group_from_hdf5(fn_hdf5=fn_hdf5, folder=folder)
-
-    if validation_dict is None:
-        validation = None
-    else:
-        args_dict = dict()
-        args = inspect.getfullargspec(ValidationSet).args[1:]
-
-        for a in args:
-            if a == "grid":
-                args_dict[a] = read_grid_from_hdf5(fn_hdf5=fn_hdf5, folder=folder + "/grid", verbose=verbose)
-            else:
-                args_dict[a] = validation_dict[a]
-
-        validation = ValidationSet(**args_dict)
-
-    return validation
-
-
-def read_group_from_hdf5(fn_hdf5, folder, verbose=False):
-    """
-    Read data from group (folder) in hdf5 file
-
-    Parameters
-    ----------
-    fn_hdf5 : str
-        Filename of .hdf5 file to write in
-    folder : str
-        Folder inside .hdf5 file where dict is saved
-    verbose : bool, optional, default: False
-        Print output info
-
-    Returns
-    -------
-    data : dict or list or OrderedDict
-        Folder content
-    """
-    f = h5py.File(fn_hdf5, "r")
-
-    attrs = dict()
-    for a in f[folder].attrs:
-        attrs[a] = f[folder].attrs.__getitem__(a)
-
-    data = dict()
-
-    if isinstance(f[folder], h5py.Group) and len(f[folder].keys()) > 0:
-        for key in f[folder].keys():
-            if folder != "/":
-                data["attrs"] = attrs
-            data[key] = read_array_from_hdf5(fn_hdf5=fn_hdf5,
-                                             arr_name=folder + "/" + key)
-
-        if folder != "/":
-            if data["attrs"]["dtype"] == "list":
-                data = [data[key] for key in data if key != "attrs"]
-
-            elif data["attrs"]["dtype"] == "dict":
-                del data["attrs"]
-
-            elif data["attrs"]["dtype"] == "collections.OrderedDict":
-                data_ordered = OrderedDict()
-
-                for key in data:
-                    if key != "attrs":
-                        data_ordered[key] = data[key]
-
-                data = data_ordered
-
-    else:
-        data = None
-
-    return data
-
-
-def read_array_from_hdf5(fn_hdf5, arr_name, verbose=False):
-    """
-
-    Parameters
-    ----------
-    fn_hdf5 : str
-        Filename of .hdf5 file to write in
-    folder : str
-        Folder inside .hdf5 file where dict is saved
-    verbose : bool, optional, default: False
-        Print output info
-
-    Returns
-    -------
-    data
-
-    attrs
-
-    """
-    f = h5py.File(fn_hdf5, "r")
-
-    if isinstance(f[arr_name], h5py.Group):
-        data = read_group_from_hdf5(fn_hdf5=fn_hdf5, folder=arr_name)
-
-    else:
-        data = f[arr_name][()]
-
-    if type(data) == np.bytes_:
-        data = str(data.astype(str))
-
-    if type(data) == str and (data == "None" or data == "N/A"):
-        data = None
-
-    return data
-
-
-def write_dict_to_hdf5(fn_hdf5, data, folder, verbose=False):
-    """
-    Takes dict and passes its keys to write_arr_to_hdf5()
-
-    fn_hdf5:folder/
-                  |--key1
-                  |--key2
-                  |...
-
-    Parameters
-    ----------
-    fn_hdf5 : str
-        Filename of .hdf5 file to write in
-    data : dict
-        Dictionary to save in .hdf5 file
-    folder : str
-        Folder inside .hdf5 file where dict is saved
-    verbose : bool, optional, default: False
-        Print output info
-    """
-    max_recursion_depth = 12
-
-    # object (dict)
-    if is_instance(data) and not isinstance(data, OrderedDict):
-
-        t, dt = get_dtype(data)
-
-        # do not save uuids in hdf5
-        if dt == "uuid.UUID":
-            return
-
-        else:
-
-            # create group and set type and dtype attributes
-            with h5py.File(fn_hdf5, "a") as f:
-                f.create_group(str(folder))
-                f[str(folder)].attrs.__setitem__("type", t)
-                f[str(folder)].attrs.__setitem__("dtype", dt)
-
-            # write content
-            for key in data.__dict__:
-                if len(folder.split("/")) >= max_recursion_depth:
-                    data.__dict__[key] = "None"
-
-                write_arr_to_hdf5(fn_hdf5=fn_hdf5,
-                                  arr_name=folder+"/"+key,
-                                  data=data.__dict__[key],
-                                  verbose=verbose)
-
-    # mappingproxy (can not be saved)
-    elif str(type(data)) == "<class 'mappingproxy'>":
-        data = "mappingproxy"
-        write_arr_to_hdf5(fn_hdf5=fn_hdf5,
-                          arr_name="mappingproxy",
-                          data=data,
-                          verbose=verbose)
-
-    # list or tuple
-    elif type(data) is list or type(data) is tuple:
-        t, dt = get_dtype(data)
-
-        # create group and set type and dtype attributes
-        with h5py.File(fn_hdf5, "a") as f:
-            f.create_group(str(folder))
-            f[str(folder)].attrs.__setitem__("type", t)
-            f[str(folder)].attrs.__setitem__("dtype", dt)
-
-        for idx, lst in enumerate(data):
-            if len(folder.split("/")) >= max_recursion_depth:
-                lst = "None"
-
-            write_arr_to_hdf5(fn_hdf5=fn_hdf5,
-                              arr_name=folder+"/"+str(idx),
-                              data=lst,
-                              verbose=verbose)
-
-    # dict or OrderedDict
-    else:
-        t, dt = get_dtype(data)
-
-        # create group and set type and dtype attributes
-        with h5py.File(fn_hdf5, "a") as f:
-            try:
-                f.create_group(str(folder))
-                f[str(folder)].attrs.__setitem__("type", t)
-                f[str(folder)].attrs.__setitem__("dtype", dt)
-            except ValueError:
-                pass
-
-        for key in list(data.keys()):
-            if len(folder.split("/")) >= max_recursion_depth:
-                data[key] = "None"
-
-            write_arr_to_hdf5(fn_hdf5=fn_hdf5,
-                              arr_name=folder+"/"+str(key),
-                              data=data[key],
-                              verbose=verbose)
-
-
-def write_arr_to_hdf5(fn_hdf5, arr_name, data, overwrite_arr=True, verbose=False):
-    """
-    Takes an array and adds it to an .hdf5 file
-
-    If data is list of dict, write_dict_to_hdf5() is called for each dict with adapted hdf5-folder name
-    Otherwise, data is casted to np.ndarray and dtype of unicode data casted to '|S'.
-
-    Parameters
-    ----------
-    fn_hdf5 : str
-        Filename of .hdf5 file
-    arr_name : str
-        Complete path in .hdf5 file with array name
-    data : ndarray, list or dict
-        Data to write
-    overwrite_arr : bool, optional, default: True
-        Overwrite existing array
-    verbose : bool, optional, default: False
-        Print information
-    """
-    max_recursion_depth = 12
-
-    # dict or OrderedDict
-    if isinstance(data, dict) or isinstance(data, OrderedDict):
-        if len(arr_name.split("/")) >= max_recursion_depth:
-            data = np.array("None")
-        else:
-            write_dict_to_hdf5(fn_hdf5=fn_hdf5,
-                               data=data,
-                               folder=arr_name,
-                               verbose=verbose)
-            return
-
-    # list of dictionaries:
-    elif isinstance(data, list) and len(data) > 0 and (isinstance(data[0], dict) or is_instance(data[0])):
-        t, dt = get_dtype(data)
-
-        # do not save uuids in hdf5
-        if dt == "uuid.UUID":
-            return
-
-        else:
-            # create group and set type and dtype attributes
-            with h5py.File(fn_hdf5, "a") as f:
-                f.create_group(str(arr_name))
-                f[str(arr_name)].attrs.__setitem__("type", t)
-                f[str(arr_name)].attrs.__setitem__("dtype", dt)
-
-            for idx, lst in enumerate(data):
-                if len(arr_name.split("/")) >= max_recursion_depth:
-                    lst = np.array("None")
-
-                write_dict_to_hdf5(fn_hdf5=fn_hdf5,
-                                   data=lst,
-                                   folder=arr_name+"/"+str(idx),
-                                   verbose=verbose)
-            return
-
-    # object
-    elif is_instance(data):
-        if len(arr_name.split("/")) >= max_recursion_depth:
-            data = np.array("None")
-        else:
-            t, dt = get_dtype(data)
-
-            # create group and set type and dtype attributes
-            with h5py.File(fn_hdf5, "a") as f:
-                f.create_group(str(arr_name))
-                f[str(arr_name)].attrs.__setitem__("type", t)
-                f[str(arr_name)].attrs.__setitem__("dtype", dt)
-
-            write_dict_to_hdf5(fn_hdf5=fn_hdf5,
-                               data=data.__dict__,
-                               folder=arr_name,
-                               verbose=verbose)
-            return
-
-    # list or tuple
-    elif type(data) is list or type(data) is tuple:
-        if len(arr_name.split("/")) >= max_recursion_depth:
-            data = np.array(["None"])
-
-        t, dt = get_dtype(data)
-
-        # do not save uuids in hdf5
-        if dt == "uuid.UUID":
-            return
-
-        else:
-            # create group and set type and dtype attributes
-            with h5py.File(fn_hdf5, "a") as f:
-                f.create_group(str(arr_name))
-                f[str(arr_name)].attrs.__setitem__("type", t)
-                f[str(arr_name)].attrs.__setitem__("dtype", dt)
-
-            data_dict = dict()
-
-            for idx, lst in enumerate(data):
-                data_dict[idx] = lst
-
-            write_dict_to_hdf5(fn_hdf5=fn_hdf5,
-                               data=data_dict,
-                               folder=arr_name,
-                               verbose=verbose)
-
-            return
-
-    elif not isinstance(data, np.ndarray):
-        if len(arr_name.split("/")) >= max_recursion_depth:
-            data = np.array("None")
-        else:
-            data = np.array(data)
-
-    # np.arrays of np.arrays
-    elif data.dtype == 'O' and len(data) > 1:
-        if len(arr_name.split("/")) >= max_recursion_depth:
-            return
-        else:
-            t, dt = get_dtype(data)
-
-            # create group and set type and dtype attributes
-            with h5py.File(fn_hdf5, "a") as f:
-                f.create_group(str(arr_name))
-                f[str(arr_name)].attrs.__setitem__("type", t)
-                f[str(arr_name)].attrs.__setitem__("dtype", dt)
-
-            data = data.tolist()
-            write_dict_to_hdf5(fn_hdf5=fn_hdf5,
-                               data=data,
-                               folder=arr_name,
-                               verbose=verbose)
-            return
-
-    # do some type casting from numpy/pd -> h5py
-    # date column from experiment.csv is O
-    # plotsetting["view"] is O list of list of different length
-    # coil1 and coil2 columns names from experiment.csv is <U8
-    # coil_mean column name from experiment.csv is <U12
-    if data.dtype == 'O' or data.dtype.kind == 'U':
-        data = data.astype('|S')
-
-        if verbose:
-            print("Converting array " + arr_name + " to string")
-
-    t, dt = get_dtype(data)
-
-    with h5py.File(fn_hdf5, 'a') as f:
-        # create data_set
-        if overwrite_arr:
-            try:
-                del f[arr_name]
-            except KeyError:
-                pass
-
-        f.create_dataset(arr_name, data=data)
-        f[str(arr_name)].attrs.__setitem__("type", t)
-        f[str(arr_name)].attrs.__setitem__("dtype", dt)
-
-    return
-
-
-def get_dtype(obj):
-    """
-    Get type and datatype of object
-
-    Parameters
-    ----------
-    obj : Object
-        Input object (any)
-
-    Returns
-    -------
-    type : str
-        Type of object (e.g. 'class')
-    dtype : str
-        Datatype of object (e.g. 'numpy.ndarray')
-    """
-    type_str = str(type(obj))
-    type_attr = re.match(pattern=r"\<(.*?)\ '", string=type_str).group(1)
-    dtype_attr = re.findall(pattern=r"'(.*?)'", string=type_str)[0]
-
-    return type_attr, dtype_attr
-
-
-def write_data_txt(data, fname):
-    """
-    Write data (quantity of interest) in .txt file (e.g. coeffs, mean, std, ...).
-
-    write_data_txt(data, fname)
-
-    Parameters
-    ----------
-    data: ndarray of float
-        Data to save
-    fname: str
-        Path to output file
-
-    Returns
-    -------
-    <file>: .txt file
-        File containing the data (tab delimited)
-    """
-
-    np.savetxt(fname, data, fmt='%.10e', delimiter='\t', newline='\n', header='', footer='')
-
-
-def read_data_hdf5(fname, loc):
-    """
-    Read data from .hdf5 file (e.g. coeffs, mean, std, ...).
-
-    load_data_hdf5(fname, loc)
-
-    Parameters
-    ----------
-    fname: str
-        path to input file
-    loc: str
-        location (folder and name) in hdf5 file (e.g. data/phi)
-
-    Returns
-    -------
-    data: ndarray of float
-        Loaded data from .hdf5 file
-    """
-
-    with h5py.File(fname, 'r') as f:
-        d = f[loc]
-        return d
-
-
-def write_data_hdf5(data, fname, loc):
-    """
-    Write quantity of interest in .hdf5 file (e.g. coeffs, mean, std, ...).
-
-    write_data_hdf5(data, fname, loc)
-
-    Parameters
-    ----------
-    data: np.ndarray
-        data to save
-    fname: str
-        path to output file
-    loc: str
-        location (folder and name) in hdf5 file (e.g. data/phi)
-    """
-
-    with h5py.File(fname, 'a') as f:
-        f.create_dataset(loc, data=data)
-
-
-def write_sobol_idx_txt(sobol_idx, fname):
-    """
-    Write sobol_idx list in file.
-
-    write_sobol_idx_txt(sobol_idx, filename)
-
-    Parameters
-    ----------
-    sobol_idx: [N_sobol] list of np.ndarray
-        List of parameter label indices belonging to Sobol indices
-    fname: str
-        Path to output file
-
-    Returns
-    -------
-    <file>: .txt file
-        File containing the sobol index list.
-    """
-
-    f = open(fname, 'w')
-    f.write('# Parameter index list of Sobol indices:\n')
-    for line in sobol_idx:
-        for entry in line:
-            if entry != line[0]:
-                f.write(', ')
-            f.write('{}'.format(entry))
-        if line != sobol_idx[-1]:
-            f.write('\n')
-
-    f.close()
-
-
-def read_sobol_idx_txt(fname):
-    """
-    Read sobol_idx list from file.
-
-    read_sobol_idx_txt(fname)
-
-    Parameters
-    ----------
-    fname: str
-        Path to input file
-
-    Returns
-    -------
-    sobol_idx: [N_sobol] list of np.array
-        List of parameter label indices belonging to Sobol indices
-    """
-
-    f = open(fname, 'r')
-
-    line = f.readline().strip('\n')
-    sobol_idx = []
-
-    while line:
-
-        # ignore comments in text file
-        if line[0] == '#':
-            line = f.readline().strip('\n')
-            continue
-
-        else:
-            # read comma separated indices and convert to ndarray
-            sobol_idx.append(np.asarray([int(x) for x in line.split(',') if x]))
-
-        line = f.readline().strip('\n')
-
-    return sobol_idx
-
-
-def write_log_sobol(fname, random_vars, sobol_rel_order_mean, sobol_rel_1st_order_mean, sobol_extracted_idx_1st):
-    """
-    Write average ratios of Sobol indices into logfile.
-
-    Parameters
-    ----------
-    fname: str
-        Path of logfile
-    random_vars: list of str
-        Labels of random variables
-    sobol_rel_order_mean: np.ndarray
-        Average proportion of the Sobol indices of the different order to the total variance (1st, 2nd, etc..,).
-        (over all output quantities)
-    sobol_rel_1st_order_mean: np.ndarray
-        Average proportion of the random variables of the 1st order Sobol indices to the total variance.
-        (over all output quantities)
-    sobol_extracted_idx_1st: list of int [N_sobol_1st]
-        Indices of extracted 1st order Sobol indices corresponding to SGPC.random_vars.
-
-    Returns
-    -------
-    <File>: .txt file
-        Logfile containing information about the average ratios of 1st order Sobol indices w.r.t. the total variance
-    """
-    # start log
-    log = open(os.path.splitext(fname)[0] + '.txt', 'w')
-    log.write("Sobol indices:\n")
-    log.write("==============\n")
-    log.write("\n")
-
-    # print order ratios
-    log.write("Ratio: order / total variance over all output quantities:\n")
-    log.write("---------------------------------------------------------\n")
-    for i in range(len(sobol_rel_order_mean)):
-        log.write("Order {}: {:.4f}\n".format(i + 1, sobol_rel_order_mean[i]))
-
-    log.write("\n")
-
-    # print 1st order ratios of parameters
-    log.write("Ratio: 1st order Sobol indices of parameters / total variance over all output quantities\n")
-    log.write("----------------------------------------------------------------------------------------\n")
-
-    # random_vars = []
-    max_len = max([len(random_vars[i]) for i in range(len(random_vars))])
-    for i in range(len(sobol_rel_1st_order_mean)):
-        log.write("{}{:s}: {:.4f}\n".format(
-            (max_len - len(random_vars[sobol_extracted_idx_1st[i]])) * ' ',
-            random_vars[sobol_extracted_idx_1st[i]],
-            sobol_rel_1st_order_mean[i]))
-        # random_vars.append(self.random_vars[sobol_extracted_idx_1st[i]])
-
-    log.close()
-
-
-# # initialize logger
-# file_logger = logging.getLogger('gPC')
-# file_logger.setLevel(logging.DEBUG)
-# file_logger_handler = logging.FileHandler('gPC.log')
-# file_logger_formatter = logging.Formatter('%(asctime)s - %(name)s - %(message)s')
-# file_logger_handler.setFormatter(file_logger_formatter)
-# file_logger.addHandler(file_logger_handler)
-
-console_logger = logging.getLogger('gPC_console_output')
-console_logger.setLevel(logging.DEBUG)
-console_logger_handler = logging.StreamHandler()
-console_logger_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
-console_logger_handler.setFormatter(console_logger_formatter)
-console_logger.addHandler(console_logger_handler)
-
-# file_logger.disabled = False
-console_logger.disabled = False
-
-
-# def activate_terminal_output():
-#     console_logger.disabled = False
-#
-#
-# def activate_logfile_output():
-#     file_logger.disabled = False
-#
-#
-# def deactivate_terminal_output():
-#     console_logger.disabled = True
-#
-#
-# def deactivate_logfile_output():
-#     file_logger.disabled = True
-
-
-def iprint(message, verbose=True, tab=None):
-    """
-    Function that prints out a message over the python logging module
-
-    iprint(message, verbose=True)
-
-    Parameters
-    ----------
-    message: string
-        String to print in standard output
-    verbose: bool, optional, default=True
-        Determines if string is printed out
-    tab: int
-        Number of tabs before message
-    """
-    if verbose:
-        if tab:
-            message = '\t' * tab + message
-        # console_logger.info(message)
-        print(message)
-
-
-def wprint(message, verbose=True, tab=None):
-    """
-    Function that prints out a warning message over the python logging module
-
-    wprint(message, verbose=True)
-
-    Parameters
-    ----------
-    message: string
-        String to print in standard output
-    verbose: bool, optional, default=True
-        Determines if string is printed out
-    tab: int
-        Number of tabs before message
-    """
-
-    if verbose:
-        if tab:
-            message = '\t' * tab + message
-        console_logger.warning(message)
+import os
+import re
+import sys
+import h5py
+import uuid
+import pickle
+import inspect
+import logging
+import numpy as np
+from .misc import is_instance
+from collections import OrderedDict
+from importlib import import_module
+
+
+def write_session(obj, fname, folder="session", overwrite=True):
+    """
+    Saves a gpc session in pickle or hdf5 file formal depending on the
+    file extension in fname (.pkl or .hdf5)
+
+    Parameters
+    ----------
+    obj : Session object
+        Session class instance containing the gPC information
+    fname : str
+        Path to output file (.pkl or .hdf5)
+    folder : str, optional, default: "session"
+        Path in .hdf5 file (for .hdf5 format only)
+    overwrite : bool, optional, default: True
+        Overwrite existing file
+
+    Returns
+    -------
+    <file>: .hdf5 or .pkl file
+        .hdf5 or .pkl file containing the gpc session
+    """
+
+    file_format = os.path.splitext(fname)[1]
+
+    if file_format == ".pkl":
+        write_session_pkl(obj, fname, overwrite=overwrite)
+
+    elif file_format == ".hdf5":
+        write_session_hdf5(obj, fname, folder, overwrite=overwrite)
+
+    else:
+        raise IOError("Session can only be saved in .pkl or .hdf5 format.")
+
+
+def write_session_pkl(obj, fname, overwrite=True):
+    """
+    Write Session object including information about the Basis, Problem and Model as pickle file.
+
+    Parameters
+    ----------
+    obj: GPC or derived class
+        Class instance containing the gPC information
+    fname: str
+        Path to output file
+    overwrite : bool, optional, default: True
+        Overwrite existing file
+
+    Returns
+    -------
+    <file>: .pkl file
+        File containing the GPC object
+    """
+    if not overwrite and os.path.exists(fname):
+        Warning("File already exists.")
+    else:
+        with open(fname, 'wb') as f:
+            pickle.dump(obj, f, -1)
+
+
+def write_session_hdf5(obj, fname, folder="session", overwrite=True):
+    """
+    Write Session object including information about the Basis, Problem and Model as .hdf5 file.
+
+    Parameters
+    ----------
+    obj : Session object
+        Session class instance containing the gPC information
+    fname : str
+        Path to output file
+    folder : str, optional, default: "session"
+        Path in .hdf5 file
+    overwrite : bool, optional, default: True
+        Overwrite existing file
+
+    Returns
+    -------
+    <file>: .hdf5 file
+        .hdf5 file containing the gpc session
+    """
+
+    if overwrite and os.path.exists(fname):
+        os.remove(fname)
+
+    write_dict_to_hdf5(fn_hdf5=fname, data=obj.__dict__, folder=folder)
+
+
+def read_session(fname, folder=None):
+    """
+    Reads a gpc session in pickle or hdf5 file formal depending on the
+    file extension in fname (.pkl or .hdf5)
+
+    Parameters
+    ----------
+    fname : str
+        path to input file
+    folder : str, optional, default: None
+        Path in .hdf5 file
+
+    Returns
+    -------
+    obj : Session Object
+        Session object containing instances of Basis, Problem and Model etc.
+    """
+
+    file_format = os.path.splitext(fname)[1]
+
+    if file_format == ".pkl":
+        obj = read_session_pkl(fname)
+
+    elif file_format == ".hdf5":
+        obj = read_session_hdf5(fname=fname, folder=folder)
+
+    else:
+        raise IOError("Session can only be read from .pkl or .hdf5 files.")
+
+    return obj
+
+
+def read_session_pkl(fname):
+    """
+    Read Session object in pickle format.
+
+    Parameters
+    ----------
+    fname: str
+        path to input file
+
+    Returns
+    -------
+    obj: Session Object
+        Session object containing instances of Basis, Problem and Model etc.
+    """
+
+    with open(fname, 'rb') as f:
+        obj = pickle.load(f)
+
+    return obj
+
+
+def read_session_hdf5(fname, folder="session", verbose=False):
+    """
+    Read gPC object including information about input pdfs, polynomials, grid etc.
+
+    object = read_gpc_obj(fname)
+
+    Parameters
+    ----------
+    fname : str
+        path to input file
+    folder : str, optional, default: "session"
+        Path in .hdf5 file
+    verbose : bool, optional, default: False
+        Print output info
+
+    Returns
+    -------
+    obj: GPC Object
+        GPC object containing instances of Basis, Problem and Model.
+    """
+    from .Problem import Problem
+    from .Session import Session
+    from .RandomParameter import RandomParameter
+
+    # model
+    try:
+        model = read_model_from_hdf5(fn_hdf5=fname, folder=folder + "/model", verbose=verbose)
+    except KeyError:
+        model = None
+
+    # parameters
+    parameters_unsorted = read_parameters_from_hdf5(fn_hdf5=fname, folder=folder + "/problem/parameters",
+                                                    verbose=verbose)
+
+    problem_dict = read_group_from_hdf5(fn_hdf5=fname, folder=folder + "/problem", verbose=verbose)
+
+    parameters = OrderedDict()
+    parameters_random = OrderedDict()
+
+    for p in problem_dict["parameters_keys"]:
+        parameters[p] = parameters_unsorted[p]
+
+        if isinstance(parameters_unsorted[p], RandomParameter):
+            parameters_random[p] = parameters_unsorted[p]
+
+    # problem(model, parameters)
+    problem = Problem(model, parameters)
+
+    # options
+    options = read_group_from_hdf5(fn_hdf5=fname, folder=folder + "/algorithm/options")
+
+    # validation
+    try:
+        validation = read_validation_from_hdf5(fn_hdf5=fname, folder=folder + "/validation", verbose=verbose)
+    except KeyError:
+        validation = None
+
+    # grid
+    grid = read_grid_from_hdf5(fn_hdf5=fname, folder=folder + "/grid", verbose=verbose)
+
+    # algorithm
+    module = import_module(".Algorithm", package="pygpc")
+    algorithm_dict = read_group_from_hdf5(fn_hdf5=fname, folder=folder + "/algorithm", verbose=verbose)
+    alg = getattr(module, algorithm_dict["attrs"]["dtype"].split(".")[-1])
+    args = inspect.getfullargspec(alg).args[1:]
+
+    args_dict = dict()
+    args = [a for a in args if a != "gpc"]
+    for a in args:
+        args_dict[a] = locals()[a]
+
+    algorithm = alg(**args_dict)
+
+    # gpc
+    gpc_raw_list = read_group_from_hdf5(fn_hdf5=fname, folder=folder + "/gpc", verbose=verbose)
+    module = import_module(".Algorithm", package="pygpc")
+
+    gpc_list = [0 for _ in range(len(gpc_raw_list))]
+    for i_gpc, gpc_raw in enumerate(gpc_raw_list):
+
+        # read and initialize classifier if present
+        if "classifier" in gpc_raw.keys():
+            classifier = read_classifier_from_hdf5(fn_hdf5=fname,
+                                                   folder=folder + "/gpc/{}/classifier".format(i_gpc),
+                                                   verbose=verbose)
+
+        # read SGPC object if present (sub-gpc)
+        if "gpc" in gpc_raw.keys():
+            gpc = read_sgpc_from_hdf5(fn_hdf5=fname,
+                                      folder=folder + "/gpc/{}/gpc".format(i_gpc),
+                                      verbose=verbose)
+
+        # get gpc class (SGPC or MEGPC)
+        g = getattr(module, gpc_raw["attrs"]["dtype"].rsplit(".", 1)[1])
+        del gpc_raw["attrs"]
+
+        # SGPC
+        if "SGPC" in g.__module__:
+            gpc_list = read_sgpc_from_hdf5(fn_hdf5=fname,
+                                           folder=folder + "/gpc/{}".format(i_gpc),
+                                           verbose=verbose)
+        # MEGPC with sub-gpcs
+        else:
+            # get input parameters of gpc
+            args = inspect.getfullargspec(g).args[1:]
+
+            args_dict = dict()
+            for a in args:
+                args_dict[a] = locals()[a]
+
+            # initialize gpc
+            gpc_list[i_gpc] = g(**args_dict)
+
+            # loop over entries and save in self (if we have it in locals() we take this,
+            # e.g. gpc, grid, validation etc)
+            for key in gpc_raw:
+                if key in locals():
+                    setattr(gpc_list[i_gpc], key, locals()[key])
+                else:
+                    setattr(gpc_list[i_gpc], key, gpc_raw[key])
+
+    # session(algorithm)
+    session = Session(algorithm=algorithm)
+
+    # read session hdf5 content
+    session_dict = read_group_from_hdf5(fn_hdf5=fname, folder=folder, verbose=verbose)
+
+    for key in session_dict:
+        if key in locals():
+            setattr(session, key, locals()[key])
+        else:
+            setattr(session, key, session_dict[key])
+
+    # add path of .hdf5 script to python which generated the session (needed in case of relative imports)
+    sys.path.append(os.path.split(session_dict["fn_script"])[0])
+
+    # set gpc type in session
+    session.set_gpc(gpc_list)
+
+    return session
+
+
+def read_problem_from_hdf5(fn_hdf5, folder, verbose=False):
+    """
+    Reads problem from hdf5 file
+
+    Parameters
+    ----------
+    fn_hdf5 : str
+        Filename of .hdf5 file to write in
+    folder : str
+        Folder inside .hdf5 file where dict is saved
+    verbose : bool, optional, default: False
+        Print output info
+
+    Returns
+    -------
+    problem : Problem object
+        Problem
+    """
+    from .Problem import Problem
+
+    # read content of problem
+    problem_dict = read_group_from_hdf5(fn_hdf5=fn_hdf5, folder=folder, verbose=verbose)
+
+    # model
+    model = read_model_from_hdf5(fn_hdf5=fn_hdf5, folder=folder + "/model", verbose=verbose)
+
+    # parameters
+    parameters_unsorted = read_parameters_from_hdf5(fn_hdf5=fn_hdf5, folder=folder + "/parameters", verbose=False)
+
+    # sort parameters
+    parameters = OrderedDict()
+
+    for p in problem_dict["parameters_keys"]:
+        parameters[p] = parameters_unsorted[p]
+
+    # initialize problem
+    problem = Problem(model, parameters)
+
+    return problem
+
+
+def read_classifier_from_hdf5(fn_hdf5, folder, verbose=False):
+    """
+    Reads classifier from hdf5 file
+
+    Parameters
+    ----------
+    fn_hdf5 : str
+        Filename of .hdf5 file to write in
+    folder : str
+        Folder inside .hdf5 file where dict is saved
+    verbose : bool, optional, default: False
+        Print output info
+
+    Returns
+    -------
+    classifier : classifier object
+        Classifier
+    """
+    classifier_dict = read_group_from_hdf5(fn_hdf5=fn_hdf5, folder=folder, verbose=verbose)
+    module = import_module(".Classifier", package="pygpc")
+    c = getattr(module, classifier_dict["attrs"]["dtype"].rsplit(".", 1)[1])
+
+    # get input parameters of classifier
+    args = inspect.getfullargspec(c).args[1:]
+
+    args_dict = dict()
+    for a in args:
+        args_dict[a] = classifier_dict[a]
+
+    init_classifier = True
+
+    # for some reason the domains may be swapped in very rare cases so we do the init again
+    while init_classifier:
+        # initialize classifier
+        classifier = c(**args_dict)
+
+        # ensure that domains are not swapped
+        classifier.domains = classifier_dict["domains"]
+        classifier.update(coords=classifier_dict["coords"],
+                          results=classifier_dict["results"])
+
+        if np.sum(classifier.predict(coords=classifier_dict["coords"]) == classifier_dict["domains"])/ \
+                len(classifier_dict["domains"]) > 0.95:
+            init_classifier = False
+
+    return classifier
+
+
+def read_basis_from_hdf5(fn_hdf5, folder, verbose=False):
+    """
+    Reads Basis from hdf5 file
+
+    Parameters
+    ----------
+    fn_hdf5 : str
+        Filename of .hdf5 file to write in
+    folder : str
+        Folder inside .hdf5 file where dict is saved
+    verbose : bool, optional, default: False
+        Print output info
+
+    Returns
+    -------
+    basis : Basis object
+        basis
+    """
+
+    basis_dict = read_group_from_hdf5(fn_hdf5=fn_hdf5, folder=folder, verbose=verbose)
+    module_basis = import_module(".Basis", package="pygpc")
+    module_basis_function = import_module(".BasisFunction", package="pygpc")
+    b = getattr(module_basis, basis_dict["attrs"]["dtype"].rsplit(".", 1)[1])
+
+    # get arguments to initialize basis
+    args = inspect.getfullargspec(b).args[1:]
+
+    # collect arguments from hdf5 file content
+    args_dict = dict()
+    for a in args:
+        args_dict[a] = basis_dict[a]
+
+    # initialize basis
+    basis = b(**args_dict)
+
+    # write content in self
+    for key in basis_dict:
+        if key != "b":
+            setattr(basis, key,  basis_dict[key])
+
+    b = [[0 for _ in range(basis_dict["dim"])] for _ in range(basis_dict["n_basis"])]
+    for i_basis, b_lst in enumerate(basis_dict["b"]):
+        for i_dim, b_ in enumerate(b_lst):
+            # get type of basis function
+            bf = getattr(module_basis_function, b_["attrs"]["dtype"].rsplit(".", 1)[1])
+
+            # read content of hdf5
+            bf_dict = read_group_from_hdf5(fn_hdf5=fn_hdf5,
+                                           folder=folder + "/b/{}/{}".format(i_basis, i_dim),
+                                           verbose=verbose)
+
+            # get arguments to initialize basis function
+            args = inspect.getfullargspec(bf).args[1:]
+
+            # collect arguments from hdf5 file content
+            args_dict = dict()
+            for a in args:
+                args_dict[a] = bf_dict[a]
+
+            # initialize basis function
+            b[i_basis][i_dim] = bf(**args_dict)
+
+    # extend basis
+    basis.extend_basis(b)
+
+    return basis
+
+
+def read_sgpc_from_hdf5(fn_hdf5, folder, verbose=False):
+    """
+    Reads SGPC from hdf5 file
+
+    Parameters
+    ----------
+    fn_hdf5 : str
+        Filename of .hdf5 file to write in
+    folder : str
+        Folder inside .hdf5 file where dict is saved
+    verbose : bool, optional, default: False
+        Print output info
+
+    Returns
+    -------
+    sgpc : SGPC object or list of SGPC objects
+        SGPC
+    """
+
+    sgpc_raw_list = read_group_from_hdf5(fn_hdf5=fn_hdf5, folder=folder, verbose=verbose)
+    module = import_module(".SGPC", package="pygpc")
+
+    if type(sgpc_raw_list) is not list:
+        sgpc_raw_list = [sgpc_raw_list]
+        sub_gpc = False
+    else:
+        sub_gpc = True
+
+    sgpc_list = [0 for _ in range(len(sgpc_raw_list))]
+
+    for i_gpc, sgpc_raw in enumerate(sgpc_raw_list):
+        if sub_gpc:
+            hdf5_loc = "/{}/".format(i_gpc)
+        else:
+            hdf5_loc = "/"
+
+        # get gpc by type
+        g = getattr(module, sgpc_raw["attrs"]["dtype"].rsplit(".", 1)[1])
+
+        # get input parameters of classifier
+        args = inspect.getfullargspec(g).args[1:]
+
+        args_dict = dict()
+        for a in args:
+            if a == "problem":
+                args_dict[a] = read_problem_from_hdf5(fn_hdf5=fn_hdf5,
+                                                      folder=folder + hdf5_loc + a,
+                                                      verbose=verbose)
+            elif a == "validation":
+                args_dict[a] = read_validation_from_hdf5(fn_hdf5=fn_hdf5,
+                                                         folder=folder + hdf5_loc + a,
+                                                         verbose=verbose)
+            else:
+                args_dict[a] = sgpc_raw[a]
+
+        # initialize SGPC object
+        sgpc_list[i_gpc] = g(**args_dict)
+
+        # write objects in self
+        for key in sgpc_raw:
+            try:
+                dtype = sgpc_raw[key]["attrs"]["dtype"]
+
+                if "pygpc.Basis" in dtype:
+                    basis = read_basis_from_hdf5(fn_hdf5=fn_hdf5,
+                                                 folder=folder + hdf5_loc + key,
+                                                 verbose=verbose)
+                    setattr(sgpc_list[i_gpc], key, basis)
+
+                elif "pygpc.Grid" in dtype:
+                    grid = read_grid_from_hdf5(fn_hdf5=fn_hdf5,
+                                               folder=folder + hdf5_loc + key,
+                                               verbose=verbose)
+                    setattr(sgpc_list[i_gpc], key, grid)
+
+                elif "pygpc.Problem" in dtype:
+                    problem = read_problem_from_hdf5(fn_hdf5=fn_hdf5,
+                                                     folder=folder + hdf5_loc + key,
+                                                     verbose=verbose)
+                    setattr(sgpc_list[i_gpc], key, problem)
+
+                else:
+                    setattr(sgpc_list[i_gpc], key, sgpc_raw[key])
+
+            except (KeyError, IndexError, TypeError):
+                setattr(sgpc_list[i_gpc], key, sgpc_raw[key])
+
+    return sgpc_list
+
+
+def read_model_from_hdf5(fn_hdf5, folder, verbose=False):
+    """
+    Reads model from hdf5 file
+
+    Parameters
+    ----------
+    fn_hdf5 : str
+        Filename of .hdf5 file to write in
+    folder : str
+        Folder inside .hdf5 file where dict is saved
+    verbose : bool, optional, default: False
+        Print output info
+
+    Returns
+    -------
+    model : Model object
+        Model
+    """
+
+    model_dict = read_group_from_hdf5(fn_hdf5=fn_hdf5, folder=folder, verbose=verbose)
+    sys.path.append(os.path.split(model_dict["fname"])[0])
+    module = import_module(os.path.splitext(os.path.split(model_dict["fname"])[1])[0])
+    model = getattr(module, model_dict["attrs"]["dtype"].rsplit(".", 1)[1])()
+
+    return model
+
+
+def read_parameters_from_hdf5(fn_hdf5, folder, verbose=False):
+    """
+    Reads parameters from hdf5 file
+
+    Parameters
+    ----------
+    fn_hdf5 : str
+        Filename of .hdf5 file to write in
+    folder : str
+        Folder inside .hdf5 file where dict is saved
+    verbose : bool, optional, default: False
+        Print output info
+
+    Returns
+    -------
+    parameters : OrderedDict
+        OrdererDict containing the parameters (random and deterministic)
+    """
+    parameters = OrderedDict()
+    parameters_dict = read_group_from_hdf5(fn_hdf5=fn_hdf5, folder=folder, verbose=verbose)
+    module = import_module(".RandomParameter", package="pygpc")
+
+    for p in parameters_dict:
+        if (type(parameters_dict[p]) is dict or type(parameters_dict[p]) is OrderedDict) and \
+                "RandomParameter" in parameters_dict[p]["attrs"]["dtype"]:
+            rp = getattr(module, parameters_dict[p]["attrs"]["dtype"].split(".")[-1])
+            args = inspect.getfullargspec(rp).args[1:]
+
+            args_dict = dict()
+            for a in args:
+                args_dict[a] = parameters_dict[p][a]
+
+            parameters[p] = rp(**args_dict)
+
+        else:
+            parameters[p] = parameters_dict[p]
+
+    return parameters
+
+
+def read_grid_from_hdf5(fn_hdf5, folder, verbose=False):
+    """
+    Reads and initializes grid from hdf5 file
+
+    Parameters
+    ----------
+    fn_hdf5 : str
+        Filename of .hdf5 file to write in
+    folder : str
+        Folder inside .hdf5 file where dict is saved
+    verbose : bool, optional, default: False
+        Print output info
+
+    Returns
+    -------
+    grid : Grid object
+        Grid
+    """
+
+    grid_dict = read_group_from_hdf5(fn_hdf5=fn_hdf5, folder=folder, verbose=verbose)
+
+    module = import_module(".Grid", package="pygpc")
+    g = getattr(module, grid_dict["attrs"]["dtype"].split(".")[-1])
+
+    # get arguments of grid function
+    args = inspect.getfullargspec(g).args[1:]
+
+    # read content of hdf5 and relate to arguments
+    args_dict = dict()
+    for a in args:
+        if a in ["coords", "coords_norm", "coords_gradient", "coords_gradient_norm", "weights"]:
+            args_dict[a] = grid_dict["_" + a]
+        elif a == "parameters_random":
+            parameters_random = read_parameters_from_hdf5(fn_hdf5=fn_hdf5,
+                                                          folder=folder + "/parameters_random",
+                                                          verbose=verbose)
+            args_dict[a] = parameters_random
+        else:
+            args_dict[a] = grid_dict[a]
+
+    # regenerate unique grid IDs
+    args_dict["coords_id"] = [uuid.uuid4() for _ in range(grid_dict["n_grid"])]
+
+    if args_dict["coords_gradient"] is not None:
+        args_dict["coords_gradient_id"] = args_dict["coords_id"]
+
+    grid = g(**args_dict)
+
+    return grid
+
+
+def read_validation_from_hdf5(fn_hdf5, folder, verbose=False):
+    """
+    Reads and initializes ValidatioSet from hdf5 file
+
+    Parameters
+    ----------
+    fn_hdf5 : str
+        Filename of .hdf5 file to write in
+    folder : str
+        Folder inside .hdf5 file where dict is saved
+    verbose : bool, optional, default: False
+        Print output info
+
+    Returns
+    -------
+    validation : ValidationSet object
+        ValidationSet
+    """
+    from .ValidationSet import ValidationSet
+    validation_dict = read_group_from_hdf5(fn_hdf5=fn_hdf5, folder=folder)
+
+    if validation_dict is None:
+        validation = None
+    else:
+        args_dict = dict()
+        args = inspect.getfullargspec(ValidationSet).args[1:]
+
+        for a in args:
+            if a == "grid":
+                args_dict[a] = read_grid_from_hdf5(fn_hdf5=fn_hdf5, folder=folder + "/grid", verbose=verbose)
+            else:
+                args_dict[a] = validation_dict[a]
+
+        validation = ValidationSet(**args_dict)
+
+    return validation
+
+
+def read_group_from_hdf5(fn_hdf5, folder, verbose=False):
+    """
+    Read data from group (folder) in hdf5 file
+
+    Parameters
+    ----------
+    fn_hdf5 : str
+        Filename of .hdf5 file to write in
+    folder : str
+        Folder inside .hdf5 file where dict is saved
+    verbose : bool, optional, default: False
+        Print output info
+
+    Returns
+    -------
+    data : dict or list or OrderedDict
+        Folder content
+    """
+    f = h5py.File(fn_hdf5, "r")
+
+    attrs = dict()
+    for a in f[folder].attrs:
+        attrs[a] = f[folder].attrs.__getitem__(a)
+
+    data = dict()
+
+    if isinstance(f[folder], h5py.Group) and len(f[folder].keys()) > 0:
+        for key in f[folder].keys():
+            if folder != "/":
+                data["attrs"] = attrs
+            data[key] = read_array_from_hdf5(fn_hdf5=fn_hdf5,
+                                             arr_name=folder + "/" + key)
+
+        if folder != "/":
+            if data["attrs"]["dtype"] == "list":
+                data = [data[key] for key in data if key != "attrs"]
+
+            elif data["attrs"]["dtype"] == "dict":
+                del data["attrs"]
+
+            elif data["attrs"]["dtype"] == "collections.OrderedDict":
+                data_ordered = OrderedDict()
+
+                for key in data:
+                    if key != "attrs":
+                        data_ordered[key] = data[key]
+
+                data = data_ordered
+
+    else:
+        data = None
+
+    return data
+
+
+def read_array_from_hdf5(fn_hdf5, arr_name, verbose=False):
+    """
+
+    Parameters
+    ----------
+    fn_hdf5 : str
+        Filename of .hdf5 file to write in
+    folder : str
+        Folder inside .hdf5 file where dict is saved
+    verbose : bool, optional, default: False
+        Print output info
+
+    Returns
+    -------
+    data
+
+    attrs
+
+    """
+    f = h5py.File(fn_hdf5, "r")
+
+    if isinstance(f[arr_name], h5py.Group):
+        data = read_group_from_hdf5(fn_hdf5=fn_hdf5, folder=arr_name)
+
+    else:
+        data = f[arr_name][()]
+
+    if type(data) == np.bytes_:
+        data = str(data.astype(str))
+
+    if type(data) == str and (data == "None" or data == "N/A"):
+        data = None
+
+    return data
+
+
+def write_dict_to_hdf5(fn_hdf5, data, folder, verbose=False):
+    """
+    Takes dict and passes its keys to write_arr_to_hdf5()
+
+    fn_hdf5:folder/
+                  |--key1
+                  |--key2
+                  |...
+
+    Parameters
+    ----------
+    fn_hdf5 : str
+        Filename of .hdf5 file to write in
+    data : dict
+        Dictionary to save in .hdf5 file
+    folder : str
+        Folder inside .hdf5 file where dict is saved
+    verbose : bool, optional, default: False
+        Print output info
+    """
+    max_recursion_depth = 12
+
+    # object (dict)
+    if is_instance(data) and not isinstance(data, OrderedDict):
+
+        t, dt = get_dtype(data)
+
+        # do not save uuids in hdf5
+        if dt == "uuid.UUID":
+            return
+
+        else:
+
+            # create group and set type and dtype attributes
+            with h5py.File(fn_hdf5, "a") as f:
+                f.create_group(str(folder))
+                f[str(folder)].attrs.__setitem__("type", t)
+                f[str(folder)].attrs.__setitem__("dtype", dt)
+
+            # write content
+            for key in data.__dict__:
+                if len(folder.split("/")) >= max_recursion_depth:
+                    data.__dict__[key] = "None"
+
+                write_arr_to_hdf5(fn_hdf5=fn_hdf5,
+                                  arr_name=folder+"/"+key,
+                                  data=data.__dict__[key],
+                                  verbose=verbose)
+
+    # mappingproxy (can not be saved)
+    elif str(type(data)) == "<class 'mappingproxy'>":
+        data = "mappingproxy"
+        write_arr_to_hdf5(fn_hdf5=fn_hdf5,
+                          arr_name="mappingproxy",
+                          data=data,
+                          verbose=verbose)
+
+    # list or tuple
+    elif type(data) is list or type(data) is tuple:
+        t, dt = get_dtype(data)
+
+        # create group and set type and dtype attributes
+        with h5py.File(fn_hdf5, "a") as f:
+            f.create_group(str(folder))
+            f[str(folder)].attrs.__setitem__("type", t)
+            f[str(folder)].attrs.__setitem__("dtype", dt)
+
+        for idx, lst in enumerate(data):
+            if len(folder.split("/")) >= max_recursion_depth:
+                lst = "None"
+
+            write_arr_to_hdf5(fn_hdf5=fn_hdf5,
+                              arr_name=folder+"/"+str(idx),
+                              data=lst,
+                              verbose=verbose)
+
+    # dict or OrderedDict
+    else:
+        t, dt = get_dtype(data)
+
+        # create group and set type and dtype attributes
+        with h5py.File(fn_hdf5, "a") as f:
+            try:
+                f.create_group(str(folder))
+                f[str(folder)].attrs.__setitem__("type", t)
+                f[str(folder)].attrs.__setitem__("dtype", dt)
+            except ValueError:
+                pass
+
+        for key in list(data.keys()):
+            if len(folder.split("/")) >= max_recursion_depth:
+                data[key] = "None"
+
+            write_arr_to_hdf5(fn_hdf5=fn_hdf5,
+                              arr_name=folder+"/"+str(key),
+                              data=data[key],
+                              verbose=verbose)
+
+
+def write_arr_to_hdf5(fn_hdf5, arr_name, data, overwrite_arr=True, verbose=False):
+    """
+    Takes an array and adds it to an .hdf5 file
+
+    If data is list of dict, write_dict_to_hdf5() is called for each dict with adapted hdf5-folder name
+    Otherwise, data is casted to np.ndarray and dtype of unicode data casted to '|S'.
+
+    Parameters
+    ----------
+    fn_hdf5 : str
+        Filename of .hdf5 file
+    arr_name : str
+        Complete path in .hdf5 file with array name
+    data : ndarray, list or dict
+        Data to write
+    overwrite_arr : bool, optional, default: True
+        Overwrite existing array
+    verbose : bool, optional, default: False
+        Print information
+    """
+    max_recursion_depth = 12
+
+    # dict or OrderedDict
+    if isinstance(data, dict) or isinstance(data, OrderedDict):
+        if len(arr_name.split("/")) >= max_recursion_depth:
+            data = np.array("None")
+        else:
+            write_dict_to_hdf5(fn_hdf5=fn_hdf5,
+                               data=data,
+                               folder=arr_name,
+                               verbose=verbose)
+            return
+
+    # list of dictionaries:
+    elif isinstance(data, list) and len(data) > 0 and (isinstance(data[0], dict) or is_instance(data[0])):
+        t, dt = get_dtype(data)
+
+        # do not save uuids in hdf5
+        if dt == "uuid.UUID":
+            return
+
+        else:
+            # create group and set type and dtype attributes
+            with h5py.File(fn_hdf5, "a") as f:
+                f.create_group(str(arr_name))
+                f[str(arr_name)].attrs.__setitem__("type", t)
+                f[str(arr_name)].attrs.__setitem__("dtype", dt)
+
+            for idx, lst in enumerate(data):
+                if len(arr_name.split("/")) >= max_recursion_depth:
+                    lst = np.array("None")
+
+                write_dict_to_hdf5(fn_hdf5=fn_hdf5,
+                                   data=lst,
+                                   folder=arr_name+"/"+str(idx),
+                                   verbose=verbose)
+            return
+
+    # object
+    elif is_instance(data):
+        if len(arr_name.split("/")) >= max_recursion_depth:
+            data = np.array("None")
+        else:
+            t, dt = get_dtype(data)
+
+            # create group and set type and dtype attributes
+            with h5py.File(fn_hdf5, "a") as f:
+                f.create_group(str(arr_name))
+                f[str(arr_name)].attrs.__setitem__("type", t)
+                f[str(arr_name)].attrs.__setitem__("dtype", dt)
+
+            write_dict_to_hdf5(fn_hdf5=fn_hdf5,
+                               data=data.__dict__,
+                               folder=arr_name,
+                               verbose=verbose)
+            return
+
+    # list or tuple
+    elif type(data) is list or type(data) is tuple:
+        if len(arr_name.split("/")) >= max_recursion_depth:
+            data = np.array(["None"])
+
+        t, dt = get_dtype(data)
+
+        # do not save uuids in hdf5
+        if dt == "uuid.UUID":
+            return
+
+        else:
+            # create group and set type and dtype attributes
+            with h5py.File(fn_hdf5, "a") as f:
+                f.create_group(str(arr_name))
+                f[str(arr_name)].attrs.__setitem__("type", t)
+                f[str(arr_name)].attrs.__setitem__("dtype", dt)
+
+            data_dict = dict()
+
+            for idx, lst in enumerate(data):
+                data_dict[idx] = lst
+
+            write_dict_to_hdf5(fn_hdf5=fn_hdf5,
+                               data=data_dict,
+                               folder=arr_name,
+                               verbose=verbose)
+
+            return
+
+    elif not isinstance(data, np.ndarray):
+        if len(arr_name.split("/")) >= max_recursion_depth:
+            data = np.array("None")
+        else:
+            data = np.array(data)
+
+    # np.arrays of np.arrays
+    elif data.dtype == 'O' and len(data) > 1:
+        if len(arr_name.split("/")) >= max_recursion_depth:
+            return
+        else:
+            t, dt = get_dtype(data)
+
+            # create group and set type and dtype attributes
+            with h5py.File(fn_hdf5, "a") as f:
+                f.create_group(str(arr_name))
+                f[str(arr_name)].attrs.__setitem__("type", t)
+                f[str(arr_name)].attrs.__setitem__("dtype", dt)
+
+            data = data.tolist()
+            write_dict_to_hdf5(fn_hdf5=fn_hdf5,
+                               data=data,
+                               folder=arr_name,
+                               verbose=verbose)
+            return
+
+    # do some type casting from numpy/pd -> h5py
+    # date column from experiment.csv is O
+    # plotsetting["view"] is O list of list of different length
+    # coil1 and coil2 columns names from experiment.csv is <U8
+    # coil_mean column name from experiment.csv is <U12
+    if data.dtype == 'O' or data.dtype.kind == 'U':
+        data = data.astype('|S')
+
+        if verbose:
+            print("Converting array " + arr_name + " to string")
+
+    t, dt = get_dtype(data)
+
+    with h5py.File(fn_hdf5, 'a') as f:
+        # create data_set
+        if overwrite_arr:
+            try:
+                del f[arr_name]
+            except KeyError:
+                pass
+
+        f.create_dataset(arr_name, data=data)
+        f[str(arr_name)].attrs.__setitem__("type", t)
+        f[str(arr_name)].attrs.__setitem__("dtype", dt)
+
+    return
+
+
+def get_dtype(obj):
+    """
+    Get type and datatype of object
+
+    Parameters
+    ----------
+    obj : Object
+        Input object (any)
+
+    Returns
+    -------
+    type : str
+        Type of object (e.g. 'class')
+    dtype : str
+        Datatype of object (e.g. 'numpy.ndarray')
+    """
+    type_str = str(type(obj))
+    type_attr = re.match(pattern=r"\<(.*?)\ '", string=type_str).group(1)
+    dtype_attr = re.findall(pattern=r"'(.*?)'", string=type_str)[0]
+
+    return type_attr, dtype_attr
+
+
+def write_data_txt(data, fname):
+    """
+    Write data (quantity of interest) in .txt file (e.g. coeffs, mean, std, ...).
+
+    write_data_txt(data, fname)
+
+    Parameters
+    ----------
+    data: ndarray of float
+        Data to save
+    fname: str
+        Path to output file
+
+    Returns
+    -------
+    <file>: .txt file
+        File containing the data (tab delimited)
+    """
+
+    np.savetxt(fname, data, fmt='%.10e', delimiter='\t', newline='\n', header='', footer='')
+
+
+def read_data_hdf5(fname, loc):
+    """
+    Read data from .hdf5 file (e.g. coeffs, mean, std, ...).
+
+    load_data_hdf5(fname, loc)
+
+    Parameters
+    ----------
+    fname: str
+        path to input file
+    loc: str
+        location (folder and name) in hdf5 file (e.g. data/phi)
+
+    Returns
+    -------
+    data: ndarray of float
+        Loaded data from .hdf5 file
+    """
+
+    with h5py.File(fname, 'r') as f:
+        d = f[loc]
+        return d
+
+
+def write_data_hdf5(data, fname, loc):
+    """
+    Write quantity of interest in .hdf5 file (e.g. coeffs, mean, std, ...).
+
+    write_data_hdf5(data, fname, loc)
+
+    Parameters
+    ----------
+    data: np.ndarray
+        data to save
+    fname: str
+        path to output file
+    loc: str
+        location (folder and name) in hdf5 file (e.g. data/phi)
+    """
+
+    with h5py.File(fname, 'a') as f:
+        f.create_dataset(loc, data=data)
+
+
+def write_sobol_idx_txt(sobol_idx, fname):
+    """
+    Write sobol_idx list in file.
+
+    write_sobol_idx_txt(sobol_idx, filename)
+
+    Parameters
+    ----------
+    sobol_idx: [N_sobol] list of np.ndarray
+        List of parameter label indices belonging to Sobol indices
+    fname: str
+        Path to output file
+
+    Returns
+    -------
+    <file>: .txt file
+        File containing the sobol index list.
+    """
+
+    f = open(fname, 'w')
+    f.write('# Parameter index list of Sobol indices:\n')
+    for line in sobol_idx:
+        for entry in line:
+            if entry != line[0]:
+                f.write(', ')
+            f.write('{}'.format(entry))
+        if line != sobol_idx[-1]:
+            f.write('\n')
+
+    f.close()
+
+
+def read_sobol_idx_txt(fname):
+    """
+    Read sobol_idx list from file.
+
+    read_sobol_idx_txt(fname)
+
+    Parameters
+    ----------
+    fname: str
+        Path to input file
+
+    Returns
+    -------
+    sobol_idx: [N_sobol] list of np.array
+        List of parameter label indices belonging to Sobol indices
+    """
+
+    f = open(fname, 'r')
+
+    line = f.readline().strip('\n')
+    sobol_idx = []
+
+    while line:
+
+        # ignore comments in text file
+        if line[0] == '#':
+            line = f.readline().strip('\n')
+            continue
+
+        else:
+            # read comma separated indices and convert to ndarray
+            sobol_idx.append(np.asarray([int(x) for x in line.split(',') if x]))
+
+        line = f.readline().strip('\n')
+
+    return sobol_idx
+
+
+def write_log_sobol(fname, random_vars, sobol_rel_order_mean, sobol_rel_1st_order_mean, sobol_extracted_idx_1st):
+    """
+    Write average ratios of Sobol indices into logfile.
+
+    Parameters
+    ----------
+    fname: str
+        Path of logfile
+    random_vars: list of str
+        Labels of random variables
+    sobol_rel_order_mean: np.ndarray
+        Average proportion of the Sobol indices of the different order to the total variance (1st, 2nd, etc..,).
+        (over all output quantities)
+    sobol_rel_1st_order_mean: np.ndarray
+        Average proportion of the random variables of the 1st order Sobol indices to the total variance.
+        (over all output quantities)
+    sobol_extracted_idx_1st: list of int [N_sobol_1st]
+        Indices of extracted 1st order Sobol indices corresponding to SGPC.random_vars.
+
+    Returns
+    -------
+    <File>: .txt file
+        Logfile containing information about the average ratios of 1st order Sobol indices w.r.t. the total variance
+    """
+    # start log
+    log = open(os.path.splitext(fname)[0] + '.txt', 'w')
+    log.write("Sobol indices:\n")
+    log.write("==============\n")
+    log.write("\n")
+
+    # print order ratios
+    log.write("Ratio: order / total variance over all output quantities:\n")
+    log.write("---------------------------------------------------------\n")
+    for i in range(len(sobol_rel_order_mean)):
+        log.write("Order {}: {:.4f}\n".format(i + 1, sobol_rel_order_mean[i]))
+
+    log.write("\n")
+
+    # print 1st order ratios of parameters
+    log.write("Ratio: 1st order Sobol indices of parameters / total variance over all output quantities\n")
+    log.write("----------------------------------------------------------------------------------------\n")
+
+    # random_vars = []
+    max_len = max([len(random_vars[i]) for i in range(len(random_vars))])
+    for i in range(len(sobol_rel_1st_order_mean)):
+        log.write("{}{:s}: {:.4f}\n".format(
+            (max_len - len(random_vars[sobol_extracted_idx_1st[i]])) * ' ',
+            random_vars[sobol_extracted_idx_1st[i]],
+            sobol_rel_1st_order_mean[i]))
+        # random_vars.append(self.random_vars[sobol_extracted_idx_1st[i]])
+
+    log.close()
+
+
+# # initialize logger
+# file_logger = logging.getLogger('gPC')
+# file_logger.setLevel(logging.DEBUG)
+# file_logger_handler = logging.FileHandler('gPC.log')
+# file_logger_formatter = logging.Formatter('%(asctime)s - %(name)s - %(message)s')
+# file_logger_handler.setFormatter(file_logger_formatter)
+# file_logger.addHandler(file_logger_handler)
+
+console_logger = logging.getLogger('gPC_console_output')
+console_logger.setLevel(logging.DEBUG)
+console_logger_handler = logging.StreamHandler()
+console_logger_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
+console_logger_handler.setFormatter(console_logger_formatter)
+console_logger.addHandler(console_logger_handler)
+
+# file_logger.disabled = False
+console_logger.disabled = False
+
+
+# def activate_terminal_output():
+#     console_logger.disabled = False
+#
+#
+# def activate_logfile_output():
+#     file_logger.disabled = False
+#
+#
+# def deactivate_terminal_output():
+#     console_logger.disabled = True
+#
+#
+# def deactivate_logfile_output():
+#     file_logger.disabled = True
+
+
+def iprint(message, verbose=True, tab=None):
+    """
+    Function that prints out a message over the python logging module
+
+    iprint(message, verbose=True)
+
+    Parameters
+    ----------
+    message: string
+        String to print in standard output
+    verbose: bool, optional, default=True
+        Determines if string is printed out
+    tab: int
+        Number of tabs before message
+    """
+    if verbose:
+        if tab:
+            message = '\t' * tab + message
+        # console_logger.info(message)
+        print(message)
+
+
+def wprint(message, verbose=True, tab=None):
+    """
+    Function that prints out a warning message over the python logging module
+
+    wprint(message, verbose=True)
+
+    Parameters
+    ----------
+    message: string
+        String to print in standard output
+    verbose: bool, optional, default=True
+        Determines if string is printed out
+    tab: int
+        Number of tabs before message
+    """
+
+    if verbose:
+        if tab:
+            message = '\t' * tab + message
+        console_logger.warning(message)
```

## pygpc/misc.py

```diff
@@ -1,2798 +1,2717 @@
-00000000: 0d0a 696d 706f 7274 2073 7973 0d0a 696d  ..import sys..im
-00000010: 706f 7274 206d 6174 680d 0a69 6d70 6f72  port math..impor
-00000020: 7420 636f 7079 0d0a 696d 706f 7274 2072  t copy..import r
-00000030: 616e 646f 6d0d 0a69 6d70 6f72 7420 7761  andom..import wa
-00000040: 726e 696e 6773 0d0a 696d 706f 7274 2069  rnings..import i
-00000050: 7465 7274 6f6f 6c73 0d0a 696d 706f 7274  tertools..import
-00000060: 206e 756d 7079 2061 7320 6e70 0d0a 696d   numpy as np..im
-00000070: 706f 7274 2073 6369 7079 2e73 7461 7473  port scipy.stats
-00000080: 0d0a 696d 706f 7274 2073 6369 7079 2e73  ..import scipy.s
-00000090: 7065 6369 616c 0d0a 696d 706f 7274 2073  pecial..import s
-000000a0: 6369 7079 2e73 7061 7469 616c 0d0a 696d  cipy.spatial..im
-000000b0: 706f 7274 206d 6174 706c 6f74 6c69 622e  port matplotlib.
-000000c0: 7079 706c 6f74 2061 7320 706c 740d 0a0d  pyplot as plt...
-000000d0: 0a66 726f 6d20 7363 6970 792e 7370 6174  .from scipy.spat
-000000e0: 6961 6c2e 6469 7374 616e 6365 2069 6d70  ial.distance imp
-000000f0: 6f72 7420 6364 6973 740d 0a66 726f 6d20  ort cdist..from 
-00000100: 2e56 6973 7561 6c69 7a61 7469 6f6e 2069  .Visualization i
-00000110: 6d70 6f72 7420 706c 6f74 5f62 6574 615f  mport plot_beta_
-00000120: 7064 665f 6669 740d 0a66 726f 6d20 6d70  pdf_fit..from mp
-00000130: 6c5f 746f 6f6c 6b69 7473 2e6d 706c 6f74  l_toolkits.mplot
-00000140: 3364 2e61 7274 3364 2069 6d70 6f72 7420  3d.art3d import 
-00000150: 506f 6c79 3344 436f 6c6c 6563 7469 6f6e  Poly3DCollection
-00000160: 0d0a 0d0a 0d0a 6465 6620 7371 7561 7265  ......def square
-00000170: 645f 6578 706f 6e65 6e74 6961 6c5f 6b65  d_exponential_ke
-00000180: 726e 656c 2878 2c20 792c 206c 656e 6774  rnel(x, y, lengt
-00000190: 6873 6361 6c65 2c20 7661 7269 616e 6365  hscale, variance
-000001a0: 293a 0d0a 2020 2020 2222 220d 0a20 2020  ):..    """..   
-000001b0: 2043 6f6d 7075 7465 7320 7468 6520 7371   Computes the sq
-000001c0: 7561 7265 6420 6578 706f 6e65 6e74 6961  uared exponentia
-000001d0: 6c20 6b65 726e 656c 2066 6f72 2047 6175  l kernel for Gau
-000001e0: 7373 6961 6e20 5072 6f63 6573 7365 732e  ssian Processes.
-000001f0: 0d0a 0d0a 2020 2020 5061 7261 6d65 7465  ....    Paramete
-00000200: 7273 0d0a 2020 2020 2d2d 2d2d 2d2d 2d2d  rs..    --------
-00000210: 2d2d 0d0a 2020 2020 7820 3a20 6e70 2e6e  --..    x : np.n
-00000220: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-00000230: 5b4e 2078 2064 696d 5d0d 0a20 2020 2020  [N x dim]..     
-00000240: 2020 2049 6e70 7574 206f 6273 6572 7661     Input observa
-00000250: 7469 6f6e 206c 6f63 6174 696f 6e73 0d0a  tion locations..
-00000260: 2020 2020 7920 3a20 6e70 2e6e 6461 7272      y : np.ndarr
-00000270: 6179 206f 6620 666c 6f61 7420 5b4d 2078  ay of float [M x
-00000280: 2064 696d 5d0d 0a20 2020 2020 2020 204f   dim]..        O
-00000290: 7574 7075 7420 6f62 7365 7276 6174 696f  utput observatio
-000002a0: 6e20 6c6f 6361 7469 6f6e 730d 0a20 2020  n locations..   
-000002b0: 206c 656e 6774 6873 6361 6c65 203a 2066   lengthscale : f
-000002c0: 6c6f 6174 0d0a 2020 2020 2020 2020 4c65  loat..        Le
-000002d0: 6e67 7468 7363 616c 6520 7061 7261 6d65  ngthscale parame
-000002e0: 7465 720d 0a20 2020 2076 6172 6961 6e63  ter..    varianc
-000002f0: 6520 3a20 666c 6f61 740d 0a20 2020 2020  e : float..     
-00000300: 2020 204f 7574 7075 7420 7661 7269 616e     Output varian
-00000310: 6365 0d0a 0d0a 2020 2020 5265 7475 726e  ce....    Return
-00000320: 730d 0a20 2020 202d 2d2d 2d2d 2d2d 0d0a  s..    -------..
-00000330: 2020 2020 6b20 3a20 6e70 2e6e 6461 7272      k : np.ndarr
-00000340: 6179 206f 6620 666c 6f61 7420 5b4d 2078  ay of float [M x
-00000350: 2058 5d0d 0a20 2020 2020 2020 204b 6572   X]..        Ker
-00000360: 6e65 6c20 6675 6e63 7469 6f6e 2076 616c  nel function val
-00000370: 7565 7320 2863 6f76 6172 6961 6e63 6520  ues (covariance 
-00000380: 6675 6e63 7469 6f6e 206f 7220 636f 7661  function or cova
-00000390: 7269 616e 6365 206d 6174 7269 7829 0d0a  riance matrix)..
-000003a0: 2020 2020 2222 220d 0a20 2020 2073 7164      """..    sqd
-000003b0: 6973 7420 3d20 6364 6973 7428 782c 2079  ist = cdist(x, y
-000003c0: 2c20 2773 7165 7563 6c69 6465 616e 2729  , 'sqeuclidean')
-000003d0: 0d0a 2020 2020 6b20 3d20 7661 7269 616e  ..    k = varian
-000003e0: 6365 202a 206e 702e 6578 7028 2d30 2e35  ce * np.exp(-0.5
-000003f0: 202a 2073 7164 6973 7420 2a20 2831 2f6c   * sqdist * (1/l
-00000400: 656e 6774 6873 6361 6c65 2a2a 3229 290d  engthscale**2)).
-00000410: 0a20 2020 2072 6574 7572 6e20 6b0d 0a0d  .    return k...
-00000420: 0a0d 0a64 6566 2069 735f 696e 7374 616e  ...def is_instan
-00000430: 6365 286f 626a 293a 0d0a 2020 2020 2222  ce(obj):..    ""
-00000440: 220d 0a20 2020 2054 6573 7473 2069 6620  "..    Tests if 
-00000450: 6f62 6a20 6973 2061 2063 6c61 7373 2069  obj is a class i
-00000460: 6e73 7461 6e63 6520 6f66 2061 6e79 2074  nstance of any t
-00000470: 7970 652e 0d0a 0d0a 2020 2020 5061 7261  ype.....    Para
-00000480: 6d65 7465 7273 0d0a 2020 2020 2d2d 2d2d  meters..    ----
-00000490: 2d2d 2d2d 2d2d 0d0a 2020 2020 6f62 6a20  ------..    obj 
-000004a0: 3a20 616e 790d 0a20 2020 2020 2020 2049  : any..        I
-000004b0: 6e70 7574 206f 626a 6563 740d 0a0d 0a20  nput object.... 
-000004c0: 2020 2052 6574 7572 6e73 0d0a 2020 2020     Returns..    
-000004d0: 2d2d 2d2d 2d2d 2d0d 0a20 2020 206f 7574  -------..    out
-000004e0: 203a 2062 6f6f 6c0d 0a20 2020 2020 2020   : bool..       
-000004f0: 2046 6c61 6720 6966 206f 626a 2069 7320   Flag if obj is 
-00000500: 636c 6173 7320 696e 7374 616e 6365 206f  class instance o
-00000510: 7220 6e6f 740d 0a20 2020 2022 2222 0d0a  r not..    """..
-00000520: 2020 2020 7472 793a 0d0a 2020 2020 2020      try:..      
-00000530: 2020 5f20 3d20 6f62 6a2e 5f5f 6469 6374    _ = obj.__dict
-00000540: 5f5f 0d0a 2020 2020 2020 2020 7265 7475  __..        retu
-00000550: 726e 2054 7275 650d 0a0d 0a20 2020 2065  rn True....    e
-00000560: 7863 6570 7420 4174 7472 6962 7574 6545  xcept AttributeE
-00000570: 7272 6f72 3a0d 0a20 2020 2020 2020 2072  rror:..        r
-00000580: 6574 7572 6e20 4661 6c73 650d 0a0d 0a0d  eturn False.....
-00000590: 0a64 6566 2064 6973 706c 6179 5f66 616e  .def display_fan
-000005a0: 6379 5f62 6172 2874 6578 742c 2069 2c20  cy_bar(text, i, 
-000005b0: 6e5f 692c 206d 6f72 655f 7465 7874 3d4e  n_i, more_text=N
-000005c0: 6f6e 6529 3a0d 0a20 2020 2022 2222 0d0a  one):..    """..
-000005d0: 2020 2020 4469 7370 6c61 7920 6120 7369      Display a si
-000005e0: 6d70 6c65 2070 726f 6772 6573 7320 6261  mple progress ba
-000005f0: 722e 2043 616c 6c20 696e 2065 6163 6820  r. Call in each 
-00000600: 6974 6572 6174 696f 6e20 616e 6420 7374  iteration and st
-00000610: 6172 7420 7769 7468 2069 3d31 2e0d 0a0d  art with i=1....
-00000620: 0a20 2020 2050 6172 616d 6574 6572 730d  .    Parameters.
-00000630: 0a20 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0d  .    ----------.
-00000640: 0a20 2020 2074 6578 743a 2073 7472 0d0a  .    text: str..
-00000650: 2020 2020 2020 2054 6578 7420 746f 2064         Text to d
-00000660: 6973 706c 6179 2069 6e20 6672 6f6e 7420  isplay in front 
-00000670: 6f66 2061 6374 7561 6c20 6974 6572 6174  of actual iterat
-00000680: 696f 6e0d 0a20 2020 2069 3a20 7374 7220  ion..    i: str 
-00000690: 6f72 2069 6e74 0d0a 2020 2020 2020 2041  or int..       A
-000006a0: 6374 7561 6c20 6974 6572 6174 696f 6e0d  ctual iteration.
-000006b0: 0a20 2020 206e 5f69 3a20 696e 740d 0a20  .    n_i: int.. 
-000006c0: 2020 2020 2020 546f 7461 6c20 6e75 6d62        Total numb
-000006d0: 6572 206f 6620 6974 6572 6174 696f 6e73  er of iterations
-000006e0: 0d0a 2020 2020 6d6f 7265 5f74 6578 743a  ..    more_text:
-000006f0: 2073 7472 2c20 6f70 7469 6f6e 616c 2c20   str, optional, 
-00000700: 6465 6661 756c 743d 4e6f 6e65 0d0a 2020  default=None..  
-00000710: 2020 2020 2054 6578 7420 7468 6174 2069       Text that i
-00000720: 7320 6469 7370 6c61 7965 6420 6f6e 2061  s displayed on a
-00000730: 6e20 6578 7472 6120 6c69 6e65 2061 626f  n extra line abo
-00000740: 7665 2074 6865 2062 6172 2e0d 0a0d 0a20  ve the bar..... 
-00000750: 2020 2045 7861 6d70 6c65 730d 0a20 2020     Examples..   
-00000760: 202d 2d2d 2d2d 2d2d 2d0d 0a20 2020 2066   --------..    f
-00000770: 616e 6379 5f62 6172 2827 5275 6e27 2c37  ancy_bar('Run',7
-00000780: 2c31 3029 3a0d 0a20 2020 2052 756e 2030  ,10):..    Run 0
-00000790: 3720 6672 6f6d 2031 3020 5b3d 3d3d 3d3d  7 from 10 [=====
-000007a0: 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d  ================
-000007b0: 3d3d 3d3d 3d3d 3d3d 3d3d 3d20 2020 2020  ===========     
-000007c0: 2020 205d 2037 3025 0d0a 0d0a 2020 2020     ] 70%....    
-000007d0: 6661 6e63 795f 6261 7228 5275 6e2c 392c  fancy_bar(Run,9,
-000007e0: 3130 2c27 536f 6d65 206d 6f72 6520 7465  10,'Some more te
-000007f0: 7874 2729 3a0d 0a20 2020 2053 6f6d 6520  xt'):..    Some 
-00000800: 6d6f 7265 2074 6578 740d 0a20 2020 2052  more text..    R
-00000810: 756e 2030 3920 6672 6f6d 2031 3020 5b3d  un 09 from 10 [=
+00000000: 0a69 6d70 6f72 7420 7379 730a 696d 706f  .import sys.impo
+00000010: 7274 206d 6174 680a 696d 706f 7274 2063  rt math.import c
+00000020: 6f70 790a 696d 706f 7274 2072 616e 646f  opy.import rando
+00000030: 6d0a 696d 706f 7274 2077 6172 6e69 6e67  m.import warning
+00000040: 730a 696d 706f 7274 2069 7465 7274 6f6f  s.import itertoo
+00000050: 6c73 0a69 6d70 6f72 7420 6e75 6d70 7920  ls.import numpy 
+00000060: 6173 206e 700a 696d 706f 7274 2073 6369  as np.import sci
+00000070: 7079 2e73 7461 7473 0a69 6d70 6f72 7420  py.stats.import 
+00000080: 7363 6970 792e 7370 6563 6961 6c0a 696d  scipy.special.im
+00000090: 706f 7274 2073 6369 7079 2e73 7061 7469  port scipy.spati
+000000a0: 616c 0a0a 7472 793a 0a20 2020 2069 6d70  al..try:.    imp
+000000b0: 6f72 7420 6d61 7470 6c6f 746c 6962 2e70  ort matplotlib.p
+000000c0: 7970 6c6f 7420 6173 2070 6c74 0a65 7863  yplot as plt.exc
+000000d0: 6570 7420 496d 706f 7274 4572 726f 723a  ept ImportError:
+000000e0: 0a20 2020 2070 6173 730a 0a66 726f 6d20  .    pass..from 
+000000f0: 7363 6970 792e 7370 6174 6961 6c2e 6469  scipy.spatial.di
+00000100: 7374 616e 6365 2069 6d70 6f72 7420 6364  stance import cd
+00000110: 6973 740a 6672 6f6d 202e 5669 7375 616c  ist.from .Visual
+00000120: 697a 6174 696f 6e20 696d 706f 7274 2070  ization import p
+00000130: 6c6f 745f 6265 7461 5f70 6466 5f66 6974  lot_beta_pdf_fit
+00000140: 0a0a 7472 793a 0a20 2020 2066 726f 6d20  ..try:.    from 
+00000150: 6d70 6c5f 746f 6f6c 6b69 7473 2e6d 706c  mpl_toolkits.mpl
+00000160: 6f74 3364 2e61 7274 3364 2069 6d70 6f72  ot3d.art3d impor
+00000170: 7420 506f 6c79 3344 436f 6c6c 6563 7469  t Poly3DCollecti
+00000180: 6f6e 0a65 7863 6570 743a 0a20 2020 2070  on.except:.    p
+00000190: 6173 730a 0a0a 6465 6620 7371 7561 7265  ass...def square
+000001a0: 645f 6578 706f 6e65 6e74 6961 6c5f 6b65  d_exponential_ke
+000001b0: 726e 656c 2878 2c20 792c 206c 656e 6774  rnel(x, y, lengt
+000001c0: 6873 6361 6c65 2c20 7661 7269 616e 6365  hscale, variance
+000001d0: 293a 0a20 2020 2022 2222 0a20 2020 2043  ):.    """.    C
+000001e0: 6f6d 7075 7465 7320 7468 6520 7371 7561  omputes the squa
+000001f0: 7265 6420 6578 706f 6e65 6e74 6961 6c20  red exponential 
+00000200: 6b65 726e 656c 2066 6f72 2047 6175 7373  kernel for Gauss
+00000210: 6961 6e20 5072 6f63 6573 7365 732e 0a0a  ian Processes...
+00000220: 2020 2020 5061 7261 6d65 7465 7273 0a20      Parameters. 
+00000230: 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020     ----------.  
+00000240: 2020 7820 3a20 6e70 2e6e 6461 7272 6179    x : np.ndarray
+00000250: 206f 6620 666c 6f61 7420 5b4e 2078 2064   of float [N x d
+00000260: 696d 5d0a 2020 2020 2020 2020 496e 7075  im].        Inpu
+00000270: 7420 6f62 7365 7276 6174 696f 6e20 6c6f  t observation lo
+00000280: 6361 7469 6f6e 730a 2020 2020 7920 3a20  cations.    y : 
+00000290: 6e70 2e6e 6461 7272 6179 206f 6620 666c  np.ndarray of fl
+000002a0: 6f61 7420 5b4d 2078 2064 696d 5d0a 2020  oat [M x dim].  
+000002b0: 2020 2020 2020 4f75 7470 7574 206f 6273        Output obs
+000002c0: 6572 7661 7469 6f6e 206c 6f63 6174 696f  ervation locatio
+000002d0: 6e73 0a20 2020 206c 656e 6774 6873 6361  ns.    lengthsca
+000002e0: 6c65 203a 2066 6c6f 6174 0a20 2020 2020  le : float.     
+000002f0: 2020 204c 656e 6774 6873 6361 6c65 2070     Lengthscale p
+00000300: 6172 616d 6574 6572 0a20 2020 2076 6172  arameter.    var
+00000310: 6961 6e63 6520 3a20 666c 6f61 740a 2020  iance : float.  
+00000320: 2020 2020 2020 4f75 7470 7574 2076 6172        Output var
+00000330: 6961 6e63 650a 0a20 2020 2052 6574 7572  iance..    Retur
+00000340: 6e73 0a20 2020 202d 2d2d 2d2d 2d2d 0a20  ns.    -------. 
+00000350: 2020 206b 203a 206e 702e 6e64 6172 7261     k : np.ndarra
+00000360: 7920 6f66 2066 6c6f 6174 205b 4d20 7820  y of float [M x 
+00000370: 585d 0a20 2020 2020 2020 204b 6572 6e65  X].        Kerne
+00000380: 6c20 6675 6e63 7469 6f6e 2076 616c 7565  l function value
+00000390: 7320 2863 6f76 6172 6961 6e63 6520 6675  s (covariance fu
+000003a0: 6e63 7469 6f6e 206f 7220 636f 7661 7269  nction or covari
+000003b0: 616e 6365 206d 6174 7269 7829 0a20 2020  ance matrix).   
+000003c0: 2022 2222 0a20 2020 2073 7164 6973 7420   """.    sqdist 
+000003d0: 3d20 6364 6973 7428 782c 2079 2c20 2773  = cdist(x, y, 's
+000003e0: 7165 7563 6c69 6465 616e 2729 0a20 2020  qeuclidean').   
+000003f0: 206b 203d 2076 6172 6961 6e63 6520 2a20   k = variance * 
+00000400: 6e70 2e65 7870 282d 302e 3520 2a20 7371  np.exp(-0.5 * sq
+00000410: 6469 7374 202a 2028 312f 6c65 6e67 7468  dist * (1/length
+00000420: 7363 616c 652a 2a32 2929 0a20 2020 2072  scale**2)).    r
+00000430: 6574 7572 6e20 6b0a 0a0a 6465 6620 6973  eturn k...def is
+00000440: 5f69 6e73 7461 6e63 6528 6f62 6a29 3a0a  _instance(obj):.
+00000450: 2020 2020 2222 220a 2020 2020 5465 7374      """.    Test
+00000460: 7320 6966 206f 626a 2069 7320 6120 636c  s if obj is a cl
+00000470: 6173 7320 696e 7374 616e 6365 206f 6620  ass instance of 
+00000480: 616e 7920 7479 7065 2e0a 0a20 2020 2050  any type...    P
+00000490: 6172 616d 6574 6572 730a 2020 2020 2d2d  arameters.    --
+000004a0: 2d2d 2d2d 2d2d 2d2d 0a20 2020 206f 626a  --------.    obj
+000004b0: 203a 2061 6e79 0a20 2020 2020 2020 2049   : any.        I
+000004c0: 6e70 7574 206f 626a 6563 740a 0a20 2020  nput object..   
+000004d0: 2052 6574 7572 6e73 0a20 2020 202d 2d2d   Returns.    ---
+000004e0: 2d2d 2d2d 0a20 2020 206f 7574 203a 2062  ----.    out : b
+000004f0: 6f6f 6c0a 2020 2020 2020 2020 466c 6167  ool.        Flag
+00000500: 2069 6620 6f62 6a20 6973 2063 6c61 7373   if obj is class
+00000510: 2069 6e73 7461 6e63 6520 6f72 206e 6f74   instance or not
+00000520: 0a20 2020 2022 2222 0a20 2020 2074 7279  .    """.    try
+00000530: 3a0a 2020 2020 2020 2020 5f20 3d20 6f62  :.        _ = ob
+00000540: 6a2e 5f5f 6469 6374 5f5f 0a20 2020 2020  j.__dict__.     
+00000550: 2020 2072 6574 7572 6e20 5472 7565 0a0a     return True..
+00000560: 2020 2020 6578 6365 7074 2041 7474 7269      except Attri
+00000570: 6275 7465 4572 726f 723a 0a20 2020 2020  buteError:.     
+00000580: 2020 2072 6574 7572 6e20 4661 6c73 650a     return False.
+00000590: 0a0a 6465 6620 6469 7370 6c61 795f 6661  ..def display_fa
+000005a0: 6e63 795f 6261 7228 7465 7874 2c20 692c  ncy_bar(text, i,
+000005b0: 206e 5f69 2c20 6d6f 7265 5f74 6578 743d   n_i, more_text=
+000005c0: 4e6f 6e65 293a 0a20 2020 2022 2222 0a20  None):.    """. 
+000005d0: 2020 2044 6973 706c 6179 2061 2073 696d     Display a sim
+000005e0: 706c 6520 7072 6f67 7265 7373 2062 6172  ple progress bar
+000005f0: 2e20 4361 6c6c 2069 6e20 6561 6368 2069  . Call in each i
+00000600: 7465 7261 7469 6f6e 2061 6e64 2073 7461  teration and sta
+00000610: 7274 2077 6974 6820 693d 312e 0a0a 2020  rt with i=1...  
+00000620: 2020 5061 7261 6d65 7465 7273 0a20 2020    Parameters.   
+00000630: 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020 2020   ----------.    
+00000640: 7465 7874 3a20 7374 720a 2020 2020 2020  text: str.      
+00000650: 2054 6578 7420 746f 2064 6973 706c 6179   Text to display
+00000660: 2069 6e20 6672 6f6e 7420 6f66 2061 6374   in front of act
+00000670: 7561 6c20 6974 6572 6174 696f 6e0a 2020  ual iteration.  
+00000680: 2020 693a 2073 7472 206f 7220 696e 740a    i: str or int.
+00000690: 2020 2020 2020 2041 6374 7561 6c20 6974         Actual it
+000006a0: 6572 6174 696f 6e0a 2020 2020 6e5f 693a  eration.    n_i:
+000006b0: 2069 6e74 0a20 2020 2020 2020 546f 7461   int.       Tota
+000006c0: 6c20 6e75 6d62 6572 206f 6620 6974 6572  l number of iter
+000006d0: 6174 696f 6e73 0a20 2020 206d 6f72 655f  ations.    more_
+000006e0: 7465 7874 3a20 7374 722c 206f 7074 696f  text: str, optio
+000006f0: 6e61 6c2c 2064 6566 6175 6c74 3d4e 6f6e  nal, default=Non
+00000700: 650a 2020 2020 2020 2054 6578 7420 7468  e.       Text th
+00000710: 6174 2069 7320 6469 7370 6c61 7965 6420  at is displayed 
+00000720: 6f6e 2061 6e20 6578 7472 6120 6c69 6e65  on an extra line
+00000730: 2061 626f 7665 2074 6865 2062 6172 2e0a   above the bar..
+00000740: 0a20 2020 2045 7861 6d70 6c65 730a 2020  .    Examples.  
+00000750: 2020 2d2d 2d2d 2d2d 2d2d 0a20 2020 2066    --------.    f
+00000760: 616e 6379 5f62 6172 2827 5275 6e27 2c37  ancy_bar('Run',7
+00000770: 2c31 3029 3a0a 2020 2020 5275 6e20 3037  ,10):.    Run 07
+00000780: 2066 726f 6d20 3130 205b 3d3d 3d3d 3d3d   from 10 [======
+00000790: 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d  ================
+000007a0: 3d3d 3d3d 3d3d 3d3d 3d3d 2020 2020 2020  ==========      
+000007b0: 2020 5d20 3730 250a 0a20 2020 2066 616e    ] 70%..    fan
+000007c0: 6379 5f62 6172 2852 756e 2c39 2c31 302c  cy_bar(Run,9,10,
+000007d0: 2753 6f6d 6520 6d6f 7265 2074 6578 7427  'Some more text'
+000007e0: 293a 0a20 2020 2053 6f6d 6520 6d6f 7265  ):.    Some more
+000007f0: 2074 6578 740a 2020 2020 5275 6e20 3039   text.    Run 09
+00000800: 2066 726f 6d20 3130 205b 3d3d 3d3d 3d3d   from 10 [======
+00000810: 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d  ================
 00000820: 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d  ================
-00000830: 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d  ================
-00000840: 3d3d 3d3d 3d3d 205d 2039 3025 0d0a 2020  ====== ] 90%..  
-00000850: 2020 2222 220d 0a0d 0a20 2020 2069 6620    """....    if 
-00000860: 6e6f 7420 6973 696e 7374 616e 6365 2869  not isinstance(i
-00000870: 2c20 7374 7229 3a0d 0a20 2020 2020 2020  , str):..       
-00000880: 2069 203d 2073 7472 2869 290d 0a0d 0a20   i = str(i).... 
-00000890: 2020 2061 7373 6572 7420 6973 696e 7374     assert isinst
-000008a0: 616e 6365 2874 6578 742c 2073 7472 290d  ance(text, str).
-000008b0: 0a20 2020 2061 7373 6572 7420 6973 696e  .    assert isin
-000008c0: 7374 616e 6365 286e 5f69 2c20 696e 7429  stance(n_i, int)
-000008d0: 0d0a 0d0a 2020 2020 6966 206e 6f74 2074  ....    if not t
-000008e0: 6578 742e 656e 6473 7769 7468 2827 2027  ext.endswith(' '
-000008f0: 293a 0d0a 2020 2020 2020 2020 7465 7874  ):..        text
-00000900: 202b 3d20 2720 270d 0a0d 0a20 2020 2023   += ' '....    #
-00000910: 2069 6620 6920 3d3d 2027 3127 3a0d 0a20   if i == '1':.. 
-00000920: 2020 2020 2020 2023 2073 7973 2e73 7464         # sys.std
-00000930: 6f75 742e 7772 6974 6528 2727 290d 0a0d  out.write('')...
-00000940: 0a20 2020 2073 7973 2e73 7464 6f75 742e  .    sys.stdout.
-00000950: 7772 6974 6528 275c 7227 290d 0a20 2020  write('\r')..   
-00000960: 2066 696c 6c5f 7769 6474 6820 3d20 6c65   fill_width = le
-00000970: 6e28 7374 7228 6e5f 6929 290d 0a0d 0a20  n(str(n_i)).... 
-00000980: 2020 2023 2074 6572 6d69 6e61 6c20 636f     # terminal co
-00000990: 6465 732c 2077 6f72 6b69 6e67 206f 6e20  des, working on 
-000009a0: 7769 6e64 6f77 7320 6173 2077 656c 6c3f  windows as well?
-000009b0: 0d0a 2020 2020 6375 7273 6f72 5f74 776f  ..    cursor_two
-000009c0: 5f75 7020 3d20 275c 7831 625b 3241 270d  _up = '\x1b[2A'.
-000009d0: 0a20 2020 2065 7261 7365 5f6c 696e 6520  .    erase_line 
-000009e0: 3d20 275c 7831 625b 324b 270d 0a0d 0a20  = '\x1b[2K'.... 
-000009f0: 2020 2069 6620 6d6f 7265 5f74 6578 743a     if more_text:
-00000a00: 0d0a 2020 2020 2020 2020 7072 696e 7428  ..        print(
-00000a10: 6375 7273 6f72 5f74 776f 5f75 7020 2b20  cursor_two_up + 
-00000a20: 6572 6173 655f 6c69 6e65 290d 0a20 2020  erase_line)..   
-00000a30: 2020 2020 2070 7269 6e74 286d 6f72 655f       print(more_
-00000a40: 7465 7874 290d 0a20 2020 2073 7973 2e73  text)..    sys.s
-00000a50: 7464 6f75 742e 7772 6974 6528 7465 7874  tdout.write(text
-00000a60: 202b 2069 2e7a 6669 6c6c 2866 696c 6c5f   + i.zfill(fill_
-00000a70: 7769 6474 6829 202b 2022 2066 726f 6d20  width) + " from 
-00000a80: 2220 2b20 7374 7228 6e5f 6929 290d 0a20  " + str(n_i)).. 
-00000a90: 2020 2023 2074 6869 7320 7072 696e 7473     # this prints
-00000aa0: 205b 3530 2d73 7061 6365 735d 2c20 6925   [50-spaces], i%
-00000ab0: 202a 203d 0d0a 2020 2020 2320 7379 732e   * =..    # sys.
-00000ac0: 7374 646f 7574 2e77 7269 7465 2822 205b  stdout.write(" [
-00000ad0: 252d 3430 735d 2025 6425 2522 2025 2028  %-40s] %d%%" % (
-00000ae0: 0d0a 2020 2020 2320 2020 2020 273d 2720  ..    #     '=' 
-00000af0: 2a20 696e 7428 2866 6c6f 6174 2869 2920  * int((float(i) 
-00000b00: 2b20 3029 202f 206e 5f69 202a 2031 3030  + 0) / n_i * 100
-00000b10: 202f 2032 2e35 292c 2066 6c6f 6174 2869   / 2.5), float(i
-00000b20: 2920 2f20 6e5f 6920 2a20 3130 302e 2929  ) / n_i * 100.))
-00000b30: 0d0a 2020 2020 7379 732e 7374 646f 7574  ..    sys.stdout
-00000b40: 2e77 7269 7465 2822 205b 7b7d 7b7d 5d20  .write(" [{}{}] 
-00000b50: 7b3a 2e31 667d 2522 2e66 6f72 6d61 7428  {:.1f}%".format(
-00000b60: 273d 2720 2a20 696e 7428 696e 7428 6929  '=' * int(int(i)
-00000b70: 202f 206e 5f69 202a 2034 3029 2c0d 0a20   / n_i * 40),.. 
-00000b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000ba0: 2020 2020 2020 2020 2020 2020 2022 2022               " "
-00000bb0: 202a 2028 3430 202d 2069 6e74 2869 6e74   * (40 - int(int
-00000bc0: 2869 2920 2f20 6e5f 6920 2a20 3430 2929  (i) / n_i * 40))
-00000bd0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-00000be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000bf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000c00: 2066 6c6f 6174 2869 6e74 2869 2920 2f20   float(int(i) / 
-00000c10: 6e5f 6920 2a20 3130 3029 2929 0d0a 2020  n_i * 100)))..  
-00000c20: 2020 7379 732e 7374 646f 7574 2e66 6c75    sys.stdout.flu
-00000c30: 7368 2829 0d0a 2020 2020 2320 6966 2069  sh()..    # if i
-00000c40: 6e74 2869 2920 3d3d 206e 5f69 3a0d 0a20  nt(i) == n_i:.. 
-00000c50: 2020 2023 2020 2020 2070 7269 6e74 2822     #     print("
-00000c60: 2229 0d0a 2020 2020 7072 696e 7428 2222  ")..    print(""
-00000c70: 290d 0a0d 0a0d 0a64 6566 2067 6574 5f63  )......def get_c
-00000c80: 6172 7465 7369 616e 5f70 726f 6475 6374  artesian_product
-00000c90: 2861 7272 6179 5f6c 6973 7429 3a0d 0a20  (array_list):.. 
-00000ca0: 2020 2022 2222 0d0a 2020 2020 4765 6e65     """..    Gene
-00000cb0: 7261 7465 2061 2063 6172 7465 7369 616e  rate a cartesian
-00000cc0: 2070 726f 6475 6374 206f 6620 696e 7075   product of inpu
-00000cd0: 7420 6172 7261 7973 2028 616c 6c20 636f  t arrays (all co
-00000ce0: 6d62 696e 6174 696f 6e73 292e 0d0a 0d0a  mbinations).....
-00000cf0: 2020 2020 6361 7274 6573 6961 6e5f 7072      cartesian_pr
-00000d00: 6f64 7563 7420 3d20 6765 745f 6361 7274  oduct = get_cart
-00000d10: 6573 6961 6e5f 7072 6f64 7563 7428 6172  esian_product(ar
-00000d20: 7261 795f 6c69 7374 290d 0a0d 0a20 2020  ray_list)....   
-00000d30: 2050 6172 616d 6574 6572 730d 0a20 2020   Parameters..   
-00000d40: 202d 2d2d 2d2d 2d2d 2d2d 2d0d 0a20 2020   ----------..   
-00000d50: 2061 7272 6179 5f6c 6973 7420 3a20 6c69   array_list : li
-00000d60: 7374 206f 6620 3144 206e 6461 7272 6179  st of 1D ndarray
-00000d70: 206f 6620 666c 6f61 740d 0a20 2020 2020   of float..     
-00000d80: 2020 2041 7272 6179 7320 746f 2063 6f6d     Arrays to com
-00000d90: 7075 7465 2074 6865 2063 6172 7465 7369  pute the cartesi
-00000da0: 616e 2070 726f 6475 6374 2077 6974 680d  an product with.
-00000db0: 0a0d 0a20 2020 2052 6574 7572 6e73 0d0a  ...    Returns..
-00000dc0: 2020 2020 2d2d 2d2d 2d2d 2d0d 0a20 2020      -------..   
-00000dd0: 2063 6172 7465 7369 616e 5f70 726f 6475   cartesian_produ
-00000de0: 6374 203a 206e 6461 7272 6179 206f 6620  ct : ndarray of 
-00000df0: 666c 6f61 740d 0a20 2020 2020 2020 2041  float..        A
-00000e00: 7272 6179 2063 6f6e 7461 696e 696e 6720  rray containing 
-00000e10: 7468 6520 6361 7274 6573 6961 6e20 7072  the cartesian pr
-00000e20: 6f64 7563 7473 2028 616c 6c20 636f 6d62  oducts (all comb
-00000e30: 696e 6174 696f 6e73 206f 6620 696e 7075  inations of inpu
-00000e40: 7420 7665 6374 6f72 7329 0d0a 2020 2020  t vectors)..    
-00000e50: 2020 2020 284d 2c20 6c65 6e28 6172 7261      (M, len(arra
-00000e60: 7973 2929 0d0a 0d0a 2020 2020 4578 616d  ys))....    Exam
-00000e70: 706c 6573 0d0a 2020 2020 2d2d 2d2d 2d2d  ples..    ------
-00000e80: 2d2d 0d0a 2020 2020 3e3e 3e20 696d 706f  --..    >>> impo
-00000e90: 7274 2070 7967 7063 0d0a 2020 2020 3e3e  rt pygpc..    >>
-00000ea0: 3e20 6f75 7420 3d20 7079 6770 632e 6765  > out = pygpc.ge
-00000eb0: 745f 6361 7274 6573 6961 6e5f 7072 6f64  t_cartesian_prod
-00000ec0: 7563 7428 285b 312c 2032 2c20 335d 2c20  uct(([1, 2, 3], 
-00000ed0: 5b34 2c20 355d 2c20 5b36 2c20 375d 2929  [4, 5], [6, 7]))
-00000ee0: 0d0a 2020 2020 3e3e 3e20 6f75 740d 0a20  ..    >>> out.. 
-00000ef0: 2020 2022 2222 0d0a 0d0a 2020 2020 6361     """....    ca
-00000f00: 7274 6573 6961 6e5f 7072 6f64 7563 7420  rtesian_product 
-00000f10: 3d20 5b65 6c65 6d65 6e74 2066 6f72 2065  = [element for e
-00000f20: 6c65 6d65 6e74 2069 6e20 6974 6572 746f  lement in iterto
-00000f30: 6f6c 732e 7072 6f64 7563 7428 2a61 7272  ols.product(*arr
-00000f40: 6179 5f6c 6973 7429 5d0d 0a20 2020 2072  ay_list)]..    r
-00000f50: 6574 7572 6e20 6e70 2e61 7272 6179 2863  eturn np.array(c
-00000f60: 6172 7465 7369 616e 5f70 726f 6475 6374  artesian_product
-00000f70: 290d 0a0d 0a0d 0a64 6566 2067 6574 5f72  )......def get_r
-00000f80: 6f74 6174 696f 6e5f 6d61 7472 6978 2874  otation_matrix(t
-00000f90: 6865 7461 293a 0d0a 2020 2020 2222 220d  heta):..    """.
-00000fa0: 0a20 2020 2047 656e 6572 6174 6520 726f  .    Generate ro
-00000fb0: 7461 7469 6f6e 206d 6174 7269 7820 6672  tation matrix fr
-00000fc0: 6f6d 2065 756c 6572 2061 6e67 6c65 732e  om euler angles.
-00000fd0: 0d0a 0d0a 2020 2020 726f 7461 7469 6f6e  ....    rotation
-00000fe0: 5f6d 6174 7269 7820 3d20 6765 745f 726f  _matrix = get_ro
-00000ff0: 7461 7469 6f6e 5f6d 6174 7269 7828 7468  tation_matrix(th
-00001000: 6574 6129 0d0a 0d0a 2020 2020 5061 7261  eta)....    Para
-00001010: 6d65 7465 7273 0d0a 2020 2020 2d2d 2d2d  meters..    ----
-00001020: 2d2d 2d2d 2d2d 0d0a 2020 2020 7468 6574  ------..    thet
-00001030: 6120 3a20 6c69 7374 206f 6620 666c 6f61  a : list of floa
-00001040: 7420 5b33 5d0d 0a20 2020 2020 2020 2045  t [3]..        E
-00001050: 756c 6572 2061 6e67 6c65 730d 0a0d 0a20  uler angles.... 
-00001060: 2020 2052 6574 7572 6e73 0d0a 2020 2020     Returns..    
-00001070: 2d2d 2d2d 2d2d 2d0d 0a20 2020 2072 6f74  -------..    rot
-00001080: 6174 696f 6e5f 6d61 7472 6978 203a 206e  ation_matrix : n
-00001090: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-000010a0: 5b33 2c20 335d 0d0a 2020 2020 2020 2020  [3, 3]..        
-000010b0: 526f 7461 7469 6f6e 206d 6174 7269 7820  Rotation matrix 
-000010c0: 636f 6d70 7574 6564 2066 726f 6d20 6575  computed from eu
-000010d0: 6c65 7220 616e 676c 6573 0d0a 2020 2020  ler angles..    
-000010e0: 2222 220d 0a0d 0a20 2020 2072 5f78 203d  """....    r_x =
-000010f0: 206e 702e 6172 7261 7928 5b5b 312c 2030   np.array([[1, 0
-00001100: 2c20 305d 2c0d 0a20 2020 2020 2020 2020  , 0],..         
-00001110: 2020 2020 2020 2020 2020 205b 302c 206d             [0, m
-00001120: 6174 682e 636f 7328 7468 6574 615b 305d  ath.cos(theta[0]
-00001130: 292c 202d 6d61 7468 2e73 696e 2874 6865  ), -math.sin(the
-00001140: 7461 5b30 5d29 5d2c 0d0a 2020 2020 2020  ta[0])],..      
-00001150: 2020 2020 2020 2020 2020 2020 2020 5b30                [0
-00001160: 2c20 6d61 7468 2e73 696e 2874 6865 7461  , math.sin(theta
-00001170: 5b30 5d29 2c20 6d61 7468 2e63 6f73 2874  [0]), math.cos(t
-00001180: 6865 7461 5b30 5d29 5d0d 0a20 2020 2020  heta[0])]..     
-00001190: 2020 2020 2020 2020 2020 2020 2020 205d                 ]
-000011a0: 290d 0a0d 0a20 2020 2072 5f79 203d 206e  )....    r_y = n
-000011b0: 702e 6172 7261 7928 5b5b 6d61 7468 2e63  p.array([[math.c
-000011c0: 6f73 2874 6865 7461 5b31 5d29 2c20 302c  os(theta[1]), 0,
-000011d0: 206d 6174 682e 7369 6e28 7468 6574 615b   math.sin(theta[
-000011e0: 315d 295d 2c0d 0a20 2020 2020 2020 2020  1])],..         
-000011f0: 2020 2020 2020 2020 2020 205b 302c 2031             [0, 1
-00001200: 2c20 305d 2c0d 0a20 2020 2020 2020 2020  , 0],..         
-00001210: 2020 2020 2020 2020 2020 205b 2d6d 6174             [-mat
-00001220: 682e 7369 6e28 7468 6574 615b 315d 292c  h.sin(theta[1]),
-00001230: 2030 2c20 6d61 7468 2e63 6f73 2874 6865   0, math.cos(the
-00001240: 7461 5b31 5d29 5d0d 0a20 2020 2020 2020  ta[1])]..       
-00001250: 2020 2020 2020 2020 2020 2020 205d 290d               ]).
-00001260: 0a0d 0a20 2020 2072 5f7a 203d 206e 702e  ...    r_z = np.
-00001270: 6172 7261 7928 5b5b 6d61 7468 2e63 6f73  array([[math.cos
-00001280: 2874 6865 7461 5b32 5d29 2c20 2d6d 6174  (theta[2]), -mat
-00001290: 682e 7369 6e28 7468 6574 615b 325d 292c  h.sin(theta[2]),
-000012a0: 2030 5d2c 0d0a 2020 2020 2020 2020 2020   0],..          
-000012b0: 2020 2020 2020 2020 2020 5b6d 6174 682e            [math.
-000012c0: 7369 6e28 7468 6574 615b 325d 292c 206d  sin(theta[2]), m
-000012d0: 6174 682e 636f 7328 7468 6574 615b 325d  ath.cos(theta[2]
-000012e0: 292c 2030 5d2c 0d0a 2020 2020 2020 2020  ), 0],..        
-000012f0: 2020 2020 2020 2020 2020 2020 5b30 2c20              [0, 
-00001300: 302c 2031 5d0d 0a20 2020 2020 2020 2020  0, 1]..         
-00001310: 2020 2020 2020 2020 2020 205d 290d 0a0d             ])...
-00001320: 0a20 2020 2072 6f74 6174 696f 6e5f 6d61  .    rotation_ma
-00001330: 7472 6978 203d 206e 702e 646f 7428 725f  trix = np.dot(r_
-00001340: 7a2c 206e 702e 646f 7428 725f 792c 2072  z, np.dot(r_y, r
-00001350: 5f78 2929 0d0a 0d0a 2020 2020 7265 7475  _x))....    retu
-00001360: 726e 2072 6f74 6174 696f 6e5f 6d61 7472  rn rotation_matr
-00001370: 6978 0d0a 0d0a 0d0a 6465 6620 6765 745f  ix......def get_
-00001380: 6469 6666 6572 656e 745f 726f 7773 5f66  different_rows_f
-00001390: 726f 6d5f 6d61 7472 6963 6573 2861 2c20  rom_matrices(a, 
-000013a0: 6229 3a0d 0a20 2020 2022 2222 0d0a 2020  b):..    """..  
-000013b0: 2020 436f 6d70 6172 6573 2072 6f77 7320    Compares rows 
-000013c0: 6672 6f6d 206d 6174 7269 7820 6120 7769  from matrix a wi
-000013d0: 7468 2072 6f77 7320 6672 6f6d 206d 6174  th rows from mat
-000013e0: 7269 7820 622e 2049 7420 6973 2061 7373  rix b. It is ass
-000013f0: 756d 6564 2074 6861 7420 6220 636f 6e74  umed that b cont
-00001400: 6169 6e73 2072 6f77 7320 6672 6f6d 2061  ains rows from a
-00001410: 2e0d 0a20 2020 2054 6865 2066 756e 6374  ...    The funct
-00001420: 696f 6e20 7265 7475 726e 7320 7468 6520  ion returns the 
-00001430: 726f 7773 206f 6620 622c 2077 6869 6368  rows of b, which
-00001440: 2061 7265 206e 6f74 2069 6e63 6c75 6465   are not include
-00001450: 6420 696e 2061 2e0d 0a0d 0a20 2020 2050  d in a.....    P
-00001460: 6172 616d 6574 6572 730d 0a20 2020 202d  arameters..    -
-00001470: 2d2d 2d2d 2d2d 2d2d 2d0d 0a20 2020 2061  ---------..    a
-00001480: 203a 206e 6461 7272 6179 206f 6620 666c   : ndarray of fl
-00001490: 6f61 7420 5b6d 3120 7820 6e5d 0d0a 2020  oat [m1 x n]..  
-000014a0: 2020 2020 2020 4669 7273 7420 6d61 7472        First matr
-000014b0: 6978 2028 7573 7561 6c6c 7920 7468 6520  ix (usually the 
-000014c0: 736d 616c 6c65 7220 6f6e 6529 2c20 7768  smaller one), wh
-000014d0: 6572 6520 726f 7773 2061 7265 2070 6172  ere rows are par
-000014e0: 7420 6f66 2062 0d0a 2020 2020 6220 3a20  t of b..    b : 
+00000830: 3d20 5d20 3930 250a 2020 2020 2222 220a  = ] 90%.    """.
+00000840: 0a20 2020 2069 6620 6e6f 7420 6973 696e  .    if not isin
+00000850: 7374 616e 6365 2869 2c20 7374 7229 3a0a  stance(i, str):.
+00000860: 2020 2020 2020 2020 6920 3d20 7374 7228          i = str(
+00000870: 6929 0a0a 2020 2020 6173 7365 7274 2069  i)..    assert i
+00000880: 7369 6e73 7461 6e63 6528 7465 7874 2c20  sinstance(text, 
+00000890: 7374 7229 0a20 2020 2061 7373 6572 7420  str).    assert 
+000008a0: 6973 696e 7374 616e 6365 286e 5f69 2c20  isinstance(n_i, 
+000008b0: 696e 7429 0a0a 2020 2020 6966 206e 6f74  int)..    if not
+000008c0: 2074 6578 742e 656e 6473 7769 7468 2827   text.endswith('
+000008d0: 2027 293a 0a20 2020 2020 2020 2074 6578   '):.        tex
+000008e0: 7420 2b3d 2027 2027 0a0a 2020 2020 2320  t += ' '..    # 
+000008f0: 6966 2069 203d 3d20 2731 273a 0a20 2020  if i == '1':.   
+00000900: 2020 2020 2023 2073 7973 2e73 7464 6f75       # sys.stdou
+00000910: 742e 7772 6974 6528 2727 290a 0a20 2020  t.write('')..   
+00000920: 2073 7973 2e73 7464 6f75 742e 7772 6974   sys.stdout.writ
+00000930: 6528 275c 7227 290a 2020 2020 6669 6c6c  e('\r').    fill
+00000940: 5f77 6964 7468 203d 206c 656e 2873 7472  _width = len(str
+00000950: 286e 5f69 2929 0a0a 2020 2020 2320 7465  (n_i))..    # te
+00000960: 726d 696e 616c 2063 6f64 6573 2c20 776f  rminal codes, wo
+00000970: 726b 696e 6720 6f6e 2077 696e 646f 7773  rking on windows
+00000980: 2061 7320 7765 6c6c 3f0a 2020 2020 6375   as well?.    cu
+00000990: 7273 6f72 5f74 776f 5f75 7020 3d20 275c  rsor_two_up = '\
+000009a0: 7831 625b 3241 270a 2020 2020 6572 6173  x1b[2A'.    eras
+000009b0: 655f 6c69 6e65 203d 2027 5c78 3162 5b32  e_line = '\x1b[2
+000009c0: 4b27 0a0a 2020 2020 6966 206d 6f72 655f  K'..    if more_
+000009d0: 7465 7874 3a0a 2020 2020 2020 2020 7072  text:.        pr
+000009e0: 696e 7428 6375 7273 6f72 5f74 776f 5f75  int(cursor_two_u
+000009f0: 7020 2b20 6572 6173 655f 6c69 6e65 290a  p + erase_line).
+00000a00: 2020 2020 2020 2020 7072 696e 7428 6d6f          print(mo
+00000a10: 7265 5f74 6578 7429 0a20 2020 2073 7973  re_text).    sys
+00000a20: 2e73 7464 6f75 742e 7772 6974 6528 7465  .stdout.write(te
+00000a30: 7874 202b 2069 2e7a 6669 6c6c 2866 696c  xt + i.zfill(fil
+00000a40: 6c5f 7769 6474 6829 202b 2022 2066 726f  l_width) + " fro
+00000a50: 6d20 2220 2b20 7374 7228 6e5f 6929 290a  m " + str(n_i)).
+00000a60: 2020 2020 2320 7468 6973 2070 7269 6e74      # this print
+00000a70: 7320 5b35 302d 7370 6163 6573 5d2c 2069  s [50-spaces], i
+00000a80: 2520 2a20 3d0a 2020 2020 2320 7379 732e  % * =.    # sys.
+00000a90: 7374 646f 7574 2e77 7269 7465 2822 205b  stdout.write(" [
+00000aa0: 252d 3430 735d 2025 6425 2522 2025 2028  %-40s] %d%%" % (
+00000ab0: 0a20 2020 2023 2020 2020 2027 3d27 202a  .    #     '=' *
+00000ac0: 2069 6e74 2828 666c 6f61 7428 6929 202b   int((float(i) +
+00000ad0: 2030 2920 2f20 6e5f 6920 2a20 3130 3020   0) / n_i * 100 
+00000ae0: 2f20 322e 3529 2c20 666c 6f61 7428 6929  / 2.5), float(i)
+00000af0: 202f 206e 5f69 202a 2031 3030 2e29 290a   / n_i * 100.)).
+00000b00: 2020 2020 7379 732e 7374 646f 7574 2e77      sys.stdout.w
+00000b10: 7269 7465 2822 205b 7b7d 7b7d 5d20 7b3a  rite(" [{}{}] {:
+00000b20: 2e31 667d 2522 2e66 6f72 6d61 7428 273d  .1f}%".format('=
+00000b30: 2720 2a20 696e 7428 696e 7428 6929 202f  ' * int(int(i) /
+00000b40: 206e 5f69 202a 2034 3029 2c0a 2020 2020   n_i * 40),.    
+00000b50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000b70: 2020 2020 2020 2020 2020 2220 2220 2a20            " " * 
+00000b80: 2834 3020 2d20 696e 7428 696e 7428 6929  (40 - int(int(i)
+00000b90: 202f 206e 5f69 202a 2034 3029 292c 0a20   / n_i * 40)),. 
+00000ba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000bc0: 2020 2020 2020 2020 2020 2020 2066 6c6f               flo
+00000bd0: 6174 2869 6e74 2869 2920 2f20 6e5f 6920  at(int(i) / n_i 
+00000be0: 2a20 3130 3029 2929 0a20 2020 2073 7973  * 100))).    sys
+00000bf0: 2e73 7464 6f75 742e 666c 7573 6828 290a  .stdout.flush().
+00000c00: 2020 2020 2320 6966 2069 6e74 2869 2920      # if int(i) 
+00000c10: 3d3d 206e 5f69 3a0a 2020 2020 2320 2020  == n_i:.    #   
+00000c20: 2020 7072 696e 7428 2222 290a 2020 2020    print("").    
+00000c30: 7072 696e 7428 2222 290a 0a0a 6465 6620  print("")...def 
+00000c40: 6765 745f 6361 7274 6573 6961 6e5f 7072  get_cartesian_pr
+00000c50: 6f64 7563 7428 6172 7261 795f 6c69 7374  oduct(array_list
+00000c60: 293a 0a20 2020 2022 2222 0a20 2020 2047  ):.    """.    G
+00000c70: 656e 6572 6174 6520 6120 6361 7274 6573  enerate a cartes
+00000c80: 6961 6e20 7072 6f64 7563 7420 6f66 2069  ian product of i
+00000c90: 6e70 7574 2061 7272 6179 7320 2861 6c6c  nput arrays (all
+00000ca0: 2063 6f6d 6269 6e61 7469 6f6e 7329 2e0a   combinations)..
+00000cb0: 0a20 2020 2063 6172 7465 7369 616e 5f70  .    cartesian_p
+00000cc0: 726f 6475 6374 203d 2067 6574 5f63 6172  roduct = get_car
+00000cd0: 7465 7369 616e 5f70 726f 6475 6374 2861  tesian_product(a
+00000ce0: 7272 6179 5f6c 6973 7429 0a0a 2020 2020  rray_list)..    
+00000cf0: 5061 7261 6d65 7465 7273 0a20 2020 202d  Parameters.    -
+00000d00: 2d2d 2d2d 2d2d 2d2d 2d0a 2020 2020 6172  ---------.    ar
+00000d10: 7261 795f 6c69 7374 203a 206c 6973 7420  ray_list : list 
+00000d20: 6f66 2031 4420 6e64 6172 7261 7920 6f66  of 1D ndarray of
+00000d30: 2066 6c6f 6174 0a20 2020 2020 2020 2041   float.        A
+00000d40: 7272 6179 7320 746f 2063 6f6d 7075 7465  rrays to compute
+00000d50: 2074 6865 2063 6172 7465 7369 616e 2070   the cartesian p
+00000d60: 726f 6475 6374 2077 6974 680a 0a20 2020  roduct with..   
+00000d70: 2052 6574 7572 6e73 0a20 2020 202d 2d2d   Returns.    ---
+00000d80: 2d2d 2d2d 0a20 2020 2063 6172 7465 7369  ----.    cartesi
+00000d90: 616e 5f70 726f 6475 6374 203a 206e 6461  an_product : nda
+00000da0: 7272 6179 206f 6620 666c 6f61 740a 2020  rray of float.  
+00000db0: 2020 2020 2020 4172 7261 7920 636f 6e74        Array cont
+00000dc0: 6169 6e69 6e67 2074 6865 2063 6172 7465  aining the carte
+00000dd0: 7369 616e 2070 726f 6475 6374 7320 2861  sian products (a
+00000de0: 6c6c 2063 6f6d 6269 6e61 7469 6f6e 7320  ll combinations 
+00000df0: 6f66 2069 6e70 7574 2076 6563 746f 7273  of input vectors
+00000e00: 290a 2020 2020 2020 2020 284d 2c20 6c65  ).        (M, le
+00000e10: 6e28 6172 7261 7973 2929 0a0a 2020 2020  n(arrays))..    
+00000e20: 4578 616d 706c 6573 0a20 2020 202d 2d2d  Examples.    ---
+00000e30: 2d2d 2d2d 2d0a 2020 2020 3e3e 3e20 696d  -----.    >>> im
+00000e40: 706f 7274 2070 7967 7063 0a20 2020 203e  port pygpc.    >
+00000e50: 3e3e 206f 7574 203d 2070 7967 7063 2e67  >> out = pygpc.g
+00000e60: 6574 5f63 6172 7465 7369 616e 5f70 726f  et_cartesian_pro
+00000e70: 6475 6374 2828 5b31 2c20 322c 2033 5d2c  duct(([1, 2, 3],
+00000e80: 205b 342c 2035 5d2c 205b 362c 2037 5d29   [4, 5], [6, 7])
+00000e90: 290a 2020 2020 3e3e 3e20 6f75 740a 2020  ).    >>> out.  
+00000ea0: 2020 2222 220a 0a20 2020 2063 6172 7465    """..    carte
+00000eb0: 7369 616e 5f70 726f 6475 6374 203d 205b  sian_product = [
+00000ec0: 656c 656d 656e 7420 666f 7220 656c 656d  element for elem
+00000ed0: 656e 7420 696e 2069 7465 7274 6f6f 6c73  ent in itertools
+00000ee0: 2e70 726f 6475 6374 282a 6172 7261 795f  .product(*array_
+00000ef0: 6c69 7374 295d 0a20 2020 2072 6574 7572  list)].    retur
+00000f00: 6e20 6e70 2e61 7272 6179 2863 6172 7465  n np.array(carte
+00000f10: 7369 616e 5f70 726f 6475 6374 290a 0a0a  sian_product)...
+00000f20: 6465 6620 6765 745f 726f 7461 7469 6f6e  def get_rotation
+00000f30: 5f6d 6174 7269 7828 7468 6574 6129 3a0a  _matrix(theta):.
+00000f40: 2020 2020 2222 220a 2020 2020 4765 6e65      """.    Gene
+00000f50: 7261 7465 2072 6f74 6174 696f 6e20 6d61  rate rotation ma
+00000f60: 7472 6978 2066 726f 6d20 6575 6c65 7220  trix from euler 
+00000f70: 616e 676c 6573 2e0a 0a20 2020 2072 6f74  angles...    rot
+00000f80: 6174 696f 6e5f 6d61 7472 6978 203d 2067  ation_matrix = g
+00000f90: 6574 5f72 6f74 6174 696f 6e5f 6d61 7472  et_rotation_matr
+00000fa0: 6978 2874 6865 7461 290a 0a20 2020 2050  ix(theta)..    P
+00000fb0: 6172 616d 6574 6572 730a 2020 2020 2d2d  arameters.    --
+00000fc0: 2d2d 2d2d 2d2d 2d2d 0a20 2020 2074 6865  --------.    the
+00000fd0: 7461 203a 206c 6973 7420 6f66 2066 6c6f  ta : list of flo
+00000fe0: 6174 205b 335d 0a20 2020 2020 2020 2045  at [3].        E
+00000ff0: 756c 6572 2061 6e67 6c65 730a 0a20 2020  uler angles..   
+00001000: 2052 6574 7572 6e73 0a20 2020 202d 2d2d   Returns.    ---
+00001010: 2d2d 2d2d 0a20 2020 2072 6f74 6174 696f  ----.    rotatio
+00001020: 6e5f 6d61 7472 6978 203a 206e 6461 7272  n_matrix : ndarr
+00001030: 6179 206f 6620 666c 6f61 7420 5b33 2c20  ay of float [3, 
+00001040: 335d 0a20 2020 2020 2020 2052 6f74 6174  3].        Rotat
+00001050: 696f 6e20 6d61 7472 6978 2063 6f6d 7075  ion matrix compu
+00001060: 7465 6420 6672 6f6d 2065 756c 6572 2061  ted from euler a
+00001070: 6e67 6c65 730a 2020 2020 2222 220a 0a20  ngles.    """.. 
+00001080: 2020 2072 5f78 203d 206e 702e 6172 7261     r_x = np.arra
+00001090: 7928 5b5b 312c 2030 2c20 305d 2c0a 2020  y([[1, 0, 0],.  
+000010a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000010b0: 2020 5b30 2c20 6d61 7468 2e63 6f73 2874    [0, math.cos(t
+000010c0: 6865 7461 5b30 5d29 2c20 2d6d 6174 682e  heta[0]), -math.
+000010d0: 7369 6e28 7468 6574 615b 305d 295d 2c0a  sin(theta[0])],.
+000010e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000010f0: 2020 2020 5b30 2c20 6d61 7468 2e73 696e      [0, math.sin
+00001100: 2874 6865 7461 5b30 5d29 2c20 6d61 7468  (theta[0]), math
+00001110: 2e63 6f73 2874 6865 7461 5b30 5d29 5d0a  .cos(theta[0])].
+00001120: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001130: 2020 2020 5d29 0a0a 2020 2020 725f 7920      ])..    r_y 
+00001140: 3d20 6e70 2e61 7272 6179 285b 5b6d 6174  = np.array([[mat
+00001150: 682e 636f 7328 7468 6574 615b 315d 292c  h.cos(theta[1]),
+00001160: 2030 2c20 6d61 7468 2e73 696e 2874 6865   0, math.sin(the
+00001170: 7461 5b31 5d29 5d2c 0a20 2020 2020 2020  ta[1])],.       
+00001180: 2020 2020 2020 2020 2020 2020 205b 302c               [0,
+00001190: 2031 2c20 305d 2c0a 2020 2020 2020 2020   1, 0],.        
+000011a0: 2020 2020 2020 2020 2020 2020 5b2d 6d61              [-ma
+000011b0: 7468 2e73 696e 2874 6865 7461 5b31 5d29  th.sin(theta[1])
+000011c0: 2c20 302c 206d 6174 682e 636f 7328 7468  , 0, math.cos(th
+000011d0: 6574 615b 315d 295d 0a20 2020 2020 2020  eta[1])].       
+000011e0: 2020 2020 2020 2020 2020 2020 205d 290a               ]).
+000011f0: 0a20 2020 2072 5f7a 203d 206e 702e 6172  .    r_z = np.ar
+00001200: 7261 7928 5b5b 6d61 7468 2e63 6f73 2874  ray([[math.cos(t
+00001210: 6865 7461 5b32 5d29 2c20 2d6d 6174 682e  heta[2]), -math.
+00001220: 7369 6e28 7468 6574 615b 325d 292c 2030  sin(theta[2]), 0
+00001230: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+00001240: 2020 2020 2020 205b 6d61 7468 2e73 696e         [math.sin
+00001250: 2874 6865 7461 5b32 5d29 2c20 6d61 7468  (theta[2]), math
+00001260: 2e63 6f73 2874 6865 7461 5b32 5d29 2c20  .cos(theta[2]), 
+00001270: 305d 2c0a 2020 2020 2020 2020 2020 2020  0],.            
+00001280: 2020 2020 2020 2020 5b30 2c20 302c 2031          [0, 0, 1
+00001290: 5d0a 2020 2020 2020 2020 2020 2020 2020  ].              
+000012a0: 2020 2020 2020 5d29 0a0a 2020 2020 726f        ])..    ro
+000012b0: 7461 7469 6f6e 5f6d 6174 7269 7820 3d20  tation_matrix = 
+000012c0: 6e70 2e64 6f74 2872 5f7a 2c20 6e70 2e64  np.dot(r_z, np.d
+000012d0: 6f74 2872 5f79 2c20 725f 7829 290a 0a20  ot(r_y, r_x)).. 
+000012e0: 2020 2072 6574 7572 6e20 726f 7461 7469     return rotati
+000012f0: 6f6e 5f6d 6174 7269 780a 0a0a 6465 6620  on_matrix...def 
+00001300: 6765 745f 6469 6666 6572 656e 745f 726f  get_different_ro
+00001310: 7773 5f66 726f 6d5f 6d61 7472 6963 6573  ws_from_matrices
+00001320: 2861 2c20 6229 3a0a 2020 2020 2222 220a  (a, b):.    """.
+00001330: 2020 2020 436f 6d70 6172 6573 2072 6f77      Compares row
+00001340: 7320 6672 6f6d 206d 6174 7269 7820 6120  s from matrix a 
+00001350: 7769 7468 2072 6f77 7320 6672 6f6d 206d  with rows from m
+00001360: 6174 7269 7820 622e 2049 7420 6973 2061  atrix b. It is a
+00001370: 7373 756d 6564 2074 6861 7420 6220 636f  ssumed that b co
+00001380: 6e74 6169 6e73 2072 6f77 7320 6672 6f6d  ntains rows from
+00001390: 2061 2e0a 2020 2020 5468 6520 6675 6e63   a..    The func
+000013a0: 7469 6f6e 2072 6574 7572 6e73 2074 6865  tion returns the
+000013b0: 2072 6f77 7320 6f66 2062 2c20 7768 6963   rows of b, whic
+000013c0: 6820 6172 6520 6e6f 7420 696e 636c 7564  h are not includ
+000013d0: 6564 2069 6e20 612e 0a0a 2020 2020 5061  ed in a...    Pa
+000013e0: 7261 6d65 7465 7273 0a20 2020 202d 2d2d  rameters.    ---
+000013f0: 2d2d 2d2d 2d2d 2d0a 2020 2020 6120 3a20  -------.    a : 
+00001400: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
+00001410: 205b 6d31 2078 206e 5d0a 2020 2020 2020   [m1 x n].      
+00001420: 2020 4669 7273 7420 6d61 7472 6978 2028    First matrix (
+00001430: 7573 7561 6c6c 7920 7468 6520 736d 616c  usually the smal
+00001440: 6c65 7220 6f6e 6529 2c20 7768 6572 6520  ler one), where 
+00001450: 726f 7773 2061 7265 2070 6172 7420 6f66  rows are part of
+00001460: 2062 0a20 2020 2062 203a 206e 6461 7272   b.    b : ndarr
+00001470: 6179 206f 6620 666c 6f61 7420 5b6d 3220  ay of float [m2 
+00001480: 7820 6e5d 0a20 2020 2020 2020 2053 6563  x n].        Sec
+00001490: 6f6e 6420 6d61 7472 6978 2028 7573 7561  ond matrix (usua
+000014a0: 6c6c 7920 7468 6520 6c61 7267 6572 206f  lly the larger o
+000014b0: 6e65 292c 2063 6f6e 7461 696e 696e 6720  ne), containing 
+000014c0: 726f 7773 206f 6620 610a 0a20 2020 2052  rows of a..    R
+000014d0: 6574 7572 6e73 0a20 2020 202d 2d2d 2d2d  eturns.    -----
+000014e0: 2d2d 0a20 2020 2062 5f64 6966 6620 3a20  --.    b_diff : 
 000014f0: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-00001500: 205b 6d32 2078 206e 5d0d 0a20 2020 2020   [m2 x n]..     
-00001510: 2020 2053 6563 6f6e 6420 6d61 7472 6978     Second matrix
-00001520: 2028 7573 7561 6c6c 7920 7468 6520 6c61   (usually the la
-00001530: 7267 6572 206f 6e65 292c 2063 6f6e 7461  rger one), conta
-00001540: 696e 696e 6720 726f 7773 206f 6620 610d  ining rows of a.
-00001550: 0a0d 0a20 2020 2052 6574 7572 6e73 0d0a  ...    Returns..
-00001560: 2020 2020 2d2d 2d2d 2d2d 2d0d 0a20 2020      -------..   
-00001570: 2062 5f64 6966 6620 3a20 6e64 6172 7261   b_diff : ndarra
-00001580: 7920 6f66 2066 6c6f 6174 205b 6d33 2078  y of float [m3 x
-00001590: 206e 5d0d 0a20 2020 2020 2020 2052 6f77   n]..        Row
-000015a0: 7320 6672 6f6d 2062 2064 6966 6665 7269  s from b differi
-000015b0: 6e67 2066 726f 6d20 610d 0a20 2020 2022  ng from a..    "
-000015c0: 2222 0d0a 2020 2020 6964 785f 696e 203d  ""..    idx_in =
-000015d0: 205b 5d0d 0a0d 0a20 2020 2066 6f72 205f   []....    for _
-000015e0: 6120 696e 2061 3a0d 0a20 2020 2020 2020  a in a:..       
-000015f0: 2066 6f72 2069 5f62 2c20 5f62 2069 6e20   for i_b, _b in 
-00001600: 656e 756d 6572 6174 6528 6229 3a0d 0a20  enumerate(b):.. 
-00001610: 2020 2020 2020 2020 2020 2069 6620 286e             if (n
-00001620: 702e 6973 636c 6f73 6528 5f61 2c20 5f62  p.isclose(_a, _b
-00001630: 2c20 6174 6f6c 3d31 652d 3629 292e 616c  , atol=1e-6)).al
-00001640: 6c28 293a 0d0a 2020 2020 2020 2020 2020  l():..          
-00001650: 2020 2020 2020 6964 785f 696e 2e61 7070        idx_in.app
-00001660: 656e 6428 695f 6229 0d0a 0d0a 2020 2020  end(i_b)....    
-00001670: 6964 7820 3d20 6e70 2e61 7261 6e67 6528  idx = np.arange(
-00001680: 622e 7368 6170 655b 305d 290d 0a20 2020  b.shape[0])..   
-00001690: 2069 6478 5f6e 6f74 5f69 6e20 3d20 5b69   idx_not_in = [i
-000016a0: 2066 6f72 2069 2069 6e20 6964 7820 6966   for i in idx if
-000016b0: 2069 206e 6f74 2069 6e20 6964 785f 696e   i not in idx_in
-000016c0: 5d0d 0a0d 0a20 2020 2072 6574 7572 6e20  ]....    return 
-000016d0: 625b 6964 785f 6e6f 745f 696e 2c20 3a5d  b[idx_not_in, :]
-000016e0: 0d0a 0d0a 0d0a 6465 6620 6765 745f 6c69  ......def get_li
-000016f0: 7374 5f6d 756c 7469 5f64 656c 6574 6528  st_multi_delete(
-00001700: 696e 7075 745f 6c69 7374 2c20 696e 6465  input_list, inde
-00001710: 7829 3a0d 0a20 2020 2022 2222 0d0a 2020  x):..    """..  
-00001720: 2020 4465 6c65 7465 206d 756c 7469 706c    Delete multipl
-00001730: 6520 656e 7472 6965 7320 6672 6f6d 206c  e entries from l
-00001740: 6973 742e 0d0a 0d0a 2020 2020 696e 7075  ist.....    inpu
-00001750: 745f 6c69 7374 203d 2067 6574 5f6c 6973  t_list = get_lis
-00001760: 745f 6d75 6c74 695f 6465 6c65 7465 2869  t_multi_delete(i
-00001770: 6e70 7574 5f6c 6973 742c 2069 6e64 6578  nput_list, index
-00001780: 290d 0a0d 0a20 2020 2050 6172 616d 6574  )....    Paramet
-00001790: 6572 730d 0a20 2020 202d 2d2d 2d2d 2d2d  ers..    -------
-000017a0: 2d2d 2d0d 0a20 2020 2069 6e70 7574 5f6c  ---..    input_l
-000017b0: 6973 7420 3a20 6c69 7374 0d0a 2020 2020  ist : list..    
-000017c0: 2020 2020 5369 6d70 6c65 206c 6973 740d      Simple list.
-000017d0: 0a20 2020 2069 6e64 6578 203a 206c 6973  .    index : lis
-000017e0: 7420 6f66 2069 6e74 6567 6572 0d0a 2020  t of integer..  
-000017f0: 2020 2020 2020 4c69 7374 206f 6620 696e        List of in
-00001800: 6469 6365 7320 746f 2064 656c 6574 650d  dices to delete.
-00001810: 0a0d 0a20 2020 2052 6574 7572 6e73 0d0a  ...    Returns..
-00001820: 2020 2020 2d2d 2d2d 2d2d 2d0d 0a20 2020      -------..   
-00001830: 2069 6e70 7574 5f6c 6973 7420 3a20 6c69   input_list : li
-00001840: 7374 0d0a 2020 2020 2020 2020 496e 7075  st..        Inpu
-00001850: 7420 6c69 7374 2077 6974 686f 7574 2065  t list without e
-00001860: 6e74 7269 6573 2073 7065 6369 6669 6564  ntries specified
-00001870: 2069 6e20 696e 6465 780d 0a20 2020 2022   in index..    "
-00001880: 2222 0d0a 0d0a 2020 2020 696e 6469 6365  ""....    indice
-00001890: 7320 3d20 736f 7274 6564 2869 6e64 6578  s = sorted(index
-000018a0: 2c20 7265 7665 7273 653d 5472 7565 290d  , reverse=True).
-000018b0: 0a20 2020 2066 6f72 206c 6973 745f 696e  .    for list_in
-000018c0: 6465 7820 696e 2069 6e64 6963 6573 3a0d  dex in indices:.
-000018d0: 0a20 2020 2020 2020 2064 656c 2069 6e70  .        del inp
-000018e0: 7574 5f6c 6973 745b 6c69 7374 5f69 6e64  ut_list[list_ind
-000018f0: 6578 5d0d 0a20 2020 2072 6574 7572 6e20  ex]..    return 
-00001900: 696e 7075 745f 6c69 7374 0d0a 0d0a 0d0a  input_list......
-00001910: 6465 6620 6765 745f 6172 7261 795f 756e  def get_array_un
-00001920: 6971 7565 5f72 6f77 7328 6172 7261 7929  ique_rows(array)
-00001930: 3a0d 0a20 2020 2022 2222 0d0a 2020 2020  :..    """..    
-00001940: 436f 6d70 7574 6520 756e 6971 7565 2072  Compute unique r
-00001950: 6f77 7320 6f66 2032 4420 6172 7261 7920  ows of 2D array 
-00001960: 616e 6420 6465 6c65 7465 2072 6f77 7320  and delete rows 
-00001970: 7468 6174 2061 7265 2072 6564 756e 6461  that are redunda
-00001980: 6e74 2e0d 0a0d 0a20 2020 2075 6e69 7175  nt.....    uniqu
-00001990: 6520 3d20 6765 745f 6172 7261 795f 756e  e = get_array_un
-000019a0: 6971 7565 5f72 6f77 7328 6172 7261 7929  ique_rows(array)
-000019b0: 0d0a 0d0a 2020 2020 5061 7261 6d65 7465  ....    Paramete
-000019c0: 7273 0d0a 2020 2020 2d2d 2d2d 2d2d 2d2d  rs..    --------
-000019d0: 2d2d 0d0a 2020 2020 6172 7261 793a 206e  --..    array: n
-000019e0: 6461 7272 6179 206f 6620 666c 6f61 740d  darray of float.
-000019f0: 0a20 2020 2020 2020 204d 6174 7269 7820  .        Matrix 
-00001a00: 7769 7468 206b 2072 6564 756e 6461 6e74  with k redundant
-00001a10: 2072 6f77 730d 0a0d 0a20 2020 2052 6574   rows....    Ret
-00001a20: 7572 6e73 0d0a 2020 2020 2d2d 2d2d 2d2d  urns..    ------
-00001a30: 2d0d 0a20 2020 2075 6e69 7175 653a 206e  -..    unique: n
-00001a40: 6461 7272 6179 206f 6620 666c 6f61 740d  darray of float.
-00001a50: 0a20 2020 2020 2020 204d 6174 7269 7820  .        Matrix 
-00001a60: 7769 7468 6f75 7420 6b20 7265 6475 6e64  without k redund
-00001a70: 616e 7420 726f 7773 0d0a 2020 2020 2222  ant rows..    ""
-00001a80: 220d 0a0d 0a20 2020 205f 2c20 696e 6465  "....    _, inde
-00001a90: 7820 3d20 6e70 2e75 6e69 7175 6528 6172  x = np.unique(ar
-00001aa0: 7261 792c 2061 7869 733d 302c 2072 6574  ray, axis=0, ret
-00001ab0: 7572 6e5f 696e 6465 783d 5472 7565 290d  urn_index=True).
-00001ac0: 0a20 2020 2069 6e64 6578 203d 206e 702e  .    index = np.
-00001ad0: 736f 7274 2869 6e64 6578 290d 0a20 2020  sort(index)..   
-00001ae0: 2072 6574 7572 6e20 6172 7261 795b 696e   return array[in
-00001af0: 6465 785d 0d0a 0d0a 0d0a 6465 6620 6e72  dex]......def nr
-00001b00: 6d73 6428 6172 7261 792c 2061 7272 6179  msd(array, array
-00001b10: 5f72 6566 2c20 6572 726f 725f 6e6f 726d  _ref, error_norm
-00001b20: 3d22 7265 6c61 7469 7665 222c 2078 5f61  ="relative", x_a
-00001b30: 7869 733d 4661 6c73 6529 3a0d 0a20 2020  xis=False):..   
-00001b40: 2022 2222 0d0a 2020 2020 4465 7465 726d   """..    Determ
-00001b50: 696e 6520 7468 6520 6e6f 726d 616c 697a  ine the normaliz
-00001b60: 6564 2072 6f6f 7420 6d65 616e 2073 7175  ed root mean squ
-00001b70: 6172 6520 6465 7669 6174 696f 6e20 6265  are deviation be
-00001b80: 7477 6565 6e20 696e 7075 7420 6461 7461  tween input data
-00001b90: 2061 6e64 2072 6566 6572 656e 6365 2064   and reference d
-00001ba0: 6174 612e 0d0a 0d0a 2020 2020 6e6f 726d  ata.....    norm
-00001bb0: 616c 697a 6564 5f72 6d73 203d 2067 6574  alized_rms = get
-00001bc0: 5f6e 6f72 6d61 6c69 7a65 645f 726d 7328  _normalized_rms(
-00001bd0: 6172 7261 792c 2061 7272 6179 5f72 6566  array, array_ref
-00001be0: 290d 0a0d 0a20 2020 2050 6172 616d 6574  )....    Paramet
-00001bf0: 6572 730d 0a20 2020 202d 2d2d 2d2d 2d2d  ers..    -------
-00001c00: 2d2d 2d0d 0a20 2020 2061 7272 6179 3a20  ---..    array: 
-00001c10: 6e70 2e6e 6461 7272 6179 0d0a 2020 2020  np.ndarray..    
-00001c20: 2020 2020 696e 7075 7420 6461 7461 205b      input data [
-00001c30: 2028 7829 2c20 7930 2c20 7931 2c20 7932   (x), y0, y1, y2
-00001c40: 202e 2e2e 205d 0d0a 2020 2020 6172 7261   ... ]..    arra
-00001c50: 795f 7265 663a 206e 702e 6e64 6172 7261  y_ref: np.ndarra
-00001c60: 790d 0a20 2020 2020 2020 2072 6566 6572  y..        refer
-00001c70: 656e 6365 2064 6174 6120 5b20 2878 5f72  ence data [ (x_r
-00001c80: 6566 292c 2079 305f 7265 662c 2079 315f  ef), y0_ref, y1_
-00001c90: 7265 662c 2079 325f 7265 6620 2e2e 2e20  ref, y2_ref ... 
-00001ca0: 5d0d 0a20 2020 2020 2020 2069 6620 6172  ]..        if ar
-00001cb0: 7261 795f 7265 6620 6973 2031 442c 2061  ray_ref is 1D, a
-00001cc0: 6c6c 2073 697a 6573 2068 6176 6520 746f  ll sizes have to
-00001cd0: 206d 6174 6368 0d0a 2020 2020 6572 726f   match..    erro
-00001ce0: 725f 6e6f 726d 3a20 7374 722c 206f 7074  r_norm: str, opt
-00001cf0: 696f 6e61 6c2c 2064 6566 6175 6c74 3d22  ional, default="
-00001d00: 7265 6c61 7469 7665 220d 0a20 2020 2020  relative"..     
-00001d10: 2020 2044 6563 6964 6520 6966 2065 7272     Decide if err
-00001d20: 6f72 2069 7320 6465 7465 726d 696e 6564  or is determined
-00001d30: 2022 7265 6c61 7469 7665 2220 6f72 2022   "relative" or "
-00001d40: 6162 736f 6c75 7465 220d 0a20 2020 2078  absolute"..    x
-00001d50: 5f61 7869 733a 2062 6f6f 6c65 616e 2c20  _axis: boolean, 
-00001d60: 6f70 7469 6f6e 616c 2c20 6465 6661 756c  optional, defaul
-00001d70: 743d 4661 6c73 650d 0a20 2020 2020 2020  t=False..       
-00001d80: 2049 6620 5472 7565 2c20 7468 6520 6669   If True, the fi
-00001d90: 7273 7420 636f 6c75 6d6e 206f 6620 6172  rst column of ar
-00001da0: 7261 7920 616e 6420 6172 7261 795f 7265  ray and array_re
-00001db0: 6620 6973 2069 6e74 6572 7072 6574 6564  f is interpreted
-00001dc0: 2061 7320 7468 6520 782d 6178 6973 2c20   as the x-axis, 
-00001dd0: 7768 6572 6520 7468 6520 6461 7461 2070  where the data p
-00001de0: 6f69 6e74 7320 6172 650d 0a20 2020 2020  oints are..     
-00001df0: 2020 2065 7661 6c75 6174 6564 2e20 4966     evaluated. If
-00001e00: 2046 616c 7365 2c20 7468 6520 6461 7461   False, the data
-00001e10: 2070 6f69 6e74 7320 6172 6520 6173 7375   points are assu
-00001e20: 6d65 6420 746f 2062 6520 6174 2074 6865  med to be at the
-00001e30: 2073 616d 6520 6c6f 6361 7469 6f6e 2e0d   same location..
-00001e40: 0a0d 0a20 2020 2052 6574 7572 6e73 0d0a  ...    Returns..
-00001e50: 2020 2020 2d2d 2d2d 2d2d 2d0d 0a20 2020      -------..   
-00001e60: 206e 6f72 6d61 6c69 7a65 645f 726d 733a   normalized_rms:
-00001e70: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-00001e80: 7420 5b61 7272 6179 2e73 6861 7065 5b31  t [array.shape[1
-00001e90: 5d5d 0d0a 2020 2020 2020 2020 4e6f 726d  ]]..        Norm
-00001ea0: 616c 697a 6564 2072 6f6f 7420 6d65 616e  alized root mean
-00001eb0: 2073 7175 6172 6520 6465 7669 6174 696f   square deviatio
-00001ec0: 6e20 6265 7477 6565 6e20 7468 6520 636f  n between the co
-00001ed0: 6c75 6d6e 7320 6f66 2061 7272 6179 2061  lumns of array a
-00001ee0: 6e64 2061 7272 6179 5f72 6566 0d0a 2020  nd array_ref..  
-00001ef0: 2020 2222 220d 0a0d 0a20 2020 206e 5f70    """....    n_p
-00001f00: 6f69 6e74 7320 3d20 6172 7261 792e 7368  oints = array.sh
-00001f10: 6170 655b 305d 0d0a 0d0a 2020 2020 6966  ape[0]....    if
-00001f20: 2078 5f61 7869 733a 0d0a 2020 2020 2020   x_axis:..      
-00001f30: 2020 2320 6861 6e64 6c65 2064 6966 6665    # handle diffe
-00001f40: 7265 6e74 2061 7272 6179 206c 656e 6774  rent array lengt
-00001f50: 6873 0d0a 2020 2020 2020 2020 6966 206c  hs..        if l
-00001f60: 656e 2861 7272 6179 5f72 6566 2e73 6861  en(array_ref.sha
-00001f70: 7065 2920 3d3d 2031 3a0d 0a20 2020 2020  pe) == 1:..     
-00001f80: 2020 2020 2020 2061 7272 6179 5f72 6566         array_ref
-00001f90: 203d 2061 7272 6179 5f72 6566 5b3a 2c20   = array_ref[:, 
-00001fa0: 4e6f 6e65 5d0d 0a20 2020 2020 2020 2069  None]..        i
-00001fb0: 6620 6c65 6e28 6172 7261 792e 7368 6170  f len(array.shap
-00001fc0: 6529 203d 3d20 313a 0d0a 2020 2020 2020  e) == 1:..      
-00001fd0: 2020 2020 2020 6172 7261 7920 3d20 6172        array = ar
-00001fe0: 7261 795b 3a2c 204e 6f6e 655d 0d0a 0d0a  ray[:, None]....
-00001ff0: 2020 2020 2020 2020 2320 6465 7465 726d          # determ
-00002000: 696e 6520 6e75 6d62 6572 206f 6620 696e  ine number of in
-00002010: 7075 7420 6172 7261 7973 0d0a 2020 2020  put arrays..    
-00002020: 2020 2020 6966 2061 7272 6179 5f72 6566      if array_ref
-00002030: 2e73 6861 7065 5b31 5d20 3d3d 2032 3a0d  .shape[1] == 2:.
-00002040: 0a20 2020 2020 2020 2020 2020 206e 5f64  .            n_d
-00002050: 6174 6120 3d20 6172 7261 792e 7368 6170  ata = array.shap
-00002060: 655b 315d 2d31 0d0a 2020 2020 2020 2020  e[1]-1..        
-00002070: 656c 7365 3a0d 0a20 2020 2020 2020 2020  else:..         
-00002080: 2020 206e 5f64 6174 6120 3d20 6172 7261     n_data = arra
-00002090: 792e 7368 6170 655b 315d 0d0a 0d0a 2020  y.shape[1]....  
-000020a0: 2020 2020 2020 2320 696e 7465 7270 6f6c        # interpol
-000020b0: 6174 6520 6172 7261 7920 6f6e 2061 7272  ate array on arr
-000020c0: 6179 5f72 6566 2064 6174 6120 6966 206e  ay_ref data if n
-000020d0: 6563 6573 7361 7279 0d0a 2020 2020 2020  ecessary..      
-000020e0: 2020 6966 2061 7272 6179 5f72 6566 2e73    if array_ref.s
-000020f0: 6861 7065 5b31 5d20 3d3d 2031 3a0d 0a20  hape[1] == 1:.. 
-00002100: 2020 2020 2020 2020 2020 2064 6174 6120             data 
-00002110: 3d20 6172 7261 790d 0a20 2020 2020 2020  = array..       
-00002120: 2020 2020 2064 6174 615f 7265 6620 3d20       data_ref = 
-00002130: 6172 7261 795f 7265 660d 0a20 2020 2020  array_ref..     
-00002140: 2020 2065 6c73 653a 0d0a 2020 2020 2020     else:..      
-00002150: 2020 2020 2020 2320 6372 6f70 2072 6566        # crop ref
-00002160: 6572 656e 6365 2069 6620 6974 2069 7320  erence if it is 
-00002170: 6c6f 6e67 6572 2074 6861 6e20 7468 6520  longer than the 
-00002180: 6178 6973 206f 6620 7468 6520 6461 7461  axis of the data
-00002190: 0d0a 2020 2020 2020 2020 2020 2020 6461  ..            da
-000021a0: 7461 5f72 6566 203d 2061 7272 6179 5f72  ta_ref = array_r
-000021b0: 6566 5b28 6172 7261 795f 7265 665b 3a2c  ef[(array_ref[:,
-000021c0: 2030 5d20 3e3d 206d 696e 2861 7272 6179   0] >= min(array
-000021d0: 5b3a 2c20 305d 2929 2026 2028 6172 7261  [:, 0])) & (arra
-000021e0: 795f 7265 665b 3a2c 2030 5d20 3c3d 206d  y_ref[:, 0] <= m
-000021f0: 6178 2861 7272 6179 5b3a 2c20 305d 2929  ax(array[:, 0]))
-00002200: 2c20 315d 0d0a 2020 2020 2020 2020 2020  , 1]..          
-00002210: 2020 6172 7261 795f 7265 6620 3d20 6172    array_ref = ar
-00002220: 7261 795f 7265 665b 2861 7272 6179 5f72  ray_ref[(array_r
-00002230: 6566 5b3a 2c20 305d 203e 3d20 6d69 6e28  ef[:, 0] >= min(
-00002240: 6172 7261 795b 3a2c 2030 5d29 2920 2620  array[:, 0])) & 
-00002250: 2861 7272 6179 5f72 6566 5b3a 2c20 305d  (array_ref[:, 0]
-00002260: 203c 3d20 6d61 7828 6172 7261 795b 3a2c   <= max(array[:,
-00002270: 2030 5d29 292c 2030 5d0d 0a0d 0a20 2020   0])), 0]....   
-00002280: 2020 2020 2020 2020 2064 6174 6120 3d20           data = 
-00002290: 6e70 2e7a 6572 6f73 285b 6c65 6e28 6172  np.zeros([len(ar
-000022a0: 7261 795f 7265 6629 2c20 6e5f 6461 7461  ray_ref), n_data
-000022b0: 5d29 0d0a 2020 2020 2020 2020 2020 2020  ])..            
-000022c0: 666f 7220 695f 6461 7461 2069 6e20 7261  for i_data in ra
-000022d0: 6e67 6528 6e5f 6461 7461 293a 0d0a 2020  nge(n_data):..  
-000022e0: 2020 2020 2020 2020 2020 2020 2020 6461                da
-000022f0: 7461 5b3a 2c20 695f 6461 7461 5d20 3d20  ta[:, i_data] = 
-00002300: 6e70 2e69 6e74 6572 7028 6172 7261 795f  np.interp(array_
-00002310: 7265 662c 2061 7272 6179 5b3a 2c20 305d  ref, array[:, 0]
-00002320: 2c20 6172 7261 795b 3a2c 2069 5f64 6174  , array[:, i_dat
-00002330: 612b 315d 290d 0a20 2020 2065 6c73 653a  a+1])..    else:
-00002340: 0d0a 2020 2020 2020 2020 6461 7461 5f72  ..        data_r
-00002350: 6566 203d 2061 7272 6179 5f72 6566 0d0a  ef = array_ref..
-00002360: 2020 2020 2020 2020 6461 7461 203d 2061          data = a
-00002370: 7272 6179 0d0a 0d0a 2020 2020 2320 6465  rray....    # de
-00002380: 7465 726d 696e 6520 2261 6273 6f6c 7574  termine "absolut
-00002390: 6522 206f 7220 2272 656c 6174 6976 6522  e" or "relative"
-000023a0: 2065 7272 6f72 0d0a 2020 2020 6966 2065   error..    if e
-000023b0: 7272 6f72 5f6e 6f72 6d20 3d3d 2022 7265  rror_norm == "re
-000023c0: 6c61 7469 7665 223a 0d0a 2020 2020 2020  lative":..      
-000023d0: 2020 2320 6d61 785f 6d69 6e5f 6964 7820    # max_min_idx 
-000023e0: 3d20 6e70 2e69 7363 6c6f 7365 286e 702e  = np.isclose(np.
-000023f0: 6d61 7828 6461 7461 5f72 6566 2c20 6178  max(data_ref, ax
-00002400: 6973 3d30 292c 206e 702e 6d69 6e28 6461  is=0), np.min(da
-00002410: 7461 5f72 6566 2c20 6178 6973 3d30 2929  ta_ref, axis=0))
-00002420: 0d0a 2020 2020 2020 2020 6465 6c74 6120  ..        delta 
-00002430: 3d20 6e70 2e6d 6178 2864 6174 615f 7265  = np.max(data_re
-00002440: 662c 2061 7869 733d 3029 202d 206e 702e  f, axis=0) - np.
-00002450: 6d69 6e28 6461 7461 5f72 6566 2c20 6178  min(data_ref, ax
-00002460: 6973 3d30 290d 0a0d 0a20 2020 2020 2020  is=0)....       
-00002470: 2023 2069 6620 6d61 785f 6d69 6e5f 6964   # if max_min_id
-00002480: 782e 616e 7928 293a 0d0a 2020 2020 2020  x.any():..      
-00002490: 2020 2320 2020 2020 6465 6c74 615b 6d61    #     delta[ma
-000024a0: 785f 6d69 6e5f 6964 785d 203d 206d 6178  x_min_idx] = max
-000024b0: 2864 6174 615f 7265 665b 6d61 785f 6d69  (data_ref[max_mi
-000024c0: 6e5f 6964 785d 290d 0a20 2020 2065 6c73  n_idx])..    els
-000024d0: 653a 0d0a 2020 2020 2020 2020 6465 6c74  e:..        delt
-000024e0: 6120 3d20 310d 0a0d 0a20 2020 2023 2066  a = 1....    # f
-000024f0: 696c 7465 7220 6e61 6e0d 0a20 2020 2072  ilter nan..    r
-00002500: 6f77 5f69 6478 5f64 6174 612c 2063 6f6c  ow_idx_data, col
-00002510: 5f69 6478 5f64 6174 6120 3d20 6e70 2e77  _idx_data = np.w
-00002520: 6865 7265 286e 702e 6973 6e61 6e28 6461  here(np.isnan(da
-00002530: 7461 2929 0d0a 2020 2020 726f 775f 6964  ta))..    row_id
-00002540: 785f 6461 7461 5f72 6566 2c20 636f 6c5f  x_data_ref, col_
-00002550: 6964 785f 6461 7461 5f72 6566 203d 206e  idx_data_ref = n
-00002560: 702e 7768 6572 6528 6e70 2e69 736e 616e  p.where(np.isnan
-00002570: 2864 6174 615f 7265 6629 290d 0a20 2020  (data_ref))..   
-00002580: 2072 6f77 5f69 6478 203d 206e 702e 6873   row_idx = np.hs
-00002590: 7461 636b 2828 726f 775f 6964 785f 6461  tack((row_idx_da
-000025a0: 7461 2c20 726f 775f 6964 785f 6461 7461  ta, row_idx_data
-000025b0: 5f72 6566 2929 0d0a 2020 2020 636f 6c5f  _ref))..    col_
-000025c0: 6964 7820 3d20 6e70 2e68 7374 6163 6b28  idx = np.hstack(
-000025d0: 2863 6f6c 5f69 6478 5f64 6174 612c 2063  (col_idx_data, c
-000025e0: 6f6c 5f69 6478 5f64 6174 615f 7265 6629  ol_idx_data_ref)
-000025f0: 290d 0a0d 0a20 2020 2069 6620 726f 775f  )....    if row_
-00002600: 6964 785f 6461 7461 2e73 697a 6520 3e20  idx_data.size > 
-00002610: 303a 0d0a 2020 2020 2020 2020 7761 726e  0:..        warn
-00002620: 696e 6773 2e77 6172 6e28 226e 616e 2069  ings.warn("nan i
-00002630: 6e20 696e 7075 7420 6461 7461 7365 7420  n input dataset 
-00002640: 666f 756e 6420 6174 2072 6f77 733d 7b7d  found at rows={}
-00002650: 2063 6f6c 733d 7b7d 2028 6967 6e6f 7265   cols={} (ignore
-00002660: 6429 222e 666f 726d 6174 2872 6f77 5f69  d)".format(row_i
-00002670: 6478 2c20 636f 6c5f 6964 7829 290d 0a0d  dx, col_idx))...
-00002680: 0a20 2020 2069 6620 726f 775f 6964 785f  .    if row_idx_
-00002690: 6461 7461 5f72 6566 2e73 697a 6520 3e20  data_ref.size > 
-000026a0: 303a 0d0a 2020 2020 2020 2020 7761 726e  0:..        warn
-000026b0: 696e 6773 2e77 6172 6e28 226e 616e 2069  ings.warn("nan i
-000026c0: 6e20 7265 6665 7265 6e63 6520 6461 7461  n reference data
-000026d0: 7365 7420 666f 756e 6420 6174 2072 6f77  set found at row
-000026e0: 733d 7b7d 2063 6f6c 733d 7b7d 2028 6967  s={} cols={} (ig
-000026f0: 6e6f 7265 6429 222e 666f 726d 6174 2872  nored)".format(r
-00002700: 6f77 5f69 6478 5f64 6174 615f 7265 662c  ow_idx_data_ref,
-00002710: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00002720: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002740: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002750: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002760: 2020 2020 2020 2020 2020 2020 2020 636f                co
-00002770: 6c5f 6964 785f 6461 7461 5f72 6566 2929  l_idx_data_ref))
-00002780: 0d0a 0d0a 2020 2020 6966 2072 6f77 5f69  ....    if row_i
-00002790: 6478 2e73 697a 6520 3e20 303a 0d0a 2020  dx.size > 0:..  
-000027a0: 2020 2020 2020 6461 7461 203d 206e 702e        data = np.
-000027b0: 6465 6c65 7465 2864 6174 612c 206e 702e  delete(data, np.
-000027c0: 756e 6971 7565 2872 6f77 5f69 6478 292c  unique(row_idx),
-000027d0: 2061 7869 733d 3029 0d0a 2020 2020 2020   axis=0)..      
-000027e0: 2020 6461 7461 5f72 6566 203d 206e 702e    data_ref = np.
-000027f0: 6465 6c65 7465 2864 6174 615f 7265 662c  delete(data_ref,
-00002800: 206e 702e 756e 6971 7565 2872 6f77 5f69   np.unique(row_i
-00002810: 6478 292c 2061 7869 733d 3029 0d0a 0d0a  dx), axis=0)....
-00002820: 2020 2020 2320 6465 7465 726d 696e 6520      # determine 
-00002830: 6e6f 726d 616c 697a 6564 2072 6d73 2064  normalized rms d
-00002840: 6576 6961 7469 6f6e 2061 6e64 2072 6574  eviation and ret
-00002850: 7572 6e0d 0a20 2020 206e 6f72 6d61 6c69  urn..    normali
-00002860: 7a65 645f 726d 7320 3d20 6e70 2e73 7172  zed_rms = np.sqr
-00002870: 7428 312e 302f 6e5f 706f 696e 7473 202a  t(1.0/n_points *
-00002880: 206e 702e 7375 6d28 2864 6174 6120 2d20   np.sum((data - 
-00002890: 6461 7461 5f72 6566 292a 2a32 2c20 6178  data_ref)**2, ax
-000028a0: 6973 3d30 2929 202f 2064 656c 7461 0d0a  is=0)) / delta..
-000028b0: 0d0a 2020 2020 7265 7475 726e 206e 6f72  ..    return nor
-000028c0: 6d61 6c69 7a65 645f 726d 730d 0a0d 0a0d  malized_rms.....
-000028d0: 0a64 6566 2067 6574 5f62 6574 615f 7064  .def get_beta_pd
-000028e0: 665f 6669 7428 6461 7461 2c20 6265 7461  f_fit(data, beta
-000028f0: 5f74 6f6c 6572 616e 6365 3d30 2c20 756e  _tolerance=0, un
-00002900: 695f 696e 7465 7276 616c 3d30 2c20 666e  i_interval=0, fn
-00002910: 5f70 6c6f 743d 4e6f 6e65 293a 0d0a 2020  _plot=None):..  
-00002920: 2020 2222 220d 0a20 2020 2046 6974 2064    """..    Fit d
-00002930: 6174 6120 746f 2061 2062 6574 6120 6469  ata to a beta di
-00002940: 7374 7269 6275 7469 6f6e 2069 6e20 7468  stribution in th
-00002950: 6520 696e 7465 7276 616c 205b 612c 2062  e interval [a, b
-00002960: 5d2e 0d0a 0d0a 2020 2020 6265 7461 5f70  ].....    beta_p
-00002970: 6172 616d 6574 6572 732c 206d 6f6d 656e  arameters, momen
-00002980: 7473 2c20 705f 7661 6c75 652c 2075 6e69  ts, p_value, uni
-00002990: 5f70 6172 616d 6574 6572 7320 3d20 6765  _parameters = ge
-000029a0: 745f 6265 7461 5f70 6466 5f66 6974 2864  t_beta_pdf_fit(d
-000029b0: 6174 612c 2062 6574 615f 746f 6c65 7261  ata, beta_tolera
-000029c0: 6e63 653d 302c 2075 6e69 5f69 6e74 6572  nce=0, uni_inter
-000029d0: 7661 6c3d 3029 0d0a 0d0a 2020 2020 5061  val=0)....    Pa
-000029e0: 7261 6d65 7465 7273 0d0a 2020 2020 2d2d  rameters..    --
-000029f0: 2d2d 2d2d 2d2d 2d2d 0d0a 2020 2020 6461  --------..    da
-00002a00: 7461 3a20 6e64 6172 7261 7920 6f66 2066  ta: ndarray of f
-00002a10: 6c6f 6174 0d0a 2020 2020 2020 2020 4461  loat..        Da
-00002a20: 7461 2074 6f20 6669 7420 6265 7461 2064  ta to fit beta d
-00002a30: 6973 7472 6962 7574 696f 6e20 6f6e 0d0a  istribution on..
-00002a40: 2020 2020 6265 7461 5f74 6f6c 6572 616e      beta_toleran
-00002a50: 6365 3a20 666c 6f61 7420 6f72 206c 6973  ce: float or lis
-00002a60: 7420 6f66 2066 6c6f 6174 2c20 6f70 7469  t of float, opti
-00002a70: 6f6e 616c 2c20 6465 6661 756c 743d 300d  onal, default=0.
-00002a80: 0a20 2020 2020 2020 2053 7065 6369 6669  .        Specifi
-00002a90: 6573 2062 6f75 6e64 7320 6f66 2062 6574  es bounds of bet
-00002aa0: 6120 6469 7374 7269 6275 7469 6f6e 2e20  a distribution. 
-00002ab0: 4966 2066 6c6f 6174 2c20 6974 2063 616c  If float, it cal
-00002ac0: 6375 6c61 7465 7320 7468 6520 746f 6c65  culates the tole
-00002ad0: 7261 6e63 650d 0a20 2020 2020 2020 2066  rance..        f
-00002ae0: 726f 6d20 6f62 7365 7276 6564 2064 6174  rom observed dat
-00002af0: 612c 2065 2e67 2e20 302e 3220 282b 2d32  a, e.g. 0.2 (+-2
-00002b00: 3025 2074 6f6c 6572 616e 6365 206f 6e20  0% tolerance on 
-00002b10: 6f62 7365 7276 6564 206d 6178 2061 6e64  observed max and
-00002b20: 206d 696e 2076 616c 7565 292e 0d0a 2020   min value)...  
-00002b30: 2020 2020 2020 4966 206c 6973 742c 2069        If list, i
-00002b40: 7420 7461 6b65 7320 5b6d 696e 2c20 6d61  t takes [min, ma
-00002b50: 785d 2061 7320 626f 756e 6473 205b 612c  x] as bounds [a,
-00002b60: 2062 5d2e 0d0a 2020 2020 756e 695f 696e   b]...    uni_in
-00002b70: 7465 7276 616c 3a20 666c 6f61 7420 6f72  terval: float or
-00002b80: 206c 6973 7420 6f66 2066 6c6f 6174 2c20   list of float, 
-00002b90: 6f70 7469 6f6e 616c 2c20 6465 6661 756c  optional, defaul
-00002ba0: 743d 300d 0a20 2020 2020 2020 2075 6e69  t=0..        uni
-00002bb0: 666f 726d 2064 6973 7472 6962 7574 696f  form distributio
-00002bc0: 6e20 696e 7465 7276 616c 2e20 4966 2066  n interval. If f
-00002bd0: 6c6f 6174 2c20 7468 6520 626f 756e 6473  loat, the bounds
-00002be0: 2061 7265 2064 6566 696e 6564 2061 7320   are defined as 
-00002bf0: 6120 6672 6163 7469 6f6e 206f 6620 7468  a fraction of th
-00002c00: 6520 6265 7461 2064 6973 7472 6962 7574  e beta distribut
-00002c10: 696f 6e0d 0a20 2020 2020 2020 2069 6e74  ion..        int
-00002c20: 6572 7661 6c20 2865 2e67 2e20 302e 3935  erval (e.g. 0.95
-00002c30: 2028 3935 2529 292e 2049 6620 6c69 7374   (95%)). If list
-00002c40: 2c20 6974 2074 616b 6573 205b 6d69 6e2c  , it takes [min,
-00002c50: 206d 6178 5d20 6173 2062 6f75 6e64 7320   max] as bounds 
-00002c60: 5b61 2c20 625d 2e0d 0a20 2020 2066 6e5f  [a, b]...    fn_
-00002c70: 706c 6f74 3a20 7374 720d 0a20 2020 2020  plot: str..     
-00002c80: 2020 2046 696c 656e 616d 6520 6f66 2070     Filename of p
-00002c90: 6c6f 7420 736f 2073 6176 6520 282e 7064  lot so save (.pd
-00002ca0: 6620 616e 6420 2e70 6e67 290d 0a20 2020  f and .png)..   
-00002cb0: 200d 0a20 2020 2052 6574 7572 6e73 0d0a   ..    Returns..
-00002cc0: 2020 2020 2d2d 2d2d 2d2d 2d0d 0a20 2020      -------..   
-00002cd0: 2062 6574 615f 7061 7261 6d65 7465 7273   beta_parameters
-00002ce0: 3a20 6c69 7374 206f 6620 666c 6f61 7420  : list of float 
-00002cf0: 5b34 5d0d 0a20 2020 2020 2020 2054 776f  [4]..        Two
-00002d00: 2073 6861 7065 2070 6172 616d 6574 6572   shape parameter
-00002d10: 7320 616e 6420 6c6f 7765 7220 616e 6420  s and lower and 
-00002d20: 7570 7065 7220 6c69 6d69 7420 5b70 2c20  upper limit [p, 
-00002d30: 712c 2061 2c20 625d 0d0a 2020 2020 6d6f  q, a, b]..    mo
-00002d40: 6d65 6e74 733a 206c 6973 7420 6f66 2066  ments: list of f
-00002d50: 6c6f 6174 205b 345d 0d0a 2020 2020 2020  loat [4]..      
-00002d60: 2020 4d65 616e 2061 6e64 2073 7464 206f    Mean and std o
-00002d70: 6620 7261 7720 6461 7461 2061 6e64 2066  f raw data and f
-00002d80: 6974 7465 6420 6265 7461 2064 6973 7472  itted beta distr
-00002d90: 6962 7574 696f 6e20 5b64 6174 615f 6d65  ibution [data_me
-00002da0: 616e 2c20 6461 7461 5f73 7464 2c20 6265  an, data_std, be
-00002db0: 7461 5f6d 6561 6e2c 2062 6574 615f 7374  ta_mean, beta_st
-00002dc0: 645d 0d0a 2020 2020 705f 7661 6c75 653a  d]..    p_value:
-00002dd0: 2066 6c6f 6174 0d0a 2020 2020 2020 2020   float..        
-00002de0: 702d 7661 6c75 6520 6f66 2074 6865 204b  p-value of the K
-00002df0: 6f6c 6d6f 676f 726f 7620 536d 6972 6e6f  olmogorov Smirno
-00002e00: 7620 7465 7374 0d0a 2020 2020 756e 695f  v test..    uni_
-00002e10: 7061 7261 6d65 7465 7273 3a20 6c69 7374  parameters: list
-00002e20: 206f 6620 666c 6f61 7420 5b32 5d0d 0a20   of float [2].. 
-00002e30: 2020 2020 2020 204c 6f77 6572 2061 6e64         Lower and
-00002e40: 2075 7070 6572 206c 696d 6974 7320 6f66   upper limits of
-00002e50: 2075 6e69 666f 726d 2064 6973 7472 6962   uniform distrib
-00002e60: 7574 696f 6e20 5b61 2c20 625d 0d0a 2020  ution [a, b]..  
-00002e70: 2020 2222 220d 0a20 2020 200d 0a20 2020    """..    ..   
-00002e80: 2064 6174 615f 6d65 616e 203d 206e 702e   data_mean = np.
-00002e90: 6d65 616e 2864 6174 6129 0d0a 2020 2020  mean(data)..    
-00002ea0: 6461 7461 5f73 7464 203d 206e 702e 7374  data_std = np.st
-00002eb0: 6428 6461 7461 290d 0a20 2020 200d 0a20  d(data)..    .. 
-00002ec0: 2020 2023 2066 6974 2062 6574 6120 6469     # fit beta di
-00002ed0: 7374 7269 6275 7469 6f6e 2074 6f20 6461  stribution to da
-00002ee0: 7461 0d0a 2020 2020 6966 2074 7970 6528  ta..    if type(
-00002ef0: 6265 7461 5f74 6f6c 6572 616e 6365 2920  beta_tolerance) 
-00002f00: 6973 206c 6973 743a 0d0a 2020 2020 2020  is list:..      
-00002f10: 2020 615f 6265 7461 203d 2062 6574 615f    a_beta = beta_
-00002f20: 746f 6c65 7261 6e63 655b 305d 0d0a 2020  tolerance[0]..  
-00002f30: 2020 2020 2020 625f 6265 7461 203d 2062        b_beta = b
-00002f40: 6574 615f 746f 6c65 7261 6e63 655b 315d  eta_tolerance[1]
-00002f50: 0d0a 2020 2020 2020 2020 705f 6265 7461  ..        p_beta
-00002f60: 2c20 715f 6265 7461 2c20 615f 6265 7461  , q_beta, a_beta
-00002f70: 2c20 6162 5f62 6574 6120 3d20 7363 6970  , ab_beta = scip
-00002f80: 792e 7374 6174 732e 6265 7461 2e66 6974  y.stats.beta.fit
-00002f90: 2864 6174 612c 2066 6c6f 633d 615f 6265  (data, floc=a_be
-00002fa0: 7461 2c20 6673 6361 6c65 3d62 5f62 6574  ta, fscale=b_bet
-00002fb0: 6120 2d20 615f 6265 7461 290d 0a20 2020  a - a_beta)..   
-00002fc0: 2065 6c69 6620 6265 7461 5f74 6f6c 6572   elif beta_toler
-00002fd0: 616e 6365 203e 2030 3a0d 0a20 2020 2020  ance > 0:..     
-00002fe0: 2020 2023 2075 7365 2075 7365 7220 6265     # use user be
-00002ff0: 7461 5f74 6f6c 6572 616e 6365 206f 6620  ta_tolerance of 
-00003000: 746f 2073 6574 206c 696d 6974 7320 6f66  to set limits of
-00003010: 2064 6973 7472 6962 7574 696f 6e0d 0a20   distribution.. 
-00003020: 2020 2020 2020 2064 6174 615f 7261 6e67         data_rang
-00003030: 6520 3d20 6461 7461 2e6d 6178 2829 2d64  e = data.max()-d
-00003040: 6174 612e 6d69 6e28 290d 0a20 2020 2020  ata.min()..     
-00003050: 2020 2061 5f62 6574 6120 3d20 6461 7461     a_beta = data
-00003060: 2e6d 696e 2829 2d62 6574 615f 746f 6c65  .min()-beta_tole
-00003070: 7261 6e63 652a 6461 7461 5f72 616e 6765  rance*data_range
-00003080: 0d0a 2020 2020 2020 2020 625f 6265 7461  ..        b_beta
-00003090: 203d 2064 6174 612e 6d61 7828 292b 6265   = data.max()+be
-000030a0: 7461 5f74 6f6c 6572 616e 6365 2a64 6174  ta_tolerance*dat
-000030b0: 615f 7261 6e67 650d 0a20 2020 2020 2020  a_range..       
-000030c0: 2070 5f62 6574 612c 2071 5f62 6574 612c   p_beta, q_beta,
-000030d0: 2061 5f62 6574 612c 2061 625f 6265 7461   a_beta, ab_beta
-000030e0: 203d 2073 6369 7079 2e73 7461 7473 2e62   = scipy.stats.b
-000030f0: 6574 612e 6669 7428 6461 7461 2c20 666c  eta.fit(data, fl
-00003100: 6f63 3d61 5f62 6574 612c 2066 7363 616c  oc=a_beta, fscal
-00003110: 653d 625f 6265 7461 2d61 5f62 6574 6129  e=b_beta-a_beta)
-00003120: 0d0a 2020 2020 656c 7365 3a0d 0a20 2020  ..    else:..   
-00003130: 2020 2020 2023 206c 6574 2073 6369 7079       # let scipy
-00003140: 2e73 7461 7473 2e62 6574 612e 6669 7420  .stats.beta.fit 
-00003150: 6465 7465 726d 696e 6520 7468 6520 6c69  determine the li
-00003160: 6d69 7473 0d0a 2020 2020 2020 2020 705f  mits..        p_
-00003170: 6265 7461 2c20 715f 6265 7461 2c20 615f  beta, q_beta, a_
-00003180: 6265 7461 2c20 6162 5f62 6574 6120 3d20  beta, ab_beta = 
-00003190: 7363 6970 792e 7374 6174 732e 6265 7461  scipy.stats.beta
-000031a0: 2e66 6974 2864 6174 6129 0d0a 2020 2020  .fit(data)..    
-000031b0: 2020 2020 625f 6265 7461 203d 2061 5f62      b_beta = a_b
-000031c0: 6574 6120 2b20 6162 5f62 6574 610d 0a20  eta + ab_beta.. 
-000031d0: 2020 200d 0a20 2020 2062 6574 615f 6d65     ..    beta_me
-000031e0: 616e 2c20 6265 7461 5f76 6172 203d 2073  an, beta_var = s
-000031f0: 6369 7079 2e73 7461 7473 2e62 6574 612e  cipy.stats.beta.
-00003200: 7374 6174 7328 705f 6265 7461 2c20 715f  stats(p_beta, q_
-00003210: 6265 7461 2c20 6c6f 633d 615f 6265 7461  beta, loc=a_beta
-00003220: 2c20 7363 616c 653d 2862 5f62 6574 612d  , scale=(b_beta-
-00003230: 615f 6265 7461 292c 206d 6f6d 656e 7473  a_beta), moments
-00003240: 3d27 6d76 2729 0d0a 2020 2020 6265 7461  ='mv')..    beta
-00003250: 5f73 7464 203d 206e 702e 7371 7274 2862  _std = np.sqrt(b
-00003260: 6574 615f 7661 7229 0d0a 2020 2020 0d0a  eta_var)..    ..
-00003270: 2020 2020 6d6f 6d65 6e74 7320 3d20 6e70      moments = np
-00003280: 2e61 7272 6179 285b 6461 7461 5f6d 6561  .array([data_mea
-00003290: 6e2c 2064 6174 615f 7374 642c 2062 6574  n, data_std, bet
-000032a0: 615f 6d65 616e 2c20 6265 7461 5f73 7464  a_mean, beta_std
-000032b0: 5d29 0d0a 0d0a 2020 2020 2320 7065 7266  ])....    # perf
-000032c0: 6f72 6d20 4b6f 6c6d 6f67 6f72 6f76 2053  orm Kolmogorov S
-000032d0: 6d69 726e 6f76 2074 6573 740d 0a20 2020  mirnov test..   
-000032e0: 205f 2c20 705f 7661 6c75 6520 3d20 7363   _, p_value = sc
-000032f0: 6970 792e 7374 6174 732e 6b73 7465 7374  ipy.stats.kstest
-00003300: 2864 6174 612c 2022 6265 7461 222c 205b  (data, "beta", [
-00003310: 705f 6265 7461 2c20 715f 6265 7461 2c20  p_beta, q_beta, 
-00003320: 615f 6265 7461 2c20 6162 5f62 6574 615d  a_beta, ab_beta]
-00003330: 290d 0a0d 0a20 2020 2062 6574 615f 7061  )....    beta_pa
-00003340: 7261 6d65 7465 7273 203d 206e 702e 6172  rameters = np.ar
-00003350: 7261 7928 5b70 5f62 6574 612c 2071 5f62  ray([p_beta, q_b
-00003360: 6574 612c 2061 5f62 6574 612c 2062 5f62  eta, a_beta, b_b
-00003370: 6574 615d 290d 0a0d 0a20 2020 2023 2064  eta])....    # d
-00003380: 6574 6572 6d69 6e65 206c 696d 6974 7320  etermine limits 
-00003390: 6f66 2075 6e69 666f 726d 2064 6973 7472  of uniform distr
-000033a0: 6962 7574 696f 6e20 5b61 5f75 6e69 2c20  ibution [a_uni, 
-000033b0: 625f 756e 695d 2063 6f76 6572 696e 6720  b_uni] covering 
-000033c0: 7468 650d 0a20 2020 2023 2069 6e74 6572  the..    # inter
-000033d0: 7661 6c20 756e 695f 696e 7465 7276 616c  val uni_interval
-000033e0: 206f 6620 7468 6520 6265 7461 2064 6973   of the beta dis
-000033f0: 7472 6962 7574 696f 6e0d 0a20 2020 2069  tribution..    i
-00003400: 6620 7479 7065 2875 6e69 5f69 6e74 6572  f type(uni_inter
-00003410: 7661 6c29 2069 7320 6c69 7374 3a0d 0a20  val) is list:.. 
-00003420: 2020 2020 2020 2061 5f75 6e69 203d 2075         a_uni = u
-00003430: 6e69 5f69 6e74 6572 7661 6c5b 305d 0d0a  ni_interval[0]..
-00003440: 2020 2020 2020 2020 625f 756e 6920 3d20          b_uni = 
-00003450: 756e 695f 696e 7465 7276 616c 5b31 5d0d  uni_interval[1].
-00003460: 0a20 2020 2020 2020 2075 6e69 5f70 6172  .        uni_par
-00003470: 616d 6574 6572 7320 3d20 6e70 2e61 7272  ameters = np.arr
-00003480: 6179 285b 615f 756e 692c 2062 5f75 6e69  ay([a_uni, b_uni
-00003490: 5d29 0d0a 2020 2020 656c 6966 2075 6e69  ])..    elif uni
-000034a0: 5f69 6e74 6572 7661 6c20 3e20 303a 0d0a  _interval > 0:..
-000034b0: 2020 2020 2020 2020 615f 756e 6920 3d20          a_uni = 
-000034c0: 7363 6970 792e 7374 6174 732e 6265 7461  scipy.stats.beta
-000034d0: 2e70 7066 2828 3120 2d20 756e 695f 696e  .ppf((1 - uni_in
-000034e0: 7465 7276 616c 2920 2f20 322c 2070 5f62  terval) / 2, p_b
-000034f0: 6574 612c 2071 5f62 6574 612c 206c 6f63  eta, q_beta, loc
-00003500: 3d61 5f62 6574 612c 2073 6361 6c65 3d62  =a_beta, scale=b
-00003510: 5f62 6574 6120 2d20 615f 6265 7461 290d  _beta - a_beta).
-00003520: 0a20 2020 2020 2020 2062 5f75 6e69 203d  .        b_uni =
-00003530: 2073 6369 7079 2e73 7461 7473 2e62 6574   scipy.stats.bet
-00003540: 612e 7070 6628 2831 202b 2075 6e69 5f69  a.ppf((1 + uni_i
-00003550: 6e74 6572 7661 6c29 202f 2032 2c20 705f  nterval) / 2, p_
-00003560: 6265 7461 2c20 715f 6265 7461 2c20 6c6f  beta, q_beta, lo
-00003570: 633d 615f 6265 7461 2c20 7363 616c 653d  c=a_beta, scale=
-00003580: 625f 6265 7461 202d 2061 5f62 6574 6129  b_beta - a_beta)
-00003590: 0d0a 2020 2020 2020 2020 756e 695f 7061  ..        uni_pa
-000035a0: 7261 6d65 7465 7273 203d 206e 702e 6172  rameters = np.ar
-000035b0: 7261 7928 5b61 5f75 6e69 2c20 625f 756e  ray([a_uni, b_un
-000035c0: 695d 290d 0a20 2020 2065 6c73 653a 0d0a  i])..    else:..
-000035d0: 2020 2020 2020 2020 615f 756e 6920 3d20          a_uni = 
-000035e0: 4e6f 6e65 0d0a 2020 2020 2020 2020 625f  None..        b_
-000035f0: 756e 6920 3d20 4e6f 6e65 0d0a 2020 2020  uni = None..    
-00003600: 2020 2020 756e 695f 7061 7261 6d65 7465      uni_paramete
-00003610: 7273 203d 204e 6f6e 650d 0a0d 0a20 2020  rs = None....   
-00003620: 2069 6620 666e 5f70 6c6f 7420 6973 206e   if fn_plot is n
-00003630: 6f74 204e 6f6e 653a 0d0a 2020 2020 2020  ot None:..      
-00003640: 2020 706c 6f74 5f62 6574 615f 7064 665f    plot_beta_pdf_
-00003650: 6669 7428 6461 7461 3d64 6174 612c 0d0a  fit(data=data,..
-00003660: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003670: 2020 2020 2020 2020 2020 615f 6265 7461            a_beta
-00003680: 3d61 5f62 6574 612c 2062 5f62 6574 613d  =a_beta, b_beta=
-00003690: 625f 6265 7461 2c20 705f 6265 7461 3d70  b_beta, p_beta=p
-000036a0: 5f62 6574 612c 2071 5f62 6574 613d 715f  _beta, q_beta=q_
-000036b0: 6265 7461 2c0d 0a20 2020 2020 2020 2020  beta,..         
-000036c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000036d0: 2061 5f75 6e69 3d61 5f75 6e69 2c20 625f   a_uni=a_uni, b_
-000036e0: 756e 693d 625f 756e 692c 0d0a 2020 2020  uni=b_uni,..    
-000036f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003700: 2020 2020 2020 696e 7465 7261 6374 6976        interactiv
-00003710: 653d 5472 7565 2c20 666e 5f70 6c6f 743d  e=True, fn_plot=
-00003720: 666e 5f70 6c6f 742c 2078 6c61 6265 6c3d  fn_plot, xlabel=
-00003730: 2224 7824 222c 2079 6c61 6265 6c3d 2224  "$x$", ylabel="$
-00003740: 7028 7829 2422 290d 0a0d 0a20 2020 2072  p(x)$")....    r
-00003750: 6574 7572 6e20 6265 7461 5f70 6172 616d  eturn beta_param
-00003760: 6574 6572 732c 206d 6f6d 656e 7473 2c20  eters, moments, 
-00003770: 705f 7661 6c75 652c 2075 6e69 5f70 6172  p_value, uni_par
-00003780: 616d 6574 6572 730d 0a0d 0a0d 0a64 6566  ameters......def
-00003790: 206d 7574 7561 6c5f 636f 6865 7265 6e63   mutual_coherenc
-000037a0: 6528 6172 7261 7929 3a0d 0a20 2020 2022  e(array):..    "
-000037b0: 2222 0d0a 2020 2020 4361 6c63 756c 6174  ""..    Calculat
-000037c0: 6520 7468 6520 6d75 7475 616c 2063 6f68  e the mutual coh
-000037d0: 6572 656e 6365 206f 6620 6120 6d61 7472  erence of a matr
-000037e0: 6978 2041 2e20 4974 2063 616e 2061 6c73  ix A. It can als
-000037f0: 6f20 6265 2072 6566 6572 7265 6420 6173  o be referred as
-00003800: 2074 6865 2063 6f73 696e 6520 6f66 2074   the cosine of t
-00003810: 6865 2073 6d61 6c6c 6573 7420 616e 676c  he smallest angl
-00003820: 650d 0a20 2020 2062 6574 7765 656e 2074  e..    between t
-00003830: 776f 2063 6f6c 756d 6e73 2e0d 0a0d 0a20  wo columns..... 
-00003840: 2020 206d 7574 7561 6c5f 636f 6865 7265     mutual_cohere
-00003850: 6e63 6520 3d20 6d75 7475 616c 5f63 6f68  nce = mutual_coh
-00003860: 6572 656e 6365 2861 7272 6179 290d 0a0d  erence(array)...
-00003870: 0a20 2020 2050 6172 616d 6574 6572 730d  .    Parameters.
-00003880: 0a20 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0d  .    ----------.
-00003890: 0a20 2020 2061 7272 6179 3a20 6e64 6172  .    array: ndar
-000038a0: 7261 7920 6f66 2066 6c6f 6174 0d0a 2020  ray of float..  
-000038b0: 2020 2020 2020 496e 7075 7420 6d61 7472        Input matr
-000038c0: 6978 0d0a 0d0a 2020 2020 5265 7475 726e  ix....    Return
-000038d0: 730d 0a20 2020 202d 2d2d 2d2d 2d2d 0d0a  s..    -------..
-000038e0: 2020 2020 6d75 7475 616c 5f63 6f68 6572      mutual_coher
-000038f0: 656e 6365 3a20 666c 6f61 740d 0a20 2020  ence: float..   
-00003900: 2020 2020 204d 7574 7561 6c20 636f 6865       Mutual cohe
-00003910: 7265 6e63 650d 0a20 2020 2022 2222 0d0a  rence..    """..
-00003920: 0d0a 2020 2020 6172 7261 7920 3d20 6172  ..    array = ar
-00003930: 7261 7920 2f20 6e70 2e6c 696e 616c 672e  ray / np.linalg.
-00003940: 6e6f 726d 2861 7272 6179 2c20 6178 6973  norm(array, axis
-00003950: 3d30 295b 6e70 2e6e 6577 6178 6973 2c20  =0)[np.newaxis, 
-00003960: 3a5d 0d0a 2020 2020 7420 3d20 6e70 2e64  :]..    t = np.d
-00003970: 6f74 2861 7272 6179 2e63 6f6e 6a28 292e  ot(array.conj().
-00003980: 542c 2061 7272 6179 290d 0a20 2020 206e  T, array)..    n
-00003990: 702e 6669 6c6c 5f64 6961 676f 6e61 6c28  p.fill_diagonal(
-000039a0: 742c 2030 2e30 290d 0a20 2020 206d 7520  t, 0.0)..    mu 
-000039b0: 3d20 6e70 2e6d 6178 2874 290d 0a0d 0a20  = np.max(t).... 
-000039c0: 2020 2072 6574 7572 6e20 6d75 0d0a 0d0a     return mu....
-000039d0: 0d0a 6465 6620 5249 5028 412c 2078 293a  ..def RIP(A, x):
-000039e0: 0d0a 2020 2020 2222 220d 0a20 2020 2043  ..    """..    C
-000039f0: 616c 6375 6c61 7465 2074 6865 2072 6573  alculate the res
-00003a00: 7472 6963 7465 6420 6973 6f6d 6574 7269  tricted isometri
-00003a10: 6320 7072 6f70 6572 7479 2063 6f6e 7374  c property const
-00003a20: 616e 7420 6465 6c74 6120 6f66 2061 206d  ant delta of a m
-00003a30: 6174 7269 7820 4120 666f 7220 6120 6769  atrix A for a gi
-00003a40: 7665 6e20 7370 6172 7365 2076 6563 746f  ven sparse vecto
-00003a50: 7220 782e 0d0a 0d0a 2020 2020 6465 6c74  r x.....    delt
-00003a60: 6120 3d20 5249 5028 412c 2078 290d 0a0d  a = RIP(A, x)...
-00003a70: 0a20 2020 2050 6172 616d 6574 6572 730d  .    Parameters.
-00003a80: 0a20 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0d  .    ----------.
-00003a90: 0a20 2020 2041 3a20 6e64 6172 7261 7920  .    A: ndarray 
-00003aa0: 6f66 2066 6c6f 6174 0d0a 2020 2020 2020  of float..      
-00003ab0: 2020 496e 7075 7420 6d61 7472 6978 0d0a    Input matrix..
-00003ac0: 2020 2020 783a 206e 6461 7272 6179 206f      x: ndarray o
-00003ad0: 6620 666c 6f61 740d 0a20 2020 2020 2020  f float..       
-00003ae0: 2061 7070 6c69 6564 2076 6563 746f 720d   applied vector.
-00003af0: 0a20 2020 2052 6574 7572 6e73 0d0a 2020  .    Returns..  
-00003b00: 2020 2d2d 2d2d 2d2d 2d0d 0a20 2020 2064    -------..    d
-00003b10: 656c 7461 3a20 666c 6f61 740d 0a20 2020  elta: float..   
-00003b20: 2020 2020 2072 6573 7472 6963 7465 6420       restricted 
-00003b30: 6973 6f6d 6574 7269 6320 7072 6f70 6572  isometric proper
-00003b40: 7479 2063 6f6e 7374 616e 740d 0a20 2020  ty constant..   
-00003b50: 2022 2222 0d0a 0d0a 2020 2020 6e6f 726d   """....    norm
-00003b60: 5f41 7820 3d20 6e70 2e6c 696e 616c 672e  _Ax = np.linalg.
-00003b70: 6e6f 726d 286e 702e 646f 7428 412c 2078  norm(np.dot(A, x
-00003b80: 2929 0d0a 2020 2020 6e6f 726d 5f78 203d  ))..    norm_x =
-00003b90: 206e 702e 6c69 6e61 6c67 2e6e 6f72 6d28   np.linalg.norm(
-00003ba0: 7829 0d0a 2020 2020 6465 6c74 6120 3d20  x)..    delta = 
-00003bb0: 286e 6f72 6d5f 4178 2a2a 3220 2f20 6e6f  (norm_Ax**2 / no
-00003bc0: 726d 5f78 2a2a 3229 202d 2031 0d0a 0d0a  rm_x**2) - 1....
-00003bd0: 2020 2020 7265 7475 726e 2064 656c 7461      return delta
-00003be0: 0d0a 0d0a 0d0a 6465 6620 7772 6170 5f66  ......def wrap_f
-00003bf0: 756e 6374 696f 6e28 666e 2c20 782c 2061  unction(fn, x, a
-00003c00: 7267 7329 3a0d 0a20 2020 2022 2222 0d0a  rgs):..    """..
-00003c10: 2020 2020 4675 6e63 7469 6f6e 2077 7261      Function wra
-00003c20: 7070 6572 2074 6f20 6361 6c6c 2061 6e6f  pper to call ano
-00003c30: 6e79 6d6f 7573 2066 756e 6374 696f 6e20  nymous function 
-00003c40: 7769 7468 2076 6172 6961 626c 6520 6e75  with variable nu
-00003c50: 6d62 6572 206f 6620 6172 6775 6d65 6e74  mber of argument
-00003c60: 7320 2874 7570 6c65 292e 0d0a 0d0a 2020  s (tuple).....  
-00003c70: 2020 7772 6170 5f66 756e 6374 696f 6e28    wrap_function(
-00003c80: 666e 2c20 782c 2061 7267 7329 0d0a 0d0a  fn, x, args)....
-00003c90: 2020 2020 5061 7261 6d65 7465 7273 0d0a      Parameters..
-00003ca0: 2020 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0d0a      ----------..
-00003cb0: 2020 2020 666e 3a20 6675 6e63 7469 6f6e      fn: function
-00003cc0: 0d0a 2020 2020 2020 2020 616e 6f6e 796d  ..        anonym
-00003cd0: 6f75 7320 6675 6e63 7469 6f6e 2074 6f20  ous function to 
-00003ce0: 6361 6c6c 0d0a 2020 2020 783a 2074 7570  call..    x: tup
-00003cf0: 6c65 0d0a 2020 2020 2020 2020 7061 7261  le..        para
-00003d00: 6d65 7465 7273 206f 6620 6675 6e63 7469  meters of functi
-00003d10: 6f6e 0d0a 2020 2020 6172 6773 3a20 7475  on..    args: tu
-00003d20: 706c 650d 0a20 2020 2020 2020 2061 7267  ple..        arg
-00003d30: 756d 656e 7473 206f 6620 6675 6e63 7469  uments of functi
-00003d40: 6f6e 0d0a 0d0a 2020 2020 5265 7475 726e  on....    Return
-00003d50: 730d 0a20 2020 202d 2d2d 2d2d 2d2d 0d0a  s..    -------..
-00003d60: 2020 2020 6675 6e63 7469 6f6e 5f77 7261      function_wra
-00003d70: 7070 6572 3a20 6675 6e63 7469 6f6e 0d0a  pper: function..
-00003d80: 2020 2020 2020 2020 7772 6170 7065 6420          wrapped 
-00003d90: 6675 6e63 7469 6f6e 0d0a 2020 2020 2222  function..    ""
-00003da0: 220d 0a0d 0a20 2020 2064 6566 2066 756e  "....    def fun
-00003db0: 6374 696f 6e5f 7772 6170 7065 7228 2a77  ction_wrapper(*w
-00003dc0: 7261 7070 6572 5f61 7267 7329 3a0d 0a20  rapper_args):.. 
-00003dd0: 2020 2020 2020 2072 6574 7572 6e20 666e         return fn
-00003de0: 282a 2877 7261 7070 6572 5f61 7267 7320  (*(wrapper_args 
-00003df0: 2b20 7820 2b20 6172 6773 2929 0d0a 0d0a  + x + args))....
-00003e00: 2020 2020 7265 7475 726e 2066 756e 6374      return funct
-00003e10: 696f 6e5f 7772 6170 7065 720d 0a0d 0a0d  ion_wrapper.....
-00003e20: 0a64 6566 2067 6574 5f6e 756d 5f63 6f65  .def get_num_coe
-00003e30: 6666 7328 6f72 6465 722c 2064 696d 293a  ffs(order, dim):
-00003e40: 0d0a 2020 2020 2222 220d 0a20 2020 2043  ..    """..    C
-00003e50: 616c 6375 6c61 7465 2074 6865 206e 756d  alculate the num
-00003e60: 6265 7220 6f66 2067 5043 2063 6f65 6666  ber of gPC coeff
-00003e70: 6963 6965 6e74 7320 6279 2074 6865 206d  icients by the m
-00003e80: 6178 696d 756d 206f 7264 6572 2061 6e64  aximum order and
-00003e90: 2074 6865 206e 756d 6265 7220 6f66 2072   the number of r
-00003ea0: 616e 646f 6d20 7661 7269 6162 6c65 732e  andom variables.
-00003eb0: 0d0a 0d0a 2020 2020 6e75 6d5f 636f 6566  ....    num_coef
-00003ec0: 6673 203d 2028 6f72 6465 722b 6469 6d29  fs = (order+dim)
-00003ed0: 2120 2f20 286f 7264 6572 2120 2a20 6469  ! / (order! * di
-00003ee0: 6d21 290d 0a0d 0a20 2020 206e 756d 5f63  m!)....    num_c
-00003ef0: 6f65 6666 7320 3d20 6765 745f 6e75 6d5f  oeffs = get_num_
-00003f00: 636f 6566 6673 286f 7264 6572 202c 2064  coeffs(order , d
-00003f10: 696d 290d 0a0d 0a20 2020 2050 6172 616d  im)....    Param
-00003f20: 6574 6572 730d 0a20 2020 202d 2d2d 2d2d  eters..    -----
-00003f30: 2d2d 2d2d 2d0d 0a20 2020 206f 7264 6572  -----..    order
-00003f40: 3a20 696e 740d 0a20 2020 2020 2020 204d  : int..        M
-00003f50: 6178 696d 756d 206f 7264 6572 206f 6620  aximum order of 
-00003f60: 6578 7061 6e73 696f 6e0d 0a20 2020 2064  expansion..    d
-00003f70: 696d 3a20 696e 740d 0a20 2020 2020 2020  im: int..       
-00003f80: 204e 756d 6265 7220 6f66 2072 616e 646f   Number of rando
-00003f90: 6d20 7661 7269 6162 6c65 730d 0a0d 0a20  m variables.... 
-00003fa0: 2020 2052 6574 7572 6e73 0d0a 2020 2020     Returns..    
-00003fb0: 2d2d 2d2d 2d2d 2d0d 0a20 2020 206e 756d  -------..    num
-00003fc0: 5f63 6f65 6666 733a 2069 6e74 0d0a 2020  _coeffs: int..  
-00003fd0: 2020 2020 2020 4e75 6d62 6572 206f 6620        Number of 
-00003fe0: 6750 4320 636f 6566 6669 6369 656e 7473  gPC coefficients
-00003ff0: 2061 6e64 2070 6f6c 796e 6f6d 6961 6c73   and polynomials
-00004000: 0d0a 2020 2020 2222 220d 0a0d 0a20 2020  ..    """....   
-00004010: 2072 6574 7572 6e20 7363 6970 792e 7370   return scipy.sp
-00004020: 6563 6961 6c2e 6661 6374 6f72 6961 6c28  ecial.factorial(
-00004030: 6f72 6465 7220 2b20 6469 6d29 202f 2028  order + dim) / (
-00004040: 7363 6970 792e 7370 6563 6961 6c2e 6661  scipy.special.fa
-00004050: 6374 6f72 6961 6c28 6f72 6465 7229 202a  ctorial(order) *
-00004060: 2073 6369 7079 2e73 7065 6369 616c 2e66   scipy.special.f
-00004070: 6163 746f 7269 616c 2864 696d 2929 0d0a  actorial(dim))..
-00004080: 0d0a 0d0a 6465 6620 6765 745f 6e75 6d5f  ....def get_num_
-00004090: 636f 6566 6673 5f73 7061 7273 6528 6f72  coeffs_sparse(or
-000040a0: 6465 725f 6469 6d5f 6d61 782c 206f 7264  der_dim_max, ord
-000040b0: 6572 5f67 6c6f 625f 6d61 782c 206f 7264  er_glob_max, ord
-000040c0: 6572 5f69 6e74 6572 5f6d 6178 2c20 6469  er_inter_max, di
-000040d0: 6d2c 206f 7264 6572 5f69 6e74 6572 5f63  m, order_inter_c
-000040e0: 7572 7265 6e74 3d4e 6f6e 652c 0d0a 2020  urrent=None,..  
-000040f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004100: 2020 2020 2020 2020 6f72 6465 725f 676c          order_gl
-00004110: 6f62 5f6d 6178 5f6e 6f72 6d3d 3129 3a0d  ob_max_norm=1):.
-00004120: 0a20 2020 2022 2222 0d0a 2020 2020 4361  .    """..    Ca
-00004130: 6c63 756c 6174 6520 7468 6520 6e75 6d62  lculate the numb
-00004140: 6572 206f 6620 6750 4320 636f 6566 6669  er of gPC coeffi
-00004150: 6369 656e 7473 2066 6f72 2061 2073 7065  cients for a spe
-00004160: 6369 6669 6320 6d61 7869 6d75 6d20 6f72  cific maximum or
-00004170: 6465 7220 696e 2065 6163 6820 6469 6d65  der in each dime
-00004180: 6e73 696f 6e20 226f 7264 6572 5f64 696d  nsion "order_dim
-00004190: 5f6d 6178 222c 0d0a 2020 2020 676c 6f62  _max",..    glob
-000041a0: 616c 206d 6178 696d 756d 206f 7264 6572  al maximum order
-000041b0: 2022 6f72 6465 725f 676c 6f62 5f6d 6178   "order_glob_max
-000041c0: 2220 616e 6420 7468 6520 696e 7465 7261  " and the intera
-000041d0: 6374 696f 6e20 6f72 6465 7220 226f 7264  ction order "ord
-000041e0: 6572 5f69 6e74 6572 5f6d 6178 222e 0d0a  er_inter_max"...
-000041f0: 0d0a 2020 2020 6e75 6d5f 636f 6566 6673  ..    num_coeffs
-00004200: 5f73 7061 7273 6520 3d20 6765 745f 6e75  _sparse = get_nu
-00004210: 6d5f 636f 6566 6673 5f73 7061 7273 6528  m_coeffs_sparse(
-00004220: 6f72 6465 725f 6469 6d5f 6d61 782c 206f  order_dim_max, o
-00004230: 7264 6572 5f67 6c6f 625f 6d61 782c 206f  rder_glob_max, o
-00004240: 7264 6572 5f69 6e74 6572 5f6d 6178 2c20  rder_inter_max, 
-00004250: 6469 6d29 0d0a 0d0a 2020 2020 5061 7261  dim)....    Para
-00004260: 6d65 7465 7273 0d0a 2020 2020 2d2d 2d2d  meters..    ----
-00004270: 2d2d 2d2d 2d2d 0d0a 2020 2020 6f72 6465  ------..    orde
-00004280: 725f 6469 6d5f 6d61 783a 206e 6461 7272  r_dim_max: ndarr
-00004290: 6179 206f 6620 696e 7420 6f72 206c 6973  ay of int or lis
-000042a0: 7420 6f66 2069 6e74 205b 6469 6d5d 0d0a  t of int [dim]..
-000042b0: 2020 2020 2020 2020 4d61 7869 6d75 6d20          Maximum 
-000042c0: 6f72 6465 7220 696e 2065 6163 6820 6469  order in each di
-000042d0: 6d65 6e73 696f 6e0d 0a20 2020 206f 7264  mension..    ord
-000042e0: 6572 5f67 6c6f 625f 6d61 783a 2069 6e74  er_glob_max: int
-000042f0: 0d0a 2020 2020 2020 2020 4d61 7869 6d75  ..        Maximu
-00004300: 6d20 676c 6f62 616c 206f 7264 6572 206f  m global order o
-00004310: 6620 696e 7465 7261 6374 696e 6720 706f  f interacting po
-00004320: 6c79 6e6f 6d69 616c 730d 0a20 2020 206f  lynomials..    o
-00004330: 7264 6572 5f69 6e74 6572 5f6d 6178 3a20  rder_inter_max: 
-00004340: 696e 740d 0a20 2020 2020 2020 2049 6e74  int..        Int
-00004350: 6572 6163 7469 6f6e 206f 7264 6572 0d0a  eraction order..
-00004360: 2020 2020 6469 6d3a 2069 6e74 0d0a 2020      dim: int..  
-00004370: 2020 2020 2020 4e75 6d62 6572 206f 6620        Number of 
-00004380: 7261 6e64 6f6d 2076 6172 6961 626c 6573  random variables
-00004390: 0d0a 2020 2020 6f72 6465 725f 696e 7465  ..    order_inte
-000043a0: 725f 6375 7272 656e 7420 3a20 696e 740d  r_current : int.
-000043b0: 0a0d 0a20 2020 206f 7264 6572 5f67 6c6f  ...    order_glo
-000043c0: 625f 6d61 785f 6e6f 726d 3a20 666c 6f61  b_max_norm: floa
-000043d0: 740d 0a20 2020 2020 2020 204e 6f72 6d2c  t..        Norm,
-000043e0: 2077 6869 6368 2064 6566 696e 6573 2068   which defines h
-000043f0: 6f77 2074 6865 206f 7264 6572 7320 6172  ow the orders ar
-00004400: 6520 6163 6375 6d75 6c61 7465 6420 746f  e accumulated to
-00004410: 2064 6572 6976 6520 7468 6520 746f 7461   derive the tota
-00004420: 6c20 6f72 6465 7220 2864 6566 6175 6c74  l order (default
-00004430: 3a20 312d 6e6f 726d 292e 0d0a 2020 2020  : 1-norm)...    
-00004440: 2020 2020 5661 6c75 6573 2073 6d61 6c6c      Values small
-00004450: 6572 2074 6861 6e20 6f6e 6520 7265 7374  er than one rest
-00004460: 7269 6374 2068 6967 6865 7220 6f72 6465  rict higher orde
-00004470: 7273 2061 6e64 2073 6872 696e 6b20 7468  rs and shrink th
-00004480: 6520 6261 7369 732e 0d0a 0d0a 2020 2020  e basis.....    
-00004490: 5265 7475 726e 730d 0a20 2020 202d 2d2d  Returns..    ---
-000044a0: 2d2d 2d2d 0d0a 2020 2020 6e75 6d5f 636f  ----..    num_co
-000044b0: 6566 6673 5f73 7061 7273 653a 2069 6e74  effs_sparse: int
-000044c0: 0d0a 2020 2020 2020 2020 4e75 6d62 6572  ..        Number
-000044d0: 206f 6620 6750 4320 636f 6566 6669 6369   of gPC coeffici
-000044e0: 656e 7473 2061 6e64 2070 6f6c 796e 6f6d  ents and polynom
-000044f0: 6961 6c73 0d0a 2020 2020 2222 220d 0a0d  ials..    """...
-00004500: 0a20 2020 2069 6620 6f72 6465 725f 696e  .    if order_in
-00004510: 7465 725f 6375 7272 656e 7420 6973 204e  ter_current is N
-00004520: 6f6e 653a 0d0a 2020 2020 2020 2020 6f72  one:..        or
-00004530: 6465 725f 696e 7465 725f 6375 7272 656e  der_inter_curren
-00004540: 7420 3d20 6f72 6465 725f 696e 7465 725f  t = order_inter_
-00004550: 6d61 780d 0a0d 0a20 2020 2069 6620 7479  max....    if ty
-00004560: 7065 286f 7264 6572 5f64 696d 5f6d 6178  pe(order_dim_max
-00004570: 2920 6973 206c 6973 743a 0d0a 2020 2020  ) is list:..    
-00004580: 2020 2020 6f72 6465 725f 6469 6d5f 6d61      order_dim_ma
-00004590: 7820 3d20 6e70 2e61 7272 6179 286f 7264  x = np.array(ord
-000045a0: 6572 5f64 696d 5f6d 6178 290d 0a0d 0a20  er_dim_max).... 
-000045b0: 2020 2069 6620 6f72 6465 725f 6469 6d5f     if order_dim_
-000045c0: 6d61 782e 7369 7a65 203d 3d20 313a 0d0a  max.size == 1:..
-000045d0: 2020 2020 2020 2020 6f72 6465 725f 6469          order_di
-000045e0: 6d5f 6d61 7820 3d20 6f72 6465 725f 6469  m_max = order_di
-000045f0: 6d5f 6d61 7820 2a20 6e70 2e6f 6e65 7328  m_max * np.ones(
-00004600: 6469 6d29 0d0a 0d0a 2020 2020 2320 6765  dim)....    # ge
-00004610: 6e65 7261 7465 206d 756c 7469 2d69 6e64  nerate multi-ind
-00004620: 6578 206c 6973 7420 7570 2074 6f20 6d61  ex list up to ma
-00004630: 7869 6d75 6d20 6f72 6465 720d 0a20 2020  ximum order..   
-00004640: 2069 6620 6469 6d20 3d3d 2031 3a0d 0a20   if dim == 1:.. 
-00004650: 2020 2020 2020 2070 6f6c 795f 6964 7820         poly_idx 
-00004660: 3d20 6e70 2e61 7272 6179 285b 6e70 2e6c  = np.array([np.l
-00004670: 696e 7370 6163 6528 302c 206f 7264 6572  inspace(0, order
-00004680: 5f64 696d 5f6d 6178 5b30 5d2c 2069 6e74  _dim_max[0], int
-00004690: 286f 7264 6572 5f64 696d 5f6d 6178 5b30  (order_dim_max[0
-000046a0: 5d20 2b20 3129 295d 292e 6173 7479 7065  ] + 1))]).astype
-000046b0: 2869 6e74 292e 7472 616e 7370 6f73 6528  (int).transpose(
-000046c0: 290d 0a20 2020 2065 6c73 653a 0d0a 2020  )..    else:..  
-000046d0: 2020 2020 2020 706f 6c79 5f69 6478 203d        poly_idx =
-000046e0: 2067 6574 5f6d 756c 7469 5f69 6e64 6963   get_multi_indic
-000046f0: 6573 286f 7264 6572 3d6f 7264 6572 5f64  es(order=order_d
-00004700: 696d 5f6d 6178 2c0d 0a20 2020 2020 2020  im_max,..       
-00004710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004720: 2020 2020 2020 2020 2020 2020 2020 6f72                or
-00004730: 6465 725f 6d61 783d 6f72 6465 725f 676c  der_max=order_gl
-00004740: 6f62 5f6d 6178 2c0d 0a20 2020 2020 2020  ob_max,..       
-00004750: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004760: 2020 2020 2020 2020 2020 2020 2020 696e                in
-00004770: 7465 7261 6374 696f 6e5f 6f72 6465 723d  teraction_order=
-00004780: 6f72 6465 725f 696e 7465 725f 6d61 782c  order_inter_max,
-00004790: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-000047a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000047b0: 2020 2020 2020 206f 7264 6572 5f6d 6178         order_max
-000047c0: 5f6e 6f72 6d3d 6f72 6465 725f 676c 6f62  _norm=order_glob
-000047d0: 5f6d 6178 5f6e 6f72 6d2c 0d0a 2020 2020  _max_norm,..    
-000047e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000047f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004800: 2069 6e74 6572 6163 7469 6f6e 5f6f 7264   interaction_ord
-00004810: 6572 5f63 7572 7265 6e74 3d6f 7264 6572  er_current=order
-00004820: 5f69 6e74 6572 5f63 7572 7265 6e74 290d  _inter_current).
-00004830: 0a0d 0a20 2020 2066 6f72 2069 5f64 696d  ...    for i_dim
-00004840: 2069 6e20 7261 6e67 6528 6469 6d29 3a0d   in range(dim):.
-00004850: 0a20 2020 2020 2020 2023 2061 6464 206d  .        # add m
-00004860: 756c 7469 2d69 6e64 6578 6573 2074 6f20  ulti-indexes to 
-00004870: 6c69 7374 2077 6865 6e20 6e6f 7420 7965  list when not ye
-00004880: 7420 696e 636c 7564 6564 0d0a 2020 2020  t included..    
-00004890: 2020 2020 6966 206f 7264 6572 5f64 696d      if order_dim
-000048a0: 5f6d 6178 5b69 5f64 696d 5d20 3e20 6f72  _max[i_dim] > or
-000048b0: 6465 725f 676c 6f62 5f6d 6178 3a0d 0a20  der_glob_max:.. 
-000048c0: 2020 2020 2020 2020 2020 2070 6f6c 795f             poly_
-000048d0: 6164 645f 6469 6d20 3d20 6e70 2e6c 696e  add_dim = np.lin
-000048e0: 7370 6163 6528 6f72 6465 725f 676c 6f62  space(order_glob
-000048f0: 5f6d 6178 202b 2031 2c0d 0a20 2020 2020  _max + 1,..     
-00004900: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004910: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004920: 2020 6f72 6465 725f 6469 6d5f 6d61 785b    order_dim_max[
-00004930: 695f 6469 6d5d 2c0d 0a20 2020 2020 2020  i_dim],..       
-00004940: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004960: 6f72 6465 725f 6469 6d5f 6d61 785b 695f  order_dim_max[i_
-00004970: 6469 6d5d 202d 2028 6f72 6465 725f 676c  dim] - (order_gl
-00004980: 6f62 5f6d 6178 202b 2031 2920 2b20 3129  ob_max + 1) + 1)
-00004990: 0d0a 2020 2020 2020 2020 2020 2020 706f  ..            po
-000049a0: 6c79 5f61 6464 5f61 6c6c 203d 206e 702e  ly_add_all = np.
-000049b0: 7a65 726f 7328 5b70 6f6c 795f 6164 645f  zeros([poly_add_
-000049c0: 6469 6d2e 7368 6170 655b 305d 2c20 6469  dim.shape[0], di
-000049d0: 6d5d 290d 0a20 2020 2020 2020 2020 2020  m])..           
-000049e0: 2070 6f6c 795f 6164 645f 616c 6c5b 3a2c   poly_add_all[:,
-000049f0: 2069 5f64 696d 5d20 3d20 706f 6c79 5f61   i_dim] = poly_a
-00004a00: 6464 5f64 696d 0d0a 2020 2020 2020 2020  dd_dim..        
-00004a10: 2020 2020 706f 6c79 5f69 6478 203d 206e      poly_idx = n
-00004a20: 702e 7673 7461 636b 285b 706f 6c79 5f69  p.vstack([poly_i
-00004a30: 6478 2c20 706f 6c79 5f61 6464 5f61 6c6c  dx, poly_add_all
-00004a40: 2e61 7374 7970 6528 696e 7429 5d29 0d0a  .astype(int)])..
-00004a50: 0d0a 2020 2020 2020 2020 2320 6465 6c65  ..        # dele
-00004a60: 7465 206d 756c 7469 2d69 6e64 6578 6573  te multi-indexes
-00004a70: 2066 726f 6d20 6c69 7374 2077 6865 6e20   from list when 
-00004a80: 7468 6579 2065 7863 6565 6420 696e 6469  they exceed indi
-00004a90: 7669 6475 616c 206d 6178 206f 7264 6572  vidual max order
-00004aa0: 206f 6620 7061 7261 6d65 7465 720d 0a20   of parameter.. 
-00004ab0: 2020 2020 2020 2065 6c69 6620 6f72 6465         elif orde
-00004ac0: 725f 6469 6d5f 6d61 785b 695f 6469 6d5d  r_dim_max[i_dim]
-00004ad0: 203c 206f 7264 6572 5f67 6c6f 625f 6d61   < order_glob_ma
-00004ae0: 783a 0d0a 2020 2020 2020 2020 2020 2020  x:..            
-00004af0: 706f 6c79 5f69 6478 203d 2070 6f6c 795f  poly_idx = poly_
-00004b00: 6964 785b 706f 6c79 5f69 6478 5b3a 2c20  idx[poly_idx[:, 
-00004b10: 695f 6469 6d5d 203c 3d20 6f72 6465 725f  i_dim] <= order_
-00004b20: 6469 6d5f 6d61 785b 695f 6469 6d5d 2c20  dim_max[i_dim], 
-00004b30: 3a5d 0d0a 0d0a 2020 2020 2320 436f 6e73  :]....    # Cons
-00004b40: 6964 6572 2069 6e74 6572 6163 7469 6f6e  ider interaction
-00004b50: 206f 7264 6572 2028 6669 6c74 6572 206f   order (filter o
-00004b60: 7574 206d 756c 7469 2d69 6e64 6963 6573  ut multi-indices
-00004b70: 2065 7863 6565 6469 6e67 2069 7429 0d0a   exceeding it)..
-00004b80: 2020 2020 706f 6c79 5f69 6478 203d 2070      poly_idx = p
-00004b90: 6f6c 795f 6964 785b 6e70 2e73 756d 2870  oly_idx[np.sum(p
-00004ba0: 6f6c 795f 6964 7820 3e20 302c 2061 7869  oly_idx > 0, axi
-00004bb0: 733d 3129 203c 3d20 6f72 6465 725f 696e  s=1) <= order_in
-00004bc0: 7465 725f 6d61 782c 203a 5d0d 0a0d 0a20  ter_max, :].... 
-00004bd0: 2020 2072 6574 7572 6e20 706f 6c79 5f69     return poly_i
-00004be0: 6478 2e73 6861 7065 5b30 5d0d 0a0d 0a0d  dx.shape[0].....
-00004bf0: 0a64 6566 2067 6574 5f70 6466 5f62 6574  .def get_pdf_bet
-00004c00: 6128 782c 2070 2c20 712c 2061 2c20 6229  a(x, p, q, a, b)
-00004c10: 3a0d 0a20 2020 2022 2222 0d0a 2020 2020  :..    """..    
-00004c20: 4361 6c63 756c 6174 6520 7468 6520 7072  Calculate the pr
-00004c30: 6f62 6162 696c 6974 7920 6465 6e73 6974  obability densit
-00004c40: 7920 6675 6e63 7469 6f6e 206f 6620 7468  y function of th
-00004c50: 6520 6265 7461 2064 6973 7472 6962 7574  e beta distribut
-00004c60: 696f 6e20 696e 2074 6865 2069 6e74 6572  ion in the inter
-00004c70: 7661 6c20 5b61 2c20 625d 2e0d 0a0d 0a20  val [a, b]..... 
-00004c80: 2020 2070 6466 203d 2028 6761 6d6d 6128     pdf = (gamma(
-00004c90: 7029 2a67 616d 6d61 2871 292f 6761 6d6d  p)*gamma(q)/gamm
-00004ca0: 6128 702b 7129 2e2a 2862 2d61 292a 2a28  a(p+q).*(b-a)**(
-00004cb0: 702b 712d 3129 292a 2a28 2d31 2920 2a0d  p+q-1))**(-1) *.
-00004cc0: 0a20 2020 2020 2020 2020 2020 2020 2028  .              (
-00004cd0: 782d 6129 2a2a 2870 2d31 2920 2a20 2862  x-a)**(p-1) * (b
-00004ce0: 2d78 292a 2a28 712d 3129 3b0d 0a0d 0a20  -x)**(q-1);.... 
-00004cf0: 2020 2070 6466 203d 2067 6574 5f70 6466     pdf = get_pdf
-00004d00: 5f62 6574 6128 782c 2070 2c20 712c 2061  _beta(x, p, q, a
-00004d10: 2c20 6229 0d0a 0d0a 2020 2020 5061 7261  , b)....    Para
-00004d20: 6d65 7465 7273 0d0a 2020 2020 2d2d 2d2d  meters..    ----
-00004d30: 2d2d 2d2d 2d2d 0d0a 2020 2020 783a 206e  ------..    x: n
-00004d40: 6461 7272 6179 206f 6620 666c 6f61 740d  darray of float.
-00004d50: 0a20 2020 2020 2020 2056 616c 7565 7320  .        Values 
-00004d60: 6f66 2072 616e 646f 6d20 7661 7269 6162  of random variab
-00004d70: 6c65 0d0a 2020 2020 613a 2066 6c6f 6174  le..    a: float
-00004d80: 0d0a 2020 2020 2020 2020 6c6f 7765 7220  ..        lower 
-00004d90: 626f 756e 6461 7279 0d0a 2020 2020 623a  boundary..    b:
-00004da0: 2066 6c6f 6174 0d0a 2020 2020 2020 2020   float..        
-00004db0: 7570 7065 7220 626f 756e 6461 7279 0d0a  upper boundary..
-00004dc0: 2020 2020 703a 2066 6c6f 6174 0d0a 2020      p: float..  
-00004dd0: 2020 2020 2020 4669 7273 7420 7368 6170        First shap
-00004de0: 6520 7061 7261 6d65 7465 7220 6465 6669  e parameter defi
-00004df0: 6e69 6e67 2074 6865 2064 6973 7472 6962  ning the distrib
-00004e00: 7574 696f 6e0d 0a20 2020 2071 3a20 666c  ution..    q: fl
-00004e10: 6f61 740d 0a20 2020 2020 2020 2053 6563  oat..        Sec
-00004e20: 6f6e 6420 7368 6170 6520 7061 7261 6d65  ond shape parame
-00004e30: 7465 7220 6465 6669 6e69 6e67 2074 6865  ter defining the
-00004e40: 2064 6973 7472 6962 7574 696f 6e0d 0a0d   distribution...
-00004e50: 0a20 2020 2052 6574 7572 6e73 0d0a 2020  .    Returns..  
-00004e60: 2020 2d2d 2d2d 2d2d 2d0d 0a20 2020 2070    -------..    p
-00004e70: 6466 3a20 6e64 6172 7261 7920 6f66 2066  df: ndarray of f
-00004e80: 6c6f 6174 0d0a 2020 2020 2020 2020 5072  loat..        Pr
-00004e90: 6f62 6162 696c 6974 7920 6465 6e73 6974  obability densit
-00004ea0: 790d 0a20 2020 2022 2222 0d0a 2020 2020  y..    """..    
-00004eb0: 7265 7475 726e 2028 7363 6970 792e 7370  return (scipy.sp
-00004ec0: 6563 6961 6c2e 6761 6d6d 6128 7029 202a  ecial.gamma(p) *
-00004ed0: 2073 6369 7079 2e73 7065 6369 616c 2e67   scipy.special.g
-00004ee0: 616d 6d61 2871 2920 2f20 7363 6970 792e  amma(q) / scipy.
-00004ef0: 7370 6563 6961 6c2e 6761 6d6d 6128 7020  special.gamma(p 
-00004f00: 2b20 7129 0d0a 2020 2020 2020 2020 2020  + q)..          
-00004f10: 2020 2a20 2862 202d 2061 2920 2a2a 2028    * (b - a) ** (
-00004f20: 7020 2b20 7120 2d20 3129 2920 2a2a 2028  p + q - 1)) ** (
-00004f30: 2d31 2920 2a20 2878 202d 2061 2920 2a2a  -1) * (x - a) **
-00004f40: 2028 7020 2d20 3129 202a 2028 6220 2d20   (p - 1) * (b - 
-00004f50: 7829 202a 2a20 2871 202d 2031 290d 0a0d  x) ** (q - 1)...
-00004f60: 0a0d 0a64 6566 2067 6574 5f61 6c6c 5f63  ...def get_all_c
-00004f70: 6f6d 6269 6e61 7469 6f6e 7328 6172 7261  ombinations(arra
-00004f80: 792c 206e 756d 6265 725f 656c 656d 656e  y, number_elemen
-00004f90: 7473 293a 0d0a 2020 2020 2222 220d 0a20  ts):..    """.. 
-00004fa0: 2020 2043 6f6d 7075 7465 2061 6c6c 206b     Compute all k
-00004fb0: 2d74 7570 6c65 7320 2865 5f31 2c20 655f  -tuples (e_1, e_
-00004fc0: 322c 202e 2e2e 2c20 655f 6b29 206f 6620  2, ..., e_k) of 
-00004fd0: 636f 6d62 696e 6174 696f 6e73 206f 6620  combinations of 
-00004fe0: 7468 6520 7365 7420 6f66 2065 6c65 6d65  the set of eleme
-00004ff0: 6e74 7320 6f66 2074 6865 2069 6e70 7574  nts of the input
-00005000: 2061 7272 6179 2077 6865 7265 0d0a 2020   array where..  
-00005010: 2020 655f 6e2b 3120 3e20 655f 6e2e 0d0a    e_n+1 > e_n...
-00005020: 2020 2020 636f 6d62 696e 6174 696f 6e73      combinations
-00005030: 203d 2067 6574 5f61 6c6c 5f63 6f6d 6269   = get_all_combi
-00005040: 6e61 7469 6f6e 7328 6172 7261 792c 206e  nations(array, n
-00005050: 756d 6265 725f 656c 656d 656e 7473 290d  umber_elements).
-00005060: 0a20 2020 2050 6172 616d 6574 6572 730d  .    Parameters.
-00005070: 0a20 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0d  .    ----------.
-00005080: 0a20 2020 2061 7272 6179 3a20 6e70 2e6e  .    array: np.n
-00005090: 6461 7272 6179 0d0a 2020 2020 2020 2020  darray..        
-000050a0: 4172 7261 7920 746f 2070 6572 666f 726d  Array to perform
-000050b0: 2074 6865 2063 6f6d 6269 6e61 746f 7269   the combinatori
-000050c0: 616c 2070 726f 626c 656d 2077 6974 680d  al problem with.
-000050d0: 0a20 2020 206e 756d 6265 725f 656c 656d  .    number_elem
-000050e0: 656e 7473 3a20 696e 740d 0a20 2020 2020  ents: int..     
-000050f0: 2020 204e 756d 6265 7220 6f66 2065 6c65     Number of ele
-00005100: 6d65 6e74 7320 696e 2074 7570 6c65 0d0a  ments in tuple..
-00005110: 2020 2020 5265 7475 726e 730d 0a20 2020      Returns..   
-00005120: 202d 2d2d 2d2d 2d2d 0d0a 2020 2020 636f   -------..    co
-00005130: 6d62 696e 6174 696f 6e73 3a20 6e70 2e6e  mbinations: np.n
-00005140: 6461 7272 6179 0d0a 2020 2020 2020 2020  darray..        
-00005150: 4172 7261 7920 6f66 2063 6f6d 6269 6e61  Array of combina
-00005160: 7469 6f6e 2076 6563 746f 7273 0d0a 2020  tion vectors..  
-00005170: 2020 2222 220d 0a0d 0a20 2020 2063 6f6d    """....    com
-00005180: 6269 6e61 7469 6f6e 7320 3d20 6974 6572  binations = iter
-00005190: 746f 6f6c 732e 636f 6d62 696e 6174 696f  tools.combinatio
-000051a0: 6e73 2861 7272 6179 2c20 6e75 6d62 6572  ns(array, number
-000051b0: 5f65 6c65 6d65 6e74 7329 0d0a 2020 2020  _elements)..    
-000051c0: 7265 7475 726e 206e 702e 6172 7261 7928  return np.array(
-000051d0: 5b63 2066 6f72 2063 2069 6e20 636f 6d62  [c for c in comb
-000051e0: 696e 6174 696f 6e73 5d29 0d0a 0d0a 0d0a  inations])......
-000051f0: 6465 6620 6765 745f 6d75 6c74 695f 696e  def get_multi_in
-00005200: 6469 6365 7328 6f72 6465 722c 206f 7264  dices(order, ord
-00005210: 6572 5f6d 6178 2c20 696e 7465 7261 6374  er_max, interact
-00005220: 696f 6e5f 6f72 6465 722c 206f 7264 6572  ion_order, order
-00005230: 5f6d 6178 5f6e 6f72 6d3d 312e 2c20 696e  _max_norm=1., in
-00005240: 7465 7261 6374 696f 6e5f 6f72 6465 725f  teraction_order_
-00005250: 6375 7272 656e 743d 4e6f 6e65 293a 0d0a  current=None):..
-00005260: 2020 2020 2222 220d 0a20 2020 2043 6f6d      """..    Com
-00005270: 7075 7465 7320 616c 6c20 6d75 6c74 692d  putes all multi-
-00005280: 696e 6469 6365 7320 7769 7468 2061 206d  indices with a m
-00005290: 6178 696d 756d 206f 7665 7261 6c6c 206f  aximum overall o
-000052a0: 7264 6572 206f 6620 6d61 785f 6f72 6465  rder of max_orde
-000052b0: 7220 636f 6e73 6964 6572 696e 6720 6120  r considering a 
-000052c0: 6365 7274 6169 6e20 6d61 7869 6d75 6d20  certain maximum 
-000052d0: 6f72 6465 7220 6e6f 726d 2e0d 0a0d 0a20  order norm..... 
-000052e0: 2020 206d 756c 7469 5f69 6e64 6963 6573     multi_indices
-000052f0: 203d 2067 6574 5f6d 756c 7469 5f69 6e64   = get_multi_ind
-00005300: 6963 6573 286c 656e 6774 682c 206d 6178  ices(length, max
-00005310: 5f6f 7264 6572 290d 0a0d 0a20 2020 2050  _order)....    P
-00005320: 6172 616d 6574 6572 730d 0a20 2020 202d  arameters..    -
-00005330: 2d2d 2d2d 2d2d 2d2d 2d0d 0a20 2020 206f  ---------..    o
-00005340: 7264 6572 203a 206c 6973 7420 6f66 2069  rder : list of i
-00005350: 6e74 205b 6469 6d5d 0d0a 2020 2020 2020  nt [dim]..      
-00005360: 2020 4d61 7869 6d75 6d20 696e 6469 7669    Maximum indivi
-00005370: 6475 616c 2065 7870 616e 7369 6f6e 206f  dual expansion o
-00005380: 7264 6572 0d0a 2020 2020 2020 2020 4765  rder..        Ge
-00005390: 6e65 7261 7465 7320 696e 6469 7669 6475  nerates individu
-000053a0: 616c 2070 6f6c 796e 6f6d 6961 6c73 2061  al polynomials a
-000053b0: 6c73 6f20 6966 206d 6178 696d 756d 2065  lso if maximum e
-000053c0: 7870 616e 7369 6f6e 206f 7264 6572 2069  xpansion order i
-000053d0: 6e20 6f72 6465 725f 6d61 7820 6973 2065  n order_max is e
-000053e0: 7863 6565 6465 640d 0a20 2020 206f 7264  xceeded..    ord
-000053f0: 6572 5f6d 6178 203a 2069 6e74 0d0a 2020  er_max : int..  
-00005400: 2020 2020 2020 4d61 7869 6d75 6d20 676c        Maximum gl
-00005410: 6f62 616c 2065 7870 616e 7369 6f6e 206f  obal expansion o
-00005420: 7264 6572 2e0d 0a20 2020 2020 2020 2054  rder...        T
-00005430: 6865 206d 6178 696d 756d 2065 7870 616e  he maximum expan
-00005440: 7369 6f6e 206f 7264 6572 2063 6f6e 7369  sion order consi
-00005450: 6465 7273 2074 6865 2073 756d 206f 6620  ders the sum of 
-00005460: 7468 6520 6f72 6465 7273 206f 6620 636f  the orders of co
-00005470: 6d62 696e 6564 2070 6f6c 796e 6f6d 6961  mbined polynomia
-00005480: 6c73 2074 6f67 6574 6865 7220 7769 7468  ls together with
-00005490: 2074 6865 0d0a 2020 2020 2020 2020 6368   the..        ch
-000054a0: 6f73 656e 206e 6f72 6d20 226f 7264 6572  osen norm "order
-000054b0: 5f6d 6178 5f6e 6f72 6d22 2e20 5479 7069  _max_norm". Typi
-000054c0: 6361 6c6c 7920 7468 6973 206e 6f72 6d20  cally this norm 
-000054d0: 6973 2031 2073 7563 6820 7468 6174 2074  is 1 such that t
-000054e0: 6865 206d 6178 696d 756d 206f 7264 6572  he maximum order
-000054f0: 2069 7320 7468 6520 7375 6d20 6f66 2061   is the sum of a
-00005500: 6c6c 0d0a 2020 2020 2020 2020 6d6f 6e6f  ll..        mono
-00005510: 6d69 616c 206f 7264 6572 732e 0d0a 2020  mial orders...  
-00005520: 2020 6f72 6465 725f 6d61 785f 6e6f 726d    order_max_norm
-00005530: 203a 2066 6c6f 6174 0d0a 2020 2020 2020   : float..      
-00005540: 2020 4e6f 726d 2066 6f72 2077 6869 6368    Norm for which
-00005550: 2074 6865 206d 6178 696d 756d 2067 6c6f   the maximum glo
-00005560: 6261 6c20 6578 7061 6e73 696f 6e20 6f72  bal expansion or
-00005570: 6465 7220 6973 2064 6566 696e 6564 205b  der is defined [
-00005580: 302c 2031 5d2e 2056 616c 7565 7320 3c20  0, 1]. Values < 
-00005590: 3120 6465 6372 6561 7365 2074 6865 2074  1 decrease the t
-000055a0: 6f74 616c 206e 756d 6265 720d 0a20 2020  otal number..   
-000055b0: 2020 2020 206f 6620 706f 6c79 6e6f 6d69       of polynomi
-000055c0: 616c 7320 696e 2074 6865 2065 7870 616e  als in the expan
-000055d0: 7369 6f6e 2073 7563 6820 7468 6174 2069  sion such that i
-000055e0: 6e74 6572 6163 7469 6f6e 2074 6572 6d73  nteraction terms
-000055f0: 2061 7265 2070 656e 616c 697a 6564 206d   are penalized m
-00005600: 6f72 652e 0d0a 2020 2020 2020 2020 7375  ore...        su
-00005610: 6d28 615f 695e 7129 5e31 2f71 203c 3d20  m(a_i^q)^1/q <= 
-00005620: 702c 2077 6865 7265 2070 2069 7320 6f72  p, where p is or
-00005630: 6465 725f 6d61 7820 616e 6420 7120 6973  der_max and q is
-00005640: 206f 7264 6572 5f6d 6178 5f6e 6f72 6d20   order_max_norm 
-00005650: 2866 6f72 206d 6f72 6520 6465 7461 696c  (for more detail
-00005660: 7320 7365 6520 6571 2028 3131 2920 696e  s see eq (11) in
-00005670: 205b 315d 292e 0d0a 2020 2020 696e 7465   [1])...    inte
-00005680: 7261 6374 696f 6e5f 6f72 6465 7220 3a20  raction_order : 
-00005690: 696e 740d 0a20 2020 2020 2020 204e 756d  int..        Num
-000056a0: 6265 7220 6f66 2072 616e 646f 6d20 7661  ber of random va
-000056b0: 7269 6162 6c65 732c 2077 6869 6368 2063  riables, which c
-000056c0: 616e 2069 6e74 6572 6163 7420 7769 7468  an interact with
-000056d0: 2065 6163 6820 6f74 6865 720d 0a20 2020   each other..   
-000056e0: 2069 6e74 6572 6163 7469 6f6e 5f6f 7264   interaction_ord
-000056f0: 6572 5f63 7572 7265 6e74 203a 2069 6e74  er_current : int
-00005700: 2c20 6f70 7469 6f6e 616c 2c20 6465 6661  , optional, defa
-00005710: 756c 743a 2069 6e74 6572 6163 7469 6f6e  ult: interaction
-00005720: 5f6f 7264 6572 0d0a 2020 2020 2020 2020  _order..        
-00005730: 4e75 6d62 6572 206f 6620 7261 6e64 6f6d  Number of random
-00005740: 2076 6172 6961 626c 6573 2063 7572 7265   variables curre
-00005750: 6e74 6c79 2069 6e74 6572 6163 7469 6e67  ntly interacting
-00005760: 2077 6974 6820 7265 7370 6563 7420 746f   with respect to
-00005770: 2074 6865 2068 6967 6865 7374 206f 7264   the highest ord
-00005780: 6572 2e0d 0a20 2020 2020 2020 2028 696e  er...        (in
-00005790: 7465 7261 6374 696f 6e5f 6f72 6465 725f  teraction_order_
-000057a0: 6375 7272 656e 7420 3c3d 2069 6e74 6572  current <= inter
-000057b0: 6163 7469 6f6e 5f6f 7264 6572 290d 0a20  action_order).. 
-000057c0: 2020 2020 2020 2054 6865 2070 6172 616d         The param
-000057d0: 6574 6572 7320 666f 7220 6c6f 7765 7220  eters for lower 
-000057e0: 6f72 6465 7273 2061 7265 2061 6c6c 2069  orders are all i
-000057f0: 6e74 6572 6163 7469 6e67 2077 6974 6820  nteracting with 
-00005800: 696e 7465 7261 6374 696f 6e5f 6f72 6465  interaction_orde
-00005810: 722e 0d0a 0d0a 2020 2020 5265 7475 726e  r.....    Return
-00005820: 730d 0a20 2020 202d 2d2d 2d2d 2d2d 0d0a  s..    -------..
-00005830: 2020 2020 6d75 6c74 695f 696e 6469 6365      multi_indice
-00005840: 733a 206e 6461 7272 6179 205b 6e5f 6261  s: ndarray [n_ba
-00005850: 7369 7320 7820 6469 6d5d 0d0a 2020 2020  sis x dim]..    
-00005860: 2020 2020 4d75 6c74 692d 696e 6469 6365      Multi-indice
-00005870: 7320 666f 7220 6120 6d61 7869 6d75 6d20  s for a maximum 
-00005880: 6f72 6465 7220 6750 4320 6173 7375 6d69  order gPC assumi
-00005890: 6e67 2061 2063 6572 7461 696e 206f 7264  ng a certain ord
-000058a0: 6572 206e 6f72 6d2e 0d0a 2020 2020 2222  er norm...    ""
-000058b0: 220d 0a0d 0a20 2020 2064 696d 203d 206c  "....    dim = l
-000058c0: 656e 286f 7264 6572 290d 0a0d 0a20 2020  en(order)....   
-000058d0: 206f 7264 6572 5f6d 6178 203d 2069 6e74   order_max = int
-000058e0: 286f 7264 6572 5f6d 6178 290d 0a20 2020  (order_max)..   
-000058f0: 206f 7264 6572 203d 205b 696e 7428 6f29   order = [int(o)
-00005900: 2066 6f72 206f 2069 6e20 6f72 6465 725d   for o in order]
-00005910: 0d0a 0d0a 2020 2020 6966 2069 6e74 6572  ....    if inter
-00005920: 6163 7469 6f6e 5f6f 7264 6572 5f63 7572  action_order_cur
-00005930: 7265 6e74 2069 7320 4e6f 6e65 206f 7220  rent is None or 
-00005940: 696e 7465 7261 6374 696f 6e5f 6f72 6465  interaction_orde
-00005950: 725f 6375 7272 656e 7420 3e20 696e 7465  r_current > inte
-00005960: 7261 6374 696f 6e5f 6f72 6465 723a 0d0a  raction_order:..
-00005970: 2020 2020 2020 2020 696e 7465 7261 6374          interact
-00005980: 696f 6e5f 6f72 6465 725f 6375 7272 656e  ion_order_curren
-00005990: 7420 3d20 696e 7465 7261 6374 696f 6e5f  t = interaction_
-000059a0: 6f72 6465 720d 0a20 2020 2065 6c73 653a  order..    else:
-000059b0: 0d0a 2020 2020 2020 2020 696e 7465 7261  ..        intera
-000059c0: 6374 696f 6e5f 6f72 6465 725f 6375 7272  ction_order_curr
-000059d0: 656e 7420 3d20 696e 7465 7261 6374 696f  ent = interactio
-000059e0: 6e5f 6f72 6465 725f 6375 7272 656e 740d  n_order_current.
-000059f0: 0a0d 0a20 2020 206d 756c 7469 5f69 6e64  ...    multi_ind
-00005a00: 6963 6573 203d 205b 5d0d 0a20 2020 2066  ices = []..    f
-00005a10: 6f72 2069 5f6f 7264 6572 5f6d 6178 2069  or i_order_max i
-00005a20: 6e20 7261 6e67 6528 6f72 6465 725f 6d61  n range(order_ma
-00005a30: 7820 2b20 3129 3a0d 0a20 2020 2020 2020  x + 1):..       
-00005a40: 2073 203d 2067 6574 5f61 6c6c 5f63 6f6d   s = get_all_com
-00005a50: 6269 6e61 7469 6f6e 7328 6e70 2e61 7261  binations(np.ara
-00005a60: 6e67 6528 6469 6d20 2b20 695f 6f72 6465  nge(dim + i_orde
-00005a70: 725f 6d61 7820 2d20 3129 202b 2031 2c20  r_max - 1) + 1, 
-00005a80: 6469 6d20 2d20 3129 0d0a 0d0a 2020 2020  dim - 1)....    
-00005a90: 2020 2020 6d20 3d20 732e 7368 6170 655b      m = s.shape[
-00005aa0: 305d 0d0a 0d0a 2020 2020 2020 2020 7331  0]....        s1
-00005ab0: 203d 206e 702e 7a65 726f 7328 5b6d 2c20   = np.zeros([m, 
-00005ac0: 315d 290d 0a20 2020 2020 2020 2073 3220  1])..        s2 
-00005ad0: 3d20 2864 696d 202b 2069 5f6f 7264 6572  = (dim + i_order
-00005ae0: 5f6d 6178 2920 2b20 7331 0d0a 0d0a 2020  _max) + s1....  
-00005af0: 2020 2020 2020 7620 3d20 6e70 2e64 6966        v = np.dif
-00005b00: 6628 6e70 2e68 7374 6163 6b28 5b73 312c  f(np.hstack([s1,
-00005b10: 2073 2c20 7332 5d29 290d 0a20 2020 2020   s, s2]))..     
-00005b20: 2020 2076 203d 2076 202d 2031 0d0a 0d0a     v = v - 1....
-00005b30: 2020 2020 2020 2020 6966 2069 5f6f 7264          if i_ord
-00005b40: 6572 5f6d 6178 203d 3d20 303a 0d0a 2020  er_max == 0:..  
-00005b50: 2020 2020 2020 2020 2020 6d75 6c74 695f            multi_
-00005b60: 696e 6469 6365 7320 3d20 760d 0a20 2020  indices = v..   
-00005b70: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
-00005b80: 2020 2020 2020 2020 6d75 6c74 695f 696e          multi_in
-00005b90: 6469 6365 7320 3d20 6e70 2e76 7374 6163  dices = np.vstac
-00005ba0: 6b28 5b6d 756c 7469 5f69 6e64 6963 6573  k([multi_indices
-00005bb0: 2c20 765d 290d 0a0d 0a20 2020 2023 2072  , v])....    # r
-00005bc0: 656d 6f76 6520 706f 6c79 6e6f 6d69 616c  emove polynomial
-00005bd0: 7320 6578 6365 6564 696e 6720 6f72 6465  s exceeding orde
-00005be0: 725f 6d61 7820 636f 6e73 6964 6572 696e  r_max considerin
-00005bf0: 6720 6d61 785f 6f72 6465 725f 6e6f 726d  g max_order_norm
-00005c00: 0d0a 2020 2020 6966 206f 7264 6572 5f6d  ..    if order_m
-00005c10: 6178 5f6e 6f72 6d20 213d 2031 3a0d 0a20  ax_norm != 1:.. 
-00005c20: 2020 2020 2020 206d 756c 7469 5f69 6e64         multi_ind
-00005c30: 6963 6573 203d 206d 756c 7469 5f69 6e64  ices = multi_ind
-00005c40: 6963 6573 5b6e 702e 6c69 6e61 6c67 2e6e  ices[np.linalg.n
-00005c50: 6f72 6d28 6d75 6c74 695f 696e 6469 6365  orm(multi_indice
-00005c60: 732c 206f 7264 3d6f 7264 6572 5f6d 6178  s, ord=order_max
-00005c70: 5f6e 6f72 6d2c 2061 7869 733d 3129 203c  _norm, axis=1) <
-00005c80: 3d0d 0a20 2020 2020 2020 2020 2020 2020  =..             
-00005c90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005ca0: 2020 2020 2020 2020 2028 6f72 6465 725f           (order_
-00005cb0: 6d61 7820 2b20 3165 2d36 292c 203a 5d0d  max + 1e-6), :].
-00005cc0: 0a0d 0a20 2020 2023 2061 6464 206f 7220  ...    # add or 
-00005cd0: 6465 6c65 7465 206d 6f6e 6f6d 6961 6c73  delete monomials
-00005ce0: 2073 7065 6369 6669 6564 2069 6e20 6f72   specified in or
-00005cf0: 6465 720d 0a20 2020 2066 6f72 2069 5f64  der..    for i_d
-00005d00: 696d 2069 6e20 7261 6e67 6528 6469 6d29  im in range(dim)
-00005d10: 3a0d 0a20 2020 2020 2020 2023 2061 6464  :..        # add
-00005d20: 206d 756c 7469 2d69 6e64 6578 6573 2074   multi-indexes t
-00005d30: 6f20 6c69 7374 2077 6865 6e20 6e6f 7420  o list when not 
-00005d40: 7965 7420 696e 636c 7564 6564 0d0a 2020  yet included..  
-00005d50: 2020 2020 2020 6966 206f 7264 6572 5b69        if order[i
-00005d60: 5f64 696d 5d20 3e20 6f72 6465 725f 6d61  _dim] > order_ma
-00005d70: 783a 0d0a 2020 2020 2020 2020 2020 2020  x:..            
-00005d80: 6d75 6c74 695f 696e 6469 6365 735f 6164  multi_indices_ad
-00005d90: 645f 6469 6d20 3d20 6e70 2e6c 696e 7370  d_dim = np.linsp
-00005da0: 6163 6528 6f72 6465 725f 6d61 7820 2b20  ace(order_max + 
-00005db0: 312c 0d0a 2020 2020 2020 2020 2020 2020  1,..            
-00005dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005dd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005de0: 2020 2020 6f72 6465 725b 695f 6469 6d5d      order[i_dim]
-00005df0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-00005e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005e10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005e20: 2020 206f 7264 6572 5b69 5f64 696d 5d20     order[i_dim] 
-00005e30: 2d20 286f 7264 6572 5f6d 6178 202b 2031  - (order_max + 1
-00005e40: 2920 2b20 3129 0d0a 2020 2020 2020 2020  ) + 1)..        
-00005e50: 2020 2020 6d75 6c74 695f 696e 6469 6365      multi_indice
-00005e60: 735f 6164 645f 616c 6c20 3d20 6e70 2e7a  s_add_all = np.z
-00005e70: 6572 6f73 285b 6d75 6c74 695f 696e 6469  eros([multi_indi
-00005e80: 6365 735f 6164 645f 6469 6d2e 7368 6170  ces_add_dim.shap
-00005e90: 655b 305d 2c20 6469 6d5d 290d 0a20 2020  e[0], dim])..   
-00005ea0: 2020 2020 2020 2020 206d 756c 7469 5f69           multi_i
-00005eb0: 6e64 6963 6573 5f61 6464 5f61 6c6c 5b3a  ndices_add_all[:
-00005ec0: 2c20 695f 6469 6d5d 203d 206d 756c 7469  , i_dim] = multi
-00005ed0: 5f69 6e64 6963 6573 5f61 6464 5f64 696d  _indices_add_dim
-00005ee0: 0d0a 2020 2020 2020 2020 2020 2020 6d75  ..            mu
-00005ef0: 6c74 695f 696e 6469 6365 7320 3d20 6e70  lti_indices = np
-00005f00: 2e76 7374 6163 6b28 5b6d 756c 7469 5f69  .vstack([multi_i
-00005f10: 6e64 6963 6573 2c20 6d75 6c74 695f 696e  ndices, multi_in
-00005f20: 6469 6365 735f 6164 645f 616c 6c2e 6173  dices_add_all.as
-00005f30: 7479 7065 2869 6e74 295d 290d 0a0d 0a20  type(int)]).... 
-00005f40: 2020 2020 2020 2023 2064 656c 6574 6520         # delete 
-00005f50: 6d75 6c74 692d 696e 6465 7865 7320 6672  multi-indexes fr
-00005f60: 6f6d 206c 6973 7420 7768 656e 2074 6865  om list when the
-00005f70: 7920 6578 6365 6564 2069 6e64 6976 6964  y exceed individ
-00005f80: 7561 6c20 6d61 7820 6f72 6465 7220 6f66  ual max order of
-00005f90: 2070 6172 616d 6574 6572 0d0a 2020 2020   parameter..    
-00005fa0: 2020 2020 656c 6966 206f 7264 6572 5b69      elif order[i
-00005fb0: 5f64 696d 5d20 3c20 6f72 6465 725f 6d61  _dim] < order_ma
-00005fc0: 783a 0d0a 2020 2020 2020 2020 2020 2020  x:..            
-00005fd0: 6d75 6c74 695f 696e 6469 6365 7320 3d20  multi_indices = 
-00005fe0: 6d75 6c74 695f 696e 6469 6365 735b 6d75  multi_indices[mu
-00005ff0: 6c74 695f 696e 6469 6365 735b 3a2c 2069  lti_indices[:, i
-00006000: 5f64 696d 5d20 3c3d 206f 7264 6572 5b69  _dim] <= order[i
-00006010: 5f64 696d 5d2c 203a 5d0d 0a0d 0a20 2020  _dim], :]....   
-00006020: 2023 2043 6f6e 7369 6465 7220 696e 7465   # Consider inte
-00006030: 7261 6374 696f 6e20 6f72 6465 7220 2866  raction order (f
-00006040: 696c 7465 7220 6f75 7420 6d75 6c74 692d  ilter out multi-
-00006050: 696e 6469 6365 7320 6578 6365 6564 696e  indices exceedin
-00006060: 6720 6974 290d 0a20 2020 2069 6620 696e  g it)..    if in
-00006070: 7465 7261 6374 696f 6e5f 6f72 6465 7220  teraction_order 
-00006080: 3c20 6469 6d3a 0d0a 2020 2020 2020 2020  < dim:..        
-00006090: 6d75 6c74 695f 696e 6469 6365 7320 3d20  multi_indices = 
-000060a0: 6d75 6c74 695f 696e 6469 6365 735b 6e70  multi_indices[np
-000060b0: 2e73 756d 286d 756c 7469 5f69 6e64 6963  .sum(multi_indic
-000060c0: 6573 203e 2030 2c20 6178 6973 3d31 2920  es > 0, axis=1) 
-000060d0: 3c3d 2069 6e74 6572 6163 7469 6f6e 5f6f  <= interaction_o
-000060e0: 7264 6572 2c20 3a5d 0d0a 0d0a 2020 2020  rder, :]....    
-000060f0: 2320 6966 2069 6e74 6572 6163 7469 6f6e  # if interaction
-00006100: 5f6f 7264 6572 5f63 7572 7265 6e74 2069  _order_current i
-00006110: 7320 736d 616c 6c65 7220 7468 616e 2069  s smaller than i
-00006120: 6e74 6572 6163 7469 6f6e 5f6f 7264 6572  nteraction_order
-00006130: 2c20 6465 6c65 7465 2074 686f 7365 2062  , delete those b
-00006140: 6173 6973 2066 756e 6374 696f 6e73 206f  asis functions o
-00006150: 6620 6869 6768 6573 7420 6f72 6465 720d  f highest order.
-00006160: 0a20 2020 2069 6620 696e 7465 7261 6374  .    if interact
-00006170: 696f 6e5f 6f72 6465 725f 6375 7272 656e  ion_order_curren
-00006180: 7420 3c20 696e 7465 7261 6374 696f 6e5f  t < interaction_
-00006190: 6f72 6465 723a 0d0a 2020 2020 2020 2020  order:..        
-000061a0: 6d61 736b 5f6f 7264 6572 5f6d 6178 203d  mask_order_max =
-000061b0: 206e 702e 7375 6d28 6d75 6c74 695f 696e   np.sum(multi_in
-000061c0: 6469 6365 732c 2061 7869 733d 3129 203d  dices, axis=1) =
-000061d0: 3d20 6f72 6465 725f 6d61 780d 0a20 2020  = order_max..   
-000061e0: 2020 2020 206d 6173 6b5f 696e 7465 7261       mask_intera
-000061f0: 6374 696f 6e5f 6f72 6465 7220 3d20 6e70  ction_order = np
-00006200: 2e73 756d 286d 756c 7469 5f69 6e64 6963  .sum(multi_indic
-00006210: 6573 203e 2030 2c20 6178 6973 3d31 2920  es > 0, axis=1) 
-00006220: 3e20 696e 7465 7261 6374 696f 6e5f 6f72  > interaction_or
-00006230: 6465 725f 6375 7272 656e 740d 0a20 2020  der_current..   
-00006240: 2020 2020 206d 6173 6b20 3d20 6e70 2e6c       mask = np.l
-00006250: 6f67 6963 616c 5f6e 6f74 286e 702e 6c6f  ogical_not(np.lo
-00006260: 6769 6361 6c5f 616e 6428 6d61 736b 5f6f  gical_and(mask_o
-00006270: 7264 6572 5f6d 6178 2c20 6d61 736b 5f69  rder_max, mask_i
-00006280: 6e74 6572 6163 7469 6f6e 5f6f 7264 6572  nteraction_order
-00006290: 2929 0d0a 2020 2020 2020 2020 6d75 6c74  ))..        mult
-000062a0: 695f 696e 6469 6365 7320 3d20 6d75 6c74  i_indices = mult
-000062b0: 695f 696e 6469 6365 735b 6d61 736b 5d0d  i_indices[mask].
-000062c0: 0a0d 0a20 2020 2072 6574 7572 6e20 6d75  ...    return mu
-000062d0: 6c74 695f 696e 6469 6365 732e 6173 7479  lti_indices.asty
-000062e0: 7065 2869 6e74 290d 0a0d 0a0d 0a64 6566  pe(int)......def
-000062f0: 2073 616d 706c 655f 7370 6865 7265 286e   sample_sphere(n
-00006300: 5f70 6f69 6e74 732c 2072 293a 0d0a 2020  _points, r):..  
-00006310: 2020 2222 220d 0a20 2020 2043 7265 6174    """..    Creat
-00006320: 6573 206e 5f70 6f69 6e74 7320 6576 656e  es n_points even
-00006330: 6c79 2073 7072 6561 6420 696e 2061 2073  ly spread in a s
-00006340: 7068 6572 6520 6f66 2072 6164 6975 7320  phere of radius 
-00006350: 722e 0d0a 0d0a 2020 2020 5061 7261 6d65  r.....    Parame
-00006360: 7465 7273 0d0a 2020 2020 2d2d 2d2d 2d2d  ters..    ------
-00006370: 2d2d 2d2d 0d0a 2020 2020 6e5f 706f 696e  ----..    n_poin
-00006380: 7473 3a20 696e 740d 0a20 2020 2020 2020  ts: int..       
-00006390: 204e 756d 6265 7220 6f66 2070 6f69 6e74   Number of point
-000063a0: 7320 746f 2062 6520 7370 7265 6164 2c20  s to be spread, 
-000063b0: 6d75 7374 2062 6520 6f64 640d 0a20 2020  must be odd..   
-000063c0: 2072 3a20 666c 6f61 740d 0a20 2020 2020   r: float..     
-000063d0: 2020 2052 6164 6975 7320 6f66 2073 7068     Radius of sph
-000063e0: 6572 650d 0a0d 0a20 2020 2052 6574 7572  ere....    Retur
-000063f0: 6e73 0d0a 2020 2020 2d2d 2d2d 2d2d 2d0d  ns..    -------.
-00006400: 0a20 2020 2070 6f69 6e74 733a 206e 6461  .    points: nda
-00006410: 7272 6179 206f 6620 666c 6f61 7420 5b4e  rray of float [N
-00006420: 2078 2033 5d0d 0a20 2020 2020 2020 2045   x 3]..        E
-00006430: 7665 6e6c 7920 7370 7265 6164 2070 6f69  venly spread poi
-00006440: 6e74 7320 696e 2061 2075 6e69 7420 7370  nts in a unit sp
-00006450: 6865 7265 0d0a 2020 2020 2222 220d 0a0d  here..    """...
-00006460: 0a20 2020 2061 7373 6572 7420 6e5f 706f  .    assert n_po
-00006470: 696e 7473 2025 2032 203d 3d20 312c 2022  ints % 2 == 1, "
-00006480: 5468 6520 6e75 6d62 6572 206f 6620 706f  The number of po
-00006490: 696e 7473 206d 7573 7420 6265 206f 6464  ints must be odd
-000064a0: 220d 0a20 2020 2070 6f69 6e74 7320 3d20  "..    points = 
-000064b0: 5b5d 0d0a 0d0a 2020 2020 2320 5468 6520  []....    # The 
-000064c0: 676f 6c64 656e 2072 6174 696f 0d0a 2020  golden ratio..  
-000064d0: 2020 7068 6920 3d20 2831 202b 206d 6174    phi = (1 + mat
-000064e0: 682e 7371 7274 2835 2929 202f 2032 2e0d  h.sqrt(5)) / 2..
-000064f0: 0a20 2020 206e 203d 2069 6e74 2828 6e5f  .    n = int((n_
-00006500: 706f 696e 7473 202d 2031 2920 2f20 3229  points - 1) / 2)
-00006510: 0d0a 0d0a 2020 2020 666f 7220 6920 696e  ....    for i in
-00006520: 2072 616e 6765 282d 6e2c 206e 202b 2031   range(-n, n + 1
-00006530: 293a 0d0a 2020 2020 2020 2020 6c61 7420  ):..        lat 
-00006540: 3d20 6d61 7468 2e61 7369 6e28 3220 2a20  = math.asin(2 * 
-00006550: 6920 2f20 6e5f 706f 696e 7473 290d 0a20  i / n_points).. 
-00006560: 2020 2020 2020 206c 6f6e 203d 2032 202a         lon = 2 *
-00006570: 206d 6174 682e 7069 202a 2069 202f 2070   math.pi * i / p
-00006580: 6869 0d0a 2020 2020 2020 2020 7820 3d20  hi..        x = 
-00006590: 7220 2a20 6d61 7468 2e63 6f73 286c 6174  r * math.cos(lat
-000065a0: 2920 2a20 6d61 7468 2e63 6f73 286c 6f6e  ) * math.cos(lon
-000065b0: 290d 0a20 2020 2020 2020 2079 203d 2072  )..        y = r
-000065c0: 202a 206d 6174 682e 636f 7328 6c61 7429   * math.cos(lat)
-000065d0: 202a 206d 6174 682e 7369 6e28 6c6f 6e29   * math.sin(lon)
-000065e0: 0d0a 2020 2020 2020 2020 7a20 3d20 7220  ..        z = r 
-000065f0: 2a20 6d61 7468 2e73 696e 286c 6174 290d  * math.sin(lat).
-00006600: 0a20 2020 2020 2020 2070 6f69 6e74 732e  .        points.
-00006610: 6170 7065 6e64 2828 782c 2079 2c20 7a29  append((x, y, z)
-00006620: 290d 0a0d 0a20 2020 2070 6f69 6e74 7320  )....    points 
-00006630: 3d20 6e70 2e61 7272 6179 2870 6f69 6e74  = np.array(point
-00006640: 732c 2064 7479 7065 3d66 6c6f 6174 290d  s, dtype=float).
-00006650: 0a0d 0a20 2020 2072 6574 7572 6e20 706f  ...    return po
-00006660: 696e 7473 0d0a 0d0a 0d0a 6465 6620 6d61  ints......def ma
-00006670: 7432 7465 6e28 6d61 742c 2069 6e63 7229  t2ten(mat, incr)
-00006680: 3a0d 0a20 2020 2022 2222 0d0a 2020 2020  :..    """..    
-00006690: 5472 616e 7366 6f72 6d73 2067 5043 2067  Transforms gPC g
-000066a0: 7261 6469 656e 7420 6d61 7472 6978 206f  radient matrix o
-000066b0: 7220 6772 6164 6965 6e74 2067 7269 6420  r gradient grid 
-000066c0: 706f 696e 7473 2066 726f 6d20 6d61 7472  points from matr
-000066d0: 6978 2074 6f20 7465 6e73 6f72 2066 6f72  ix to tensor for
-000066e0: 6d0d 0a0d 0a20 2020 2050 6172 616d 6574  m....    Paramet
-000066f0: 6572 730d 0a20 2020 202d 2d2d 2d2d 2d2d  ers..    -------
-00006700: 2d2d 2d0d 0a20 2020 206d 6174 203a 206e  ---..    mat : n
-00006710: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-00006720: 5b6e 5f67 7269 642a 696e 6372 2c20 6d5d  [n_grid*incr, m]
-00006730: 0d0a 2020 2020 2020 2020 4d61 7472 6978  ..        Matrix
-00006740: 2074 6f20 7472 616e 7366 6f72 6d0d 0a20   to transform.. 
-00006750: 2020 2069 6e63 7220 3a20 696e 740d 0a20     incr : int.. 
-00006760: 2020 2020 2020 2049 6e63 7265 6d65 6e74         Increment
-00006770: 2061 6674 6572 2065 7665 7279 2072 6f77   after every row
-00006780: 2c20 6120 6e65 7720 7465 6e73 6f72 2073  , a new tensor s
-00006790: 6c69 6365 2069 7320 6372 6561 7465 640d  lice is created.
-000067a0: 0a0d 0a20 2020 2052 6574 7572 6e73 0d0a  ...    Returns..
-000067b0: 2020 2020 2d2d 2d2d 2d2d 2d0d 0a20 2020      -------..   
-000067c0: 2074 656e 203a 206e 6461 7272 6179 206f   ten : ndarray o
-000067d0: 6620 666c 6f61 7420 5b6e 5f67 7269 642c  f float [n_grid,
-000067e0: 206d 2c20 696e 6372 5d0d 0a20 2020 2020   m, incr]..     
-000067f0: 2020 2054 656e 736f 720d 0a0d 0a20 2020     Tensor....   
-00006800: 204e 6f74 6573 0d0a 2020 2020 2d2d 2d2d   Notes..    ----
-00006810: 2d0d 0a20 2020 2042 7569 6c64 7320 6368  -..    Builds ch
-00006820: 756e 6b73 2061 6674 6572 2065 7665 7279  unks after every
-00006830: 2022 696e 6372 2220 726f 7720 616e 6420   "incr" row and 
-00006840: 7772 6974 6573 2069 7420 696e 2061 206e  writes it in a n
-00006850: 6577 2073 6c69 6365 205b 692c 203a 2c20  ew slice [i, :, 
-00006860: 3a5d 0d0a 2020 2020 2222 220d 0a0d 0a20  :]..    """.... 
-00006870: 2020 2074 656e 203d 206e 702e 7a65 726f     ten = np.zero
-00006880: 7328 2869 6e74 286d 6174 2e73 6861 7065  s((int(mat.shape
-00006890: 5b30 5d2f 696e 6372 292c 206d 6174 2e73  [0]/incr), mat.s
-000068a0: 6861 7065 5b31 5d2c 2069 6e63 7229 290d  hape[1], incr)).
-000068b0: 0a20 2020 2069 6478 203d 206e 702e 6172  .    idx = np.ar
-000068c0: 616e 6765 2830 2c20 6d61 742e 7368 6170  ange(0, mat.shap
-000068d0: 655b 305d 2c20 696e 6372 290d 0a0d 0a20  e[0], incr).... 
-000068e0: 2020 2066 6f72 2069 2069 6e20 7261 6e67     for i in rang
-000068f0: 6528 696e 6372 293a 0d0a 2020 2020 2020  e(incr):..      
-00006900: 2020 7465 6e5b 3a2c 203a 2c20 695d 203d    ten[:, :, i] =
-00006910: 206d 6174 5b69 6478 202b 2069 2c20 3a5d   mat[idx + i, :]
-00006920: 0d0a 0d0a 2020 2020 7265 7475 726e 2074  ....    return t
-00006930: 656e 0d0a 0d0a 0d0a 6465 6620 7465 6e32  en......def ten2
-00006940: 6d61 7428 7465 6e29 3a0d 0a20 2020 2022  mat(ten):..    "
-00006950: 2222 0d0a 2020 2020 5472 616e 7366 6f72  ""..    Transfor
-00006960: 6d73 2067 5043 2067 7261 6469 656e 7420  ms gPC gradient 
-00006970: 7465 6e73 6f72 206f 7220 6772 6164 6965  tensor or gradie
-00006980: 6e74 2067 7269 6420 706f 696e 7473 2066  nt grid points f
-00006990: 726f 6d20 7465 6e73 6f72 2074 6f20 6d61  rom tensor to ma
-000069a0: 7472 6978 2066 6f72 6d0d 0a0d 0a20 2020  trix form....   
-000069b0: 2050 6172 616d 6574 6572 730d 0a20 2020   Parameters..   
-000069c0: 202d 2d2d 2d2d 2d2d 2d2d 2d0d 0a20 2020   ----------..   
-000069d0: 2074 656e 203a 206e 6461 7272 6179 206f   ten : ndarray o
-000069e0: 6620 666c 6f61 7420 5b6e 5f67 7269 642c  f float [n_grid,
-000069f0: 206d 2c20 696e 6372 5d0d 0a20 2020 2020   m, incr]..     
-00006a00: 2020 2054 656e 736f 7220 746f 2074 7261     Tensor to tra
-00006a10: 6e73 666f 726d 0d0a 0d0a 2020 2020 5265  nsform....    Re
-00006a20: 7475 726e 730d 0a20 2020 202d 2d2d 2d2d  turns..    -----
-00006a30: 2d2d 0d0a 2020 2020 6d61 7420 3a20 6e64  --..    mat : nd
-00006a40: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
-00006a50: 6e5f 6772 6964 2a69 6e63 722c 206d 5d0d  n_grid*incr, m].
-00006a60: 0a20 2020 2020 2020 204d 6174 7269 780d  .        Matrix.
-00006a70: 0a0d 0a20 2020 204e 6f74 6573 0d0a 2020  ...    Notes..  
-00006a80: 2020 2d2d 2d2d 2d0d 0a20 2020 2053 7461    -----..    Sta
-00006a90: 636b 7320 736c 6963 6573 205b 692c 203a  cks slices [i, :
-00006aa0: 2c20 3a5d 2076 6572 7469 6361 6c6c 790d  , :] vertically.
-00006ab0: 0a20 2020 2022 2222 0d0a 2020 2020 6d61  .    """..    ma
-00006ac0: 7420 3d20 6e70 2e76 7374 6163 6b28 5b74  t = np.vstack([t
-00006ad0: 656e 5b69 2c20 3a2c 203a 5d2e 7472 616e  en[i, :, :].tran
-00006ae0: 7370 6f73 6528 2920 666f 7220 6920 696e  spose() for i in
-00006af0: 2072 616e 6765 2874 656e 2e73 6861 7065   range(ten.shape
-00006b00: 5b30 5d29 5d29 0d0a 0d0a 2020 2020 7265  [0])])....    re
-00006b10: 7475 726e 206d 6174 0d0a 0d0a 0d0a 6465  turn mat......de
-00006b20: 6620 6c69 7374 3264 6963 7428 6c29 3a0d  f list2dict(l):.
-00006b30: 0a20 2020 2022 2222 0d0a 2020 2020 5472  .    """..    Tr
-00006b40: 616e 7366 6f72 6d20 6c69 7374 206f 6620  ansform list of 
-00006b50: 6469 6374 7320 7769 7468 2073 616d 6520  dicts with same 
-00006b60: 6b65 7973 2074 6f20 6469 6374 206f 6620  keys to dict of 
-00006b70: 6c69 7374 0d0a 0d0a 2020 2020 5061 7261  list....    Para
-00006b80: 6d65 7465 7273 0d0a 2020 2020 2d2d 2d2d  meters..    ----
-00006b90: 2d2d 2d2d 2d2d 0d0a 2020 2020 6c20 3a20  ------..    l : 
-00006ba0: 6c69 7374 206f 6620 6469 6374 0d0a 2020  list of dict..  
-00006bb0: 2020 2020 2020 4c69 7374 2063 6f6e 7461        List conta
-00006bc0: 696e 696e 6720 6469 6374 696f 6e61 7269  ining dictionari
-00006bd0: 6573 2077 6974 6820 7361 6d65 206b 6579  es with same key
-00006be0: 730d 0a0d 0a20 2020 2052 6574 7572 6e73  s....    Returns
-00006bf0: 0d0a 2020 2020 2d2d 2d2d 2d2d 2d0d 0a20  ..    -------.. 
-00006c00: 2020 2064 203a 2064 6963 7420 6f66 206c     d : dict of l
-00006c10: 6973 7473 0d0a 2020 2020 2020 2020 4469  ists..        Di
-00006c20: 6374 696f 6e61 7279 2063 6f6e 7461 696e  ctionary contain
-00006c30: 696e 6720 7468 6520 656e 7472 6965 7320  ing the entries 
-00006c40: 696e 2061 206c 6973 740d 0a20 2020 2022  in a list..    "
-00006c50: 2222 0d0a 0d0a 2020 2020 6e20 3d20 6c65  ""....    n = le
-00006c60: 6e28 6c29 0d0a 2020 2020 6b65 7973 203d  n(l)..    keys =
-00006c70: 206c 5b30 5d2e 6b65 7973 2829 0d0a 2020   l[0].keys()..  
-00006c80: 2020 6420 3d20 6469 6374 2829 0d0a 0d0a    d = dict()....
-00006c90: 2020 2020 666f 7220 6b65 7920 696e 206b      for key in k
-00006ca0: 6579 733a 0d0a 2020 2020 2020 2020 645b  eys:..        d[
-00006cb0: 6b65 795d 203d 205b 3020 666f 7220 5f20  key] = [0 for _ 
-00006cc0: 696e 2072 616e 6765 286e 295d 0d0a 2020  in range(n)]..  
-00006cd0: 2020 2020 2020 666f 7220 6920 696e 2072        for i in r
-00006ce0: 616e 6765 286e 293a 0d0a 2020 2020 2020  ange(n):..      
-00006cf0: 2020 2020 2020 645b 6b65 795d 5b69 5d20        d[key][i] 
-00006d00: 3d20 6c5b 695d 5b6b 6579 5d0d 0a0d 0a20  = l[i][key].... 
-00006d10: 2020 2072 6574 7572 6e20 640d 0a0d 0a0d     return d.....
-00006d20: 0a64 6566 2067 6574 5f67 7261 6469 656e  .def get_gradien
-00006d30: 745f 6964 785f 646f 6d61 696e 2864 6f6d  t_idx_domain(dom
-00006d40: 6169 6e73 2c20 642c 2067 7261 6469 656e  ains, d, gradien
-00006d50: 745f 6964 7829 3a0d 0a20 2020 2022 2222  t_idx):..    """
-00006d60: 0d0a 2020 2020 4465 7465 726d 696e 6520  ..    Determine 
-00006d70: 6c6f 6361 6c20 6772 6164 6965 6e74 5f69  local gradient_i
-00006d80: 6478 2069 6e20 646f 6d61 696e 2022 6422  dx in domain "d"
-00006d90: 2066 726f 6d20 676c 6f62 616c 2067 7261   from global gra
-00006da0: 6469 656e 745f 6964 780d 0a0d 0a20 2020  dient_idx....   
-00006db0: 2050 6172 616d 6574 6572 730d 0a20 2020   Parameters..   
-00006dc0: 202d 2d2d 2d2d 2d2d 2d2d 2d0d 0a20 2020   ----------..   
-00006dd0: 2064 6f6d 6169 6e73 203a 206e 6461 7272   domains : ndarr
-00006de0: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
-00006df0: 7269 645f 676c 6f62 616c 5d0d 0a20 2020  rid_global]..   
-00006e00: 2020 2020 2041 7272 6179 2063 6f6e 7461       Array conta
-00006e10: 696e 696e 6720 7468 6520 646f 6d61 696e  ining the domain
-00006e20: 2049 4473 0d0a 2020 2020 6420 3a20 696e   IDs..    d : in
-00006e30: 740d 0a20 2020 2020 2020 2044 6f6d 6169  t..        Domai
-00006e40: 6e20 4944 2066 6f72 2077 6869 6368 2074  n ID for which t
-00006e50: 6865 2067 7261 6469 656e 7420 696e 6465  he gradient inde
-00006e60: 7820 6861 7320 746f 2062 6520 636f 6d70  x has to be comp
-00006e70: 7574 6564 2066 6f72 0d0a 2020 2020 6772  uted for..    gr
-00006e80: 6164 6965 6e74 5f69 6478 203a 206e 6461  adient_idx : nda
-00006e90: 7272 6179 206f 6620 696e 7420 5b6e 5f67  rray of int [n_g
-00006ea0: 7269 645f 676c 6f62 616c 5d0d 0a20 2020  rid_global]..   
-00006eb0: 2020 2020 2049 6e64 6963 6573 206f 6620       Indices of 
-00006ec0: 6772 6964 2070 6f69 6e74 7320 2867 6c6f  grid points (glo
-00006ed0: 6261 6c29 2077 6865 7265 2074 6865 2067  bal) where the g
-00006ee0: 7261 6469 656e 7420 696e 2067 7261 6469  radient in gradi
-00006ef0: 656e 745f 7265 7375 6c74 7320 6973 2070  ent_results is p
-00006f00: 726f 7669 6465 640d 0a0d 0a20 2020 2052  rovided....    R
-00006f10: 6574 7572 6e73 0d0a 2020 2020 2d2d 2d2d  eturns..    ----
-00006f20: 2d2d 2d0d 0a20 2020 2067 7261 6469 656e  ---..    gradien
-00006f30: 745f 6964 785f 6c6f 6361 6c20 3a20 6e64  t_idx_local : nd
-00006f40: 6172 7261 7920 6f66 2069 6e74 205b 6c65  array of int [le
-00006f50: 6e28 646f 6d61 696e 735b 646f 6d61 696e  n(domains[domain
-00006f60: 733d 3d64 5d29 5d0d 0a20 2020 2020 2020  s==d])]..       
-00006f70: 2049 6e64 6963 6573 206f 6620 6772 6964   Indices of grid
-00006f80: 2070 6f69 6e74 7320 286c 6f63 616c 2920   points (local) 
-00006f90: 7768 6572 6520 7468 6520 6772 6164 6965  where the gradie
-00006fa0: 6e74 2069 6e20 6772 6164 6965 6e74 5f72  nt in gradient_r
-00006fb0: 6573 756c 7473 2069 7320 7072 6f76 6964  esults is provid
-00006fc0: 6564 0d0a 2020 2020 2222 220d 0a20 2020  ed..    """..   
-00006fd0: 2061 7272 203d 206e 702e 6172 616e 6765   arr = np.arange
-00006fe0: 286c 656e 2864 6f6d 6169 6e73 2929 0d0a  (len(domains))..
-00006ff0: 2020 2020 6772 6164 6965 6e74 5f69 6478      gradient_idx
-00007000: 5f6c 6f63 616c 203d 206e 702e 6172 7261  _local = np.arra
-00007010: 7928 5b69 0d0a 2020 2020 2020 2020 2020  y([i..          
-00007020: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007030: 2020 2020 2020 2020 2066 6f72 2069 2c20           for i, 
-00007040: 6320 696e 2065 6e75 6d65 7261 7465 2861  c in enumerate(a
-00007050: 7272 5b64 6f6d 6169 6e73 203d 3d20 645d  rr[domains == d]
-00007060: 2920 2023 206c 6f63 616c 0d0a 2020 2020  )  # local..    
-00007070: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007080: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-00007090: 6f72 2063 7220 696e 2061 7272 5b67 7261  or cr in arr[gra
-000070a0: 6469 656e 745f 6964 785d 2020 2020 2020  dient_idx]      
-000070b0: 2020 2020 2020 2020 2023 2067 6c6f 6261           # globa
-000070c0: 6c0d 0a20 2020 2020 2020 2020 2020 2020  l..             
-000070d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000070e0: 2020 2020 2020 6966 2028 6320 3d3d 2063        if (c == c
-000070f0: 7229 2e61 6c6c 2829 5d29 0d0a 0d0a 2020  r).all()])....  
-00007100: 2020 7265 7475 726e 2067 7261 6469 656e    return gradien
-00007110: 745f 6964 785f 6c6f 6361 6c0d 0a0d 0a0d  t_idx_local.....
-00007120: 0a64 6566 2064 6574 6572 6d69 6e65 5f70  .def determine_p
-00007130: 726f 6a65 6374 696f 6e5f 6d61 7472 6978  rojection_matrix
-00007140: 2867 7261 6469 656e 745f 7265 7375 6c74  (gradient_result
-00007150: 732c 206c 616d 6264 615f 6570 733d 302e  s, lambda_eps=0.
-00007160: 3935 293a 0d0a 2020 2020 2222 220d 0a20  95):..    """.. 
-00007170: 2020 2044 6574 6572 6d69 6e65 7320 7072     Determines pr
-00007180: 6f6a 6563 7469 6f6e 206d 6174 7269 7820  ojection matrix 
-00007190: 5b50 5d2e 0d0a 0d0a 2020 2020 2e2e 206d  [P].....    .. m
-000071a0: 6174 683a 3a20 5c5c 6574 6120 3d20 5b5c  ath:: \\eta = [\
-000071b0: 5c6d 6174 6862 667b 507d 5d20 5c5c 7869  \mathbf{P}] \\xi
-000071c0: 0d0a 0d0a 2020 2020 5061 7261 6d65 7465  ....    Paramete
-000071d0: 7273 0d0a 2020 2020 2d2d 2d2d 2d2d 2d2d  rs..    --------
-000071e0: 2d2d 0d0a 2020 2020 6772 6164 6965 6e74  --..    gradient
-000071f0: 5f72 6573 756c 7473 203a 206e 6461 7272  _results : ndarr
-00007200: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
-00007210: 7269 6420 7820 6e5f 6f75 7420 7820 6469  rid x n_out x di
-00007220: 6d5d 0d0a 2020 2020 2020 2020 4772 6164  m]..        Grad
-00007230: 6965 6e74 206f 6620 6d6f 6465 6c20 6675  ient of model fu
-00007240: 6e63 7469 6f6e 2069 6e20 6772 6964 2070  nction in grid p
-00007250: 6f69 6e74 730d 0a20 2020 206c 616d 6264  oints..    lambd
-00007260: 615f 6570 7320 3a20 666c 6f61 742c 206f  a_eps : float, o
-00007270: 7074 696f 6e61 6c2c 2064 6566 6175 6c74  ptional, default
-00007280: 3a20 302e 3935 0d0a 2020 2020 2020 2020  : 0.95..        
-00007290: 426f 756e 6420 6f66 2070 7269 6e63 6970  Bound of princip
-000072a0: 616c 2063 6f6d 706f 6e65 6e74 7320 696e  al components in
-000072b0: 2025 2e20 416c 6c20 6569 6765 6e76 6563   %. All eigenvec
-000072c0: 746f 7273 2061 7265 2069 6e63 6c75 6465  tors are include
-000072d0: 6420 756e 7469 6c20 6c61 6d62 6461 5f65  d until lambda_e
-000072e0: 7073 206f 6620 746f 7461 6c20 7375 6d20  ps of total sum 
-000072f0: 6f66 2061 6c6c 0d0a 2020 2020 2020 2020  of all..        
-00007300: 6569 6765 6e76 616c 7565 7320 6973 2069  eigenvalues is i
-00007310: 6e63 6c75 6465 6420 696e 2074 6865 2073  ncluded in the s
-00007320: 7973 7465 6d2e 0d0a 0d0a 2020 2020 5265  ystem.....    Re
-00007330: 7475 726e 730d 0a20 2020 202d 2d2d 2d2d  turns..    -----
-00007340: 2d2d 0d0a 2020 2020 705f 6d61 7472 6978  --..    p_matrix
-00007350: 203a 206e 6461 7272 6179 206f 6620 666c   : ndarray of fl
-00007360: 6f61 7420 5b64 696d 5f72 6564 7563 6564  oat [dim_reduced
-00007370: 2078 2064 696d 5d0d 0a20 2020 2020 2020   x dim]..       
-00007380: 2052 6564 7563 6564 2070 726f 6a65 6374   Reduced project
-00007390: 696f 6e20 6d61 7472 6978 2066 6f72 2051  ion matrix for Q
-000073a0: 4f49 2e0d 0a20 2020 2070 5f6d 6174 7269  OI...    p_matri
-000073b0: 785f 636f 6d70 6c65 7465 203a 206e 6461  x_complete : nda
-000073c0: 7272 6179 206f 6620 666c 6f61 7420 5b64  rray of float [d
-000073d0: 696d 5f72 6564 7563 6564 2078 2064 696d  im_reduced x dim
-000073e0: 5d0d 0a20 2020 2020 2020 2043 6f6d 706c  ]..        Compl
-000073f0: 6574 6520 7072 6f6a 6563 7469 6f6e 206d  ete projection m
-00007400: 6174 7269 7820 666f 7220 514f 492e 0d0a  atrix for QOI...
-00007410: 2020 2020 2222 220d 0a0d 0a20 2020 2023      """....    #
-00007420: 2044 6574 6572 6d69 6e65 2070 726f 6a65   Determine proje
-00007430: 6374 696f 6e20 6d61 7472 6963 6573 2062  ction matrices b
-00007440: 7920 5356 4420 6f66 2067 7261 6469 656e  y SVD of gradien
-00007450: 7473 0d0a 2020 2020 752c 2073 2c20 7620  ts..    u, s, v 
-00007460: 3d20 6e70 2e6c 696e 616c 672e 7376 6428  = np.linalg.svd(
-00007470: 6772 6164 6965 6e74 5f72 6573 756c 7473  gradient_results
-00007480: 290d 0a0d 0a20 2020 2023 2064 6574 6572  )....    # deter
-00007490: 6d69 6e65 2064 6f6d 696e 616e 7420 6569  mine dominant ei
-000074a0: 6765 6e76 616c 7565 7320 7570 2074 6f20  genvalues up to 
-000074b0: 6c61 6d62 6461 5f65 7073 202a 2073 5f73  lambda_eps * s_s
-000074c0: 756d 0d0a 2020 2020 735f 6d61 736b 203d  um..    s_mask =
-000074d0: 205b 4661 6c73 655d 2a6c 656e 2873 290d   [False]*len(s).
-000074e0: 0a20 2020 2073 5f73 756d 5f70 6172 7420  .    s_sum_part 
-000074f0: 3d20 300d 0a20 2020 2073 5f73 756d 203d  = 0..    s_sum =
-00007500: 206e 702e 7375 6d28 7329 0d0a 2020 2020   np.sum(s)..    
-00007510: 695f 7320 3d20 300d 0a0d 0a20 2020 2077  i_s = 0....    w
-00007520: 6869 6c65 2073 5f73 756d 5f70 6172 7420  hile s_sum_part 
-00007530: 3c3d 206c 616d 6264 615f 6570 732a 735f  <= lambda_eps*s_
-00007540: 7375 6d3a 0d0a 2020 2020 2020 2020 735f  sum:..        s_
-00007550: 7375 6d5f 7061 7274 202b 3d20 735b 695f  sum_part += s[i_
-00007560: 735d 0d0a 2020 2020 2020 2020 735f 6d61  s]..        s_ma
-00007570: 736b 5b69 5f73 5d20 3d20 5472 7565 0d0a  sk[i_s] = True..
-00007580: 2020 2020 2020 2020 695f 7320 2b3d 2031          i_s += 1
-00007590: 0d0a 0d0a 2020 2020 735f 6669 6c74 203d  ....    s_filt =
-000075a0: 2073 5b73 5f6d 6173 6b5d 0d0a 2020 2020   s[s_mask]..    
-000075b0: 765f 6669 6c74 203d 2076 5b6e 702e 6170  v_filt = v[np.ap
-000075c0: 7065 6e64 2873 5f6d 6173 6b2c 205b 4661  pend(s_mask, [Fa
-000075d0: 6c73 655d 2a28 762e 7368 6170 655b 305d  lse]*(v.shape[0]
-000075e0: 2d75 2e73 6861 7065 5b31 5d29 2920 3e20  -u.shape[1])) > 
-000075f0: 302c 203a 5d0d 0a20 2020 2070 5f6d 6174  0, :]..    p_mat
-00007600: 7269 7820 3d20 765f 6669 6c74 0d0a 2020  rix = v_filt..  
-00007610: 2020 705f 6d61 7472 6978 5f63 6f6d 706c    p_matrix_compl
-00007620: 6574 6520 3d20 760d 0a0d 0a20 2020 2072  ete = v....    r
-00007630: 6574 7572 6e20 705f 6d61 7472 6978 2c20  eturn p_matrix, 
-00007640: 705f 6d61 7472 6978 5f63 6f6d 706c 6574  p_matrix_complet
-00007650: 650d 0a0d 0a0d 0a64 6566 2067 6574 5f69  e......def get_i
-00007660: 6e64 6963 6573 5f6f 665f 6b5f 736d 616c  ndices_of_k_smal
-00007670: 6c65 7374 2861 7272 2c20 6b29 3a0d 0a20  lest(arr, k):.. 
-00007680: 2020 2022 2222 0d0a 2020 2020 4669 6e64     """..    Find
-00007690: 2069 6e64 6963 6573 206f 6620 6b20 736d   indices of k sm
-000076a0: 616c 6c65 7374 2065 6c65 6d65 6e74 7320  allest elements 
-000076b0: 696e 206e 6461 7272 6179 0d0a 0d0a 2020  in ndarray....  
-000076c0: 2020 5061 7261 6d65 7465 7273 0d0a 2020    Parameters..  
-000076d0: 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0d0a 2020    ----------..  
-000076e0: 2020 6172 7220 3a20 6e64 6172 7261 7920    arr : ndarray 
-000076f0: 6f66 2066 6c6f 6174 0d0a 2020 2020 2020  of float..      
-00007700: 2020 4172 7261 790d 0a20 2020 206b 203a    Array..    k :
-00007710: 2069 6e74 0d0a 2020 2020 2020 2020 4e75   int..        Nu
-00007720: 6d62 6572 206f 6620 736d 616c 6c65 7374  mber of smallest
-00007730: 2076 616c 7565 7320 746f 2065 7874 7261   values to extra
-00007740: 6374 0d0a 0d0a 2020 2020 5265 7475 726e  ct....    Return
-00007750: 730d 0a20 2020 202d 2d2d 2d2d 2d2d 0d0a  s..    -------..
-00007760: 2020 2020 6964 7820 3a20 7475 706c 6520      idx : tuple 
-00007770: 6f66 206e 6461 7272 6179 205b 6b5d 0d0a  of ndarray [k]..
-00007780: 2020 2020 2020 2020 496e 6469 6365 7320          Indices 
-00007790: 6f66 206b 2073 6d61 6c6c 6573 7420 656c  of k smallest el
-000077a0: 656d 656e 7473 2069 6e20 6172 7261 790d  ements in array.
-000077b0: 0a20 2020 2022 2222 0d0a 2020 2020 2320  .    """..    # 
-000077c0: 696e 6465 7820 3d20 6e70 2e61 7267 7061  index = np.argpa
-000077d0: 7274 6974 696f 6e28 6172 722e 7261 7665  rtition(arr.rave
-000077e0: 6c28 292c 206b 290d 0a20 2020 2023 2069  l(), k)..    # i
-000077f0: 6478 203d 2074 7570 6c65 286e 702e 6172  dx = tuple(np.ar
-00007800: 7261 7928 6e70 2e75 6e72 6176 656c 5f69  ray(np.unravel_i
-00007810: 6e64 6578 2869 6e64 6578 2c20 6172 722e  ndex(index, arr.
-00007820: 7368 6170 6529 295b 3a2c 2072 616e 6765  shape))[:, range
-00007830: 286d 696e 286b 2c20 3029 2c20 6d61 7828  (min(k, 0), max(
-00007840: 6b2c 2030 2929 5d29 0d0a 2020 2020 230d  k, 0))])..    #.
-00007850: 0a20 2020 2023 2072 6574 7572 6e20 6964  .    # return id
-00007860: 780d 0a0d 0a20 2020 2069 6478 203d 206e  x....    idx = n
-00007870: 702e 6172 6770 6172 7469 7469 6f6e 2861  p.argpartition(a
-00007880: 7272 2e72 6176 656c 2829 2c20 6172 722e  rr.ravel(), arr.
-00007890: 7369 7a65 202d 206b 295b 3a6b 5d0d 0a0d  size - k)[:k]...
-000078a0: 0a20 2020 2072 6574 7572 6e20 7475 706c  .    return tupl
-000078b0: 6528 6e70 2e75 6e72 6176 656c 5f69 6e64  e(np.unravel_ind
-000078c0: 6578 2869 6478 2c20 6172 722e 7368 6170  ex(idx, arr.shap
-000078d0: 6529 290d 0a0d 0a0d 0a64 6566 2067 6574  e))......def get
-000078e0: 5f63 6f6f 7264 735f 6469 7363 6f6e 7469  _coords_disconti
-000078f0: 6e75 6974 7928 636c 6173 7369 6669 6572  nuity(classifier
-00007900: 2c20 785f 6d69 6e2c 2078 5f6d 6178 2c20  , x_min, x_max, 
-00007910: 6e5f 636f 6f72 6473 5f64 6973 633d 3130  n_coords_disc=10
-00007920: 2c20 626f 7264 6572 5f73 616d 706c 696e  , border_samplin
-00007930: 673d 2273 7472 7563 7475 7265 6422 293a  g="structured"):
-00007940: 0d0a 2020 2020 2222 220d 0a20 2020 2044  ..    """..    D
-00007950: 6574 6572 6d69 6e65 206e 5f63 6f6f 7264  etermine n_coord
-00007960: 735f 6469 7363 2067 7269 6420 706f 696e  s_disc grid poin
-00007970: 7473 2063 6c6f 7365 2074 6f20 6469 7363  ts close to disc
-00007980: 6f6e 7469 6e75 6974 790d 0a0d 0a20 2020  ontinuity....   
-00007990: 2050 6172 616d 6574 6572 730d 0a20 2020   Parameters..   
-000079a0: 202d 2d2d 2d2d 2d2d 2d2d 2d0d 0a20 2020   ----------..   
-000079b0: 2063 6c61 7373 6966 6965 7220 3a20 436c   classifier : Cl
-000079c0: 6173 7369 6669 6572 206f 626a 6563 740d  assifier object.
-000079d0: 0a20 2020 2020 2020 2043 6c61 7373 6966  .        Classif
-000079e0: 6965 7220 6f62 6a65 6374 2074 6f20 7072  ier object to pr
-000079f0: 6564 6963 7420 636c 6173 7365 7320 6672  edict classes fr
-00007a00: 6f6d 2063 6f6f 7264 696e 6174 6573 2028  om coordinates (
-00007a10: 6e65 6564 7320 746f 2063 6f6e 7461 696e  needs to contain
-00007a20: 2061 2063 6c61 7373 6966 6965 722e 7072   a classifier.pr
-00007a30: 6564 6963 7428 2920 6d65 7468 6f64 290d  edict() method).
-00007a40: 0a20 2020 2078 5f6d 696e 203a 206e 6461  .    x_min : nda
-00007a50: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
-00007a60: 5f64 696d 5d0d 0a20 2020 2020 2020 204d  _dim]..        M
-00007a70: 696e 696d 616c 2076 616c 7565 7320 696e  inimal values in
-00007a80: 2070 6172 616d 6574 6572 2073 7061 6365   parameter space
-00007a90: 2074 6f20 7365 6172 6368 2064 6973 636f   to search disco
-00007aa0: 6e74 696e 7569 7479 0d0a 2020 2020 785f  ntinuity..    x_
-00007ab0: 6d61 7820 3a20 6e64 6172 7261 7920 6f66  max : ndarray of
-00007ac0: 2066 6c6f 6174 205b 6e5f 6469 6d5d 0d0a   float [n_dim]..
-00007ad0: 2020 2020 2020 2020 4d61 7869 6d61 6c20          Maximal 
-00007ae0: 7661 6c75 6573 2069 6e20 7061 7261 6d65  values in parame
-00007af0: 7465 7220 7370 6163 6520 746f 2073 6561  ter space to sea
-00007b00: 7263 6820 6469 7363 6f6e 7469 6e75 6974  rch discontinuit
-00007b10: 790d 0a20 2020 206e 5f63 6f6f 7264 735f  y..    n_coords_
-00007b20: 6469 7363 203a 2069 6e74 2c20 6f70 7469  disc : int, opti
-00007b30: 6f6e 616c 2c20 6465 6661 756c 743a 2031  onal, default: 1
-00007b40: 300d 0a20 2020 2020 2020 204e 756d 6265  0..        Numbe
-00007b50: 7220 6f66 2067 7269 6420 706f 696e 7473  r of grid points
-00007b60: 2074 6f20 6465 7465 726d 696e 6520 636c   to determine cl
-00007b70: 6f73 6520 746f 2064 6973 636f 6e74 696e  ose to discontin
-00007b80: 7569 7479 0d0a 2020 2020 626f 7264 6572  uity..    border
-00007b90: 5f73 616d 706c 696e 6720 3a20 7374 722c  _sampling : str,
-00007ba0: 206f 7074 696f 6e61 6c2c 2064 6566 6175   optional, defau
-00007bb0: 6c74 3a20 2273 7472 7563 7475 7265 6422  lt: "structured"
-00007bc0: 0d0a 2020 2020 2020 2020 5361 6d70 6c69  ..        Sampli
-00007bd0: 6e67 206d 6574 686f 6420 746f 2064 6574  ng method to det
-00007be0: 6572 6d69 6e65 206c 6f63 6174 696f 6e20  ermine location 
-00007bf0: 6f66 2064 6973 636f 6e74 696e 7569 7479  of discontinuity
-00007c00: 0d0a 0d0a 0d0a 2020 2020 5265 7475 726e  ......    Return
-00007c10: 730d 0a20 2020 202d 2d2d 2d2d 2d2d 0d0a  s..    -------..
-00007c20: 2020 2020 636f 6f72 6473 5f64 6973 6320      coords_disc 
-00007c30: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
-00007c40: 6174 205b 6e5f 636f 6f72 6473 5f64 6973  at [n_coords_dis
-00007c50: 635d 0d0a 2020 2020 2222 220d 0a0d 0a20  c]..    """.... 
-00007c60: 2020 2023 2069 6620 626f 7264 6572 5f73     # if border_s
-00007c70: 616d 706c 696e 6720 3d3d 2022 7261 6e64  ampling == "rand
-00007c80: 6f6d 223a 0d0a 2020 2020 2320 2020 2020  om":..    #     
-00007c90: 636f 6f72 6473 5f62 6f72 6465 725f 6465  coords_border_de
-00007ca0: 7420 3d20 6772 6964 5f6c 6561 726e 5f63  t = grid_learn_c
-00007cb0: 6c75 7374 6572 2e63 6f6f 7264 730d 0a20  luster.coords.. 
-00007cc0: 2020 2023 2020 2020 2064 6f6d 6169 6e73     #     domains
-00007cd0: 203d 206d 6f64 656c 5f6b 6d65 616e 732e   = model_kmeans.
-00007ce0: 6c61 6265 6c73 5f0d 0a20 2020 2064 696d  labels_..    dim
-00007cf0: 203d 206c 656e 2878 5f6d 696e 290d 0a0d   = len(x_min)...
-00007d00: 0a20 2020 2023 2063 7265 6174 6520 7465  .    # create te
-00007d10: 6e73 6f72 6564 206d 6573 6820 746f 2066  nsored mesh to f
-00007d20: 696e 6420 6469 7363 6f6e 7469 6e75 6974  ind discontinuit
-00007d30: 790d 0a20 2020 2069 6620 626f 7264 6572  y..    if border
-00007d40: 5f73 616d 706c 696e 6720 3d3d 2022 7374  _sampling == "st
-00007d50: 7275 6374 7572 6564 223a 0d0a 2020 2020  ructured":..    
-00007d60: 2020 2020 6e5f 7361 6d70 6c65 7320 3d20      n_samples = 
-00007d70: 696e 7428 3145 342a 2a28 312e 2f64 696d  int(1E4**(1./dim
-00007d80: 2929 0d0a 2020 2020 2020 2020 6576 616c  ))..        eval
-00007d90: 5f73 7472 203d 2022 6e70 2e61 7272 6179  _str = "np.array
-00007da0: 286e 702e 6d65 7368 6772 6964 2822 0d0a  (np.meshgrid("..
-00007db0: 0d0a 2020 2020 2020 2020 666f 7220 6920  ..        for i 
-00007dc0: 696e 2072 616e 6765 2864 696d 293a 0d0a  in range(dim):..
-00007dd0: 2020 2020 2020 2020 2020 2020 6576 616c              eval
-00007de0: 5f73 7472 202b 3d20 226e 702e 6c69 6e73  _str += "np.lins
-00007df0: 7061 6365 2878 5f6d 696e 5b7b 7d5d 2c20  pace(x_min[{}], 
-00007e00: 785f 6d61 785b 7b7d 5d2c 207b 7d29 222e  x_max[{}], {})".
-00007e10: 666f 726d 6174 2869 2c20 692c 206e 5f73  format(i, i, n_s
-00007e20: 616d 706c 6573 290d 0a0d 0a20 2020 2020  amples)....     
-00007e30: 2020 2020 2020 2069 6620 6920 3c20 6469         if i < di
-00007e40: 6d2d 313a 0d0a 2020 2020 2020 2020 2020  m-1:..          
-00007e50: 2020 2020 2020 6576 616c 5f73 7472 202b        eval_str +
-00007e60: 3d20 222c 2022 0d0a 0d0a 2020 2020 2020  = ", "....      
-00007e70: 2020 6576 616c 5f73 7472 202b 3d20 2229    eval_str += ")
-00007e80: 292e 542e 7265 7368 6170 6528 2d31 2c20  ).T.reshape(-1, 
-00007e90: 7b7d 2922 2e66 6f72 6d61 7428 6469 6d29  {})".format(dim)
-00007ea0: 0d0a 0d0a 2020 2020 2020 2020 636f 6f72  ....        coor
-00007eb0: 6473 5f62 6f72 6465 725f 6465 7420 3d20  ds_border_det = 
-00007ec0: 6576 616c 2865 7661 6c5f 7374 7229 0d0a  eval(eval_str)..
-00007ed0: 0d0a 2020 2020 2020 2020 646f 6d61 696e  ..        domain
-00007ee0: 7320 3d20 636c 6173 7369 6669 6572 2e70  s = classifier.p
-00007ef0: 7265 6469 6374 2863 6f6f 7264 735f 626f  redict(coords_bo
-00007f00: 7264 6572 5f64 6574 290d 0a20 2020 2065  rder_det)..    e
-00007f10: 6c73 653a 0d0a 2020 2020 2020 2020 7261  lse:..        ra
-00007f20: 6973 6520 4e6f 7449 6d70 6c65 6d65 6e74  ise NotImplement
-00007f30: 6564 4572 726f 7228 2250 6c65 6173 6520  edError("Please 
-00007f40: 7573 6520 7661 6c69 6420 626f 7264 6572  use valid border
-00007f50: 2073 616d 706c 696e 6720 6d65 7468 6f64   sampling method
-00007f60: 2028 2222 7374 7275 6374 7572 6564 2222   (""structured""
-00007f70: 2922 290d 0a0d 0a20 2020 2023 2064 6574  )")....    # det
-00007f80: 6572 6d69 6e65 206d 6173 6b20 6f66 206e  ermine mask of n
-00007f90: 6f74 2065 7175 616c 696e 6720 646f 6d61  ot equaling doma
-00007fa0: 696e 2070 6f69 6e74 730d 0a20 2020 2023  in points..    #
-00007fb0: 2064 6f6d 5f6d 6174 203d 206e 702e 7469   dom_mat = np.ti
-00007fc0: 6c65 2864 6f6d 6169 6e73 5b3a 2c20 6e70  le(domains[:, np
-00007fd0: 2e6e 6577 6178 6973 5d2c 2028 312c 2064  .newaxis], (1, d
-00007fe0: 6f6d 6169 6e73 2e73 6861 7065 5b30 5d29  omains.shape[0])
-00007ff0: 290d 0a20 2020 2064 6f6d 5f6d 6174 203d  )..    dom_mat =
-00008000: 206e 702e 6272 6f61 6463 6173 745f 746f   np.broadcast_to
-00008010: 2864 6f6d 6169 6e73 2c20 286c 656e 2864  (domains, (len(d
-00008020: 6f6d 6169 6e73 292c 206c 656e 2864 6f6d  omains), len(dom
-00008030: 6169 6e73 2929 292e 540d 0a20 2020 206d  ains))).T..    m
-00008040: 6173 6b20 3d20 646f 6d5f 6d61 7420 213d  ask = dom_mat !=
-00008050: 2064 6f6d 5f6d 6174 2e74 7261 6e73 706f   dom_mat.transpo
-00008060: 7365 2829 0d0a 2020 2020 6d61 736b 203d  se()..    mask =
-00008070: 206e 702e 7472 696c 286d 6173 6b29 202a   np.tril(mask) *
-00008080: 2046 616c 7365 202b 206e 702e 7472 6975   False + np.triu
-00008090: 286d 6173 6b29 0d0a 0d0a 2020 2020 2320  (mask)....    # 
-000080a0: 6465 7465 726d 696e 6520 6469 7374 616e  determine distan
-000080b0: 6365 7320 6265 7477 6565 6e20 6772 6964  ces between grid
-000080c0: 2070 6f69 6e74 7320 696e 2064 6966 6665   points in diffe
-000080d0: 7265 6e74 2064 6f6d 6169 6e73 0d0a 2020  rent domains..  
-000080e0: 2020 6469 7374 616e 6365 5f6d 6174 7269    distance_matri
-000080f0: 7820 3d20 6e70 2e6f 6e65 7328 6d61 736b  x = np.ones(mask
-00008100: 2e73 6861 7065 2920 2a20 6e70 2e6e 616e  .shape) * np.nan
-00008110: 0d0a 2020 2020 666f 7220 695f 632c 2063  ..    for i_c, c
-00008120: 2069 6e20 656e 756d 6572 6174 6528 636f   in enumerate(co
-00008130: 6f72 6473 5f62 6f72 6465 725f 6465 7429  ords_border_det)
-00008140: 3a0d 0a20 2020 2020 2020 2064 6973 7461  :..        dista
-00008150: 6e63 655f 6d61 7472 6978 5b69 5f63 2c20  nce_matrix[i_c, 
-00008160: 6d61 736b 5b69 5f63 2c20 3a5d 5d20 3d20  mask[i_c, :]] = 
-00008170: 6e70 2e6c 696e 616c 672e 6e6f 726d 2863  np.linalg.norm(c
-00008180: 6f6f 7264 735f 626f 7264 6572 5f64 6574  oords_border_det
-00008190: 5b6d 6173 6b5b 695f 632c 203a 5d2c 203a  [mask[i_c, :], :
-000081a0: 5d20 2d20 632c 2061 7869 733d 3129 0d0a  ] - c, axis=1)..
-000081b0: 0d0a 2020 2020 6e70 2e66 696c 6c5f 6469  ..    np.fill_di
-000081c0: 6167 6f6e 616c 2864 6973 7461 6e63 655f  agonal(distance_
-000081d0: 6d61 7472 6978 2c20 6e70 2e6e 616e 290d  matrix, np.nan).
-000081e0: 0a0d 0a20 2020 2023 2066 696e 6420 6e5f  ...    # find n_
-000081f0: 736d 616c 6c65 7374 2064 6973 7461 6e63  smallest distanc
-00008200: 6573 2061 6e64 2064 6574 6572 6d69 6e65  es and determine
-00008210: 206d 6964 706f 696e 7473 2062 6574 7765   midpoints betwe
-00008220: 656e 2074 686f 7365 2070 6f69 6e74 730d  en those points.
-00008230: 0a20 2020 206e 5f73 6d61 6c6c 6573 7420  .    n_smallest 
-00008240: 3d20 3130 3030 0d0a 2020 2020 6964 7820  = 1000..    idx 
-00008250: 3d20 6765 745f 696e 6469 6365 735f 6f66  = get_indices_of
-00008260: 5f6b 5f73 6d61 6c6c 6573 7428 6469 7374  _k_smallest(dist
-00008270: 616e 6365 5f6d 6174 7269 782c 206e 5f73  ance_matrix, n_s
-00008280: 6d61 6c6c 6573 7429 0d0a 2020 2020 636f  mallest)..    co
-00008290: 6f72 6473 5f62 6f72 6465 7220 3d20 2863  ords_border = (c
-000082a0: 6f6f 7264 735f 626f 7264 6572 5f64 6574  oords_border_det
-000082b0: 5b69 6478 5b30 5d2c 203a 5d20 2b20 636f  [idx[0], :] + co
-000082c0: 6f72 6473 5f62 6f72 6465 725f 6465 745b  ords_border_det[
-000082d0: 6964 785b 315d 2c20 3a5d 2920 2f20 320d  idx[1], :]) / 2.
-000082e0: 0a0d 0a20 2020 2023 2072 6573 616d 706c  ...    # resampl
-000082f0: 6520 6e5f 636f 6f72 6473 5f64 6973 6320  e n_coords_disc 
-00008300: 6571 7561 6c6c 7920 6469 7374 7269 6275  equally distribu
-00008310: 7465 6420 706f 696e 7473 2066 726f 6d20  ted points from 
-00008320: 6e5f 736d 616c 6c65 7374 2070 6f69 6e74  n_smallest point
-00008330: 7320 6f6e 2064 6973 636f 6e74 696e 7569  s on discontinui
-00008340: 7479 0d0a 2020 2020 6e5f 7265 7073 203d  ty..    n_reps =
-00008350: 2031 3030 3020 2023 206e 756d 6265 7220   1000  # number 
-00008360: 6f66 2072 6570 6574 6974 696f 6e73 0d0a  of repetitions..
-00008370: 2020 2020 6964 7820 3d20 6e70 2e7a 6572      idx = np.zer
-00008380: 6f73 2828 6e5f 636f 6f72 6473 5f64 6973  os((n_coords_dis
-00008390: 632c 206e 5f72 6570 7329 290d 0a20 2020  c, n_reps))..   
-000083a0: 2064 6973 7461 6e63 655f 6d65 616e 203d   distance_mean =
-000083b0: 206e 702e 7a65 726f 7328 6e5f 7265 7073   np.zeros(n_reps
-000083c0: 290d 0a0d 0a20 2020 2023 2073 656c 6563  )....    # selec
-000083d0: 7420 6e5f 636f 6f72 6473 5f64 6973 6320  t n_coords_disc 
-000083e0: 706f 696e 7473 2072 616e 646f 6d6c 7920  points randomly 
-000083f0: 616e 6420 6465 7465 726d 696e 6520 6176  and determine av
-00008400: 6572 6167 6520 6d69 6e69 6d61 6c20 6469  erage minimal di
-00008410: 7374 616e 6365 2062 6574 7765 656e 2070  stance between p
-00008420: 6f69 6e74 730d 0a20 2020 2066 6f72 2069  oints..    for i
-00008430: 2069 6e20 7261 6e67 6528 6e5f 7265 7073   in range(n_reps
-00008440: 293a 0d0a 2020 2020 2020 2020 2320 7361  ):..        # sa
-00008450: 6d70 6c65 206e 5f72 6573 616d 706c 6520  mple n_resample 
-00008460: 706f 696e 7473 2066 726f 6d20 636f 6f72  points from coor
-00008470: 6473 5f62 6f72 6465 720d 0a20 2020 2020  ds_border..     
-00008480: 2020 2069 6478 5b3a 2c20 695d 203d 2072     idx[:, i] = r
-00008490: 616e 646f 6d2e 7361 6d70 6c65 286c 6973  andom.sample(lis
-000084a0: 7428 7261 6e67 6528 636f 6f72 6473 5f62  t(range(coords_b
-000084b0: 6f72 6465 722e 7368 6170 655b 305d 2929  order.shape[0]))
-000084c0: 2c20 6e5f 636f 6f72 6473 5f64 6973 6329  , n_coords_disc)
-000084d0: 0d0a 0d0a 2020 2020 2020 2020 2320 6465  ....        # de
-000084e0: 7465 726d 696e 6520 616c 6c20 746f 2061  termine all to a
-000084f0: 6c6c 2064 6973 7461 6e63 6573 0d0a 2020  ll distances..  
-00008500: 2020 2020 2020 6469 7374 616e 6365 5f6d        distance_m
-00008510: 6174 7269 785f 7265 7361 6d70 6c65 203d  atrix_resample =
-00008520: 206e 702e 6f6e 6573 2828 6e5f 636f 6f72   np.ones((n_coor
-00008530: 6473 5f64 6973 632c 206e 5f63 6f6f 7264  ds_disc, n_coord
-00008540: 735f 6469 7363 2929 202a 206e 702e 6e61  s_disc)) * np.na
-00008550: 6e0d 0a0d 0a20 2020 2020 2020 2066 6f72  n....        for
-00008560: 2069 5f63 2c20 6320 696e 2065 6e75 6d65   i_c, c in enume
-00008570: 7261 7465 2863 6f6f 7264 735f 626f 7264  rate(coords_bord
-00008580: 6572 5b69 6478 5b3a 2c20 695d 2e61 7374  er[idx[:, i].ast
-00008590: 7970 6528 696e 7429 2c20 3a5d 293a 0d0a  ype(int), :]):..
-000085a0: 2020 2020 2020 2020 2020 2020 6469 7374              dist
-000085b0: 616e 6365 5f6d 6174 7269 785f 7265 7361  ance_matrix_resa
-000085c0: 6d70 6c65 5b69 5f63 2c20 3a5d 203d 206e  mple[i_c, :] = n
-000085d0: 702e 6c69 6e61 6c67 2e6e 6f72 6d28 636f  p.linalg.norm(co
-000085e0: 6f72 6473 5f62 6f72 6465 725b 6964 785b  ords_border[idx[
-000085f0: 3a2c 2069 5d2e 6173 7479 7065 2869 6e74  :, i].astype(int
-00008600: 292c 203a 5d20 2d20 632c 2061 7869 733d  ), :] - c, axis=
-00008610: 3129 0d0a 0d0a 2020 2020 2020 2020 6e70  1)....        np
-00008620: 2e66 696c 6c5f 6469 6167 6f6e 616c 2864  .fill_diagonal(d
-00008630: 6973 7461 6e63 655f 6d61 7472 6978 5f72  istance_matrix_r
-00008640: 6573 616d 706c 652c 2031 3030 3029 0d0a  esample, 1000)..
-00008650: 2020 2020 2020 2020 6469 7374 616e 6365          distance
-00008660: 5f6d 6561 6e5b 695d 203d 206e 702e 6d65  _mean[i] = np.me
-00008670: 616e 286e 702e 6d69 6e28 6469 7374 616e  an(np.min(distan
-00008680: 6365 5f6d 6174 7269 785f 7265 7361 6d70  ce_matrix_resamp
-00008690: 6c65 2c20 6178 6973 3d31 2929 0d0a 0d0a  le, axis=1))....
-000086a0: 2020 2020 636f 6f72 6473 5f64 6973 6320      coords_disc 
-000086b0: 3d20 636f 6f72 6473 5f62 6f72 6465 725b  = coords_border[
-000086c0: 6964 785b 3a2c 206e 702e 6172 676d 6178  idx[:, np.argmax
-000086d0: 2864 6973 7461 6e63 655f 6d65 616e 295d  (distance_mean)]
-000086e0: 2e61 7374 7970 6528 696e 7429 2c20 3a5d  .astype(int), :]
-000086f0: 0d0a 0d0a 2020 2020 7265 7475 726e 2063  ....    return c
-00008700: 6f6f 7264 735f 6469 7363 0d0a 0d0a 0d0a  oords_disc......
-00008710: 6465 6620 696e 6372 656d 656e 745f 6261  def increment_ba
-00008720: 7369 7328 6f72 6465 725f 6375 7272 656e  sis(order_curren
-00008730: 742c 2069 6e74 6572 6163 7469 6f6e 5f6f  t, interaction_o
-00008740: 7264 6572 5f63 7572 7265 6e74 2c20 696e  rder_current, in
-00008750: 7465 7261 6374 696f 6e5f 6f72 6465 725f  teraction_order_
-00008760: 6d61 782c 2069 6e63 7229 3a0d 0a20 2020  max, incr):..   
-00008770: 2022 2222 0d0a 2020 2020 496e 6372 656d   """..    Increm
-00008780: 656e 7473 2062 6173 6973 0d0a 0d0a 2020  ents basis....  
-00008790: 2020 5061 7261 6d65 7465 7273 0d0a 2020    Parameters..  
-000087a0: 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0d0a 2020    ----------..  
-000087b0: 2020 6f72 6465 725f 6375 7272 656e 743a    order_current:
-000087c0: 2069 6e74 0d0a 2020 2020 2020 2020 4d61   int..        Ma
-000087d0: 7869 6d75 6d20 676c 6f62 616c 2065 7870  ximum global exp
-000087e0: 616e 7369 6f6e 206f 7264 6572 2e0d 0a20  ansion order... 
-000087f0: 2020 2020 2020 2054 6865 206d 6178 696d         The maxim
-00008800: 756d 2065 7870 616e 7369 6f6e 206f 7264  um expansion ord
-00008810: 6572 2063 6f6e 7369 6465 7273 2074 6865  er considers the
-00008820: 2073 756d 206f 6620 7468 6520 6f72 6465   sum of the orde
-00008830: 7273 206f 6620 636f 6d62 696e 6564 2070  rs of combined p
-00008840: 6f6c 796e 6f6d 6961 6c73 2074 6f67 6574  olynomials toget
-00008850: 6865 7220 7769 7468 2074 6865 0d0a 2020  her with the..  
-00008860: 2020 2020 2020 6368 6f73 656e 206e 6f72        chosen nor
-00008870: 6d20 226f 7264 6572 5f6d 6178 5f6e 6f72  m "order_max_nor
-00008880: 6d22 2e20 5479 7069 6361 6c6c 7920 7468  m". Typically th
-00008890: 6973 206e 6f72 6d20 6973 2031 2073 7563  is norm is 1 suc
-000088a0: 6820 7468 6174 2074 6865 206d 6178 696d  h that the maxim
-000088b0: 756d 206f 7264 6572 2069 7320 7468 6520  um order is the 
-000088c0: 7375 6d20 6f66 2061 6c6c 0d0a 2020 2020  sum of all..    
-000088d0: 2020 2020 6d6f 6e6f 6d69 616c 206f 7264      monomial ord
-000088e0: 6572 732e 0d0a 2020 2020 696e 7465 7261  ers...    intera
-000088f0: 6374 696f 6e5f 6f72 6465 725f 6375 7272  ction_order_curr
-00008900: 656e 7420 3a20 696e 740d 0a20 2020 2020  ent : int..     
-00008910: 2020 2043 7572 7265 6e74 206e 756d 6265     Current numbe
-00008920: 7220 6f66 2072 616e 646f 6d20 7661 7269  r of random vari
-00008930: 6162 6c65 732c 2077 6869 6368 2063 616e  ables, which can
-00008940: 2069 6e74 6572 6163 7420 7769 7468 2065   interact with e
-00008950: 6163 6820 6f74 6865 720d 0a20 2020 2020  ach other..     
-00008960: 2020 2041 6c6c 2070 6f6c 796e 6f6d 6961     All polynomia
-00008970: 6c73 2061 7265 2069 676e 6f72 6564 2c20  ls are ignored, 
-00008980: 7768 6963 6820 6861 7665 2061 6e20 696e  which have an in
-00008990: 7465 7261 6374 696f 6e20 6f72 6465 7220  teraction order 
-000089a0: 6772 6561 7465 7220 7468 616e 2073 7065  greater than spe
-000089b0: 6369 6669 6564 0d0a 2020 2020 696e 7465  cified..    inte
-000089c0: 7261 6374 696f 6e5f 6f72 6465 725f 6d61  raction_order_ma
-000089d0: 7820 3a20 696e 740d 0a20 2020 2020 2020  x : int..       
-000089e0: 204d 6178 696d 756d 206e 756d 6265 7220   Maximum number 
-000089f0: 6f66 2072 616e 646f 6d20 7661 7269 6162  of random variab
-00008a00: 6c65 732c 2077 6869 6368 2063 616e 2069  les, which can i
-00008a10: 6e74 6572 6163 7420 7769 7468 2065 6163  nteract with eac
-00008a20: 6820 6f74 6865 720d 0a20 2020 2020 2020  h other..       
-00008a30: 2041 6c6c 2070 6f6c 796e 6f6d 6961 6c73   All polynomials
-00008a40: 2061 7265 2069 676e 6f72 6564 2c20 7768   are ignored, wh
-00008a50: 6963 6820 6861 7665 2061 6e20 696e 7465  ich have an inte
-00008a60: 7261 6374 696f 6e20 6f72 6465 7220 6772  raction order gr
-00008a70: 6561 7465 7220 7468 616e 2073 7065 6369  eater than speci
-00008a80: 6669 6564 0d0a 2020 2020 696e 6372 203a  fied..    incr :
-00008a90: 2069 6e74 0d0a 2020 2020 2020 2020 4e75   int..        Nu
-00008aa0: 6d62 6572 206f 6620 7375 622d 6974 6572  mber of sub-iter
-00008ab0: 6174 696f 6e20 696e 6372 656d 656e 7473  ation increments
-00008ac0: 0d0a 0d0a 2020 2020 5265 7475 726e 730d  ....    Returns.
-00008ad0: 0a20 2020 202d 2d2d 2d2d 2d2d 0d0a 2020  .    -------..  
-00008ae0: 2020 6f72 6465 7220 3a20 696e 740d 0a20    order : int.. 
-00008af0: 2020 2020 2020 2055 7064 6174 6564 206f         Updated o
-00008b00: 7264 6572 0d0a 2020 2020 696e 7465 7261  rder..    intera
-00008b10: 6374 696f 6e5f 6f72 6465 7220 3a20 696e  ction_order : in
-00008b20: 740d 0a20 2020 2020 2020 2055 7064 6174  t..        Updat
-00008b30: 6564 2069 6e74 6572 6163 7469 6f6e 206f  ed interaction o
-00008b40: 7264 6572 0d0a 2020 2020 2222 220d 0a20  rder..    """.. 
-00008b50: 2020 2077 6869 6c65 2069 6e63 7220 3e20     while incr > 
-00008b60: 303a 0d0a 2020 2020 2020 2020 6966 2069  0:..        if i
-00008b70: 6e74 6572 6163 7469 6f6e 5f6f 7264 6572  nteraction_order
-00008b80: 5f63 7572 7265 6e74 202b 2031 203c 3d20  _current + 1 <= 
-00008b90: 6d69 6e28 6f72 6465 725f 6375 7272 656e  min(order_curren
-00008ba0: 742c 2069 6e74 6572 6163 7469 6f6e 5f6f  t, interaction_o
-00008bb0: 7264 6572 5f6d 6178 293a 0d0a 2020 2020  rder_max):..    
-00008bc0: 2020 2020 2020 2020 696e 7465 7261 6374          interact
-00008bd0: 696f 6e5f 6f72 6465 725f 6375 7272 656e  ion_order_curren
-00008be0: 7420 2b3d 2031 0d0a 2020 2020 2020 2020  t += 1..        
-00008bf0: 656c 7365 3a0d 0a20 2020 2020 2020 2020  else:..         
-00008c00: 2020 206f 7264 6572 5f63 7572 7265 6e74     order_current
-00008c10: 202b 3d20 310d 0a20 2020 2020 2020 2020   += 1..         
-00008c20: 2020 2069 6e74 6572 6163 7469 6f6e 5f6f     interaction_o
-00008c30: 7264 6572 5f63 7572 7265 6e74 203d 2031  rder_current = 1
-00008c40: 0d0a 0d0a 2020 2020 2020 2020 696e 6372  ....        incr
-00008c50: 202d 3d20 310d 0a0d 0a20 2020 2072 6574   -= 1....    ret
-00008c60: 7572 6e20 6f72 6465 725f 6375 7272 656e  urn order_curren
-00008c70: 742c 2069 6e74 6572 6163 7469 6f6e 5f6f  t, interaction_o
-00008c80: 7264 6572 5f63 7572 7265 6e74 0d0a 0d0a  rder_current....
-00008c90: 0d0a 6465 6620 636f 6d70 7574 655f 6368  ..def compute_ch
-00008ca0: 756e 6b73 2873 6571 2c20 6e75 6d29 3a0d  unks(seq, num):.
-00008cb0: 0a20 2020 2022 2222 0d0a 2020 2020 5370  .    """..    Sp
-00008cc0: 6c69 7473 2075 7020 6120 7365 7175 656e  lits up a sequen
-00008cd0: 6365 205f 7365 715f 2069 6e74 6f20 5f6e  ce _seq_ into _n
-00008ce0: 756d 5f20 6368 756e 6b73 206f 6620 7369  um_ chunks of si
-00008cf0: 6d69 6c61 7220 7369 7a65 2e0d 0a20 2020  milar size...   
-00008d00: 2049 6620 6c65 6e28 7365 7129 203c 206e   If len(seq) < n
-00008d10: 756d 2c20 286e 756d 2d6c 656e 2873 6571  um, (num-len(seq
-00008d20: 2929 2065 6d70 7479 2063 6875 6e6b 7320  )) empty chunks 
-00008d30: 6172 6520 7265 7475 726e 6564 2073 6f20  are returned so 
-00008d40: 7468 6174 206c 656e 286f 7574 2920 3d3d  that len(out) ==
-00008d50: 206e 756d 0d0a 0d0a 2020 2020 5061 7261   num....    Para
-00008d60: 6d65 7465 7273 0d0a 2020 2020 2d2d 2d2d  meters..    ----
-00008d70: 2d2d 2d2d 2d2d 0d0a 2020 2020 7365 7120  ------..    seq 
-00008d80: 3a20 6c69 7374 206f 6620 736f 6d65 7468  : list of someth
-00008d90: 696e 6720 5b4e 5f65 6c65 5d0d 0a20 2020  ing [N_ele]..   
-00008da0: 2020 2020 204c 6973 7420 636f 6e74 6169       List contai
-00008db0: 6e69 6e67 2064 6174 6120 6f72 2069 6e64  ning data or ind
-00008dc0: 6963 6573 2c20 7768 6963 6820 6973 2064  ices, which is d
-00008dd0: 6976 6964 6564 2069 6e74 6f20 6368 756e  ivided into chun
-00008de0: 6b73 0d0a 2020 2020 6e75 6d20 3a20 696e  ks..    num : in
-00008df0: 740d 0a20 2020 2020 2020 204e 756d 6265  t..        Numbe
-00008e00: 7220 6f66 2063 6875 6e6b 7320 746f 2067  r of chunks to g
-00008e10: 656e 6572 6174 650d 0a0d 0a20 2020 2052  enerate....    R
-00008e20: 6574 7572 6e73 0d0a 2020 2020 2d2d 2d2d  eturns..    ----
-00008e30: 2d2d 2d0d 0a20 2020 206f 7574 203a 206c  ---..    out : l
-00008e40: 6973 7420 6f66 206e 756d 2073 7562 6c69  ist of num subli
-00008e50: 7374 730d 0a20 2020 2020 2020 206e 756d  sts..        num
-00008e60: 2073 7562 2d6c 6973 7473 206f 6620 7365   sub-lists of se
-00008e70: 7120 7769 7468 2065 6163 6820 6f66 2061  q with each of a
-00008e80: 2073 696d 696c 6172 206e 756d 6265 7220   similar number 
-00008e90: 6f66 2065 6c65 6d65 6e74 7320 286f 7220  of elements (or 
-00008ea0: 656d 7074 7929 2e0d 0a20 2020 2022 2222  empty)...    """
-00008eb0: 0d0a 2020 2020 6173 7365 7274 206c 656e  ..    assert len
-00008ec0: 2873 6571 2920 3e20 300d 0a20 2020 2061  (seq) > 0..    a
-00008ed0: 7373 6572 7420 6e75 6d20 3e20 300d 0a20  ssert num > 0.. 
-00008ee0: 2020 2023 2061 7373 6572 7420 6973 696e     # assert isin
-00008ef0: 7374 616e 6365 2873 6571 2c20 6c69 7374  stance(seq, list
-00008f00: 292c 2066 227b 7479 7065 2873 6571 297d  ), f"{type(seq)}
-00008f10: 2063 616e 2774 2062 6520 6368 756e 6b65   can't be chunke
-00008f20: 642e 2050 726f 7669 6465 206c 6973 742e  d. Provide list.
-00008f30: 220d 0a0d 0a20 2020 2061 7667 203d 206c  "....    avg = l
-00008f40: 656e 2873 6571 2920 2f20 666c 6f61 7428  en(seq) / float(
-00008f50: 6e75 6d29 0d0a 2020 2020 6e5f 656d 7074  num)..    n_empt
-00008f60: 7920 3d20 3020 2023 2069 6620 6c65 6e28  y = 0  # if len(
-00008f70: 7365 6729 203c 206e 756d 2c20 686f 7720  seg) < num, how 
-00008f80: 6d61 6e79 2065 6d70 7479 206c 6973 7473  many empty lists
-00008f90: 2074 6f20 6170 7065 6e64 2074 6f20 7265   to append to re
-00008fa0: 7475 726e 3f0d 0a0d 0a20 2020 2069 6620  turn?....    if 
-00008fb0: 6176 6720 3c20 313a 0d0a 2020 2020 2020  avg < 1:..      
-00008fc0: 2020 6176 6720 3d20 310d 0a20 2020 2020    avg = 1..     
-00008fd0: 2020 206e 5f65 6d70 7479 203d 206e 756d     n_empty = num
-00008fe0: 202d 206c 656e 2873 6571 290d 0a0d 0a20   - len(seq).... 
-00008ff0: 2020 206f 7574 203d 205b 5d0d 0a20 2020     out = []..   
-00009000: 206c 6173 7420 3d20 302e 300d 0a0d 0a20   last = 0.0.... 
-00009010: 2020 2077 6869 6c65 206c 6173 7420 3c20     while last < 
-00009020: 6c65 6e28 7365 7129 3a0d 0a20 2020 2020  len(seq):..     
-00009030: 2020 2023 2069 6620 6f6e 6c79 206f 6e65     # if only one
-00009040: 2065 6c65 6d65 6e74 2077 6f75 6c64 2062   element would b
-00009050: 6520 6c65 6674 2069 6e20 7468 6520 6c61  e left in the la
-00009060: 7374 2072 756e 2c20 6164 6420 6974 2074  st run, add it t
-00009070: 6f20 7468 6520 6375 7272 656e 740d 0a20  o the current.. 
-00009080: 2020 2020 2020 2069 6620 2869 6e74 286c         if (int(l
-00009090: 6173 7420 2b20 6176 6729 202b 2031 2920  ast + avg) + 1) 
-000090a0: 3d3d 206c 656e 2873 6571 293a 0d0a 2020  == len(seq):..  
-000090b0: 2020 2020 2020 2020 2020 6c61 7374 5f61            last_a
-000090c0: 7070 656e 645f 6964 7820 3d20 696e 7428  ppend_idx = int(
-000090d0: 6c61 7374 202b 2061 7667 2920 2b20 310d  last + avg) + 1.
-000090e0: 0a20 2020 2020 2020 2065 6c73 653a 0d0a  .        else:..
-000090f0: 2020 2020 2020 2020 2020 2020 6c61 7374              last
-00009100: 5f61 7070 656e 645f 6964 7820 3d20 696e  _append_idx = in
-00009110: 7428 6c61 7374 202b 2061 7667 290d 0a0d  t(last + avg)...
-00009120: 0a20 2020 2020 2020 206f 7574 2e61 7070  .        out.app
-00009130: 656e 6428 7365 715b 696e 7428 6c61 7374  end(seq[int(last
-00009140: 293a 6c61 7374 5f61 7070 656e 645f 6964  ):last_append_id
-00009150: 785d 290d 0a0d 0a20 2020 2020 2020 2069  x])....        i
-00009160: 6620 2869 6e74 286c 6173 7420 2b20 6176  f (int(last + av
-00009170: 6729 202b 2031 2920 3d3d 206c 656e 2873  g) + 1) == len(s
-00009180: 6571 293a 0d0a 2020 2020 2020 2020 2020  eq):..          
-00009190: 2020 6c61 7374 202b 3d20 6176 6720 2b20    last += avg + 
-000091a0: 310d 0a20 2020 2020 2020 2065 6c73 653a  1..        else:
-000091b0: 0d0a 2020 2020 2020 2020 2020 2020 6c61  ..            la
-000091c0: 7374 202b 3d20 6176 670d 0a0d 0a20 2020  st += avg....   
-000091d0: 2023 2061 7070 656e 6420 656d 7074 7920   # append empty 
-000091e0: 6c69 7374 7320 6966 206c 656e 2873 6571  lists if len(seq
-000091f0: 2920 3c20 6e75 6d0d 0a20 2020 206f 7574  ) < num..    out
-00009200: 202b 3d20 5b5b 5d5d 202a 206e 5f65 6d70   += [[]] * n_emp
-00009210: 7479 0d0a 0d0a 2020 2020 7265 7475 726e  ty....    return
-00009220: 206f 7574 0d0a 0d0a 0d0a 6465 6620 745f   out......def t_
-00009230: 6176 6572 6167 6564 5f6d 7574 7561 6c5f  averaged_mutual_
-00009240: 636f 6865 7265 6e63 6528 6172 7261 792c  coherence(array,
-00009250: 2074 3d30 2e32 293a 0d0a 2020 2020 2222   t=0.2):..    ""
-00009260: 220d 0a20 2020 2043 6f6d 7075 7465 7320  "..    Computes 
-00009270: 7468 6520 742d 6176 6572 6167 6564 206d  the t-averaged m
-00009280: 7574 7561 6c20 636f 6865 7265 6e63 652e  utual coherence.
-00009290: 0d0a 0d0a 2020 2020 5061 7261 6d65 7465  ....    Paramete
-000092a0: 7273 0d0a 2020 2020 2d2d 2d2d 2d2d 2d2d  rs..    --------
-000092b0: 2d2d 0d0a 2020 2020 6172 7261 7920 3a20  --..    array : 
-000092c0: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-000092d0: 205b 6d20 7820 6e5d 0d0a 2020 2020 2020   [m x n]..      
-000092e0: 2020 4d61 7472 6978 0d0a 2020 2020 7420    Matrix..    t 
-000092f0: 3a20 666c 6f61 740d 0a20 2020 2020 2020  : float..       
-00009300: 2054 6872 6573 686f 6c64 0d0a 0d0a 2020   Threshold....  
-00009310: 2020 5265 7475 726e 730d 0a20 2020 202d    Returns..    -
-00009320: 2d2d 2d2d 2d2d 0d0a 2020 2020 7265 7320  ------..    res 
-00009330: 3a20 666c 6f61 740d 0a20 2020 2020 2020  : float..       
-00009340: 2074 2d61 7665 7261 6765 6420 6d75 7475   t-averaged mutu
-00009350: 616c 2063 6f68 6572 656e 6365 0d0a 2020  al coherence..  
-00009360: 2020 2222 220d 0a20 2020 2061 7272 6179    """..    array
-00009370: 203d 206e 702e 6162 7328 6172 7261 7929   = np.abs(array)
-00009380: 0d0a 2020 2020 6d61 736b 203d 2061 7272  ..    mask = arr
-00009390: 6179 203e 2074 0d0a 0d0a 2020 2020 7265  ay > t....    re
-000093a0: 7475 726e 206e 702e 7375 6d28 6172 7261  turn np.sum(arra
-000093b0: 795b 6d61 736b 5d29 202f 206e 702e 7375  y[mask]) / np.su
-000093c0: 6d28 6d61 736b 290d 0a0d 0a0d 0a64 6566  m(mask)......def
-000093d0: 2061 7665 7261 6765 5f63 726f 7373 5f63   average_cross_c
-000093e0: 6f72 7265 6c61 7469 6f6e 5f67 7261 6d28  orrelation_gram(
-000093f0: 6172 7261 7929 3a0d 0a20 2020 2022 2222  array):..    """
-00009400: 0d0a 2020 2020 436f 6d70 7574 6573 2074  ..    Computes t
-00009410: 6865 2061 7665 7261 6765 2063 726f 7373  he average cross
-00009420: 2063 6f72 7265 6c61 7469 6f6e 206f 6620   correlation of 
-00009430: 7468 6520 6772 616d 206d 6174 7269 782e  the gram matrix.
-00009440: 0d0a 0d0a 2020 2020 5061 7261 6d65 7465  ....    Paramete
-00009450: 7273 0d0a 2020 2020 2d2d 2d2d 2d2d 2d2d  rs..    --------
-00009460: 2d2d 0d0a 2020 2020 6172 7261 7920 3a20  --..    array : 
-00009470: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-00009480: 205b 6d20 7820 6e5d 0d0a 2020 2020 2020   [m x n]..      
-00009490: 2020 4772 616d 206d 6174 7269 780d 0a0d    Gram matrix...
-000094a0: 0a20 2020 2052 6574 7572 6e73 0d0a 2020  .    Returns..  
-000094b0: 2020 2d2d 2d2d 2d2d 2d0d 0a20 2020 2072    -------..    r
-000094c0: 6573 203a 2066 6c6f 6174 0d0a 2020 2020  es : float..    
-000094d0: 2020 2020 6372 6f73 7320 636f 7272 656c      cross correl
-000094e0: 6174 696f 6e0d 0a20 2020 2022 2222 0d0a  ation..    """..
-000094f0: 2020 2020 6b20 3d20 6172 7261 792e 7368      k = array.sh
-00009500: 6170 655b 315d 0d0a 2020 2020 6e20 3d20  ape[1]..    n = 
-00009510: 6b20 2a20 286b 202d 2031 290d 0a0d 0a20  k * (k - 1).... 
-00009520: 2020 2072 6574 7572 6e20 2831 202f 206e     return (1 / n
-00009530: 2920 2a20 286e 702e 6c69 6e61 6c67 2e6e  ) * (np.linalg.n
-00009540: 6f72 6d28 6e70 2e69 6465 6e74 6974 7928  orm(np.identity(
-00009550: 6b29 202d 2061 7272 6179 2920 2a2a 2032  k) - array) ** 2
-00009560: 290d 0a0d 0a0d 0a64 6566 2050 6869 5028  )......def PhiP(
-00009570: 782c 2070 3d31 3029 3a0d 0a20 2020 2022  x, p=10):..    "
-00009580: 2222 0d0a 2020 2020 4361 6c63 756c 6174  ""..    Calculat
-00009590: 6573 2074 6865 2050 6869 2d70 2063 7269  es the Phi-p cri
-000095a0: 7465 7269 6f6e 206f 6620 7468 6520 6465  terion of the de
-000095b0: 7369 676e 2078 2077 6974 6820 706f 7765  sign x with powe
-000095c0: 7220 7020 5b31 5d2e 0d0a 0d0a 2020 2020  r p [1].....    
-000095d0: 5061 7261 6d65 7465 7273 0d0a 2020 2020  Parameters..    
-000095e0: 2d2d 2d2d 2d2d 2d2d 2d2d 0d0a 2020 2020  ----------..    
-000095f0: 7820 3a20 6e64 6172 7261 7920 6f66 2066  x : ndarray of f
-00009600: 6c6f 6174 205b 6e20 7820 6d5d 0d0a 2020  loat [n x m]..  
-00009610: 2020 2020 2020 5468 6520 6465 7369 676e        The design
-00009620: 2074 6f20 6361 6c63 756c 6174 6520 5068   to calculate Ph
-00009630: 692d 7020 666f 720d 0a20 2020 2070 203a  i-p for..    p :
-00009640: 2069 6e74 2c20 6f70 7469 6f6e 616c 2c20   int, optional, 
-00009650: 6465 6661 756c 743a 2031 300d 0a20 2020  default: 10..   
-00009660: 2020 2020 2054 6865 2070 6f77 6572 2075       The power u
-00009670: 7365 6420 666f 7220 7468 6520 6361 6c63  sed for the calc
-00009680: 756c 6174 696f 6e20 6f66 2050 6869 500d  ulation of PhiP.
-00009690: 0a0d 0a20 2020 2052 6574 7572 6e73 0d0a  ...    Returns..
-000096a0: 2020 2020 2d2d 2d2d 2d2d 2d0d 0a20 2020      -------..   
-000096b0: 2070 6869 7020 3a20 666c 6f61 740d 0a20   phip : float.. 
-000096c0: 2020 2020 2020 2050 6869 2d70 2063 7269         Phi-p cri
-000096d0: 7465 7269 6f6e 0d0a 0d0a 2020 2020 4e6f  terion....    No
-000096e0: 7465 730d 0a20 2020 202d 2d2d 2d2d 0d0a  tes..    -----..
-000096f0: 2020 2020 2e2e 205b 315d 204d 6f72 7269      .. [1] Morri
-00009700: 732c 204d 2e20 442e 2c20 2620 4d69 7463  s, M. D., & Mitc
-00009710: 6865 6c6c 2c20 542e 204a 2e20 2831 3939  hell, T. J. (199
-00009720: 3529 2e20 4578 706c 6f72 6174 6f72 7920  5). Exploratory 
-00009730: 6465 7369 676e 7320 666f 7220 636f 6d70  designs for comp
-00009740: 7574 6174 696f 6e61 6c20 6578 7065 7269  utational experi
-00009750: 6d65 6e74 732e 0d0a 2020 2020 2020 204a  ments...       J
-00009760: 6f75 726e 616c 206f 6620 7374 6174 6973  ournal of statis
-00009770: 7469 6361 6c20 706c 616e 6e69 6e67 2061  tical planning a
-00009780: 6e64 2069 6e66 6572 656e 6365 2c20 3433  nd inference, 43
-00009790: 2833 292c 2033 3831 2d34 3032 2e0d 0a20  (3), 381-402... 
-000097a0: 2020 2022 2222 0d0a 0d0a 2020 2020 7068     """....    ph
-000097b0: 6970 203d 2028 2873 6369 7079 2e73 7061  ip = ((scipy.spa
-000097c0: 7469 616c 2e64 6973 7461 6e63 652e 7064  tial.distance.pd
-000097d0: 6973 7428 7829 202a 2a20 282d 7029 292e  ist(x) ** (-p)).
-000097e0: 7375 6d28 2929 202a 2a20 2831 2e30 202f  sum()) ** (1.0 /
-000097f0: 2070 290d 0a0d 0a20 2020 2072 6574 7572   p)....    retur
-00009800: 6e20 7068 6970 0d0a 0d0a 0d0a 6465 6620  n phip......def 
-00009810: 706f 6c79 5f65 7870 616e 6428 6375 7272  poly_expand(curr
-00009820: 656e 745f 7365 742c 2074 6f5f 6578 7061  ent_set, to_expa
-00009830: 6e64 2c20 6f72 6465 725f 6d61 782c 2069  nd, order_max, i
-00009840: 6e74 6572 6163 7469 6f6e 5f6f 7264 6572  nteraction_order
-00009850: 293a 0d0a 2020 2020 2222 220d 0a20 2020  ):..    """..   
-00009860: 2041 6c67 6f72 6974 686d 2062 7920 4765   Algorithm by Ge
-00009870: 7273 746e 6572 2061 6e64 2047 7269 6562  rstner and Grieb
-00009880: 656c 2074 6f20 6578 7061 6e64 2070 6f6c  el to expand pol
-00009890: 796e 6f6d 6961 6c20 6261 7369 7320 5b31  ynomial basis [1
-000098a0: 5d20 6163 636f 7264 696e 6720 746f 2074  ] according to t
-000098b0: 776f 2063 7269 7465 7269 613a 0d0a 2020  wo criteria:..  
-000098c0: 2020 2020 2020 2831 2920 5468 6520 6261        (1) The ba
-000098d0: 7369 7320 6675 6e63 7469 6f6e 206d 6179  sis function may
-000098e0: 206e 6f74 2062 6520 636f 6d70 6c65 7465   not be complete
-000098f0: 6c79 2065 6e63 6c6f 7365 6420 6279 2061  ly enclosed by a
-00009900: 6c72 6561 6479 2065 7869 7374 696e 6720  lready existing 
-00009910: 6261 7369 7320 6675 6e63 7469 6f6e 732e  basis functions.
-00009920: 2049 6e20 7468 6973 2063 6173 6520 7468   In this case th
-00009930: 6520 6164 6465 640d 0a20 2020 2020 2020  e added..       
-00009940: 2020 2020 2062 6173 6973 2077 6f75 6c64       basis would
-00009950: 2062 6520 616c 7265 6164 7920 696e 636c   be already incl
-00009960: 7564 6564 2069 6e20 616e 7920 6361 7365  uded in any case
-00009970: 2e0d 0a20 2020 2020 2020 2028 3229 2054  ...        (2) T
-00009980: 6865 2062 6173 6973 2066 756e 6374 696f  he basis functio
-00009990: 6e20 6973 206e 6f74 2061 2063 616e 6469  n is not a candi
-000099a0: 6461 7465 2069 6620 6164 6469 6e67 2061  date if adding a
-000099b0: 6e79 2062 6173 6973 2077 6f75 6c64 2068  ny basis would h
-000099c0: 6176 6520 6e6f 2070 7265 6465 6365 7373  ave no predecess
-000099d0: 6f72 732e 2054 6865 206e 6577 2062 6173  ors. The new bas
-000099e0: 6973 206d 7573 7420 6861 7665 0d0a 2020  is must have..  
-000099f0: 2020 2020 2020 2020 2020 7072 6564 6563            predec
-00009a00: 6573 736f 7273 2069 6e20 616c 6c20 6465  essors in all de
-00009a10: 6372 6561 7369 6e67 2064 6972 6563 7469  creasing directi
-00009a20: 6f6e 2061 6e64 206d 6179 206e 6f74 2022  on and may not "
-00009a30: 666c 6f61 7422 2e0d 0a0d 0a20 2020 2050  float".....    P
-00009a40: 6172 616d 6574 6572 730d 0a20 2020 202d  arameters..    -
-00009a50: 2d2d 2d2d 2d2d 2d2d 2d0d 0a20 2020 2063  ---------..    c
-00009a60: 7572 7265 6e74 5f73 6574 203a 206e 6461  urrent_set : nda
-00009a70: 7272 6179 206f 6620 696e 7420 5b6e 5f62  rray of int [n_b
-00009a80: 6173 6973 2c20 6469 6d5d 0d0a 2020 2020  asis, dim]..    
-00009a90: 2020 2020 4172 7261 7920 6f66 206d 756c      Array of mul
-00009aa0: 7469 2d69 6e64 6963 6573 206f 6620 6261  ti-indices of ba
-00009ab0: 7369 7320 6675 6e63 7469 6f6e 730d 0a20  sis functions.. 
-00009ac0: 2020 2074 6f5f 6578 7061 6e64 203a 206e     to_expand : n
-00009ad0: 6461 7272 6179 206f 6620 696e 7420 5b64  darray of int [d
-00009ae0: 696d 5d0d 0a20 2020 2020 2020 2053 656c  im]..        Sel
-00009af0: 6563 7465 6420 6261 7369 7320 6675 6e63  ected basis func
-00009b00: 7469 6f6e 2028 7769 7468 2068 6967 6865  tion (with highe
-00009b10: 7374 2067 5043 2063 6f65 6666 6963 6965  st gPC coefficie
-00009b20: 6e74 292c 2077 6869 6368 2077 696c 6c20  nt), which will 
-00009b30: 6265 2065 7870 616e 6465 6420 696e 2061  be expanded in a
-00009b40: 6c6c 2070 6f73 7369 626c 6520 6469 7265  ll possible dire
-00009b50: 6374 696f 6e0d 0a20 2020 206f 7264 6572  ction..    order
-00009b60: 5f6d 6178 203a 2069 6e74 0d0a 2020 2020  _max : int..    
-00009b70: 2020 2020 4d61 7869 6d61 6c20 6163 6375      Maximal accu
-00009b80: 6d75 6c61 7465 6420 6f72 6465 7220 2873  mulated order (s
-00009b90: 756d 206f 7665 7220 616c 6c20 7061 7261  um over all para
-00009ba0: 6d65 7465 7273 290d 0a20 2020 2069 6e74  meters)..    int
-00009bb0: 6572 6163 7469 6f6e 5f6f 7264 6572 203a  eraction_order :
-00009bc0: 2069 6e74 0d0a 2020 2020 2020 2020 416c   int..        Al
-00009bd0: 6c6f 7765 6420 696e 7465 7261 6374 696f  lowed interactio
-00009be0: 6e20 6f72 6465 7220 6265 7477 6565 6e20  n order between 
-00009bf0: 7661 7269 6162 6c65 7320 283c 3d20 6469  variables (<= di
-00009c00: 6d29 0d0a 0d0a 2020 2020 5265 7475 726e  m)....    Return
-00009c10: 730d 0a20 2020 202d 2d2d 2d2d 2d2d 0d0a  s..    -------..
-00009c20: 2020 2020 6578 7061 6e64 203a 206e 6461      expand : nda
-00009c30: 7272 6179 206f 6620 696e 7420 5b6e 5f62  rray of int [n_b
-00009c40: 6173 6973 2c20 6469 6d5d 0d0a 2020 2020  asis, dim]..    
-00009c50: 2020 2020 4172 7261 7920 6f66 206d 756c      Array of mul
-00009c60: 7469 2d69 6e64 6963 6573 2c20 7768 6963  ti-indices, whic
-00009c70: 6820 7769 6c6c 2062 6520 6164 6465 6420  h will be added 
-00009c80: 746f 2074 6865 2073 6574 206f 6620 6261  to the set of ba
-00009c90: 7369 7320 6675 6e63 7469 6f6e 730d 0a0d  sis functions...
-00009ca0: 0a20 2020 204e 6f74 6573 0d0a 2020 2020  .    Notes..    
-00009cb0: 2d2d 2d2d 2d0d 0a20 2020 202e 2e20 5b31  -----..    .. [1
-00009cc0: 5d20 5420 4765 7273 746e 6572 2061 6e64  ] T Gerstner and
-00009cd0: 204d 2047 7269 6562 656c 2e20 4469 6d65   M Griebel. Dime
-00009ce0: 6e73 696f 6e20 6164 6170 7469 7665 2074  nsion adaptive t
-00009cf0: 656e 736f 7220 7072 6f64 7563 7420 7175  ensor product qu
-00009d00: 6164 7261 7475 7265 2e20 436f 6d70 7574  adrature. Comput
-00009d10: 696e 672c 2037 313a 3635 e280 9338 372c  ing, 71:65...87,
-00009d20: 2032 3030 332e 0d0a 2020 2020 2222 220d   2003...    """.
-00009d30: 0a0d 0a20 2020 2069 6620 7479 7065 2863  ...    if type(c
-00009d40: 7572 7265 6e74 5f73 6574 2920 6973 206e  urrent_set) is n
-00009d50: 6f74 206c 6973 743a 0d0a 2020 2020 2020  ot list:..      
-00009d60: 2020 6375 7272 656e 745f 7365 7420 3d20    current_set = 
-00009d70: 6375 7272 656e 745f 7365 742e 746f 6c69  current_set.toli
-00009d80: 7374 2829 0d0a 0d0a 2020 2020 6578 7061  st()....    expa
-00009d90: 6e64 203d 205b 5d0d 0a20 2020 2066 6f72  nd = []..    for
-00009da0: 2065 2069 6e20 7261 6e67 6528 6c65 6e28   e in range(len(
-00009db0: 746f 5f65 7870 616e 6429 293a 0d0a 2020  to_expand)):..  
-00009dc0: 2020 2020 2020 666f 7277 6172 6420 3d20        forward = 
-00009dd0: 636f 7079 2e64 6565 7063 6f70 7928 746f  copy.deepcopy(to
-00009de0: 5f65 7870 616e 6429 0d0a 2020 2020 2020  _expand)..      
-00009df0: 2020 666f 7277 6172 645b 655d 202b 3d20    forward[e] += 
-00009e00: 310d 0a20 2020 2020 2020 2068 6173 5f70  1..        has_p
-00009e10: 7265 6465 6365 7373 6f72 7320 3d20 5472  redecessors = Tr
-00009e20: 7565 0d0a 2020 2020 2020 2020 666f 7220  ue..        for 
-00009e30: 6532 2069 6e20 7261 6e67 6528 6c65 6e28  e2 in range(len(
-00009e40: 746f 5f65 7870 616e 6429 293a 0d0a 2020  to_expand)):..  
-00009e50: 2020 2020 2020 2020 2020 6966 2066 6f72            if for
-00009e60: 7761 7264 5b65 325d 203e 2030 3a0d 0a20  ward[e2] > 0:.. 
-00009e70: 2020 2020 2020 2020 2020 2020 2020 2070                 p
-00009e80: 7265 6465 6365 7373 6f72 203d 2066 6f72  redecessor = for
-00009e90: 7761 7264 2e63 6f70 7928 290d 0a20 2020  ward.copy()..   
-00009ea0: 2020 2020 2020 2020 2020 2020 2070 7265               pre
-00009eb0: 6465 6365 7373 6f72 5b65 325d 202d 3d20  decessor[e2] -= 
-00009ec0: 310d 0a20 2020 2020 2020 2020 2020 2020  1..             
-00009ed0: 2020 2068 6173 5f70 7265 6465 6365 7373     has_predecess
-00009ee0: 6f72 7320 2a3d 206c 6973 7428 7072 6564  ors *= list(pred
-00009ef0: 6563 6573 736f 7229 2069 6e20 6375 7272  ecessor) in curr
-00009f00: 656e 745f 7365 740d 0a20 2020 2020 2020  ent_set..       
-00009f10: 2069 6620 6861 735f 7072 6564 6563 6573   if has_predeces
-00009f20: 736f 7273 2061 6e64 2028 6e70 2e73 756d  sors and (np.sum
-00009f30: 286e 702e 6162 7328 666f 7277 6172 6429  (np.abs(forward)
-00009f40: 2920 3c3d 206f 7264 6572 5f6d 6178 2920  ) <= order_max) 
-00009f50: 616e 6420 286e 702e 7375 6d28 666f 7277  and (np.sum(forw
-00009f60: 6172 6420 3e20 3029 203c 3d20 696e 7465  ard > 0) <= inte
-00009f70: 7261 6374 696f 6e5f 6f72 6465 7229 3a0d  raction_order):.
-00009f80: 0a20 2020 2020 2020 2020 2020 2065 7870  .            exp
-00009f90: 616e 6420 2b3d 205b 7475 706c 6528 666f  and += [tuple(fo
-00009fa0: 7277 6172 6429 5d0d 0a0d 0a20 2020 2072  rward)]....    r
-00009fb0: 6574 7572 6e20 6e70 2e61 7272 6179 2865  eturn np.array(e
-00009fc0: 7870 616e 6429 0d0a 0d0a 0d0a 6465 6620  xpand)......def 
-00009fd0: 6765 745f 6e6f 6e5f 656e 636c 6f73 6564  get_non_enclosed
-00009fe0: 5f6d 756c 7469 5f69 6e64 6963 6573 286d  _multi_indices(m
-00009ff0: 756c 7469 5f69 6e64 6963 6573 2c20 696e  ulti_indices, in
-0000a000: 7465 7261 6374 696f 6e5f 6f72 6465 7229  teraction_order)
-0000a010: 3a0d 0a20 2020 2022 2222 0d0a 2020 2020  :..    """..    
-0000a020: 4578 7472 6163 7420 706f 7373 6962 6c65  Extract possible
-0000a030: 206d 756c 7469 2d69 6e64 6963 6573 2066   multi-indices f
-0000a040: 726f 6d20 6120 6769 7665 6e20 7365 7420  rom a given set 
-0000a050: 7768 6963 6820 6172 6520 706f 7465 6e74  which are potent
-0000a060: 6961 6c20 6361 6e64 6964 6174 6573 2066  ial candidates f
-0000a070: 6f72 2061 6e69 736f 7472 6f70 6963 2062  or anisotropic b
-0000a080: 6173 6973 2065 7874 656e 7369 6f6e 2e0d  asis extension..
-0000a090: 0a20 2020 2054 776f 2063 7269 7465 7269  .    Two criteri
-0000a0a0: 6120 6d75 7374 2062 6520 6d65 743a 0d0a  a must be met:..
-0000a0b0: 2020 2020 2831 2920 5468 6520 6261 7369      (1) The basi
-0000a0c0: 7320 6675 6e63 7469 6f6e 206d 6179 206e  s function may n
-0000a0d0: 6f74 2062 6520 636f 6d70 6c65 7465 6c79  ot be completely
-0000a0e0: 2065 6e63 6c6f 7365 6420 6279 2061 6c72   enclosed by alr
-0000a0f0: 6561 6479 2065 7869 7374 696e 6720 6261  eady existing ba
-0000a100: 7369 7320 6675 6e63 7469 6f6e 732e 2049  sis functions. I
-0000a110: 6e20 7468 6973 2063 6173 6520 7468 6520  n this case the 
-0000a120: 6164 6465 640d 0a20 2020 2020 2020 2062  added..        b
-0000a130: 6173 6973 2077 6f75 6c64 2062 6520 616c  asis would be al
-0000a140: 7265 6164 7920 696e 636c 7564 6564 2069  ready included i
-0000a150: 6e20 616e 7920 6361 7365 2e0d 0a20 2020  n any case...   
-0000a160: 2028 3229 2054 6865 2062 6173 6973 2066   (2) The basis f
-0000a170: 756e 6374 696f 6e20 6973 206e 6f74 2061  unction is not a
-0000a180: 2063 616e 6469 6461 7465 2069 6620 6164   candidate if ad
-0000a190: 6469 6e67 2061 6e79 2062 6173 6973 2077  ding any basis w
-0000a1a0: 6f75 6c64 2068 6176 6520 6e6f 2070 7265  ould have no pre
-0000a1b0: 6465 6365 7373 6f72 732e 2054 6865 206e  decessors. The n
-0000a1c0: 6577 2062 6173 6973 206d 7573 7420 6861  ew basis must ha
-0000a1d0: 7665 0d0a 2020 2020 2020 2020 7072 6564  ve..        pred
-0000a1e0: 6563 6573 736f 7273 2069 6e20 616c 6c20  ecessors in all 
-0000a1f0: 6465 6372 6561 7369 6e67 2064 6972 6563  decreasing direc
-0000a200: 7469 6f6e 2061 6e64 206d 6179 206e 6f74  tion and may not
-0000a210: 2022 666c 6f61 7422 2e0d 0a0d 0a20 2020   "float".....   
-0000a220: 2050 6172 616d 6574 6572 730d 0a20 2020   Parameters..   
-0000a230: 202d 2d2d 2d2d 2d2d 2d2d 2d0d 0a20 2020   ----------..   
-0000a240: 206d 756c 7469 5f69 6e64 6963 6573 203a   multi_indices :
-0000a250: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-0000a260: 7420 5b6e 5f62 6173 6973 2c20 6469 6d5d  t [n_basis, dim]
-0000a270: 0d0a 2020 2020 2020 2020 4172 7261 7920  ..        Array 
-0000a280: 6f66 206d 756c 7469 2d69 6e64 6963 6573  of multi-indices
-0000a290: 206f 6620 6261 7369 7320 6675 6e63 7469   of basis functi
-0000a2a0: 6f6e 730d 0a20 2020 2069 6e74 6572 6163  ons..    interac
-0000a2b0: 7469 6f6e 5f6f 7264 6572 203a 2069 6e74  tion_order : int
-0000a2c0: 0d0a 2020 2020 2020 2020 416c 6c6f 7765  ..        Allowe
-0000a2d0: 6420 696e 7465 7261 6374 696f 6e20 6f72  d interaction or
-0000a2e0: 6465 7220 6265 7477 6565 6e20 7661 7269  der between vari
-0000a2f0: 6162 6c65 7320 283c 3d20 6469 6d29 0d0a  ables (<= dim)..
-0000a300: 0d0a 2020 2020 5265 7475 726e 730d 0a20  ..    Returns.. 
-0000a310: 2020 202d 2d2d 2d2d 2d2d 0d0a 2020 2020     -------..    
-0000a320: 6d75 6c74 695f 696e 6469 6365 735f 6e6f  multi_indices_no
-0000a330: 6e5f 656e 636c 6f73 6564 203a 206e 6461  n_enclosed : nda
-0000a340: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
-0000a350: 5f62 6173 6973 5f63 616e 6469 6461 7465  _basis_candidate
-0000a360: 732c 2064 696d 5d0d 0a20 2020 2020 2020  s, dim]..       
-0000a370: 2041 7272 6179 206f 6620 706f 7373 6962   Array of possib
-0000a380: 6c65 206d 756c 7469 2d69 6e64 6963 6573  le multi-indices
-0000a390: 206f 6620 6261 7369 7320 6675 6e63 7469   of basis functi
-0000a3a0: 6f6e 730d 0a20 2020 2070 6f6c 795f 696e  ons..    poly_in
-0000a3b0: 6469 6365 735f 6e6f 6e5f 656e 636c 6f73  dices_non_enclos
-0000a3c0: 6564 203a 206c 6973 7420 6f66 2069 6e74  ed : list of int
-0000a3d0: 0d0a 2020 2020 2020 2020 496e 6469 6365  ..        Indice
-0000a3e0: 7320 6f66 2073 656c 6563 7465 6420 6261  s of selected ba
-0000a3f0: 7369 7320 6675 6e63 7469 6f6e 7320 696e  sis functions in
-0000a400: 2067 6c6f 6261 6c20 226d 756c 7469 2d69   global "multi-i
-0000a410: 6e64 6963 6573 2220 6172 7261 790d 0a20  ndices" array.. 
-0000a420: 2020 2022 2222 0d0a 2020 2020 6d75 6c74     """..    mult
-0000a430: 695f 696e 6469 6365 735f 6e6f 6e5f 656e  i_indices_non_en
-0000a440: 636c 6f73 6564 203d 205b 5d0d 0a0d 0a20  closed = [].... 
-0000a450: 2020 2069 6620 7479 7065 286d 756c 7469     if type(multi
-0000a460: 5f69 6e64 6963 6573 2920 6973 206e 6f74  _indices) is not
-0000a470: 206c 6973 743a 0d0a 2020 2020 2020 2020   list:..        
-0000a480: 6d75 6c74 695f 696e 6469 6365 7320 3d20  multi_indices = 
-0000a490: 6d75 6c74 695f 696e 6469 6365 732e 746f  multi_indices.to
-0000a4a0: 6c69 7374 2829 0d0a 0d0a 2020 2020 6469  list()....    di
-0000a4b0: 6d20 3d20 6c65 6e28 6d75 6c74 695f 696e  m = len(multi_in
-0000a4c0: 6469 6365 735b 305d 290d 0a0d 0a20 2020  dices[0])....   
-0000a4d0: 2066 6f72 206d 2069 6e20 6e70 2e61 7272   for m in np.arr
-0000a4e0: 6179 286d 756c 7469 5f69 6e64 6963 6573  ay(multi_indices
-0000a4f0: 293a 0d0a 2020 2020 2020 2020 666f 7220  ):..        for 
-0000a500: 695f 6469 6d20 696e 2072 616e 6765 2864  i_dim in range(d
-0000a510: 696d 293a 0d0a 2020 2020 2020 2020 2020  im):..          
-0000a520: 2020 6d5f 7465 7374 203d 2063 6f70 792e    m_test = copy.
-0000a530: 6465 6570 636f 7079 286e 702e 6172 7261  deepcopy(np.arra
-0000a540: 7928 6d29 290d 0a20 2020 2020 2020 2020  y(m))..         
-0000a550: 2020 206d 5f74 6573 745b 695f 6469 6d5d     m_test[i_dim]
-0000a560: 203d 206d 5f74 6573 745b 695f 6469 6d5d   = m_test[i_dim]
-0000a570: 202b 2031 0d0a 2020 2020 2020 2020 2020   + 1..          
-0000a580: 2020 6861 735f 7072 6564 6563 6573 736f    has_predecesso
-0000a590: 7273 203d 2054 7275 650d 0a0d 0a20 2020  rs = True....   
-0000a5a0: 2020 2020 2020 2020 2069 6620 6e70 2e73           if np.s
-0000a5b0: 756d 286d 5f74 6573 7420 3e20 3029 203c  um(m_test > 0) <
-0000a5c0: 3d20 696e 7465 7261 6374 696f 6e5f 6f72  = interaction_or
-0000a5d0: 6465 723a 0d0a 2020 2020 2020 2020 2020  der:..          
-0000a5e0: 2020 2020 2020 6966 206c 6973 7428 6d5f        if list(m_
-0000a5f0: 7465 7374 2920 6e6f 7420 696e 206d 756c  test) not in mul
-0000a600: 7469 5f69 6e64 6963 6573 3a0d 0a20 2020  ti_indices:..   
-0000a610: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a620: 2066 6f72 2065 3220 696e 2072 616e 6765   for e2 in range
-0000a630: 2864 696d 293a 0d0a 2020 2020 2020 2020  (dim):..        
-0000a640: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a650: 6966 206d 5f74 6573 745b 6532 5d20 3e20  if m_test[e2] > 
-0000a660: 303a 0d0a 2020 2020 2020 2020 2020 2020  0:..            
-0000a670: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a680: 7072 6564 6563 6573 736f 7220 3d20 636f  predecessor = co
-0000a690: 7079 2e64 6565 7063 6f70 7928 6d5f 7465  py.deepcopy(m_te
-0000a6a0: 7374 290d 0a20 2020 2020 2020 2020 2020  st)..           
-0000a6b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a6c0: 2070 7265 6465 6365 7373 6f72 5b65 325d   predecessor[e2]
-0000a6d0: 203d 2070 7265 6465 6365 7373 6f72 5b65   = predecessor[e
-0000a6e0: 325d 202d 2031 0d0a 2020 2020 2020 2020  2] - 1..        
-0000a6f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a700: 2020 2020 6861 735f 7072 6564 6563 6573      has_predeces
-0000a710: 736f 7273 202a 3d20 6c69 7374 2870 7265  sors *= list(pre
-0000a720: 6465 6365 7373 6f72 2920 696e 206d 756c  decessor) in mul
-0000a730: 7469 5f69 6e64 6963 6573 0d0a 2020 2020  ti_indices..    
-0000a740: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a750: 6966 2068 6173 5f70 7265 6465 6365 7373  if has_predecess
-0000a760: 6f72 733a 0d0a 2020 2020 2020 2020 2020  ors:..          
-0000a770: 2020 2020 2020 2020 2020 2020 2020 6d75                mu
-0000a780: 6c74 695f 696e 6469 6365 735f 6e6f 6e5f  lti_indices_non_
-0000a790: 656e 636c 6f73 6564 2e61 7070 656e 6428  enclosed.append(
-0000a7a0: 6d29 0d0a 0d0a 2020 2020 6d75 6c74 695f  m)....    multi_
-0000a7b0: 696e 6469 6365 735f 6e6f 6e5f 656e 636c  indices_non_encl
-0000a7c0: 6f73 6564 203d 206e 702e 756e 6971 7565  osed = np.unique
-0000a7d0: 286d 756c 7469 5f69 6e64 6963 6573 5f6e  (multi_indices_n
-0000a7e0: 6f6e 5f65 6e63 6c6f 7365 642c 2061 7869  on_enclosed, axi
-0000a7f0: 733d 3029 0d0a 2020 2020 706f 6c79 5f69  s=0)..    poly_i
-0000a800: 6e64 6963 6573 5f6e 6f6e 5f65 6e63 6c6f  ndices_non_enclo
-0000a810: 7365 6420 3d20 5b6e 702e 7768 6572 6528  sed = [np.where(
-0000a820: 286d 756c 7469 5f69 6e64 6963 6573 203d  (multi_indices =
-0000a830: 3d20 6d29 2e61 6c6c 2861 7869 733d 3129  = m).all(axis=1)
-0000a840: 295b 305d 5b30 5d20 666f 7220 6d20 696e  )[0][0] for m in
-0000a850: 206d 756c 7469 5f69 6e64 6963 6573 5f6e   multi_indices_n
-0000a860: 6f6e 5f65 6e63 6c6f 7365 645d 0d0a 0d0a  on_enclosed]....
-0000a870: 2020 2020 7265 7475 726e 206d 756c 7469      return multi
-0000a880: 5f69 6e64 6963 6573 5f6e 6f6e 5f65 6e63  _indices_non_enc
-0000a890: 6c6f 7365 642c 2070 6f6c 795f 696e 6469  losed, poly_indi
-0000a8a0: 6365 735f 6e6f 6e5f 656e 636c 6f73 6564  ces_non_enclosed
-0000a8b0: 0d0a 0d0a 0d0a 6465 6620 706c 6f74 5f62  ......def plot_b
-0000a8c0: 6173 6973 5f62 795f 6d75 6c74 6969 6e64  asis_by_multiind
-0000a8d0: 6578 2861 293a 0d0a 2020 2020 2222 220d  ex(a):..    """.
-0000a8e0: 0a0d 0a20 2020 2050 6172 616d 6574 6572  ...    Parameter
-0000a8f0: 730d 0a20 2020 202d 2d2d 2d2d 2d2d 2d2d  s..    ---------
-0000a900: 2d0d 0a20 2020 2061 0d0a 0d0a 2020 2020  -..    a....    
-0000a910: 5265 7475 726e 730d 0a20 2020 202d 2d2d  Returns..    ---
-0000a920: 2d2d 2d2d 0d0a 0d0a 2020 2020 2222 220d  ----....    """.
-0000a930: 0a20 2020 2066 6967 203d 2070 6c74 2e66  .    fig = plt.f
-0000a940: 6967 7572 6528 6669 6773 697a 653d 2834  igure(figsize=(4
-0000a950: 2c20 3429 290d 0a0d 0a20 2020 2061 7820  , 4))....    ax 
-0000a960: 3d20 6669 672e 6164 645f 7375 6270 6c6f  = fig.add_subplo
-0000a970: 7428 3131 312c 2070 726f 6a65 6374 696f  t(111, projectio
-0000a980: 6e3d 2733 6427 290d 0a0d 0a20 2020 2066  n='3d')....    f
-0000a990: 6f72 2069 2069 6e20 7261 6e67 6528 6c65  or i in range(le
-0000a9a0: 6e28 6129 293a 0d0a 2020 2020 2020 2020  n(a)):..        
-0000a9b0: 6520 3d20 302e 330d 0a20 2020 2020 2020  e = 0.3..       
-0000a9c0: 2078 203d 2061 5b69 5d5b 305d 202b 2065   x = a[i][0] + e
-0000a9d0: 0d0a 2020 2020 2020 2020 7920 3d20 615b  ..        y = a[
-0000a9e0: 695d 5b31 5d20 2b20 650d 0a20 2020 2020  i][1] + e..     
-0000a9f0: 2020 207a 203d 2061 5b69 5d5b 325d 202b     z = a[i][2] +
-0000aa00: 2065 0d0a 2020 2020 2020 2020 7665 7274   e..        vert
-0000aa10: 6963 6573 203d 205b 5b28 7820 2b20 652c  ices = [[(x + e,
-0000aa20: 2079 202b 2065 2c20 7a20 2b20 6529 2c20   y + e, z + e), 
-0000aa30: 2878 202b 2065 2c20 7920 2b20 652c 207a  (x + e, y + e, z
-0000aa40: 202d 2065 292c 2028 7820 2b20 652c 2079   - e), (x + e, y
-0000aa50: 202d 2065 2c20 7a20 2d20 6529 2c20 2878   - e, z - e), (x
-0000aa60: 202b 2065 2c20 7920 2d20 652c 207a 202b   + e, y - e, z +
-0000aa70: 2065 295d 2c0d 0a20 2020 2020 2020 2020   e)],..         
-0000aa80: 2020 2020 2020 2020 2020 205b 2878 202d             [(x -
-0000aa90: 2065 2c20 7920 2b20 652c 207a 202b 2065   e, y + e, z + e
-0000aaa0: 292c 2028 7820 2d20 652c 2079 202b 2065  ), (x - e, y + e
-0000aab0: 2c20 7a20 2d20 6529 2c20 2878 202d 2065  , z - e), (x - e
-0000aac0: 2c20 7920 2d20 652c 207a 202d 2065 292c  , y - e, z - e),
-0000aad0: 2028 7820 2d20 652c 2079 202d 2065 2c20   (x - e, y - e, 
-0000aae0: 7a20 2b20 6529 5d2c 0d0a 2020 2020 2020  z + e)],..      
-0000aaf0: 2020 2020 2020 2020 2020 2020 2020 5b28                [(
-0000ab00: 7820 2b20 652c 2079 202b 2065 2c20 7a20  x + e, y + e, z 
-0000ab10: 2b20 6529 2c20 2878 202b 2065 2c20 7920  + e), (x + e, y 
-0000ab20: 2b20 652c 207a 202d 2065 292c 2028 7820  + e, z - e), (x 
-0000ab30: 2d20 652c 2079 202b 2065 2c20 7a20 2d20  - e, y + e, z - 
-0000ab40: 6529 2c20 2878 202d 2065 2c20 7920 2b20  e), (x - e, y + 
-0000ab50: 652c 207a 202b 2065 295d 2c0d 0a20 2020  e, z + e)],..   
-0000ab60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ab70: 205b 2878 202b 2065 2c20 7920 2d20 652c   [(x + e, y - e,
-0000ab80: 207a 202b 2065 292c 2028 7820 2b20 652c   z + e), (x + e,
-0000ab90: 2079 202d 2065 2c20 7a20 2d20 6529 2c20   y - e, z - e), 
-0000aba0: 2878 202d 2065 2c20 7920 2d20 652c 207a  (x - e, y - e, z
-0000abb0: 202d 2065 292c 2028 7820 2d20 652c 2079   - e), (x - e, y
-0000abc0: 202d 2065 2c20 7a20 2b20 6529 5d2c 0d0a   - e, z + e)],..
-0000abd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000abe0: 2020 2020 5b28 7820 2b20 652c 2079 202b      [(x + e, y +
-0000abf0: 2065 2c20 7a20 2b20 6529 2c20 2878 202b   e, z + e), (x +
-0000ac00: 2065 2c20 7920 2d20 652c 207a 202b 2065   e, y - e, z + e
-0000ac10: 292c 2028 7820 2d20 652c 2079 202d 2065  ), (x - e, y - e
-0000ac20: 2c20 7a20 2b20 6529 2c20 2878 202d 2065  , z + e), (x - e
-0000ac30: 2c20 7920 2b20 652c 207a 202b 2065 295d  , y + e, z + e)]
-0000ac40: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-0000ac50: 2020 2020 2020 205b 2878 202b 2065 2c20         [(x + e, 
-0000ac60: 7920 2b20 652c 207a 202d 2065 292c 2028  y + e, z - e), (
-0000ac70: 7820 2b20 652c 2079 202d 2065 2c20 7a20  x + e, y - e, z 
-0000ac80: 2d20 6529 2c20 2878 202d 2065 2c20 7920  - e), (x - e, y 
-0000ac90: 2d20 652c 207a 202d 2065 292c 2028 7820  - e, z - e), (x 
-0000aca0: 2d20 652c 2079 202b 2065 2c20 7a20 2d20  - e, y + e, z - 
-0000acb0: 6529 5d5d 0d0a 2020 2020 2020 2020 706f  e)]]..        po
-0000acc0: 6c79 203d 2050 6f6c 7933 4443 6f6c 6c65  ly = Poly3DColle
-0000acd0: 6374 696f 6e28 7665 7274 6963 6573 2c20  ction(vertices, 
-0000ace0: 616c 7068 613d 302e 3529 0d0a 2020 2020  alpha=0.5)..    
-0000acf0: 2020 2020 6178 2e61 6464 5f63 6f6c 6c65      ax.add_colle
-0000ad00: 6374 696f 6e33 6428 706f 6c79 290d 0a0d  ction3d(poly)...
-0000ad10: 0a20 2020 2020 2020 2066 6f72 206a 2069  .        for j i
-0000ad20: 6e20 7261 6e67 6528 3629 3a0d 0a20 2020  n range(6):..   
-0000ad30: 2020 2020 2020 2020 206c 696e 655f 7873           line_xs
-0000ad40: 203d 206e 702e 6873 7461 636b 2828 6e70   = np.hstack((np
-0000ad50: 2e61 7272 6179 2876 6572 7469 6365 735b  .array(vertices[
-0000ad60: 6a5d 292e 545b 305d 2c20 6e70 2e61 7272  j]).T[0], np.arr
-0000ad70: 6179 2876 6572 7469 6365 735b 6a5d 292e  ay(vertices[j]).
-0000ad80: 545b 305d 5b30 5d29 290d 0a20 2020 2020  T[0][0]))..     
-0000ad90: 2020 2020 2020 206c 696e 655f 7973 203d         line_ys =
-0000ada0: 206e 702e 6873 7461 636b 2828 6e70 2e61   np.hstack((np.a
-0000adb0: 7272 6179 2876 6572 7469 6365 735b 6a5d  rray(vertices[j]
-0000adc0: 292e 545b 315d 2c20 6e70 2e61 7272 6179  ).T[1], np.array
-0000add0: 2876 6572 7469 6365 735b 6a5d 292e 545b  (vertices[j]).T[
-0000ade0: 315d 5b30 5d29 290d 0a20 2020 2020 2020  1][0]))..       
-0000adf0: 2020 2020 206c 696e 655f 7a73 203d 206e       line_zs = n
-0000ae00: 702e 6873 7461 636b 2828 6e70 2e61 7272  p.hstack((np.arr
-0000ae10: 6179 2876 6572 7469 6365 735b 6a5d 292e  ay(vertices[j]).
-0000ae20: 545b 325d 2c20 6e70 2e61 7272 6179 2876  T[2], np.array(v
-0000ae30: 6572 7469 6365 735b 6a5d 292e 545b 325d  ertices[j]).T[2]
-0000ae40: 5b30 5d29 290d 0a20 2020 2020 2020 2020  [0]))..         
-0000ae50: 2020 2070 6c74 2e70 6c6f 7428 6c69 6e65     plt.plot(line
-0000ae60: 5f78 732c 206c 696e 655f 7973 2c20 6c69  _xs, line_ys, li
-0000ae70: 6e65 5f7a 732c 2063 6f6c 6f72 3d27 6b27  ne_zs, color='k'
-0000ae80: 290d 0a0d 0a20 2020 2061 782e 7365 745f  )....    ax.set_
-0000ae90: 786c 696d 2830 2c20 3329 0d0a 2020 2020  xlim(0, 3)..    
-0000aea0: 6178 2e73 6574 5f79 6c69 6d28 302c 2033  ax.set_ylim(0, 3
-0000aeb0: 290d 0a20 2020 2061 782e 7365 745f 7a6c  )..    ax.set_zl
-0000aec0: 696d 2830 2c20 3329 0d0a 2020 2020 706c  im(0, 3)..    pl
-0000aed0: 742e 7368 6f77 2829                      t.show()
+00001500: 205b 6d33 2078 206e 5d0a 2020 2020 2020   [m3 x n].      
+00001510: 2020 526f 7773 2066 726f 6d20 6220 6469    Rows from b di
+00001520: 6666 6572 696e 6720 6672 6f6d 2061 0a20  ffering from a. 
+00001530: 2020 2022 2222 0a20 2020 2069 6478 5f69     """.    idx_i
+00001540: 6e20 3d20 5b5d 0a0a 2020 2020 666f 7220  n = []..    for 
+00001550: 5f61 2069 6e20 613a 0a20 2020 2020 2020  _a in a:.       
+00001560: 2066 6f72 2069 5f62 2c20 5f62 2069 6e20   for i_b, _b in 
+00001570: 656e 756d 6572 6174 6528 6229 3a0a 2020  enumerate(b):.  
+00001580: 2020 2020 2020 2020 2020 6966 2028 6e70            if (np
+00001590: 2e69 7363 6c6f 7365 285f 612c 205f 622c  .isclose(_a, _b,
+000015a0: 2061 746f 6c3d 3165 2d36 2929 2e61 6c6c   atol=1e-6)).all
+000015b0: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
+000015c0: 2020 2020 6964 785f 696e 2e61 7070 656e      idx_in.appen
+000015d0: 6428 695f 6229 0a0a 2020 2020 6964 7820  d(i_b)..    idx 
+000015e0: 3d20 6e70 2e61 7261 6e67 6528 622e 7368  = np.arange(b.sh
+000015f0: 6170 655b 305d 290a 2020 2020 6964 785f  ape[0]).    idx_
+00001600: 6e6f 745f 696e 203d 205b 6920 666f 7220  not_in = [i for 
+00001610: 6920 696e 2069 6478 2069 6620 6920 6e6f  i in idx if i no
+00001620: 7420 696e 2069 6478 5f69 6e5d 0a0a 2020  t in idx_in]..  
+00001630: 2020 7265 7475 726e 2062 5b69 6478 5f6e    return b[idx_n
+00001640: 6f74 5f69 6e2c 203a 5d0a 0a0a 6465 6620  ot_in, :]...def 
+00001650: 6765 745f 6c69 7374 5f6d 756c 7469 5f64  get_list_multi_d
+00001660: 656c 6574 6528 696e 7075 745f 6c69 7374  elete(input_list
+00001670: 2c20 696e 6465 7829 3a0a 2020 2020 2222  , index):.    ""
+00001680: 220a 2020 2020 4465 6c65 7465 206d 756c  ".    Delete mul
+00001690: 7469 706c 6520 656e 7472 6965 7320 6672  tiple entries fr
+000016a0: 6f6d 206c 6973 742e 0a0a 2020 2020 696e  om list...    in
+000016b0: 7075 745f 6c69 7374 203d 2067 6574 5f6c  put_list = get_l
+000016c0: 6973 745f 6d75 6c74 695f 6465 6c65 7465  ist_multi_delete
+000016d0: 2869 6e70 7574 5f6c 6973 742c 2069 6e64  (input_list, ind
+000016e0: 6578 290a 0a20 2020 2050 6172 616d 6574  ex)..    Paramet
+000016f0: 6572 730a 2020 2020 2d2d 2d2d 2d2d 2d2d  ers.    --------
+00001700: 2d2d 0a20 2020 2069 6e70 7574 5f6c 6973  --.    input_lis
+00001710: 7420 3a20 6c69 7374 0a20 2020 2020 2020  t : list.       
+00001720: 2053 696d 706c 6520 6c69 7374 0a20 2020   Simple list.   
+00001730: 2069 6e64 6578 203a 206c 6973 7420 6f66   index : list of
+00001740: 2069 6e74 6567 6572 0a20 2020 2020 2020   integer.       
+00001750: 204c 6973 7420 6f66 2069 6e64 6963 6573   List of indices
+00001760: 2074 6f20 6465 6c65 7465 0a0a 2020 2020   to delete..    
+00001770: 5265 7475 726e 730a 2020 2020 2d2d 2d2d  Returns.    ----
+00001780: 2d2d 2d0a 2020 2020 696e 7075 745f 6c69  ---.    input_li
+00001790: 7374 203a 206c 6973 740a 2020 2020 2020  st : list.      
+000017a0: 2020 496e 7075 7420 6c69 7374 2077 6974    Input list wit
+000017b0: 686f 7574 2065 6e74 7269 6573 2073 7065  hout entries spe
+000017c0: 6369 6669 6564 2069 6e20 696e 6465 780a  cified in index.
+000017d0: 2020 2020 2222 220a 0a20 2020 2069 6e64      """..    ind
+000017e0: 6963 6573 203d 2073 6f72 7465 6428 696e  ices = sorted(in
+000017f0: 6465 782c 2072 6576 6572 7365 3d54 7275  dex, reverse=Tru
+00001800: 6529 0a20 2020 2066 6f72 206c 6973 745f  e).    for list_
+00001810: 696e 6465 7820 696e 2069 6e64 6963 6573  index in indices
+00001820: 3a0a 2020 2020 2020 2020 6465 6c20 696e  :.        del in
+00001830: 7075 745f 6c69 7374 5b6c 6973 745f 696e  put_list[list_in
+00001840: 6465 785d 0a20 2020 2072 6574 7572 6e20  dex].    return 
+00001850: 696e 7075 745f 6c69 7374 0a0a 0a64 6566  input_list...def
+00001860: 2067 6574 5f61 7272 6179 5f75 6e69 7175   get_array_uniqu
+00001870: 655f 726f 7773 2861 7272 6179 293a 0a20  e_rows(array):. 
+00001880: 2020 2022 2222 0a20 2020 2043 6f6d 7075     """.    Compu
+00001890: 7465 2075 6e69 7175 6520 726f 7773 206f  te unique rows o
+000018a0: 6620 3244 2061 7272 6179 2061 6e64 2064  f 2D array and d
+000018b0: 656c 6574 6520 726f 7773 2074 6861 7420  elete rows that 
+000018c0: 6172 6520 7265 6475 6e64 616e 742e 0a0a  are redundant...
+000018d0: 2020 2020 756e 6971 7565 203d 2067 6574      unique = get
+000018e0: 5f61 7272 6179 5f75 6e69 7175 655f 726f  _array_unique_ro
+000018f0: 7773 2861 7272 6179 290a 0a20 2020 2050  ws(array)..    P
+00001900: 6172 616d 6574 6572 730a 2020 2020 2d2d  arameters.    --
+00001910: 2d2d 2d2d 2d2d 2d2d 0a20 2020 2061 7272  --------.    arr
+00001920: 6179 3a20 6e64 6172 7261 7920 6f66 2066  ay: ndarray of f
+00001930: 6c6f 6174 0a20 2020 2020 2020 204d 6174  loat.        Mat
+00001940: 7269 7820 7769 7468 206b 2072 6564 756e  rix with k redun
+00001950: 6461 6e74 2072 6f77 730a 0a20 2020 2052  dant rows..    R
+00001960: 6574 7572 6e73 0a20 2020 202d 2d2d 2d2d  eturns.    -----
+00001970: 2d2d 0a20 2020 2075 6e69 7175 653a 206e  --.    unique: n
+00001980: 6461 7272 6179 206f 6620 666c 6f61 740a  darray of float.
+00001990: 2020 2020 2020 2020 4d61 7472 6978 2077          Matrix w
+000019a0: 6974 686f 7574 206b 2072 6564 756e 6461  ithout k redunda
+000019b0: 6e74 2072 6f77 730a 2020 2020 2222 220a  nt rows.    """.
+000019c0: 0a20 2020 205f 2c20 696e 6465 7820 3d20  .    _, index = 
+000019d0: 6e70 2e75 6e69 7175 6528 6172 7261 792c  np.unique(array,
+000019e0: 2061 7869 733d 302c 2072 6574 7572 6e5f   axis=0, return_
+000019f0: 696e 6465 783d 5472 7565 290a 2020 2020  index=True).    
+00001a00: 696e 6465 7820 3d20 6e70 2e73 6f72 7428  index = np.sort(
+00001a10: 696e 6465 7829 0a20 2020 2072 6574 7572  index).    retur
+00001a20: 6e20 6172 7261 795b 696e 6465 785d 0a0a  n array[index]..
+00001a30: 0a64 6566 206e 726d 7364 2861 7272 6179  .def nrmsd(array
+00001a40: 2c20 6172 7261 795f 7265 662c 2065 7272  , array_ref, err
+00001a50: 6f72 5f6e 6f72 6d3d 2272 656c 6174 6976  or_norm="relativ
+00001a60: 6522 2c20 785f 6178 6973 3d46 616c 7365  e", x_axis=False
+00001a70: 293a 0a20 2020 2022 2222 0a20 2020 2044  ):.    """.    D
+00001a80: 6574 6572 6d69 6e65 2074 6865 206e 6f72  etermine the nor
+00001a90: 6d61 6c69 7a65 6420 726f 6f74 206d 6561  malized root mea
+00001aa0: 6e20 7371 7561 7265 2064 6576 6961 7469  n square deviati
+00001ab0: 6f6e 2062 6574 7765 656e 2069 6e70 7574  on between input
+00001ac0: 2064 6174 6120 616e 6420 7265 6665 7265   data and refere
+00001ad0: 6e63 6520 6461 7461 2e0a 0a20 2020 206e  nce data...    n
+00001ae0: 6f72 6d61 6c69 7a65 645f 726d 7320 3d20  ormalized_rms = 
+00001af0: 6765 745f 6e6f 726d 616c 697a 6564 5f72  get_normalized_r
+00001b00: 6d73 2861 7272 6179 2c20 6172 7261 795f  ms(array, array_
+00001b10: 7265 6629 0a0a 2020 2020 5061 7261 6d65  ref)..    Parame
+00001b20: 7465 7273 0a20 2020 202d 2d2d 2d2d 2d2d  ters.    -------
+00001b30: 2d2d 2d0a 2020 2020 6172 7261 793a 206e  ---.    array: n
+00001b40: 702e 6e64 6172 7261 790a 2020 2020 2020  p.ndarray.      
+00001b50: 2020 696e 7075 7420 6461 7461 205b 2028    input data [ (
+00001b60: 7829 2c20 7930 2c20 7931 2c20 7932 202e  x), y0, y1, y2 .
+00001b70: 2e2e 205d 0a20 2020 2061 7272 6179 5f72  .. ].    array_r
+00001b80: 6566 3a20 6e70 2e6e 6461 7272 6179 0a20  ef: np.ndarray. 
+00001b90: 2020 2020 2020 2072 6566 6572 656e 6365         reference
+00001ba0: 2064 6174 6120 5b20 2878 5f72 6566 292c   data [ (x_ref),
+00001bb0: 2079 305f 7265 662c 2079 315f 7265 662c   y0_ref, y1_ref,
+00001bc0: 2079 325f 7265 6620 2e2e 2e20 5d0a 2020   y2_ref ... ].  
+00001bd0: 2020 2020 2020 6966 2061 7272 6179 5f72        if array_r
+00001be0: 6566 2069 7320 3144 2c20 616c 6c20 7369  ef is 1D, all si
+00001bf0: 7a65 7320 6861 7665 2074 6f20 6d61 7463  zes have to matc
+00001c00: 680a 2020 2020 6572 726f 725f 6e6f 726d  h.    error_norm
+00001c10: 3a20 7374 722c 206f 7074 696f 6e61 6c2c  : str, optional,
+00001c20: 2064 6566 6175 6c74 3d22 7265 6c61 7469   default="relati
+00001c30: 7665 220a 2020 2020 2020 2020 4465 6369  ve".        Deci
+00001c40: 6465 2069 6620 6572 726f 7220 6973 2064  de if error is d
+00001c50: 6574 6572 6d69 6e65 6420 2272 656c 6174  etermined "relat
+00001c60: 6976 6522 206f 7220 2261 6273 6f6c 7574  ive" or "absolut
+00001c70: 6522 0a20 2020 2078 5f61 7869 733a 2062  e".    x_axis: b
+00001c80: 6f6f 6c65 616e 2c20 6f70 7469 6f6e 616c  oolean, optional
+00001c90: 2c20 6465 6661 756c 743d 4661 6c73 650a  , default=False.
+00001ca0: 2020 2020 2020 2020 4966 2054 7275 652c          If True,
+00001cb0: 2074 6865 2066 6972 7374 2063 6f6c 756d   the first colum
+00001cc0: 6e20 6f66 2061 7272 6179 2061 6e64 2061  n of array and a
+00001cd0: 7272 6179 5f72 6566 2069 7320 696e 7465  rray_ref is inte
+00001ce0: 7270 7265 7465 6420 6173 2074 6865 2078  rpreted as the x
+00001cf0: 2d61 7869 732c 2077 6865 7265 2074 6865  -axis, where the
+00001d00: 2064 6174 6120 706f 696e 7473 2061 7265   data points are
+00001d10: 0a20 2020 2020 2020 2065 7661 6c75 6174  .        evaluat
+00001d20: 6564 2e20 4966 2046 616c 7365 2c20 7468  ed. If False, th
+00001d30: 6520 6461 7461 2070 6f69 6e74 7320 6172  e data points ar
+00001d40: 6520 6173 7375 6d65 6420 746f 2062 6520  e assumed to be 
+00001d50: 6174 2074 6865 2073 616d 6520 6c6f 6361  at the same loca
+00001d60: 7469 6f6e 2e0a 0a20 2020 2052 6574 7572  tion...    Retur
+00001d70: 6e73 0a20 2020 202d 2d2d 2d2d 2d2d 0a20  ns.    -------. 
+00001d80: 2020 206e 6f72 6d61 6c69 7a65 645f 726d     normalized_rm
+00001d90: 733a 206e 6461 7272 6179 206f 6620 666c  s: ndarray of fl
+00001da0: 6f61 7420 5b61 7272 6179 2e73 6861 7065  oat [array.shape
+00001db0: 5b31 5d5d 0a20 2020 2020 2020 204e 6f72  [1]].        Nor
+00001dc0: 6d61 6c69 7a65 6420 726f 6f74 206d 6561  malized root mea
+00001dd0: 6e20 7371 7561 7265 2064 6576 6961 7469  n square deviati
+00001de0: 6f6e 2062 6574 7765 656e 2074 6865 2063  on between the c
+00001df0: 6f6c 756d 6e73 206f 6620 6172 7261 7920  olumns of array 
+00001e00: 616e 6420 6172 7261 795f 7265 660a 2020  and array_ref.  
+00001e10: 2020 2222 220a 0a20 2020 206e 5f70 6f69    """..    n_poi
+00001e20: 6e74 7320 3d20 6172 7261 792e 7368 6170  nts = array.shap
+00001e30: 655b 305d 0a0a 2020 2020 6966 2078 5f61  e[0]..    if x_a
+00001e40: 7869 733a 0a20 2020 2020 2020 2023 2068  xis:.        # h
+00001e50: 616e 646c 6520 6469 6666 6572 656e 7420  andle different 
+00001e60: 6172 7261 7920 6c65 6e67 7468 730a 2020  array lengths.  
+00001e70: 2020 2020 2020 6966 206c 656e 2861 7272        if len(arr
+00001e80: 6179 5f72 6566 2e73 6861 7065 2920 3d3d  ay_ref.shape) ==
+00001e90: 2031 3a0a 2020 2020 2020 2020 2020 2020   1:.            
+00001ea0: 6172 7261 795f 7265 6620 3d20 6172 7261  array_ref = arra
+00001eb0: 795f 7265 665b 3a2c 204e 6f6e 655d 0a20  y_ref[:, None]. 
+00001ec0: 2020 2020 2020 2069 6620 6c65 6e28 6172         if len(ar
+00001ed0: 7261 792e 7368 6170 6529 203d 3d20 313a  ray.shape) == 1:
+00001ee0: 0a20 2020 2020 2020 2020 2020 2061 7272  .            arr
+00001ef0: 6179 203d 2061 7272 6179 5b3a 2c20 4e6f  ay = array[:, No
+00001f00: 6e65 5d0a 0a20 2020 2020 2020 2023 2064  ne]..        # d
+00001f10: 6574 6572 6d69 6e65 206e 756d 6265 7220  etermine number 
+00001f20: 6f66 2069 6e70 7574 2061 7272 6179 730a  of input arrays.
+00001f30: 2020 2020 2020 2020 6966 2061 7272 6179          if array
+00001f40: 5f72 6566 2e73 6861 7065 5b31 5d20 3d3d  _ref.shape[1] ==
+00001f50: 2032 3a0a 2020 2020 2020 2020 2020 2020   2:.            
+00001f60: 6e5f 6461 7461 203d 2061 7272 6179 2e73  n_data = array.s
+00001f70: 6861 7065 5b31 5d2d 310a 2020 2020 2020  hape[1]-1.      
+00001f80: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00001f90: 2020 2020 6e5f 6461 7461 203d 2061 7272      n_data = arr
+00001fa0: 6179 2e73 6861 7065 5b31 5d0a 0a20 2020  ay.shape[1]..   
+00001fb0: 2020 2020 2023 2069 6e74 6572 706f 6c61       # interpola
+00001fc0: 7465 2061 7272 6179 206f 6e20 6172 7261  te array on arra
+00001fd0: 795f 7265 6620 6461 7461 2069 6620 6e65  y_ref data if ne
+00001fe0: 6365 7373 6172 790a 2020 2020 2020 2020  cessary.        
+00001ff0: 6966 2061 7272 6179 5f72 6566 2e73 6861  if array_ref.sha
+00002000: 7065 5b31 5d20 3d3d 2031 3a0a 2020 2020  pe[1] == 1:.    
+00002010: 2020 2020 2020 2020 6461 7461 203d 2061          data = a
+00002020: 7272 6179 0a20 2020 2020 2020 2020 2020  rray.           
+00002030: 2064 6174 615f 7265 6620 3d20 6172 7261   data_ref = arra
+00002040: 795f 7265 660a 2020 2020 2020 2020 656c  y_ref.        el
+00002050: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+00002060: 2320 6372 6f70 2072 6566 6572 656e 6365  # crop reference
+00002070: 2069 6620 6974 2069 7320 6c6f 6e67 6572   if it is longer
+00002080: 2074 6861 6e20 7468 6520 6178 6973 206f   than the axis o
+00002090: 6620 7468 6520 6461 7461 0a20 2020 2020  f the data.     
+000020a0: 2020 2020 2020 2064 6174 615f 7265 6620         data_ref 
+000020b0: 3d20 6172 7261 795f 7265 665b 2861 7272  = array_ref[(arr
+000020c0: 6179 5f72 6566 5b3a 2c20 305d 203e 3d20  ay_ref[:, 0] >= 
+000020d0: 6d69 6e28 6172 7261 795b 3a2c 2030 5d29  min(array[:, 0])
+000020e0: 2920 2620 2861 7272 6179 5f72 6566 5b3a  ) & (array_ref[:
+000020f0: 2c20 305d 203c 3d20 6d61 7828 6172 7261  , 0] <= max(arra
+00002100: 795b 3a2c 2030 5d29 292c 2031 5d0a 2020  y[:, 0])), 1].  
+00002110: 2020 2020 2020 2020 2020 6172 7261 795f            array_
+00002120: 7265 6620 3d20 6172 7261 795f 7265 665b  ref = array_ref[
+00002130: 2861 7272 6179 5f72 6566 5b3a 2c20 305d  (array_ref[:, 0]
+00002140: 203e 3d20 6d69 6e28 6172 7261 795b 3a2c   >= min(array[:,
+00002150: 2030 5d29 2920 2620 2861 7272 6179 5f72   0])) & (array_r
+00002160: 6566 5b3a 2c20 305d 203c 3d20 6d61 7828  ef[:, 0] <= max(
+00002170: 6172 7261 795b 3a2c 2030 5d29 292c 2030  array[:, 0])), 0
+00002180: 5d0a 0a20 2020 2020 2020 2020 2020 2064  ]..            d
+00002190: 6174 6120 3d20 6e70 2e7a 6572 6f73 285b  ata = np.zeros([
+000021a0: 6c65 6e28 6172 7261 795f 7265 6629 2c20  len(array_ref), 
+000021b0: 6e5f 6461 7461 5d29 0a20 2020 2020 2020  n_data]).       
+000021c0: 2020 2020 2066 6f72 2069 5f64 6174 6120       for i_data 
+000021d0: 696e 2072 616e 6765 286e 5f64 6174 6129  in range(n_data)
+000021e0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+000021f0: 2020 6461 7461 5b3a 2c20 695f 6461 7461    data[:, i_data
+00002200: 5d20 3d20 6e70 2e69 6e74 6572 7028 6172  ] = np.interp(ar
+00002210: 7261 795f 7265 662c 2061 7272 6179 5b3a  ray_ref, array[:
+00002220: 2c20 305d 2c20 6172 7261 795b 3a2c 2069  , 0], array[:, i
+00002230: 5f64 6174 612b 315d 290a 2020 2020 656c  _data+1]).    el
+00002240: 7365 3a0a 2020 2020 2020 2020 6461 7461  se:.        data
+00002250: 5f72 6566 203d 2061 7272 6179 5f72 6566  _ref = array_ref
+00002260: 0a20 2020 2020 2020 2064 6174 6120 3d20  .        data = 
+00002270: 6172 7261 790a 0a20 2020 2023 2064 6574  array..    # det
+00002280: 6572 6d69 6e65 2022 6162 736f 6c75 7465  ermine "absolute
+00002290: 2220 6f72 2022 7265 6c61 7469 7665 2220  " or "relative" 
+000022a0: 6572 726f 720a 2020 2020 6966 2065 7272  error.    if err
+000022b0: 6f72 5f6e 6f72 6d20 3d3d 2022 7265 6c61  or_norm == "rela
+000022c0: 7469 7665 223a 0a20 2020 2020 2020 2023  tive":.        #
+000022d0: 206d 6178 5f6d 696e 5f69 6478 203d 206e   max_min_idx = n
+000022e0: 702e 6973 636c 6f73 6528 6e70 2e6d 6178  p.isclose(np.max
+000022f0: 2864 6174 615f 7265 662c 2061 7869 733d  (data_ref, axis=
+00002300: 3029 2c20 6e70 2e6d 696e 2864 6174 615f  0), np.min(data_
+00002310: 7265 662c 2061 7869 733d 3029 290a 2020  ref, axis=0)).  
+00002320: 2020 2020 2020 6465 6c74 6120 3d20 6e70        delta = np
+00002330: 2e6d 6178 2864 6174 615f 7265 662c 2061  .max(data_ref, a
+00002340: 7869 733d 3029 202d 206e 702e 6d69 6e28  xis=0) - np.min(
+00002350: 6461 7461 5f72 6566 2c20 6178 6973 3d30  data_ref, axis=0
+00002360: 290a 0a20 2020 2020 2020 2023 2069 6620  )..        # if 
+00002370: 6d61 785f 6d69 6e5f 6964 782e 616e 7928  max_min_idx.any(
+00002380: 293a 0a20 2020 2020 2020 2023 2020 2020  ):.        #    
+00002390: 2064 656c 7461 5b6d 6178 5f6d 696e 5f69   delta[max_min_i
+000023a0: 6478 5d20 3d20 6d61 7828 6461 7461 5f72  dx] = max(data_r
+000023b0: 6566 5b6d 6178 5f6d 696e 5f69 6478 5d29  ef[max_min_idx])
+000023c0: 0a20 2020 2065 6c73 653a 0a20 2020 2020  .    else:.     
+000023d0: 2020 2064 656c 7461 203d 2031 0a0a 2020     delta = 1..  
+000023e0: 2020 2320 6669 6c74 6572 206e 616e 0a20    # filter nan. 
+000023f0: 2020 2072 6f77 5f69 6478 5f64 6174 612c     row_idx_data,
+00002400: 2063 6f6c 5f69 6478 5f64 6174 6120 3d20   col_idx_data = 
+00002410: 6e70 2e77 6865 7265 286e 702e 6973 6e61  np.where(np.isna
+00002420: 6e28 6461 7461 2929 0a20 2020 2072 6f77  n(data)).    row
+00002430: 5f69 6478 5f64 6174 615f 7265 662c 2063  _idx_data_ref, c
+00002440: 6f6c 5f69 6478 5f64 6174 615f 7265 6620  ol_idx_data_ref 
+00002450: 3d20 6e70 2e77 6865 7265 286e 702e 6973  = np.where(np.is
+00002460: 6e61 6e28 6461 7461 5f72 6566 2929 0a20  nan(data_ref)). 
+00002470: 2020 2072 6f77 5f69 6478 203d 206e 702e     row_idx = np.
+00002480: 6873 7461 636b 2828 726f 775f 6964 785f  hstack((row_idx_
+00002490: 6461 7461 2c20 726f 775f 6964 785f 6461  data, row_idx_da
+000024a0: 7461 5f72 6566 2929 0a20 2020 2063 6f6c  ta_ref)).    col
+000024b0: 5f69 6478 203d 206e 702e 6873 7461 636b  _idx = np.hstack
+000024c0: 2828 636f 6c5f 6964 785f 6461 7461 2c20  ((col_idx_data, 
+000024d0: 636f 6c5f 6964 785f 6461 7461 5f72 6566  col_idx_data_ref
+000024e0: 2929 0a0a 2020 2020 6966 2072 6f77 5f69  ))..    if row_i
+000024f0: 6478 5f64 6174 612e 7369 7a65 203e 2030  dx_data.size > 0
+00002500: 3a0a 2020 2020 2020 2020 7761 726e 696e  :.        warnin
+00002510: 6773 2e77 6172 6e28 226e 616e 2069 6e20  gs.warn("nan in 
+00002520: 696e 7075 7420 6461 7461 7365 7420 666f  input dataset fo
+00002530: 756e 6420 6174 2072 6f77 733d 7b7d 2063  und at rows={} c
+00002540: 6f6c 733d 7b7d 2028 6967 6e6f 7265 6429  ols={} (ignored)
+00002550: 222e 666f 726d 6174 2872 6f77 5f69 6478  ".format(row_idx
+00002560: 2c20 636f 6c5f 6964 7829 290a 0a20 2020  , col_idx))..   
+00002570: 2069 6620 726f 775f 6964 785f 6461 7461   if row_idx_data
+00002580: 5f72 6566 2e73 697a 6520 3e20 303a 0a20  _ref.size > 0:. 
+00002590: 2020 2020 2020 2077 6172 6e69 6e67 732e         warnings.
+000025a0: 7761 726e 2822 6e61 6e20 696e 2072 6566  warn("nan in ref
+000025b0: 6572 656e 6365 2064 6174 6173 6574 2066  erence dataset f
+000025c0: 6f75 6e64 2061 7420 726f 7773 3d7b 7d20  ound at rows={} 
+000025d0: 636f 6c73 3d7b 7d20 2869 676e 6f72 6564  cols={} (ignored
+000025e0: 2922 2e66 6f72 6d61 7428 726f 775f 6964  )".format(row_id
+000025f0: 785f 6461 7461 5f72 6566 2c0a 2020 2020  x_data_ref,.    
+00002600: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002620: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002630: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002640: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002650: 2020 2020 2020 2020 636f 6c5f 6964 785f          col_idx_
+00002660: 6461 7461 5f72 6566 2929 0a0a 2020 2020  data_ref))..    
+00002670: 6966 2072 6f77 5f69 6478 2e73 697a 6520  if row_idx.size 
+00002680: 3e20 303a 0a20 2020 2020 2020 2064 6174  > 0:.        dat
+00002690: 6120 3d20 6e70 2e64 656c 6574 6528 6461  a = np.delete(da
+000026a0: 7461 2c20 6e70 2e75 6e69 7175 6528 726f  ta, np.unique(ro
+000026b0: 775f 6964 7829 2c20 6178 6973 3d30 290a  w_idx), axis=0).
+000026c0: 2020 2020 2020 2020 6461 7461 5f72 6566          data_ref
+000026d0: 203d 206e 702e 6465 6c65 7465 2864 6174   = np.delete(dat
+000026e0: 615f 7265 662c 206e 702e 756e 6971 7565  a_ref, np.unique
+000026f0: 2872 6f77 5f69 6478 292c 2061 7869 733d  (row_idx), axis=
+00002700: 3029 0a0a 2020 2020 2320 6465 7465 726d  0)..    # determ
+00002710: 696e 6520 6e6f 726d 616c 697a 6564 2072  ine normalized r
+00002720: 6d73 2064 6576 6961 7469 6f6e 2061 6e64  ms deviation and
+00002730: 2072 6574 7572 6e0a 2020 2020 6e6f 726d   return.    norm
+00002740: 616c 697a 6564 5f72 6d73 203d 206e 702e  alized_rms = np.
+00002750: 7371 7274 2831 2e30 2f6e 5f70 6f69 6e74  sqrt(1.0/n_point
+00002760: 7320 2a20 6e70 2e73 756d 2828 6461 7461  s * np.sum((data
+00002770: 202d 2064 6174 615f 7265 6629 2a2a 322c   - data_ref)**2,
+00002780: 2061 7869 733d 3029 2920 2f20 6465 6c74   axis=0)) / delt
+00002790: 610a 0a20 2020 2072 6574 7572 6e20 6e6f  a..    return no
+000027a0: 726d 616c 697a 6564 5f72 6d73 0a0a 0a64  rmalized_rms...d
+000027b0: 6566 2067 6574 5f62 6574 615f 7064 665f  ef get_beta_pdf_
+000027c0: 6669 7428 6461 7461 2c20 6265 7461 5f74  fit(data, beta_t
+000027d0: 6f6c 6572 616e 6365 3d30 2c20 756e 695f  olerance=0, uni_
+000027e0: 696e 7465 7276 616c 3d30 2c20 666e 5f70  interval=0, fn_p
+000027f0: 6c6f 743d 4e6f 6e65 293a 0a20 2020 2022  lot=None):.    "
+00002800: 2222 0a20 2020 2046 6974 2064 6174 6120  "".    Fit data 
+00002810: 746f 2061 2062 6574 6120 6469 7374 7269  to a beta distri
+00002820: 6275 7469 6f6e 2069 6e20 7468 6520 696e  bution in the in
+00002830: 7465 7276 616c 205b 612c 2062 5d2e 0a0a  terval [a, b]...
+00002840: 2020 2020 6265 7461 5f70 6172 616d 6574      beta_paramet
+00002850: 6572 732c 206d 6f6d 656e 7473 2c20 705f  ers, moments, p_
+00002860: 7661 6c75 652c 2075 6e69 5f70 6172 616d  value, uni_param
+00002870: 6574 6572 7320 3d20 6765 745f 6265 7461  eters = get_beta
+00002880: 5f70 6466 5f66 6974 2864 6174 612c 2062  _pdf_fit(data, b
+00002890: 6574 615f 746f 6c65 7261 6e63 653d 302c  eta_tolerance=0,
+000028a0: 2075 6e69 5f69 6e74 6572 7661 6c3d 3029   uni_interval=0)
+000028b0: 0a0a 2020 2020 5061 7261 6d65 7465 7273  ..    Parameters
+000028c0: 0a20 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0a  .    ----------.
+000028d0: 2020 2020 6461 7461 3a20 6e64 6172 7261      data: ndarra
+000028e0: 7920 6f66 2066 6c6f 6174 0a20 2020 2020  y of float.     
+000028f0: 2020 2044 6174 6120 746f 2066 6974 2062     Data to fit b
+00002900: 6574 6120 6469 7374 7269 6275 7469 6f6e  eta distribution
+00002910: 206f 6e0a 2020 2020 6265 7461 5f74 6f6c   on.    beta_tol
+00002920: 6572 616e 6365 3a20 666c 6f61 7420 6f72  erance: float or
+00002930: 206c 6973 7420 6f66 2066 6c6f 6174 2c20   list of float, 
+00002940: 6f70 7469 6f6e 616c 2c20 6465 6661 756c  optional, defaul
+00002950: 743d 300a 2020 2020 2020 2020 5370 6563  t=0.        Spec
+00002960: 6966 6965 7320 626f 756e 6473 206f 6620  ifies bounds of 
+00002970: 6265 7461 2064 6973 7472 6962 7574 696f  beta distributio
+00002980: 6e2e 2049 6620 666c 6f61 742c 2069 7420  n. If float, it 
+00002990: 6361 6c63 756c 6174 6573 2074 6865 2074  calculates the t
+000029a0: 6f6c 6572 616e 6365 0a20 2020 2020 2020  olerance.       
+000029b0: 2066 726f 6d20 6f62 7365 7276 6564 2064   from observed d
+000029c0: 6174 612c 2065 2e67 2e20 302e 3220 282b  ata, e.g. 0.2 (+
+000029d0: 2d32 3025 2074 6f6c 6572 616e 6365 206f  -20% tolerance o
+000029e0: 6e20 6f62 7365 7276 6564 206d 6178 2061  n observed max a
+000029f0: 6e64 206d 696e 2076 616c 7565 292e 0a20  nd min value).. 
+00002a00: 2020 2020 2020 2049 6620 6c69 7374 2c20         If list, 
+00002a10: 6974 2074 616b 6573 205b 6d69 6e2c 206d  it takes [min, m
+00002a20: 6178 5d20 6173 2062 6f75 6e64 7320 5b61  ax] as bounds [a
+00002a30: 2c20 625d 2e0a 2020 2020 756e 695f 696e  , b]..    uni_in
+00002a40: 7465 7276 616c 3a20 666c 6f61 7420 6f72  terval: float or
+00002a50: 206c 6973 7420 6f66 2066 6c6f 6174 2c20   list of float, 
+00002a60: 6f70 7469 6f6e 616c 2c20 6465 6661 756c  optional, defaul
+00002a70: 743d 300a 2020 2020 2020 2020 756e 6966  t=0.        unif
+00002a80: 6f72 6d20 6469 7374 7269 6275 7469 6f6e  orm distribution
+00002a90: 2069 6e74 6572 7661 6c2e 2049 6620 666c   interval. If fl
+00002aa0: 6f61 742c 2074 6865 2062 6f75 6e64 7320  oat, the bounds 
+00002ab0: 6172 6520 6465 6669 6e65 6420 6173 2061  are defined as a
+00002ac0: 2066 7261 6374 696f 6e20 6f66 2074 6865   fraction of the
+00002ad0: 2062 6574 6120 6469 7374 7269 6275 7469   beta distributi
+00002ae0: 6f6e 0a20 2020 2020 2020 2069 6e74 6572  on.        inter
+00002af0: 7661 6c20 2865 2e67 2e20 302e 3935 2028  val (e.g. 0.95 (
+00002b00: 3935 2529 292e 2049 6620 6c69 7374 2c20  95%)). If list, 
+00002b10: 6974 2074 616b 6573 205b 6d69 6e2c 206d  it takes [min, m
+00002b20: 6178 5d20 6173 2062 6f75 6e64 7320 5b61  ax] as bounds [a
+00002b30: 2c20 625d 2e0a 2020 2020 666e 5f70 6c6f  , b]..    fn_plo
+00002b40: 743a 2073 7472 0a20 2020 2020 2020 2046  t: str.        F
+00002b50: 696c 656e 616d 6520 6f66 2070 6c6f 7420  ilename of plot 
+00002b60: 736f 2073 6176 6520 282e 7064 6620 616e  so save (.pdf an
+00002b70: 6420 2e70 6e67 290a 2020 2020 0a20 2020  d .png).    .   
+00002b80: 2052 6574 7572 6e73 0a20 2020 202d 2d2d   Returns.    ---
+00002b90: 2d2d 2d2d 0a20 2020 2062 6574 615f 7061  ----.    beta_pa
+00002ba0: 7261 6d65 7465 7273 3a20 6c69 7374 206f  rameters: list o
+00002bb0: 6620 666c 6f61 7420 5b34 5d0a 2020 2020  f float [4].    
+00002bc0: 2020 2020 5477 6f20 7368 6170 6520 7061      Two shape pa
+00002bd0: 7261 6d65 7465 7273 2061 6e64 206c 6f77  rameters and low
+00002be0: 6572 2061 6e64 2075 7070 6572 206c 696d  er and upper lim
+00002bf0: 6974 205b 702c 2071 2c20 612c 2062 5d0a  it [p, q, a, b].
+00002c00: 2020 2020 6d6f 6d65 6e74 733a 206c 6973      moments: lis
+00002c10: 7420 6f66 2066 6c6f 6174 205b 345d 0a20  t of float [4]. 
+00002c20: 2020 2020 2020 204d 6561 6e20 616e 6420         Mean and 
+00002c30: 7374 6420 6f66 2072 6177 2064 6174 6120  std of raw data 
+00002c40: 616e 6420 6669 7474 6564 2062 6574 6120  and fitted beta 
+00002c50: 6469 7374 7269 6275 7469 6f6e 205b 6461  distribution [da
+00002c60: 7461 5f6d 6561 6e2c 2064 6174 615f 7374  ta_mean, data_st
+00002c70: 642c 2062 6574 615f 6d65 616e 2c20 6265  d, beta_mean, be
+00002c80: 7461 5f73 7464 5d0a 2020 2020 705f 7661  ta_std].    p_va
+00002c90: 6c75 653a 2066 6c6f 6174 0a20 2020 2020  lue: float.     
+00002ca0: 2020 2070 2d76 616c 7565 206f 6620 7468     p-value of th
+00002cb0: 6520 4b6f 6c6d 6f67 6f72 6f76 2053 6d69  e Kolmogorov Smi
+00002cc0: 726e 6f76 2074 6573 740a 2020 2020 756e  rnov test.    un
+00002cd0: 695f 7061 7261 6d65 7465 7273 3a20 6c69  i_parameters: li
+00002ce0: 7374 206f 6620 666c 6f61 7420 5b32 5d0a  st of float [2].
+00002cf0: 2020 2020 2020 2020 4c6f 7765 7220 616e          Lower an
+00002d00: 6420 7570 7065 7220 6c69 6d69 7473 206f  d upper limits o
+00002d10: 6620 756e 6966 6f72 6d20 6469 7374 7269  f uniform distri
+00002d20: 6275 7469 6f6e 205b 612c 2062 5d0a 2020  bution [a, b].  
+00002d30: 2020 2222 220a 2020 2020 0a20 2020 2064    """.    .    d
+00002d40: 6174 615f 6d65 616e 203d 206e 702e 6d65  ata_mean = np.me
+00002d50: 616e 2864 6174 6129 0a20 2020 2064 6174  an(data).    dat
+00002d60: 615f 7374 6420 3d20 6e70 2e73 7464 2864  a_std = np.std(d
+00002d70: 6174 6129 0a20 2020 200a 2020 2020 2320  ata).    .    # 
+00002d80: 6669 7420 6265 7461 2064 6973 7472 6962  fit beta distrib
+00002d90: 7574 696f 6e20 746f 2064 6174 610a 2020  ution to data.  
+00002da0: 2020 6966 2074 7970 6528 6265 7461 5f74    if type(beta_t
+00002db0: 6f6c 6572 616e 6365 2920 6973 206c 6973  olerance) is lis
+00002dc0: 743a 0a20 2020 2020 2020 2061 5f62 6574  t:.        a_bet
+00002dd0: 6120 3d20 6265 7461 5f74 6f6c 6572 616e  a = beta_toleran
+00002de0: 6365 5b30 5d0a 2020 2020 2020 2020 625f  ce[0].        b_
+00002df0: 6265 7461 203d 2062 6574 615f 746f 6c65  beta = beta_tole
+00002e00: 7261 6e63 655b 315d 0a20 2020 2020 2020  rance[1].       
+00002e10: 2070 5f62 6574 612c 2071 5f62 6574 612c   p_beta, q_beta,
+00002e20: 2061 5f62 6574 612c 2061 625f 6265 7461   a_beta, ab_beta
+00002e30: 203d 2073 6369 7079 2e73 7461 7473 2e62   = scipy.stats.b
+00002e40: 6574 612e 6669 7428 6461 7461 2c20 666c  eta.fit(data, fl
+00002e50: 6f63 3d61 5f62 6574 612c 2066 7363 616c  oc=a_beta, fscal
+00002e60: 653d 625f 6265 7461 202d 2061 5f62 6574  e=b_beta - a_bet
+00002e70: 6129 0a20 2020 2065 6c69 6620 6265 7461  a).    elif beta
+00002e80: 5f74 6f6c 6572 616e 6365 203e 2030 3a0a  _tolerance > 0:.
+00002e90: 2020 2020 2020 2020 2320 7573 6520 7573          # use us
+00002ea0: 6572 2062 6574 615f 746f 6c65 7261 6e63  er beta_toleranc
+00002eb0: 6520 6f66 2074 6f20 7365 7420 6c69 6d69  e of to set limi
+00002ec0: 7473 206f 6620 6469 7374 7269 6275 7469  ts of distributi
+00002ed0: 6f6e 0a20 2020 2020 2020 2064 6174 615f  on.        data_
+00002ee0: 7261 6e67 6520 3d20 6461 7461 2e6d 6178  range = data.max
+00002ef0: 2829 2d64 6174 612e 6d69 6e28 290a 2020  ()-data.min().  
+00002f00: 2020 2020 2020 615f 6265 7461 203d 2064        a_beta = d
+00002f10: 6174 612e 6d69 6e28 292d 6265 7461 5f74  ata.min()-beta_t
+00002f20: 6f6c 6572 616e 6365 2a64 6174 615f 7261  olerance*data_ra
+00002f30: 6e67 650a 2020 2020 2020 2020 625f 6265  nge.        b_be
+00002f40: 7461 203d 2064 6174 612e 6d61 7828 292b  ta = data.max()+
+00002f50: 6265 7461 5f74 6f6c 6572 616e 6365 2a64  beta_tolerance*d
+00002f60: 6174 615f 7261 6e67 650a 2020 2020 2020  ata_range.      
+00002f70: 2020 705f 6265 7461 2c20 715f 6265 7461    p_beta, q_beta
+00002f80: 2c20 615f 6265 7461 2c20 6162 5f62 6574  , a_beta, ab_bet
+00002f90: 6120 3d20 7363 6970 792e 7374 6174 732e  a = scipy.stats.
+00002fa0: 6265 7461 2e66 6974 2864 6174 612c 2066  beta.fit(data, f
+00002fb0: 6c6f 633d 615f 6265 7461 2c20 6673 6361  loc=a_beta, fsca
+00002fc0: 6c65 3d62 5f62 6574 612d 615f 6265 7461  le=b_beta-a_beta
+00002fd0: 290a 2020 2020 656c 7365 3a0a 2020 2020  ).    else:.    
+00002fe0: 2020 2020 2320 6c65 7420 7363 6970 792e      # let scipy.
+00002ff0: 7374 6174 732e 6265 7461 2e66 6974 2064  stats.beta.fit d
+00003000: 6574 6572 6d69 6e65 2074 6865 206c 696d  etermine the lim
+00003010: 6974 730a 2020 2020 2020 2020 705f 6265  its.        p_be
+00003020: 7461 2c20 715f 6265 7461 2c20 615f 6265  ta, q_beta, a_be
+00003030: 7461 2c20 6162 5f62 6574 6120 3d20 7363  ta, ab_beta = sc
+00003040: 6970 792e 7374 6174 732e 6265 7461 2e66  ipy.stats.beta.f
+00003050: 6974 2864 6174 6129 0a20 2020 2020 2020  it(data).       
+00003060: 2062 5f62 6574 6120 3d20 615f 6265 7461   b_beta = a_beta
+00003070: 202b 2061 625f 6265 7461 0a20 2020 200a   + ab_beta.    .
+00003080: 2020 2020 6265 7461 5f6d 6561 6e2c 2062      beta_mean, b
+00003090: 6574 615f 7661 7220 3d20 7363 6970 792e  eta_var = scipy.
+000030a0: 7374 6174 732e 6265 7461 2e73 7461 7473  stats.beta.stats
+000030b0: 2870 5f62 6574 612c 2071 5f62 6574 612c  (p_beta, q_beta,
+000030c0: 206c 6f63 3d61 5f62 6574 612c 2073 6361   loc=a_beta, sca
+000030d0: 6c65 3d28 625f 6265 7461 2d61 5f62 6574  le=(b_beta-a_bet
+000030e0: 6129 2c20 6d6f 6d65 6e74 733d 276d 7627  a), moments='mv'
+000030f0: 290a 2020 2020 6265 7461 5f73 7464 203d  ).    beta_std =
+00003100: 206e 702e 7371 7274 2862 6574 615f 7661   np.sqrt(beta_va
+00003110: 7229 0a20 2020 200a 2020 2020 6d6f 6d65  r).    .    mome
+00003120: 6e74 7320 3d20 6e70 2e61 7272 6179 285b  nts = np.array([
+00003130: 6461 7461 5f6d 6561 6e2c 2064 6174 615f  data_mean, data_
+00003140: 7374 642c 2062 6574 615f 6d65 616e 2c20  std, beta_mean, 
+00003150: 6265 7461 5f73 7464 5d29 0a0a 2020 2020  beta_std])..    
+00003160: 2320 7065 7266 6f72 6d20 4b6f 6c6d 6f67  # perform Kolmog
+00003170: 6f72 6f76 2053 6d69 726e 6f76 2074 6573  orov Smirnov tes
+00003180: 740a 2020 2020 5f2c 2070 5f76 616c 7565  t.    _, p_value
+00003190: 203d 2073 6369 7079 2e73 7461 7473 2e6b   = scipy.stats.k
+000031a0: 7374 6573 7428 6461 7461 2c20 2262 6574  stest(data, "bet
+000031b0: 6122 2c20 5b70 5f62 6574 612c 2071 5f62  a", [p_beta, q_b
+000031c0: 6574 612c 2061 5f62 6574 612c 2061 625f  eta, a_beta, ab_
+000031d0: 6265 7461 5d29 0a0a 2020 2020 6265 7461  beta])..    beta
+000031e0: 5f70 6172 616d 6574 6572 7320 3d20 6e70  _parameters = np
+000031f0: 2e61 7272 6179 285b 705f 6265 7461 2c20  .array([p_beta, 
+00003200: 715f 6265 7461 2c20 615f 6265 7461 2c20  q_beta, a_beta, 
+00003210: 625f 6265 7461 5d29 0a0a 2020 2020 2320  b_beta])..    # 
+00003220: 6465 7465 726d 696e 6520 6c69 6d69 7473  determine limits
+00003230: 206f 6620 756e 6966 6f72 6d20 6469 7374   of uniform dist
+00003240: 7269 6275 7469 6f6e 205b 615f 756e 692c  ribution [a_uni,
+00003250: 2062 5f75 6e69 5d20 636f 7665 7269 6e67   b_uni] covering
+00003260: 2074 6865 0a20 2020 2023 2069 6e74 6572   the.    # inter
+00003270: 7661 6c20 756e 695f 696e 7465 7276 616c  val uni_interval
+00003280: 206f 6620 7468 6520 6265 7461 2064 6973   of the beta dis
+00003290: 7472 6962 7574 696f 6e0a 2020 2020 6966  tribution.    if
+000032a0: 2074 7970 6528 756e 695f 696e 7465 7276   type(uni_interv
+000032b0: 616c 2920 6973 206c 6973 743a 0a20 2020  al) is list:.   
+000032c0: 2020 2020 2061 5f75 6e69 203d 2075 6e69       a_uni = uni
+000032d0: 5f69 6e74 6572 7661 6c5b 305d 0a20 2020  _interval[0].   
+000032e0: 2020 2020 2062 5f75 6e69 203d 2075 6e69       b_uni = uni
+000032f0: 5f69 6e74 6572 7661 6c5b 315d 0a20 2020  _interval[1].   
+00003300: 2020 2020 2075 6e69 5f70 6172 616d 6574       uni_paramet
+00003310: 6572 7320 3d20 6e70 2e61 7272 6179 285b  ers = np.array([
+00003320: 615f 756e 692c 2062 5f75 6e69 5d29 0a20  a_uni, b_uni]). 
+00003330: 2020 2065 6c69 6620 756e 695f 696e 7465     elif uni_inte
+00003340: 7276 616c 203e 2030 3a0a 2020 2020 2020  rval > 0:.      
+00003350: 2020 615f 756e 6920 3d20 7363 6970 792e    a_uni = scipy.
+00003360: 7374 6174 732e 6265 7461 2e70 7066 2828  stats.beta.ppf((
+00003370: 3120 2d20 756e 695f 696e 7465 7276 616c  1 - uni_interval
+00003380: 2920 2f20 322c 2070 5f62 6574 612c 2071  ) / 2, p_beta, q
+00003390: 5f62 6574 612c 206c 6f63 3d61 5f62 6574  _beta, loc=a_bet
+000033a0: 612c 2073 6361 6c65 3d62 5f62 6574 6120  a, scale=b_beta 
+000033b0: 2d20 615f 6265 7461 290a 2020 2020 2020  - a_beta).      
+000033c0: 2020 625f 756e 6920 3d20 7363 6970 792e    b_uni = scipy.
+000033d0: 7374 6174 732e 6265 7461 2e70 7066 2828  stats.beta.ppf((
+000033e0: 3120 2b20 756e 695f 696e 7465 7276 616c  1 + uni_interval
+000033f0: 2920 2f20 322c 2070 5f62 6574 612c 2071  ) / 2, p_beta, q
+00003400: 5f62 6574 612c 206c 6f63 3d61 5f62 6574  _beta, loc=a_bet
+00003410: 612c 2073 6361 6c65 3d62 5f62 6574 6120  a, scale=b_beta 
+00003420: 2d20 615f 6265 7461 290a 2020 2020 2020  - a_beta).      
+00003430: 2020 756e 695f 7061 7261 6d65 7465 7273    uni_parameters
+00003440: 203d 206e 702e 6172 7261 7928 5b61 5f75   = np.array([a_u
+00003450: 6e69 2c20 625f 756e 695d 290a 2020 2020  ni, b_uni]).    
+00003460: 656c 7365 3a0a 2020 2020 2020 2020 615f  else:.        a_
+00003470: 756e 6920 3d20 4e6f 6e65 0a20 2020 2020  uni = None.     
+00003480: 2020 2062 5f75 6e69 203d 204e 6f6e 650a     b_uni = None.
+00003490: 2020 2020 2020 2020 756e 695f 7061 7261          uni_para
+000034a0: 6d65 7465 7273 203d 204e 6f6e 650a 0a20  meters = None.. 
+000034b0: 2020 2069 6620 666e 5f70 6c6f 7420 6973     if fn_plot is
+000034c0: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
+000034d0: 2020 2070 6c6f 745f 6265 7461 5f70 6466     plot_beta_pdf
+000034e0: 5f66 6974 2864 6174 613d 6461 7461 2c0a  _fit(data=data,.
+000034f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003500: 2020 2020 2020 2020 2020 615f 6265 7461            a_beta
+00003510: 3d61 5f62 6574 612c 2062 5f62 6574 613d  =a_beta, b_beta=
+00003520: 625f 6265 7461 2c20 705f 6265 7461 3d70  b_beta, p_beta=p
+00003530: 5f62 6574 612c 2071 5f62 6574 613d 715f  _beta, q_beta=q_
+00003540: 6265 7461 2c0a 2020 2020 2020 2020 2020  beta,.          
+00003550: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003560: 615f 756e 693d 615f 756e 692c 2062 5f75  a_uni=a_uni, b_u
+00003570: 6e69 3d62 5f75 6e69 2c0a 2020 2020 2020  ni=b_uni,.      
+00003580: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003590: 2020 2020 696e 7465 7261 6374 6976 653d      interactive=
+000035a0: 5472 7565 2c20 666e 5f70 6c6f 743d 666e  True, fn_plot=fn
+000035b0: 5f70 6c6f 742c 2078 6c61 6265 6c3d 2224  _plot, xlabel="$
+000035c0: 7824 222c 2079 6c61 6265 6c3d 2224 7028  x$", ylabel="$p(
+000035d0: 7829 2422 290a 0a20 2020 2072 6574 7572  x)$")..    retur
+000035e0: 6e20 6265 7461 5f70 6172 616d 6574 6572  n beta_parameter
+000035f0: 732c 206d 6f6d 656e 7473 2c20 705f 7661  s, moments, p_va
+00003600: 6c75 652c 2075 6e69 5f70 6172 616d 6574  lue, uni_paramet
+00003610: 6572 730a 0a0a 6465 6620 6d75 7475 616c  ers...def mutual
+00003620: 5f63 6f68 6572 656e 6365 2861 7272 6179  _coherence(array
+00003630: 293a 0a20 2020 2022 2222 0a20 2020 2043  ):.    """.    C
+00003640: 616c 6375 6c61 7465 2074 6865 206d 7574  alculate the mut
+00003650: 7561 6c20 636f 6865 7265 6e63 6520 6f66  ual coherence of
+00003660: 2061 206d 6174 7269 7820 412e 2049 7420   a matrix A. It 
+00003670: 6361 6e20 616c 736f 2062 6520 7265 6665  can also be refe
+00003680: 7272 6564 2061 7320 7468 6520 636f 7369  rred as the cosi
+00003690: 6e65 206f 6620 7468 6520 736d 616c 6c65  ne of the smalle
+000036a0: 7374 2061 6e67 6c65 0a20 2020 2062 6574  st angle.    bet
+000036b0: 7765 656e 2074 776f 2063 6f6c 756d 6e73  ween two columns
+000036c0: 2e0a 0a20 2020 206d 7574 7561 6c5f 636f  ...    mutual_co
+000036d0: 6865 7265 6e63 6520 3d20 6d75 7475 616c  herence = mutual
+000036e0: 5f63 6f68 6572 656e 6365 2861 7272 6179  _coherence(array
+000036f0: 290a 0a20 2020 2050 6172 616d 6574 6572  )..    Parameter
+00003700: 730a 2020 2020 2d2d 2d2d 2d2d 2d2d 2d2d  s.    ----------
+00003710: 0a20 2020 2061 7272 6179 3a20 6e64 6172  .    array: ndar
+00003720: 7261 7920 6f66 2066 6c6f 6174 0a20 2020  ray of float.   
+00003730: 2020 2020 2049 6e70 7574 206d 6174 7269       Input matri
+00003740: 780a 0a20 2020 2052 6574 7572 6e73 0a20  x..    Returns. 
+00003750: 2020 202d 2d2d 2d2d 2d2d 0a20 2020 206d     -------.    m
+00003760: 7574 7561 6c5f 636f 6865 7265 6e63 653a  utual_coherence:
+00003770: 2066 6c6f 6174 0a20 2020 2020 2020 204d   float.        M
+00003780: 7574 7561 6c20 636f 6865 7265 6e63 650a  utual coherence.
+00003790: 2020 2020 2222 220a 0a20 2020 2061 7272      """..    arr
+000037a0: 6179 203d 2061 7272 6179 202f 206e 702e  ay = array / np.
+000037b0: 6c69 6e61 6c67 2e6e 6f72 6d28 6172 7261  linalg.norm(arra
+000037c0: 792c 2061 7869 733d 3029 5b6e 702e 6e65  y, axis=0)[np.ne
+000037d0: 7761 7869 732c 203a 5d0a 2020 2020 7420  waxis, :].    t 
+000037e0: 3d20 6e70 2e64 6f74 2861 7272 6179 2e63  = np.dot(array.c
+000037f0: 6f6e 6a28 292e 542c 2061 7272 6179 290a  onj().T, array).
+00003800: 2020 2020 6e70 2e66 696c 6c5f 6469 6167      np.fill_diag
+00003810: 6f6e 616c 2874 2c20 302e 3029 0a20 2020  onal(t, 0.0).   
+00003820: 206d 7520 3d20 6e70 2e6d 6178 2874 290a   mu = np.max(t).
+00003830: 0a20 2020 2072 6574 7572 6e20 6d75 0a0a  .    return mu..
+00003840: 0a64 6566 2052 4950 2841 2c20 7829 3a0a  .def RIP(A, x):.
+00003850: 2020 2020 2222 220a 2020 2020 4361 6c63      """.    Calc
+00003860: 756c 6174 6520 7468 6520 7265 7374 7269  ulate the restri
+00003870: 6374 6564 2069 736f 6d65 7472 6963 2070  cted isometric p
+00003880: 726f 7065 7274 7920 636f 6e73 7461 6e74  roperty constant
+00003890: 2064 656c 7461 206f 6620 6120 6d61 7472   delta of a matr
+000038a0: 6978 2041 2066 6f72 2061 2067 6976 656e  ix A for a given
+000038b0: 2073 7061 7273 6520 7665 6374 6f72 2078   sparse vector x
+000038c0: 2e0a 0a20 2020 2064 656c 7461 203d 2052  ...    delta = R
+000038d0: 4950 2841 2c20 7829 0a0a 2020 2020 5061  IP(A, x)..    Pa
+000038e0: 7261 6d65 7465 7273 0a20 2020 202d 2d2d  rameters.    ---
+000038f0: 2d2d 2d2d 2d2d 2d0a 2020 2020 413a 206e  -------.    A: n
+00003900: 6461 7272 6179 206f 6620 666c 6f61 740a  darray of float.
+00003910: 2020 2020 2020 2020 496e 7075 7420 6d61          Input ma
+00003920: 7472 6978 0a20 2020 2078 3a20 6e64 6172  trix.    x: ndar
+00003930: 7261 7920 6f66 2066 6c6f 6174 0a20 2020  ray of float.   
+00003940: 2020 2020 2061 7070 6c69 6564 2076 6563       applied vec
+00003950: 746f 720a 2020 2020 5265 7475 726e 730a  tor.    Returns.
+00003960: 2020 2020 2d2d 2d2d 2d2d 2d0a 2020 2020      -------.    
+00003970: 6465 6c74 613a 2066 6c6f 6174 0a20 2020  delta: float.   
+00003980: 2020 2020 2072 6573 7472 6963 7465 6420       restricted 
+00003990: 6973 6f6d 6574 7269 6320 7072 6f70 6572  isometric proper
+000039a0: 7479 2063 6f6e 7374 616e 740a 2020 2020  ty constant.    
+000039b0: 2222 220a 0a20 2020 206e 6f72 6d5f 4178  """..    norm_Ax
+000039c0: 203d 206e 702e 6c69 6e61 6c67 2e6e 6f72   = np.linalg.nor
+000039d0: 6d28 6e70 2e64 6f74 2841 2c20 7829 290a  m(np.dot(A, x)).
+000039e0: 2020 2020 6e6f 726d 5f78 203d 206e 702e      norm_x = np.
+000039f0: 6c69 6e61 6c67 2e6e 6f72 6d28 7829 0a20  linalg.norm(x). 
+00003a00: 2020 2064 656c 7461 203d 2028 6e6f 726d     delta = (norm
+00003a10: 5f41 782a 2a32 202f 206e 6f72 6d5f 782a  _Ax**2 / norm_x*
+00003a20: 2a32 2920 2d20 310a 0a20 2020 2072 6574  *2) - 1..    ret
+00003a30: 7572 6e20 6465 6c74 610a 0a0a 6465 6620  urn delta...def 
+00003a40: 7772 6170 5f66 756e 6374 696f 6e28 666e  wrap_function(fn
+00003a50: 2c20 782c 2061 7267 7329 3a0a 2020 2020  , x, args):.    
+00003a60: 2222 220a 2020 2020 4675 6e63 7469 6f6e  """.    Function
+00003a70: 2077 7261 7070 6572 2074 6f20 6361 6c6c   wrapper to call
+00003a80: 2061 6e6f 6e79 6d6f 7573 2066 756e 6374   anonymous funct
+00003a90: 696f 6e20 7769 7468 2076 6172 6961 626c  ion with variabl
+00003aa0: 6520 6e75 6d62 6572 206f 6620 6172 6775  e number of argu
+00003ab0: 6d65 6e74 7320 2874 7570 6c65 292e 0a0a  ments (tuple)...
+00003ac0: 2020 2020 7772 6170 5f66 756e 6374 696f      wrap_functio
+00003ad0: 6e28 666e 2c20 782c 2061 7267 7329 0a0a  n(fn, x, args)..
+00003ae0: 2020 2020 5061 7261 6d65 7465 7273 0a20      Parameters. 
+00003af0: 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020     ----------.  
+00003b00: 2020 666e 3a20 6675 6e63 7469 6f6e 0a20    fn: function. 
+00003b10: 2020 2020 2020 2061 6e6f 6e79 6d6f 7573         anonymous
+00003b20: 2066 756e 6374 696f 6e20 746f 2063 616c   function to cal
+00003b30: 6c0a 2020 2020 783a 2074 7570 6c65 0a20  l.    x: tuple. 
+00003b40: 2020 2020 2020 2070 6172 616d 6574 6572         parameter
+00003b50: 7320 6f66 2066 756e 6374 696f 6e0a 2020  s of function.  
+00003b60: 2020 6172 6773 3a20 7475 706c 650a 2020    args: tuple.  
+00003b70: 2020 2020 2020 6172 6775 6d65 6e74 7320        arguments 
+00003b80: 6f66 2066 756e 6374 696f 6e0a 0a20 2020  of function..   
+00003b90: 2052 6574 7572 6e73 0a20 2020 202d 2d2d   Returns.    ---
+00003ba0: 2d2d 2d2d 0a20 2020 2066 756e 6374 696f  ----.    functio
+00003bb0: 6e5f 7772 6170 7065 723a 2066 756e 6374  n_wrapper: funct
+00003bc0: 696f 6e0a 2020 2020 2020 2020 7772 6170  ion.        wrap
+00003bd0: 7065 6420 6675 6e63 7469 6f6e 0a20 2020  ped function.   
+00003be0: 2022 2222 0a0a 2020 2020 6465 6620 6675   """..    def fu
+00003bf0: 6e63 7469 6f6e 5f77 7261 7070 6572 282a  nction_wrapper(*
+00003c00: 7772 6170 7065 725f 6172 6773 293a 0a20  wrapper_args):. 
+00003c10: 2020 2020 2020 2072 6574 7572 6e20 666e         return fn
+00003c20: 282a 2877 7261 7070 6572 5f61 7267 7320  (*(wrapper_args 
+00003c30: 2b20 7820 2b20 6172 6773 2929 0a0a 2020  + x + args))..  
+00003c40: 2020 7265 7475 726e 2066 756e 6374 696f    return functio
+00003c50: 6e5f 7772 6170 7065 720a 0a0a 6465 6620  n_wrapper...def 
+00003c60: 6765 745f 6e75 6d5f 636f 6566 6673 286f  get_num_coeffs(o
+00003c70: 7264 6572 2c20 6469 6d29 3a0a 2020 2020  rder, dim):.    
+00003c80: 2222 220a 2020 2020 4361 6c63 756c 6174  """.    Calculat
+00003c90: 6520 7468 6520 6e75 6d62 6572 206f 6620  e the number of 
+00003ca0: 6750 4320 636f 6566 6669 6369 656e 7473  gPC coefficients
+00003cb0: 2062 7920 7468 6520 6d61 7869 6d75 6d20   by the maximum 
+00003cc0: 6f72 6465 7220 616e 6420 7468 6520 6e75  order and the nu
+00003cd0: 6d62 6572 206f 6620 7261 6e64 6f6d 2076  mber of random v
+00003ce0: 6172 6961 626c 6573 2e0a 0a20 2020 206e  ariables...    n
+00003cf0: 756d 5f63 6f65 6666 7320 3d20 286f 7264  um_coeffs = (ord
+00003d00: 6572 2b64 696d 2921 202f 2028 6f72 6465  er+dim)! / (orde
+00003d10: 7221 202a 2064 696d 2129 0a0a 2020 2020  r! * dim!)..    
+00003d20: 6e75 6d5f 636f 6566 6673 203d 2067 6574  num_coeffs = get
+00003d30: 5f6e 756d 5f63 6f65 6666 7328 6f72 6465  _num_coeffs(orde
+00003d40: 7220 2c20 6469 6d29 0a0a 2020 2020 5061  r , dim)..    Pa
+00003d50: 7261 6d65 7465 7273 0a20 2020 202d 2d2d  rameters.    ---
+00003d60: 2d2d 2d2d 2d2d 2d0a 2020 2020 6f72 6465  -------.    orde
+00003d70: 723a 2069 6e74 0a20 2020 2020 2020 204d  r: int.        M
+00003d80: 6178 696d 756d 206f 7264 6572 206f 6620  aximum order of 
+00003d90: 6578 7061 6e73 696f 6e0a 2020 2020 6469  expansion.    di
+00003da0: 6d3a 2069 6e74 0a20 2020 2020 2020 204e  m: int.        N
+00003db0: 756d 6265 7220 6f66 2072 616e 646f 6d20  umber of random 
+00003dc0: 7661 7269 6162 6c65 730a 0a20 2020 2052  variables..    R
+00003dd0: 6574 7572 6e73 0a20 2020 202d 2d2d 2d2d  eturns.    -----
+00003de0: 2d2d 0a20 2020 206e 756d 5f63 6f65 6666  --.    num_coeff
+00003df0: 733a 2069 6e74 0a20 2020 2020 2020 204e  s: int.        N
+00003e00: 756d 6265 7220 6f66 2067 5043 2063 6f65  umber of gPC coe
+00003e10: 6666 6963 6965 6e74 7320 616e 6420 706f  fficients and po
+00003e20: 6c79 6e6f 6d69 616c 730a 2020 2020 2222  lynomials.    ""
+00003e30: 220a 0a20 2020 2072 6574 7572 6e20 7363  "..    return sc
+00003e40: 6970 792e 7370 6563 6961 6c2e 6661 6374  ipy.special.fact
+00003e50: 6f72 6961 6c28 6f72 6465 7220 2b20 6469  orial(order + di
+00003e60: 6d29 202f 2028 7363 6970 792e 7370 6563  m) / (scipy.spec
+00003e70: 6961 6c2e 6661 6374 6f72 6961 6c28 6f72  ial.factorial(or
+00003e80: 6465 7229 202a 2073 6369 7079 2e73 7065  der) * scipy.spe
+00003e90: 6369 616c 2e66 6163 746f 7269 616c 2864  cial.factorial(d
+00003ea0: 696d 2929 0a0a 0a64 6566 2067 6574 5f6e  im))...def get_n
+00003eb0: 756d 5f63 6f65 6666 735f 7370 6172 7365  um_coeffs_sparse
+00003ec0: 286f 7264 6572 5f64 696d 5f6d 6178 2c20  (order_dim_max, 
+00003ed0: 6f72 6465 725f 676c 6f62 5f6d 6178 2c20  order_glob_max, 
+00003ee0: 6f72 6465 725f 696e 7465 725f 6d61 782c  order_inter_max,
+00003ef0: 2064 696d 2c20 6f72 6465 725f 696e 7465   dim, order_inte
+00003f00: 725f 6375 7272 656e 743d 4e6f 6e65 2c0a  r_current=None,.
+00003f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003f20: 2020 2020 2020 2020 2020 6f72 6465 725f            order_
+00003f30: 676c 6f62 5f6d 6178 5f6e 6f72 6d3d 3129  glob_max_norm=1)
+00003f40: 3a0a 2020 2020 2222 220a 2020 2020 4361  :.    """.    Ca
+00003f50: 6c63 756c 6174 6520 7468 6520 6e75 6d62  lculate the numb
+00003f60: 6572 206f 6620 6750 4320 636f 6566 6669  er of gPC coeffi
+00003f70: 6369 656e 7473 2066 6f72 2061 2073 7065  cients for a spe
+00003f80: 6369 6669 6320 6d61 7869 6d75 6d20 6f72  cific maximum or
+00003f90: 6465 7220 696e 2065 6163 6820 6469 6d65  der in each dime
+00003fa0: 6e73 696f 6e20 226f 7264 6572 5f64 696d  nsion "order_dim
+00003fb0: 5f6d 6178 222c 0a20 2020 2067 6c6f 6261  _max",.    globa
+00003fc0: 6c20 6d61 7869 6d75 6d20 6f72 6465 7220  l maximum order 
+00003fd0: 226f 7264 6572 5f67 6c6f 625f 6d61 7822  "order_glob_max"
+00003fe0: 2061 6e64 2074 6865 2069 6e74 6572 6163   and the interac
+00003ff0: 7469 6f6e 206f 7264 6572 2022 6f72 6465  tion order "orde
+00004000: 725f 696e 7465 725f 6d61 7822 2e0a 0a20  r_inter_max"... 
+00004010: 2020 206e 756d 5f63 6f65 6666 735f 7370     num_coeffs_sp
+00004020: 6172 7365 203d 2067 6574 5f6e 756d 5f63  arse = get_num_c
+00004030: 6f65 6666 735f 7370 6172 7365 286f 7264  oeffs_sparse(ord
+00004040: 6572 5f64 696d 5f6d 6178 2c20 6f72 6465  er_dim_max, orde
+00004050: 725f 676c 6f62 5f6d 6178 2c20 6f72 6465  r_glob_max, orde
+00004060: 725f 696e 7465 725f 6d61 782c 2064 696d  r_inter_max, dim
+00004070: 290a 0a20 2020 2050 6172 616d 6574 6572  )..    Parameter
+00004080: 730a 2020 2020 2d2d 2d2d 2d2d 2d2d 2d2d  s.    ----------
+00004090: 0a20 2020 206f 7264 6572 5f64 696d 5f6d  .    order_dim_m
+000040a0: 6178 3a20 6e64 6172 7261 7920 6f66 2069  ax: ndarray of i
+000040b0: 6e74 206f 7220 6c69 7374 206f 6620 696e  nt or list of in
+000040c0: 7420 5b64 696d 5d0a 2020 2020 2020 2020  t [dim].        
+000040d0: 4d61 7869 6d75 6d20 6f72 6465 7220 696e  Maximum order in
+000040e0: 2065 6163 6820 6469 6d65 6e73 696f 6e0a   each dimension.
+000040f0: 2020 2020 6f72 6465 725f 676c 6f62 5f6d      order_glob_m
+00004100: 6178 3a20 696e 740a 2020 2020 2020 2020  ax: int.        
+00004110: 4d61 7869 6d75 6d20 676c 6f62 616c 206f  Maximum global o
+00004120: 7264 6572 206f 6620 696e 7465 7261 6374  rder of interact
+00004130: 696e 6720 706f 6c79 6e6f 6d69 616c 730a  ing polynomials.
+00004140: 2020 2020 6f72 6465 725f 696e 7465 725f      order_inter_
+00004150: 6d61 783a 2069 6e74 0a20 2020 2020 2020  max: int.       
+00004160: 2049 6e74 6572 6163 7469 6f6e 206f 7264   Interaction ord
+00004170: 6572 0a20 2020 2064 696d 3a20 696e 740a  er.    dim: int.
+00004180: 2020 2020 2020 2020 4e75 6d62 6572 206f          Number o
+00004190: 6620 7261 6e64 6f6d 2076 6172 6961 626c  f random variabl
+000041a0: 6573 0a20 2020 206f 7264 6572 5f69 6e74  es.    order_int
+000041b0: 6572 5f63 7572 7265 6e74 203a 2069 6e74  er_current : int
+000041c0: 0a0a 2020 2020 6f72 6465 725f 676c 6f62  ..    order_glob
+000041d0: 5f6d 6178 5f6e 6f72 6d3a 2066 6c6f 6174  _max_norm: float
+000041e0: 0a20 2020 2020 2020 204e 6f72 6d2c 2077  .        Norm, w
+000041f0: 6869 6368 2064 6566 696e 6573 2068 6f77  hich defines how
+00004200: 2074 6865 206f 7264 6572 7320 6172 6520   the orders are 
+00004210: 6163 6375 6d75 6c61 7465 6420 746f 2064  accumulated to d
+00004220: 6572 6976 6520 7468 6520 746f 7461 6c20  erive the total 
+00004230: 6f72 6465 7220 2864 6566 6175 6c74 3a20  order (default: 
+00004240: 312d 6e6f 726d 292e 0a20 2020 2020 2020  1-norm)..       
+00004250: 2056 616c 7565 7320 736d 616c 6c65 7220   Values smaller 
+00004260: 7468 616e 206f 6e65 2072 6573 7472 6963  than one restric
+00004270: 7420 6869 6768 6572 206f 7264 6572 7320  t higher orders 
+00004280: 616e 6420 7368 7269 6e6b 2074 6865 2062  and shrink the b
+00004290: 6173 6973 2e0a 0a20 2020 2052 6574 7572  asis...    Retur
+000042a0: 6e73 0a20 2020 202d 2d2d 2d2d 2d2d 0a20  ns.    -------. 
+000042b0: 2020 206e 756d 5f63 6f65 6666 735f 7370     num_coeffs_sp
+000042c0: 6172 7365 3a20 696e 740a 2020 2020 2020  arse: int.      
+000042d0: 2020 4e75 6d62 6572 206f 6620 6750 4320    Number of gPC 
+000042e0: 636f 6566 6669 6369 656e 7473 2061 6e64  coefficients and
+000042f0: 2070 6f6c 796e 6f6d 6961 6c73 0a20 2020   polynomials.   
+00004300: 2022 2222 0a0a 2020 2020 6966 206f 7264   """..    if ord
+00004310: 6572 5f69 6e74 6572 5f63 7572 7265 6e74  er_inter_current
+00004320: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+00004330: 2020 6f72 6465 725f 696e 7465 725f 6375    order_inter_cu
+00004340: 7272 656e 7420 3d20 6f72 6465 725f 696e  rrent = order_in
+00004350: 7465 725f 6d61 780a 0a20 2020 2069 6620  ter_max..    if 
+00004360: 7479 7065 286f 7264 6572 5f64 696d 5f6d  type(order_dim_m
+00004370: 6178 2920 6973 206c 6973 743a 0a20 2020  ax) is list:.   
+00004380: 2020 2020 206f 7264 6572 5f64 696d 5f6d       order_dim_m
+00004390: 6178 203d 206e 702e 6172 7261 7928 6f72  ax = np.array(or
+000043a0: 6465 725f 6469 6d5f 6d61 7829 0a0a 2020  der_dim_max)..  
+000043b0: 2020 6966 206f 7264 6572 5f64 696d 5f6d    if order_dim_m
+000043c0: 6178 2e73 697a 6520 3d3d 2031 3a0a 2020  ax.size == 1:.  
+000043d0: 2020 2020 2020 6f72 6465 725f 6469 6d5f        order_dim_
+000043e0: 6d61 7820 3d20 6f72 6465 725f 6469 6d5f  max = order_dim_
+000043f0: 6d61 7820 2a20 6e70 2e6f 6e65 7328 6469  max * np.ones(di
+00004400: 6d29 0a0a 2020 2020 2320 6765 6e65 7261  m)..    # genera
+00004410: 7465 206d 756c 7469 2d69 6e64 6578 206c  te multi-index l
+00004420: 6973 7420 7570 2074 6f20 6d61 7869 6d75  ist up to maximu
+00004430: 6d20 6f72 6465 720a 2020 2020 6966 2064  m order.    if d
+00004440: 696d 203d 3d20 313a 0a20 2020 2020 2020  im == 1:.       
+00004450: 2070 6f6c 795f 6964 7820 3d20 6e70 2e61   poly_idx = np.a
+00004460: 7272 6179 285b 6e70 2e6c 696e 7370 6163  rray([np.linspac
+00004470: 6528 302c 206f 7264 6572 5f64 696d 5f6d  e(0, order_dim_m
+00004480: 6178 5b30 5d2c 2069 6e74 286f 7264 6572  ax[0], int(order
+00004490: 5f64 696d 5f6d 6178 5b30 5d20 2b20 3129  _dim_max[0] + 1)
+000044a0: 295d 292e 6173 7479 7065 2869 6e74 292e  )]).astype(int).
+000044b0: 7472 616e 7370 6f73 6528 290a 2020 2020  transpose().    
+000044c0: 656c 7365 3a0a 2020 2020 2020 2020 706f  else:.        po
+000044d0: 6c79 5f69 6478 203d 2067 6574 5f6d 756c  ly_idx = get_mul
+000044e0: 7469 5f69 6e64 6963 6573 286f 7264 6572  ti_indices(order
+000044f0: 3d6f 7264 6572 5f64 696d 5f6d 6178 2c0a  =order_dim_max,.
+00004500: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004510: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004520: 2020 2020 206f 7264 6572 5f6d 6178 3d6f       order_max=o
+00004530: 7264 6572 5f67 6c6f 625f 6d61 782c 0a20  rder_glob_max,. 
+00004540: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004550: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004560: 2020 2020 696e 7465 7261 6374 696f 6e5f      interaction_
+00004570: 6f72 6465 723d 6f72 6465 725f 696e 7465  order=order_inte
+00004580: 725f 6d61 782c 0a20 2020 2020 2020 2020  r_max,.         
+00004590: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000045a0: 2020 2020 2020 2020 2020 2020 6f72 6465              orde
+000045b0: 725f 6d61 785f 6e6f 726d 3d6f 7264 6572  r_max_norm=order
+000045c0: 5f67 6c6f 625f 6d61 785f 6e6f 726d 2c0a  _glob_max_norm,.
+000045d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000045e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000045f0: 2020 2020 2069 6e74 6572 6163 7469 6f6e       interaction
+00004600: 5f6f 7264 6572 5f63 7572 7265 6e74 3d6f  _order_current=o
+00004610: 7264 6572 5f69 6e74 6572 5f63 7572 7265  rder_inter_curre
+00004620: 6e74 290a 0a20 2020 2066 6f72 2069 5f64  nt)..    for i_d
+00004630: 696d 2069 6e20 7261 6e67 6528 6469 6d29  im in range(dim)
+00004640: 3a0a 2020 2020 2020 2020 2320 6164 6420  :.        # add 
+00004650: 6d75 6c74 692d 696e 6465 7865 7320 746f  multi-indexes to
+00004660: 206c 6973 7420 7768 656e 206e 6f74 2079   list when not y
+00004670: 6574 2069 6e63 6c75 6465 640a 2020 2020  et included.    
+00004680: 2020 2020 6966 206f 7264 6572 5f64 696d      if order_dim
+00004690: 5f6d 6178 5b69 5f64 696d 5d20 3e20 6f72  _max[i_dim] > or
+000046a0: 6465 725f 676c 6f62 5f6d 6178 3a0a 2020  der_glob_max:.  
+000046b0: 2020 2020 2020 2020 2020 706f 6c79 5f61            poly_a
+000046c0: 6464 5f64 696d 203d 206e 702e 6c69 6e73  dd_dim = np.lins
+000046d0: 7061 6365 286f 7264 6572 5f67 6c6f 625f  pace(order_glob_
+000046e0: 6d61 7820 2b20 312c 0a20 2020 2020 2020  max + 1,.       
+000046f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004700: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004710: 6f72 6465 725f 6469 6d5f 6d61 785b 695f  order_dim_max[i_
+00004720: 6469 6d5d 2c0a 2020 2020 2020 2020 2020  dim],.          
+00004730: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004740: 2020 2020 2020 2020 2020 2020 206f 7264               ord
+00004750: 6572 5f64 696d 5f6d 6178 5b69 5f64 696d  er_dim_max[i_dim
+00004760: 5d20 2d20 286f 7264 6572 5f67 6c6f 625f  ] - (order_glob_
+00004770: 6d61 7820 2b20 3129 202b 2031 290a 2020  max + 1) + 1).  
+00004780: 2020 2020 2020 2020 2020 706f 6c79 5f61            poly_a
+00004790: 6464 5f61 6c6c 203d 206e 702e 7a65 726f  dd_all = np.zero
+000047a0: 7328 5b70 6f6c 795f 6164 645f 6469 6d2e  s([poly_add_dim.
+000047b0: 7368 6170 655b 305d 2c20 6469 6d5d 290a  shape[0], dim]).
+000047c0: 2020 2020 2020 2020 2020 2020 706f 6c79              poly
+000047d0: 5f61 6464 5f61 6c6c 5b3a 2c20 695f 6469  _add_all[:, i_di
+000047e0: 6d5d 203d 2070 6f6c 795f 6164 645f 6469  m] = poly_add_di
+000047f0: 6d0a 2020 2020 2020 2020 2020 2020 706f  m.            po
+00004800: 6c79 5f69 6478 203d 206e 702e 7673 7461  ly_idx = np.vsta
+00004810: 636b 285b 706f 6c79 5f69 6478 2c20 706f  ck([poly_idx, po
+00004820: 6c79 5f61 6464 5f61 6c6c 2e61 7374 7970  ly_add_all.astyp
+00004830: 6528 696e 7429 5d29 0a0a 2020 2020 2020  e(int)])..      
+00004840: 2020 2320 6465 6c65 7465 206d 756c 7469    # delete multi
+00004850: 2d69 6e64 6578 6573 2066 726f 6d20 6c69  -indexes from li
+00004860: 7374 2077 6865 6e20 7468 6579 2065 7863  st when they exc
+00004870: 6565 6420 696e 6469 7669 6475 616c 206d  eed individual m
+00004880: 6178 206f 7264 6572 206f 6620 7061 7261  ax order of para
+00004890: 6d65 7465 720a 2020 2020 2020 2020 656c  meter.        el
+000048a0: 6966 206f 7264 6572 5f64 696d 5f6d 6178  if order_dim_max
+000048b0: 5b69 5f64 696d 5d20 3c20 6f72 6465 725f  [i_dim] < order_
+000048c0: 676c 6f62 5f6d 6178 3a0a 2020 2020 2020  glob_max:.      
+000048d0: 2020 2020 2020 706f 6c79 5f69 6478 203d        poly_idx =
+000048e0: 2070 6f6c 795f 6964 785b 706f 6c79 5f69   poly_idx[poly_i
+000048f0: 6478 5b3a 2c20 695f 6469 6d5d 203c 3d20  dx[:, i_dim] <= 
+00004900: 6f72 6465 725f 6469 6d5f 6d61 785b 695f  order_dim_max[i_
+00004910: 6469 6d5d 2c20 3a5d 0a0a 2020 2020 2320  dim], :]..    # 
+00004920: 436f 6e73 6964 6572 2069 6e74 6572 6163  Consider interac
+00004930: 7469 6f6e 206f 7264 6572 2028 6669 6c74  tion order (filt
+00004940: 6572 206f 7574 206d 756c 7469 2d69 6e64  er out multi-ind
+00004950: 6963 6573 2065 7863 6565 6469 6e67 2069  ices exceeding i
+00004960: 7429 0a20 2020 2070 6f6c 795f 6964 7820  t).    poly_idx 
+00004970: 3d20 706f 6c79 5f69 6478 5b6e 702e 7375  = poly_idx[np.su
+00004980: 6d28 706f 6c79 5f69 6478 203e 2030 2c20  m(poly_idx > 0, 
+00004990: 6178 6973 3d31 2920 3c3d 206f 7264 6572  axis=1) <= order
+000049a0: 5f69 6e74 6572 5f6d 6178 2c20 3a5d 0a0a  _inter_max, :]..
+000049b0: 2020 2020 7265 7475 726e 2070 6f6c 795f      return poly_
+000049c0: 6964 782e 7368 6170 655b 305d 0a0a 0a64  idx.shape[0]...d
+000049d0: 6566 2067 6574 5f70 6466 5f62 6574 6128  ef get_pdf_beta(
+000049e0: 782c 2070 2c20 712c 2061 2c20 6229 3a0a  x, p, q, a, b):.
+000049f0: 2020 2020 2222 220a 2020 2020 4361 6c63      """.    Calc
+00004a00: 756c 6174 6520 7468 6520 7072 6f62 6162  ulate the probab
+00004a10: 696c 6974 7920 6465 6e73 6974 7920 6675  ility density fu
+00004a20: 6e63 7469 6f6e 206f 6620 7468 6520 6265  nction of the be
+00004a30: 7461 2064 6973 7472 6962 7574 696f 6e20  ta distribution 
+00004a40: 696e 2074 6865 2069 6e74 6572 7661 6c20  in the interval 
+00004a50: 5b61 2c20 625d 2e0a 0a20 2020 2070 6466  [a, b]...    pdf
+00004a60: 203d 2028 6761 6d6d 6128 7029 2a67 616d   = (gamma(p)*gam
+00004a70: 6d61 2871 292f 6761 6d6d 6128 702b 7129  ma(q)/gamma(p+q)
+00004a80: 2e2a 2862 2d61 292a 2a28 702b 712d 3129  .*(b-a)**(p+q-1)
+00004a90: 292a 2a28 2d31 2920 2a0a 2020 2020 2020  )**(-1) *.      
+00004aa0: 2020 2020 2020 2020 2878 2d61 292a 2a28          (x-a)**(
+00004ab0: 702d 3129 202a 2028 622d 7829 2a2a 2871  p-1) * (b-x)**(q
+00004ac0: 2d31 293b 0a0a 2020 2020 7064 6620 3d20  -1);..    pdf = 
+00004ad0: 6765 745f 7064 665f 6265 7461 2878 2c20  get_pdf_beta(x, 
+00004ae0: 702c 2071 2c20 612c 2062 290a 0a20 2020  p, q, a, b)..   
+00004af0: 2050 6172 616d 6574 6572 730a 2020 2020   Parameters.    
+00004b00: 2d2d 2d2d 2d2d 2d2d 2d2d 0a20 2020 2078  ----------.    x
+00004b10: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
+00004b20: 6174 0a20 2020 2020 2020 2056 616c 7565  at.        Value
+00004b30: 7320 6f66 2072 616e 646f 6d20 7661 7269  s of random vari
+00004b40: 6162 6c65 0a20 2020 2061 3a20 666c 6f61  able.    a: floa
+00004b50: 740a 2020 2020 2020 2020 6c6f 7765 7220  t.        lower 
+00004b60: 626f 756e 6461 7279 0a20 2020 2062 3a20  boundary.    b: 
+00004b70: 666c 6f61 740a 2020 2020 2020 2020 7570  float.        up
+00004b80: 7065 7220 626f 756e 6461 7279 0a20 2020  per boundary.   
+00004b90: 2070 3a20 666c 6f61 740a 2020 2020 2020   p: float.      
+00004ba0: 2020 4669 7273 7420 7368 6170 6520 7061    First shape pa
+00004bb0: 7261 6d65 7465 7220 6465 6669 6e69 6e67  rameter defining
+00004bc0: 2074 6865 2064 6973 7472 6962 7574 696f   the distributio
+00004bd0: 6e0a 2020 2020 713a 2066 6c6f 6174 0a20  n.    q: float. 
+00004be0: 2020 2020 2020 2053 6563 6f6e 6420 7368         Second sh
+00004bf0: 6170 6520 7061 7261 6d65 7465 7220 6465  ape parameter de
+00004c00: 6669 6e69 6e67 2074 6865 2064 6973 7472  fining the distr
+00004c10: 6962 7574 696f 6e0a 0a20 2020 2052 6574  ibution..    Ret
+00004c20: 7572 6e73 0a20 2020 202d 2d2d 2d2d 2d2d  urns.    -------
+00004c30: 0a20 2020 2070 6466 3a20 6e64 6172 7261  .    pdf: ndarra
+00004c40: 7920 6f66 2066 6c6f 6174 0a20 2020 2020  y of float.     
+00004c50: 2020 2050 726f 6261 6269 6c69 7479 2064     Probability d
+00004c60: 656e 7369 7479 0a20 2020 2022 2222 0a20  ensity.    """. 
+00004c70: 2020 2072 6574 7572 6e20 2873 6369 7079     return (scipy
+00004c80: 2e73 7065 6369 616c 2e67 616d 6d61 2870  .special.gamma(p
+00004c90: 2920 2a20 7363 6970 792e 7370 6563 6961  ) * scipy.specia
+00004ca0: 6c2e 6761 6d6d 6128 7129 202f 2073 6369  l.gamma(q) / sci
+00004cb0: 7079 2e73 7065 6369 616c 2e67 616d 6d61  py.special.gamma
+00004cc0: 2870 202b 2071 290a 2020 2020 2020 2020  (p + q).        
+00004cd0: 2020 2020 2a20 2862 202d 2061 2920 2a2a      * (b - a) **
+00004ce0: 2028 7020 2b20 7120 2d20 3129 2920 2a2a   (p + q - 1)) **
+00004cf0: 2028 2d31 2920 2a20 2878 202d 2061 2920   (-1) * (x - a) 
+00004d00: 2a2a 2028 7020 2d20 3129 202a 2028 6220  ** (p - 1) * (b 
+00004d10: 2d20 7829 202a 2a20 2871 202d 2031 290a  - x) ** (q - 1).
+00004d20: 0a0a 6465 6620 6765 745f 616c 6c5f 636f  ..def get_all_co
+00004d30: 6d62 696e 6174 696f 6e73 2861 7272 6179  mbinations(array
+00004d40: 2c20 6e75 6d62 6572 5f65 6c65 6d65 6e74  , number_element
+00004d50: 7329 3a0a 2020 2020 2222 220a 2020 2020  s):.    """.    
+00004d60: 436f 6d70 7574 6520 616c 6c20 6b2d 7475  Compute all k-tu
+00004d70: 706c 6573 2028 655f 312c 2065 5f32 2c20  ples (e_1, e_2, 
+00004d80: 2e2e 2e2c 2065 5f6b 2920 6f66 2063 6f6d  ..., e_k) of com
+00004d90: 6269 6e61 7469 6f6e 7320 6f66 2074 6865  binations of the
+00004da0: 2073 6574 206f 6620 656c 656d 656e 7473   set of elements
+00004db0: 206f 6620 7468 6520 696e 7075 7420 6172   of the input ar
+00004dc0: 7261 7920 7768 6572 650a 2020 2020 655f  ray where.    e_
+00004dd0: 6e2b 3120 3e20 655f 6e2e 0a20 2020 2063  n+1 > e_n..    c
+00004de0: 6f6d 6269 6e61 7469 6f6e 7320 3d20 6765  ombinations = ge
+00004df0: 745f 616c 6c5f 636f 6d62 696e 6174 696f  t_all_combinatio
+00004e00: 6e73 2861 7272 6179 2c20 6e75 6d62 6572  ns(array, number
+00004e10: 5f65 6c65 6d65 6e74 7329 0a20 2020 2050  _elements).    P
+00004e20: 6172 616d 6574 6572 730a 2020 2020 2d2d  arameters.    --
+00004e30: 2d2d 2d2d 2d2d 2d2d 0a20 2020 2061 7272  --------.    arr
+00004e40: 6179 3a20 6e70 2e6e 6461 7272 6179 0a20  ay: np.ndarray. 
+00004e50: 2020 2020 2020 2041 7272 6179 2074 6f20         Array to 
+00004e60: 7065 7266 6f72 6d20 7468 6520 636f 6d62  perform the comb
+00004e70: 696e 6174 6f72 6961 6c20 7072 6f62 6c65  inatorial proble
+00004e80: 6d20 7769 7468 0a20 2020 206e 756d 6265  m with.    numbe
+00004e90: 725f 656c 656d 656e 7473 3a20 696e 740a  r_elements: int.
+00004ea0: 2020 2020 2020 2020 4e75 6d62 6572 206f          Number o
+00004eb0: 6620 656c 656d 656e 7473 2069 6e20 7475  f elements in tu
+00004ec0: 706c 650a 2020 2020 5265 7475 726e 730a  ple.    Returns.
+00004ed0: 2020 2020 2d2d 2d2d 2d2d 2d0a 2020 2020      -------.    
+00004ee0: 636f 6d62 696e 6174 696f 6e73 3a20 6e70  combinations: np
+00004ef0: 2e6e 6461 7272 6179 0a20 2020 2020 2020  .ndarray.       
+00004f00: 2041 7272 6179 206f 6620 636f 6d62 696e   Array of combin
+00004f10: 6174 696f 6e20 7665 6374 6f72 730a 2020  ation vectors.  
+00004f20: 2020 2222 220a 0a20 2020 2063 6f6d 6269    """..    combi
+00004f30: 6e61 7469 6f6e 7320 3d20 6974 6572 746f  nations = iterto
+00004f40: 6f6c 732e 636f 6d62 696e 6174 696f 6e73  ols.combinations
+00004f50: 2861 7272 6179 2c20 6e75 6d62 6572 5f65  (array, number_e
+00004f60: 6c65 6d65 6e74 7329 0a20 2020 2072 6574  lements).    ret
+00004f70: 7572 6e20 6e70 2e61 7272 6179 285b 6320  urn np.array([c 
+00004f80: 666f 7220 6320 696e 2063 6f6d 6269 6e61  for c in combina
+00004f90: 7469 6f6e 735d 290a 0a0a 6465 6620 6765  tions])...def ge
+00004fa0: 745f 6d75 6c74 695f 696e 6469 6365 7328  t_multi_indices(
+00004fb0: 6f72 6465 722c 206f 7264 6572 5f6d 6178  order, order_max
+00004fc0: 2c20 696e 7465 7261 6374 696f 6e5f 6f72  , interaction_or
+00004fd0: 6465 722c 206f 7264 6572 5f6d 6178 5f6e  der, order_max_n
+00004fe0: 6f72 6d3d 312e 2c20 696e 7465 7261 6374  orm=1., interact
+00004ff0: 696f 6e5f 6f72 6465 725f 6375 7272 656e  ion_order_curren
+00005000: 743d 4e6f 6e65 293a 0a20 2020 2022 2222  t=None):.    """
+00005010: 0a20 2020 2043 6f6d 7075 7465 7320 616c  .    Computes al
+00005020: 6c20 6d75 6c74 692d 696e 6469 6365 7320  l multi-indices 
+00005030: 7769 7468 2061 206d 6178 696d 756d 206f  with a maximum o
+00005040: 7665 7261 6c6c 206f 7264 6572 206f 6620  verall order of 
+00005050: 6d61 785f 6f72 6465 7220 636f 6e73 6964  max_order consid
+00005060: 6572 696e 6720 6120 6365 7274 6169 6e20  ering a certain 
+00005070: 6d61 7869 6d75 6d20 6f72 6465 7220 6e6f  maximum order no
+00005080: 726d 2e0a 0a20 2020 206d 756c 7469 5f69  rm...    multi_i
+00005090: 6e64 6963 6573 203d 2067 6574 5f6d 756c  ndices = get_mul
+000050a0: 7469 5f69 6e64 6963 6573 286c 656e 6774  ti_indices(lengt
+000050b0: 682c 206d 6178 5f6f 7264 6572 290a 0a20  h, max_order).. 
+000050c0: 2020 2050 6172 616d 6574 6572 730a 2020     Parameters.  
+000050d0: 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0a20 2020    ----------.   
+000050e0: 206f 7264 6572 203a 206c 6973 7420 6f66   order : list of
+000050f0: 2069 6e74 205b 6469 6d5d 0a20 2020 2020   int [dim].     
+00005100: 2020 204d 6178 696d 756d 2069 6e64 6976     Maximum indiv
+00005110: 6964 7561 6c20 6578 7061 6e73 696f 6e20  idual expansion 
+00005120: 6f72 6465 720a 2020 2020 2020 2020 4765  order.        Ge
+00005130: 6e65 7261 7465 7320 696e 6469 7669 6475  nerates individu
+00005140: 616c 2070 6f6c 796e 6f6d 6961 6c73 2061  al polynomials a
+00005150: 6c73 6f20 6966 206d 6178 696d 756d 2065  lso if maximum e
+00005160: 7870 616e 7369 6f6e 206f 7264 6572 2069  xpansion order i
+00005170: 6e20 6f72 6465 725f 6d61 7820 6973 2065  n order_max is e
+00005180: 7863 6565 6465 640a 2020 2020 6f72 6465  xceeded.    orde
+00005190: 725f 6d61 7820 3a20 696e 740a 2020 2020  r_max : int.    
+000051a0: 2020 2020 4d61 7869 6d75 6d20 676c 6f62      Maximum glob
+000051b0: 616c 2065 7870 616e 7369 6f6e 206f 7264  al expansion ord
+000051c0: 6572 2e0a 2020 2020 2020 2020 5468 6520  er..        The 
+000051d0: 6d61 7869 6d75 6d20 6578 7061 6e73 696f  maximum expansio
+000051e0: 6e20 6f72 6465 7220 636f 6e73 6964 6572  n order consider
+000051f0: 7320 7468 6520 7375 6d20 6f66 2074 6865  s the sum of the
+00005200: 206f 7264 6572 7320 6f66 2063 6f6d 6269   orders of combi
+00005210: 6e65 6420 706f 6c79 6e6f 6d69 616c 7320  ned polynomials 
+00005220: 746f 6765 7468 6572 2077 6974 6820 7468  together with th
+00005230: 650a 2020 2020 2020 2020 6368 6f73 656e  e.        chosen
+00005240: 206e 6f72 6d20 226f 7264 6572 5f6d 6178   norm "order_max
+00005250: 5f6e 6f72 6d22 2e20 5479 7069 6361 6c6c  _norm". Typicall
+00005260: 7920 7468 6973 206e 6f72 6d20 6973 2031  y this norm is 1
+00005270: 2073 7563 6820 7468 6174 2074 6865 206d   such that the m
+00005280: 6178 696d 756d 206f 7264 6572 2069 7320  aximum order is 
+00005290: 7468 6520 7375 6d20 6f66 2061 6c6c 0a20  the sum of all. 
+000052a0: 2020 2020 2020 206d 6f6e 6f6d 6961 6c20         monomial 
+000052b0: 6f72 6465 7273 2e0a 2020 2020 6f72 6465  orders..    orde
+000052c0: 725f 6d61 785f 6e6f 726d 203a 2066 6c6f  r_max_norm : flo
+000052d0: 6174 0a20 2020 2020 2020 204e 6f72 6d20  at.        Norm 
+000052e0: 666f 7220 7768 6963 6820 7468 6520 6d61  for which the ma
+000052f0: 7869 6d75 6d20 676c 6f62 616c 2065 7870  ximum global exp
+00005300: 616e 7369 6f6e 206f 7264 6572 2069 7320  ansion order is 
+00005310: 6465 6669 6e65 6420 5b30 2c20 315d 2e20  defined [0, 1]. 
+00005320: 5661 6c75 6573 203c 2031 2064 6563 7265  Values < 1 decre
+00005330: 6173 6520 7468 6520 746f 7461 6c20 6e75  ase the total nu
+00005340: 6d62 6572 0a20 2020 2020 2020 206f 6620  mber.        of 
+00005350: 706f 6c79 6e6f 6d69 616c 7320 696e 2074  polynomials in t
+00005360: 6865 2065 7870 616e 7369 6f6e 2073 7563  he expansion suc
+00005370: 6820 7468 6174 2069 6e74 6572 6163 7469  h that interacti
+00005380: 6f6e 2074 6572 6d73 2061 7265 2070 656e  on terms are pen
+00005390: 616c 697a 6564 206d 6f72 652e 0a20 2020  alized more..   
+000053a0: 2020 2020 2073 756d 2861 5f69 5e71 295e       sum(a_i^q)^
+000053b0: 312f 7120 3c3d 2070 2c20 7768 6572 6520  1/q <= p, where 
+000053c0: 7020 6973 206f 7264 6572 5f6d 6178 2061  p is order_max a
+000053d0: 6e64 2071 2069 7320 6f72 6465 725f 6d61  nd q is order_ma
+000053e0: 785f 6e6f 726d 2028 666f 7220 6d6f 7265  x_norm (for more
+000053f0: 2064 6574 6169 6c73 2073 6565 2065 7120   details see eq 
+00005400: 2831 3129 2069 6e20 5b31 5d29 2e0a 2020  (11) in [1])..  
+00005410: 2020 696e 7465 7261 6374 696f 6e5f 6f72    interaction_or
+00005420: 6465 7220 3a20 696e 740a 2020 2020 2020  der : int.      
+00005430: 2020 4e75 6d62 6572 206f 6620 7261 6e64    Number of rand
+00005440: 6f6d 2076 6172 6961 626c 6573 2c20 7768  om variables, wh
+00005450: 6963 6820 6361 6e20 696e 7465 7261 6374  ich can interact
+00005460: 2077 6974 6820 6561 6368 206f 7468 6572   with each other
+00005470: 0a20 2020 2069 6e74 6572 6163 7469 6f6e  .    interaction
+00005480: 5f6f 7264 6572 5f63 7572 7265 6e74 203a  _order_current :
+00005490: 2069 6e74 2c20 6f70 7469 6f6e 616c 2c20   int, optional, 
+000054a0: 6465 6661 756c 743a 2069 6e74 6572 6163  default: interac
+000054b0: 7469 6f6e 5f6f 7264 6572 0a20 2020 2020  tion_order.     
+000054c0: 2020 204e 756d 6265 7220 6f66 2072 616e     Number of ran
+000054d0: 646f 6d20 7661 7269 6162 6c65 7320 6375  dom variables cu
+000054e0: 7272 656e 746c 7920 696e 7465 7261 6374  rrently interact
+000054f0: 696e 6720 7769 7468 2072 6573 7065 6374  ing with respect
+00005500: 2074 6f20 7468 6520 6869 6768 6573 7420   to the highest 
+00005510: 6f72 6465 722e 0a20 2020 2020 2020 2028  order..        (
+00005520: 696e 7465 7261 6374 696f 6e5f 6f72 6465  interaction_orde
+00005530: 725f 6375 7272 656e 7420 3c3d 2069 6e74  r_current <= int
+00005540: 6572 6163 7469 6f6e 5f6f 7264 6572 290a  eraction_order).
+00005550: 2020 2020 2020 2020 5468 6520 7061 7261          The para
+00005560: 6d65 7465 7273 2066 6f72 206c 6f77 6572  meters for lower
+00005570: 206f 7264 6572 7320 6172 6520 616c 6c20   orders are all 
+00005580: 696e 7465 7261 6374 696e 6720 7769 7468  interacting with
+00005590: 2069 6e74 6572 6163 7469 6f6e 5f6f 7264   interaction_ord
+000055a0: 6572 2e0a 0a20 2020 2052 6574 7572 6e73  er...    Returns
+000055b0: 0a20 2020 202d 2d2d 2d2d 2d2d 0a20 2020  .    -------.   
+000055c0: 206d 756c 7469 5f69 6e64 6963 6573 3a20   multi_indices: 
+000055d0: 6e64 6172 7261 7920 5b6e 5f62 6173 6973  ndarray [n_basis
+000055e0: 2078 2064 696d 5d0a 2020 2020 2020 2020   x dim].        
+000055f0: 4d75 6c74 692d 696e 6469 6365 7320 666f  Multi-indices fo
+00005600: 7220 6120 6d61 7869 6d75 6d20 6f72 6465  r a maximum orde
+00005610: 7220 6750 4320 6173 7375 6d69 6e67 2061  r gPC assuming a
+00005620: 2063 6572 7461 696e 206f 7264 6572 206e   certain order n
+00005630: 6f72 6d2e 0a20 2020 2022 2222 0a0a 2020  orm..    """..  
+00005640: 2020 6469 6d20 3d20 6c65 6e28 6f72 6465    dim = len(orde
+00005650: 7229 0a0a 2020 2020 6f72 6465 725f 6d61  r)..    order_ma
+00005660: 7820 3d20 696e 7428 6f72 6465 725f 6d61  x = int(order_ma
+00005670: 7829 0a20 2020 206f 7264 6572 203d 205b  x).    order = [
+00005680: 696e 7428 6f29 2066 6f72 206f 2069 6e20  int(o) for o in 
+00005690: 6f72 6465 725d 0a0a 2020 2020 6966 2069  order]..    if i
+000056a0: 6e74 6572 6163 7469 6f6e 5f6f 7264 6572  nteraction_order
+000056b0: 5f63 7572 7265 6e74 2069 7320 4e6f 6e65  _current is None
+000056c0: 206f 7220 696e 7465 7261 6374 696f 6e5f   or interaction_
+000056d0: 6f72 6465 725f 6375 7272 656e 7420 3e20  order_current > 
+000056e0: 696e 7465 7261 6374 696f 6e5f 6f72 6465  interaction_orde
+000056f0: 723a 0a20 2020 2020 2020 2069 6e74 6572  r:.        inter
+00005700: 6163 7469 6f6e 5f6f 7264 6572 5f63 7572  action_order_cur
+00005710: 7265 6e74 203d 2069 6e74 6572 6163 7469  rent = interacti
+00005720: 6f6e 5f6f 7264 6572 0a20 2020 2065 6c73  on_order.    els
+00005730: 653a 0a20 2020 2020 2020 2069 6e74 6572  e:.        inter
+00005740: 6163 7469 6f6e 5f6f 7264 6572 5f63 7572  action_order_cur
+00005750: 7265 6e74 203d 2069 6e74 6572 6163 7469  rent = interacti
+00005760: 6f6e 5f6f 7264 6572 5f63 7572 7265 6e74  on_order_current
+00005770: 0a0a 2020 2020 6d75 6c74 695f 696e 6469  ..    multi_indi
+00005780: 6365 7320 3d20 5b5d 0a20 2020 2066 6f72  ces = [].    for
+00005790: 2069 5f6f 7264 6572 5f6d 6178 2069 6e20   i_order_max in 
+000057a0: 7261 6e67 6528 6f72 6465 725f 6d61 7820  range(order_max 
+000057b0: 2b20 3129 3a0a 2020 2020 2020 2020 7320  + 1):.        s 
+000057c0: 3d20 6765 745f 616c 6c5f 636f 6d62 696e  = get_all_combin
+000057d0: 6174 696f 6e73 286e 702e 6172 616e 6765  ations(np.arange
+000057e0: 2864 696d 202b 2069 5f6f 7264 6572 5f6d  (dim + i_order_m
+000057f0: 6178 202d 2031 2920 2b20 312c 2064 696d  ax - 1) + 1, dim
+00005800: 202d 2031 290a 0a20 2020 2020 2020 206d   - 1)..        m
+00005810: 203d 2073 2e73 6861 7065 5b30 5d0a 0a20   = s.shape[0].. 
+00005820: 2020 2020 2020 2073 3120 3d20 6e70 2e7a         s1 = np.z
+00005830: 6572 6f73 285b 6d2c 2031 5d29 0a20 2020  eros([m, 1]).   
+00005840: 2020 2020 2073 3220 3d20 2864 696d 202b       s2 = (dim +
+00005850: 2069 5f6f 7264 6572 5f6d 6178 2920 2b20   i_order_max) + 
+00005860: 7331 0a0a 2020 2020 2020 2020 7620 3d20  s1..        v = 
+00005870: 6e70 2e64 6966 6628 6e70 2e68 7374 6163  np.diff(np.hstac
+00005880: 6b28 5b73 312c 2073 2c20 7332 5d29 290a  k([s1, s, s2])).
+00005890: 2020 2020 2020 2020 7620 3d20 7620 2d20          v = v - 
+000058a0: 310a 0a20 2020 2020 2020 2069 6620 695f  1..        if i_
+000058b0: 6f72 6465 725f 6d61 7820 3d3d 2030 3a0a  order_max == 0:.
+000058c0: 2020 2020 2020 2020 2020 2020 6d75 6c74              mult
+000058d0: 695f 696e 6469 6365 7320 3d20 760a 2020  i_indices = v.  
+000058e0: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+000058f0: 2020 2020 2020 2020 6d75 6c74 695f 696e          multi_in
+00005900: 6469 6365 7320 3d20 6e70 2e76 7374 6163  dices = np.vstac
+00005910: 6b28 5b6d 756c 7469 5f69 6e64 6963 6573  k([multi_indices
+00005920: 2c20 765d 290a 0a20 2020 2023 2072 656d  , v])..    # rem
+00005930: 6f76 6520 706f 6c79 6e6f 6d69 616c 7320  ove polynomials 
+00005940: 6578 6365 6564 696e 6720 6f72 6465 725f  exceeding order_
+00005950: 6d61 7820 636f 6e73 6964 6572 696e 6720  max considering 
+00005960: 6d61 785f 6f72 6465 725f 6e6f 726d 0a20  max_order_norm. 
+00005970: 2020 2069 6620 6f72 6465 725f 6d61 785f     if order_max_
+00005980: 6e6f 726d 2021 3d20 313a 0a20 2020 2020  norm != 1:.     
+00005990: 2020 206d 756c 7469 5f69 6e64 6963 6573     multi_indices
+000059a0: 203d 206d 756c 7469 5f69 6e64 6963 6573   = multi_indices
+000059b0: 5b6e 702e 6c69 6e61 6c67 2e6e 6f72 6d28  [np.linalg.norm(
+000059c0: 6d75 6c74 695f 696e 6469 6365 732c 206f  multi_indices, o
+000059d0: 7264 3d6f 7264 6572 5f6d 6178 5f6e 6f72  rd=order_max_nor
+000059e0: 6d2c 2061 7869 733d 3129 203c 3d0a 2020  m, axis=1) <=.  
+000059f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005a10: 2020 2020 286f 7264 6572 5f6d 6178 202b      (order_max +
+00005a20: 2031 652d 3629 2c20 3a5d 0a0a 2020 2020   1e-6), :]..    
+00005a30: 2320 6164 6420 6f72 2064 656c 6574 6520  # add or delete 
+00005a40: 6d6f 6e6f 6d69 616c 7320 7370 6563 6966  monomials specif
+00005a50: 6965 6420 696e 206f 7264 6572 0a20 2020  ied in order.   
+00005a60: 2066 6f72 2069 5f64 696d 2069 6e20 7261   for i_dim in ra
+00005a70: 6e67 6528 6469 6d29 3a0a 2020 2020 2020  nge(dim):.      
+00005a80: 2020 2320 6164 6420 6d75 6c74 692d 696e    # add multi-in
+00005a90: 6465 7865 7320 746f 206c 6973 7420 7768  dexes to list wh
+00005aa0: 656e 206e 6f74 2079 6574 2069 6e63 6c75  en not yet inclu
+00005ab0: 6465 640a 2020 2020 2020 2020 6966 206f  ded.        if o
+00005ac0: 7264 6572 5b69 5f64 696d 5d20 3e20 6f72  rder[i_dim] > or
+00005ad0: 6465 725f 6d61 783a 0a20 2020 2020 2020  der_max:.       
+00005ae0: 2020 2020 206d 756c 7469 5f69 6e64 6963       multi_indic
+00005af0: 6573 5f61 6464 5f64 696d 203d 206e 702e  es_add_dim = np.
+00005b00: 6c69 6e73 7061 6365 286f 7264 6572 5f6d  linspace(order_m
+00005b10: 6178 202b 2031 2c0a 2020 2020 2020 2020  ax + 1,.        
+00005b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005b30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005b40: 2020 2020 2020 2020 6f72 6465 725b 695f          order[i_
+00005b50: 6469 6d5d 2c0a 2020 2020 2020 2020 2020  dim],.          
+00005b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005b80: 2020 2020 2020 6f72 6465 725b 695f 6469        order[i_di
+00005b90: 6d5d 202d 2028 6f72 6465 725f 6d61 7820  m] - (order_max 
+00005ba0: 2b20 3129 202b 2031 290a 2020 2020 2020  + 1) + 1).      
+00005bb0: 2020 2020 2020 6d75 6c74 695f 696e 6469        multi_indi
+00005bc0: 6365 735f 6164 645f 616c 6c20 3d20 6e70  ces_add_all = np
+00005bd0: 2e7a 6572 6f73 285b 6d75 6c74 695f 696e  .zeros([multi_in
+00005be0: 6469 6365 735f 6164 645f 6469 6d2e 7368  dices_add_dim.sh
+00005bf0: 6170 655b 305d 2c20 6469 6d5d 290a 2020  ape[0], dim]).  
+00005c00: 2020 2020 2020 2020 2020 6d75 6c74 695f            multi_
+00005c10: 696e 6469 6365 735f 6164 645f 616c 6c5b  indices_add_all[
+00005c20: 3a2c 2069 5f64 696d 5d20 3d20 6d75 6c74  :, i_dim] = mult
+00005c30: 695f 696e 6469 6365 735f 6164 645f 6469  i_indices_add_di
+00005c40: 6d0a 2020 2020 2020 2020 2020 2020 6d75  m.            mu
+00005c50: 6c74 695f 696e 6469 6365 7320 3d20 6e70  lti_indices = np
+00005c60: 2e76 7374 6163 6b28 5b6d 756c 7469 5f69  .vstack([multi_i
+00005c70: 6e64 6963 6573 2c20 6d75 6c74 695f 696e  ndices, multi_in
+00005c80: 6469 6365 735f 6164 645f 616c 6c2e 6173  dices_add_all.as
+00005c90: 7479 7065 2869 6e74 295d 290a 0a20 2020  type(int)])..   
+00005ca0: 2020 2020 2023 2064 656c 6574 6520 6d75       # delete mu
+00005cb0: 6c74 692d 696e 6465 7865 7320 6672 6f6d  lti-indexes from
+00005cc0: 206c 6973 7420 7768 656e 2074 6865 7920   list when they 
+00005cd0: 6578 6365 6564 2069 6e64 6976 6964 7561  exceed individua
+00005ce0: 6c20 6d61 7820 6f72 6465 7220 6f66 2070  l max order of p
+00005cf0: 6172 616d 6574 6572 0a20 2020 2020 2020  arameter.       
+00005d00: 2065 6c69 6620 6f72 6465 725b 695f 6469   elif order[i_di
+00005d10: 6d5d 203c 206f 7264 6572 5f6d 6178 3a0a  m] < order_max:.
+00005d20: 2020 2020 2020 2020 2020 2020 6d75 6c74              mult
+00005d30: 695f 696e 6469 6365 7320 3d20 6d75 6c74  i_indices = mult
+00005d40: 695f 696e 6469 6365 735b 6d75 6c74 695f  i_indices[multi_
+00005d50: 696e 6469 6365 735b 3a2c 2069 5f64 696d  indices[:, i_dim
+00005d60: 5d20 3c3d 206f 7264 6572 5b69 5f64 696d  ] <= order[i_dim
+00005d70: 5d2c 203a 5d0a 0a20 2020 2023 2043 6f6e  ], :]..    # Con
+00005d80: 7369 6465 7220 696e 7465 7261 6374 696f  sider interactio
+00005d90: 6e20 6f72 6465 7220 2866 696c 7465 7220  n order (filter 
+00005da0: 6f75 7420 6d75 6c74 692d 696e 6469 6365  out multi-indice
+00005db0: 7320 6578 6365 6564 696e 6720 6974 290a  s exceeding it).
+00005dc0: 2020 2020 6966 2069 6e74 6572 6163 7469      if interacti
+00005dd0: 6f6e 5f6f 7264 6572 203c 2064 696d 3a0a  on_order < dim:.
+00005de0: 2020 2020 2020 2020 6d75 6c74 695f 696e          multi_in
+00005df0: 6469 6365 7320 3d20 6d75 6c74 695f 696e  dices = multi_in
+00005e00: 6469 6365 735b 6e70 2e73 756d 286d 756c  dices[np.sum(mul
+00005e10: 7469 5f69 6e64 6963 6573 203e 2030 2c20  ti_indices > 0, 
+00005e20: 6178 6973 3d31 2920 3c3d 2069 6e74 6572  axis=1) <= inter
+00005e30: 6163 7469 6f6e 5f6f 7264 6572 2c20 3a5d  action_order, :]
+00005e40: 0a0a 2020 2020 2320 6966 2069 6e74 6572  ..    # if inter
+00005e50: 6163 7469 6f6e 5f6f 7264 6572 5f63 7572  action_order_cur
+00005e60: 7265 6e74 2069 7320 736d 616c 6c65 7220  rent is smaller 
+00005e70: 7468 616e 2069 6e74 6572 6163 7469 6f6e  than interaction
+00005e80: 5f6f 7264 6572 2c20 6465 6c65 7465 2074  _order, delete t
+00005e90: 686f 7365 2062 6173 6973 2066 756e 6374  hose basis funct
+00005ea0: 696f 6e73 206f 6620 6869 6768 6573 7420  ions of highest 
+00005eb0: 6f72 6465 720a 2020 2020 6966 2069 6e74  order.    if int
+00005ec0: 6572 6163 7469 6f6e 5f6f 7264 6572 5f63  eraction_order_c
+00005ed0: 7572 7265 6e74 203c 2069 6e74 6572 6163  urrent < interac
+00005ee0: 7469 6f6e 5f6f 7264 6572 3a0a 2020 2020  tion_order:.    
+00005ef0: 2020 2020 6d61 736b 5f6f 7264 6572 5f6d      mask_order_m
+00005f00: 6178 203d 206e 702e 7375 6d28 6d75 6c74  ax = np.sum(mult
+00005f10: 695f 696e 6469 6365 732c 2061 7869 733d  i_indices, axis=
+00005f20: 3129 203d 3d20 6f72 6465 725f 6d61 780a  1) == order_max.
+00005f30: 2020 2020 2020 2020 6d61 736b 5f69 6e74          mask_int
+00005f40: 6572 6163 7469 6f6e 5f6f 7264 6572 203d  eraction_order =
+00005f50: 206e 702e 7375 6d28 6d75 6c74 695f 696e   np.sum(multi_in
+00005f60: 6469 6365 7320 3e20 302c 2061 7869 733d  dices > 0, axis=
+00005f70: 3129 203e 2069 6e74 6572 6163 7469 6f6e  1) > interaction
+00005f80: 5f6f 7264 6572 5f63 7572 7265 6e74 0a20  _order_current. 
+00005f90: 2020 2020 2020 206d 6173 6b20 3d20 6e70         mask = np
+00005fa0: 2e6c 6f67 6963 616c 5f6e 6f74 286e 702e  .logical_not(np.
+00005fb0: 6c6f 6769 6361 6c5f 616e 6428 6d61 736b  logical_and(mask
+00005fc0: 5f6f 7264 6572 5f6d 6178 2c20 6d61 736b  _order_max, mask
+00005fd0: 5f69 6e74 6572 6163 7469 6f6e 5f6f 7264  _interaction_ord
+00005fe0: 6572 2929 0a20 2020 2020 2020 206d 756c  er)).        mul
+00005ff0: 7469 5f69 6e64 6963 6573 203d 206d 756c  ti_indices = mul
+00006000: 7469 5f69 6e64 6963 6573 5b6d 6173 6b5d  ti_indices[mask]
+00006010: 0a0a 2020 2020 7265 7475 726e 206d 756c  ..    return mul
+00006020: 7469 5f69 6e64 6963 6573 2e61 7374 7970  ti_indices.astyp
+00006030: 6528 696e 7429 0a0a 0a64 6566 2073 616d  e(int)...def sam
+00006040: 706c 655f 7370 6865 7265 286e 5f70 6f69  ple_sphere(n_poi
+00006050: 6e74 732c 2072 293a 0a20 2020 2022 2222  nts, r):.    """
+00006060: 0a20 2020 2043 7265 6174 6573 206e 5f70  .    Creates n_p
+00006070: 6f69 6e74 7320 6576 656e 6c79 2073 7072  oints evenly spr
+00006080: 6561 6420 696e 2061 2073 7068 6572 6520  ead in a sphere 
+00006090: 6f66 2072 6164 6975 7320 722e 0a0a 2020  of radius r...  
+000060a0: 2020 5061 7261 6d65 7465 7273 0a20 2020    Parameters.   
+000060b0: 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020 2020   ----------.    
+000060c0: 6e5f 706f 696e 7473 3a20 696e 740a 2020  n_points: int.  
+000060d0: 2020 2020 2020 4e75 6d62 6572 206f 6620        Number of 
+000060e0: 706f 696e 7473 2074 6f20 6265 2073 7072  points to be spr
+000060f0: 6561 642c 206d 7573 7420 6265 206f 6464  ead, must be odd
+00006100: 0a20 2020 2072 3a20 666c 6f61 740a 2020  .    r: float.  
+00006110: 2020 2020 2020 5261 6469 7573 206f 6620        Radius of 
+00006120: 7370 6865 7265 0a0a 2020 2020 5265 7475  sphere..    Retu
+00006130: 726e 730a 2020 2020 2d2d 2d2d 2d2d 2d0a  rns.    -------.
+00006140: 2020 2020 706f 696e 7473 3a20 6e64 6172      points: ndar
+00006150: 7261 7920 6f66 2066 6c6f 6174 205b 4e20  ray of float [N 
+00006160: 7820 335d 0a20 2020 2020 2020 2045 7665  x 3].        Eve
+00006170: 6e6c 7920 7370 7265 6164 2070 6f69 6e74  nly spread point
+00006180: 7320 696e 2061 2075 6e69 7420 7370 6865  s in a unit sphe
+00006190: 7265 0a20 2020 2022 2222 0a0a 2020 2020  re.    """..    
+000061a0: 6173 7365 7274 206e 5f70 6f69 6e74 7320  assert n_points 
+000061b0: 2520 3220 3d3d 2031 2c20 2254 6865 206e  % 2 == 1, "The n
+000061c0: 756d 6265 7220 6f66 2070 6f69 6e74 7320  umber of points 
+000061d0: 6d75 7374 2062 6520 6f64 6422 0a20 2020  must be odd".   
+000061e0: 2070 6f69 6e74 7320 3d20 5b5d 0a0a 2020   points = []..  
+000061f0: 2020 2320 5468 6520 676f 6c64 656e 2072    # The golden r
+00006200: 6174 696f 0a20 2020 2070 6869 203d 2028  atio.    phi = (
+00006210: 3120 2b20 6d61 7468 2e73 7172 7428 3529  1 + math.sqrt(5)
+00006220: 2920 2f20 322e 0a20 2020 206e 203d 2069  ) / 2..    n = i
+00006230: 6e74 2828 6e5f 706f 696e 7473 202d 2031  nt((n_points - 1
+00006240: 2920 2f20 3229 0a0a 2020 2020 666f 7220  ) / 2)..    for 
+00006250: 6920 696e 2072 616e 6765 282d 6e2c 206e  i in range(-n, n
+00006260: 202b 2031 293a 0a20 2020 2020 2020 206c   + 1):.        l
+00006270: 6174 203d 206d 6174 682e 6173 696e 2832  at = math.asin(2
+00006280: 202a 2069 202f 206e 5f70 6f69 6e74 7329   * i / n_points)
+00006290: 0a20 2020 2020 2020 206c 6f6e 203d 2032  .        lon = 2
+000062a0: 202a 206d 6174 682e 7069 202a 2069 202f   * math.pi * i /
+000062b0: 2070 6869 0a20 2020 2020 2020 2078 203d   phi.        x =
+000062c0: 2072 202a 206d 6174 682e 636f 7328 6c61   r * math.cos(la
+000062d0: 7429 202a 206d 6174 682e 636f 7328 6c6f  t) * math.cos(lo
+000062e0: 6e29 0a20 2020 2020 2020 2079 203d 2072  n).        y = r
+000062f0: 202a 206d 6174 682e 636f 7328 6c61 7429   * math.cos(lat)
+00006300: 202a 206d 6174 682e 7369 6e28 6c6f 6e29   * math.sin(lon)
+00006310: 0a20 2020 2020 2020 207a 203d 2072 202a  .        z = r *
+00006320: 206d 6174 682e 7369 6e28 6c61 7429 0a20   math.sin(lat). 
+00006330: 2020 2020 2020 2070 6f69 6e74 732e 6170         points.ap
+00006340: 7065 6e64 2828 782c 2079 2c20 7a29 290a  pend((x, y, z)).
+00006350: 0a20 2020 2070 6f69 6e74 7320 3d20 6e70  .    points = np
+00006360: 2e61 7272 6179 2870 6f69 6e74 732c 2064  .array(points, d
+00006370: 7479 7065 3d66 6c6f 6174 290a 0a20 2020  type=float)..   
+00006380: 2072 6574 7572 6e20 706f 696e 7473 0a0a   return points..
+00006390: 0a64 6566 206d 6174 3274 656e 286d 6174  .def mat2ten(mat
+000063a0: 2c20 696e 6372 293a 0a20 2020 2022 2222  , incr):.    """
+000063b0: 0a20 2020 2054 7261 6e73 666f 726d 7320  .    Transforms 
+000063c0: 6750 4320 6772 6164 6965 6e74 206d 6174  gPC gradient mat
+000063d0: 7269 7820 6f72 2067 7261 6469 656e 7420  rix or gradient 
+000063e0: 6772 6964 2070 6f69 6e74 7320 6672 6f6d  grid points from
+000063f0: 206d 6174 7269 7820 746f 2074 656e 736f   matrix to tenso
+00006400: 7220 666f 726d 0a0a 2020 2020 5061 7261  r form..    Para
+00006410: 6d65 7465 7273 0a20 2020 202d 2d2d 2d2d  meters.    -----
+00006420: 2d2d 2d2d 2d0a 2020 2020 6d61 7420 3a20  -----.    mat : 
+00006430: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
+00006440: 205b 6e5f 6772 6964 2a69 6e63 722c 206d   [n_grid*incr, m
+00006450: 5d0a 2020 2020 2020 2020 4d61 7472 6978  ].        Matrix
+00006460: 2074 6f20 7472 616e 7366 6f72 6d0a 2020   to transform.  
+00006470: 2020 696e 6372 203a 2069 6e74 0a20 2020    incr : int.   
+00006480: 2020 2020 2049 6e63 7265 6d65 6e74 2061       Increment a
+00006490: 6674 6572 2065 7665 7279 2072 6f77 2c20  fter every row, 
+000064a0: 6120 6e65 7720 7465 6e73 6f72 2073 6c69  a new tensor sli
+000064b0: 6365 2069 7320 6372 6561 7465 640a 0a20  ce is created.. 
+000064c0: 2020 2052 6574 7572 6e73 0a20 2020 202d     Returns.    -
+000064d0: 2d2d 2d2d 2d2d 0a20 2020 2074 656e 203a  ------.    ten :
+000064e0: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
+000064f0: 7420 5b6e 5f67 7269 642c 206d 2c20 696e  t [n_grid, m, in
+00006500: 6372 5d0a 2020 2020 2020 2020 5465 6e73  cr].        Tens
+00006510: 6f72 0a0a 2020 2020 4e6f 7465 730a 2020  or..    Notes.  
+00006520: 2020 2d2d 2d2d 2d0a 2020 2020 4275 696c    -----.    Buil
+00006530: 6473 2063 6875 6e6b 7320 6166 7465 7220  ds chunks after 
+00006540: 6576 6572 7920 2269 6e63 7222 2072 6f77  every "incr" row
+00006550: 2061 6e64 2077 7269 7465 7320 6974 2069   and writes it i
+00006560: 6e20 6120 6e65 7720 736c 6963 6520 5b69  n a new slice [i
+00006570: 2c20 3a2c 203a 5d0a 2020 2020 2222 220a  , :, :].    """.
+00006580: 0a20 2020 2074 656e 203d 206e 702e 7a65  .    ten = np.ze
+00006590: 726f 7328 2869 6e74 286d 6174 2e73 6861  ros((int(mat.sha
+000065a0: 7065 5b30 5d2f 696e 6372 292c 206d 6174  pe[0]/incr), mat
+000065b0: 2e73 6861 7065 5b31 5d2c 2069 6e63 7229  .shape[1], incr)
+000065c0: 290a 2020 2020 6964 7820 3d20 6e70 2e61  ).    idx = np.a
+000065d0: 7261 6e67 6528 302c 206d 6174 2e73 6861  range(0, mat.sha
+000065e0: 7065 5b30 5d2c 2069 6e63 7229 0a0a 2020  pe[0], incr)..  
+000065f0: 2020 666f 7220 6920 696e 2072 616e 6765    for i in range
+00006600: 2869 6e63 7229 3a0a 2020 2020 2020 2020  (incr):.        
+00006610: 7465 6e5b 3a2c 203a 2c20 695d 203d 206d  ten[:, :, i] = m
+00006620: 6174 5b69 6478 202b 2069 2c20 3a5d 0a0a  at[idx + i, :]..
+00006630: 2020 2020 7265 7475 726e 2074 656e 0a0a      return ten..
+00006640: 0a64 6566 2074 656e 326d 6174 2874 656e  .def ten2mat(ten
+00006650: 293a 0a20 2020 2022 2222 0a20 2020 2054  ):.    """.    T
+00006660: 7261 6e73 666f 726d 7320 6750 4320 6772  ransforms gPC gr
+00006670: 6164 6965 6e74 2074 656e 736f 7220 6f72  adient tensor or
+00006680: 2067 7261 6469 656e 7420 6772 6964 2070   gradient grid p
+00006690: 6f69 6e74 7320 6672 6f6d 2074 656e 736f  oints from tenso
+000066a0: 7220 746f 206d 6174 7269 7820 666f 726d  r to matrix form
+000066b0: 0a0a 2020 2020 5061 7261 6d65 7465 7273  ..    Parameters
+000066c0: 0a20 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0a  .    ----------.
+000066d0: 2020 2020 7465 6e20 3a20 6e64 6172 7261      ten : ndarra
+000066e0: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
+000066f0: 6964 2c20 6d2c 2069 6e63 725d 0a20 2020  id, m, incr].   
+00006700: 2020 2020 2054 656e 736f 7220 746f 2074       Tensor to t
+00006710: 7261 6e73 666f 726d 0a0a 2020 2020 5265  ransform..    Re
+00006720: 7475 726e 730a 2020 2020 2d2d 2d2d 2d2d  turns.    ------
+00006730: 2d0a 2020 2020 6d61 7420 3a20 6e64 6172  -.    mat : ndar
+00006740: 7261 7920 6f66 2066 6c6f 6174 205b 6e5f  ray of float [n_
+00006750: 6772 6964 2a69 6e63 722c 206d 5d0a 2020  grid*incr, m].  
+00006760: 2020 2020 2020 4d61 7472 6978 0a0a 2020        Matrix..  
+00006770: 2020 4e6f 7465 730a 2020 2020 2d2d 2d2d    Notes.    ----
+00006780: 2d0a 2020 2020 5374 6163 6b73 2073 6c69  -.    Stacks sli
+00006790: 6365 7320 5b69 2c20 3a2c 203a 5d20 7665  ces [i, :, :] ve
+000067a0: 7274 6963 616c 6c79 0a20 2020 2022 2222  rtically.    """
+000067b0: 0a20 2020 206d 6174 203d 206e 702e 7673  .    mat = np.vs
+000067c0: 7461 636b 285b 7465 6e5b 692c 203a 2c20  tack([ten[i, :, 
+000067d0: 3a5d 2e74 7261 6e73 706f 7365 2829 2066  :].transpose() f
+000067e0: 6f72 2069 2069 6e20 7261 6e67 6528 7465  or i in range(te
+000067f0: 6e2e 7368 6170 655b 305d 295d 290a 0a20  n.shape[0])]).. 
+00006800: 2020 2072 6574 7572 6e20 6d61 740a 0a0a     return mat...
+00006810: 6465 6620 6c69 7374 3264 6963 7428 6c29  def list2dict(l)
+00006820: 3a0a 2020 2020 2222 220a 2020 2020 5472  :.    """.    Tr
+00006830: 616e 7366 6f72 6d20 6c69 7374 206f 6620  ansform list of 
+00006840: 6469 6374 7320 7769 7468 2073 616d 6520  dicts with same 
+00006850: 6b65 7973 2074 6f20 6469 6374 206f 6620  keys to dict of 
+00006860: 6c69 7374 0a0a 2020 2020 5061 7261 6d65  list..    Parame
+00006870: 7465 7273 0a20 2020 202d 2d2d 2d2d 2d2d  ters.    -------
+00006880: 2d2d 2d0a 2020 2020 6c20 3a20 6c69 7374  ---.    l : list
+00006890: 206f 6620 6469 6374 0a20 2020 2020 2020   of dict.       
+000068a0: 204c 6973 7420 636f 6e74 6169 6e69 6e67   List containing
+000068b0: 2064 6963 7469 6f6e 6172 6965 7320 7769   dictionaries wi
+000068c0: 7468 2073 616d 6520 6b65 7973 0a0a 2020  th same keys..  
+000068d0: 2020 5265 7475 726e 730a 2020 2020 2d2d    Returns.    --
+000068e0: 2d2d 2d2d 2d0a 2020 2020 6420 3a20 6469  -----.    d : di
+000068f0: 6374 206f 6620 6c69 7374 730a 2020 2020  ct of lists.    
+00006900: 2020 2020 4469 6374 696f 6e61 7279 2063      Dictionary c
+00006910: 6f6e 7461 696e 696e 6720 7468 6520 656e  ontaining the en
+00006920: 7472 6965 7320 696e 2061 206c 6973 740a  tries in a list.
+00006930: 2020 2020 2222 220a 0a20 2020 206e 203d      """..    n =
+00006940: 206c 656e 286c 290a 2020 2020 6b65 7973   len(l).    keys
+00006950: 203d 206c 5b30 5d2e 6b65 7973 2829 0a20   = l[0].keys(). 
+00006960: 2020 2064 203d 2064 6963 7428 290a 0a20     d = dict().. 
+00006970: 2020 2066 6f72 206b 6579 2069 6e20 6b65     for key in ke
+00006980: 7973 3a0a 2020 2020 2020 2020 645b 6b65  ys:.        d[ke
+00006990: 795d 203d 205b 3020 666f 7220 5f20 696e  y] = [0 for _ in
+000069a0: 2072 616e 6765 286e 295d 0a20 2020 2020   range(n)].     
+000069b0: 2020 2066 6f72 2069 2069 6e20 7261 6e67     for i in rang
+000069c0: 6528 6e29 3a0a 2020 2020 2020 2020 2020  e(n):.          
+000069d0: 2020 645b 6b65 795d 5b69 5d20 3d20 6c5b    d[key][i] = l[
+000069e0: 695d 5b6b 6579 5d0a 0a20 2020 2072 6574  i][key]..    ret
+000069f0: 7572 6e20 640a 0a0a 6465 6620 6765 745f  urn d...def get_
+00006a00: 6772 6164 6965 6e74 5f69 6478 5f64 6f6d  gradient_idx_dom
+00006a10: 6169 6e28 646f 6d61 696e 732c 2064 2c20  ain(domains, d, 
+00006a20: 6772 6164 6965 6e74 5f69 6478 293a 0a20  gradient_idx):. 
+00006a30: 2020 2022 2222 0a20 2020 2044 6574 6572     """.    Deter
+00006a40: 6d69 6e65 206c 6f63 616c 2067 7261 6469  mine local gradi
+00006a50: 656e 745f 6964 7820 696e 2064 6f6d 6169  ent_idx in domai
+00006a60: 6e20 2264 2220 6672 6f6d 2067 6c6f 6261  n "d" from globa
+00006a70: 6c20 6772 6164 6965 6e74 5f69 6478 0a0a  l gradient_idx..
+00006a80: 2020 2020 5061 7261 6d65 7465 7273 0a20      Parameters. 
+00006a90: 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020     ----------.  
+00006aa0: 2020 646f 6d61 696e 7320 3a20 6e64 6172    domains : ndar
+00006ab0: 7261 7920 6f66 2066 6c6f 6174 205b 6e5f  ray of float [n_
+00006ac0: 6772 6964 5f67 6c6f 6261 6c5d 0a20 2020  grid_global].   
+00006ad0: 2020 2020 2041 7272 6179 2063 6f6e 7461       Array conta
+00006ae0: 696e 696e 6720 7468 6520 646f 6d61 696e  ining the domain
+00006af0: 2049 4473 0a20 2020 2064 203a 2069 6e74   IDs.    d : int
+00006b00: 0a20 2020 2020 2020 2044 6f6d 6169 6e20  .        Domain 
+00006b10: 4944 2066 6f72 2077 6869 6368 2074 6865  ID for which the
+00006b20: 2067 7261 6469 656e 7420 696e 6465 7820   gradient index 
+00006b30: 6861 7320 746f 2062 6520 636f 6d70 7574  has to be comput
+00006b40: 6564 2066 6f72 0a20 2020 2067 7261 6469  ed for.    gradi
+00006b50: 656e 745f 6964 7820 3a20 6e64 6172 7261  ent_idx : ndarra
+00006b60: 7920 6f66 2069 6e74 205b 6e5f 6772 6964  y of int [n_grid
+00006b70: 5f67 6c6f 6261 6c5d 0a20 2020 2020 2020  _global].       
+00006b80: 2049 6e64 6963 6573 206f 6620 6772 6964   Indices of grid
+00006b90: 2070 6f69 6e74 7320 2867 6c6f 6261 6c29   points (global)
+00006ba0: 2077 6865 7265 2074 6865 2067 7261 6469   where the gradi
+00006bb0: 656e 7420 696e 2067 7261 6469 656e 745f  ent in gradient_
+00006bc0: 7265 7375 6c74 7320 6973 2070 726f 7669  results is provi
+00006bd0: 6465 640a 0a20 2020 2052 6574 7572 6e73  ded..    Returns
+00006be0: 0a20 2020 202d 2d2d 2d2d 2d2d 0a20 2020  .    -------.   
+00006bf0: 2067 7261 6469 656e 745f 6964 785f 6c6f   gradient_idx_lo
+00006c00: 6361 6c20 3a20 6e64 6172 7261 7920 6f66  cal : ndarray of
+00006c10: 2069 6e74 205b 6c65 6e28 646f 6d61 696e   int [len(domain
+00006c20: 735b 646f 6d61 696e 733d 3d64 5d29 5d0a  s[domains==d])].
+00006c30: 2020 2020 2020 2020 496e 6469 6365 7320          Indices 
+00006c40: 6f66 2067 7269 6420 706f 696e 7473 2028  of grid points (
+00006c50: 6c6f 6361 6c29 2077 6865 7265 2074 6865  local) where the
+00006c60: 2067 7261 6469 656e 7420 696e 2067 7261   gradient in gra
+00006c70: 6469 656e 745f 7265 7375 6c74 7320 6973  dient_results is
+00006c80: 2070 726f 7669 6465 640a 2020 2020 2222   provided.    ""
+00006c90: 220a 2020 2020 6172 7220 3d20 6e70 2e61  ".    arr = np.a
+00006ca0: 7261 6e67 6528 6c65 6e28 646f 6d61 696e  range(len(domain
+00006cb0: 7329 290a 2020 2020 6772 6164 6965 6e74  s)).    gradient
+00006cc0: 5f69 6478 5f6c 6f63 616c 203d 206e 702e  _idx_local = np.
+00006cd0: 6172 7261 7928 5b69 0a20 2020 2020 2020  array([i.       
+00006ce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006cf0: 2020 2020 2020 2020 2020 2020 666f 7220              for 
+00006d00: 692c 2063 2069 6e20 656e 756d 6572 6174  i, c in enumerat
+00006d10: 6528 6172 725b 646f 6d61 696e 7320 3d3d  e(arr[domains ==
+00006d20: 2064 5d29 2020 2320 6c6f 6361 6c0a 2020   d])  # local.  
+00006d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006d50: 2066 6f72 2063 7220 696e 2061 7272 5b67   for cr in arr[g
+00006d60: 7261 6469 656e 745f 6964 785d 2020 2020  radient_idx]    
+00006d70: 2020 2020 2020 2020 2020 2023 2067 6c6f             # glo
+00006d80: 6261 6c0a 2020 2020 2020 2020 2020 2020  bal.            
+00006d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006da0: 2020 2020 2020 2069 6620 2863 203d 3d20         if (c == 
+00006db0: 6372 292e 616c 6c28 295d 290a 0a20 2020  cr).all()])..   
+00006dc0: 2072 6574 7572 6e20 6772 6164 6965 6e74   return gradient
+00006dd0: 5f69 6478 5f6c 6f63 616c 0a0a 0a64 6566  _idx_local...def
+00006de0: 2064 6574 6572 6d69 6e65 5f70 726f 6a65   determine_proje
+00006df0: 6374 696f 6e5f 6d61 7472 6978 2867 7261  ction_matrix(gra
+00006e00: 6469 656e 745f 7265 7375 6c74 732c 206c  dient_results, l
+00006e10: 616d 6264 615f 6570 733d 302e 3935 293a  ambda_eps=0.95):
+00006e20: 0a20 2020 2022 2222 0a20 2020 2044 6574  .    """.    Det
+00006e30: 6572 6d69 6e65 7320 7072 6f6a 6563 7469  ermines projecti
+00006e40: 6f6e 206d 6174 7269 7820 5b50 5d2e 0a0a  on matrix [P]...
+00006e50: 2020 2020 2e2e 206d 6174 683a 3a20 5c5c      .. math:: \\
+00006e60: 6574 6120 3d20 5b5c 5c6d 6174 6862 667b  eta = [\\mathbf{
+00006e70: 507d 5d20 5c5c 7869 0a0a 2020 2020 5061  P}] \\xi..    Pa
+00006e80: 7261 6d65 7465 7273 0a20 2020 202d 2d2d  rameters.    ---
+00006e90: 2d2d 2d2d 2d2d 2d0a 2020 2020 6772 6164  -------.    grad
+00006ea0: 6965 6e74 5f72 6573 756c 7473 203a 206e  ient_results : n
+00006eb0: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+00006ec0: 5b6e 5f67 7269 6420 7820 6e5f 6f75 7420  [n_grid x n_out 
+00006ed0: 7820 6469 6d5d 0a20 2020 2020 2020 2047  x dim].        G
+00006ee0: 7261 6469 656e 7420 6f66 206d 6f64 656c  radient of model
+00006ef0: 2066 756e 6374 696f 6e20 696e 2067 7269   function in gri
+00006f00: 6420 706f 696e 7473 0a20 2020 206c 616d  d points.    lam
+00006f10: 6264 615f 6570 7320 3a20 666c 6f61 742c  bda_eps : float,
+00006f20: 206f 7074 696f 6e61 6c2c 2064 6566 6175   optional, defau
+00006f30: 6c74 3a20 302e 3935 0a20 2020 2020 2020  lt: 0.95.       
+00006f40: 2042 6f75 6e64 206f 6620 7072 696e 6369   Bound of princi
+00006f50: 7061 6c20 636f 6d70 6f6e 656e 7473 2069  pal components i
+00006f60: 6e20 252e 2041 6c6c 2065 6967 656e 7665  n %. All eigenve
+00006f70: 6374 6f72 7320 6172 6520 696e 636c 7564  ctors are includ
+00006f80: 6564 2075 6e74 696c 206c 616d 6264 615f  ed until lambda_
+00006f90: 6570 7320 6f66 2074 6f74 616c 2073 756d  eps of total sum
+00006fa0: 206f 6620 616c 6c0a 2020 2020 2020 2020   of all.        
+00006fb0: 6569 6765 6e76 616c 7565 7320 6973 2069  eigenvalues is i
+00006fc0: 6e63 6c75 6465 6420 696e 2074 6865 2073  ncluded in the s
+00006fd0: 7973 7465 6d2e 0a0a 2020 2020 5265 7475  ystem...    Retu
+00006fe0: 726e 730a 2020 2020 2d2d 2d2d 2d2d 2d0a  rns.    -------.
+00006ff0: 2020 2020 705f 6d61 7472 6978 203a 206e      p_matrix : n
+00007000: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+00007010: 5b64 696d 5f72 6564 7563 6564 2078 2064  [dim_reduced x d
+00007020: 696d 5d0a 2020 2020 2020 2020 5265 6475  im].        Redu
+00007030: 6365 6420 7072 6f6a 6563 7469 6f6e 206d  ced projection m
+00007040: 6174 7269 7820 666f 7220 514f 492e 0a20  atrix for QOI.. 
+00007050: 2020 2070 5f6d 6174 7269 785f 636f 6d70     p_matrix_comp
+00007060: 6c65 7465 203a 206e 6461 7272 6179 206f  lete : ndarray o
+00007070: 6620 666c 6f61 7420 5b64 696d 5f72 6564  f float [dim_red
+00007080: 7563 6564 2078 2064 696d 5d0a 2020 2020  uced x dim].    
+00007090: 2020 2020 436f 6d70 6c65 7465 2070 726f      Complete pro
+000070a0: 6a65 6374 696f 6e20 6d61 7472 6978 2066  jection matrix f
+000070b0: 6f72 2051 4f49 2e0a 2020 2020 2222 220a  or QOI..    """.
+000070c0: 0a20 2020 2023 2044 6574 6572 6d69 6e65  .    # Determine
+000070d0: 2070 726f 6a65 6374 696f 6e20 6d61 7472   projection matr
+000070e0: 6963 6573 2062 7920 5356 4420 6f66 2067  ices by SVD of g
+000070f0: 7261 6469 656e 7473 0a20 2020 2075 2c20  radients.    u, 
+00007100: 732c 2076 203d 206e 702e 6c69 6e61 6c67  s, v = np.linalg
+00007110: 2e73 7664 2867 7261 6469 656e 745f 7265  .svd(gradient_re
+00007120: 7375 6c74 7329 0a0a 2020 2020 2320 6465  sults)..    # de
+00007130: 7465 726d 696e 6520 646f 6d69 6e61 6e74  termine dominant
+00007140: 2065 6967 656e 7661 6c75 6573 2075 7020   eigenvalues up 
+00007150: 746f 206c 616d 6264 615f 6570 7320 2a20  to lambda_eps * 
+00007160: 735f 7375 6d0a 2020 2020 735f 6d61 736b  s_sum.    s_mask
+00007170: 203d 205b 4661 6c73 655d 2a6c 656e 2873   = [False]*len(s
+00007180: 290a 2020 2020 735f 7375 6d5f 7061 7274  ).    s_sum_part
+00007190: 203d 2030 0a20 2020 2073 5f73 756d 203d   = 0.    s_sum =
+000071a0: 206e 702e 7375 6d28 7329 0a20 2020 2069   np.sum(s).    i
+000071b0: 5f73 203d 2030 0a0a 2020 2020 7768 696c  _s = 0..    whil
+000071c0: 6520 735f 7375 6d5f 7061 7274 203c 3d20  e s_sum_part <= 
+000071d0: 6c61 6d62 6461 5f65 7073 2a73 5f73 756d  lambda_eps*s_sum
+000071e0: 3a0a 2020 2020 2020 2020 735f 7375 6d5f  :.        s_sum_
+000071f0: 7061 7274 202b 3d20 735b 695f 735d 0a20  part += s[i_s]. 
+00007200: 2020 2020 2020 2073 5f6d 6173 6b5b 695f         s_mask[i_
+00007210: 735d 203d 2054 7275 650a 2020 2020 2020  s] = True.      
+00007220: 2020 695f 7320 2b3d 2031 0a0a 2020 2020    i_s += 1..    
+00007230: 735f 6669 6c74 203d 2073 5b73 5f6d 6173  s_filt = s[s_mas
+00007240: 6b5d 0a20 2020 2076 5f66 696c 7420 3d20  k].    v_filt = 
+00007250: 765b 6e70 2e61 7070 656e 6428 735f 6d61  v[np.append(s_ma
+00007260: 736b 2c20 5b46 616c 7365 5d2a 2876 2e73  sk, [False]*(v.s
+00007270: 6861 7065 5b30 5d2d 752e 7368 6170 655b  hape[0]-u.shape[
+00007280: 315d 2929 203e 2030 2c20 3a5d 0a20 2020  1])) > 0, :].   
+00007290: 2070 5f6d 6174 7269 7820 3d20 765f 6669   p_matrix = v_fi
+000072a0: 6c74 0a20 2020 2070 5f6d 6174 7269 785f  lt.    p_matrix_
+000072b0: 636f 6d70 6c65 7465 203d 2076 0a0a 2020  complete = v..  
+000072c0: 2020 7265 7475 726e 2070 5f6d 6174 7269    return p_matri
+000072d0: 782c 2070 5f6d 6174 7269 785f 636f 6d70  x, p_matrix_comp
+000072e0: 6c65 7465 0a0a 0a64 6566 2067 6574 5f69  lete...def get_i
+000072f0: 6e64 6963 6573 5f6f 665f 6b5f 736d 616c  ndices_of_k_smal
+00007300: 6c65 7374 2861 7272 2c20 6b29 3a0a 2020  lest(arr, k):.  
+00007310: 2020 2222 220a 2020 2020 4669 6e64 2069    """.    Find i
+00007320: 6e64 6963 6573 206f 6620 6b20 736d 616c  ndices of k smal
+00007330: 6c65 7374 2065 6c65 6d65 6e74 7320 696e  lest elements in
+00007340: 206e 6461 7272 6179 0a0a 2020 2020 5061   ndarray..    Pa
+00007350: 7261 6d65 7465 7273 0a20 2020 202d 2d2d  rameters.    ---
+00007360: 2d2d 2d2d 2d2d 2d0a 2020 2020 6172 7220  -------.    arr 
+00007370: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
+00007380: 6174 0a20 2020 2020 2020 2041 7272 6179  at.        Array
+00007390: 0a20 2020 206b 203a 2069 6e74 0a20 2020  .    k : int.   
+000073a0: 2020 2020 204e 756d 6265 7220 6f66 2073       Number of s
+000073b0: 6d61 6c6c 6573 7420 7661 6c75 6573 2074  mallest values t
+000073c0: 6f20 6578 7472 6163 740a 0a20 2020 2052  o extract..    R
+000073d0: 6574 7572 6e73 0a20 2020 202d 2d2d 2d2d  eturns.    -----
+000073e0: 2d2d 0a20 2020 2069 6478 203a 2074 7570  --.    idx : tup
+000073f0: 6c65 206f 6620 6e64 6172 7261 7920 5b6b  le of ndarray [k
+00007400: 5d0a 2020 2020 2020 2020 496e 6469 6365  ].        Indice
+00007410: 7320 6f66 206b 2073 6d61 6c6c 6573 7420  s of k smallest 
+00007420: 656c 656d 656e 7473 2069 6e20 6172 7261  elements in arra
+00007430: 790a 2020 2020 2222 220a 2020 2020 2320  y.    """.    # 
+00007440: 696e 6465 7820 3d20 6e70 2e61 7267 7061  index = np.argpa
+00007450: 7274 6974 696f 6e28 6172 722e 7261 7665  rtition(arr.rave
+00007460: 6c28 292c 206b 290a 2020 2020 2320 6964  l(), k).    # id
+00007470: 7820 3d20 7475 706c 6528 6e70 2e61 7272  x = tuple(np.arr
+00007480: 6179 286e 702e 756e 7261 7665 6c5f 696e  ay(np.unravel_in
+00007490: 6465 7828 696e 6465 782c 2061 7272 2e73  dex(index, arr.s
+000074a0: 6861 7065 2929 5b3a 2c20 7261 6e67 6528  hape))[:, range(
+000074b0: 6d69 6e28 6b2c 2030 292c 206d 6178 286b  min(k, 0), max(k
+000074c0: 2c20 3029 295d 290a 2020 2020 230a 2020  , 0))]).    #.  
+000074d0: 2020 2320 7265 7475 726e 2069 6478 0a0a    # return idx..
+000074e0: 2020 2020 6964 7820 3d20 6e70 2e61 7267      idx = np.arg
+000074f0: 7061 7274 6974 696f 6e28 6172 722e 7261  partition(arr.ra
+00007500: 7665 6c28 292c 2061 7272 2e73 697a 6520  vel(), arr.size 
+00007510: 2d20 6b29 5b3a 6b5d 0a0a 2020 2020 7265  - k)[:k]..    re
+00007520: 7475 726e 2074 7570 6c65 286e 702e 756e  turn tuple(np.un
+00007530: 7261 7665 6c5f 696e 6465 7828 6964 782c  ravel_index(idx,
+00007540: 2061 7272 2e73 6861 7065 2929 0a0a 0a64   arr.shape))...d
+00007550: 6566 2067 6574 5f63 6f6f 7264 735f 6469  ef get_coords_di
+00007560: 7363 6f6e 7469 6e75 6974 7928 636c 6173  scontinuity(clas
+00007570: 7369 6669 6572 2c20 785f 6d69 6e2c 2078  sifier, x_min, x
+00007580: 5f6d 6178 2c20 6e5f 636f 6f72 6473 5f64  _max, n_coords_d
+00007590: 6973 633d 3130 2c20 626f 7264 6572 5f73  isc=10, border_s
+000075a0: 616d 706c 696e 673d 2273 7472 7563 7475  ampling="structu
+000075b0: 7265 6422 293a 0a20 2020 2022 2222 0a20  red"):.    """. 
+000075c0: 2020 2044 6574 6572 6d69 6e65 206e 5f63     Determine n_c
+000075d0: 6f6f 7264 735f 6469 7363 2067 7269 6420  oords_disc grid 
+000075e0: 706f 696e 7473 2063 6c6f 7365 2074 6f20  points close to 
+000075f0: 6469 7363 6f6e 7469 6e75 6974 790a 0a20  discontinuity.. 
+00007600: 2020 2050 6172 616d 6574 6572 730a 2020     Parameters.  
+00007610: 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0a20 2020    ----------.   
+00007620: 2063 6c61 7373 6966 6965 7220 3a20 436c   classifier : Cl
+00007630: 6173 7369 6669 6572 206f 626a 6563 740a  assifier object.
+00007640: 2020 2020 2020 2020 436c 6173 7369 6669          Classifi
+00007650: 6572 206f 626a 6563 7420 746f 2070 7265  er object to pre
+00007660: 6469 6374 2063 6c61 7373 6573 2066 726f  dict classes fro
+00007670: 6d20 636f 6f72 6469 6e61 7465 7320 286e  m coordinates (n
+00007680: 6565 6473 2074 6f20 636f 6e74 6169 6e20  eeds to contain 
+00007690: 6120 636c 6173 7369 6669 6572 2e70 7265  a classifier.pre
+000076a0: 6469 6374 2829 206d 6574 686f 6429 0a20  dict() method). 
+000076b0: 2020 2078 5f6d 696e 203a 206e 6461 7272     x_min : ndarr
+000076c0: 6179 206f 6620 666c 6f61 7420 5b6e 5f64  ay of float [n_d
+000076d0: 696d 5d0a 2020 2020 2020 2020 4d69 6e69  im].        Mini
+000076e0: 6d61 6c20 7661 6c75 6573 2069 6e20 7061  mal values in pa
+000076f0: 7261 6d65 7465 7220 7370 6163 6520 746f  rameter space to
+00007700: 2073 6561 7263 6820 6469 7363 6f6e 7469   search disconti
+00007710: 6e75 6974 790a 2020 2020 785f 6d61 7820  nuity.    x_max 
+00007720: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
+00007730: 6174 205b 6e5f 6469 6d5d 0a20 2020 2020  at [n_dim].     
+00007740: 2020 204d 6178 696d 616c 2076 616c 7565     Maximal value
+00007750: 7320 696e 2070 6172 616d 6574 6572 2073  s in parameter s
+00007760: 7061 6365 2074 6f20 7365 6172 6368 2064  pace to search d
+00007770: 6973 636f 6e74 696e 7569 7479 0a20 2020  iscontinuity.   
+00007780: 206e 5f63 6f6f 7264 735f 6469 7363 203a   n_coords_disc :
+00007790: 2069 6e74 2c20 6f70 7469 6f6e 616c 2c20   int, optional, 
+000077a0: 6465 6661 756c 743a 2031 300a 2020 2020  default: 10.    
+000077b0: 2020 2020 4e75 6d62 6572 206f 6620 6772      Number of gr
+000077c0: 6964 2070 6f69 6e74 7320 746f 2064 6574  id points to det
+000077d0: 6572 6d69 6e65 2063 6c6f 7365 2074 6f20  ermine close to 
+000077e0: 6469 7363 6f6e 7469 6e75 6974 790a 2020  discontinuity.  
+000077f0: 2020 626f 7264 6572 5f73 616d 706c 696e    border_samplin
+00007800: 6720 3a20 7374 722c 206f 7074 696f 6e61  g : str, optiona
+00007810: 6c2c 2064 6566 6175 6c74 3a20 2273 7472  l, default: "str
+00007820: 7563 7475 7265 6422 0a20 2020 2020 2020  uctured".       
+00007830: 2053 616d 706c 696e 6720 6d65 7468 6f64   Sampling method
+00007840: 2074 6f20 6465 7465 726d 696e 6520 6c6f   to determine lo
+00007850: 6361 7469 6f6e 206f 6620 6469 7363 6f6e  cation of discon
+00007860: 7469 6e75 6974 790a 0a0a 2020 2020 5265  tinuity...    Re
+00007870: 7475 726e 730a 2020 2020 2d2d 2d2d 2d2d  turns.    ------
+00007880: 2d0a 2020 2020 636f 6f72 6473 5f64 6973  -.    coords_dis
+00007890: 6320 3a20 6e64 6172 7261 7920 6f66 2066  c : ndarray of f
+000078a0: 6c6f 6174 205b 6e5f 636f 6f72 6473 5f64  loat [n_coords_d
+000078b0: 6973 635d 0a20 2020 2022 2222 0a0a 2020  isc].    """..  
+000078c0: 2020 2320 6966 2062 6f72 6465 725f 7361    # if border_sa
+000078d0: 6d70 6c69 6e67 203d 3d20 2272 616e 646f  mpling == "rando
+000078e0: 6d22 3a0a 2020 2020 2320 2020 2020 636f  m":.    #     co
+000078f0: 6f72 6473 5f62 6f72 6465 725f 6465 7420  ords_border_det 
+00007900: 3d20 6772 6964 5f6c 6561 726e 5f63 6c75  = grid_learn_clu
+00007910: 7374 6572 2e63 6f6f 7264 730a 2020 2020  ster.coords.    
+00007920: 2320 2020 2020 646f 6d61 696e 7320 3d20  #     domains = 
+00007930: 6d6f 6465 6c5f 6b6d 6561 6e73 2e6c 6162  model_kmeans.lab
+00007940: 656c 735f 0a20 2020 2064 696d 203d 206c  els_.    dim = l
+00007950: 656e 2878 5f6d 696e 290a 0a20 2020 2023  en(x_min)..    #
+00007960: 2063 7265 6174 6520 7465 6e73 6f72 6564   create tensored
+00007970: 206d 6573 6820 746f 2066 696e 6420 6469   mesh to find di
+00007980: 7363 6f6e 7469 6e75 6974 790a 2020 2020  scontinuity.    
+00007990: 6966 2062 6f72 6465 725f 7361 6d70 6c69  if border_sampli
+000079a0: 6e67 203d 3d20 2273 7472 7563 7475 7265  ng == "structure
+000079b0: 6422 3a0a 2020 2020 2020 2020 6e5f 7361  d":.        n_sa
+000079c0: 6d70 6c65 7320 3d20 696e 7428 3145 342a  mples = int(1E4*
+000079d0: 2a28 312e 2f64 696d 2929 0a20 2020 2020  *(1./dim)).     
+000079e0: 2020 2065 7661 6c5f 7374 7220 3d20 226e     eval_str = "n
+000079f0: 702e 6172 7261 7928 6e70 2e6d 6573 6867  p.array(np.meshg
+00007a00: 7269 6428 220a 0a20 2020 2020 2020 2066  rid("..        f
+00007a10: 6f72 2069 2069 6e20 7261 6e67 6528 6469  or i in range(di
+00007a20: 6d29 3a0a 2020 2020 2020 2020 2020 2020  m):.            
+00007a30: 6576 616c 5f73 7472 202b 3d20 226e 702e  eval_str += "np.
+00007a40: 6c69 6e73 7061 6365 2878 5f6d 696e 5b7b  linspace(x_min[{
+00007a50: 7d5d 2c20 785f 6d61 785b 7b7d 5d2c 207b  }], x_max[{}], {
+00007a60: 7d29 222e 666f 726d 6174 2869 2c20 692c  })".format(i, i,
+00007a70: 206e 5f73 616d 706c 6573 290a 0a20 2020   n_samples)..   
+00007a80: 2020 2020 2020 2020 2069 6620 6920 3c20           if i < 
+00007a90: 6469 6d2d 313a 0a20 2020 2020 2020 2020  dim-1:.         
+00007aa0: 2020 2020 2020 2065 7661 6c5f 7374 7220         eval_str 
+00007ab0: 2b3d 2022 2c20 220a 0a20 2020 2020 2020  += ", "..       
+00007ac0: 2065 7661 6c5f 7374 7220 2b3d 2022 2929   eval_str += "))
+00007ad0: 2e54 2e72 6573 6861 7065 282d 312c 207b  .T.reshape(-1, {
+00007ae0: 7d29 222e 666f 726d 6174 2864 696d 290a  })".format(dim).
+00007af0: 0a20 2020 2020 2020 2063 6f6f 7264 735f  .        coords_
+00007b00: 626f 7264 6572 5f64 6574 203d 2065 7661  border_det = eva
+00007b10: 6c28 6576 616c 5f73 7472 290a 0a20 2020  l(eval_str)..   
+00007b20: 2020 2020 2064 6f6d 6169 6e73 203d 2063       domains = c
+00007b30: 6c61 7373 6966 6965 722e 7072 6564 6963  lassifier.predic
+00007b40: 7428 636f 6f72 6473 5f62 6f72 6465 725f  t(coords_border_
+00007b50: 6465 7429 0a20 2020 2065 6c73 653a 0a20  det).    else:. 
+00007b60: 2020 2020 2020 2072 6169 7365 204e 6f74         raise Not
+00007b70: 496d 706c 656d 656e 7465 6445 7272 6f72  ImplementedError
+00007b80: 2822 506c 6561 7365 2075 7365 2076 616c  ("Please use val
+00007b90: 6964 2062 6f72 6465 7220 7361 6d70 6c69  id border sampli
+00007ba0: 6e67 206d 6574 686f 6420 2822 2273 7472  ng method (""str
+00007bb0: 7563 7475 7265 6422 2229 2229 0a0a 2020  uctured"")")..  
+00007bc0: 2020 2320 6465 7465 726d 696e 6520 6d61    # determine ma
+00007bd0: 736b 206f 6620 6e6f 7420 6571 7561 6c69  sk of not equali
+00007be0: 6e67 2064 6f6d 6169 6e20 706f 696e 7473  ng domain points
+00007bf0: 0a20 2020 2023 2064 6f6d 5f6d 6174 203d  .    # dom_mat =
+00007c00: 206e 702e 7469 6c65 2864 6f6d 6169 6e73   np.tile(domains
+00007c10: 5b3a 2c20 6e70 2e6e 6577 6178 6973 5d2c  [:, np.newaxis],
+00007c20: 2028 312c 2064 6f6d 6169 6e73 2e73 6861   (1, domains.sha
+00007c30: 7065 5b30 5d29 290a 2020 2020 646f 6d5f  pe[0])).    dom_
+00007c40: 6d61 7420 3d20 6e70 2e62 726f 6164 6361  mat = np.broadca
+00007c50: 7374 5f74 6f28 646f 6d61 696e 732c 2028  st_to(domains, (
+00007c60: 6c65 6e28 646f 6d61 696e 7329 2c20 6c65  len(domains), le
+00007c70: 6e28 646f 6d61 696e 7329 2929 2e54 0a20  n(domains))).T. 
+00007c80: 2020 206d 6173 6b20 3d20 646f 6d5f 6d61     mask = dom_ma
+00007c90: 7420 213d 2064 6f6d 5f6d 6174 2e74 7261  t != dom_mat.tra
+00007ca0: 6e73 706f 7365 2829 0a20 2020 206d 6173  nspose().    mas
+00007cb0: 6b20 3d20 6e70 2e74 7269 6c28 6d61 736b  k = np.tril(mask
+00007cc0: 2920 2a20 4661 6c73 6520 2b20 6e70 2e74  ) * False + np.t
+00007cd0: 7269 7528 6d61 736b 290a 0a20 2020 2023  riu(mask)..    #
+00007ce0: 2064 6574 6572 6d69 6e65 2064 6973 7461   determine dista
+00007cf0: 6e63 6573 2062 6574 7765 656e 2067 7269  nces between gri
+00007d00: 6420 706f 696e 7473 2069 6e20 6469 6666  d points in diff
+00007d10: 6572 656e 7420 646f 6d61 696e 730a 2020  erent domains.  
+00007d20: 2020 6469 7374 616e 6365 5f6d 6174 7269    distance_matri
+00007d30: 7820 3d20 6e70 2e6f 6e65 7328 6d61 736b  x = np.ones(mask
+00007d40: 2e73 6861 7065 2920 2a20 6e70 2e6e 616e  .shape) * np.nan
+00007d50: 0a20 2020 2066 6f72 2069 5f63 2c20 6320  .    for i_c, c 
+00007d60: 696e 2065 6e75 6d65 7261 7465 2863 6f6f  in enumerate(coo
+00007d70: 7264 735f 626f 7264 6572 5f64 6574 293a  rds_border_det):
+00007d80: 0a20 2020 2020 2020 2064 6973 7461 6e63  .        distanc
+00007d90: 655f 6d61 7472 6978 5b69 5f63 2c20 6d61  e_matrix[i_c, ma
+00007da0: 736b 5b69 5f63 2c20 3a5d 5d20 3d20 6e70  sk[i_c, :]] = np
+00007db0: 2e6c 696e 616c 672e 6e6f 726d 2863 6f6f  .linalg.norm(coo
+00007dc0: 7264 735f 626f 7264 6572 5f64 6574 5b6d  rds_border_det[m
+00007dd0: 6173 6b5b 695f 632c 203a 5d2c 203a 5d20  ask[i_c, :], :] 
+00007de0: 2d20 632c 2061 7869 733d 3129 0a0a 2020  - c, axis=1)..  
+00007df0: 2020 6e70 2e66 696c 6c5f 6469 6167 6f6e    np.fill_diagon
+00007e00: 616c 2864 6973 7461 6e63 655f 6d61 7472  al(distance_matr
+00007e10: 6978 2c20 6e70 2e6e 616e 290a 0a20 2020  ix, np.nan)..   
+00007e20: 2023 2066 696e 6420 6e5f 736d 616c 6c65   # find n_smalle
+00007e30: 7374 2064 6973 7461 6e63 6573 2061 6e64  st distances and
+00007e40: 2064 6574 6572 6d69 6e65 206d 6964 706f   determine midpo
+00007e50: 696e 7473 2062 6574 7765 656e 2074 686f  ints between tho
+00007e60: 7365 2070 6f69 6e74 730a 2020 2020 6e5f  se points.    n_
+00007e70: 736d 616c 6c65 7374 203d 2031 3030 300a  smallest = 1000.
+00007e80: 2020 2020 6964 7820 3d20 6765 745f 696e      idx = get_in
+00007e90: 6469 6365 735f 6f66 5f6b 5f73 6d61 6c6c  dices_of_k_small
+00007ea0: 6573 7428 6469 7374 616e 6365 5f6d 6174  est(distance_mat
+00007eb0: 7269 782c 206e 5f73 6d61 6c6c 6573 7429  rix, n_smallest)
+00007ec0: 0a20 2020 2063 6f6f 7264 735f 626f 7264  .    coords_bord
+00007ed0: 6572 203d 2028 636f 6f72 6473 5f62 6f72  er = (coords_bor
+00007ee0: 6465 725f 6465 745b 6964 785b 305d 2c20  der_det[idx[0], 
+00007ef0: 3a5d 202b 2063 6f6f 7264 735f 626f 7264  :] + coords_bord
+00007f00: 6572 5f64 6574 5b69 6478 5b31 5d2c 203a  er_det[idx[1], :
+00007f10: 5d29 202f 2032 0a0a 2020 2020 2320 7265  ]) / 2..    # re
+00007f20: 7361 6d70 6c65 206e 5f63 6f6f 7264 735f  sample n_coords_
+00007f30: 6469 7363 2065 7175 616c 6c79 2064 6973  disc equally dis
+00007f40: 7472 6962 7574 6564 2070 6f69 6e74 7320  tributed points 
+00007f50: 6672 6f6d 206e 5f73 6d61 6c6c 6573 7420  from n_smallest 
+00007f60: 706f 696e 7473 206f 6e20 6469 7363 6f6e  points on discon
+00007f70: 7469 6e75 6974 790a 2020 2020 6e5f 7265  tinuity.    n_re
+00007f80: 7073 203d 2031 3030 3020 2023 206e 756d  ps = 1000  # num
+00007f90: 6265 7220 6f66 2072 6570 6574 6974 696f  ber of repetitio
+00007fa0: 6e73 0a20 2020 2069 6478 203d 206e 702e  ns.    idx = np.
+00007fb0: 7a65 726f 7328 286e 5f63 6f6f 7264 735f  zeros((n_coords_
+00007fc0: 6469 7363 2c20 6e5f 7265 7073 2929 0a20  disc, n_reps)). 
+00007fd0: 2020 2064 6973 7461 6e63 655f 6d65 616e     distance_mean
+00007fe0: 203d 206e 702e 7a65 726f 7328 6e5f 7265   = np.zeros(n_re
+00007ff0: 7073 290a 0a20 2020 2023 2073 656c 6563  ps)..    # selec
+00008000: 7420 6e5f 636f 6f72 6473 5f64 6973 6320  t n_coords_disc 
+00008010: 706f 696e 7473 2072 616e 646f 6d6c 7920  points randomly 
+00008020: 616e 6420 6465 7465 726d 696e 6520 6176  and determine av
+00008030: 6572 6167 6520 6d69 6e69 6d61 6c20 6469  erage minimal di
+00008040: 7374 616e 6365 2062 6574 7765 656e 2070  stance between p
+00008050: 6f69 6e74 730a 2020 2020 666f 7220 6920  oints.    for i 
+00008060: 696e 2072 616e 6765 286e 5f72 6570 7329  in range(n_reps)
+00008070: 3a0a 2020 2020 2020 2020 2320 7361 6d70  :.        # samp
+00008080: 6c65 206e 5f72 6573 616d 706c 6520 706f  le n_resample po
+00008090: 696e 7473 2066 726f 6d20 636f 6f72 6473  ints from coords
+000080a0: 5f62 6f72 6465 720a 2020 2020 2020 2020  _border.        
+000080b0: 6964 785b 3a2c 2069 5d20 3d20 7261 6e64  idx[:, i] = rand
+000080c0: 6f6d 2e73 616d 706c 6528 6c69 7374 2872  om.sample(list(r
+000080d0: 616e 6765 2863 6f6f 7264 735f 626f 7264  ange(coords_bord
+000080e0: 6572 2e73 6861 7065 5b30 5d29 292c 206e  er.shape[0])), n
+000080f0: 5f63 6f6f 7264 735f 6469 7363 290a 0a20  _coords_disc).. 
+00008100: 2020 2020 2020 2023 2064 6574 6572 6d69         # determi
+00008110: 6e65 2061 6c6c 2074 6f20 616c 6c20 6469  ne all to all di
+00008120: 7374 616e 6365 730a 2020 2020 2020 2020  stances.        
+00008130: 6469 7374 616e 6365 5f6d 6174 7269 785f  distance_matrix_
+00008140: 7265 7361 6d70 6c65 203d 206e 702e 6f6e  resample = np.on
+00008150: 6573 2828 6e5f 636f 6f72 6473 5f64 6973  es((n_coords_dis
+00008160: 632c 206e 5f63 6f6f 7264 735f 6469 7363  c, n_coords_disc
+00008170: 2929 202a 206e 702e 6e61 6e0a 0a20 2020  )) * np.nan..   
+00008180: 2020 2020 2066 6f72 2069 5f63 2c20 6320       for i_c, c 
+00008190: 696e 2065 6e75 6d65 7261 7465 2863 6f6f  in enumerate(coo
+000081a0: 7264 735f 626f 7264 6572 5b69 6478 5b3a  rds_border[idx[:
+000081b0: 2c20 695d 2e61 7374 7970 6528 696e 7429  , i].astype(int)
+000081c0: 2c20 3a5d 293a 0a20 2020 2020 2020 2020  , :]):.         
+000081d0: 2020 2064 6973 7461 6e63 655f 6d61 7472     distance_matr
+000081e0: 6978 5f72 6573 616d 706c 655b 695f 632c  ix_resample[i_c,
+000081f0: 203a 5d20 3d20 6e70 2e6c 696e 616c 672e   :] = np.linalg.
+00008200: 6e6f 726d 2863 6f6f 7264 735f 626f 7264  norm(coords_bord
+00008210: 6572 5b69 6478 5b3a 2c20 695d 2e61 7374  er[idx[:, i].ast
+00008220: 7970 6528 696e 7429 2c20 3a5d 202d 2063  ype(int), :] - c
+00008230: 2c20 6178 6973 3d31 290a 0a20 2020 2020  , axis=1)..     
+00008240: 2020 206e 702e 6669 6c6c 5f64 6961 676f     np.fill_diago
+00008250: 6e61 6c28 6469 7374 616e 6365 5f6d 6174  nal(distance_mat
+00008260: 7269 785f 7265 7361 6d70 6c65 2c20 3130  rix_resample, 10
+00008270: 3030 290a 2020 2020 2020 2020 6469 7374  00).        dist
+00008280: 616e 6365 5f6d 6561 6e5b 695d 203d 206e  ance_mean[i] = n
+00008290: 702e 6d65 616e 286e 702e 6d69 6e28 6469  p.mean(np.min(di
+000082a0: 7374 616e 6365 5f6d 6174 7269 785f 7265  stance_matrix_re
+000082b0: 7361 6d70 6c65 2c20 6178 6973 3d31 2929  sample, axis=1))
+000082c0: 0a0a 2020 2020 636f 6f72 6473 5f64 6973  ..    coords_dis
+000082d0: 6320 3d20 636f 6f72 6473 5f62 6f72 6465  c = coords_borde
+000082e0: 725b 6964 785b 3a2c 206e 702e 6172 676d  r[idx[:, np.argm
+000082f0: 6178 2864 6973 7461 6e63 655f 6d65 616e  ax(distance_mean
+00008300: 295d 2e61 7374 7970 6528 696e 7429 2c20  )].astype(int), 
+00008310: 3a5d 0a0a 2020 2020 7265 7475 726e 2063  :]..    return c
+00008320: 6f6f 7264 735f 6469 7363 0a0a 0a64 6566  oords_disc...def
+00008330: 2069 6e63 7265 6d65 6e74 5f62 6173 6973   increment_basis
+00008340: 286f 7264 6572 5f63 7572 7265 6e74 2c20  (order_current, 
+00008350: 696e 7465 7261 6374 696f 6e5f 6f72 6465  interaction_orde
+00008360: 725f 6375 7272 656e 742c 2069 6e74 6572  r_current, inter
+00008370: 6163 7469 6f6e 5f6f 7264 6572 5f6d 6178  action_order_max
+00008380: 2c20 696e 6372 293a 0a20 2020 2022 2222  , incr):.    """
+00008390: 0a20 2020 2049 6e63 7265 6d65 6e74 7320  .    Increments 
+000083a0: 6261 7369 730a 0a20 2020 2050 6172 616d  basis..    Param
+000083b0: 6574 6572 730a 2020 2020 2d2d 2d2d 2d2d  eters.    ------
+000083c0: 2d2d 2d2d 0a20 2020 206f 7264 6572 5f63  ----.    order_c
+000083d0: 7572 7265 6e74 3a20 696e 740a 2020 2020  urrent: int.    
+000083e0: 2020 2020 4d61 7869 6d75 6d20 676c 6f62      Maximum glob
+000083f0: 616c 2065 7870 616e 7369 6f6e 206f 7264  al expansion ord
+00008400: 6572 2e0a 2020 2020 2020 2020 5468 6520  er..        The 
+00008410: 6d61 7869 6d75 6d20 6578 7061 6e73 696f  maximum expansio
+00008420: 6e20 6f72 6465 7220 636f 6e73 6964 6572  n order consider
+00008430: 7320 7468 6520 7375 6d20 6f66 2074 6865  s the sum of the
+00008440: 206f 7264 6572 7320 6f66 2063 6f6d 6269   orders of combi
+00008450: 6e65 6420 706f 6c79 6e6f 6d69 616c 7320  ned polynomials 
+00008460: 746f 6765 7468 6572 2077 6974 6820 7468  together with th
+00008470: 650a 2020 2020 2020 2020 6368 6f73 656e  e.        chosen
+00008480: 206e 6f72 6d20 226f 7264 6572 5f6d 6178   norm "order_max
+00008490: 5f6e 6f72 6d22 2e20 5479 7069 6361 6c6c  _norm". Typicall
+000084a0: 7920 7468 6973 206e 6f72 6d20 6973 2031  y this norm is 1
+000084b0: 2073 7563 6820 7468 6174 2074 6865 206d   such that the m
+000084c0: 6178 696d 756d 206f 7264 6572 2069 7320  aximum order is 
+000084d0: 7468 6520 7375 6d20 6f66 2061 6c6c 0a20  the sum of all. 
+000084e0: 2020 2020 2020 206d 6f6e 6f6d 6961 6c20         monomial 
+000084f0: 6f72 6465 7273 2e0a 2020 2020 696e 7465  orders..    inte
+00008500: 7261 6374 696f 6e5f 6f72 6465 725f 6375  raction_order_cu
+00008510: 7272 656e 7420 3a20 696e 740a 2020 2020  rrent : int.    
+00008520: 2020 2020 4375 7272 656e 7420 6e75 6d62      Current numb
+00008530: 6572 206f 6620 7261 6e64 6f6d 2076 6172  er of random var
+00008540: 6961 626c 6573 2c20 7768 6963 6820 6361  iables, which ca
+00008550: 6e20 696e 7465 7261 6374 2077 6974 6820  n interact with 
+00008560: 6561 6368 206f 7468 6572 0a20 2020 2020  each other.     
+00008570: 2020 2041 6c6c 2070 6f6c 796e 6f6d 6961     All polynomia
+00008580: 6c73 2061 7265 2069 676e 6f72 6564 2c20  ls are ignored, 
+00008590: 7768 6963 6820 6861 7665 2061 6e20 696e  which have an in
+000085a0: 7465 7261 6374 696f 6e20 6f72 6465 7220  teraction order 
+000085b0: 6772 6561 7465 7220 7468 616e 2073 7065  greater than spe
+000085c0: 6369 6669 6564 0a20 2020 2069 6e74 6572  cified.    inter
+000085d0: 6163 7469 6f6e 5f6f 7264 6572 5f6d 6178  action_order_max
+000085e0: 203a 2069 6e74 0a20 2020 2020 2020 204d   : int.        M
+000085f0: 6178 696d 756d 206e 756d 6265 7220 6f66  aximum number of
+00008600: 2072 616e 646f 6d20 7661 7269 6162 6c65   random variable
+00008610: 732c 2077 6869 6368 2063 616e 2069 6e74  s, which can int
+00008620: 6572 6163 7420 7769 7468 2065 6163 6820  eract with each 
+00008630: 6f74 6865 720a 2020 2020 2020 2020 416c  other.        Al
+00008640: 6c20 706f 6c79 6e6f 6d69 616c 7320 6172  l polynomials ar
+00008650: 6520 6967 6e6f 7265 642c 2077 6869 6368  e ignored, which
+00008660: 2068 6176 6520 616e 2069 6e74 6572 6163   have an interac
+00008670: 7469 6f6e 206f 7264 6572 2067 7265 6174  tion order great
+00008680: 6572 2074 6861 6e20 7370 6563 6966 6965  er than specifie
+00008690: 640a 2020 2020 696e 6372 203a 2069 6e74  d.    incr : int
+000086a0: 0a20 2020 2020 2020 204e 756d 6265 7220  .        Number 
+000086b0: 6f66 2073 7562 2d69 7465 7261 7469 6f6e  of sub-iteration
+000086c0: 2069 6e63 7265 6d65 6e74 730a 0a20 2020   increments..   
+000086d0: 2052 6574 7572 6e73 0a20 2020 202d 2d2d   Returns.    ---
+000086e0: 2d2d 2d2d 0a20 2020 206f 7264 6572 203a  ----.    order :
+000086f0: 2069 6e74 0a20 2020 2020 2020 2055 7064   int.        Upd
+00008700: 6174 6564 206f 7264 6572 0a20 2020 2069  ated order.    i
+00008710: 6e74 6572 6163 7469 6f6e 5f6f 7264 6572  nteraction_order
+00008720: 203a 2069 6e74 0a20 2020 2020 2020 2055   : int.        U
+00008730: 7064 6174 6564 2069 6e74 6572 6163 7469  pdated interacti
+00008740: 6f6e 206f 7264 6572 0a20 2020 2022 2222  on order.    """
+00008750: 0a20 2020 2077 6869 6c65 2069 6e63 7220  .    while incr 
+00008760: 3e20 303a 0a20 2020 2020 2020 2069 6620  > 0:.        if 
+00008770: 696e 7465 7261 6374 696f 6e5f 6f72 6465  interaction_orde
+00008780: 725f 6375 7272 656e 7420 2b20 3120 3c3d  r_current + 1 <=
+00008790: 206d 696e 286f 7264 6572 5f63 7572 7265   min(order_curre
+000087a0: 6e74 2c20 696e 7465 7261 6374 696f 6e5f  nt, interaction_
+000087b0: 6f72 6465 725f 6d61 7829 3a0a 2020 2020  order_max):.    
+000087c0: 2020 2020 2020 2020 696e 7465 7261 6374          interact
+000087d0: 696f 6e5f 6f72 6465 725f 6375 7272 656e  ion_order_curren
+000087e0: 7420 2b3d 2031 0a20 2020 2020 2020 2065  t += 1.        e
+000087f0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+00008800: 206f 7264 6572 5f63 7572 7265 6e74 202b   order_current +
+00008810: 3d20 310a 2020 2020 2020 2020 2020 2020  = 1.            
+00008820: 696e 7465 7261 6374 696f 6e5f 6f72 6465  interaction_orde
+00008830: 725f 6375 7272 656e 7420 3d20 310a 0a20  r_current = 1.. 
+00008840: 2020 2020 2020 2069 6e63 7220 2d3d 2031         incr -= 1
+00008850: 0a0a 2020 2020 7265 7475 726e 206f 7264  ..    return ord
+00008860: 6572 5f63 7572 7265 6e74 2c20 696e 7465  er_current, inte
+00008870: 7261 6374 696f 6e5f 6f72 6465 725f 6375  raction_order_cu
+00008880: 7272 656e 740a 0a0a 6465 6620 636f 6d70  rrent...def comp
+00008890: 7574 655f 6368 756e 6b73 2873 6571 2c20  ute_chunks(seq, 
+000088a0: 6e75 6d29 3a0a 2020 2020 2222 220a 2020  num):.    """.  
+000088b0: 2020 5370 6c69 7473 2075 7020 6120 7365    Splits up a se
+000088c0: 7175 656e 6365 205f 7365 715f 2069 6e74  quence _seq_ int
+000088d0: 6f20 5f6e 756d 5f20 6368 756e 6b73 206f  o _num_ chunks o
+000088e0: 6620 7369 6d69 6c61 7220 7369 7a65 2e0a  f similar size..
+000088f0: 2020 2020 4966 206c 656e 2873 6571 2920      If len(seq) 
+00008900: 3c20 6e75 6d2c 2028 6e75 6d2d 6c65 6e28  < num, (num-len(
+00008910: 7365 7129 2920 656d 7074 7920 6368 756e  seq)) empty chun
+00008920: 6b73 2061 7265 2072 6574 7572 6e65 6420  ks are returned 
+00008930: 736f 2074 6861 7420 6c65 6e28 6f75 7429  so that len(out)
+00008940: 203d 3d20 6e75 6d0a 0a20 2020 2050 6172   == num..    Par
+00008950: 616d 6574 6572 730a 2020 2020 2d2d 2d2d  ameters.    ----
+00008960: 2d2d 2d2d 2d2d 0a20 2020 2073 6571 203a  ------.    seq :
+00008970: 206c 6973 7420 6f66 2073 6f6d 6574 6869   list of somethi
+00008980: 6e67 205b 4e5f 656c 655d 0a20 2020 2020  ng [N_ele].     
+00008990: 2020 204c 6973 7420 636f 6e74 6169 6e69     List containi
+000089a0: 6e67 2064 6174 6120 6f72 2069 6e64 6963  ng data or indic
+000089b0: 6573 2c20 7768 6963 6820 6973 2064 6976  es, which is div
+000089c0: 6964 6564 2069 6e74 6f20 6368 756e 6b73  ided into chunks
+000089d0: 0a20 2020 206e 756d 203a 2069 6e74 0a20  .    num : int. 
+000089e0: 2020 2020 2020 204e 756d 6265 7220 6f66         Number of
+000089f0: 2063 6875 6e6b 7320 746f 2067 656e 6572   chunks to gener
+00008a00: 6174 650a 0a20 2020 2052 6574 7572 6e73  ate..    Returns
+00008a10: 0a20 2020 202d 2d2d 2d2d 2d2d 0a20 2020  .    -------.   
+00008a20: 206f 7574 203a 206c 6973 7420 6f66 206e   out : list of n
+00008a30: 756d 2073 7562 6c69 7374 730a 2020 2020  um sublists.    
+00008a40: 2020 2020 6e75 6d20 7375 622d 6c69 7374      num sub-list
+00008a50: 7320 6f66 2073 6571 2077 6974 6820 6561  s of seq with ea
+00008a60: 6368 206f 6620 6120 7369 6d69 6c61 7220  ch of a similar 
+00008a70: 6e75 6d62 6572 206f 6620 656c 656d 656e  number of elemen
+00008a80: 7473 2028 6f72 2065 6d70 7479 292e 0a20  ts (or empty).. 
+00008a90: 2020 2022 2222 0a20 2020 2061 7373 6572     """.    asser
+00008aa0: 7420 6c65 6e28 7365 7129 203e 2030 0a20  t len(seq) > 0. 
+00008ab0: 2020 2061 7373 6572 7420 6e75 6d20 3e20     assert num > 
+00008ac0: 300a 2020 2020 2320 6173 7365 7274 2069  0.    # assert i
+00008ad0: 7369 6e73 7461 6e63 6528 7365 712c 206c  sinstance(seq, l
+00008ae0: 6973 7429 2c20 6622 7b74 7970 6528 7365  ist), f"{type(se
+00008af0: 7129 7d20 6361 6e27 7420 6265 2063 6875  q)} can't be chu
+00008b00: 6e6b 6564 2e20 5072 6f76 6964 6520 6c69  nked. Provide li
+00008b10: 7374 2e22 0a0a 2020 2020 6176 6720 3d20  st."..    avg = 
+00008b20: 6c65 6e28 7365 7129 202f 2066 6c6f 6174  len(seq) / float
+00008b30: 286e 756d 290a 2020 2020 6e5f 656d 7074  (num).    n_empt
+00008b40: 7920 3d20 3020 2023 2069 6620 6c65 6e28  y = 0  # if len(
+00008b50: 7365 6729 203c 206e 756d 2c20 686f 7720  seg) < num, how 
+00008b60: 6d61 6e79 2065 6d70 7479 206c 6973 7473  many empty lists
+00008b70: 2074 6f20 6170 7065 6e64 2074 6f20 7265   to append to re
+00008b80: 7475 726e 3f0a 0a20 2020 2069 6620 6176  turn?..    if av
+00008b90: 6720 3c20 313a 0a20 2020 2020 2020 2061  g < 1:.        a
+00008ba0: 7667 203d 2031 0a20 2020 2020 2020 206e  vg = 1.        n
+00008bb0: 5f65 6d70 7479 203d 206e 756d 202d 206c  _empty = num - l
+00008bc0: 656e 2873 6571 290a 0a20 2020 206f 7574  en(seq)..    out
+00008bd0: 203d 205b 5d0a 2020 2020 6c61 7374 203d   = [].    last =
+00008be0: 2030 2e30 0a0a 2020 2020 7768 696c 6520   0.0..    while 
+00008bf0: 6c61 7374 203c 206c 656e 2873 6571 293a  last < len(seq):
+00008c00: 0a20 2020 2020 2020 2023 2069 6620 6f6e  .        # if on
+00008c10: 6c79 206f 6e65 2065 6c65 6d65 6e74 2077  ly one element w
+00008c20: 6f75 6c64 2062 6520 6c65 6674 2069 6e20  ould be left in 
+00008c30: 7468 6520 6c61 7374 2072 756e 2c20 6164  the last run, ad
+00008c40: 6420 6974 2074 6f20 7468 6520 6375 7272  d it to the curr
+00008c50: 656e 740a 2020 2020 2020 2020 6966 2028  ent.        if (
+00008c60: 696e 7428 6c61 7374 202b 2061 7667 2920  int(last + avg) 
+00008c70: 2b20 3129 203d 3d20 6c65 6e28 7365 7129  + 1) == len(seq)
+00008c80: 3a0a 2020 2020 2020 2020 2020 2020 6c61  :.            la
+00008c90: 7374 5f61 7070 656e 645f 6964 7820 3d20  st_append_idx = 
+00008ca0: 696e 7428 6c61 7374 202b 2061 7667 2920  int(last + avg) 
+00008cb0: 2b20 310a 2020 2020 2020 2020 656c 7365  + 1.        else
+00008cc0: 3a0a 2020 2020 2020 2020 2020 2020 6c61  :.            la
+00008cd0: 7374 5f61 7070 656e 645f 6964 7820 3d20  st_append_idx = 
+00008ce0: 696e 7428 6c61 7374 202b 2061 7667 290a  int(last + avg).
+00008cf0: 0a20 2020 2020 2020 206f 7574 2e61 7070  .        out.app
+00008d00: 656e 6428 7365 715b 696e 7428 6c61 7374  end(seq[int(last
+00008d10: 293a 6c61 7374 5f61 7070 656e 645f 6964  ):last_append_id
+00008d20: 785d 290a 0a20 2020 2020 2020 2069 6620  x])..        if 
+00008d30: 2869 6e74 286c 6173 7420 2b20 6176 6729  (int(last + avg)
+00008d40: 202b 2031 2920 3d3d 206c 656e 2873 6571   + 1) == len(seq
+00008d50: 293a 0a20 2020 2020 2020 2020 2020 206c  ):.            l
+00008d60: 6173 7420 2b3d 2061 7667 202b 2031 0a20  ast += avg + 1. 
+00008d70: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+00008d80: 2020 2020 2020 2020 206c 6173 7420 2b3d           last +=
+00008d90: 2061 7667 0a0a 2020 2020 2320 6170 7065   avg..    # appe
+00008da0: 6e64 2065 6d70 7479 206c 6973 7473 2069  nd empty lists i
+00008db0: 6620 6c65 6e28 7365 7129 203c 206e 756d  f len(seq) < num
+00008dc0: 0a20 2020 206f 7574 202b 3d20 5b5b 5d5d  .    out += [[]]
+00008dd0: 202a 206e 5f65 6d70 7479 0a0a 2020 2020   * n_empty..    
+00008de0: 7265 7475 726e 206f 7574 0a0a 0a64 6566  return out...def
+00008df0: 2074 5f61 7665 7261 6765 645f 6d75 7475   t_averaged_mutu
+00008e00: 616c 5f63 6f68 6572 656e 6365 2861 7272  al_coherence(arr
+00008e10: 6179 2c20 743d 302e 3229 3a0a 2020 2020  ay, t=0.2):.    
+00008e20: 2222 220a 2020 2020 436f 6d70 7574 6573  """.    Computes
+00008e30: 2074 6865 2074 2d61 7665 7261 6765 6420   the t-averaged 
+00008e40: 6d75 7475 616c 2063 6f68 6572 656e 6365  mutual coherence
+00008e50: 2e0a 0a20 2020 2050 6172 616d 6574 6572  ...    Parameter
+00008e60: 730a 2020 2020 2d2d 2d2d 2d2d 2d2d 2d2d  s.    ----------
+00008e70: 0a20 2020 2061 7272 6179 203a 206e 6461  .    array : nda
+00008e80: 7272 6179 206f 6620 666c 6f61 7420 5b6d  rray of float [m
+00008e90: 2078 206e 5d0a 2020 2020 2020 2020 4d61   x n].        Ma
+00008ea0: 7472 6978 0a20 2020 2074 203a 2066 6c6f  trix.    t : flo
+00008eb0: 6174 0a20 2020 2020 2020 2054 6872 6573  at.        Thres
+00008ec0: 686f 6c64 0a0a 2020 2020 5265 7475 726e  hold..    Return
+00008ed0: 730a 2020 2020 2d2d 2d2d 2d2d 2d0a 2020  s.    -------.  
+00008ee0: 2020 7265 7320 3a20 666c 6f61 740a 2020    res : float.  
+00008ef0: 2020 2020 2020 742d 6176 6572 6167 6564        t-averaged
+00008f00: 206d 7574 7561 6c20 636f 6865 7265 6e63   mutual coherenc
+00008f10: 650a 2020 2020 2222 220a 2020 2020 6172  e.    """.    ar
+00008f20: 7261 7920 3d20 6e70 2e61 6273 2861 7272  ray = np.abs(arr
+00008f30: 6179 290a 2020 2020 6d61 736b 203d 2061  ay).    mask = a
+00008f40: 7272 6179 203e 2074 0a0a 2020 2020 7265  rray > t..    re
+00008f50: 7475 726e 206e 702e 7375 6d28 6172 7261  turn np.sum(arra
+00008f60: 795b 6d61 736b 5d29 202f 206e 702e 7375  y[mask]) / np.su
+00008f70: 6d28 6d61 736b 290a 0a0a 6465 6620 6176  m(mask)...def av
+00008f80: 6572 6167 655f 6372 6f73 735f 636f 7272  erage_cross_corr
+00008f90: 656c 6174 696f 6e5f 6772 616d 2861 7272  elation_gram(arr
+00008fa0: 6179 293a 0a20 2020 2022 2222 0a20 2020  ay):.    """.   
+00008fb0: 2043 6f6d 7075 7465 7320 7468 6520 6176   Computes the av
+00008fc0: 6572 6167 6520 6372 6f73 7320 636f 7272  erage cross corr
+00008fd0: 656c 6174 696f 6e20 6f66 2074 6865 2067  elation of the g
+00008fe0: 7261 6d20 6d61 7472 6978 2e0a 0a20 2020  ram matrix...   
+00008ff0: 2050 6172 616d 6574 6572 730a 2020 2020   Parameters.    
+00009000: 2d2d 2d2d 2d2d 2d2d 2d2d 0a20 2020 2061  ----------.    a
+00009010: 7272 6179 203a 206e 6461 7272 6179 206f  rray : ndarray o
+00009020: 6620 666c 6f61 7420 5b6d 2078 206e 5d0a  f float [m x n].
+00009030: 2020 2020 2020 2020 4772 616d 206d 6174          Gram mat
+00009040: 7269 780a 0a20 2020 2052 6574 7572 6e73  rix..    Returns
+00009050: 0a20 2020 202d 2d2d 2d2d 2d2d 0a20 2020  .    -------.   
+00009060: 2072 6573 203a 2066 6c6f 6174 0a20 2020   res : float.   
+00009070: 2020 2020 2063 726f 7373 2063 6f72 7265       cross corre
+00009080: 6c61 7469 6f6e 0a20 2020 2022 2222 0a20  lation.    """. 
+00009090: 2020 206b 203d 2061 7272 6179 2e73 6861     k = array.sha
+000090a0: 7065 5b31 5d0a 2020 2020 6e20 3d20 6b20  pe[1].    n = k 
+000090b0: 2a20 286b 202d 2031 290a 0a20 2020 2072  * (k - 1)..    r
+000090c0: 6574 7572 6e20 2831 202f 206e 2920 2a20  eturn (1 / n) * 
+000090d0: 286e 702e 6c69 6e61 6c67 2e6e 6f72 6d28  (np.linalg.norm(
+000090e0: 6e70 2e69 6465 6e74 6974 7928 6b29 202d  np.identity(k) -
+000090f0: 2061 7272 6179 2920 2a2a 2032 290a 0a0a   array) ** 2)...
+00009100: 6465 6620 5068 6950 2878 2c20 703d 3130  def PhiP(x, p=10
+00009110: 293a 0a20 2020 2022 2222 0a20 2020 2043  ):.    """.    C
+00009120: 616c 6375 6c61 7465 7320 7468 6520 5068  alculates the Ph
+00009130: 692d 7020 6372 6974 6572 696f 6e20 6f66  i-p criterion of
+00009140: 2074 6865 2064 6573 6967 6e20 7820 7769   the design x wi
+00009150: 7468 2070 6f77 6572 2070 205b 315d 2e0a  th power p [1]..
+00009160: 0a20 2020 2050 6172 616d 6574 6572 730a  .    Parameters.
+00009170: 2020 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0a20      ----------. 
+00009180: 2020 2078 203a 206e 6461 7272 6179 206f     x : ndarray o
+00009190: 6620 666c 6f61 7420 5b6e 2078 206d 5d0a  f float [n x m].
+000091a0: 2020 2020 2020 2020 5468 6520 6465 7369          The desi
+000091b0: 676e 2074 6f20 6361 6c63 756c 6174 6520  gn to calculate 
+000091c0: 5068 692d 7020 666f 720a 2020 2020 7020  Phi-p for.    p 
+000091d0: 3a20 696e 742c 206f 7074 696f 6e61 6c2c  : int, optional,
+000091e0: 2064 6566 6175 6c74 3a20 3130 0a20 2020   default: 10.   
+000091f0: 2020 2020 2054 6865 2070 6f77 6572 2075       The power u
+00009200: 7365 6420 666f 7220 7468 6520 6361 6c63  sed for the calc
+00009210: 756c 6174 696f 6e20 6f66 2050 6869 500a  ulation of PhiP.
+00009220: 0a20 2020 2052 6574 7572 6e73 0a20 2020  .    Returns.   
+00009230: 202d 2d2d 2d2d 2d2d 0a20 2020 2070 6869   -------.    phi
+00009240: 7020 3a20 666c 6f61 740a 2020 2020 2020  p : float.      
+00009250: 2020 5068 692d 7020 6372 6974 6572 696f    Phi-p criterio
+00009260: 6e0a 0a20 2020 204e 6f74 6573 0a20 2020  n..    Notes.   
+00009270: 202d 2d2d 2d2d 0a20 2020 202e 2e20 5b31   -----.    .. [1
+00009280: 5d20 4d6f 7272 6973 2c20 4d2e 2044 2e2c  ] Morris, M. D.,
+00009290: 2026 204d 6974 6368 656c 6c2c 2054 2e20   & Mitchell, T. 
+000092a0: 4a2e 2028 3139 3935 292e 2045 7870 6c6f  J. (1995). Explo
+000092b0: 7261 746f 7279 2064 6573 6967 6e73 2066  ratory designs f
+000092c0: 6f72 2063 6f6d 7075 7461 7469 6f6e 616c  or computational
+000092d0: 2065 7870 6572 696d 656e 7473 2e0a 2020   experiments..  
+000092e0: 2020 2020 204a 6f75 726e 616c 206f 6620       Journal of 
+000092f0: 7374 6174 6973 7469 6361 6c20 706c 616e  statistical plan
+00009300: 6e69 6e67 2061 6e64 2069 6e66 6572 656e  ning and inferen
+00009310: 6365 2c20 3433 2833 292c 2033 3831 2d34  ce, 43(3), 381-4
+00009320: 3032 2e0a 2020 2020 2222 220a 0a20 2020  02..    """..   
+00009330: 2070 6869 7020 3d20 2828 7363 6970 792e   phip = ((scipy.
+00009340: 7370 6174 6961 6c2e 6469 7374 616e 6365  spatial.distance
+00009350: 2e70 6469 7374 2878 2920 2a2a 2028 2d70  .pdist(x) ** (-p
+00009360: 2929 2e73 756d 2829 2920 2a2a 2028 312e  )).sum()) ** (1.
+00009370: 3020 2f20 7029 0a0a 2020 2020 7265 7475  0 / p)..    retu
+00009380: 726e 2070 6869 700a 0a0a 6465 6620 706f  rn phip...def po
+00009390: 6c79 5f65 7870 616e 6428 6375 7272 656e  ly_expand(curren
+000093a0: 745f 7365 742c 2074 6f5f 6578 7061 6e64  t_set, to_expand
+000093b0: 2c20 6f72 6465 725f 6d61 782c 2069 6e74  , order_max, int
+000093c0: 6572 6163 7469 6f6e 5f6f 7264 6572 293a  eraction_order):
+000093d0: 0a20 2020 2022 2222 0a20 2020 2041 6c67  .    """.    Alg
+000093e0: 6f72 6974 686d 2062 7920 4765 7273 746e  orithm by Gerstn
+000093f0: 6572 2061 6e64 2047 7269 6562 656c 2074  er and Griebel t
+00009400: 6f20 6578 7061 6e64 2070 6f6c 796e 6f6d  o expand polynom
+00009410: 6961 6c20 6261 7369 7320 5b31 5d20 6163  ial basis [1] ac
+00009420: 636f 7264 696e 6720 746f 2074 776f 2063  cording to two c
+00009430: 7269 7465 7269 613a 0a20 2020 2020 2020  riteria:.       
+00009440: 2028 3129 2054 6865 2062 6173 6973 2066   (1) The basis f
+00009450: 756e 6374 696f 6e20 6d61 7920 6e6f 7420  unction may not 
+00009460: 6265 2063 6f6d 706c 6574 656c 7920 656e  be completely en
+00009470: 636c 6f73 6564 2062 7920 616c 7265 6164  closed by alread
+00009480: 7920 6578 6973 7469 6e67 2062 6173 6973  y existing basis
+00009490: 2066 756e 6374 696f 6e73 2e20 496e 2074   functions. In t
+000094a0: 6869 7320 6361 7365 2074 6865 2061 6464  his case the add
+000094b0: 6564 0a20 2020 2020 2020 2020 2020 2062  ed.            b
+000094c0: 6173 6973 2077 6f75 6c64 2062 6520 616c  asis would be al
+000094d0: 7265 6164 7920 696e 636c 7564 6564 2069  ready included i
+000094e0: 6e20 616e 7920 6361 7365 2e0a 2020 2020  n any case..    
+000094f0: 2020 2020 2832 2920 5468 6520 6261 7369      (2) The basi
+00009500: 7320 6675 6e63 7469 6f6e 2069 7320 6e6f  s function is no
+00009510: 7420 6120 6361 6e64 6964 6174 6520 6966  t a candidate if
+00009520: 2061 6464 696e 6720 616e 7920 6261 7369   adding any basi
+00009530: 7320 776f 756c 6420 6861 7665 206e 6f20  s would have no 
+00009540: 7072 6564 6563 6573 736f 7273 2e20 5468  predecessors. Th
+00009550: 6520 6e65 7720 6261 7369 7320 6d75 7374  e new basis must
+00009560: 2068 6176 650a 2020 2020 2020 2020 2020   have.          
+00009570: 2020 7072 6564 6563 6573 736f 7273 2069    predecessors i
+00009580: 6e20 616c 6c20 6465 6372 6561 7369 6e67  n all decreasing
+00009590: 2064 6972 6563 7469 6f6e 2061 6e64 206d   direction and m
+000095a0: 6179 206e 6f74 2022 666c 6f61 7422 2e0a  ay not "float"..
+000095b0: 0a20 2020 2050 6172 616d 6574 6572 730a  .    Parameters.
+000095c0: 2020 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0a20      ----------. 
+000095d0: 2020 2063 7572 7265 6e74 5f73 6574 203a     current_set :
+000095e0: 206e 6461 7272 6179 206f 6620 696e 7420   ndarray of int 
+000095f0: 5b6e 5f62 6173 6973 2c20 6469 6d5d 0a20  [n_basis, dim]. 
+00009600: 2020 2020 2020 2041 7272 6179 206f 6620         Array of 
+00009610: 6d75 6c74 692d 696e 6469 6365 7320 6f66  multi-indices of
+00009620: 2062 6173 6973 2066 756e 6374 696f 6e73   basis functions
+00009630: 0a20 2020 2074 6f5f 6578 7061 6e64 203a  .    to_expand :
+00009640: 206e 6461 7272 6179 206f 6620 696e 7420   ndarray of int 
+00009650: 5b64 696d 5d0a 2020 2020 2020 2020 5365  [dim].        Se
+00009660: 6c65 6374 6564 2062 6173 6973 2066 756e  lected basis fun
+00009670: 6374 696f 6e20 2877 6974 6820 6869 6768  ction (with high
+00009680: 6573 7420 6750 4320 636f 6566 6669 6369  est gPC coeffici
+00009690: 656e 7429 2c20 7768 6963 6820 7769 6c6c  ent), which will
+000096a0: 2062 6520 6578 7061 6e64 6564 2069 6e20   be expanded in 
+000096b0: 616c 6c20 706f 7373 6962 6c65 2064 6972  all possible dir
+000096c0: 6563 7469 6f6e 0a20 2020 206f 7264 6572  ection.    order
+000096d0: 5f6d 6178 203a 2069 6e74 0a20 2020 2020  _max : int.     
+000096e0: 2020 204d 6178 696d 616c 2061 6363 756d     Maximal accum
+000096f0: 756c 6174 6564 206f 7264 6572 2028 7375  ulated order (su
+00009700: 6d20 6f76 6572 2061 6c6c 2070 6172 616d  m over all param
+00009710: 6574 6572 7329 0a20 2020 2069 6e74 6572  eters).    inter
+00009720: 6163 7469 6f6e 5f6f 7264 6572 203a 2069  action_order : i
+00009730: 6e74 0a20 2020 2020 2020 2041 6c6c 6f77  nt.        Allow
+00009740: 6564 2069 6e74 6572 6163 7469 6f6e 206f  ed interaction o
+00009750: 7264 6572 2062 6574 7765 656e 2076 6172  rder between var
+00009760: 6961 626c 6573 2028 3c3d 2064 696d 290a  iables (<= dim).
+00009770: 0a20 2020 2052 6574 7572 6e73 0a20 2020  .    Returns.   
+00009780: 202d 2d2d 2d2d 2d2d 0a20 2020 2065 7870   -------.    exp
+00009790: 616e 6420 3a20 6e64 6172 7261 7920 6f66  and : ndarray of
+000097a0: 2069 6e74 205b 6e5f 6261 7369 732c 2064   int [n_basis, d
+000097b0: 696d 5d0a 2020 2020 2020 2020 4172 7261  im].        Arra
+000097c0: 7920 6f66 206d 756c 7469 2d69 6e64 6963  y of multi-indic
+000097d0: 6573 2c20 7768 6963 6820 7769 6c6c 2062  es, which will b
+000097e0: 6520 6164 6465 6420 746f 2074 6865 2073  e added to the s
+000097f0: 6574 206f 6620 6261 7369 7320 6675 6e63  et of basis func
+00009800: 7469 6f6e 730a 0a20 2020 204e 6f74 6573  tions..    Notes
+00009810: 0a20 2020 202d 2d2d 2d2d 0a20 2020 202e  .    -----.    .
+00009820: 2e20 5b31 5d20 5420 4765 7273 746e 6572  . [1] T Gerstner
+00009830: 2061 6e64 204d 2047 7269 6562 656c 2e20   and M Griebel. 
+00009840: 4469 6d65 6e73 696f 6e20 6164 6170 7469  Dimension adapti
+00009850: 7665 2074 656e 736f 7220 7072 6f64 7563  ve tensor produc
+00009860: 7420 7175 6164 7261 7475 7265 2e20 436f  t quadrature. Co
+00009870: 6d70 7574 696e 672c 2037 313a 3635 e280  mputing, 71:65..
+00009880: 9338 372c 2032 3030 332e 0a20 2020 2022  .87, 2003..    "
+00009890: 2222 0a0a 2020 2020 6966 2074 7970 6528  ""..    if type(
+000098a0: 6375 7272 656e 745f 7365 7429 2069 7320  current_set) is 
+000098b0: 6e6f 7420 6c69 7374 3a0a 2020 2020 2020  not list:.      
+000098c0: 2020 6375 7272 656e 745f 7365 7420 3d20    current_set = 
+000098d0: 6375 7272 656e 745f 7365 742e 746f 6c69  current_set.toli
+000098e0: 7374 2829 0a0a 2020 2020 6578 7061 6e64  st()..    expand
+000098f0: 203d 205b 5d0a 2020 2020 666f 7220 6520   = [].    for e 
+00009900: 696e 2072 616e 6765 286c 656e 2874 6f5f  in range(len(to_
+00009910: 6578 7061 6e64 2929 3a0a 2020 2020 2020  expand)):.      
+00009920: 2020 666f 7277 6172 6420 3d20 636f 7079    forward = copy
+00009930: 2e64 6565 7063 6f70 7928 746f 5f65 7870  .deepcopy(to_exp
+00009940: 616e 6429 0a20 2020 2020 2020 2066 6f72  and).        for
+00009950: 7761 7264 5b65 5d20 2b3d 2031 0a20 2020  ward[e] += 1.   
+00009960: 2020 2020 2068 6173 5f70 7265 6465 6365       has_predece
+00009970: 7373 6f72 7320 3d20 5472 7565 0a20 2020  ssors = True.   
+00009980: 2020 2020 2066 6f72 2065 3220 696e 2072       for e2 in r
+00009990: 616e 6765 286c 656e 2874 6f5f 6578 7061  ange(len(to_expa
+000099a0: 6e64 2929 3a0a 2020 2020 2020 2020 2020  nd)):.          
+000099b0: 2020 6966 2066 6f72 7761 7264 5b65 325d    if forward[e2]
+000099c0: 203e 2030 3a0a 2020 2020 2020 2020 2020   > 0:.          
+000099d0: 2020 2020 2020 7072 6564 6563 6573 736f        predecesso
+000099e0: 7220 3d20 666f 7277 6172 642e 636f 7079  r = forward.copy
+000099f0: 2829 0a20 2020 2020 2020 2020 2020 2020  ().             
+00009a00: 2020 2070 7265 6465 6365 7373 6f72 5b65     predecessor[e
+00009a10: 325d 202d 3d20 310a 2020 2020 2020 2020  2] -= 1.        
+00009a20: 2020 2020 2020 2020 6861 735f 7072 6564          has_pred
+00009a30: 6563 6573 736f 7273 202a 3d20 6c69 7374  ecessors *= list
+00009a40: 2870 7265 6465 6365 7373 6f72 2920 696e  (predecessor) in
+00009a50: 2063 7572 7265 6e74 5f73 6574 0a20 2020   current_set.   
+00009a60: 2020 2020 2069 6620 6861 735f 7072 6564       if has_pred
+00009a70: 6563 6573 736f 7273 2061 6e64 2028 6e70  ecessors and (np
+00009a80: 2e73 756d 286e 702e 6162 7328 666f 7277  .sum(np.abs(forw
+00009a90: 6172 6429 2920 3c3d 206f 7264 6572 5f6d  ard)) <= order_m
+00009aa0: 6178 2920 616e 6420 286e 702e 7375 6d28  ax) and (np.sum(
+00009ab0: 666f 7277 6172 6420 3e20 3029 203c 3d20  forward > 0) <= 
+00009ac0: 696e 7465 7261 6374 696f 6e5f 6f72 6465  interaction_orde
+00009ad0: 7229 3a0a 2020 2020 2020 2020 2020 2020  r):.            
+00009ae0: 6578 7061 6e64 202b 3d20 5b74 7570 6c65  expand += [tuple
+00009af0: 2866 6f72 7761 7264 295d 0a0a 2020 2020  (forward)]..    
+00009b00: 7265 7475 726e 206e 702e 6172 7261 7928  return np.array(
+00009b10: 6578 7061 6e64 290a 0a0a 6465 6620 6765  expand)...def ge
+00009b20: 745f 6e6f 6e5f 656e 636c 6f73 6564 5f6d  t_non_enclosed_m
+00009b30: 756c 7469 5f69 6e64 6963 6573 286d 756c  ulti_indices(mul
+00009b40: 7469 5f69 6e64 6963 6573 2c20 696e 7465  ti_indices, inte
+00009b50: 7261 6374 696f 6e5f 6f72 6465 7229 3a0a  raction_order):.
+00009b60: 2020 2020 2222 220a 2020 2020 4578 7472      """.    Extr
+00009b70: 6163 7420 706f 7373 6962 6c65 206d 756c  act possible mul
+00009b80: 7469 2d69 6e64 6963 6573 2066 726f 6d20  ti-indices from 
+00009b90: 6120 6769 7665 6e20 7365 7420 7768 6963  a given set whic
+00009ba0: 6820 6172 6520 706f 7465 6e74 6961 6c20  h are potential 
+00009bb0: 6361 6e64 6964 6174 6573 2066 6f72 2061  candidates for a
+00009bc0: 6e69 736f 7472 6f70 6963 2062 6173 6973  nisotropic basis
+00009bd0: 2065 7874 656e 7369 6f6e 2e0a 2020 2020   extension..    
+00009be0: 5477 6f20 6372 6974 6572 6961 206d 7573  Two criteria mus
+00009bf0: 7420 6265 206d 6574 3a0a 2020 2020 2831  t be met:.    (1
+00009c00: 2920 5468 6520 6261 7369 7320 6675 6e63  ) The basis func
+00009c10: 7469 6f6e 206d 6179 206e 6f74 2062 6520  tion may not be 
+00009c20: 636f 6d70 6c65 7465 6c79 2065 6e63 6c6f  completely enclo
+00009c30: 7365 6420 6279 2061 6c72 6561 6479 2065  sed by already e
+00009c40: 7869 7374 696e 6720 6261 7369 7320 6675  xisting basis fu
+00009c50: 6e63 7469 6f6e 732e 2049 6e20 7468 6973  nctions. In this
+00009c60: 2063 6173 6520 7468 6520 6164 6465 640a   case the added.
+00009c70: 2020 2020 2020 2020 6261 7369 7320 776f          basis wo
+00009c80: 756c 6420 6265 2061 6c72 6561 6479 2069  uld be already i
+00009c90: 6e63 6c75 6465 6420 696e 2061 6e79 2063  ncluded in any c
+00009ca0: 6173 652e 0a20 2020 2028 3229 2054 6865  ase..    (2) The
+00009cb0: 2062 6173 6973 2066 756e 6374 696f 6e20   basis function 
+00009cc0: 6973 206e 6f74 2061 2063 616e 6469 6461  is not a candida
+00009cd0: 7465 2069 6620 6164 6469 6e67 2061 6e79  te if adding any
+00009ce0: 2062 6173 6973 2077 6f75 6c64 2068 6176   basis would hav
+00009cf0: 6520 6e6f 2070 7265 6465 6365 7373 6f72  e no predecessor
+00009d00: 732e 2054 6865 206e 6577 2062 6173 6973  s. The new basis
+00009d10: 206d 7573 7420 6861 7665 0a20 2020 2020   must have.     
+00009d20: 2020 2070 7265 6465 6365 7373 6f72 7320     predecessors 
+00009d30: 696e 2061 6c6c 2064 6563 7265 6173 696e  in all decreasin
+00009d40: 6720 6469 7265 6374 696f 6e20 616e 6420  g direction and 
+00009d50: 6d61 7920 6e6f 7420 2266 6c6f 6174 222e  may not "float".
+00009d60: 0a0a 2020 2020 5061 7261 6d65 7465 7273  ..    Parameters
+00009d70: 0a20 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0a  .    ----------.
+00009d80: 2020 2020 6d75 6c74 695f 696e 6469 6365      multi_indice
+00009d90: 7320 3a20 6e64 6172 7261 7920 6f66 2066  s : ndarray of f
+00009da0: 6c6f 6174 205b 6e5f 6261 7369 732c 2064  loat [n_basis, d
+00009db0: 696d 5d0a 2020 2020 2020 2020 4172 7261  im].        Arra
+00009dc0: 7920 6f66 206d 756c 7469 2d69 6e64 6963  y of multi-indic
+00009dd0: 6573 206f 6620 6261 7369 7320 6675 6e63  es of basis func
+00009de0: 7469 6f6e 730a 2020 2020 696e 7465 7261  tions.    intera
+00009df0: 6374 696f 6e5f 6f72 6465 7220 3a20 696e  ction_order : in
+00009e00: 740a 2020 2020 2020 2020 416c 6c6f 7765  t.        Allowe
+00009e10: 6420 696e 7465 7261 6374 696f 6e20 6f72  d interaction or
+00009e20: 6465 7220 6265 7477 6565 6e20 7661 7269  der between vari
+00009e30: 6162 6c65 7320 283c 3d20 6469 6d29 0a0a  ables (<= dim)..
+00009e40: 2020 2020 5265 7475 726e 730a 2020 2020      Returns.    
+00009e50: 2d2d 2d2d 2d2d 2d0a 2020 2020 6d75 6c74  -------.    mult
+00009e60: 695f 696e 6469 6365 735f 6e6f 6e5f 656e  i_indices_non_en
+00009e70: 636c 6f73 6564 203a 206e 6461 7272 6179  closed : ndarray
+00009e80: 206f 6620 666c 6f61 7420 5b6e 5f62 6173   of float [n_bas
+00009e90: 6973 5f63 616e 6469 6461 7465 732c 2064  is_candidates, d
+00009ea0: 696d 5d0a 2020 2020 2020 2020 4172 7261  im].        Arra
+00009eb0: 7920 6f66 2070 6f73 7369 626c 6520 6d75  y of possible mu
+00009ec0: 6c74 692d 696e 6469 6365 7320 6f66 2062  lti-indices of b
+00009ed0: 6173 6973 2066 756e 6374 696f 6e73 0a20  asis functions. 
+00009ee0: 2020 2070 6f6c 795f 696e 6469 6365 735f     poly_indices_
+00009ef0: 6e6f 6e5f 656e 636c 6f73 6564 203a 206c  non_enclosed : l
+00009f00: 6973 7420 6f66 2069 6e74 0a20 2020 2020  ist of int.     
+00009f10: 2020 2049 6e64 6963 6573 206f 6620 7365     Indices of se
+00009f20: 6c65 6374 6564 2062 6173 6973 2066 756e  lected basis fun
+00009f30: 6374 696f 6e73 2069 6e20 676c 6f62 616c  ctions in global
+00009f40: 2022 6d75 6c74 692d 696e 6469 6365 7322   "multi-indices"
+00009f50: 2061 7272 6179 0a20 2020 2022 2222 0a20   array.    """. 
+00009f60: 2020 206d 756c 7469 5f69 6e64 6963 6573     multi_indices
+00009f70: 5f6e 6f6e 5f65 6e63 6c6f 7365 6420 3d20  _non_enclosed = 
+00009f80: 5b5d 0a0a 2020 2020 6966 2074 7970 6528  []..    if type(
+00009f90: 6d75 6c74 695f 696e 6469 6365 7329 2069  multi_indices) i
+00009fa0: 7320 6e6f 7420 6c69 7374 3a0a 2020 2020  s not list:.    
+00009fb0: 2020 2020 6d75 6c74 695f 696e 6469 6365      multi_indice
+00009fc0: 7320 3d20 6d75 6c74 695f 696e 6469 6365  s = multi_indice
+00009fd0: 732e 746f 6c69 7374 2829 0a0a 2020 2020  s.tolist()..    
+00009fe0: 6469 6d20 3d20 6c65 6e28 6d75 6c74 695f  dim = len(multi_
+00009ff0: 696e 6469 6365 735b 305d 290a 0a20 2020  indices[0])..   
+0000a000: 2066 6f72 206d 2069 6e20 6e70 2e61 7272   for m in np.arr
+0000a010: 6179 286d 756c 7469 5f69 6e64 6963 6573  ay(multi_indices
+0000a020: 293a 0a20 2020 2020 2020 2066 6f72 2069  ):.        for i
+0000a030: 5f64 696d 2069 6e20 7261 6e67 6528 6469  _dim in range(di
+0000a040: 6d29 3a0a 2020 2020 2020 2020 2020 2020  m):.            
+0000a050: 6d5f 7465 7374 203d 2063 6f70 792e 6465  m_test = copy.de
+0000a060: 6570 636f 7079 286e 702e 6172 7261 7928  epcopy(np.array(
+0000a070: 6d29 290a 2020 2020 2020 2020 2020 2020  m)).            
+0000a080: 6d5f 7465 7374 5b69 5f64 696d 5d20 3d20  m_test[i_dim] = 
+0000a090: 6d5f 7465 7374 5b69 5f64 696d 5d20 2b20  m_test[i_dim] + 
+0000a0a0: 310a 2020 2020 2020 2020 2020 2020 6861  1.            ha
+0000a0b0: 735f 7072 6564 6563 6573 736f 7273 203d  s_predecessors =
+0000a0c0: 2054 7275 650a 0a20 2020 2020 2020 2020   True..         
+0000a0d0: 2020 2069 6620 6e70 2e73 756d 286d 5f74     if np.sum(m_t
+0000a0e0: 6573 7420 3e20 3029 203c 3d20 696e 7465  est > 0) <= inte
+0000a0f0: 7261 6374 696f 6e5f 6f72 6465 723a 0a20  raction_order:. 
+0000a100: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+0000a110: 6620 6c69 7374 286d 5f74 6573 7429 206e  f list(m_test) n
+0000a120: 6f74 2069 6e20 6d75 6c74 695f 696e 6469  ot in multi_indi
+0000a130: 6365 733a 0a20 2020 2020 2020 2020 2020  ces:.           
+0000a140: 2020 2020 2020 2020 2066 6f72 2065 3220           for e2 
+0000a150: 696e 2072 616e 6765 2864 696d 293a 0a20  in range(dim):. 
+0000a160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a170: 2020 2020 2020 2069 6620 6d5f 7465 7374         if m_test
+0000a180: 5b65 325d 203e 2030 3a0a 2020 2020 2020  [e2] > 0:.      
+0000a190: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a1a0: 2020 2020 2020 7072 6564 6563 6573 736f        predecesso
+0000a1b0: 7220 3d20 636f 7079 2e64 6565 7063 6f70  r = copy.deepcop
+0000a1c0: 7928 6d5f 7465 7374 290a 2020 2020 2020  y(m_test).      
+0000a1d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a1e0: 2020 2020 2020 7072 6564 6563 6573 736f        predecesso
+0000a1f0: 725b 6532 5d20 3d20 7072 6564 6563 6573  r[e2] = predeces
+0000a200: 736f 725b 6532 5d20 2d20 310a 2020 2020  sor[e2] - 1.    
+0000a210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a220: 2020 2020 2020 2020 6861 735f 7072 6564          has_pred
+0000a230: 6563 6573 736f 7273 202a 3d20 6c69 7374  ecessors *= list
+0000a240: 2870 7265 6465 6365 7373 6f72 2920 696e  (predecessor) in
+0000a250: 206d 756c 7469 5f69 6e64 6963 6573 0a20   multi_indices. 
+0000a260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a270: 2020 2069 6620 6861 735f 7072 6564 6563     if has_predec
+0000a280: 6573 736f 7273 3a0a 2020 2020 2020 2020  essors:.        
+0000a290: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a2a0: 6d75 6c74 695f 696e 6469 6365 735f 6e6f  multi_indices_no
+0000a2b0: 6e5f 656e 636c 6f73 6564 2e61 7070 656e  n_enclosed.appen
+0000a2c0: 6428 6d29 0a0a 2020 2020 6d75 6c74 695f  d(m)..    multi_
+0000a2d0: 696e 6469 6365 735f 6e6f 6e5f 656e 636c  indices_non_encl
+0000a2e0: 6f73 6564 203d 206e 702e 756e 6971 7565  osed = np.unique
+0000a2f0: 286d 756c 7469 5f69 6e64 6963 6573 5f6e  (multi_indices_n
+0000a300: 6f6e 5f65 6e63 6c6f 7365 642c 2061 7869  on_enclosed, axi
+0000a310: 733d 3029 0a20 2020 2070 6f6c 795f 696e  s=0).    poly_in
+0000a320: 6469 6365 735f 6e6f 6e5f 656e 636c 6f73  dices_non_enclos
+0000a330: 6564 203d 205b 6e70 2e77 6865 7265 2828  ed = [np.where((
+0000a340: 6d75 6c74 695f 696e 6469 6365 7320 3d3d  multi_indices ==
+0000a350: 206d 292e 616c 6c28 6178 6973 3d31 2929   m).all(axis=1))
+0000a360: 5b30 5d5b 305d 2066 6f72 206d 2069 6e20  [0][0] for m in 
+0000a370: 6d75 6c74 695f 696e 6469 6365 735f 6e6f  multi_indices_no
+0000a380: 6e5f 656e 636c 6f73 6564 5d0a 0a20 2020  n_enclosed]..   
+0000a390: 2072 6574 7572 6e20 6d75 6c74 695f 696e   return multi_in
+0000a3a0: 6469 6365 735f 6e6f 6e5f 656e 636c 6f73  dices_non_enclos
+0000a3b0: 6564 2c20 706f 6c79 5f69 6e64 6963 6573  ed, poly_indices
+0000a3c0: 5f6e 6f6e 5f65 6e63 6c6f 7365 640a 0a0a  _non_enclosed...
+0000a3d0: 6465 6620 706c 6f74 5f62 6173 6973 5f62  def plot_basis_b
+0000a3e0: 795f 6d75 6c74 6969 6e64 6578 2861 293a  y_multiindex(a):
+0000a3f0: 0a20 2020 2022 2222 0a0a 2020 2020 5061  .    """..    Pa
+0000a400: 7261 6d65 7465 7273 0a20 2020 202d 2d2d  rameters.    ---
+0000a410: 2d2d 2d2d 2d2d 2d0a 2020 2020 610a 0a20  -------.    a.. 
+0000a420: 2020 2052 6574 7572 6e73 0a20 2020 202d     Returns.    -
+0000a430: 2d2d 2d2d 2d2d 0a0a 2020 2020 2222 220a  ------..    """.
+0000a440: 2020 2020 6669 6720 3d20 706c 742e 6669      fig = plt.fi
+0000a450: 6775 7265 2866 6967 7369 7a65 3d28 342c  gure(figsize=(4,
+0000a460: 2034 2929 0a0a 2020 2020 6178 203d 2066   4))..    ax = f
+0000a470: 6967 2e61 6464 5f73 7562 706c 6f74 2831  ig.add_subplot(1
+0000a480: 3131 2c20 7072 6f6a 6563 7469 6f6e 3d27  11, projection='
+0000a490: 3364 2729 0a0a 2020 2020 666f 7220 6920  3d')..    for i 
+0000a4a0: 696e 2072 616e 6765 286c 656e 2861 2929  in range(len(a))
+0000a4b0: 3a0a 2020 2020 2020 2020 6520 3d20 302e  :.        e = 0.
+0000a4c0: 330a 2020 2020 2020 2020 7820 3d20 615b  3.        x = a[
+0000a4d0: 695d 5b30 5d20 2b20 650a 2020 2020 2020  i][0] + e.      
+0000a4e0: 2020 7920 3d20 615b 695d 5b31 5d20 2b20    y = a[i][1] + 
+0000a4f0: 650a 2020 2020 2020 2020 7a20 3d20 615b  e.        z = a[
+0000a500: 695d 5b32 5d20 2b20 650a 2020 2020 2020  i][2] + e.      
+0000a510: 2020 7665 7274 6963 6573 203d 205b 5b28    vertices = [[(
+0000a520: 7820 2b20 652c 2079 202b 2065 2c20 7a20  x + e, y + e, z 
+0000a530: 2b20 6529 2c20 2878 202b 2065 2c20 7920  + e), (x + e, y 
+0000a540: 2b20 652c 207a 202d 2065 292c 2028 7820  + e, z - e), (x 
+0000a550: 2b20 652c 2079 202d 2065 2c20 7a20 2d20  + e, y - e, z - 
+0000a560: 6529 2c20 2878 202b 2065 2c20 7920 2d20  e), (x + e, y - 
+0000a570: 652c 207a 202b 2065 295d 2c0a 2020 2020  e, z + e)],.    
+0000a580: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a590: 5b28 7820 2d20 652c 2079 202b 2065 2c20  [(x - e, y + e, 
+0000a5a0: 7a20 2b20 6529 2c20 2878 202d 2065 2c20  z + e), (x - e, 
+0000a5b0: 7920 2b20 652c 207a 202d 2065 292c 2028  y + e, z - e), (
+0000a5c0: 7820 2d20 652c 2079 202d 2065 2c20 7a20  x - e, y - e, z 
+0000a5d0: 2d20 6529 2c20 2878 202d 2065 2c20 7920  - e), (x - e, y 
+0000a5e0: 2d20 652c 207a 202b 2065 295d 2c0a 2020  - e, z + e)],.  
+0000a5f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a600: 2020 5b28 7820 2b20 652c 2079 202b 2065    [(x + e, y + e
+0000a610: 2c20 7a20 2b20 6529 2c20 2878 202b 2065  , z + e), (x + e
+0000a620: 2c20 7920 2b20 652c 207a 202d 2065 292c  , y + e, z - e),
+0000a630: 2028 7820 2d20 652c 2079 202b 2065 2c20   (x - e, y + e, 
+0000a640: 7a20 2d20 6529 2c20 2878 202d 2065 2c20  z - e), (x - e, 
+0000a650: 7920 2b20 652c 207a 202b 2065 295d 2c0a  y + e, z + e)],.
+0000a660: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a670: 2020 2020 5b28 7820 2b20 652c 2079 202d      [(x + e, y -
+0000a680: 2065 2c20 7a20 2b20 6529 2c20 2878 202b   e, z + e), (x +
+0000a690: 2065 2c20 7920 2d20 652c 207a 202d 2065   e, y - e, z - e
+0000a6a0: 292c 2028 7820 2d20 652c 2079 202d 2065  ), (x - e, y - e
+0000a6b0: 2c20 7a20 2d20 6529 2c20 2878 202d 2065  , z - e), (x - e
+0000a6c0: 2c20 7920 2d20 652c 207a 202b 2065 295d  , y - e, z + e)]
+0000a6d0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000a6e0: 2020 2020 2020 5b28 7820 2b20 652c 2079        [(x + e, y
+0000a6f0: 202b 2065 2c20 7a20 2b20 6529 2c20 2878   + e, z + e), (x
+0000a700: 202b 2065 2c20 7920 2d20 652c 207a 202b   + e, y - e, z +
+0000a710: 2065 292c 2028 7820 2d20 652c 2079 202d   e), (x - e, y -
+0000a720: 2065 2c20 7a20 2b20 6529 2c20 2878 202d   e, z + e), (x -
+0000a730: 2065 2c20 7920 2b20 652c 207a 202b 2065   e, y + e, z + e
+0000a740: 295d 2c0a 2020 2020 2020 2020 2020 2020  )],.            
+0000a750: 2020 2020 2020 2020 5b28 7820 2b20 652c          [(x + e,
+0000a760: 2079 202b 2065 2c20 7a20 2d20 6529 2c20   y + e, z - e), 
+0000a770: 2878 202b 2065 2c20 7920 2d20 652c 207a  (x + e, y - e, z
+0000a780: 202d 2065 292c 2028 7820 2d20 652c 2079   - e), (x - e, y
+0000a790: 202d 2065 2c20 7a20 2d20 6529 2c20 2878   - e, z - e), (x
+0000a7a0: 202d 2065 2c20 7920 2b20 652c 207a 202d   - e, y + e, z -
+0000a7b0: 2065 295d 5d0a 2020 2020 2020 2020 706f   e)]].        po
+0000a7c0: 6c79 203d 2050 6f6c 7933 4443 6f6c 6c65  ly = Poly3DColle
+0000a7d0: 6374 696f 6e28 7665 7274 6963 6573 2c20  ction(vertices, 
+0000a7e0: 616c 7068 613d 302e 3529 0a20 2020 2020  alpha=0.5).     
+0000a7f0: 2020 2061 782e 6164 645f 636f 6c6c 6563     ax.add_collec
+0000a800: 7469 6f6e 3364 2870 6f6c 7929 0a0a 2020  tion3d(poly)..  
+0000a810: 2020 2020 2020 666f 7220 6a20 696e 2072        for j in r
+0000a820: 616e 6765 2836 293a 0a20 2020 2020 2020  ange(6):.       
+0000a830: 2020 2020 206c 696e 655f 7873 203d 206e       line_xs = n
+0000a840: 702e 6873 7461 636b 2828 6e70 2e61 7272  p.hstack((np.arr
+0000a850: 6179 2876 6572 7469 6365 735b 6a5d 292e  ay(vertices[j]).
+0000a860: 545b 305d 2c20 6e70 2e61 7272 6179 2876  T[0], np.array(v
+0000a870: 6572 7469 6365 735b 6a5d 292e 545b 305d  ertices[j]).T[0]
+0000a880: 5b30 5d29 290a 2020 2020 2020 2020 2020  [0])).          
+0000a890: 2020 6c69 6e65 5f79 7320 3d20 6e70 2e68    line_ys = np.h
+0000a8a0: 7374 6163 6b28 286e 702e 6172 7261 7928  stack((np.array(
+0000a8b0: 7665 7274 6963 6573 5b6a 5d29 2e54 5b31  vertices[j]).T[1
+0000a8c0: 5d2c 206e 702e 6172 7261 7928 7665 7274  ], np.array(vert
+0000a8d0: 6963 6573 5b6a 5d29 2e54 5b31 5d5b 305d  ices[j]).T[1][0]
+0000a8e0: 2929 0a20 2020 2020 2020 2020 2020 206c  )).            l
+0000a8f0: 696e 655f 7a73 203d 206e 702e 6873 7461  ine_zs = np.hsta
+0000a900: 636b 2828 6e70 2e61 7272 6179 2876 6572  ck((np.array(ver
+0000a910: 7469 6365 735b 6a5d 292e 545b 325d 2c20  tices[j]).T[2], 
+0000a920: 6e70 2e61 7272 6179 2876 6572 7469 6365  np.array(vertice
+0000a930: 735b 6a5d 292e 545b 325d 5b30 5d29 290a  s[j]).T[2][0])).
+0000a940: 2020 2020 2020 2020 2020 2020 706c 742e              plt.
+0000a950: 706c 6f74 286c 696e 655f 7873 2c20 6c69  plot(line_xs, li
+0000a960: 6e65 5f79 732c 206c 696e 655f 7a73 2c20  ne_ys, line_zs, 
+0000a970: 636f 6c6f 723d 276b 2729 0a0a 2020 2020  color='k')..    
+0000a980: 6178 2e73 6574 5f78 6c69 6d28 302c 2033  ax.set_xlim(0, 3
+0000a990: 290a 2020 2020 6178 2e73 6574 5f79 6c69  ).    ax.set_yli
+0000a9a0: 6d28 302c 2033 290a 2020 2020 6178 2e73  m(0, 3).    ax.s
+0000a9b0: 6574 5f7a 6c69 6d28 302c 2033 290a 2020  et_zlim(0, 3).  
+0000a9c0: 2020 706c 742e 7368 6f77 2829              plt.show()
```

## pygpc/oakley_ohagan_2004_M.txt

 * *Ordering differences only*

```diff
@@ -1,15 +1,15 @@
- -2.2482886e-002 -1.8501666e-001  1.3418263e-001  3.6867264e-001  1.7172785e-001  1.3651143e-001 -4.4034404e-001 -8.1422854e-002  7.1321025e-001 -4.4361072e-001  5.0383394e-001 -2.4101458e-002 -4.5939684e-002  2.1666181e-001  5.5887417e-002
-  2.5659630e-001  5.3792287e-002  2.5800381e-001  2.3795905e-001 -5.9125756e-001 -8.1627077e-002 -2.8749073e-001  4.1581639e-001  4.9752241e-001  8.3893165e-002 -1.1056683e-001  3.3222351e-002 -1.3979497e-001 -3.1020556e-002 -2.2318721e-001
- -5.5999811e-002  1.9542252e-001  9.5529005e-002 -2.8626530e-001 -1.4441303e-001  2.2369356e-001  1.4527412e-001  2.8998481e-001  2.3105010e-001 -3.1929879e-001 -2.9039128e-001 -2.0956898e-001  4.3139047e-001  2.4429152e-002  4.4904409e-002
-  6.6448103e-001  4.3069872e-001  2.9924645e-001 -1.6202441e-001 -3.1479544e-001 -3.9026802e-001  1.7679822e-001  5.7952663e-002  1.7230342e-001  1.3466011e-001 -3.5275240e-001  2.5146896e-001 -1.8810529e-002  3.6482392e-001 -3.2504618e-001
- -1.2127800e-001  1.2463327e-001  1.0656519e-001  4.6562296e-002 -2.1678617e-001  1.9492172e-001 -6.5521126e-002  2.4404669e-002 -9.6828860e-002  1.9366196e-001  3.3354757e-001  3.1295994e-001 -8.3615456e-002 -2.5342082e-001  3.7325717e-001
- -2.8376230e-001 -3.2820154e-001 -1.0496068e-001 -2.2073452e-001 -1.3708154e-001 -1.4426375e-001 -1.1503319e-001  2.2424151e-001 -3.0395022e-002 -5.1505615e-001  1.7254978e-002  3.8957118e-002  3.6069184e-001  3.0902452e-001  5.0030193e-002
- -7.7875893e-002  3.7456560e-003  8.8685604e-001 -2.6590028e-001 -7.9325357e-002 -4.2734919e-002 -1.8653782e-001 -3.5604718e-001 -1.7497421e-001  8.8699956e-002  4.0025886e-001 -5.5979693e-002  1.3724479e-001  2.1485613e-001 -1.1265799e-002
- -9.2294730e-002  5.9209563e-001  3.1338285e-002 -3.3080861e-002 -2.4308858e-001 -9.9798547e-002  3.4460195e-002  9.5119813e-002 -3.3801620e-001  6.3860024e-003 -6.1207299e-001  8.1325416e-002  8.8683114e-001  1.4254905e-001  1.4776204e-001
- -1.3189434e-001  5.2878496e-001  1.2652391e-001  4.5113625e-002  5.8373514e-001  3.7291503e-001  1.1395325e-001 -2.9479222e-001 -5.7014085e-001  4.6291592e-001 -9.4050179e-002  1.3959097e-001 -3.8607402e-001 -4.4897060e-001 -1.4602419e-001
-  5.8107658e-002 -3.2289338e-001  9.3139162e-002  7.2427234e-002 -5.6919401e-001  5.2554237e-001  2.3656926e-001 -1.1782016e-002  7.1820601e-002  7.8277291e-002 -1.3355752e-001  2.2722721e-001  1.4369455e-001 -4.5198935e-001 -5.5574794e-001
-  6.6145875e-001  3.4633299e-001  1.4098019e-001  5.1882591e-001 -2.8019898e-001 -1.6032260e-001 -6.8413337e-002 -2.0428242e-001  6.9672173e-002  2.3112577e-001 -4.4368579e-002 -1.6455425e-001  2.1620977e-001  4.2702105e-003 -8.7399014e-002
-  3.1599556e-001 -2.7551859e-002  1.3434254e-001  1.3497371e-001  5.4005680e-002 -1.7374789e-001  1.7525393e-001  6.0258929e-002 -1.7914162e-001 -3.1056619e-001 -2.5358691e-001  2.5847535e-002 -4.3006001e-001 -6.2266361e-001 -3.3996882e-002
- -2.9038151e-001  3.4101270e-002  3.4903413e-002 -1.2121764e-001  2.6030714e-002 -3.3546274e-001 -4.1424111e-001  5.3248380e-002 -2.7099455e-001 -2.6251302e-002  4.1024137e-001  2.6636349e-001  1.5582891e-001 -1.8666254e-001  1.9895831e-002
- -2.4388652e-001 -4.4098852e-001  1.2618825e-002  2.4945112e-001  7.1101888e-002  2.4623792e-001  1.7484502e-001  8.5286769e-003  2.5147070e-001 -1.4659862e-001 -8.4625150e-002  3.6931333e-001 -2.9955293e-001  1.1044360e-001 -7.5690139e-001
+ -2.2482886e-002 -1.8501666e-001  1.3418263e-001  3.6867264e-001  1.7172785e-001  1.3651143e-001 -4.4034404e-001 -8.1422854e-002  7.1321025e-001 -4.4361072e-001  5.0383394e-001 -2.4101458e-002 -4.5939684e-002  2.1666181e-001  5.5887417e-002
+  2.5659630e-001  5.3792287e-002  2.5800381e-001  2.3795905e-001 -5.9125756e-001 -8.1627077e-002 -2.8749073e-001  4.1581639e-001  4.9752241e-001  8.3893165e-002 -1.1056683e-001  3.3222351e-002 -1.3979497e-001 -3.1020556e-002 -2.2318721e-001
+ -5.5999811e-002  1.9542252e-001  9.5529005e-002 -2.8626530e-001 -1.4441303e-001  2.2369356e-001  1.4527412e-001  2.8998481e-001  2.3105010e-001 -3.1929879e-001 -2.9039128e-001 -2.0956898e-001  4.3139047e-001  2.4429152e-002  4.4904409e-002
+  6.6448103e-001  4.3069872e-001  2.9924645e-001 -1.6202441e-001 -3.1479544e-001 -3.9026802e-001  1.7679822e-001  5.7952663e-002  1.7230342e-001  1.3466011e-001 -3.5275240e-001  2.5146896e-001 -1.8810529e-002  3.6482392e-001 -3.2504618e-001
+ -1.2127800e-001  1.2463327e-001  1.0656519e-001  4.6562296e-002 -2.1678617e-001  1.9492172e-001 -6.5521126e-002  2.4404669e-002 -9.6828860e-002  1.9366196e-001  3.3354757e-001  3.1295994e-001 -8.3615456e-002 -2.5342082e-001  3.7325717e-001
+ -2.8376230e-001 -3.2820154e-001 -1.0496068e-001 -2.2073452e-001 -1.3708154e-001 -1.4426375e-001 -1.1503319e-001  2.2424151e-001 -3.0395022e-002 -5.1505615e-001  1.7254978e-002  3.8957118e-002  3.6069184e-001  3.0902452e-001  5.0030193e-002
+ -7.7875893e-002  3.7456560e-003  8.8685604e-001 -2.6590028e-001 -7.9325357e-002 -4.2734919e-002 -1.8653782e-001 -3.5604718e-001 -1.7497421e-001  8.8699956e-002  4.0025886e-001 -5.5979693e-002  1.3724479e-001  2.1485613e-001 -1.1265799e-002
+ -9.2294730e-002  5.9209563e-001  3.1338285e-002 -3.3080861e-002 -2.4308858e-001 -9.9798547e-002  3.4460195e-002  9.5119813e-002 -3.3801620e-001  6.3860024e-003 -6.1207299e-001  8.1325416e-002  8.8683114e-001  1.4254905e-001  1.4776204e-001
+ -1.3189434e-001  5.2878496e-001  1.2652391e-001  4.5113625e-002  5.8373514e-001  3.7291503e-001  1.1395325e-001 -2.9479222e-001 -5.7014085e-001  4.6291592e-001 -9.4050179e-002  1.3959097e-001 -3.8607402e-001 -4.4897060e-001 -1.4602419e-001
+  5.8107658e-002 -3.2289338e-001  9.3139162e-002  7.2427234e-002 -5.6919401e-001  5.2554237e-001  2.3656926e-001 -1.1782016e-002  7.1820601e-002  7.8277291e-002 -1.3355752e-001  2.2722721e-001  1.4369455e-001 -4.5198935e-001 -5.5574794e-001
+  6.6145875e-001  3.4633299e-001  1.4098019e-001  5.1882591e-001 -2.8019898e-001 -1.6032260e-001 -6.8413337e-002 -2.0428242e-001  6.9672173e-002  2.3112577e-001 -4.4368579e-002 -1.6455425e-001  2.1620977e-001  4.2702105e-003 -8.7399014e-002
+  3.1599556e-001 -2.7551859e-002  1.3434254e-001  1.3497371e-001  5.4005680e-002 -1.7374789e-001  1.7525393e-001  6.0258929e-002 -1.7914162e-001 -3.1056619e-001 -2.5358691e-001  2.5847535e-002 -4.3006001e-001 -6.2266361e-001 -3.3996882e-002
+ -2.9038151e-001  3.4101270e-002  3.4903413e-002 -1.2121764e-001  2.6030714e-002 -3.3546274e-001 -4.1424111e-001  5.3248380e-002 -2.7099455e-001 -2.6251302e-002  4.1024137e-001  2.6636349e-001  1.5582891e-001 -1.8666254e-001  1.9895831e-002
+ -2.4388652e-001 -4.4098852e-001  1.2618825e-002  2.4945112e-001  7.1101888e-002  2.4623792e-001  1.7484502e-001  8.5286769e-003  2.5147070e-001 -1.4659862e-001 -8.4625150e-002  3.6931333e-001 -2.9955293e-001  1.1044360e-001 -7.5690139e-001
   4.1494323e-002 -2.5980564e-001  4.6402128e-001 -3.6112127e-001 -9.4980789e-001 -1.6504063e-001  3.0943325e-003  5.2792942e-002  2.2523648e-001  3.8390366e-001  4.5562427e-001 -1.8631744e-001  8.2333995e-003  1.6670803e-001  1.6045688e-001
```

## pygpc/oakley_ohagan_2004_a1.txt

 * *Ordering differences only*

```diff
@@ -1,15 +1,15 @@
-0.0118
-0.0456
-0.2297
-0.0393
-0.1177
-0.3865
-0.3897
-0.6061
-0.6159
-0.4005
-1.0741
-1.1474
-0.7880
-1.1242
+0.0118
+0.0456
+0.2297
+0.0393
+0.1177
+0.3865
+0.3897
+0.6061
+0.6159
+0.4005
+1.0741
+1.1474
+0.7880
+1.1242
 1.1982
```

## pygpc/oakley_ohagan_2004_a2.txt

 * *Ordering differences only*

```diff
@@ -1,15 +1,15 @@
-0.4341
-0.0887
-0.0512
-0.3233
-0.1489
-1.0360
-0.9892
-0.9672
-0.8977
-0.8083
-1.8426
-2.4712
-2.3946
-2.0045
+0.4341
+0.0887
+0.0512
+0.3233
+0.1489
+1.0360
+0.9892
+0.9672
+0.8977
+0.8083
+1.8426
+2.4712
+2.3946
+2.0045
 2.2621
```

## pygpc/oakley_ohagan_2004_a3.txt

 * *Ordering differences only*

```diff
@@ -1,15 +1,15 @@
-0.1044
-0.2057
-0.0774
-0.2730
-0.1253
-0.7526
-0.8570
-1.0331
-0.8388
-0.7970
-2.2145
-2.0382
-2.4004
-2.0541
+0.1044
+0.2057
+0.0774
+0.2730
+0.1253
+0.7526
+0.8570
+1.0331
+0.8388
+0.7970
+2.2145
+2.0382
+2.4004
+2.0541
 1.9845
```

## pygpc/postprocessing.py

```diff
@@ -1,1078 +1,1081 @@
-import h5py
-import matplotlib
-import numpy as np
-import pandas as pd
-
-from .Grid import *
-from .MEGPC import *
-from .io import read_session
-
-
-def get_sensitivities_hdf5(fn_gpc, output_idx=False, calc_sobol=True, calc_global_sens=False, calc_pdf=False,
-                           algorithm="standard", n_samples=1e5):
-    """
-    Post-processes the gPC expansion from the gPC coefficients (standard) or by sampling. Adds mean,
-    standard deviation, relative standard deviation, variance, Sobol indices, global derivative based
-    sensitivity coefficients and probability density functions of output quantities to .hdf5 file of gPC.
-
-    Parameters
-    ----------
-    fn_gpc : str
-        Filename of gPC .pkl object and corresponding .hdf5 results file (without file extension)
-        (e.g. .../foo/gpc)
-    output_idx : nparray of int
-        Indices of output quantities (QOIs) to consider in postprocessing (default: all)
-    calc_sobol : bool
-        Calculate Sobol indices (default: True)
-    calc_global_sens : bool
-        Calculate global derivative based sensitivities (default: False)
-    calc_pdf : bool
-        Calculate probability density functions of output quantities (default: False)
-    algorithm : str, optional, default: "standard"
-        Algorithm to determine the Sobol indices
-        - "standard": Sobol indices are determined from the gPC coefficients
-        - "sampling": Sobol indices are determined from sampling using Saltelli's Sobol sampling sequence [1, 2, 3]
-    n_samples : int, optional, default: 1e5
-        Number of samples to determine Sobol indices by sampling. The efficient number of samples
-        increases to n_samples * (2*dim + 2) in Saltelli's Sobol sampling sequence.
-
-    Returns
-    -------
-    <File> : .hdf5
-        Adds datasets "sens/..." to the gPC .hdf5 file
-
-    Example
-    -------
-    The content of .hdf5 files can be shown using the tool HDFView
-    (https://support.hdfgroup.org/products/java/hdfview/)
-
-    ::
-        sens
-        I---/mean               [n_qoi]                 Mean of QOIs
-        I---/std                [n_qoi]                 Standard deviation of QOIs
-        I---/rstd               [n_qoi]                 Relative standard deviation of QOIs
-        I---/var                [n_qoi]                 Variance of QOIs
-        I---/sobol              [n_sobol x n_qoi]       Sobol indices (all available orders)
-        I---/sobol_idx_bool     [n_sobol x n_dim]       Corresponding parameter (combinations) of Sobol indices
-        I---/global_sens        [n_dim x n_qoi]         Global derivative based sensitivity coefficients
-        I---/pdf_x              [100 x n_qoi]           x-axis values of output PDFs
-        I---/pdf_y              [100 x n_qoi]           y-axis values of output PDFs
-    """
-    sobol = None
-    sobol_idx_bool = None
-    global_sens = None
-    pdf_x = None
-    pdf_y = None
-    grid = None
-    res = None
-
-    with h5py.File(fn_gpc + ".hdf5", 'r') as f:
-        # filename of associated gPC .pkl files
-        fn_session = os.path.join(os.path.split(fn_gpc)[0], f["misc/fn_session"][0].astype(str))
-        fn_session_folder = f["misc/fn_session_folder"][0].astype(str)
-
-    print("> Loading gpc session object: {}".format(fn_session))
-    session = read_session(fname=fn_session, folder=fn_session_folder)
-
-    with h5py.File(fn_gpc + ".hdf5", 'r') as f:
-        # check if we have qoi specific gPCs here
-        try:
-            if "qoi" in list(f["coeffs"].keys())[0]:
-                qoi_keys = list(f["coeffs"].keys())
-
-        except AttributeError:
-            pass
-
-        # load coeffs depending on gpc type
-        print("> Loading gpc coeffs: {}".format(fn_gpc + ".hdf5"))
-
-        if not session.qoi_specific and not session.gpc_type == "megpc":
-            coeffs = np.array(f['coeffs'][:])
-
-            if not output_idx:
-                output_idx = np.arange(coeffs.shape[1])
-
-        elif not session.qoi_specific and session.gpc_type == "megpc":
-
-            coeffs = [None for _ in range(len(list(f['coeffs'].keys())))]
-
-            for i, d in enumerate(list(f['coeffs'].keys())):
-                coeffs[i] = np.array(f['coeffs/' + str(d)])[:]
-
-            if not output_idx:
-                output_idx = np.arange(coeffs[0].shape[1])
-
-        elif session.qoi_specific and not session.gpc_type == "megpc":
-
-            algorithm = "sampling"
-            coeffs = dict()
-
-            for key in qoi_keys:
-                coeffs[key] = np.array(f['coeffs/' + key])[:]
-
-            if not output_idx:
-                output_idx = np.arange(len(list(coeffs.keys())))
-
-        elif session.qoi_specific and session.gpc_type == "megpc":
-
-            algorithm = "sampling"
-            coeffs = dict()
-
-            for key in qoi_keys:
-                coeffs[key] = [None for _ in range(len(list(f['coeffs/' + key].keys())))]
-
-                for i, d in enumerate(list(f['coeffs/' + key].keys())):
-                    coeffs[key][i] = np.array(f['coeffs/' + key + "/" + str(d)])[:]
-
-            if not output_idx:
-                output_idx = np.arange(len(list(coeffs.keys())))
-
-        dim = f["grid/coords"][:].shape[1]
-
-    # generate samples in case of sampling approach
-    if algorithm == "sampling":
-        grid = Random(parameters_random=session.parameters_random,
-                      n_grid=n_samples,
-                      options=None)
-
-    # start prostprocessing depending on gPC type
-    if not session.qoi_specific and not session.gpc_type == "megpc":
-
-        coeffs = coeffs[:, output_idx]
-
-        if algorithm == "standard":
-            # determine mean
-            mean = session.gpc[0].get_mean(coeffs=coeffs)
-
-            # determine standard deviation
-            std = session.gpc[0].get_std(coeffs=coeffs)
-
-        elif algorithm == "sampling":
-            # run model evaluations
-            res = session.gpc[0].get_approximation(coeffs=coeffs, x=grid.coords_norm)
-
-            # determine mean
-            mean = session.gpc[0].get_mean(samples=res)
-
-            # determine standard deviation
-            std = session.gpc[0].get_std(samples=res)
-
-        else:
-            raise AssertionError("Please provide valid algorithm argument (""standard"" or ""sampling"")")
-
-        # determine Sobol indices
-        if calc_sobol:
-            sobol, sobol_idx, sobol_idx_bool = session.gpc[0].get_sobol_indices(coeffs=coeffs,
-                                                                                algorithm=algorithm,
-                                                                                n_samples=n_samples)
-
-        # determine global derivative based sensitivity coefficients
-        if calc_global_sens:
-            global_sens = session.gpc[0].get_global_sens(coeffs=coeffs,
-                                                         algorithm=algorithm,
-                                                         n_samples=n_samples)
-
-        # determine pdfs
-        if calc_pdf:
-            pdf_x, pdf_y = session.gpc[0].get_pdf(coeffs, n_samples=n_samples, output_idx=output_idx)
-
-    elif session.qoi_specific and not session.gpc_type == "megpc":
-
-        gpc = []
-        pdf_x = np.zeros((100, len(output_idx)))
-        pdf_y = np.zeros((100, len(output_idx)))
-        global_sens = np.zeros((dim, len(output_idx)))
-
-        res = np.zeros((grid.coords_norm.shape[0], len(output_idx)))
-
-        # loop over qoi (there may be different approximations and projections)
-        for i, idx in enumerate(output_idx):
-
-            # run model evaluations
-            res[:, i] = session.gpc[idx].get_approximation(coeffs=coeffs["qoi_" + str(idx)],
-                                                           x=grid.coords_norm).flatten()
-
-            # determine Sobol indices
-            if calc_sobol:
-                sobol_qoi, sobol_idx_qoi, sobol_idx_bool_qoi = \
-                    session.gpc[idx].get_sobol_indices(coeffs=coeffs["qoi_" + str(idx)],
-                                                       algorithm=algorithm,
-                                                       n_samples=n_samples)
-
-            # rearrange sobol indices according to first qoi (reference)
-            # (they are sorted w.r.t. highest contribution and this may change between qoi)
-            if i == 0:
-                sobol = copy.deepcopy(sobol_qoi)
-                sobol_idx = copy.deepcopy(sobol_idx_qoi)
-                sobol_idx_bool = copy.deepcopy(sobol_idx_bool_qoi)
-
-            else:
-                sobol = np.hstack((sobol, np.zeros(sobol.shape)))
-                sobol_sort_idx = []
-                for ii, s_idx in enumerate(sobol_idx):
-                    for jj, s_idx_qoi in enumerate(sobol_idx_qoi):
-                        if (s_idx == s_idx_qoi).all():
-                            sobol_sort_idx.append(jj)
-
-                for jj, s in enumerate(sobol_sort_idx):
-                    sobol[jj, i] = sobol_qoi[s]
-
-            # determine global derivative based sensitivity coefficients
-            if calc_global_sens:
-                global_sens[:, ] = session.gpc[idx].get_global_sens(coeffs=coeffs["qoi_" + str(idx)],
-                                                                    algorithm=algorithm,
-                                                                    n_samples=n_samples)
-
-            # determine pdfs
-            if calc_pdf:
-                pdf_x[:, ], pdf_y[:, ] = session.gpc[idx].get_pdf(coeffs=coeffs["qoi_" + str(idx)],
-                                                                  n_samples=n_samples,
-                                                                  output_idx=0)
-
-        # determine mean
-        mean = gpc.get_mean(samples=res)
-
-        # determine standard deviation
-        std = gpc.get_std(samples=res)
-
-    elif not session.qoi_specific and session.gpc_type == "megpc":
-
-        pdf_x = np.zeros((100, len(output_idx)))
-        pdf_y = np.zeros((100, len(output_idx)))
-        global_sens = np.zeros((dim, len(output_idx)))
-
-        if algorithm == "sampling":
-
-            # run model evaluations
-            res = session.gpc[0].get_approximation(coeffs=coeffs, x=grid.coords_norm)
-
-            # determine Sobol indices
-            if calc_sobol:
-                sobol, sobol_idx, sobol_idx_bool = session.gpc[0].get_sobol_indices(coeffs=coeffs,
-                                                                                    n_samples=n_samples)
-
-            # determine global derivative based sensitivity coefficients
-            if calc_global_sens:
-                global_sens[:, ] = session.gpc[0].get_global_sens(coeffs=coeffs,
-                                                                  n_samples=n_samples)
-
-            # determine pdfs
-            if calc_pdf:
-                pdf_x[:, ], pdf_y[:, ] = session.gpc[0].get_pdf(coeffs=coeffs,
-                                                                n_samples=n_samples,
-                                                                output_idx=output_idx)
-
-            # determine mean
-            mean = session.gpc[0].get_mean(samples=res)
-
-            # determine standard deviation
-            std = session.gpc[0].get_std(samples=res)
-
-        else:
-            raise AssertionError("Please use ""sampling"" algorithm in case of multi-element gPC!")
-
-    elif session.qoi_specific and session.gpc_type == "megpc":
-
-        pdf_x = np.zeros((100, len(output_idx)))
-        pdf_y = np.zeros((100, len(output_idx)))
-        global_sens = np.zeros((dim, len(output_idx)))
-
-        if algorithm == "sampling":
-
-            res = np.zeros((grid.coords_norm.shape[0], len(output_idx)))
-
-            # loop over qoi (there may be different approximations and projections)
-            for i, idx in enumerate(output_idx):
-
-                # run model evaluations
-                res[:, i] = session.gpc[idx].get_approximation(coeffs=coeffs["qoi_" + str(idx)],
-                                                               x=grid.coords_norm).flatten()
-
-                # determine Sobol indices
-                if calc_sobol:
-                    sobol_qoi, sobol_idx_qoi, sobol_idx_bool_qoi = \
-                        session.gpc[idx].get_sobol_indices(coeffs=coeffs["qoi_" + str(idx)],
-                                                           n_samples=n_samples)
-
-                # rearrange sobol indices according to first qoi (reference)
-                # (they are sorted w.r.t. highest contribution and this may change between qoi)
-                if i == 0:
-                    sobol = copy.deepcopy(sobol_qoi)
-                    sobol_idx = copy.deepcopy(sobol_idx_qoi)
-                    sobol_idx_bool = copy.deepcopy(sobol_idx_bool_qoi)
-
-                else:
-                    sobol = np.hstack((sobol, np.zeros((sobol.shape[0], 1))))
-                    sobol_sort_idx = []
-                    for ii, s_idx in enumerate(sobol_idx):
-                        for jj, s_idx_qoi in enumerate(sobol_idx_qoi):
-                            if (s_idx == s_idx_qoi).all():
-                                sobol_sort_idx.append(jj)
-
-                    for jj, s in enumerate(sobol_sort_idx):
-                        sobol[jj, i] = sobol_qoi[s]
-
-                # determine global derivative based sensitivity coefficients
-                if calc_global_sens:
-                    global_sens[:, ] = session.gpc[idx].get_global_sens(coeffs=coeffs["qoi_" + str(idx)],
-                                                                        n_samples=n_samples)
-
-                # determine pdfs
-                if calc_pdf:
-                    pdf_x[:, ], pdf_y[:, ] = session.gpc[idx].get_pdf(coeffs=coeffs["qoi_" + str(idx)],
-                                                                      n_samples=n_samples,
-                                                                      output_idx=0)
-
-            # determine mean
-            mean = session.gpc[0].get_mean(samples=res)
-
-            # determine standard deviation
-            std = session.gpc[0].get_std(samples=res)
-
-        else:
-            raise AssertionError("Please use ""sampling"" algorithm in case of multi-element gPC!")
-
-    # determine relative standard deviation
-    rstd = std / mean
-
-    # determine variance
-    var = std ** 2
-
-    print("> Adding results to: {}".format(fn_gpc + ".hdf5"))
-    # save results in .hdf5 file (overwrite existing quantities in sens/...)
-    with h5py.File(fn_gpc + ".hdf5", 'a') as f:
-
-        try:
-            del f["sens"]
-        except KeyError:
-            pass
-
-        f.create_dataset(data=mean, name="sens/mean")
-        f.create_dataset(data=std, name="sens/std")
-        f.create_dataset(data=rstd, name="sens/rstd")
-        f.create_dataset(data=var, name="sens/var")
-
-        if algorithm == "sampling":
-            f.create_dataset(data=grid.coords_norm, name="sens/coords_norm")
-            f.create_dataset(data=res, name="sens/res")
-
-        if calc_sobol:
-            f.create_dataset(data=sobol * var, name="sens/sobol")
-            f.create_dataset(data=sobol, name="sens/sobol_norm")
-            f.create_dataset(data=sobol_idx_bool, name="sens/sobol_idx_bool")
-
-        if calc_global_sens:
-            f.create_dataset(data=global_sens, name="sens/global_sens")
-
-        if calc_pdf:
-            f.create_dataset(data=pdf_x, name="sens/pdf_x")
-            f.create_dataset(data=pdf_y, name="sens/pdf_y")
-
-
-def get_extracted_sobol_order(sobol, sobol_idx_bool, order=1):
-    """
-    Extract Sobol indices with specified order from Sobol data.
-
-    Parameters
-    ----------
-    sobol: ndarray of float [n_sobol x n_out]
-        Sobol indices of n_out output quantities
-    sobol_idx_bool: list of ndarray of bool
-        Boolean mask which contains unique multi indices.
-    order: int, optional, default=1
-        Sobol index order to extract
-
-    Returns
-    -------
-    sobol_n_order: ndarray of float [n_out]
-        n-th order Sobol indices of n_out output quantities
-    sobol_idx_n_order: ndarray of int
-        Parameter label indices belonging to n-th order Sobol indices
-    """
-
-    sobol_idx = [np.argwhere(sobol_idx_bool[i, :]).flatten() for i in range(sobol_idx_bool.shape[0])]
-
-    # make mask of nth order sobol indices
-    mask = [index for index, sobol_element in enumerate(sobol_idx) if sobol_element.shape[0] == order]
-
-    # extract from dataset
-    sobol_n_order = sobol[mask, :]
-    sobol_idx_n_order = np.array([sobol_idx[m] for m in mask])
-
-    # sort sobol indices according to parameter indices in ascending order
-    sort_idx = np.argsort(sobol_idx_n_order, axis=0)[:, 0]
-    sobol_n_order = sobol_n_order[sort_idx, :]
-    sobol_idx_n_order = sobol_idx_n_order[sort_idx, :]
-
-    return sobol_n_order, sobol_idx_n_order
-
-
-def get_sobol_composition(sobol, sobol_idx_bool, random_vars=None, verbose=False):
-    """
-    Determine average ratios of Sobol indices over all output quantities:
-    (i) over all orders and (e.g. 1st: 90%, 2nd: 8%, 3rd: 2%)
-    (ii) for the 1st order indices w.r.t. each random variable. (1st: x1: 50%, x2: 40%)
-
-
-    Parameters
-    ----------
-    sobol : ndarray of float [n_sobol x n_out]
-        Unnormalized sobol_indices
-    sobol_idx_bool : list of ndarray of bool
-        Boolean mask which contains unique multi indices.
-    random_vars : list of str
-        Names of random variables in the order as they appear in the OrderedDict from the Problem class
-    verbose : boolean, optional, default=True
-        Print output info
-
-    Returns
-    -------
-    sobol_rel_order_mean: ndarray of float [n_out]
-        Average proportion of the Sobol indices of the different order to the total variance (1st, 2nd, etc..,),
-        (over all output quantities)
-    sobol_rel_order_std: ndarray of float [n_out]
-        Standard deviation of the proportion of the Sobol indices of the different order to the total variance
-        (1st, 2nd, etc..,), (over all output quantities)
-    sobol_rel_1st_order_mean: ndarray of float [n_out]
-        Average proportion of the random variables of the 1st order Sobol indices to the total variance,
-        (over all output quantities)
-    sobol_rel_1st_order_std: ndarray of float [n_out]
-        Standard deviation of the proportion of the random variables of the 1st order Sobol indices to the total
-        variance
-        (over all output quantities)
-    sobol_rel_2nd_order_mean: ndarray of float [n_out]
-        Average proportion of the random variables of the 2nd order Sobol indices to the total variance,
-        (over all output quantities)
-    sobol_rel_2nd_order_std: ndarray of float [n_out]
-        Standard deviation of the proportion of the random variables of the 2nd order Sobol indices to the total
-        variance
-        (over all output quantities)
-    """
-
-    # sobol_idx = [np.argwhere(sobol_idx_bool[i, :]).flatten() for i in range(sobol_idx_bool.shape[0])]
-
-    # get max order
-    order_max = np.max(np.sum(sobol_idx_bool, axis=1))
-
-    # total variance
-    var = np.sum(sobol, axis=0).flatten()
-
-    # get NaN values
-    not_nan_mask = np.logical_not(np.isnan(var))
-
-    sobol_rel_order_mean = []
-    sobol_rel_order_std = []
-    sobol_rel_1st_order_mean = []
-    sobol_rel_1st_order_std = []
-    sobol_rel_2nd_order_mean = []
-    sobol_rel_2nd_order_std = []
-    str_out = []
-
-    # get maximum length of random_vars label
-    if random_vars is not None:
-        max_len = max([len(p) for p in random_vars])
-
-    for i in range(order_max):
-        # extract sobol coefficients of order i
-        sobol_extracted, sobol_extracted_idx = get_extracted_sobol_order(sobol, sobol_idx_bool, i + 1)
-
-        # determine average sobol index over all elements
-        sobol_rel_order_mean.append(np.sum(np.sum(sobol_extracted[:, not_nan_mask], axis=0).flatten()) /
-                                    np.sum(var[not_nan_mask]))
-
-        sobol_rel_order_std.append(np.std(np.sum(sobol_extracted[:, not_nan_mask], axis=0).flatten() /
-                                          var[not_nan_mask]))
-
-        iprint("Ratio: Sobol indices order {} / total variance: {:.4f} +- {:.4f}"
-               .format(i+1, sobol_rel_order_mean[i], sobol_rel_order_std[i]), tab=0, verbose=verbose)
-
-        # for 1st order indices, determine ratios of all random variables
-        if i == 0:
-            sobol_extracted_idx_1st = sobol_extracted_idx[:]
-            for j in range(sobol_extracted.shape[0]):
-                sobol_rel_1st_order_mean.append(np.sum(sobol_extracted[j, not_nan_mask].flatten())
-                                                / np.sum(var[not_nan_mask]))
-                sobol_rel_1st_order_std.append(0)
-
-                if random_vars is not None:
-                    str_out.append("\t{}{}: {:.4f}"
-                                   .format((max_len - len(random_vars[sobol_extracted_idx_1st[j][0]])) * ' ',
-                                           random_vars[sobol_extracted_idx_1st[j][0]],
-                                           sobol_rel_1st_order_mean[j]))
-
-        # for 2nd order indices, determine ratios of all random variables
-        if i == 1:
-            for j in range(sobol_extracted.shape[0]):
-                sobol_rel_2nd_order_mean.append(np.sum(sobol_extracted[j, not_nan_mask].flatten())
-                                                / np.sum(var[not_nan_mask]))
-                sobol_rel_2nd_order_std.append(0)
-
-    sobol_rel_order_mean = np.array(sobol_rel_order_mean)
-    sobol_rel_1st_order_mean = np.array(sobol_rel_1st_order_mean)
-    sobol_rel_2nd_order_mean = np.array(sobol_rel_2nd_order_mean)
-
-    # print output of 1st order Sobol indices ratios of parameters
-    if verbose:
-        for j in range(len(str_out)):
-            print(str_out[j])
-
-    return sobol_rel_order_mean, sobol_rel_order_std, \
-           sobol_rel_1st_order_mean, sobol_rel_1st_order_std, \
-           sobol_rel_2nd_order_mean, sobol_rel_2nd_order_std
-
-
-def get_sens_summary(fn_gpc, parameters_random, fn_out=None):
-    """
-    Print summary of Sobol indices and global derivative based sensitivity coefficients
-
-    Parameters
-    ----------
-    fn_gpc : str
-        Filename of gpc results file (without .hdf5 extension)
-    parameters_random: OrderedDict containing the RandomParameter class instances
-        Dictionary (ordered) containing the properties of the random parameters
-    fn_out : str
-        Filename of output .txt file containing the Sobol coefficient summary
-
-    Returns
-    -------
-    sobol : pandas DataFrame
-        Pandas DataFrame containing the normalized Sobol indices by significance
-    gsens : pandas DataFrame
-        Pandas DataFrame containing the global derivative based sensitivity coefficients
-    """
-
-    parameter_names = list(parameters_random.keys())
-
-    with h5py.File(fn_gpc + ".hdf5", "r") as f:
-        sobol_idx_bool = f["/sens/sobol_idx_bool"][:]
-        sobol_norm = f["/sens/sobol_norm"][:]
-        global_sens = f["/sens/global_sens"][:]
-
-    global_sens_sort_idx = np.flip(np.argsort(global_sens[:, 0]))
-
-    sobol_dict = OrderedDict()
-    p_length = []
-    params = []
-
-    # Extract Sobol coefficients
-    for i_s, s in enumerate(sobol_norm):
-        params.append([p for i_p, p in enumerate(parameter_names) if sobol_idx_bool[i_s, i_p]])
-        sobol_dict[str(params[-1])] = s
-        p_length.append(len(str(params[-1])))
-
-    sobol = pd.DataFrame.from_dict(sobol_dict, orient="index", columns=[f"sobol_norm (qoi {i})"
-                                                                        for i in range(sobol_norm.shape[1])])
-    len_max = np.max(p_length)
-
-    # Extract global derivative sensitivity coefficients
-    gsens_dict = OrderedDict()
-    for i_p, p in enumerate(parameter_names):
-        gsens_dict[p] = global_sens[i_p, :]
-
-    gsens = pd.DataFrame.from_dict(gsens_dict, orient="index", columns=[f"global_sens (qoi {i})"
-                                                                        for i in range(sobol_norm.shape[1])])
-
-    # write output file
-    if fn_out:
-        # Sobol indices
-        sep = " " * 4
-        sobol_text = []
-        sobol_text.append("Normalized Sobol indices:\n")
-        sobol_text.append("=" * (len_max + 10) + "\n")
-
-        for i_p, p in enumerate(params):
-            len_diff = len_max - p_length[i_p]
-            sobol_text.append(f"{str(p)}: " + " " * len_diff)
-            for i_qoi in range(sobol_norm.shape[1]):
-                sobol_text[-1] += sep + f"{sobol_norm[i_p, i_qoi]:.6f}"
-            sobol_text.append("\n")
-
-        len_max_sobol = np.max([len(line) for line in sobol_text])
-        sobol_text[1] = "=" * (len_max_sobol) + "\n"
-
-        # Derivative based sensitivity coefficients
-        gsens_text = []
-        gsens_text.append("Average derivatives:\n")
-        gsens_text.append("=" * (len_max + 10) + "\n")
-
-        for i_p, p in enumerate(parameter_names):
-            len_diff = len_max - len(parameter_names[global_sens_sort_idx[i_p]]) - 4
-
-            gsens_text.append(f"['{str(parameter_names[global_sens_sort_idx[i_p]])}']: " + " " * len_diff)
-            for i_qoi in range(sobol_norm.shape[1]):
-                if global_sens[global_sens_sort_idx[i_p]][0] < 0:
-                    sep = " " * 3
-                else:
-                    sep = " " * 4
-                gsens_text[-1] += sep + f"{global_sens[global_sens_sort_idx[i_p], i_qoi]:.2e}"
-            gsens_text.append("\n")
-
-        len_max_gsens = np.max([len(line) for line in gsens_text])
-        gsens_text[1] = "=" * (len_max_gsens) + "\n"
-
-        # write in file
-        with open(fn_out, 'w') as f:
-            for line in sobol_text:
-                f.write(line)
-            f.write("\n")
-            for line in gsens_text:
-                f.write(line)
-
-    return sobol, gsens
-
-
-def plot_sens_summary(sobol, gsens, session=None, coeffs=None, qois=None, mean=None, std=None, output_idx=None,
-                      y_label="y", x_label="x", zlim=None, sobol_donut=True, plot_pdf_over_output_idx=False,
-                      fn_plot=None):
-    """
-    Plot summary of Sobol indices and global derivative based sensitivity coefficients
-
-    Parameters
-    ----------
-    session : GPC Session object instance
-        GPC session object containing all information i.e., gPC, Problem, Model, Grid, Basis, RandomParameter instances
-    coeffs : ndarray of float [n_coeffs x n_out] or list of ndarray of float [n_qoi][n_coeffs x n_out]
-        GPC coefficients
-    sobol : pandas DataFrame
-        Pandas DataFrame containing the normalized Sobol indices from get_sens_summary()
-    gsens: pandas DataFrame
-        Pandas DataFrame containing the global derivative based sensitivity coefficients from get_sens_summary()
-    sobol_donut : Boolean
-        Option to plot the sobol indices as donut (pie) chart instead of bars, default is True
-    multiple_qoi: Boolean
-        Option to plot over a quantity of interest, needs an array of qoi values and results
-    qois: numpy ndarray
-        Axis of quantities of interest (x-axis, e.g. time)
-    mean: numpy ndarray
-        Mean from gpc session (determined with e.g.: pygpc.SGPC.get_mean(coeffs))
-    std: numpy ndarray
-        Std from gpc session (determined with e.g.: pygpc.SGPC.get_std(coeffs))
-        (can be given and plotted when plot_pdf_over_output_idx=False)
-    output_idx : int, str or None, optional, default=0
-        Indices of output quantity to consider
-    x_label : str
-        Label of x-axis in case of multiple QOI plots
-    y_label : str
-        Label of y-axis in case of multiple QOI plots
-    zlim : list of float, optional, default: None
-        Limits of 3D plot (e.g. pdf) in z direction
-    plot_pdf_over_output_idx : bool, optional, default: False
-        Plots pdf as a surface plot over output index (e.g. a time axis)
-    fn_plot : str, optional, default: None
-        Filename of the plot to save (.png or .pdf)
-    """
-    import matplotlib.pyplot as plt
-
-    if type(output_idx) is int:
-        output_idx = [output_idx]
-
-    if output_idx is None or output_idx == "all":
-        if coeffs is not None:
-            output_idx = np.arange(coeffs.shape[1])
-        else:
-            output_idx = np.array([0])
-
-    glob_sens = gsens.values[:, output_idx].flatten()
-    gsens_keys = gsens["global_sens (qoi 0)"].keys()
-
-    sobols = sobol.values[:, output_idx].flatten()
-    sobol_keys = sobol["sobol_norm (qoi 0)"].keys()
-
-    # ignore very low Sobol indices
-    mask = sobols >= 0.001
-
-    # format keys for plot ticks
-    sobol_labels = [(x[1:-1].replace("'", " ")).replace(" ,", ",") for x in sobol_keys]
-
-    sobols = sobols[mask]
-    sobol_labels = [s for i, s in enumerate(sobol_labels) if mask[i]]
-
-    if len(output_idx) == 1:
-        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(7, 7))
-        if sobol_donut:
-            wedgeprops = {"linewidth": 0.5, 'width': 0.5, "edgecolor": "k"}
-            wedges, texts = ax1.pie(sobols, wedgeprops=wedgeprops, startangle=-40)
-            bbox_props = dict(boxstyle="square,pad=0.3", fc="w", ec="w", lw=0.72)
-            kw = dict(arrowprops=dict(arrowstyle="-"), bbox=bbox_props, zorder=0, va="center")
-
-            last_label = False
-            for i, p in enumerate(wedges):
-                ang = (p.theta2 - p.theta1) / 2. + p.theta1
-
-                if not last_label:
-                    y = np.sin(np.deg2rad(ang))
-                    x = np.cos(np.deg2rad(ang))
-                    horizontalalignment = {-1: "right", 1: "left"}[int(np.sign(x))]
-                    connectionstyle = "angle,angleA=0,angleB={}".format(ang)
-                    kw["arrowprops"].update({"connectionstyle": connectionstyle})
-                    ax1.annotate(sobol_labels[i] + f" ({sobols[i]*100:.1f}%)", xy=(x, y), xytext=(1.35 * np.sign(x), 1.4 * y),
-                                horizontalalignment=horizontalalignment, **kw)
-                    if ang > 310:
-                        last_label = True
-
-            # for i, p in enumerate(wedges):
-            #     ang = (p.theta2 - p.theta1) / 2. + p.theta1
-            #     y = np.sin(np.deg2rad(ang))
-            #     x = np.cos(np.deg2rad(ang))
-            #     horizontalalignment = {-1: "right", 1: "left"}[int(np.sign(x))]
-            #     connectionstyle = "angle,angleA=0,angleB={}".format(ang)
-            #     kw["arrowprops"].update({"connectionstyle": connectionstyle})
-            #     ax1.annotate(sobol_labels[i], xy=(x, y), xytext=(1.35 * np.sign(x), 1.4 * y),
-            #                 horizontalalignment=horizontalalignment, **kw)
-
-            # ax1.legend(wedges, sobol_labels,
-            #           title="Parameter",
-            #           loc="center left",
-            #           bbox_to_anchor=(1, 0, 0.5, 1))
-
-            ax1.set_title("Normalized Sobol indices")
-        else:
-            ax1.bar(np.arange(len(sobol_keys)) + 1, sobols, width=0.8)
-            ax1.set_xticklabels([" "] + sobol_labels)
-            ax1.set_yscale('log')
-            ax1.set_ylabel('Sobol indices', fontsize=14)
-            ax1.set_xlabel('parameter', fontsize=14)
-            ax1.set_xlim(0, len(sobol_keys) + 1)
-            ax1.set_ylim(0., 1.0)
-        ax2.bar(np.arange(len(gsens_keys)) + 1, glob_sens, color='orange')
-        ax2.set_xticks(list(np.arange(len(gsens_keys)) + 1))
-        ax2.set_xticklabels(list(gsens_keys))
-        ax2.set_ylabel('global sensitivities', fontsize=14)
-        ax2.set_xlabel('parameter', fontsize=14)
-        ax2.axhline(y=0, color='k', alpha=0.5)
-        plt.tight_layout()
-
-    else:
-        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=[8, 9])
-
-        # Estimate output pdf
-        if plot_pdf_over_output_idx:
-            if session.qoi_specific:
-                pdf_x = np.zeros((100, len(output_idx)))
-                pdf_y = np.zeros((100, len(output_idx)))
-
-                for i, o_idx in enumerate(output_idx):
-                    pdf_x_tmp, pdf_y_tmp = session.gpc[o_idx].get_pdf(coeffs=coeffs[o_idx], n_samples=1e5, output_idx=0)
-                    pdf_x[:, i] = pdf_x_tmp.flatten()
-                    pdf_y[:, i] = pdf_y_tmp.flatten()
-            else:
-                pdf_x, pdf_y, _, y_gpc_samples = session.gpc[0].get_pdf(coeffs=coeffs,
-                                                                        n_samples=1e5,
-                                                                        output_idx=output_idx,
-                                                                        return_samples=True)
-
-            # interpolate pdf data on common grid
-            x_interp = np.linspace(0, np.max(pdf_x), 1000)
-            y_interp = np.zeros((len(x_interp), np.shape(pdf_x)[1]))
-
-            for i in range(np.shape(pdf_x)[1]):
-                y_interp[:, i] = np.interp(x_interp, pdf_x[:, i], pdf_y[:, i], left=0, right=0)
-
-            if zlim is not None:
-                vmin = zlim[0]
-                vmax = zlim[1]
-            else:
-                vmin = np.min(y_interp)
-                vmax = np.max(y_interp)
-
-            if qois is not None:
-                x_axis = qois
-            else:
-                x_axis = np.arange(0, len(output_idx))
-
-            xx, yy = np.meshgrid(x_axis, x_interp)
-
-            # plot pdf over output_idx
-            ax1.pcolor(xx, yy, y_interp, cmap="bone_r", vmin=vmin, vmax=vmax)
-            ax1.plot(x_axis, mean, "r", linewidth=1.5)
-            legend_elements = [matplotlib.lines.Line2D([0], [0], color='r', lw=2, label='mean'),
-                               matplotlib.patches.Patch(facecolor='grey', edgecolor='k', label='pdf')]
-            ax1.legend(handles=legend_elements)
-
-            ax1.grid()
-
-            if x_label is not None:
-                ax1.set_xlabel(x_label, fontsize=14)
-
-            if y_label is not None:
-                ax1.set_ylabel(y_label, fontsize=14)
-
-        else:
-            # mean and std
-            ax1.plot(qois, mean)
-            ax1.grid()
-            ax1.set_ylabel(y_label, fontsize=14)
-            ax1.set_xlabel(x_label, fontsize=14)
-            ax1.legend(["mean of " + y_label], loc='upper left')
-            ax1.set_xlim(qois[0], qois[-1] + (np.max(qois[-1]) * 1e-3))
-            ax1.set_title("Mean and standard deviation of " + y_label, fontsize=14)
-            # ax2.set_ylim(np.min(results) + np.max(std_results), np.max(results) + np.max(std_results))
-            ax1.fill_between(qois, mean - std, mean + std, color="grey", alpha=0.5)
-
-        # sobol
-        for i in range(sobol.values.shape[0]):
-            ax2.plot(qois, sobol.values[i])
-            ax2.set_title("Sobol indices of the parameters over the qois", fontsize=14)
-            ax2.set_xlabel(x_label, fontsize=14)
-            ax2.set_ylabel("Sobol index", fontsize=14)
-            ax2.set_yscale('log')
-        sobol_labels = [(x[1:-1].replace("'", " ")).replace(" ,", ",") for x in sobol_keys]
-        ax2.legend(sobol_labels)
-        # ax1.legend(sobol['sobol_norm (qoi 0)'].keys())
-        ax2.set_xlim(qois[0], qois[-1] + (np.max(qois[-1]) * 1e-3))
-        ax2.grid()
-
-        # gsens
-        for i in range(gsens.values.shape[0]):
-            ax3.plot(qois, gsens.values[i])
-            ax3.set_title("Global derivatives of the parameters over the qois", fontsize=14)
-            ax3.set_xlabel(x_label, fontsize=14)
-            ax3.set_ylabel("Global sensitivity", fontsize=14)
-            # ax3.set_yscale('log')
-        gsens_labels = [x for x in gsens_keys]
-        ax3.legend(gsens_labels)
-        # ax1.legend(sobol['sobol_norm (qoi 0)'].keys())
-        ax3.set_xlim(qois[0], qois[-1] + (np.max(qois[-1]) * 1e-3))
-        ax3.grid()
-        plt.tight_layout()
-
-    if fn_plot is not None:
-        plt.savefig(fn_plot, dpi=600)
-        plt.close()
-
-
-def plot_gpc(session, coeffs, random_vars=None, coords=None, results=None, n_grid=None, output_idx=0, fn_plot=None,
-             camera_pos=None, zlim=None, plot_pdf_over_output_idx=False, qois=None, x_label=None, y_label=None):
-    """
-    Compares gPC approximation with original model function. Evaluates both at n_grid (x n_grid) sampling points and
-    calculate the difference between two solutions at the output quantity with output_idx and saves the plot as
-    *_QOI_idx_<output_idx>.png/pdf. Also generates one .hdf5 results file with the evaluation results.
-
-    Parameters
-    ----------
-    session : GPC Session object instance
-        GPC session object containing all information i.e., gPC, Problem, Model, Grid, Basis, RandomParameter instances
-    coeffs : ndarray of float [n_coeffs x n_out] or list of ndarray of float [n_qoi][n_coeffs x n_out]
-        GPC coefficients
-    random_vars: str or list of str [2]
-        Names of the random variables, the analysis is performed for one or max. two random variables
-    n_grid : int or list of int [2], optional
-        Number of samples in each dimension to compare the gPC approximation with the original model function.
-        A cartesian grid is generated based on the limits of the specified random_vars
-    coords : ndarray of float [n_coords x n_dim]
-        Parameter combinations for the random_vars the comparison is conducted with
-    output_idx : int, str or None, optional, default=0
-        Indices of output quantity to consider
-    results: ndarray of float [n_coords x n_out]
-        If available, data of original model function at grid, containing all QOIs
-    fn_plot : str, optional, default: None
-        Filename of plot comparing original vs gPC model (*.png or *.pdf)
-    camera_pos : list [2], optional, default: None
-        Camera position of 3D surface plot (for 2 random variables only) [azimuth, elevation]
-    zlim : list of float, optional, default: None
-        Limits of 3D plot (e.g. pdf) in z direction
-    plot_pdf_over_output_idx : bool, optional, default: False
-        Plots pdf as a surface plot over output index (e.g. a time axis)
-    qois: numpy ndarray
-        Axis of quantities of interest (x-axis, e.g. time)
-    x_label : str
-        Label of x-axis in case of multiple QOI plots
-    y_label : str
-        Label of y-axis in case of multiple QOI plots
-
-    Returns
-    -------
-    <file> : .hdf5 file
-        Data file containing the grid points and the results of the original and the gpc approximation
-    <file> : .png and .pdf file
-        Plot comparing original vs gPC model
-    """
-    y_orig = None
-
-    if type(output_idx) is int:
-        output_idx = [output_idx]
-
-    if output_idx is None or output_idx == "all":
-        output_idx = np.arange(coeffs.shape[1])
-
-    if random_vars is not None:
-        if type(random_vars) is not list:
-            random_vars = random_vars.tolist()
-        assert len(random_vars) <= 2
-
-    if n_grid is not None:
-        if n_grid and type(n_grid) is not list:
-            n_grid = n_grid.tolist()
-    else:
-        n_grid = [10, 10]
-
-    if random_vars is not None:
-        # Create grid such that it includes the mean values of other random variables
-        grid = np.zeros((np.prod(n_grid), len(session.parameters_random)))
-
-        idx = []
-        idx_global = []
-
-        # sort random_vars according to gpc.parameters
-        for i_p, p in enumerate(session.parameters_random.keys()):
-            if p not in random_vars:
-                grid[:, i_p] = session.parameters_random[p].mean
-
-            else:
-                idx.append(random_vars.index(p))
-                idx_global.append(i_p)
-
-        random_vars = [random_vars[i] for i in idx]
-        x = []
-
-        for i_p, p in enumerate(random_vars):
-            x.append(np.linspace(session.parameters_random[p].pdf_limits[0],
-                                 session.parameters_random[p].pdf_limits[1],
-                                 n_grid[i_p]))
-
-        coords_gpc = get_cartesian_product(x)
-        if len(random_vars) == 2:
-            x1_2d, x2_2d = np.meshgrid(x[0], x[1])
-
-        grid[:, idx_global] = coords_gpc
-
-        # Normalize grid
-        grid_norm = Grid(parameters_random=session.parameters_random).get_normalized_coordinates(grid)
-
-    # Evaluate gPC expansion on grid and estimate output pdf
-    if session.qoi_specific:
-        y_gpc = np.zeros((grid_norm.shape[0], len(output_idx)))
-        pdf_x = np.zeros((100, len(output_idx)))
-        pdf_y = np.zeros((100, len(output_idx)))
-
-        for i, o_idx in enumerate(output_idx):
-            y_gpc[:, i] = session.gpc[o_idx].get_approximation(coeffs=coeffs[o_idx], x=grid_norm,
-                                                               output_idx=0).flatten()
-
-            pdf_x_tmp, pdf_y_tmp = session.gpc[o_idx].get_pdf(coeffs=coeffs[o_idx], n_samples=1e5, output_idx=0)
-            pdf_x[:, i] = pdf_x_tmp.flatten()
-            pdf_y[:, i] = pdf_y_tmp.flatten()
-    else:
-        if not plot_pdf_over_output_idx:
-            y_gpc = session.gpc[0].get_approximation(coeffs=coeffs,
-                                                     x=grid_norm,
-                                                     output_idx=output_idx)
-
-        pdf_x, pdf_y, _, y_gpc_samples = session.gpc[0].get_pdf(coeffs=coeffs,
-                                                                n_samples=1e5,
-                                                                output_idx=output_idx,
-                                                                return_samples=True)
-
-    if not plot_pdf_over_output_idx:
-        if results is not None:
-            y_orig = results[:, output_idx]
-
-            if y_orig.ndim == 1:
-                y_orig = y_orig[:, np.newaxis]
-
-        # add axes if necessary
-        if y_gpc.ndim == 1:
-            y_gpc = y_gpc[:, np.newaxis]
-
-    # Plot results
-    matplotlib.rc('text', usetex=False)
-    matplotlib.rc('xtick', labelsize=13)
-    matplotlib.rc('ytick', labelsize=13)
-    fs = 14
-
-    if plot_pdf_over_output_idx:
-        # interpolate pdf data on common grid
-        x_interp = np.linspace(0, np.max(pdf_x), 1000)
-        y_interp = np.zeros((len(x_interp), np.shape(pdf_x)[1]))
-
-        for i in range(np.shape(pdf_x)[1]):
-            y_interp[:, i] = np.interp(x_interp, pdf_x[:, i], pdf_y[:, i], left=0, right=0)
-
-        if zlim is not None:
-            vmin = zlim[0]
-            vmax = zlim[1]
-        else:
-            vmin = np.min(y_interp)
-            vmax = np.max(y_interp)
-
-        if qois is not None:
-            x_axis = qois
-        else:
-            x_axis = np.arange(0, len(output_idx))
-
-        xx, yy = np.meshgrid(x_axis, x_interp)
-
-        # plot pdf over output_idx
-        plt.figure(figsize=[10, 6])
-        plt.pcolor(xx, yy, y_interp, cmap="bone_r", vmin=vmin, vmax=vmax)
-        plt.plot(x_axis, np.mean(y_gpc_samples, axis=0), "r", linewidth=1.5)
-        plt.grid()
-
-        if x_label is not None:
-            plt.xlabel(x_label, fontsize=14)
-
-        if y_label is not None:
-            plt.ylabel(y_label, fontsize=14)
-
-        plt.tight_layout()
-
-        if fn_plot is not None:
-            plt.savefig(os.path.splitext(fn_plot)[0] + "_pdf_qoi.png", dpi=1200)
-            plt.savefig(os.path.splitext(fn_plot)[0] + "_pdf_qoi.pdf")
-            plt.close()
-
-    else:
-        for _i, i in enumerate(output_idx):
-            fig = plt.figure(figsize=(12, 5))
-
-            # One random variable
-            if len(random_vars) == 1:
-                ax1 = fig.add_subplot(1, 2, 1)
-                ax1.plot(coords_gpc, y_gpc[:, i])
-                if y_orig is not None:
-                    ax1.scatter(coords[:, idx_global[0]], y_orig[:, _i], s=7 * np.ones(len(y_orig[:, i])),
-                                facecolor='w', edgecolors='k')
-                    legend = [r"gPC", r"original"]
-                else:
-                    legend = [r"gPC"]
-                ax1.legend(legend, fontsize=fs)
-                ax1.set_xlabel(r"%s" % random_vars[0], fontsize=fs)
-                ax1.set_ylabel(r"y(%s)" % random_vars[0], fontsize=fs)
-                ax1.grid()
-
-            # Two random variables
-            elif len(random_vars) == 2:
-                ax1 = fig.add_subplot(1, 2, 1, projection='3d')
-                im1 = ax1.plot_surface(x1_2d, x2_2d, np.reshape(y_gpc[:, _i], (x[1].size, x[0].size), order='f'),
-                                       cmap="jet", alpha=0.75, linewidth=0, edgecolors=None)
-                if y_orig is not None:
-                    ax1.scatter(coords[:, idx_global[0]], coords[:, idx_global[1]], y_orig[:, _i],
-                                'k', alpha=1, edgecolors='k', depthshade=False)
-                ax1.set_title(r'gPC approximation', fontsize=fs)
-                ax1.set_xlabel(r"%s" % random_vars[0], fontsize=fs)
-                ax1.set_ylabel(r"%s" % random_vars[1], fontsize=fs)
-
-                if camera_pos is not None:
-                    ax1.view_init(elev=camera_pos[0], azim=camera_pos[1])
-
-                fig.colorbar(im1, ax=ax1, orientation='vertical')
-
-                if zlim is not None:
-                    ax1.set_zlim(zlim)
-
-            # plot histogram of output data and gPC estimated pdf
-            ax2 = fig.add_subplot(1, 2, 2)
-            if y_orig is not None:
-                ax2.hist(y_orig[:, _i], density=True, bins=20, edgecolor='k')
-            ax2.plot(pdf_x[:, _i], pdf_y[:, _i], 'r')
-            ax2.grid()
-            ax2.set_title("Probability density", fontsize=fs)
-            ax2.set_xlabel(r'$y$', fontsize=16)
-            ax2.set_ylabel(r'$p(y)$', fontsize=16)
-            plt.tight_layout()
-
-            if fn_plot is not None:
-                plt.savefig(os.path.splitext(fn_plot)[0] + "_qoi_" + str(output_idx[i]) + '.png', dpi=1200)
-                plt.savefig(os.path.splitext(fn_plot)[0] + "_qoi_" + str(output_idx[i]) + '.pdf')
-                plt.close()
+import h5py
+import numpy as np
+import pandas as pd
+
+from .Grid import *
+from .MEGPC import *
+from .io import read_session
+
+try:
+    import matplotlib
+except ImportError:
+    pass
+
+def get_sensitivities_hdf5(fn_gpc, output_idx=False, calc_sobol=True, calc_global_sens=False, calc_pdf=False,
+                           algorithm="standard", n_samples=1e5):
+    """
+    Post-processes the gPC expansion from the gPC coefficients (standard) or by sampling. Adds mean,
+    standard deviation, relative standard deviation, variance, Sobol indices, global derivative based
+    sensitivity coefficients and probability density functions of output quantities to .hdf5 file of gPC.
+
+    Parameters
+    ----------
+    fn_gpc : str
+        Filename of gPC .pkl object and corresponding .hdf5 results file (without file extension)
+        (e.g. .../foo/gpc)
+    output_idx : nparray of int
+        Indices of output quantities (QOIs) to consider in postprocessing (default: all)
+    calc_sobol : bool
+        Calculate Sobol indices (default: True)
+    calc_global_sens : bool
+        Calculate global derivative based sensitivities (default: False)
+    calc_pdf : bool
+        Calculate probability density functions of output quantities (default: False)
+    algorithm : str, optional, default: "standard"
+        Algorithm to determine the Sobol indices
+        - "standard": Sobol indices are determined from the gPC coefficients
+        - "sampling": Sobol indices are determined from sampling using Saltelli's Sobol sampling sequence [1, 2, 3]
+    n_samples : int, optional, default: 1e5
+        Number of samples to determine Sobol indices by sampling. The efficient number of samples
+        increases to n_samples * (2*dim + 2) in Saltelli's Sobol sampling sequence.
+
+    Returns
+    -------
+    <File> : .hdf5
+        Adds datasets "sens/..." to the gPC .hdf5 file
+
+    Example
+    -------
+    The content of .hdf5 files can be shown using the tool HDFView
+    (https://support.hdfgroup.org/products/java/hdfview/)
+
+    ::
+        sens
+        I---/mean               [n_qoi]                 Mean of QOIs
+        I---/std                [n_qoi]                 Standard deviation of QOIs
+        I---/rstd               [n_qoi]                 Relative standard deviation of QOIs
+        I---/var                [n_qoi]                 Variance of QOIs
+        I---/sobol              [n_sobol x n_qoi]       Sobol indices (all available orders)
+        I---/sobol_idx_bool     [n_sobol x n_dim]       Corresponding parameter (combinations) of Sobol indices
+        I---/global_sens        [n_dim x n_qoi]         Global derivative based sensitivity coefficients
+        I---/pdf_x              [100 x n_qoi]           x-axis values of output PDFs
+        I---/pdf_y              [100 x n_qoi]           y-axis values of output PDFs
+    """
+    sobol = None
+    sobol_idx_bool = None
+    global_sens = None
+    pdf_x = None
+    pdf_y = None
+    grid = None
+    res = None
+
+    with h5py.File(fn_gpc + ".hdf5", 'r') as f:
+        # filename of associated gPC .pkl files
+        fn_session = os.path.join(os.path.split(fn_gpc)[0], f["misc/fn_session"][0].astype(str))
+        fn_session_folder = f["misc/fn_session_folder"][0].astype(str)
+
+    print("> Loading gpc session object: {}".format(fn_session))
+    session = read_session(fname=fn_session, folder=fn_session_folder)
+
+    with h5py.File(fn_gpc + ".hdf5", 'r') as f:
+        # check if we have qoi specific gPCs here
+        try:
+            if "qoi" in list(f["coeffs"].keys())[0]:
+                qoi_keys = list(f["coeffs"].keys())
+
+        except AttributeError:
+            pass
+
+        # load coeffs depending on gpc type
+        print("> Loading gpc coeffs: {}".format(fn_gpc + ".hdf5"))
+
+        if not session.qoi_specific and not session.gpc_type == "megpc":
+            coeffs = np.array(f['coeffs'][:])
+
+            if not output_idx:
+                output_idx = np.arange(coeffs.shape[1])
+
+        elif not session.qoi_specific and session.gpc_type == "megpc":
+
+            coeffs = [None for _ in range(len(list(f['coeffs'].keys())))]
+
+            for i, d in enumerate(list(f['coeffs'].keys())):
+                coeffs[i] = np.array(f['coeffs/' + str(d)])[:]
+
+            if not output_idx:
+                output_idx = np.arange(coeffs[0].shape[1])
+
+        elif session.qoi_specific and not session.gpc_type == "megpc":
+
+            algorithm = "sampling"
+            coeffs = dict()
+
+            for key in qoi_keys:
+                coeffs[key] = np.array(f['coeffs/' + key])[:]
+
+            if not output_idx:
+                output_idx = np.arange(len(list(coeffs.keys())))
+
+        elif session.qoi_specific and session.gpc_type == "megpc":
+
+            algorithm = "sampling"
+            coeffs = dict()
+
+            for key in qoi_keys:
+                coeffs[key] = [None for _ in range(len(list(f['coeffs/' + key].keys())))]
+
+                for i, d in enumerate(list(f['coeffs/' + key].keys())):
+                    coeffs[key][i] = np.array(f['coeffs/' + key + "/" + str(d)])[:]
+
+            if not output_idx:
+                output_idx = np.arange(len(list(coeffs.keys())))
+
+        dim = f["grid/coords"][:].shape[1]
+
+    # generate samples in case of sampling approach
+    if algorithm == "sampling":
+        grid = Random(parameters_random=session.parameters_random,
+                      n_grid=n_samples,
+                      options=None)
+
+    # start prostprocessing depending on gPC type
+    if not session.qoi_specific and not session.gpc_type == "megpc":
+
+        coeffs = coeffs[:, output_idx]
+
+        if algorithm == "standard":
+            # determine mean
+            mean = session.gpc[0].get_mean(coeffs=coeffs)
+
+            # determine standard deviation
+            std = session.gpc[0].get_std(coeffs=coeffs)
+
+        elif algorithm == "sampling":
+            # run model evaluations
+            res = session.gpc[0].get_approximation(coeffs=coeffs, x=grid.coords_norm)
+
+            # determine mean
+            mean = session.gpc[0].get_mean(samples=res)
+
+            # determine standard deviation
+            std = session.gpc[0].get_std(samples=res)
+
+        else:
+            raise AssertionError("Please provide valid algorithm argument (""standard"" or ""sampling"")")
+
+        # determine Sobol indices
+        if calc_sobol:
+            sobol, sobol_idx, sobol_idx_bool = session.gpc[0].get_sobol_indices(coeffs=coeffs,
+                                                                                algorithm=algorithm,
+                                                                                n_samples=n_samples)
+
+        # determine global derivative based sensitivity coefficients
+        if calc_global_sens:
+            global_sens = session.gpc[0].get_global_sens(coeffs=coeffs,
+                                                         algorithm=algorithm,
+                                                         n_samples=n_samples)
+
+        # determine pdfs
+        if calc_pdf:
+            pdf_x, pdf_y = session.gpc[0].get_pdf(coeffs, n_samples=n_samples, output_idx=output_idx)
+
+    elif session.qoi_specific and not session.gpc_type == "megpc":
+
+        gpc = []
+        pdf_x = np.zeros((100, len(output_idx)))
+        pdf_y = np.zeros((100, len(output_idx)))
+        global_sens = np.zeros((dim, len(output_idx)))
+
+        res = np.zeros((grid.coords_norm.shape[0], len(output_idx)))
+
+        # loop over qoi (there may be different approximations and projections)
+        for i, idx in enumerate(output_idx):
+
+            # run model evaluations
+            res[:, i] = session.gpc[idx].get_approximation(coeffs=coeffs["qoi_" + str(idx)],
+                                                           x=grid.coords_norm).flatten()
+
+            # determine Sobol indices
+            if calc_sobol:
+                sobol_qoi, sobol_idx_qoi, sobol_idx_bool_qoi = \
+                    session.gpc[idx].get_sobol_indices(coeffs=coeffs["qoi_" + str(idx)],
+                                                       algorithm=algorithm,
+                                                       n_samples=n_samples)
+
+            # rearrange sobol indices according to first qoi (reference)
+            # (they are sorted w.r.t. highest contribution and this may change between qoi)
+            if i == 0:
+                sobol = copy.deepcopy(sobol_qoi)
+                sobol_idx = copy.deepcopy(sobol_idx_qoi)
+                sobol_idx_bool = copy.deepcopy(sobol_idx_bool_qoi)
+
+            else:
+                sobol = np.hstack((sobol, np.zeros(sobol.shape)))
+                sobol_sort_idx = []
+                for ii, s_idx in enumerate(sobol_idx):
+                    for jj, s_idx_qoi in enumerate(sobol_idx_qoi):
+                        if (s_idx == s_idx_qoi).all():
+                            sobol_sort_idx.append(jj)
+
+                for jj, s in enumerate(sobol_sort_idx):
+                    sobol[jj, i] = sobol_qoi[s]
+
+            # determine global derivative based sensitivity coefficients
+            if calc_global_sens:
+                global_sens[:, ] = session.gpc[idx].get_global_sens(coeffs=coeffs["qoi_" + str(idx)],
+                                                                    algorithm=algorithm,
+                                                                    n_samples=n_samples)
+
+            # determine pdfs
+            if calc_pdf:
+                pdf_x[:, ], pdf_y[:, ] = session.gpc[idx].get_pdf(coeffs=coeffs["qoi_" + str(idx)],
+                                                                  n_samples=n_samples,
+                                                                  output_idx=0)
+
+        # determine mean
+        mean = gpc.get_mean(samples=res)
+
+        # determine standard deviation
+        std = gpc.get_std(samples=res)
+
+    elif not session.qoi_specific and session.gpc_type == "megpc":
+
+        pdf_x = np.zeros((100, len(output_idx)))
+        pdf_y = np.zeros((100, len(output_idx)))
+        global_sens = np.zeros((dim, len(output_idx)))
+
+        if algorithm == "sampling":
+
+            # run model evaluations
+            res = session.gpc[0].get_approximation(coeffs=coeffs, x=grid.coords_norm)
+
+            # determine Sobol indices
+            if calc_sobol:
+                sobol, sobol_idx, sobol_idx_bool = session.gpc[0].get_sobol_indices(coeffs=coeffs,
+                                                                                    n_samples=n_samples)
+
+            # determine global derivative based sensitivity coefficients
+            if calc_global_sens:
+                global_sens[:, ] = session.gpc[0].get_global_sens(coeffs=coeffs,
+                                                                  n_samples=n_samples)
+
+            # determine pdfs
+            if calc_pdf:
+                pdf_x[:, ], pdf_y[:, ] = session.gpc[0].get_pdf(coeffs=coeffs,
+                                                                n_samples=n_samples,
+                                                                output_idx=output_idx)
+
+            # determine mean
+            mean = session.gpc[0].get_mean(samples=res)
+
+            # determine standard deviation
+            std = session.gpc[0].get_std(samples=res)
+
+        else:
+            raise AssertionError("Please use ""sampling"" algorithm in case of multi-element gPC!")
+
+    elif session.qoi_specific and session.gpc_type == "megpc":
+
+        pdf_x = np.zeros((100, len(output_idx)))
+        pdf_y = np.zeros((100, len(output_idx)))
+        global_sens = np.zeros((dim, len(output_idx)))
+
+        if algorithm == "sampling":
+
+            res = np.zeros((grid.coords_norm.shape[0], len(output_idx)))
+
+            # loop over qoi (there may be different approximations and projections)
+            for i, idx in enumerate(output_idx):
+
+                # run model evaluations
+                res[:, i] = session.gpc[idx].get_approximation(coeffs=coeffs["qoi_" + str(idx)],
+                                                               x=grid.coords_norm).flatten()
+
+                # determine Sobol indices
+                if calc_sobol:
+                    sobol_qoi, sobol_idx_qoi, sobol_idx_bool_qoi = \
+                        session.gpc[idx].get_sobol_indices(coeffs=coeffs["qoi_" + str(idx)],
+                                                           n_samples=n_samples)
+
+                # rearrange sobol indices according to first qoi (reference)
+                # (they are sorted w.r.t. highest contribution and this may change between qoi)
+                if i == 0:
+                    sobol = copy.deepcopy(sobol_qoi)
+                    sobol_idx = copy.deepcopy(sobol_idx_qoi)
+                    sobol_idx_bool = copy.deepcopy(sobol_idx_bool_qoi)
+
+                else:
+                    sobol = np.hstack((sobol, np.zeros((sobol.shape[0], 1))))
+                    sobol_sort_idx = []
+                    for ii, s_idx in enumerate(sobol_idx):
+                        for jj, s_idx_qoi in enumerate(sobol_idx_qoi):
+                            if (s_idx == s_idx_qoi).all():
+                                sobol_sort_idx.append(jj)
+
+                    for jj, s in enumerate(sobol_sort_idx):
+                        sobol[jj, i] = sobol_qoi[s]
+
+                # determine global derivative based sensitivity coefficients
+                if calc_global_sens:
+                    global_sens[:, ] = session.gpc[idx].get_global_sens(coeffs=coeffs["qoi_" + str(idx)],
+                                                                        n_samples=n_samples)
+
+                # determine pdfs
+                if calc_pdf:
+                    pdf_x[:, ], pdf_y[:, ] = session.gpc[idx].get_pdf(coeffs=coeffs["qoi_" + str(idx)],
+                                                                      n_samples=n_samples,
+                                                                      output_idx=0)
+
+            # determine mean
+            mean = session.gpc[0].get_mean(samples=res)
+
+            # determine standard deviation
+            std = session.gpc[0].get_std(samples=res)
+
+        else:
+            raise AssertionError("Please use ""sampling"" algorithm in case of multi-element gPC!")
+
+    # determine relative standard deviation
+    rstd = std / mean
+
+    # determine variance
+    var = std ** 2
+
+    print("> Adding results to: {}".format(fn_gpc + ".hdf5"))
+    # save results in .hdf5 file (overwrite existing quantities in sens/...)
+    with h5py.File(fn_gpc + ".hdf5", 'a') as f:
+
+        try:
+            del f["sens"]
+        except KeyError:
+            pass
+
+        f.create_dataset(data=mean, name="sens/mean")
+        f.create_dataset(data=std, name="sens/std")
+        f.create_dataset(data=rstd, name="sens/rstd")
+        f.create_dataset(data=var, name="sens/var")
+
+        if algorithm == "sampling":
+            f.create_dataset(data=grid.coords_norm, name="sens/coords_norm")
+            f.create_dataset(data=res, name="sens/res")
+
+        if calc_sobol:
+            f.create_dataset(data=sobol * var, name="sens/sobol")
+            f.create_dataset(data=sobol, name="sens/sobol_norm")
+            f.create_dataset(data=sobol_idx_bool, name="sens/sobol_idx_bool")
+
+        if calc_global_sens:
+            f.create_dataset(data=global_sens, name="sens/global_sens")
+
+        if calc_pdf:
+            f.create_dataset(data=pdf_x, name="sens/pdf_x")
+            f.create_dataset(data=pdf_y, name="sens/pdf_y")
+
+
+def get_extracted_sobol_order(sobol, sobol_idx_bool, order=1):
+    """
+    Extract Sobol indices with specified order from Sobol data.
+
+    Parameters
+    ----------
+    sobol: ndarray of float [n_sobol x n_out]
+        Sobol indices of n_out output quantities
+    sobol_idx_bool: list of ndarray of bool
+        Boolean mask which contains unique multi indices.
+    order: int, optional, default=1
+        Sobol index order to extract
+
+    Returns
+    -------
+    sobol_n_order: ndarray of float [n_out]
+        n-th order Sobol indices of n_out output quantities
+    sobol_idx_n_order: ndarray of int
+        Parameter label indices belonging to n-th order Sobol indices
+    """
+
+    sobol_idx = [np.argwhere(sobol_idx_bool[i, :]).flatten() for i in range(sobol_idx_bool.shape[0])]
+
+    # make mask of nth order sobol indices
+    mask = [index for index, sobol_element in enumerate(sobol_idx) if sobol_element.shape[0] == order]
+
+    # extract from dataset
+    sobol_n_order = sobol[mask, :]
+    sobol_idx_n_order = np.array([sobol_idx[m] for m in mask])
+
+    # sort sobol indices according to parameter indices in ascending order
+    sort_idx = np.argsort(sobol_idx_n_order, axis=0)[:, 0]
+    sobol_n_order = sobol_n_order[sort_idx, :]
+    sobol_idx_n_order = sobol_idx_n_order[sort_idx, :]
+
+    return sobol_n_order, sobol_idx_n_order
+
+
+def get_sobol_composition(sobol, sobol_idx_bool, random_vars=None, verbose=False):
+    """
+    Determine average ratios of Sobol indices over all output quantities:
+    (i) over all orders and (e.g. 1st: 90%, 2nd: 8%, 3rd: 2%)
+    (ii) for the 1st order indices w.r.t. each random variable. (1st: x1: 50%, x2: 40%)
+
+
+    Parameters
+    ----------
+    sobol : ndarray of float [n_sobol x n_out]
+        Unnormalized sobol_indices
+    sobol_idx_bool : list of ndarray of bool
+        Boolean mask which contains unique multi indices.
+    random_vars : list of str
+        Names of random variables in the order as they appear in the OrderedDict from the Problem class
+    verbose : boolean, optional, default=True
+        Print output info
+
+    Returns
+    -------
+    sobol_rel_order_mean: ndarray of float [n_out]
+        Average proportion of the Sobol indices of the different order to the total variance (1st, 2nd, etc..,),
+        (over all output quantities)
+    sobol_rel_order_std: ndarray of float [n_out]
+        Standard deviation of the proportion of the Sobol indices of the different order to the total variance
+        (1st, 2nd, etc..,), (over all output quantities)
+    sobol_rel_1st_order_mean: ndarray of float [n_out]
+        Average proportion of the random variables of the 1st order Sobol indices to the total variance,
+        (over all output quantities)
+    sobol_rel_1st_order_std: ndarray of float [n_out]
+        Standard deviation of the proportion of the random variables of the 1st order Sobol indices to the total
+        variance
+        (over all output quantities)
+    sobol_rel_2nd_order_mean: ndarray of float [n_out]
+        Average proportion of the random variables of the 2nd order Sobol indices to the total variance,
+        (over all output quantities)
+    sobol_rel_2nd_order_std: ndarray of float [n_out]
+        Standard deviation of the proportion of the random variables of the 2nd order Sobol indices to the total
+        variance
+        (over all output quantities)
+    """
+
+    # sobol_idx = [np.argwhere(sobol_idx_bool[i, :]).flatten() for i in range(sobol_idx_bool.shape[0])]
+
+    # get max order
+    order_max = np.max(np.sum(sobol_idx_bool, axis=1))
+
+    # total variance
+    var = np.sum(sobol, axis=0).flatten()
+
+    # get NaN values
+    not_nan_mask = np.logical_not(np.isnan(var))
+
+    sobol_rel_order_mean = []
+    sobol_rel_order_std = []
+    sobol_rel_1st_order_mean = []
+    sobol_rel_1st_order_std = []
+    sobol_rel_2nd_order_mean = []
+    sobol_rel_2nd_order_std = []
+    str_out = []
+
+    # get maximum length of random_vars label
+    if random_vars is not None:
+        max_len = max([len(p) for p in random_vars])
+
+    for i in range(order_max):
+        # extract sobol coefficients of order i
+        sobol_extracted, sobol_extracted_idx = get_extracted_sobol_order(sobol, sobol_idx_bool, i + 1)
+
+        # determine average sobol index over all elements
+        sobol_rel_order_mean.append(np.sum(np.sum(sobol_extracted[:, not_nan_mask], axis=0).flatten()) /
+                                    np.sum(var[not_nan_mask]))
+
+        sobol_rel_order_std.append(np.std(np.sum(sobol_extracted[:, not_nan_mask], axis=0).flatten() /
+                                          var[not_nan_mask]))
+
+        iprint("Ratio: Sobol indices order {} / total variance: {:.4f} +- {:.4f}"
+               .format(i+1, sobol_rel_order_mean[i], sobol_rel_order_std[i]), tab=0, verbose=verbose)
+
+        # for 1st order indices, determine ratios of all random variables
+        if i == 0:
+            sobol_extracted_idx_1st = sobol_extracted_idx[:]
+            for j in range(sobol_extracted.shape[0]):
+                sobol_rel_1st_order_mean.append(np.sum(sobol_extracted[j, not_nan_mask].flatten())
+                                                / np.sum(var[not_nan_mask]))
+                sobol_rel_1st_order_std.append(0)
+
+                if random_vars is not None:
+                    str_out.append("\t{}{}: {:.4f}"
+                                   .format((max_len - len(random_vars[sobol_extracted_idx_1st[j][0]])) * ' ',
+                                           random_vars[sobol_extracted_idx_1st[j][0]],
+                                           sobol_rel_1st_order_mean[j]))
+
+        # for 2nd order indices, determine ratios of all random variables
+        if i == 1:
+            for j in range(sobol_extracted.shape[0]):
+                sobol_rel_2nd_order_mean.append(np.sum(sobol_extracted[j, not_nan_mask].flatten())
+                                                / np.sum(var[not_nan_mask]))
+                sobol_rel_2nd_order_std.append(0)
+
+    sobol_rel_order_mean = np.array(sobol_rel_order_mean)
+    sobol_rel_1st_order_mean = np.array(sobol_rel_1st_order_mean)
+    sobol_rel_2nd_order_mean = np.array(sobol_rel_2nd_order_mean)
+
+    # print output of 1st order Sobol indices ratios of parameters
+    if verbose:
+        for j in range(len(str_out)):
+            print(str_out[j])
+
+    return sobol_rel_order_mean, sobol_rel_order_std, \
+           sobol_rel_1st_order_mean, sobol_rel_1st_order_std, \
+           sobol_rel_2nd_order_mean, sobol_rel_2nd_order_std
+
+
+def get_sens_summary(fn_gpc, parameters_random, fn_out=None):
+    """
+    Print summary of Sobol indices and global derivative based sensitivity coefficients
+
+    Parameters
+    ----------
+    fn_gpc : str
+        Filename of gpc results file (without .hdf5 extension)
+    parameters_random: OrderedDict containing the RandomParameter class instances
+        Dictionary (ordered) containing the properties of the random parameters
+    fn_out : str
+        Filename of output .txt file containing the Sobol coefficient summary
+
+    Returns
+    -------
+    sobol : pandas DataFrame
+        Pandas DataFrame containing the normalized Sobol indices by significance
+    gsens : pandas DataFrame
+        Pandas DataFrame containing the global derivative based sensitivity coefficients
+    """
+
+    parameter_names = list(parameters_random.keys())
+
+    with h5py.File(fn_gpc + ".hdf5", "r") as f:
+        sobol_idx_bool = f["/sens/sobol_idx_bool"][:]
+        sobol_norm = f["/sens/sobol_norm"][:]
+        global_sens = f["/sens/global_sens"][:]
+
+    global_sens_sort_idx = np.flip(np.argsort(global_sens[:, 0]))
+
+    sobol_dict = OrderedDict()
+    p_length = []
+    params = []
+
+    # Extract Sobol coefficients
+    for i_s, s in enumerate(sobol_norm):
+        params.append([p for i_p, p in enumerate(parameter_names) if sobol_idx_bool[i_s, i_p]])
+        sobol_dict[str(params[-1])] = s
+        p_length.append(len(str(params[-1])))
+
+    sobol = pd.DataFrame.from_dict(sobol_dict, orient="index", columns=[f"sobol_norm (qoi {i})"
+                                                                        for i in range(sobol_norm.shape[1])])
+    len_max = np.max(p_length)
+
+    # Extract global derivative sensitivity coefficients
+    gsens_dict = OrderedDict()
+    for i_p, p in enumerate(parameter_names):
+        gsens_dict[p] = global_sens[i_p, :]
+
+    gsens = pd.DataFrame.from_dict(gsens_dict, orient="index", columns=[f"global_sens (qoi {i})"
+                                                                        for i in range(sobol_norm.shape[1])])
+
+    # write output file
+    if fn_out:
+        # Sobol indices
+        sep = " " * 4
+        sobol_text = []
+        sobol_text.append("Normalized Sobol indices:\n")
+        sobol_text.append("=" * (len_max + 10) + "\n")
+
+        for i_p, p in enumerate(params):
+            len_diff = len_max - p_length[i_p]
+            sobol_text.append(f"{str(p)}: " + " " * len_diff)
+            for i_qoi in range(sobol_norm.shape[1]):
+                sobol_text[-1] += sep + f"{sobol_norm[i_p, i_qoi]:.6f}"
+            sobol_text.append("\n")
+
+        len_max_sobol = np.max([len(line) for line in sobol_text])
+        sobol_text[1] = "=" * (len_max_sobol) + "\n"
+
+        # Derivative based sensitivity coefficients
+        gsens_text = []
+        gsens_text.append("Average derivatives:\n")
+        gsens_text.append("=" * (len_max + 10) + "\n")
+
+        for i_p, p in enumerate(parameter_names):
+            len_diff = len_max - len(parameter_names[global_sens_sort_idx[i_p]]) - 4
+
+            gsens_text.append(f"['{str(parameter_names[global_sens_sort_idx[i_p]])}']: " + " " * len_diff)
+            for i_qoi in range(sobol_norm.shape[1]):
+                if global_sens[global_sens_sort_idx[i_p]][0] < 0:
+                    sep = " " * 3
+                else:
+                    sep = " " * 4
+                gsens_text[-1] += sep + f"{global_sens[global_sens_sort_idx[i_p], i_qoi]:.2e}"
+            gsens_text.append("\n")
+
+        len_max_gsens = np.max([len(line) for line in gsens_text])
+        gsens_text[1] = "=" * (len_max_gsens) + "\n"
+
+        # write in file
+        with open(fn_out, 'w') as f:
+            for line in sobol_text:
+                f.write(line)
+            f.write("\n")
+            for line in gsens_text:
+                f.write(line)
+
+    return sobol, gsens
+
+
+def plot_sens_summary(sobol, gsens, session=None, coeffs=None, qois=None, mean=None, std=None, output_idx=None,
+                      y_label="y", x_label="x", zlim=None, sobol_donut=True, plot_pdf_over_output_idx=False,
+                      fn_plot=None):
+    """
+    Plot summary of Sobol indices and global derivative based sensitivity coefficients
+
+    Parameters
+    ----------
+    session : GPC Session object instance
+        GPC session object containing all information i.e., gPC, Problem, Model, Grid, Basis, RandomParameter instances
+    coeffs : ndarray of float [n_coeffs x n_out] or list of ndarray of float [n_qoi][n_coeffs x n_out]
+        GPC coefficients
+    sobol : pandas DataFrame
+        Pandas DataFrame containing the normalized Sobol indices from get_sens_summary()
+    gsens: pandas DataFrame
+        Pandas DataFrame containing the global derivative based sensitivity coefficients from get_sens_summary()
+    sobol_donut : Boolean
+        Option to plot the sobol indices as donut (pie) chart instead of bars, default is True
+    multiple_qoi: Boolean
+        Option to plot over a quantity of interest, needs an array of qoi values and results
+    qois: numpy ndarray
+        Axis of quantities of interest (x-axis, e.g. time)
+    mean: numpy ndarray
+        Mean from gpc session (determined with e.g.: pygpc.SGPC.get_mean(coeffs))
+    std: numpy ndarray
+        Std from gpc session (determined with e.g.: pygpc.SGPC.get_std(coeffs))
+        (can be given and plotted when plot_pdf_over_output_idx=False)
+    output_idx : int, str or None, optional, default=0
+        Indices of output quantity to consider
+    x_label : str
+        Label of x-axis in case of multiple QOI plots
+    y_label : str
+        Label of y-axis in case of multiple QOI plots
+    zlim : list of float, optional, default: None
+        Limits of 3D plot (e.g. pdf) in z direction
+    plot_pdf_over_output_idx : bool, optional, default: False
+        Plots pdf as a surface plot over output index (e.g. a time axis)
+    fn_plot : str, optional, default: None
+        Filename of the plot to save (.png or .pdf)
+    """
+    import matplotlib.pyplot as plt
+
+    if type(output_idx) is int:
+        output_idx = [output_idx]
+
+    if output_idx is None or output_idx == "all":
+        if coeffs is not None:
+            output_idx = np.arange(coeffs.shape[1])
+        else:
+            output_idx = np.array([0])
+
+    glob_sens = gsens.values[:, output_idx].flatten()
+    gsens_keys = gsens["global_sens (qoi 0)"].keys()
+
+    sobols = sobol.values[:, output_idx].flatten()
+    sobol_keys = sobol["sobol_norm (qoi 0)"].keys()
+
+    # ignore very low Sobol indices
+    mask = sobols >= 0.001
+
+    # format keys for plot ticks
+    sobol_labels = [(x[1:-1].replace("'", " ")).replace(" ,", ",") for x in sobol_keys]
+
+    sobols = sobols[mask]
+    sobol_labels = [s for i, s in enumerate(sobol_labels) if mask[i]]
+
+    if len(output_idx) == 1:
+        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(7, 7))
+        if sobol_donut:
+            wedgeprops = {"linewidth": 0.5, 'width': 0.5, "edgecolor": "k"}
+            wedges, texts = ax1.pie(sobols, wedgeprops=wedgeprops, startangle=-40)
+            bbox_props = dict(boxstyle="square,pad=0.3", fc="w", ec="w", lw=0.72)
+            kw = dict(arrowprops=dict(arrowstyle="-"), bbox=bbox_props, zorder=0, va="center")
+
+            last_label = False
+            for i, p in enumerate(wedges):
+                ang = (p.theta2 - p.theta1) / 2. + p.theta1
+
+                if not last_label:
+                    y = np.sin(np.deg2rad(ang))
+                    x = np.cos(np.deg2rad(ang))
+                    horizontalalignment = {-1: "right", 1: "left"}[int(np.sign(x))]
+                    connectionstyle = "angle,angleA=0,angleB={}".format(ang)
+                    kw["arrowprops"].update({"connectionstyle": connectionstyle})
+                    ax1.annotate(sobol_labels[i] + f" ({sobols[i]*100:.1f}%)", xy=(x, y), xytext=(1.35 * np.sign(x), 1.4 * y),
+                                horizontalalignment=horizontalalignment, **kw)
+                    if ang > 310:
+                        last_label = True
+
+            # for i, p in enumerate(wedges):
+            #     ang = (p.theta2 - p.theta1) / 2. + p.theta1
+            #     y = np.sin(np.deg2rad(ang))
+            #     x = np.cos(np.deg2rad(ang))
+            #     horizontalalignment = {-1: "right", 1: "left"}[int(np.sign(x))]
+            #     connectionstyle = "angle,angleA=0,angleB={}".format(ang)
+            #     kw["arrowprops"].update({"connectionstyle": connectionstyle})
+            #     ax1.annotate(sobol_labels[i], xy=(x, y), xytext=(1.35 * np.sign(x), 1.4 * y),
+            #                 horizontalalignment=horizontalalignment, **kw)
+
+            # ax1.legend(wedges, sobol_labels,
+            #           title="Parameter",
+            #           loc="center left",
+            #           bbox_to_anchor=(1, 0, 0.5, 1))
+
+            ax1.set_title("Normalized Sobol indices")
+        else:
+            ax1.bar(np.arange(len(sobol_keys)) + 1, sobols, width=0.8)
+            ax1.set_xticklabels([" "] + sobol_labels)
+            ax1.set_yscale('log')
+            ax1.set_ylabel('Sobol indices', fontsize=14)
+            ax1.set_xlabel('parameter', fontsize=14)
+            ax1.set_xlim(0, len(sobol_keys) + 1)
+            ax1.set_ylim(0., 1.0)
+        ax2.bar(np.arange(len(gsens_keys)) + 1, glob_sens, color='orange')
+        ax2.set_xticks(list(np.arange(len(gsens_keys)) + 1))
+        ax2.set_xticklabels(list(gsens_keys))
+        ax2.set_ylabel('global sensitivities', fontsize=14)
+        ax2.set_xlabel('parameter', fontsize=14)
+        ax2.axhline(y=0, color='k', alpha=0.5)
+        plt.tight_layout()
+
+    else:
+        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=[8, 9])
+
+        # Estimate output pdf
+        if plot_pdf_over_output_idx:
+            if session.qoi_specific:
+                pdf_x = np.zeros((100, len(output_idx)))
+                pdf_y = np.zeros((100, len(output_idx)))
+
+                for i, o_idx in enumerate(output_idx):
+                    pdf_x_tmp, pdf_y_tmp = session.gpc[o_idx].get_pdf(coeffs=coeffs[o_idx], n_samples=1e5, output_idx=0)
+                    pdf_x[:, i] = pdf_x_tmp.flatten()
+                    pdf_y[:, i] = pdf_y_tmp.flatten()
+            else:
+                pdf_x, pdf_y, _, y_gpc_samples = session.gpc[0].get_pdf(coeffs=coeffs,
+                                                                        n_samples=1e5,
+                                                                        output_idx=output_idx,
+                                                                        return_samples=True)
+
+            # interpolate pdf data on common grid
+            x_interp = np.linspace(0, np.max(pdf_x), 1000)
+            y_interp = np.zeros((len(x_interp), np.shape(pdf_x)[1]))
+
+            for i in range(np.shape(pdf_x)[1]):
+                y_interp[:, i] = np.interp(x_interp, pdf_x[:, i], pdf_y[:, i], left=0, right=0)
+
+            if zlim is not None:
+                vmin = zlim[0]
+                vmax = zlim[1]
+            else:
+                vmin = np.min(y_interp)
+                vmax = np.max(y_interp)
+
+            if qois is not None:
+                x_axis = qois
+            else:
+                x_axis = np.arange(0, len(output_idx))
+
+            xx, yy = np.meshgrid(x_axis, x_interp)
+
+            # plot pdf over output_idx
+            ax1.pcolor(xx, yy, y_interp, cmap="bone_r", vmin=vmin, vmax=vmax)
+            ax1.plot(x_axis, mean, "r", linewidth=1.5)
+            legend_elements = [matplotlib.lines.Line2D([0], [0], color='r', lw=2, label='mean'),
+                               matplotlib.patches.Patch(facecolor='grey', edgecolor='k', label='pdf')]
+            ax1.legend(handles=legend_elements)
+
+            ax1.grid()
+
+            if x_label is not None:
+                ax1.set_xlabel(x_label, fontsize=14)
+
+            if y_label is not None:
+                ax1.set_ylabel(y_label, fontsize=14)
+
+        else:
+            # mean and std
+            ax1.plot(qois, mean)
+            ax1.grid()
+            ax1.set_ylabel(y_label, fontsize=14)
+            ax1.set_xlabel(x_label, fontsize=14)
+            ax1.legend(["mean of " + y_label], loc='upper left')
+            ax1.set_xlim(qois[0], qois[-1] + (np.max(qois[-1]) * 1e-3))
+            ax1.set_title("Mean and standard deviation of " + y_label, fontsize=14)
+            # ax2.set_ylim(np.min(results) + np.max(std_results), np.max(results) + np.max(std_results))
+            ax1.fill_between(qois, mean - std, mean + std, color="grey", alpha=0.5)
+
+        # sobol
+        for i in range(sobol.values.shape[0]):
+            ax2.plot(qois, sobol.values[i])
+            ax2.set_title("Sobol indices of the parameters over the qois", fontsize=14)
+            ax2.set_xlabel(x_label, fontsize=14)
+            ax2.set_ylabel("Sobol index", fontsize=14)
+            ax2.set_yscale('log')
+        sobol_labels = [(x[1:-1].replace("'", " ")).replace(" ,", ",") for x in sobol_keys]
+        ax2.legend(sobol_labels)
+        # ax1.legend(sobol['sobol_norm (qoi 0)'].keys())
+        ax2.set_xlim(qois[0], qois[-1] + (np.max(qois[-1]) * 1e-3))
+        ax2.grid()
+
+        # gsens
+        for i in range(gsens.values.shape[0]):
+            ax3.plot(qois, gsens.values[i])
+            ax3.set_title("Global derivatives of the parameters over the qois", fontsize=14)
+            ax3.set_xlabel(x_label, fontsize=14)
+            ax3.set_ylabel("Global sensitivity", fontsize=14)
+            # ax3.set_yscale('log')
+        gsens_labels = [x for x in gsens_keys]
+        ax3.legend(gsens_labels)
+        # ax1.legend(sobol['sobol_norm (qoi 0)'].keys())
+        ax3.set_xlim(qois[0], qois[-1] + (np.max(qois[-1]) * 1e-3))
+        ax3.grid()
+        plt.tight_layout()
+
+    if fn_plot is not None:
+        plt.savefig(fn_plot, dpi=600)
+        plt.close()
+
+
+def plot_gpc(session, coeffs, random_vars=None, coords=None, results=None, n_grid=None, output_idx=0, fn_plot=None,
+             camera_pos=None, zlim=None, plot_pdf_over_output_idx=False, qois=None, x_label=None, y_label=None):
+    """
+    Compares gPC approximation with original model function. Evaluates both at n_grid (x n_grid) sampling points and
+    calculate the difference between two solutions at the output quantity with output_idx and saves the plot as
+    *_QOI_idx_<output_idx>.png/pdf. Also generates one .hdf5 results file with the evaluation results.
+
+    Parameters
+    ----------
+    session : GPC Session object instance
+        GPC session object containing all information i.e., gPC, Problem, Model, Grid, Basis, RandomParameter instances
+    coeffs : ndarray of float [n_coeffs x n_out] or list of ndarray of float [n_qoi][n_coeffs x n_out]
+        GPC coefficients
+    random_vars: str or list of str [2]
+        Names of the random variables, the analysis is performed for one or max. two random variables
+    n_grid : int or list of int [2], optional
+        Number of samples in each dimension to compare the gPC approximation with the original model function.
+        A cartesian grid is generated based on the limits of the specified random_vars
+    coords : ndarray of float [n_coords x n_dim]
+        Parameter combinations for the random_vars the comparison is conducted with
+    output_idx : int, str or None, optional, default=0
+        Indices of output quantity to consider
+    results: ndarray of float [n_coords x n_out]
+        If available, data of original model function at grid, containing all QOIs
+    fn_plot : str, optional, default: None
+        Filename of plot comparing original vs gPC model (*.png or *.pdf)
+    camera_pos : list [2], optional, default: None
+        Camera position of 3D surface plot (for 2 random variables only) [azimuth, elevation]
+    zlim : list of float, optional, default: None
+        Limits of 3D plot (e.g. pdf) in z direction
+    plot_pdf_over_output_idx : bool, optional, default: False
+        Plots pdf as a surface plot over output index (e.g. a time axis)
+    qois: numpy ndarray
+        Axis of quantities of interest (x-axis, e.g. time)
+    x_label : str
+        Label of x-axis in case of multiple QOI plots
+    y_label : str
+        Label of y-axis in case of multiple QOI plots
+
+    Returns
+    -------
+    <file> : .hdf5 file
+        Data file containing the grid points and the results of the original and the gpc approximation
+    <file> : .png and .pdf file
+        Plot comparing original vs gPC model
+    """
+    y_orig = None
+
+    if type(output_idx) is int:
+        output_idx = [output_idx]
+
+    if output_idx is None or output_idx == "all":
+        output_idx = np.arange(coeffs.shape[1])
+
+    if random_vars is not None:
+        if type(random_vars) is not list:
+            random_vars = random_vars.tolist()
+        assert len(random_vars) <= 2
+
+    if n_grid is not None:
+        if n_grid and type(n_grid) is not list:
+            n_grid = n_grid.tolist()
+    else:
+        n_grid = [10, 10]
+
+    if random_vars is not None:
+        # Create grid such that it includes the mean values of other random variables
+        grid = np.zeros((np.prod(n_grid), len(session.parameters_random)))
+
+        idx = []
+        idx_global = []
+
+        # sort random_vars according to gpc.parameters
+        for i_p, p in enumerate(session.parameters_random.keys()):
+            if p not in random_vars:
+                grid[:, i_p] = session.parameters_random[p].mean
+
+            else:
+                idx.append(random_vars.index(p))
+                idx_global.append(i_p)
+
+        random_vars = [random_vars[i] for i in idx]
+        x = []
+
+        for i_p, p in enumerate(random_vars):
+            x.append(np.linspace(session.parameters_random[p].pdf_limits[0],
+                                 session.parameters_random[p].pdf_limits[1],
+                                 n_grid[i_p]))
+
+        coords_gpc = get_cartesian_product(x)
+        if len(random_vars) == 2:
+            x1_2d, x2_2d = np.meshgrid(x[0], x[1])
+
+        grid[:, idx_global] = coords_gpc
+
+        # Normalize grid
+        grid_norm = Grid(parameters_random=session.parameters_random).get_normalized_coordinates(grid)
+
+    # Evaluate gPC expansion on grid and estimate output pdf
+    if session.qoi_specific:
+        y_gpc = np.zeros((grid_norm.shape[0], len(output_idx)))
+        pdf_x = np.zeros((100, len(output_idx)))
+        pdf_y = np.zeros((100, len(output_idx)))
+
+        for i, o_idx in enumerate(output_idx):
+            y_gpc[:, i] = session.gpc[o_idx].get_approximation(coeffs=coeffs[o_idx], x=grid_norm,
+                                                               output_idx=0).flatten()
+
+            pdf_x_tmp, pdf_y_tmp = session.gpc[o_idx].get_pdf(coeffs=coeffs[o_idx], n_samples=1e5, output_idx=0)
+            pdf_x[:, i] = pdf_x_tmp.flatten()
+            pdf_y[:, i] = pdf_y_tmp.flatten()
+    else:
+        if not plot_pdf_over_output_idx:
+            y_gpc = session.gpc[0].get_approximation(coeffs=coeffs,
+                                                     x=grid_norm,
+                                                     output_idx=output_idx)
+
+        pdf_x, pdf_y, _, y_gpc_samples = session.gpc[0].get_pdf(coeffs=coeffs,
+                                                                n_samples=1e5,
+                                                                output_idx=output_idx,
+                                                                return_samples=True)
+
+    if not plot_pdf_over_output_idx:
+        if results is not None:
+            y_orig = results[:, output_idx]
+
+            if y_orig.ndim == 1:
+                y_orig = y_orig[:, np.newaxis]
+
+        # add axes if necessary
+        if y_gpc.ndim == 1:
+            y_gpc = y_gpc[:, np.newaxis]
+
+    # Plot results
+    matplotlib.rc('text', usetex=False)
+    matplotlib.rc('xtick', labelsize=13)
+    matplotlib.rc('ytick', labelsize=13)
+    fs = 14
+
+    if plot_pdf_over_output_idx:
+        # interpolate pdf data on common grid
+        x_interp = np.linspace(0, np.max(pdf_x), 1000)
+        y_interp = np.zeros((len(x_interp), np.shape(pdf_x)[1]))
+
+        for i in range(np.shape(pdf_x)[1]):
+            y_interp[:, i] = np.interp(x_interp, pdf_x[:, i], pdf_y[:, i], left=0, right=0)
+
+        if zlim is not None:
+            vmin = zlim[0]
+            vmax = zlim[1]
+        else:
+            vmin = np.min(y_interp)
+            vmax = np.max(y_interp)
+
+        if qois is not None:
+            x_axis = qois
+        else:
+            x_axis = np.arange(0, len(output_idx))
+
+        xx, yy = np.meshgrid(x_axis, x_interp)
+
+        # plot pdf over output_idx
+        plt.figure(figsize=[10, 6])
+        plt.pcolor(xx, yy, y_interp, cmap="bone_r", vmin=vmin, vmax=vmax)
+        plt.plot(x_axis, np.mean(y_gpc_samples, axis=0), "r", linewidth=1.5)
+        plt.grid()
+
+        if x_label is not None:
+            plt.xlabel(x_label, fontsize=14)
+
+        if y_label is not None:
+            plt.ylabel(y_label, fontsize=14)
+
+        plt.tight_layout()
+
+        if fn_plot is not None:
+            plt.savefig(os.path.splitext(fn_plot)[0] + "_pdf_qoi.png", dpi=1200)
+            plt.savefig(os.path.splitext(fn_plot)[0] + "_pdf_qoi.pdf")
+            plt.close()
+
+    else:
+        for _i, i in enumerate(output_idx):
+            fig = plt.figure(figsize=(12, 5))
+
+            # One random variable
+            if len(random_vars) == 1:
+                ax1 = fig.add_subplot(1, 2, 1)
+                ax1.plot(coords_gpc, y_gpc[:, i])
+                if y_orig is not None:
+                    ax1.scatter(coords[:, idx_global[0]], y_orig[:, _i], s=7 * np.ones(len(y_orig[:, i])),
+                                facecolor='w', edgecolors='k')
+                    legend = [r"gPC", r"original"]
+                else:
+                    legend = [r"gPC"]
+                ax1.legend(legend, fontsize=fs)
+                ax1.set_xlabel(r"%s" % random_vars[0], fontsize=fs)
+                ax1.set_ylabel(r"y(%s)" % random_vars[0], fontsize=fs)
+                ax1.grid()
+
+            # Two random variables
+            elif len(random_vars) == 2:
+                ax1 = fig.add_subplot(1, 2, 1, projection='3d')
+                im1 = ax1.plot_surface(x1_2d, x2_2d, np.reshape(y_gpc[:, _i], (x[1].size, x[0].size), order='f'),
+                                       cmap="jet", alpha=0.75, linewidth=0, edgecolors=None)
+                if y_orig is not None:
+                    ax1.scatter(coords[:, idx_global[0]], coords[:, idx_global[1]], y_orig[:, _i],
+                                'k', alpha=1, edgecolors='k', depthshade=False)
+                ax1.set_title(r'gPC approximation', fontsize=fs)
+                ax1.set_xlabel(r"%s" % random_vars[0], fontsize=fs)
+                ax1.set_ylabel(r"%s" % random_vars[1], fontsize=fs)
+
+                if camera_pos is not None:
+                    ax1.view_init(elev=camera_pos[0], azim=camera_pos[1])
+
+                fig.colorbar(im1, ax=ax1, orientation='vertical')
+
+                if zlim is not None:
+                    ax1.set_zlim(zlim)
+
+            # plot histogram of output data and gPC estimated pdf
+            ax2 = fig.add_subplot(1, 2, 2)
+            if y_orig is not None:
+                ax2.hist(y_orig[:, _i], density=True, bins=20, edgecolor='k')
+            ax2.plot(pdf_x[:, _i], pdf_y[:, _i], 'r')
+            ax2.grid()
+            ax2.set_title("Probability density", fontsize=fs)
+            ax2.set_xlabel(r'$y$', fontsize=16)
+            ax2.set_ylabel(r'$p(y)$', fontsize=16)
+            plt.tight_layout()
+
+            if fn_plot is not None:
+                plt.savefig(os.path.splitext(fn_plot)[0] + "_qoi_" + str(output_idx[i]) + '.png', dpi=1200)
+                plt.savefig(os.path.splitext(fn_plot)[0] + "_qoi_" + str(output_idx[i]) + '.pdf')
+                plt.close()
```

## pygpc/sobol_saltelli.py

 * *Ordering differences only*

```diff
@@ -1,322 +1,322 @@
-import os
-import math
-import numpy as np
-import h5py
-from scipy.stats import norm
-from scipy.special import binom
-
-##############################################################################
-# The following code is based on the Sobol sequence generator by Frances
-# Y. Kuo and Stephen Joe. The license terms are provided below.
-#
-# Copyright (c) 2008, Frances Y. Kuo and Stephen Joe
-# All rights reserved.
-#
-# Redistribution and use in source and binary forms, with or without
-# modification, are permitted provided that the following conditions are
-# met:
-#
-# Redistributions of source code must retain the above copyright
-# notice, this list of conditions and the following disclaimer.
-#
-# Redistributions in binary form must reproduce the above copyright
-# notice, this list of conditions and the following disclaimer in the
-# documentation and/or other materials provided with the distribution.
-#
-# Neither the names of the copyright holders nor the names of the
-# University of New South Wales and the University of Waikato
-# and its contributors may be used to endorse or promote products derived
-# from this software without specific prior written permission.
-#
-# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
-# EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
-# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
-# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS BE LIABLE FOR ANY
-# DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
-# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
-# OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
-# HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
-# STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
-# ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
-# POSSIBILITY OF SUCH DAMAGE.
-##############################################################################
-
-
-def sobol_sampling(n, dim):
-    """Generate (N x D) numpy array of Sobol sequence samples"""
-    scale = 31
-    result = np.zeros([n, dim])
-
-    # load directions
-    fn = os.path.join(os.path.dirname(__file__), "sobol_saltelli_directions.hdf5")
-
-    with h5py.File(fn, "r") as f:
-        directions_raw = []
-        directions = []
-
-        for key in f.keys():
-            directions_raw.append(f[key][:].tolist())
-
-        for i in range(len(directions_raw)):
-            for d in directions_raw[i]:
-                directions.append(d)
-
-    if dim > len(directions) + 1:
-        raise ValueError("Error in Sobol sequence: not enough dimensions")
-
-    ll = int(math.ceil(math.log(n) / math.log(2)))
-
-    if ll > scale:
-        raise ValueError("Error in Sobol sequence: not enough bits")
-
-    for i in range(dim):
-        v = np.zeros(ll + 1, dtype=int)
-
-        if i == 0:
-            for j in range(1, ll + 1):
-                v[j] = 1 << (scale - j)  # all m's = 1
-        else:
-            m = np.array(directions[i - 1], dtype=int)
-            a = m[0]
-            s = len(m) - 1
-
-            # The following code discards the first row of the ``m`` array
-            # Because it has floating point errors, e.g. values of 2.24e-314
-            if ll <= s:
-                for j in range(1, ll + 1):
-                    v[j] = m[j] << (scale - j)
-            else:
-                for j in range(1, s + 1):
-                    v[j] = m[j] << (scale - j)
-                for j in range(s + 1, ll + 1):
-                    v[j] = v[j - s] ^ (v[j - s] >> s)
-                    for k in range(1, s):
-                        v[j] ^= ((a >> (s - 1 - k)) & 1) * v[j - k]
-
-        x = int(0)
-        for j in range(1, n):
-            x ^= v[index_of_least_significant_zero_bit(j - 1)]
-            result[j][i] = float(x / math.pow(2, scale))
-
-    return result
-
-
-def index_of_least_significant_zero_bit(value):
-    index = 1
-    while (value & 1) != 0:
-        value >>= 1
-        index += 1
-
-    return index
-
-
-def saltelli_sampling(n_samples, dim, calc_second_order=True):
-    """Generates model inputs using Saltelli's extension of the Sobol sequence.
-
-    Returns a NumPy matrix containing the model inputs using Saltelli's sampling
-    scheme.  Saltelli's scheme extends the Sobol sequence in a way to reduce
-    the error rates in the resulting sensitivity index calculations.  If
-    calc_second_order is False, the resulting matrix has N * (D + 2)
-    rows, where D is the number of parameters.  If calc_second_order is True,
-    the resulting matrix has N * (2D + 2) rows.  These model inputs are
-    intended to be used with :func:`SALib.analyze.sobol.analyze`.
-
-    Parameters
-    ----------
-    n_samples : int
-        The number of samples to generate
-    dim : int
-        The number of dimensions
-    calc_second_order : bool
-        Calculate second-order sensitivities (default True)
-    """
-    dim = int(dim)
-    n_samples = int(n_samples)
-    dg = dim
-
-    # How many values of the Sobol sequence to skip
-    skip_values = 1000
-
-    # Create base sequence - could be any type of sampling
-    base_sequence = sobol_sampling(n_samples + skip_values, 2 * dim)
-
-    if calc_second_order:
-        saltelli_sequence = np.zeros([(2 * dg + 2) * n_samples, dim])
-    else:
-        saltelli_sequence = np.zeros([(dg + 2) * n_samples, dim])
-    index = 0
-
-    for i in range(skip_values, n_samples + skip_values):
-
-        # Copy matrix "A"
-        for j in range(dim):
-            saltelli_sequence[index, j] = base_sequence[i, j]
-
-        index += 1
-
-        # Cross-sample elements of "B" into "A"
-        for k in range(dg):
-            for j in range(dim):
-                if j == k:
-                    saltelli_sequence[index, j] = base_sequence[i, j + dim]
-                else:
-                    saltelli_sequence[index, j] = base_sequence[i, j]
-
-            index += 1
-
-        # Cross-sample elements of "A" into "B"
-        # Only needed if you're doing second-order indices (true by default)
-        if calc_second_order:
-            for k in range(dg):
-                for j in range(dim):
-                    if j == k:
-                        saltelli_sequence[index, j] = base_sequence[i, j]
-                    else:
-                        saltelli_sequence[index, j] = base_sequence[i, j + dim]
-
-                index += 1
-
-        # Copy matrix "B"
-        for j in range(dim):
-            saltelli_sequence[index, j] = base_sequence[i, j + dim]
-
-        index += 1
-    return saltelli_sequence
-
-
-def get_sobol_indices_saltelli(y, dim, calc_second_order=True, num_resamples=100,
-                               conf_level=0.95):
-    """Perform Sobol Analysis on model outputs.
-
-    Returns a dictionary with keys 'S1', 'S1_conf', 'ST', and 'ST_conf', where
-    each entry is a list of size D (the number of parameters) containing the
-    indices in the same order as the parameter file.  If calc_second_order is
-    True, the dictionary also contains keys 'S2' and 'S2_conf'.
-
-    Parameters
-    ----------
-    y : numpy.array
-        A NumPy array containing the model outputs
-    dim : int
-        Number of dimensions
-    calc_second_order : bool
-        Calculate second-order sensitivities (default True)
-    num_resamples : int
-        The number of resamples (default 100)
-    conf_level : float
-        The confidence interval level (default 0.95)
-
-    References
-    ----------
-    .. [1] Sobol, I. M. (2001).  "Global sensitivity indices for nonlinear
-           mathematical models and their Monte Carlo estimates."  Mathematics
-           and Computers in Simulation, 55(1-3):271-280,
-           doi:10.1016/S0378-4754(00)00270-6.
-    .. [2] Saltelli, A. (2002).  "Making best use of model evaluations to
-           compute sensitivity indices."  Computer Physics Communications,
-           145(2):280-297, doi:10.1016/S0010-4655(02)00280-1.
-    .. [3] Saltelli, A., P. Annoni, I. Azzini, F. Campolongo, M. Ratto, and
-           S. Tarantola (2010).  "Variance based sensitivity analysis of model
-           output.  Design and estimator for the total sensitivity index."
-           Computer Physics Communications, 181(2):259-270,
-           doi:10.1016/j.cpc.2009.09.018.
-    """
-
-    if calc_second_order and y.shape[0] % (2 * dim + 2) == 0:
-        n = int(y.shape[0] / (2 * dim + 2))
-    elif not calc_second_order and y.shape[0] % (dim + 2) == 0:
-        n = int(y.shape[0] / (dim + 2))
-    else:
-        raise RuntimeError("""
-        Incorrect number of samples in model output file.
-        Confirm that calc_second_order matches option used during sampling.""")
-
-    if conf_level < 0 or conf_level > 1:
-        raise RuntimeError("Confidence level must be between 0-1.")
-
-    # normalize the model output
-    y = (y - y.mean(axis=0)) / y.std(axis=0)
-
-    a, b, ab, ba = separate_output_values(y, dim, n, calc_second_order)
-    r = np.random.randint(n, size=(n, num_resamples))
-    z = norm.ppf(0.5 + conf_level / 2)
-
-    n_sobol = int(dim + binom(dim, 2))
-    sobol = np.zeros((n_sobol, y.shape[1]))
-    sobol_total = np.zeros((dim, y.shape[1]))
-    sobol_total_conf = np.zeros((dim, y.shape[1]))
-    sobol_conf = np.zeros((n_sobol, y.shape[1]))
-    sobol_idx = [np.nan for _ in range(n_sobol)]
-    sobol_idx_bool = np.zeros((n_sobol, dim)).astype(bool)
-
-    # first and total order (+ confidence interval)
-    i_sobol = 0
-    for j in range(dim):
-        sobol[j, :] = first_order(a, ab[:, j, :], b)
-        sobol_conf[j, :] = z * first_order(a[r], ab[r, j], b[r]).std(ddof=1)
-        sobol_total[j, :] = z * total_order(a, ab[:, j], b)
-        sobol_total_conf[j, :] = z * total_order(a[r], ab[r, j], b[r]).std(ddof=1)
-        sobol_idx[j] = np.array([j])
-        sobol_idx_bool[j, j] = True
-        i_sobol += 1
-
-    # Second order (+ confidence interval)
-    if calc_second_order:
-        for j in range(dim):
-            for k in range(j + 1, dim):
-                sobol[i_sobol, :] = second_order(a, ab[:, j, :], ab[:, k, :], ba[:, j, :], b)
-                sobol_conf[i_sobol, :] = z * second_order(a[r], ab[r, j], ab[r, k], ba[r, j], b[r]).std(ddof=1)
-                sobol_idx[i_sobol] = np.array([j, k])
-                sobol_idx_bool[i_sobol, [j, k]] = True
-                i_sobol += 1
-
-    return sobol, sobol_idx, sobol_idx_bool
-
-
-def first_order(a, ab, b):
-    # First order estimator following Saltelli et al. 2010 CPC, normalized by
-    # sample variance
-    return np.mean(b * (ab - a), axis=0) / np.var(np.r_[a, b], axis=0)
-
-
-def total_order(a, ab, b):
-    # Total order estimator following Saltelli et al. 2010 CPC, normalized by
-    # sample variance
-    return 0.5 * np.mean((a - ab) ** 2, axis=0) / np.var(np.r_[a, b], axis=0)
-
-
-def second_order(a, abj, abk, baj, b):
-    # Second order estimator following Saltelli 2002
-    vjk = np.mean(baj * abk - a * b, axis=0) / np.var(np.r_[a, b], axis=0)
-    sj = first_order(a, abj, b)
-    sk = first_order(a, abk, b)
-
-    return vjk - sj - sk
-
-
-def create_si_dict(dim, calc_second_order):
-    # initialize empty dict to store sensitivity indices
-    s = dict((k, np.zeros(dim)) for k in ('S1', 'S1_conf', 'ST', 'ST_conf'))
-
-    if calc_second_order:
-        s['S2'] = np.zeros((dim, dim))
-        s['S2'][:] = np.nan
-        s['S2_conf'] = np.zeros((dim, dim))
-        s['S2_conf'][:] = np.nan
-
-    return s
-
-
-def separate_output_values(y, dim, n, calc_second_order):
-    ab = np.zeros((n, dim, y.shape[1]))
-    ba = np.zeros((n, dim, y.shape[1])) if calc_second_order else None
-    step = 2 * dim + 2 if calc_second_order else dim + 2
-
-    a = y[0:y.shape[0]:step, :]
-    b = y[(step - 1):y.shape[0]:step, :]
-    for j in range(dim):
-        ab[:, j, :] = y[(j + 1):y.shape[0]:step, :]
-        if calc_second_order:
-            ba[:, j, :] = y[(j + 1 + dim):y.shape[0]:step, :]
-
-    return a, b, ab, ba
+import os
+import math
+import numpy as np
+import h5py
+from scipy.stats import norm
+from scipy.special import binom
+
+##############################################################################
+# The following code is based on the Sobol sequence generator by Frances
+# Y. Kuo and Stephen Joe. The license terms are provided below.
+#
+# Copyright (c) 2008, Frances Y. Kuo and Stephen Joe
+# All rights reserved.
+#
+# Redistribution and use in source and binary forms, with or without
+# modification, are permitted provided that the following conditions are
+# met:
+#
+# Redistributions of source code must retain the above copyright
+# notice, this list of conditions and the following disclaimer.
+#
+# Redistributions in binary form must reproduce the above copyright
+# notice, this list of conditions and the following disclaimer in the
+# documentation and/or other materials provided with the distribution.
+#
+# Neither the names of the copyright holders nor the names of the
+# University of New South Wales and the University of Waikato
+# and its contributors may be used to endorse or promote products derived
+# from this software without specific prior written permission.
+#
+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+# EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS BE LIABLE FOR ANY
+# DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+# OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+# HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
+# STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
+# ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+# POSSIBILITY OF SUCH DAMAGE.
+##############################################################################
+
+
+def sobol_sampling(n, dim):
+    """Generate (N x D) numpy array of Sobol sequence samples"""
+    scale = 31
+    result = np.zeros([n, dim])
+
+    # load directions
+    fn = os.path.join(os.path.dirname(__file__), "sobol_saltelli_directions.hdf5")
+
+    with h5py.File(fn, "r") as f:
+        directions_raw = []
+        directions = []
+
+        for key in f.keys():
+            directions_raw.append(f[key][:].tolist())
+
+        for i in range(len(directions_raw)):
+            for d in directions_raw[i]:
+                directions.append(d)
+
+    if dim > len(directions) + 1:
+        raise ValueError("Error in Sobol sequence: not enough dimensions")
+
+    ll = int(math.ceil(math.log(n) / math.log(2)))
+
+    if ll > scale:
+        raise ValueError("Error in Sobol sequence: not enough bits")
+
+    for i in range(dim):
+        v = np.zeros(ll + 1, dtype=int)
+
+        if i == 0:
+            for j in range(1, ll + 1):
+                v[j] = 1 << (scale - j)  # all m's = 1
+        else:
+            m = np.array(directions[i - 1], dtype=int)
+            a = m[0]
+            s = len(m) - 1
+
+            # The following code discards the first row of the ``m`` array
+            # Because it has floating point errors, e.g. values of 2.24e-314
+            if ll <= s:
+                for j in range(1, ll + 1):
+                    v[j] = m[j] << (scale - j)
+            else:
+                for j in range(1, s + 1):
+                    v[j] = m[j] << (scale - j)
+                for j in range(s + 1, ll + 1):
+                    v[j] = v[j - s] ^ (v[j - s] >> s)
+                    for k in range(1, s):
+                        v[j] ^= ((a >> (s - 1 - k)) & 1) * v[j - k]
+
+        x = int(0)
+        for j in range(1, n):
+            x ^= v[index_of_least_significant_zero_bit(j - 1)]
+            result[j][i] = float(x / math.pow(2, scale))
+
+    return result
+
+
+def index_of_least_significant_zero_bit(value):
+    index = 1
+    while (value & 1) != 0:
+        value >>= 1
+        index += 1
+
+    return index
+
+
+def saltelli_sampling(n_samples, dim, calc_second_order=True):
+    """Generates model inputs using Saltelli's extension of the Sobol sequence.
+
+    Returns a NumPy matrix containing the model inputs using Saltelli's sampling
+    scheme.  Saltelli's scheme extends the Sobol sequence in a way to reduce
+    the error rates in the resulting sensitivity index calculations.  If
+    calc_second_order is False, the resulting matrix has N * (D + 2)
+    rows, where D is the number of parameters.  If calc_second_order is True,
+    the resulting matrix has N * (2D + 2) rows.  These model inputs are
+    intended to be used with :func:`SALib.analyze.sobol.analyze`.
+
+    Parameters
+    ----------
+    n_samples : int
+        The number of samples to generate
+    dim : int
+        The number of dimensions
+    calc_second_order : bool
+        Calculate second-order sensitivities (default True)
+    """
+    dim = int(dim)
+    n_samples = int(n_samples)
+    dg = dim
+
+    # How many values of the Sobol sequence to skip
+    skip_values = 1000
+
+    # Create base sequence - could be any type of sampling
+    base_sequence = sobol_sampling(n_samples + skip_values, 2 * dim)
+
+    if calc_second_order:
+        saltelli_sequence = np.zeros([(2 * dg + 2) * n_samples, dim])
+    else:
+        saltelli_sequence = np.zeros([(dg + 2) * n_samples, dim])
+    index = 0
+
+    for i in range(skip_values, n_samples + skip_values):
+
+        # Copy matrix "A"
+        for j in range(dim):
+            saltelli_sequence[index, j] = base_sequence[i, j]
+
+        index += 1
+
+        # Cross-sample elements of "B" into "A"
+        for k in range(dg):
+            for j in range(dim):
+                if j == k:
+                    saltelli_sequence[index, j] = base_sequence[i, j + dim]
+                else:
+                    saltelli_sequence[index, j] = base_sequence[i, j]
+
+            index += 1
+
+        # Cross-sample elements of "A" into "B"
+        # Only needed if you're doing second-order indices (true by default)
+        if calc_second_order:
+            for k in range(dg):
+                for j in range(dim):
+                    if j == k:
+                        saltelli_sequence[index, j] = base_sequence[i, j]
+                    else:
+                        saltelli_sequence[index, j] = base_sequence[i, j + dim]
+
+                index += 1
+
+        # Copy matrix "B"
+        for j in range(dim):
+            saltelli_sequence[index, j] = base_sequence[i, j + dim]
+
+        index += 1
+    return saltelli_sequence
+
+
+def get_sobol_indices_saltelli(y, dim, calc_second_order=True, num_resamples=100,
+                               conf_level=0.95):
+    """Perform Sobol Analysis on model outputs.
+
+    Returns a dictionary with keys 'S1', 'S1_conf', 'ST', and 'ST_conf', where
+    each entry is a list of size D (the number of parameters) containing the
+    indices in the same order as the parameter file.  If calc_second_order is
+    True, the dictionary also contains keys 'S2' and 'S2_conf'.
+
+    Parameters
+    ----------
+    y : numpy.array
+        A NumPy array containing the model outputs
+    dim : int
+        Number of dimensions
+    calc_second_order : bool
+        Calculate second-order sensitivities (default True)
+    num_resamples : int
+        The number of resamples (default 100)
+    conf_level : float
+        The confidence interval level (default 0.95)
+
+    References
+    ----------
+    .. [1] Sobol, I. M. (2001).  "Global sensitivity indices for nonlinear
+           mathematical models and their Monte Carlo estimates."  Mathematics
+           and Computers in Simulation, 55(1-3):271-280,
+           doi:10.1016/S0378-4754(00)00270-6.
+    .. [2] Saltelli, A. (2002).  "Making best use of model evaluations to
+           compute sensitivity indices."  Computer Physics Communications,
+           145(2):280-297, doi:10.1016/S0010-4655(02)00280-1.
+    .. [3] Saltelli, A., P. Annoni, I. Azzini, F. Campolongo, M. Ratto, and
+           S. Tarantola (2010).  "Variance based sensitivity analysis of model
+           output.  Design and estimator for the total sensitivity index."
+           Computer Physics Communications, 181(2):259-270,
+           doi:10.1016/j.cpc.2009.09.018.
+    """
+
+    if calc_second_order and y.shape[0] % (2 * dim + 2) == 0:
+        n = int(y.shape[0] / (2 * dim + 2))
+    elif not calc_second_order and y.shape[0] % (dim + 2) == 0:
+        n = int(y.shape[0] / (dim + 2))
+    else:
+        raise RuntimeError("""
+        Incorrect number of samples in model output file.
+        Confirm that calc_second_order matches option used during sampling.""")
+
+    if conf_level < 0 or conf_level > 1:
+        raise RuntimeError("Confidence level must be between 0-1.")
+
+    # normalize the model output
+    y = (y - y.mean(axis=0)) / y.std(axis=0)
+
+    a, b, ab, ba = separate_output_values(y, dim, n, calc_second_order)
+    r = np.random.randint(n, size=(n, num_resamples))
+    z = norm.ppf(0.5 + conf_level / 2)
+
+    n_sobol = int(dim + binom(dim, 2))
+    sobol = np.zeros((n_sobol, y.shape[1]))
+    sobol_total = np.zeros((dim, y.shape[1]))
+    sobol_total_conf = np.zeros((dim, y.shape[1]))
+    sobol_conf = np.zeros((n_sobol, y.shape[1]))
+    sobol_idx = [np.nan for _ in range(n_sobol)]
+    sobol_idx_bool = np.zeros((n_sobol, dim)).astype(bool)
+
+    # first and total order (+ confidence interval)
+    i_sobol = 0
+    for j in range(dim):
+        sobol[j, :] = first_order(a, ab[:, j, :], b)
+        sobol_conf[j, :] = z * first_order(a[r], ab[r, j], b[r]).std(ddof=1)
+        sobol_total[j, :] = z * total_order(a, ab[:, j], b)
+        sobol_total_conf[j, :] = z * total_order(a[r], ab[r, j], b[r]).std(ddof=1)
+        sobol_idx[j] = np.array([j])
+        sobol_idx_bool[j, j] = True
+        i_sobol += 1
+
+    # Second order (+ confidence interval)
+    if calc_second_order:
+        for j in range(dim):
+            for k in range(j + 1, dim):
+                sobol[i_sobol, :] = second_order(a, ab[:, j, :], ab[:, k, :], ba[:, j, :], b)
+                sobol_conf[i_sobol, :] = z * second_order(a[r], ab[r, j], ab[r, k], ba[r, j], b[r]).std(ddof=1)
+                sobol_idx[i_sobol] = np.array([j, k])
+                sobol_idx_bool[i_sobol, [j, k]] = True
+                i_sobol += 1
+
+    return sobol, sobol_idx, sobol_idx_bool
+
+
+def first_order(a, ab, b):
+    # First order estimator following Saltelli et al. 2010 CPC, normalized by
+    # sample variance
+    return np.mean(b * (ab - a), axis=0) / np.var(np.r_[a, b], axis=0)
+
+
+def total_order(a, ab, b):
+    # Total order estimator following Saltelli et al. 2010 CPC, normalized by
+    # sample variance
+    return 0.5 * np.mean((a - ab) ** 2, axis=0) / np.var(np.r_[a, b], axis=0)
+
+
+def second_order(a, abj, abk, baj, b):
+    # Second order estimator following Saltelli 2002
+    vjk = np.mean(baj * abk - a * b, axis=0) / np.var(np.r_[a, b], axis=0)
+    sj = first_order(a, abj, b)
+    sk = first_order(a, abk, b)
+
+    return vjk - sj - sk
+
+
+def create_si_dict(dim, calc_second_order):
+    # initialize empty dict to store sensitivity indices
+    s = dict((k, np.zeros(dim)) for k in ('S1', 'S1_conf', 'ST', 'ST_conf'))
+
+    if calc_second_order:
+        s['S2'] = np.zeros((dim, dim))
+        s['S2'][:] = np.nan
+        s['S2_conf'] = np.zeros((dim, dim))
+        s['S2_conf'][:] = np.nan
+
+    return s
+
+
+def separate_output_values(y, dim, n, calc_second_order):
+    ab = np.zeros((n, dim, y.shape[1]))
+    ba = np.zeros((n, dim, y.shape[1])) if calc_second_order else None
+    step = 2 * dim + 2 if calc_second_order else dim + 2
+
+    a = y[0:y.shape[0]:step, :]
+    b = y[(step - 1):y.shape[0]:step, :]
+    for j in range(dim):
+        ab[:, j, :] = y[(j + 1):y.shape[0]:step, :]
+        if calc_second_order:
+            ba[:, j, :] = y[(j + 1 + dim):y.shape[0]:step, :]
+
+    return a, b, ab, ba
```

## pygpc/test_utils.py

 * *Ordering differences only*

```diff
@@ -1,172 +1,172 @@
-import numpy as np
-import h5py
-from .io import read_session
-from .MEGPC import *
-
-
-def check_file_consistency(fn_hdf5):
-    """
-    Test gPC output files for consistency.
-
-    Parameters
-    ----------
-    fn_hdf5 : str
-        Filename of gPC results (.hdf5) file
-
-    Returns
-    -------
-    file_status : boolean
-        File consistency
-    error_msg : list of str
-        Error messages if files are not consistent
-    """
-    error_msg = []
-    file_status = True
-
-    # get list of filenames of gPC .pkl files
-    try:
-        with h5py.File(fn_hdf5, "r") as f:
-            try:
-                fn_session = os.path.join(os.path.split(fn_hdf5)[0], f["misc/fn_session"][0].astype(str))
-                fn_session_folder = f["misc/fn_session_folder"][0].astype(str)
-            except KeyError:
-                error_msg.append("misc/fn_gpc_pkl not found in results file: {}".format(fn_hdf5))
-                file_status = False
-
-    except FileNotFoundError:
-        error_msg.append("gPC results file not found: {}".format(fn_hdf5))
-        file_status = False
-        return file_status, error_msg
-
-    # check for gPC object file
-    ###########################
-    try:
-        session = read_session(fname=fn_session, folder=fn_session_folder)
-    except FileNotFoundError:
-        error_msg.append("gPC session not found in file: {}".format(fn_session))
-        file_status = False
-        return file_status, error_msg
-
-    # check for gPC results file and kind of simulation
-    ###################################################
-
-    with h5py.File(fn_hdf5, "r") as f:
-        qoi_keys = [""]
-        try:
-            if isinstance(f["coeffs/"], h5py.Group):
-                if np.array(["qoi" in s for s in list(f["coeffs/"].keys())]).any():
-                    qoi_keys = list(f["coeffs"].keys())
-                    qoi_idx = [int(key.split("qoi_")[1]) for key in qoi_keys]
-            else:
-                qoi_keys = [""]
-        except KeyError:
-            pass
-
-    if session.gpc_type == "megpc":
-        dom_keys = ["dom_{}".format(int(i)) for i in range(len(np.unique(session.gpc[0].domains)))]
-
-    else:
-        dom_keys = [""]
-
-    # check for general .hdf5 file content
-    ######################################
-    with h5py.File(fn_hdf5, "r") as f:
-        for target in ["grid/coords", "grid/coords_norm", "model_evaluations/results"]:
-            try:
-                if type(f[target][:]) is not np.ndarray:
-                    error_msg.append(target + " is not a numpy array")
-                    file_status = False
-            except KeyError:
-                error_msg.append(target + " not found in results file: {}".format(fn_hdf5))
-                file_status = False
-
-        if session.projection or (session.gradient and session.algorithm.options["gradient_calculation"] == "FD_fwd"):
-            for target in ["grid/coords_gradient", "grid/coords_gradient_norm", "model_evaluations/gradient_results"]:
-                try:
-                    if type(f[target][()]) is not np.ndarray:
-                        error_msg.append(target + " is not a numpy array")
-                        file_status = False
-                except KeyError:
-                    error_msg.append(target + " not found in results file: {}".format(fn_hdf5))
-                    file_status = False
-
-        try:
-            if not(type(f["misc/error_type"][...][()]) is str or type(f["misc/error_type"][...][()]) is bytes):
-                error_msg.append("misc/error_type is not str or bytes")
-                file_status = False
-        except KeyError:
-            error_msg.append("misc/error_type not found in results file: {}".format(fn_hdf5))
-            file_status = False
-
-    # check for specific .hdf5 file content
-    #######################################
-    with h5py.File(fn_hdf5, "r") as f:
-
-        for i_qoi, q_idx in enumerate(qoi_keys):
-
-            for target in ["domains"]:
-                if not(target == "domains" and not session.gpc_type == "megpc"):
-                    try:
-                        h5_path = target + "/" + q_idx
-                        if type(f[h5_path][()]) not in [np.ndarray, np.float64]:
-                            error_msg.append(h5_path + " is not a numpy array")
-                            file_status = False
-
-                    except KeyError:
-                        error_msg.append(h5_path + " not found in results file: {}".format(fn_hdf5))
-                        file_status = False
-
-            for d_idx in dom_keys:
-
-                # error can be domain specific or not in case of ME gPC (depending on the algorithm)
-                for target in ["error"]:
-                    try:
-                        h5_path = target + "/" + q_idx + "/" + d_idx
-                        tmp = f[h5_path][...]
-
-                    except KeyError:
-                        try:
-                            h5_path = target + "/" + q_idx
-
-                            if type(f[h5_path][()]) not in [np.ndarray, np.float64]:
-                                error_msg.append(h5_path + " is not a numpy array")
-                                file_status = False
-
-                        except KeyError:
-                            error_msg.append(h5_path + " not found in results file: {}".format(fn_hdf5))
-                            file_status = False
-
-                for target in ["coeffs", "gpc_matrix"]:
-                    try:
-                        h5_path = target + "/" + q_idx + "/" + d_idx
-                        if type(f[h5_path][()]) not in [np.ndarray]:
-                            error_msg.append(h5_path + " is not a numpy array")
-                            file_status = False
-
-                    except KeyError:
-                        error_msg.append(h5_path + " not found in results file: {}".format(fn_hdf5))
-                        file_status = False
-
-                if session.gradient and session.algorithm.options["gradient_calculation"] == "FD_fwd":
-                    for target in ["gpc_matrix_gradient"]:
-                        try:
-                            h5_path = target + "/" + q_idx + "/" + d_idx
-                            if type(f[h5_path][()]) not in [np.ndarray]:
-                                error_msg.append(h5_path + " is not a numpy array")
-                                file_status = False
-                        except KeyError:
-                            error_msg.append(h5_path + " not found in results file: {}".format(fn_hdf5))
-                            file_status = False
-
-                if session.projection:
-                    for target in ["p_matrix"]:
-                        try:
-                            h5_path = target + "/" + q_idx + "/" + d_idx
-                            if type(f[h5_path][()]) not in [np.ndarray]:
-                                error_msg.append(h5_path + " is not a numpy array")
-                                file_status = False
-                        except KeyError:
-                            error_msg.append(h5_path + " not found in results file: {}".format(fn_hdf5))
-                            file_status = False
-
-    return file_status, error_msg
+import numpy as np
+import h5py
+from .io import read_session
+from .MEGPC import *
+
+
+def check_file_consistency(fn_hdf5):
+    """
+    Test gPC output files for consistency.
+
+    Parameters
+    ----------
+    fn_hdf5 : str
+        Filename of gPC results (.hdf5) file
+
+    Returns
+    -------
+    file_status : boolean
+        File consistency
+    error_msg : list of str
+        Error messages if files are not consistent
+    """
+    error_msg = []
+    file_status = True
+
+    # get list of filenames of gPC .pkl files
+    try:
+        with h5py.File(fn_hdf5, "r") as f:
+            try:
+                fn_session = os.path.join(os.path.split(fn_hdf5)[0], f["misc/fn_session"][0].astype(str))
+                fn_session_folder = f["misc/fn_session_folder"][0].astype(str)
+            except KeyError:
+                error_msg.append("misc/fn_gpc_pkl not found in results file: {}".format(fn_hdf5))
+                file_status = False
+
+    except FileNotFoundError:
+        error_msg.append("gPC results file not found: {}".format(fn_hdf5))
+        file_status = False
+        return file_status, error_msg
+
+    # check for gPC object file
+    ###########################
+    try:
+        session = read_session(fname=fn_session, folder=fn_session_folder)
+    except FileNotFoundError:
+        error_msg.append("gPC session not found in file: {}".format(fn_session))
+        file_status = False
+        return file_status, error_msg
+
+    # check for gPC results file and kind of simulation
+    ###################################################
+
+    with h5py.File(fn_hdf5, "r") as f:
+        qoi_keys = [""]
+        try:
+            if isinstance(f["coeffs/"], h5py.Group):
+                if np.array(["qoi" in s for s in list(f["coeffs/"].keys())]).any():
+                    qoi_keys = list(f["coeffs"].keys())
+                    qoi_idx = [int(key.split("qoi_")[1]) for key in qoi_keys]
+            else:
+                qoi_keys = [""]
+        except KeyError:
+            pass
+
+    if session.gpc_type == "megpc":
+        dom_keys = ["dom_{}".format(int(i)) for i in range(len(np.unique(session.gpc[0].domains)))]
+
+    else:
+        dom_keys = [""]
+
+    # check for general .hdf5 file content
+    ######################################
+    with h5py.File(fn_hdf5, "r") as f:
+        for target in ["grid/coords", "grid/coords_norm", "model_evaluations/results"]:
+            try:
+                if type(f[target][:]) is not np.ndarray:
+                    error_msg.append(target + " is not a numpy array")
+                    file_status = False
+            except KeyError:
+                error_msg.append(target + " not found in results file: {}".format(fn_hdf5))
+                file_status = False
+
+        if session.projection or (session.gradient and session.algorithm.options["gradient_calculation"] == "FD_fwd"):
+            for target in ["grid/coords_gradient", "grid/coords_gradient_norm", "model_evaluations/gradient_results"]:
+                try:
+                    if type(f[target][()]) is not np.ndarray:
+                        error_msg.append(target + " is not a numpy array")
+                        file_status = False
+                except KeyError:
+                    error_msg.append(target + " not found in results file: {}".format(fn_hdf5))
+                    file_status = False
+
+        try:
+            if not(type(f["misc/error_type"][...][()]) is str or type(f["misc/error_type"][...][()]) is bytes):
+                error_msg.append("misc/error_type is not str or bytes")
+                file_status = False
+        except KeyError:
+            error_msg.append("misc/error_type not found in results file: {}".format(fn_hdf5))
+            file_status = False
+
+    # check for specific .hdf5 file content
+    #######################################
+    with h5py.File(fn_hdf5, "r") as f:
+
+        for i_qoi, q_idx in enumerate(qoi_keys):
+
+            for target in ["domains"]:
+                if not(target == "domains" and not session.gpc_type == "megpc"):
+                    try:
+                        h5_path = target + "/" + q_idx
+                        if type(f[h5_path][()]) not in [np.ndarray, np.float64]:
+                            error_msg.append(h5_path + " is not a numpy array")
+                            file_status = False
+
+                    except KeyError:
+                        error_msg.append(h5_path + " not found in results file: {}".format(fn_hdf5))
+                        file_status = False
+
+            for d_idx in dom_keys:
+
+                # error can be domain specific or not in case of ME gPC (depending on the algorithm)
+                for target in ["error"]:
+                    try:
+                        h5_path = target + "/" + q_idx + "/" + d_idx
+                        tmp = f[h5_path][...]
+
+                    except KeyError:
+                        try:
+                            h5_path = target + "/" + q_idx
+
+                            if type(f[h5_path][()]) not in [np.ndarray, np.float64]:
+                                error_msg.append(h5_path + " is not a numpy array")
+                                file_status = False
+
+                        except KeyError:
+                            error_msg.append(h5_path + " not found in results file: {}".format(fn_hdf5))
+                            file_status = False
+
+                for target in ["coeffs", "gpc_matrix"]:
+                    try:
+                        h5_path = target + "/" + q_idx + "/" + d_idx
+                        if type(f[h5_path][()]) not in [np.ndarray]:
+                            error_msg.append(h5_path + " is not a numpy array")
+                            file_status = False
+
+                    except KeyError:
+                        error_msg.append(h5_path + " not found in results file: {}".format(fn_hdf5))
+                        file_status = False
+
+                if session.gradient and session.algorithm.options["gradient_calculation"] == "FD_fwd":
+                    for target in ["gpc_matrix_gradient"]:
+                        try:
+                            h5_path = target + "/" + q_idx + "/" + d_idx
+                            if type(f[h5_path][()]) not in [np.ndarray]:
+                                error_msg.append(h5_path + " is not a numpy array")
+                                file_status = False
+                        except KeyError:
+                            error_msg.append(h5_path + " not found in results file: {}".format(fn_hdf5))
+                            file_status = False
+
+                if session.projection:
+                    for target in ["p_matrix"]:
+                        try:
+                            h5_path = target + "/" + q_idx + "/" + d_idx
+                            if type(f[h5_path][()]) not in [np.ndarray]:
+                                error_msg.append(h5_path + " is not a numpy array")
+                                file_status = False
+                        except KeyError:
+                            error_msg.append(h5_path + " not found in results file: {}".format(fn_hdf5))
+                            file_status = False
+
+    return file_status, error_msg
```

## pygpc/validation.py

```diff
@@ -1,417 +1,421 @@
-import os
-import h5py
-import matplotlib
-import seaborn as sns
-import matplotlib.pyplot as plt
-import scipy.stats
-from scipy.signal import savgol_filter
-from .misc import nrmsd
-from .misc import get_cartesian_product
-from pygpc.Computation import *
-from .MEGPC import *
-from .Grid import *
-from .Visualization import *
-
-
-def validate_gpc_mc(session, coeffs, coords=None, data_original=None, n_samples=1e4, output_idx=0, n_cpu=1,
-                    smooth_pdf=[51, 5], bins=100, hist=False, fn_out=None, folder="gpc_vs_original_mc", plot=True):
-    """
-    Compares gPC approximation with original model function. Evaluates both at "n_samples" sampling points and
-    evaluates the root mean square deviation. It also computes the pdf at the output quantity with output_idx
-    and saves the plot as fn_pdf.png and fn_pdf.pdf.
-
-    Parameters
-    ----------
-    session : GPC Session object instance
-        GPC session object containing all information i.e., gPC, Problem, Model, Grid, Basis, RandomParameter instances
-    coeffs : ndarray of float [n_coeffs x n_out]
-        GPC coefficients
-    coords : ndarray of float [n_coords x n_dim]
-        Parameter combinations for the random_vars the comparison is conducted with
-    data_original: ndarray of float [n_coords x n_out], optional, default: None
-        If available, data of original model function at grid, containing all QOIs
-    n_samples : int
-        Number of samples to validate the gPC approximation (ignored if coords and data_original is provided)
-    output_idx : int or ndarray of int or list of int, optional, default=None [1 x n_out]
-        Index of output quantities to consider (if output_idx=None, all output quantities are considered)
-    n_cpu : int, optional, default=1
-        Number of CPU cores to use (parallel function evaluations) to evaluate original model function
-    smooth_pdf : bool, optional, default: True
-        Smooth probability density functions using a Savgol filter [polylength, order]
-    bins : int, optional, default: 100
-        Number of bins to estimate pdf
-    hist : bool, optional, default: False
-        Plot histogram instead of pdf
-    fn_out : str or None
-        Filename of validation results and plot comparing original vs gPC model (w/o file extension)
-    folder : str, optional, default: "gpc_vs_original_plot"
-        Folder in .hdf5 file to save data in
-    plot : boolean, optional, default: True
-        Plots the pdfs of the original model function and the gPC approximation
-
-    Returns
-    -------
-    nrmsd : ndarray of float [n_out]
-        Normalized root mean square deviation for all output quantities between gPC and original model
-    <file> : .hdf5 file
-        Data file containing the sampling points, the results and the pdfs of the original and the gpc approximation
-    <file> : .pdf file
-        Plot showing the pdfs of the original and the gpc approximation
-    """
-
-    if smooth_pdf is True:
-        smooth_pdf = [51, 5]
-
-    if type(output_idx) is int:
-        output_idx = [output_idx]
-
-    if data_original is None or coords is None:
-        # Create sampling points
-        grid_mc = Random(parameters_random=session.parameters_random,
-                         n_grid=n_samples,
-                         options=None)
-
-        coords_norm = grid_mc.coords_norm
-        coords = grid_mc.coords
-
-        # Evaluate original model at grid points
-        com = Computation(n_cpu=n_cpu, matlab_model=session.matlab_model)
-
-        y_orig = com.run(model=session.model,
-                         problem=session.problem,
-                         coords=coords,
-                         coords_norm=coords_norm,
-                         i_iter=None,
-                         i_subiter=None,
-                         fn_results=None,
-                         print_func_time=False)
-
-        if output_idx is None:
-            output_idx = np.arange(y_orig.shape[1])
-
-        y_orig = y_orig[:, output_idx]
-
-    else:
-
-        if output_idx is None:
-            output_idx = np.arange(data_original.shape[1])
-
-        grid_mc = Random(parameters_random=session.parameters_random,
-                         n_grid=0,
-                         options=None)
-        grid_mc.coords = coords
-        coords_norm = grid_mc.get_normalized_coordinates(coords)
-        y_orig = data_original
-
-        # y_orig = session.validation.results[:, output_idx]
-        # coords_norm = session.validation.grid.coords_norm
-        # coords = session.validation.grid.coords
-
-    if y_orig.ndim == 1:
-        y_orig = y_orig[:, np.newaxis]
-
-    # Evaluate gPC expansion on grid
-    if session.qoi_specific:
-        y_gpc = np.zeros((coords_norm.shape[0], len(output_idx)))
-
-        for i, o_idx in enumerate(output_idx):
-            y_gpc[:, i] = session.gpc[o_idx].get_approximation(coeffs=coeffs[o_idx], x=coords_norm,
-                                                               output_idx=0).flatten()
-
-    else:
-        y_gpc = session.gpc[0].get_approximation(coeffs=coeffs, x=coords_norm, output_idx=output_idx)
-
-    if y_gpc.ndim == 1:
-        y_gpc = y_gpc[:, np.newaxis]
-
-    # Calculate normalized root mean square deviation
-    relative_error_nrmsd = nrmsd(y_gpc, y_orig)
-
-    for i, o_idx in enumerate(output_idx):
-        pdf_y_gpc, tmp = np.histogram(y_gpc[:, i].flatten(), bins=bins, density=True)
-        pdf_x_gpc = (tmp[1:] + tmp[0:-1]) / 2.
-
-        pdf_y_orig, tmp = np.histogram(y_orig[:, i].flatten(), bins=bins, density=True)
-        pdf_x_orig = (tmp[1:] + tmp[0:-1]) / 2.
-
-        if smooth_pdf is not None:
-            if smooth_pdf is not False:
-                # smooth gpc pdf
-                y_gpc_smoothed = False
-                while not y_gpc_smoothed:
-                    try:
-                        pdf_y_gpc = savgol_filter(pdf_y_gpc, smooth_pdf[0], smooth_pdf[1])
-                        y_gpc_smoothed = True
-                    except np.linalg.LinAlgError:
-                        smooth_pdf[1] += int(3*np.random.random(1))
-
-                # smooth original pdf
-                y_orig_smoothed = False
-                while not y_orig_smoothed:
-                    try:
-                        pdf_y_orig = savgol_filter(pdf_y_orig, smooth_pdf[0], smooth_pdf[1])
-                        y_orig_smoothed = True
-                    except np.linalg.LinAlgError:
-                        smooth_pdf[1] += int(3*np.random.random(1))
-
-        # plot pdfs
-        if plot:
-            matplotlib.rc('text', usetex=False)
-            matplotlib.rc('xtick', labelsize=12)
-            matplotlib.rc('ytick', labelsize=12)
-
-            fig1, ax1 = plt.subplots(nrows=1, ncols=1, squeeze=True, figsize=(6, 5))
-
-            if hist is None:
-                ax1.plot(pdf_x_gpc, pdf_y_gpc, pdf_x_orig, pdf_y_orig)
-            else:
-                sns.distplot(y_gpc[:, i].flatten(), bins=bins, ax=ax1)
-                sns.distplot(y_orig[:, i].flatten(), bins=bins, label=r'original', ax=ax1)
-                # ax1.hist((y_gpc[:, i].flatten(), y_orig[:, i].flatten()), bins=bins, density=True)
-
-            ax1.legend([r'gpc', r'original'], fontsize=14, loc="upper right")
-            ax1.grid()
-            ax1.set_xlabel(r'$y$', fontsize=16)
-            ax1.set_ylabel(r'$p(y)$', fontsize=16)
-            ax1.text(0.05, 0.95, r'$error=%.2f$' % (100 * relative_error_nrmsd[0],) + "%",
-                     transform=ax1.transAxes, fontsize=12, verticalalignment='top',
-                     bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
-            plt.tight_layout()
-
-            if fn_out:
-                plt.savefig(os.path.splitext(fn_out)[0] + "_qoi_" + str(o_idx) + '.pdf')
-                plt.savefig(os.path.splitext(fn_out)[0] + "_qoi_" + str(o_idx) + '.png', dpi=1200)
-
-        if fn_out:
-            # save results in .hdf5 file
-            with h5py.File(os.path.splitext(fn_out)[0] + '.hdf5', 'a') as f:
-                f.create_dataset(folder + '/error/qoi_{}/nrmsd'.format(o_idx),
-                                 data=relative_error_nrmsd[i])
-                f.create_dataset(folder + '/pdf/qoi_{}/original'.format(o_idx),
-                                 data=np.vstack((pdf_x_orig, pdf_y_orig)).transpose())
-                f.create_dataset(folder + '/pdf/qoi_{}/gpc'.format(o_idx),
-                                 data=np.vstack((pdf_x_gpc, pdf_y_gpc)).transpose())
-                f.create_dataset(folder + '/grid/coords',
-                                 data=coords)
-                f.create_dataset(folder + '/grid/coords_norm',
-                                 data=coords_norm)
-                f.create_dataset(folder + '/model_evaluations/results/gpc',
-                                 data=y_gpc)
-                f.create_dataset(folder + '/model_evaluations/results/orig',
-                                 data=y_orig)
-
-    return relative_error_nrmsd
-
-
-def validate_gpc_plot(session, coeffs, random_vars, n_grid=None, coords=None, output_idx=0, data_original=None,
-                      fn_out=None, folder="gpc_vs_original_plot", n_cpu=1):
-    """
-    Compares gPC approximation with original model function. Evaluates both at n_grid (x n_grid) sampling points and
-    calculate the difference between two solutions at the output quantity with output_idx and saves the plot as
-    *_QOI_idx_<output_idx>.png/pdf. Also generates one .hdf5 results file with the evaluation results.
-
-    Parameters
-    ----------
-    session : GPC Session object instance
-        GPC session object containing all information i.e., gPC, Problem, Model, Grid, Basis, RandomParameter instances
-    coeffs : ndarray of float [n_coeffs x n_out] or list of ndarray of float [n_qoi][n_coeffs x n_out]
-        GPC coefficients
-    random_vars: str or list of str [2]
-        Names of the random variables, the analysis is performed for one or max. two random variables
-    n_grid : int or list of int [2], optional
-        Number of samples in each dimension to compare the gPC approximation with the original model function.
-        A cartesian grid is generated based on the limits of the specified random_vars
-    coords : ndarray of float [n_coords x n_dim]
-        Parameter combinations for the random_vars the comparison is conducted with
-    output_idx : int or list of int, optional, default=0
-        List of indices of output quantity to consider
-    data_original: ndarray of float [n_coords x n_out], optional, default: None
-        If available, data of original model function at grid, containing all QOIs
-    fn_out : str, optional, default: None
-        Filename of plot comparing original vs gPC model (*_QOI_idx_<output_idx>.png is added)
-        Filename of .hdf5 file containing the grid and the data from the original model and the gPC
-    folder : str, optional, default: "gpc_vs_original_plot"
-        Folder in .hdf5 file to save data in
-    n_cpu : int, default=1
-        Number of CPU cores to use to calculate results of original model on grid.
-
-    Returns
-    -------
-    <file> : .hdf5 file
-        Data file containing the grid points and the results of the original and the gpc approximation
-    <file> : .png and .pdf file
-        Plot comparing original vs gPC model
-    """
-    if type(output_idx) is int:
-        output_idx = [output_idx]
-
-    if type(random_vars) is not list:
-        random_vars = random_vars.tolist()
-
-    if n_grid and type(n_grid) is not list:
-        n_grid = n_grid.tolist()
-
-    # Create grid such that it includes the mean values of other random variables
-    if coords is None:
-        grid = np.zeros((np.prod(n_grid), len(session.parameters_random)))
-    else:
-        grid = np.zeros((coords.shape[0], len(session.parameters_random)))
-
-    idx = []
-    idx_global = []
-
-    # sort random_vars according to gpc.parameters
-    for i_p, p in enumerate(session.parameters_random.keys()):
-        if p not in random_vars:
-            grid[:, i_p] = session.parameters_random[p].mean
-
-        else:
-            idx.append(random_vars.index(p))
-            idx_global.append(i_p)
-
-    random_vars = [random_vars[i] for i in idx]
-    x = []
-
-    if coords is None:
-        n_grid = [n_grid[i] for i in idx]
-
-        for i_p, p in enumerate(random_vars):
-            x.append(np.linspace(session.parameters_random[p].pdf_limits[0],
-                                 session.parameters_random[p].pdf_limits[1],
-                                 n_grid[i_p]))
-
-        coords = get_cartesian_product(x)
-
-    else:
-        for i_p, p in enumerate(random_vars):
-            x.append(np.unique(coords[:, i_p]))
-
-    grid[:, idx_global] = coords
-
-    # Normalize grid
-    grid_norm = Grid(parameters_random=session.parameters_random).get_normalized_coordinates(grid)
-
-    # Evaluate gPC expansion on grid
-    if session.qoi_specific:
-        y_gpc = np.zeros((grid_norm.shape[0], len(output_idx)))
-
-        for i, o_idx in enumerate(output_idx):
-            y_gpc[:, i] = session.gpc[o_idx].get_approximation(coeffs=coeffs[o_idx], x=grid_norm,
-                                                               output_idx=0).flatten()
-
-    else:
-        y_gpc = session.gpc[0].get_approximation(coeffs=coeffs, x=grid_norm, output_idx=output_idx)
-
-    # Evaluate original model function on grid
-    if data_original is None:
-        com = Computation(n_cpu=n_cpu, matlab_model=session.matlab_model)
-        y_orig_all = com.run(model=session.model,
-                             problem=session.problem,
-                             coords=grid,
-                             coords_norm=grid_norm,
-                             i_iter=None,
-                             i_subiter=None,
-                             fn_results=None,
-                             print_func_time=False)
-        y_orig = y_orig_all[:, output_idx]
-
-    else:
-        y_orig_all = data_original
-        y_orig = data_original[:, output_idx]
-
-    # add axes if necessary
-    if y_gpc.ndim == 1:
-        y_gpc = y_gpc[:, np.newaxis]
-
-    if y_orig.ndim == 1:
-        y_orig = y_orig[:, np.newaxis]
-
-    # Evaluate difference between original and gPC approximation
-    y_dif = y_orig - y_gpc
-
-    # save results in .hdf5 file
-    if fn_out is not None:
-        with h5py.File(os.path.splitext(fn_out)[0] + '.hdf5', 'a') as f:
-            f.create_dataset(folder + '/model_evaluations/original', data=y_orig)
-            f.create_dataset(folder + '/model_evaluations/original_all_qoi', data=y_orig_all)
-            f.create_dataset(folder + '/model_evaluations/gpc', data=y_gpc)
-            f.create_dataset(folder + '/model_evaluations/difference', data=y_dif)
-            f.create_dataset(folder + '/grid/coords', data=grid)
-            f.create_dataset(folder + '/grid/coords_norm', data=grid_norm)
-
-    # Plot results
-    matplotlib.rc('text', usetex=False)
-    matplotlib.rc('xtick', labelsize=13)
-    matplotlib.rc('ytick', labelsize=13)
-    fs = 14
-
-    for i in range(len(output_idx)):
-        # One random variable
-        if len(random_vars) == 1:
-            fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, squeeze=True, figsize=(12, 5))
-
-            ax1.plot(coords, y_orig[:, i])
-            ax1.plot(coords, y_gpc[:, i])
-            ax1.legend([r"original", r"gPC"], fontsize=fs)
-            ax1.set_xlabel(r"%s" % random_vars[0], fontsize=fs)
-            ax1.set_ylabel(r"y(%s)" % random_vars[0], fontsize=fs)
-            ax1.grid()
-
-            ax2.plot(coords, y_dif[:, i], '--k')
-            ax2.legend([r"difference"], fontsize=fs)
-            ax1.set_xlabel(r"%s" % random_vars[0], fontsize=fs)
-            ax2.grid()
-
-        # Two random variables
-        elif len(random_vars) == 2:
-            fig, (ax1, ax2, ax3) = matplotlib.pyplot.subplots(nrows=1, ncols=3,
-                                                              sharex='all', sharey='all',
-                                                              squeeze=True, figsize=(16, 5))
-
-            x1_2d, x2_2d = np.meshgrid(x[0], x[1])
-
-            min_all = np.min(np.array(np.min(y_orig[:, i]), np.min(y_gpc[:, i])))
-            max_all = np.max(np.array(np.max(y_orig[:, i]), np.max(y_gpc[:, i])))
-
-            # Original model function
-            im1 = ax1.pcolor(x1_2d, x2_2d, np.reshape(y_orig[:, i], (x[1].size, x[0].size), order='f'),
-                             cmap="jet",
-                             vmin=min_all,
-                             vmax=max_all)
-            ax1.set_title(r'Original model', fontsize=fs)
-            ax1.set_xlabel(r"%s" % random_vars[0], fontsize=fs)
-            ax1.set_ylabel(r"%s" % random_vars[1], fontsize=fs)
-
-            # gPC approximation
-            # Original model function
-            im2 = ax2.pcolor(x1_2d, x2_2d, np.reshape(y_gpc[:, i], (x[1].size, x[0].size), order='f'),
-                             cmap="jet",
-                             vmin=min_all,
-                             vmax=max_all)
-            ax2.set_title(r'gPC approximation', fontsize=fs)
-            ax1.set_xlabel(r"%s" % random_vars[0], fontsize=fs)
-            ax1.set_ylabel(r"%s" % random_vars[1], fontsize=fs)
-
-            # Difference
-            min_dif = np.min(y_dif[:, i])
-            max_dif = np.max(y_dif[:, i])
-
-            b2rcw_cmap = make_cmap(b2rcw(min_dif, max_dif))
-
-            im3 = ax3.pcolor(x1_2d, x2_2d, np.reshape(y_dif[:, i], (x[1].size, x[0].size), order='f'),
-                             cmap=b2rcw_cmap,
-                             vmin=min_dif,
-                             vmax=max_dif)
-            ax3.set_title(r'Difference (Original vs gPC)', fontsize=fs)
-            ax1.set_xlabel(r"%s" % random_vars[0], fontsize=fs)
-            ax1.set_ylabel(r"%s" % random_vars[1], fontsize=fs)
-
-            fig.colorbar(im1, ax=ax1, orientation='vertical')
-            fig.colorbar(im2, ax=ax2, orientation='vertical')
-            fig.colorbar(im3, ax=ax3, orientation='vertical')
-
-            plt.tight_layout()
-
-        if fn_out is not None:
-            plt.savefig(os.path.splitext(fn_out)[0] + "_qoi_" + str(output_idx[i]) + '.png', dpi=1200)
-            plt.savefig(os.path.splitext(fn_out)[0] + "_qoi_" + str(output_idx[i]) + '.pdf')
+import os
+import h5py
+import scipy.stats
+from scipy.signal import savgol_filter
+from .misc import nrmsd
+from .misc import get_cartesian_product
+from pygpc.Computation import *
+from .MEGPC import *
+from .Grid import *
+from .Visualization import *
+
+try:
+    import matplotlib
+    import seaborn as sns
+    import matplotlib.pyplot as plt
+except ImportError:
+    pass
+
+
+def validate_gpc_mc(session, coeffs, coords=None, data_original=None, n_samples=1e4, output_idx=0, n_cpu=1,
+                    smooth_pdf=[51, 5], bins=100, hist=False, fn_out=None, folder="gpc_vs_original_mc", plot=True):
+    """
+    Compares gPC approximation with original model function. Evaluates both at "n_samples" sampling points and
+    evaluates the root mean square deviation. It also computes the pdf at the output quantity with output_idx
+    and saves the plot as fn_pdf.png and fn_pdf.pdf.
+
+    Parameters
+    ----------
+    session : GPC Session object instance
+        GPC session object containing all information i.e., gPC, Problem, Model, Grid, Basis, RandomParameter instances
+    coeffs : ndarray of float [n_coeffs x n_out]
+        GPC coefficients
+    coords : ndarray of float [n_coords x n_dim]
+        Parameter combinations for the random_vars the comparison is conducted with
+    data_original: ndarray of float [n_coords x n_out], optional, default: None
+        If available, data of original model function at grid, containing all QOIs
+    n_samples : int
+        Number of samples to validate the gPC approximation (ignored if coords and data_original is provided)
+    output_idx : int or ndarray of int or list of int, optional, default=None [1 x n_out]
+        Index of output quantities to consider (if output_idx=None, all output quantities are considered)
+    n_cpu : int, optional, default=1
+        Number of CPU cores to use (parallel function evaluations) to evaluate original model function
+    smooth_pdf : bool, optional, default: True
+        Smooth probability density functions using a Savgol filter [polylength, order]
+    bins : int, optional, default: 100
+        Number of bins to estimate pdf
+    hist : bool, optional, default: False
+        Plot histogram instead of pdf
+    fn_out : str or None
+        Filename of validation results and plot comparing original vs gPC model (w/o file extension)
+    folder : str, optional, default: "gpc_vs_original_plot"
+        Folder in .hdf5 file to save data in
+    plot : boolean, optional, default: True
+        Plots the pdfs of the original model function and the gPC approximation
+
+    Returns
+    -------
+    nrmsd : ndarray of float [n_out]
+        Normalized root mean square deviation for all output quantities between gPC and original model
+    <file> : .hdf5 file
+        Data file containing the sampling points, the results and the pdfs of the original and the gpc approximation
+    <file> : .pdf file
+        Plot showing the pdfs of the original and the gpc approximation
+    """
+
+    if smooth_pdf is True:
+        smooth_pdf = [51, 5]
+
+    if type(output_idx) is int:
+        output_idx = [output_idx]
+
+    if data_original is None or coords is None:
+        # Create sampling points
+        grid_mc = Random(parameters_random=session.parameters_random,
+                         n_grid=n_samples,
+                         options=None)
+
+        coords_norm = grid_mc.coords_norm
+        coords = grid_mc.coords
+
+        # Evaluate original model at grid points
+        com = Computation(n_cpu=n_cpu, matlab_model=session.matlab_model)
+
+        y_orig = com.run(model=session.model,
+                         problem=session.problem,
+                         coords=coords,
+                         coords_norm=coords_norm,
+                         i_iter=None,
+                         i_subiter=None,
+                         fn_results=None,
+                         print_func_time=False)
+
+        if output_idx is None:
+            output_idx = np.arange(y_orig.shape[1])
+
+        y_orig = y_orig[:, output_idx]
+
+    else:
+
+        if output_idx is None:
+            output_idx = np.arange(data_original.shape[1])
+
+        grid_mc = Random(parameters_random=session.parameters_random,
+                         n_grid=0,
+                         options=None)
+        grid_mc.coords = coords
+        coords_norm = grid_mc.get_normalized_coordinates(coords)
+        y_orig = data_original
+
+        # y_orig = session.validation.results[:, output_idx]
+        # coords_norm = session.validation.grid.coords_norm
+        # coords = session.validation.grid.coords
+
+    if y_orig.ndim == 1:
+        y_orig = y_orig[:, np.newaxis]
+
+    # Evaluate gPC expansion on grid
+    if session.qoi_specific:
+        y_gpc = np.zeros((coords_norm.shape[0], len(output_idx)))
+
+        for i, o_idx in enumerate(output_idx):
+            y_gpc[:, i] = session.gpc[o_idx].get_approximation(coeffs=coeffs[o_idx], x=coords_norm,
+                                                               output_idx=0).flatten()
+
+    else:
+        y_gpc = session.gpc[0].get_approximation(coeffs=coeffs, x=coords_norm, output_idx=output_idx)
+
+    if y_gpc.ndim == 1:
+        y_gpc = y_gpc[:, np.newaxis]
+
+    # Calculate normalized root mean square deviation
+    relative_error_nrmsd = nrmsd(y_gpc, y_orig)
+
+    for i, o_idx in enumerate(output_idx):
+        pdf_y_gpc, tmp = np.histogram(y_gpc[:, i].flatten(), bins=bins, density=True)
+        pdf_x_gpc = (tmp[1:] + tmp[0:-1]) / 2.
+
+        pdf_y_orig, tmp = np.histogram(y_orig[:, i].flatten(), bins=bins, density=True)
+        pdf_x_orig = (tmp[1:] + tmp[0:-1]) / 2.
+
+        if smooth_pdf is not None:
+            if smooth_pdf is not False:
+                # smooth gpc pdf
+                y_gpc_smoothed = False
+                while not y_gpc_smoothed:
+                    try:
+                        pdf_y_gpc = savgol_filter(pdf_y_gpc, smooth_pdf[0], smooth_pdf[1])
+                        y_gpc_smoothed = True
+                    except np.linalg.LinAlgError:
+                        smooth_pdf[1] += int(3*np.random.random(1))
+
+                # smooth original pdf
+                y_orig_smoothed = False
+                while not y_orig_smoothed:
+                    try:
+                        pdf_y_orig = savgol_filter(pdf_y_orig, smooth_pdf[0], smooth_pdf[1])
+                        y_orig_smoothed = True
+                    except np.linalg.LinAlgError:
+                        smooth_pdf[1] += int(3*np.random.random(1))
+
+        # plot pdfs
+        if plot:
+            matplotlib.rc('text', usetex=False)
+            matplotlib.rc('xtick', labelsize=12)
+            matplotlib.rc('ytick', labelsize=12)
+
+            fig1, ax1 = plt.subplots(nrows=1, ncols=1, squeeze=True, figsize=(6, 5))
+
+            if hist is None:
+                ax1.plot(pdf_x_gpc, pdf_y_gpc, pdf_x_orig, pdf_y_orig)
+            else:
+                sns.distplot(y_gpc[:, i].flatten(), bins=bins, ax=ax1)
+                sns.distplot(y_orig[:, i].flatten(), bins=bins, label=r'original', ax=ax1)
+                # ax1.hist((y_gpc[:, i].flatten(), y_orig[:, i].flatten()), bins=bins, density=True)
+
+            ax1.legend([r'gpc', r'original'], fontsize=14, loc="upper right")
+            ax1.grid()
+            ax1.set_xlabel(r'$y$', fontsize=16)
+            ax1.set_ylabel(r'$p(y)$', fontsize=16)
+            ax1.text(0.05, 0.95, r'$error=%.2f$' % (100 * relative_error_nrmsd[0],) + "%",
+                     transform=ax1.transAxes, fontsize=12, verticalalignment='top',
+                     bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
+            plt.tight_layout()
+
+            if fn_out:
+                plt.savefig(os.path.splitext(fn_out)[0] + "_qoi_" + str(o_idx) + '.pdf')
+                plt.savefig(os.path.splitext(fn_out)[0] + "_qoi_" + str(o_idx) + '.png', dpi=1200)
+
+        if fn_out:
+            # save results in .hdf5 file
+            with h5py.File(os.path.splitext(fn_out)[0] + '.hdf5', 'a') as f:
+                f.create_dataset(folder + '/error/qoi_{}/nrmsd'.format(o_idx),
+                                 data=relative_error_nrmsd[i])
+                f.create_dataset(folder + '/pdf/qoi_{}/original'.format(o_idx),
+                                 data=np.vstack((pdf_x_orig, pdf_y_orig)).transpose())
+                f.create_dataset(folder + '/pdf/qoi_{}/gpc'.format(o_idx),
+                                 data=np.vstack((pdf_x_gpc, pdf_y_gpc)).transpose())
+                f.create_dataset(folder + '/grid/coords',
+                                 data=coords)
+                f.create_dataset(folder + '/grid/coords_norm',
+                                 data=coords_norm)
+                f.create_dataset(folder + '/model_evaluations/results/gpc',
+                                 data=y_gpc)
+                f.create_dataset(folder + '/model_evaluations/results/orig',
+                                 data=y_orig)
+
+    return relative_error_nrmsd
+
+
+def validate_gpc_plot(session, coeffs, random_vars, n_grid=None, coords=None, output_idx=0, data_original=None,
+                      fn_out=None, folder="gpc_vs_original_plot", n_cpu=1):
+    """
+    Compares gPC approximation with original model function. Evaluates both at n_grid (x n_grid) sampling points and
+    calculate the difference between two solutions at the output quantity with output_idx and saves the plot as
+    *_QOI_idx_<output_idx>.png/pdf. Also generates one .hdf5 results file with the evaluation results.
+
+    Parameters
+    ----------
+    session : GPC Session object instance
+        GPC session object containing all information i.e., gPC, Problem, Model, Grid, Basis, RandomParameter instances
+    coeffs : ndarray of float [n_coeffs x n_out] or list of ndarray of float [n_qoi][n_coeffs x n_out]
+        GPC coefficients
+    random_vars: str or list of str [2]
+        Names of the random variables, the analysis is performed for one or max. two random variables
+    n_grid : int or list of int [2], optional
+        Number of samples in each dimension to compare the gPC approximation with the original model function.
+        A cartesian grid is generated based on the limits of the specified random_vars
+    coords : ndarray of float [n_coords x n_dim]
+        Parameter combinations for the random_vars the comparison is conducted with
+    output_idx : int or list of int, optional, default=0
+        List of indices of output quantity to consider
+    data_original: ndarray of float [n_coords x n_out], optional, default: None
+        If available, data of original model function at grid, containing all QOIs
+    fn_out : str, optional, default: None
+        Filename of plot comparing original vs gPC model (*_QOI_idx_<output_idx>.png is added)
+        Filename of .hdf5 file containing the grid and the data from the original model and the gPC
+    folder : str, optional, default: "gpc_vs_original_plot"
+        Folder in .hdf5 file to save data in
+    n_cpu : int, default=1
+        Number of CPU cores to use to calculate results of original model on grid.
+
+    Returns
+    -------
+    <file> : .hdf5 file
+        Data file containing the grid points and the results of the original and the gpc approximation
+    <file> : .png and .pdf file
+        Plot comparing original vs gPC model
+    """
+    if type(output_idx) is int:
+        output_idx = [output_idx]
+
+    if type(random_vars) is not list:
+        random_vars = random_vars.tolist()
+
+    if n_grid and type(n_grid) is not list:
+        n_grid = n_grid.tolist()
+
+    # Create grid such that it includes the mean values of other random variables
+    if coords is None:
+        grid = np.zeros((np.prod(n_grid), len(session.parameters_random)))
+    else:
+        grid = np.zeros((coords.shape[0], len(session.parameters_random)))
+
+    idx = []
+    idx_global = []
+
+    # sort random_vars according to gpc.parameters
+    for i_p, p in enumerate(session.parameters_random.keys()):
+        if p not in random_vars:
+            grid[:, i_p] = session.parameters_random[p].mean
+
+        else:
+            idx.append(random_vars.index(p))
+            idx_global.append(i_p)
+
+    random_vars = [random_vars[i] for i in idx]
+    x = []
+
+    if coords is None:
+        n_grid = [n_grid[i] for i in idx]
+
+        for i_p, p in enumerate(random_vars):
+            x.append(np.linspace(session.parameters_random[p].pdf_limits[0],
+                                 session.parameters_random[p].pdf_limits[1],
+                                 n_grid[i_p]))
+
+        coords = get_cartesian_product(x)
+
+    else:
+        for i_p, p in enumerate(random_vars):
+            x.append(np.unique(coords[:, i_p]))
+
+    grid[:, idx_global] = coords
+
+    # Normalize grid
+    grid_norm = Grid(parameters_random=session.parameters_random).get_normalized_coordinates(grid)
+
+    # Evaluate gPC expansion on grid
+    if session.qoi_specific:
+        y_gpc = np.zeros((grid_norm.shape[0], len(output_idx)))
+
+        for i, o_idx in enumerate(output_idx):
+            y_gpc[:, i] = session.gpc[o_idx].get_approximation(coeffs=coeffs[o_idx], x=grid_norm,
+                                                               output_idx=0).flatten()
+
+    else:
+        y_gpc = session.gpc[0].get_approximation(coeffs=coeffs, x=grid_norm, output_idx=output_idx)
+
+    # Evaluate original model function on grid
+    if data_original is None:
+        com = Computation(n_cpu=n_cpu, matlab_model=session.matlab_model)
+        y_orig_all = com.run(model=session.model,
+                             problem=session.problem,
+                             coords=grid,
+                             coords_norm=grid_norm,
+                             i_iter=None,
+                             i_subiter=None,
+                             fn_results=None,
+                             print_func_time=False)
+        y_orig = y_orig_all[:, output_idx]
+
+    else:
+        y_orig_all = data_original
+        y_orig = data_original[:, output_idx]
+
+    # add axes if necessary
+    if y_gpc.ndim == 1:
+        y_gpc = y_gpc[:, np.newaxis]
+
+    if y_orig.ndim == 1:
+        y_orig = y_orig[:, np.newaxis]
+
+    # Evaluate difference between original and gPC approximation
+    y_dif = y_orig - y_gpc
+
+    # save results in .hdf5 file
+    if fn_out is not None:
+        with h5py.File(os.path.splitext(fn_out)[0] + '.hdf5', 'a') as f:
+            f.create_dataset(folder + '/model_evaluations/original', data=y_orig)
+            f.create_dataset(folder + '/model_evaluations/original_all_qoi', data=y_orig_all)
+            f.create_dataset(folder + '/model_evaluations/gpc', data=y_gpc)
+            f.create_dataset(folder + '/model_evaluations/difference', data=y_dif)
+            f.create_dataset(folder + '/grid/coords', data=grid)
+            f.create_dataset(folder + '/grid/coords_norm', data=grid_norm)
+
+    # Plot results
+    matplotlib.rc('text', usetex=False)
+    matplotlib.rc('xtick', labelsize=13)
+    matplotlib.rc('ytick', labelsize=13)
+    fs = 14
+
+    for i in range(len(output_idx)):
+        # One random variable
+        if len(random_vars) == 1:
+            fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, squeeze=True, figsize=(12, 5))
+
+            ax1.plot(coords, y_orig[:, i])
+            ax1.plot(coords, y_gpc[:, i])
+            ax1.legend([r"original", r"gPC"], fontsize=fs)
+            ax1.set_xlabel(r"%s" % random_vars[0], fontsize=fs)
+            ax1.set_ylabel(r"y(%s)" % random_vars[0], fontsize=fs)
+            ax1.grid()
+
+            ax2.plot(coords, y_dif[:, i], '--k')
+            ax2.legend([r"difference"], fontsize=fs)
+            ax1.set_xlabel(r"%s" % random_vars[0], fontsize=fs)
+            ax2.grid()
+
+        # Two random variables
+        elif len(random_vars) == 2:
+            fig, (ax1, ax2, ax3) = matplotlib.pyplot.subplots(nrows=1, ncols=3,
+                                                              sharex='all', sharey='all',
+                                                              squeeze=True, figsize=(16, 5))
+
+            x1_2d, x2_2d = np.meshgrid(x[0], x[1])
+
+            min_all = np.min(np.array(np.min(y_orig[:, i]), np.min(y_gpc[:, i])))
+            max_all = np.max(np.array(np.max(y_orig[:, i]), np.max(y_gpc[:, i])))
+
+            # Original model function
+            im1 = ax1.pcolor(x1_2d, x2_2d, np.reshape(y_orig[:, i], (x[1].size, x[0].size), order='f'),
+                             cmap="jet",
+                             vmin=min_all,
+                             vmax=max_all)
+            ax1.set_title(r'Original model', fontsize=fs)
+            ax1.set_xlabel(r"%s" % random_vars[0], fontsize=fs)
+            ax1.set_ylabel(r"%s" % random_vars[1], fontsize=fs)
+
+            # gPC approximation
+            # Original model function
+            im2 = ax2.pcolor(x1_2d, x2_2d, np.reshape(y_gpc[:, i], (x[1].size, x[0].size), order='f'),
+                             cmap="jet",
+                             vmin=min_all,
+                             vmax=max_all)
+            ax2.set_title(r'gPC approximation', fontsize=fs)
+            ax1.set_xlabel(r"%s" % random_vars[0], fontsize=fs)
+            ax1.set_ylabel(r"%s" % random_vars[1], fontsize=fs)
+
+            # Difference
+            min_dif = np.min(y_dif[:, i])
+            max_dif = np.max(y_dif[:, i])
+
+            b2rcw_cmap = make_cmap(b2rcw(min_dif, max_dif))
+
+            im3 = ax3.pcolor(x1_2d, x2_2d, np.reshape(y_dif[:, i], (x[1].size, x[0].size), order='f'),
+                             cmap=b2rcw_cmap,
+                             vmin=min_dif,
+                             vmax=max_dif)
+            ax3.set_title(r'Difference (Original vs gPC)', fontsize=fs)
+            ax1.set_xlabel(r"%s" % random_vars[0], fontsize=fs)
+            ax1.set_ylabel(r"%s" % random_vars[1], fontsize=fs)
+
+            fig.colorbar(im1, ax=ax1, orientation='vertical')
+            fig.colorbar(im2, ax=ax2, orientation='vertical')
+            fig.colorbar(im3, ax=ax3, orientation='vertical')
+
+            plt.tight_layout()
+
+        if fn_out is not None:
+            plt.savefig(os.path.splitext(fn_out)[0] + "_qoi_" + str(output_idx[i]) + '.png', dpi=1200)
+            plt.savefig(os.path.splitext(fn_out)[0] + "_qoi_" + str(output_idx[i]) + '.pdf')
```

## pygpc/testfunctions/__init__.py

 * *Ordering differences only*

```diff
@@ -1 +1 @@
-from .testfunctions import *
+from .testfunctions import *
```

## pygpc/testfunctions/euber_libV3.py

```diff
@@ -1,481 +1,485 @@
-# Version 3 with steiner implenentation for non-mid section 2
-import sympy as sp
-from sympy import Matrix as syma
-from sympy import diff
-import numpy as np
-import scipy.optimize
-import pdb
-import mpmath as mp
-from matplotlib.patches import Rectangle
-import matplotlib.pyplot as plt
-
-
-class euber():
- 
-    def __init__(self):
-        eigenvalues_of_simple_bridge = [4.7300407449, 7.8532046241, 10.9956078382, 14.1371654913, 17.2787596574, 20.4203522456]
-        # sympy stuff
-        self.x = sp.symbols('x')
-        tau1, tau2 = sp.symbols('tau1 tau2')
-        tau11, tau12, tau13 = sp.symbols('tau11 tau12 tau13')
-        tau21, tau22, tau23 = sp.symbols('tau21 tau22 tau23')
-        # L_1, L_2, L_3 = sp.symbols('L_1 L_2  L_3')
-        # E_1, E_2, E_3 = sp.symbols('E_1 E_2 E_3')
-        # I_1, I_2, I_3 = sp.symbols('I_1 I_2 I_3')
-        # A_1, A_2, A_3 = sp.symbols('A_1 A_2 A_3')
-        # rho_1, rho_2, rho_3 = sp.symbols('rho_1 rho_2 rho_3')
-
-        self.Lsym_1, self.Lsym_2, self.Lsym_3 = sp.symbols('Lsym_1 Lsym_2 Lsym_3')
-        self.Esym_1, self.Esym_2, self.Esym_3 = sp.symbols('Esym_1 Esym_2 Esym_3')
-        self.Isym_1, self.Isym_2, self.Isym_3 = sp.symbols('Isym_1 Isym_2 Isym_3')
-
-        # trancendet Ansatz functions for E-B-Beam with 3 sections and axial tension
-        TRAN_axt = ([sp.cos(self.x*tau1), sp.sin(self.x*tau1), sp.cosh(self.x*tau2), sp.sinh(self.x*tau2)])
-        self.X1_axt = [i.subs([(tau1, tau11)
-                               ,(tau2, tau21)]) for i in TRAN_axt]
-        self.X2_axt = [i.subs([(tau1, tau12)
-                               ,(tau2, tau22)]) for i in TRAN_axt]
-        self.X3_axt = [i.subs([(tau1, tau13)
-                               ,(tau2, tau23)]) for i in TRAN_axt]
-
-       #mpmath
-        self.tau1_sec1_axt_mp = lambda omega, k1, p1: mp.sqrt(2)*mp.sqrt((mp.sqrt(4*k1**4*omega**2 + p1**4) - p1**2)/k1**4)/2 #sin&cos = LOI2
-        self.tau1_sec2_axt_mp = lambda lambda_1,k1,k2,p1,p2: ((1/2)*mp.sqrt(-2*p2**4 + 2*mp.sqrt(4*k1**4*k2**4*lambda_1**4 + 4*k2**4*lambda_1**2*p1**4 + p2**8))/k2**2)
-        self.tau1_sec3_axt_mp = lambda lambda_1,k1,k3,p1,p3: ((1/2)*mp.sqrt(-2*p3**4 + 2*mp.sqrt(4*k1**4*k3**4*lambda_1**4 + 4*k3**4*lambda_1**2*p1**4 + p3**8))/k3**2)
-
-        self.tau2_sec1_axt_mp = lambda omega, k1, p1: mp.sqrt(2)*mp.sqrt((p1**2 + mp.sqrt(4*k1**4*omega**2 + p1**4))/k1**4)/2 #sinh&cosh = LOI1
-        self.tau2_sec2_axt_mp = lambda lambda_1,k1,k2,p1,p2: ((1/2)*mp.sqrt(2*p2**4 + 2*mp.sqrt(4*k1**4*k2**4*lambda_1**4 - 4*k2**4*lambda_1**2*p1**4 + p2**8))/k2**2)
-        self.tau2_sec3_axt_mp = lambda lambda_1,k1,k3,p1,p3: ((1/2)*mp.sqrt(2*p3**4 + 2*mp.sqrt(4*k1**4*k3**4*lambda_1**4 - 4*k3**4*lambda_1**2*p1**4 + p3**8))/k3**2)
-        self.tau2_23_alt = lambda lambda_1,k1,k2,p1,p2: ((1/2)*mp.sqrt(2*p2**4 - 2*mp.sqrt(4*k1**4*k2**4*lambda_1**4 - 4*k2**4*lambda_1**2*p1**4 + p2**8))/k2**2)
-
-
-        # Calculating lambda initially to avoid multiple calculations
-        self.BCMatrix_3sec_axt_lambda = self.get_BCMatrix_3sec_axt_lambda()
-
-        # Precision with mpmath calculations (Determinant and taus)
-        self.prec = 50
-
-    def define_simple_beam(self, b1=0.03, b2=0.05, b3=0.03,
-                                 h1=0.02, h2=0.01, h3=0.02,
-                                 L1=0.3, L2=0.7, L3=1.0,
-                                 E1=200.0e9, E2=70.0e9, E3=200.0e9,
-                                 rho1=8700.0, rho2=2700.0, rho3=8700.0,
-                                 N=100):
-        self.b_1 = b1
-        self.b_2 = b2
-        self.b_3 = b3
-        self.h_1 = h1
-        self.h_2 = h2
-        self.h_3 = h3
-        self.L_1 = L1
-        self.L_2 = L2
-        self.L_3 = L3
-        self.E_1 = E1
-        self.E_2 = E2
-        self.E_3 = E3
-        self.rho_1 = rho1
-        self.rho_2 = rho2
-        self.rho_3 = rho3
-        self.N = N
-        self.A_1, self.I_1 = self.get_area_and_inertia_rectangle(self.b_1, self.h_1)
-        self.A_2, self.I_2 = self.get_area_and_inertia_rectangle(self.b_2, self.h_2)
-        self.A_3, self.I_3 = self.get_area_and_inertia_rectangle(self.b_3, self.h_3)
-        self.k_1, self.p_1 = self.get_k_and_p_value(self.A_1, self.I_1, E1, rho1, N)
-        self.k_2, self.p_2 = self.get_k_and_p_value(self.A_2, self.I_2, E2, rho2, N)
-        self.k_3, self.p_3 = self.get_k_and_p_value(self.A_3, self.I_3, E3, rho3, N)
-        
-    def define_layered_beam(self, b1=0.03, #b2=0.05, b3=0.03,            #Sections
-                                  L1=0.3, L2=0.7, L3=1.0,               #Sections
-                                  dA=0.02, dB=0.01, dC=0.02,            #Layers
-                                  EA=200.0e9, EB=70.0e9, EC=200.0e9,    #Layers
-                                  rhoA=8700.0, rhoB=2700.0, rhoC=8700.0,#Layers
-                                  N=100):                               #uniform
-        
-        #Layers
-        self.b_1 = b1
-        self.b_2 = b1 #!!
-        self.b_3 = b1 #!!
-        self.h_1 = dA + dB + dC
-        self.h_2 = dA + dB
-        self.h_3 = self.h_1
-        self.L_1 = L1
-        self.L_2 = L2
-        self.L_3 = L3
-        self.d_A = dA
-        self.d_B = dB
-        self.d_C = dC
-
-        #Sections
-        self.E_A = EA
-        self.E_B = EB
-        self.E_C = EC
-        self.rho_A = rhoA
-        self.rho_B = rhoB
-        self.rho_C = rhoC
-
-        self.init_parameter_lists()
-        
-        #self.get_section_E([EA, EB, EC], [dA, dB, dC])
-        self.I_1 = np.sum(self.I_layers123_steiner)
-        self.I_2 = np.sum(self.I_layers12_steiner)
-        dist_of_neutral_layers = self.h_1/2 - self.h_2/2#- self.get_neutral_layer(self.ys[:2], self.A_layers[:2], self.E_layers[:2])
-        #self.I_2 = self.I_2 + (self.d_C/2)**2 * np.sum(self.A_layers[:1])
-        
-
-        self.I_3 = self.I_1
-
-        self.E_1 = np.sum(self.I_layers123_steiner*self.E_layers)/self.I_1
-        #self.E_2 = np.sum(self.I_layers12_steiner*self.E_layers[:2])/np.sum(self.I_layers12_steiner)
-        self.E_2 = np.sum(self.I_layers12_steiner*self.E_layers[:2])/self.I_2
-        self.E_3 = self.E_1 # Seciton1 and 3 have same layers
-        self.I_2 = self.I_2 + dist_of_neutral_layers**2 * np.sum(self.A_layers[:1])
-
-
-        self.A_1 = np.sum(self.A_layers)
-        self.A_2 = np.sum(self.A_layers[:2])
-        self.A_3 = self.A_1 # Seciton1 and 3 have same layers
-        self.rho_1 = np.sum(self.rho_layers_weighted)/self.A_1
-        self.rho_2 = np.sum(self.rho_layers_weighted[:2])/self.A_2
-        self.rho_3 = self.rho_1 # Seciton1 and 3 have same layers
-
-        self.k_1, self.p_1 = self.get_k_and_p_value(self.A_1, self.I_1, self.E_1, self.rho_1, N)
-        self.k_2, self.p_2 = self.get_k_and_p_value(self.A_2, self.I_2, self.E_2, self.rho_2, N)
-        self.k_3, self.p_3 = self.get_k_and_p_value(self.A_3, self.I_3, self.E_3, self.rho_3, N)
-
-    def init_parameter_lists(self):
-        # Sections 123
-        self.b = np.array([self.b_1, self.b_2, self.b_3])
-        helper = self.d_A + self.d_B + self.d_C
-        self.height = np.array([helper, helper - self.d_C, helper]) # only if A_1  = A3
-
-        # Layers abc
-        self.d = np.array([self.d_A, self.d_B, self.d_C])
-        self.ys = self.get_centerpoints_of_layers_rectangle(*self.d) # center points of each Layer
-        self.E_layers = np.array([self.E_A, self.E_B, self.E_C])
-        self.A_layers, self.I_layers = self.get_area_and_inertia_rectangle(self.b, self.d)# only if b = [b1,b1,b1]=[bA,bB,bC]
-        
-        self.I_layers123_steiner = self.get_weighted_I_layer()
-        self.I_layers12_steiner = self.get_weighted_I_layer(layers=[0, 1])
-
-        self.rho_layers = np.array([self.rho_A, self.rho_B, self.rho_C])
-        self.rho_layers_weighted = self.get_weighted_rho_layer()
-
-    def get_weighted_I_layer(self, layers=[0, 1, 2]):
-        neutral_layer = self.get_neutral_layer(self.ys[layers], self.A_layers[layers], self.E_layers[layers])
-        offset_to_neutral_layer = self.ys[layers] - neutral_layer
-        # print(neutral_layer)
-        # print(offset_to_neutral_layer)
-        return np.array(self.I_layers[layers] + offset_to_neutral_layer**2*self.A_layers[layers])
-        
-    def get_weighted_rho_layer(self):
-        return self.rho_layers * self.A_layers
-
-    # Systemmatrix for beam with 3 sections and axial tension
-    # #######################################################
-    def BCMatrix_3sec_axt(self):
-        BC = sp.zeros(12,12)
-        # Boundary Conditions left x==|--|==|
-        BC[0,:] = syma([[i.subs(self.x,0) for i in self.X1_axt] + 
-                        [0,0,0,0] + 
-                        [0,0,0,0] ])  
-
-        BC[1,:] = syma([[diff(i,self.x).subs(self.x,0) for i in self.X1_axt] +
-                        [0,0,0,0] + 
-                        [0,0,0,0] ])
-
-        # Transition Conditions left |==x--|==|
-        BC[2,:] = syma([[i.subs(self.x,self.Lsym_1) for i in self.X1_axt]  + 
-                        [i.subs(self.x,self.Lsym_1)*(-1) for i in self.X2_axt] + 
-                        [0,0,0,0] ])
-
-        BC[3,:] = syma([[diff(i,self.x).subs(self.x,self.Lsym_1) for i in self.X1_axt]  + 
-                        [diff(i,self.x).subs(self.x,self.Lsym_1)*(-1) for i in self.X2_axt] + 
-                        [0,0,0,0] ])
-
-        BC[4,:] = syma([[self.Esym_1*self.Isym_1*diff(i,self.x,self.x).subs(self.x,self.Lsym_1)*(-1)  for i in self.X1_axt] + 
-                        [self.Esym_2*self.Isym_2*diff(i,self.x,self.x).subs(self.x,self.Lsym_1)  for i in self.X2_axt]+ 
-                        [0,0,0,0] ])
-
-        BC[5,:] = syma([[self.Esym_1*self.Isym_1*diff(i,self.x,self.x,self.x).subs(self.x,self.Lsym_1)  for i in self.X1_axt] + 
-                        [self.Esym_2*self.Isym_2*diff(i,self.x,self.x,self.x).subs(self.x,self.Lsym_1)*(-1)  for i in self.X2_axt]+ 
-                        [0,0,0,0] ])
-
-        # Transition Conditions right |==|--x==|
-        BC[6,:] = syma([[0,0,0,0] +
-                        [i.subs(self.x,self.Lsym_2) for i in self.X2_axt] + 
-                        [i.subs(self.x,self.Lsym_2)*(-1) for i in self.X3_axt]]) 
-
-        BC[7,:] = syma([[0,0,0,0] +
-                        [diff(i,self.x).subs(self.x,self.Lsym_2) for i in self.X2_axt] + 
-                        [diff(i,self.x).subs(self.x,self.Lsym_2)*(-1) for i in self.X3_axt]]) 
-        BC[8,:] = syma([[0,0,0,0] +
-                        [self.Esym_2*self.Isym_2*diff(i,self.x,self.x).subs(self.x,self.Lsym_2)*(-1) for i in self.X2_axt] + 
-                        [self.Esym_3*self.Isym_3*diff(i,self.x,self.x).subs(self.x,self.Lsym_2) for i in self.X3_axt]]) 
-        BC[9,:] = syma([[0,0,0,0] +
-                        [self.Esym_2*self.Isym_2*diff(i,self.x,self.x,self.x).subs(self.x,self.Lsym_2) for i in self.X2_axt] + 
-                        [self.Esym_3*self.Isym_3*diff(i,self.x,self.x,self.x).subs(self.x,self.Lsym_2)*(-1) for i in self.X3_axt]]) 
-
-        # Boundary Conditions right |==|--|==x
-        BC[10,:] = syma([[0,0,0,0] +
-                        [0,0,0,0] +  
-                        [i.subs(self.x, self.Lsym_3) for i in self.X3_axt]]) 
-        BC[11,:] = syma([[0,0,0,0] + 
-                        [0,0,0,0] +
-                        [diff(i,self.x).subs(self.x, self.Lsym_3) for i in self.X3_axt]]) 
-        return BC
-
-    def get_BCMatrix_3sec_axt_lambda(self):
-        #smbls = ['tau11', 'tau21', 'tau12', 'tau22', 'tau13', 'tau23', 'E_1', 'E_2', 'E_3', 'I_1', 'I_2', 'I_3', 'L_1', 'L_2', 'L_3']
-        smbls = ['tau11', 'tau21', 'tau12', 'tau22', 'tau13', 'tau23', 
-                 'Esym_1', 'Esym_2', 'Esym_3', 
-                 'Isym_1', 'Isym_2', 'Isym_3', 
-                 'Lsym_1', 'Lsym_2', 'Lsym_3']
-        symdet = self.BCMatrix_3sec_axt()
-        return sp.utilities.lambdify(smbls, symdet, modules='mpmath')
-    
-    def calc_taus(self, omega):
-        mp.mp.dps = self.prec
-        
-        # Section 1
-        self.tau11 = mp.fabs(self.tau1_sec1_axt_mp(omega, self.k_1, self.p_1))
-        self.tau21 = mp.fabs(self.tau2_sec1_axt_mp(omega, self.k_1, self.p_1))
-        # Section 2
-        self.tau12 = mp.fabs(self.tau1_sec2_axt_mp(self.tau11, self.k_1, self.k_2, self.p_1, self.p_2))
-        self.tau22 = mp.fabs(self.tau2_sec2_axt_mp(self.tau21, self.k_1, self.k_2, self.p_1, self.p_2))
-        # Section 3
-        self.tau13 = mp.fabs(self.tau1_sec3_axt_mp(self.tau11, self.k_1, self.k_3, self.p_1, self.p_3))
-        self.tau23 = mp.fabs(self.tau2_sec3_axt_mp(self.tau21, self.k_1, self.k_3, self.p_1, self.p_3))
-    
-    
-    def get_BCMatrix_3sec_axt_det(self):
-        mp.mp.dps = self.prec
-        mat = self.BCMatrix_3sec_axt_lambda(self.tau11, self.tau21,
-                                            self.tau12, self.tau22,
-                                            self.tau13, self.tau23,
-                                            self.E_1, self.E_2, self.E_3, 
-                                            self.I_1, self.I_2, self.I_3, 
-                                            self.L_1, self.L_2, self.L_3)
-        det = mp.det(mat)
-        det = np.float64( mp.log(mp.fabs(det))*mp.sign(det) )
-        return det
-
-    def peek_det(self, oms):
-        mp.mp.dps = self.prec
-        det = []
-        for om in oms:
-            self.calc_taus(om)
-            det.append( self.get_BCMatrix_3sec_axt_det() )
-        return np.array(det)
-
-    def peek_det_scalar(self, om):
-        mp.mp.dps = self.prec
-        self.calc_taus(om)
-        return self.get_BCMatrix_3sec_axt_det() 
-        
-
-
-    def lyrd_beam_reduced_params(self, b1, 
-                                 l1, l2, l3, 
-                                 dA, dB, dC, 
-                                 EA=200.0e9, EB=70.0e9, EC=200.0e9,    #Layers
-                                 rhoA=8700.0, rhoB=2700.0, rhoC=8700.0,#Layers
-                                 N=1000):
-        L1 = l1
-        L2 = l1 + l2
-        L3 = l1 + l2 + l3 
-        self.define_layered_beam(b1,                                   #Sections
-                                L1, L2, L3,                           #Sections
-                                dA, dB, dC,                           #Layers
-                                EA=EA, EB=EB, EC=EC,    #Layers
-                                rhoA=rhoA, rhoB=rhoB, rhoC=rhoC,#Layers
-                                N=N                               #uniform
-                                )
-
-    # search angular eigenfrequencies
-    def get_first3_ekf(self):
-        # does not work on random structures
-        det = []
-        om = 100.0
-        while True:
-            det.append(self.peek_det_scalar(om))
-            if len(det)>1 and np.sign(det[-2]) != np.sign(det[-1]):
-                om1 = scipy.optimize.brentq(self.peek_det_scalar,om-100,om)
-                break
-            om += 100
-        om2 = scipy.optimize.brentq(self.peek_det_scalar, om1*2, om1*3, xtol=1e-2)
-        om3 = scipy.optimize.brentq(self.peek_det_scalar, om1*3, om2*3, xtol=1e-2)
-        return np.array([om1, om2, om3])
-
-    def get_first_n_ekf_bruteforce(self, n=3, om=100.0, stepsize=100.0, brentq_xtol=1e-2):
-        det = []
-        oms = []        
-        ekfs = []
-        while True:
-            det.append(self.peek_det_scalar(om))
-            oms.append(om)
-            if len(det)>1 and np.sign(det[-2]) != np.sign(det[-1]):
-                ekfs.append( scipy.optimize.brentq(self.peek_det_scalar,oms[-2],oms[-1], xtol=brentq_xtol) )
-                stepsize = ekfs[0]
-                if len(ekfs) == n:
-                    return np.array(ekfs), det, oms
-                    
-            om += stepsize
-
-            
-                    
-            om += stepsize
-    ### alternative eigenvalue calc
-    def calc_taus_alt(self, omega):
-        mp.mp.dps = self.prec
-        
-        # Section 1
-        self.tau11 = mp.fabs(self.tau1_sec1_axt_mp(omega, self.k_1, self.p_1))
-        self.tau21 = mp.fabs(self.tau2_sec1_axt_mp(omega, self.k_1, self.p_1))
-        # Section 2
-        self.tau12 = mp.fabs(self.tau1_sec2_axt_mp(self.tau11, self.k_1, self.k_2, self.p_1, self.p_2))
-        self.tau22 = mp.fabs(self.tau2_sec2_axt_mp(self.tau21, self.k_1, self.k_2, self.p_1, self.p_2))
-        # Section 3
-        self.tau13 = mp.fabs(self.tau1_sec3_axt_mp(self.tau11, self.k_1, self.k_3, self.p_1, self.p_3))
-        self.tau23 = mp.fabs(self.tau2_23_alt(self.tau21, self.k_1, self.k_3, self.p_1, self.p_3))
-
-    def get_first_n_ekf_bruteforce_alt(self, n=3, om=100.0, stepsize=100.0, brentq_xtol=1e-2):
-        det = []
-        oms = []        
-        ekfs = []
-        while True:
-            det.append(self.peek_det_scalar_alt(om))
-            oms.append(om)
-            if len(det)>1 and np.sign(det[-2]) != np.sign(det[-1]):
-                ekfs.append( scipy.optimize.brentq(self.peek_det_scalar_alt,oms[-2],oms[-1], xtol=brentq_xtol) )
-                stepsize = ekfs[0]
-                if len(ekfs) == n:
-                    return np.array(ekfs), det, oms
-                    
-            om += stepsize
-    def peek_det_scalar_alt(self, om):
-        mp.mp.dps = self.prec
-        self.calc_taus_alt(om)
-        return self.get_BCMatrix_3sec_axt_det() 
- 
-    
-
-    ### Static Methods
-    @staticmethod
-    def get_approx_ekf(fist_3_ekfs, order, poly_deg=2):
-        coef = np.polyfit(range(1, poly_deg+2), fist_3_ekfs, poly_deg)
-        return np.polyval(coef, order)
-
-    @staticmethod
-    def get_area_and_inertia_rectangle(b, h):
-        A = b * h
-        Iz = b * h**3 / 12
-        return A, Iz
-    
-    @staticmethod
-    def get_k_and_p_value(A, Iz, E, rho, N):
-        k = (E * Iz / rho / A )**0.25
-        p = (N / rho / A)**0.5
-        return k, p
-       
-    @staticmethod
-    def get_centerpoints_of_layers_rectangle(*args):
-        return np.array([d/2+sum(args[:i]) for i, d in enumerate(args)])
-
-    @staticmethod
-    def get_neutral_layer(ys, A_layers, E_layers):
-        helper = np.array(A_layers * E_layers)
-        return np.sum(ys * helper) / np.sum(helper)
-
-
-def plot_beam_geometry(geom_param, hight_factor=10 , colors=['red', 'green', 'orange']):
-    # Plotting Geometry
-    b1, l1, l2, l3, hA, hB, hC = geom_param
-    hA, hB, hC = hA*hight_factor, hB*hight_factor, hC*hight_factor
-    rects = []
-    # layerA
-    rects.append(Rectangle((0, 0), l1+l2+l3, hA, color=colors[0], edgecolor=None,linewidth=0))
-    # layerB
-    rects.append(Rectangle((0, hA), l1+l2+l3, hB, color=colors[1], edgecolor=None, linewidth=0))
-    # layerC
-    rects.append(Rectangle((0, hA+hB), l1, hC, color=colors[2], edgecolor=None, linewidth=0))
-    rects.append(Rectangle((l1+l2,hA+hB), l3, hC, color=colors[2], edgecolor=None, linewidth=0))
-
-    fig, ax = plt.subplots(1, figsize=cm2inch((l1+l2+l3)*3.2, (hA+hB+hC)*1.2), subplot_kw={'xlim':(0,l1+l2+l3), 'ylim':(0,hA+hB+hC)})
-    [ax.add_patch(p) for p in rects]
-    ax.axis('off')
-
-    return fig
-
-    
-def cm2inch(*tupl):
-    inch = 2.54
-    if isinstance(tupl[0], tuple):
-        return tuple(i/inch for i in tupl[0])
-    else:
-        return tuple(i/inch for i in tupl)
-# import time
-# cycls = 200
-
-# # init_time = time.time()
-# # for _ in range(cycls):
-# #     bb = euber()
-# # init_time = (time.time() - init_time)/cycls
-# bb = euber()
-# definetime = time.time()
-# for _ in range(cycls):
-#     bb.define_layered_beam()
-# definetime = (time.time() - definetime)/cycls
-
-# dettime = time.time()
-# for _ in range(cycls):
-#     bb.calc_taus(30)
-#     bb.get_BCMatrix_3sec_axt_det()
-# dettime = (time.time() - dettime)/cycls
-
-# print(definetime, dettime)
-
-# beam = euber()
-# beam.define_layered_beam()
-# bendingstiffness = lambda E,I,y,A: np.sum( np.array(E)*(np.array(I)+np.array(y)**2*np.array(A)) )
-# reduced_mass = lambda rho, A: np.sum(rho*A)
-
-# E = beam.E_layers
-# A = beam.A_layers
-# layers = [0,1,2]
-# helper = np.array(beam.A_layers[layers]) * np.array(beam.E_layers[layers])
-# neutral_layer = np.sum(np.array(beam.ys[layers]) * helper) / np.sum(helper)
-# offset_to_neutral_layer = beam.ys[layers] - neutral_layer
-# I_layers = beam.b * beam.d**3/12
-# EI_from_euber = beam.E_1*beam.I_1
-
-# mss = reduced_mass(beam.rho_layers, A)
-# print(f'oop={beam.rho_1 * beam.A_1}')
-# print(f'bnd={mss}')
-# 1+1
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
+# Version 3 with steiner implenentation for non-mid section 2
+import sympy as sp
+from sympy import Matrix as syma
+from sympy import diff
+import numpy as np
+import scipy.optimize
+import pdb
+import mpmath as mp
+
+try:
+    from matplotlib.patches import Rectangle
+    import matplotlib.pyplot as plt
+except ImportError:
+    pass
+
+
+class euber():
+ 
+    def __init__(self):
+        eigenvalues_of_simple_bridge = [4.7300407449, 7.8532046241, 10.9956078382, 14.1371654913, 17.2787596574, 20.4203522456]
+        # sympy stuff
+        self.x = sp.symbols('x')
+        tau1, tau2 = sp.symbols('tau1 tau2')
+        tau11, tau12, tau13 = sp.symbols('tau11 tau12 tau13')
+        tau21, tau22, tau23 = sp.symbols('tau21 tau22 tau23')
+        # L_1, L_2, L_3 = sp.symbols('L_1 L_2  L_3')
+        # E_1, E_2, E_3 = sp.symbols('E_1 E_2 E_3')
+        # I_1, I_2, I_3 = sp.symbols('I_1 I_2 I_3')
+        # A_1, A_2, A_3 = sp.symbols('A_1 A_2 A_3')
+        # rho_1, rho_2, rho_3 = sp.symbols('rho_1 rho_2 rho_3')
+
+        self.Lsym_1, self.Lsym_2, self.Lsym_3 = sp.symbols('Lsym_1 Lsym_2 Lsym_3')
+        self.Esym_1, self.Esym_2, self.Esym_3 = sp.symbols('Esym_1 Esym_2 Esym_3')
+        self.Isym_1, self.Isym_2, self.Isym_3 = sp.symbols('Isym_1 Isym_2 Isym_3')
+
+        # trancendet Ansatz functions for E-B-Beam with 3 sections and axial tension
+        TRAN_axt = ([sp.cos(self.x*tau1), sp.sin(self.x*tau1), sp.cosh(self.x*tau2), sp.sinh(self.x*tau2)])
+        self.X1_axt = [i.subs([(tau1, tau11)
+                               ,(tau2, tau21)]) for i in TRAN_axt]
+        self.X2_axt = [i.subs([(tau1, tau12)
+                               ,(tau2, tau22)]) for i in TRAN_axt]
+        self.X3_axt = [i.subs([(tau1, tau13)
+                               ,(tau2, tau23)]) for i in TRAN_axt]
+
+       #mpmath
+        self.tau1_sec1_axt_mp = lambda omega, k1, p1: mp.sqrt(2)*mp.sqrt((mp.sqrt(4*k1**4*omega**2 + p1**4) - p1**2)/k1**4)/2 #sin&cos = LOI2
+        self.tau1_sec2_axt_mp = lambda lambda_1,k1,k2,p1,p2: ((1/2)*mp.sqrt(-2*p2**4 + 2*mp.sqrt(4*k1**4*k2**4*lambda_1**4 + 4*k2**4*lambda_1**2*p1**4 + p2**8))/k2**2)
+        self.tau1_sec3_axt_mp = lambda lambda_1,k1,k3,p1,p3: ((1/2)*mp.sqrt(-2*p3**4 + 2*mp.sqrt(4*k1**4*k3**4*lambda_1**4 + 4*k3**4*lambda_1**2*p1**4 + p3**8))/k3**2)
+
+        self.tau2_sec1_axt_mp = lambda omega, k1, p1: mp.sqrt(2)*mp.sqrt((p1**2 + mp.sqrt(4*k1**4*omega**2 + p1**4))/k1**4)/2 #sinh&cosh = LOI1
+        self.tau2_sec2_axt_mp = lambda lambda_1,k1,k2,p1,p2: ((1/2)*mp.sqrt(2*p2**4 + 2*mp.sqrt(4*k1**4*k2**4*lambda_1**4 - 4*k2**4*lambda_1**2*p1**4 + p2**8))/k2**2)
+        self.tau2_sec3_axt_mp = lambda lambda_1,k1,k3,p1,p3: ((1/2)*mp.sqrt(2*p3**4 + 2*mp.sqrt(4*k1**4*k3**4*lambda_1**4 - 4*k3**4*lambda_1**2*p1**4 + p3**8))/k3**2)
+        self.tau2_23_alt = lambda lambda_1,k1,k2,p1,p2: ((1/2)*mp.sqrt(2*p2**4 - 2*mp.sqrt(4*k1**4*k2**4*lambda_1**4 - 4*k2**4*lambda_1**2*p1**4 + p2**8))/k2**2)
+
+
+        # Calculating lambda initially to avoid multiple calculations
+        self.BCMatrix_3sec_axt_lambda = self.get_BCMatrix_3sec_axt_lambda()
+
+        # Precision with mpmath calculations (Determinant and taus)
+        self.prec = 50
+
+    def define_simple_beam(self, b1=0.03, b2=0.05, b3=0.03,
+                                 h1=0.02, h2=0.01, h3=0.02,
+                                 L1=0.3, L2=0.7, L3=1.0,
+                                 E1=200.0e9, E2=70.0e9, E3=200.0e9,
+                                 rho1=8700.0, rho2=2700.0, rho3=8700.0,
+                                 N=100):
+        self.b_1 = b1
+        self.b_2 = b2
+        self.b_3 = b3
+        self.h_1 = h1
+        self.h_2 = h2
+        self.h_3 = h3
+        self.L_1 = L1
+        self.L_2 = L2
+        self.L_3 = L3
+        self.E_1 = E1
+        self.E_2 = E2
+        self.E_3 = E3
+        self.rho_1 = rho1
+        self.rho_2 = rho2
+        self.rho_3 = rho3
+        self.N = N
+        self.A_1, self.I_1 = self.get_area_and_inertia_rectangle(self.b_1, self.h_1)
+        self.A_2, self.I_2 = self.get_area_and_inertia_rectangle(self.b_2, self.h_2)
+        self.A_3, self.I_3 = self.get_area_and_inertia_rectangle(self.b_3, self.h_3)
+        self.k_1, self.p_1 = self.get_k_and_p_value(self.A_1, self.I_1, E1, rho1, N)
+        self.k_2, self.p_2 = self.get_k_and_p_value(self.A_2, self.I_2, E2, rho2, N)
+        self.k_3, self.p_3 = self.get_k_and_p_value(self.A_3, self.I_3, E3, rho3, N)
+        
+    def define_layered_beam(self, b1=0.03, #b2=0.05, b3=0.03,            #Sections
+                                  L1=0.3, L2=0.7, L3=1.0,               #Sections
+                                  dA=0.02, dB=0.01, dC=0.02,            #Layers
+                                  EA=200.0e9, EB=70.0e9, EC=200.0e9,    #Layers
+                                  rhoA=8700.0, rhoB=2700.0, rhoC=8700.0,#Layers
+                                  N=100):                               #uniform
+        
+        #Layers
+        self.b_1 = b1
+        self.b_2 = b1 #!!
+        self.b_3 = b1 #!!
+        self.h_1 = dA + dB + dC
+        self.h_2 = dA + dB
+        self.h_3 = self.h_1
+        self.L_1 = L1
+        self.L_2 = L2
+        self.L_3 = L3
+        self.d_A = dA
+        self.d_B = dB
+        self.d_C = dC
+
+        #Sections
+        self.E_A = EA
+        self.E_B = EB
+        self.E_C = EC
+        self.rho_A = rhoA
+        self.rho_B = rhoB
+        self.rho_C = rhoC
+
+        self.init_parameter_lists()
+        
+        #self.get_section_E([EA, EB, EC], [dA, dB, dC])
+        self.I_1 = np.sum(self.I_layers123_steiner)
+        self.I_2 = np.sum(self.I_layers12_steiner)
+        dist_of_neutral_layers = self.h_1/2 - self.h_2/2#- self.get_neutral_layer(self.ys[:2], self.A_layers[:2], self.E_layers[:2])
+        #self.I_2 = self.I_2 + (self.d_C/2)**2 * np.sum(self.A_layers[:1])
+        
+
+        self.I_3 = self.I_1
+
+        self.E_1 = np.sum(self.I_layers123_steiner*self.E_layers)/self.I_1
+        #self.E_2 = np.sum(self.I_layers12_steiner*self.E_layers[:2])/np.sum(self.I_layers12_steiner)
+        self.E_2 = np.sum(self.I_layers12_steiner*self.E_layers[:2])/self.I_2
+        self.E_3 = self.E_1 # Seciton1 and 3 have same layers
+        self.I_2 = self.I_2 + dist_of_neutral_layers**2 * np.sum(self.A_layers[:1])
+
+
+        self.A_1 = np.sum(self.A_layers)
+        self.A_2 = np.sum(self.A_layers[:2])
+        self.A_3 = self.A_1 # Seciton1 and 3 have same layers
+        self.rho_1 = np.sum(self.rho_layers_weighted)/self.A_1
+        self.rho_2 = np.sum(self.rho_layers_weighted[:2])/self.A_2
+        self.rho_3 = self.rho_1 # Seciton1 and 3 have same layers
+
+        self.k_1, self.p_1 = self.get_k_and_p_value(self.A_1, self.I_1, self.E_1, self.rho_1, N)
+        self.k_2, self.p_2 = self.get_k_and_p_value(self.A_2, self.I_2, self.E_2, self.rho_2, N)
+        self.k_3, self.p_3 = self.get_k_and_p_value(self.A_3, self.I_3, self.E_3, self.rho_3, N)
+
+    def init_parameter_lists(self):
+        # Sections 123
+        self.b = np.array([self.b_1, self.b_2, self.b_3])
+        helper = self.d_A + self.d_B + self.d_C
+        self.height = np.array([helper, helper - self.d_C, helper]) # only if A_1  = A3
+
+        # Layers abc
+        self.d = np.array([self.d_A, self.d_B, self.d_C])
+        self.ys = self.get_centerpoints_of_layers_rectangle(*self.d) # center points of each Layer
+        self.E_layers = np.array([self.E_A, self.E_B, self.E_C])
+        self.A_layers, self.I_layers = self.get_area_and_inertia_rectangle(self.b, self.d)# only if b = [b1,b1,b1]=[bA,bB,bC]
+        
+        self.I_layers123_steiner = self.get_weighted_I_layer()
+        self.I_layers12_steiner = self.get_weighted_I_layer(layers=[0, 1])
+
+        self.rho_layers = np.array([self.rho_A, self.rho_B, self.rho_C])
+        self.rho_layers_weighted = self.get_weighted_rho_layer()
+
+    def get_weighted_I_layer(self, layers=[0, 1, 2]):
+        neutral_layer = self.get_neutral_layer(self.ys[layers], self.A_layers[layers], self.E_layers[layers])
+        offset_to_neutral_layer = self.ys[layers] - neutral_layer
+        # print(neutral_layer)
+        # print(offset_to_neutral_layer)
+        return np.array(self.I_layers[layers] + offset_to_neutral_layer**2*self.A_layers[layers])
+        
+    def get_weighted_rho_layer(self):
+        return self.rho_layers * self.A_layers
+
+    # Systemmatrix for beam with 3 sections and axial tension
+    # #######################################################
+    def BCMatrix_3sec_axt(self):
+        BC = sp.zeros(12,12)
+        # Boundary Conditions left x==|--|==|
+        BC[0,:] = syma([[i.subs(self.x,0) for i in self.X1_axt] + 
+                        [0,0,0,0] + 
+                        [0,0,0,0] ])  
+
+        BC[1,:] = syma([[diff(i,self.x).subs(self.x,0) for i in self.X1_axt] +
+                        [0,0,0,0] + 
+                        [0,0,0,0] ])
+
+        # Transition Conditions left |==x--|==|
+        BC[2,:] = syma([[i.subs(self.x,self.Lsym_1) for i in self.X1_axt]  + 
+                        [i.subs(self.x,self.Lsym_1)*(-1) for i in self.X2_axt] + 
+                        [0,0,0,0] ])
+
+        BC[3,:] = syma([[diff(i,self.x).subs(self.x,self.Lsym_1) for i in self.X1_axt]  + 
+                        [diff(i,self.x).subs(self.x,self.Lsym_1)*(-1) for i in self.X2_axt] + 
+                        [0,0,0,0] ])
+
+        BC[4,:] = syma([[self.Esym_1*self.Isym_1*diff(i,self.x,self.x).subs(self.x,self.Lsym_1)*(-1)  for i in self.X1_axt] + 
+                        [self.Esym_2*self.Isym_2*diff(i,self.x,self.x).subs(self.x,self.Lsym_1)  for i in self.X2_axt]+ 
+                        [0,0,0,0] ])
+
+        BC[5,:] = syma([[self.Esym_1*self.Isym_1*diff(i,self.x,self.x,self.x).subs(self.x,self.Lsym_1)  for i in self.X1_axt] + 
+                        [self.Esym_2*self.Isym_2*diff(i,self.x,self.x,self.x).subs(self.x,self.Lsym_1)*(-1)  for i in self.X2_axt]+ 
+                        [0,0,0,0] ])
+
+        # Transition Conditions right |==|--x==|
+        BC[6,:] = syma([[0,0,0,0] +
+                        [i.subs(self.x,self.Lsym_2) for i in self.X2_axt] + 
+                        [i.subs(self.x,self.Lsym_2)*(-1) for i in self.X3_axt]]) 
+
+        BC[7,:] = syma([[0,0,0,0] +
+                        [diff(i,self.x).subs(self.x,self.Lsym_2) for i in self.X2_axt] + 
+                        [diff(i,self.x).subs(self.x,self.Lsym_2)*(-1) for i in self.X3_axt]]) 
+        BC[8,:] = syma([[0,0,0,0] +
+                        [self.Esym_2*self.Isym_2*diff(i,self.x,self.x).subs(self.x,self.Lsym_2)*(-1) for i in self.X2_axt] + 
+                        [self.Esym_3*self.Isym_3*diff(i,self.x,self.x).subs(self.x,self.Lsym_2) for i in self.X3_axt]]) 
+        BC[9,:] = syma([[0,0,0,0] +
+                        [self.Esym_2*self.Isym_2*diff(i,self.x,self.x,self.x).subs(self.x,self.Lsym_2) for i in self.X2_axt] + 
+                        [self.Esym_3*self.Isym_3*diff(i,self.x,self.x,self.x).subs(self.x,self.Lsym_2)*(-1) for i in self.X3_axt]]) 
+
+        # Boundary Conditions right |==|--|==x
+        BC[10,:] = syma([[0,0,0,0] +
+                        [0,0,0,0] +  
+                        [i.subs(self.x, self.Lsym_3) for i in self.X3_axt]]) 
+        BC[11,:] = syma([[0,0,0,0] + 
+                        [0,0,0,0] +
+                        [diff(i,self.x).subs(self.x, self.Lsym_3) for i in self.X3_axt]]) 
+        return BC
+
+    def get_BCMatrix_3sec_axt_lambda(self):
+        #smbls = ['tau11', 'tau21', 'tau12', 'tau22', 'tau13', 'tau23', 'E_1', 'E_2', 'E_3', 'I_1', 'I_2', 'I_3', 'L_1', 'L_2', 'L_3']
+        smbls = ['tau11', 'tau21', 'tau12', 'tau22', 'tau13', 'tau23', 
+                 'Esym_1', 'Esym_2', 'Esym_3', 
+                 'Isym_1', 'Isym_2', 'Isym_3', 
+                 'Lsym_1', 'Lsym_2', 'Lsym_3']
+        symdet = self.BCMatrix_3sec_axt()
+        return sp.utilities.lambdify(smbls, symdet, modules='mpmath')
+    
+    def calc_taus(self, omega):
+        mp.mp.dps = self.prec
+        
+        # Section 1
+        self.tau11 = mp.fabs(self.tau1_sec1_axt_mp(omega, self.k_1, self.p_1))
+        self.tau21 = mp.fabs(self.tau2_sec1_axt_mp(omega, self.k_1, self.p_1))
+        # Section 2
+        self.tau12 = mp.fabs(self.tau1_sec2_axt_mp(self.tau11, self.k_1, self.k_2, self.p_1, self.p_2))
+        self.tau22 = mp.fabs(self.tau2_sec2_axt_mp(self.tau21, self.k_1, self.k_2, self.p_1, self.p_2))
+        # Section 3
+        self.tau13 = mp.fabs(self.tau1_sec3_axt_mp(self.tau11, self.k_1, self.k_3, self.p_1, self.p_3))
+        self.tau23 = mp.fabs(self.tau2_sec3_axt_mp(self.tau21, self.k_1, self.k_3, self.p_1, self.p_3))
+    
+    
+    def get_BCMatrix_3sec_axt_det(self):
+        mp.mp.dps = self.prec
+        mat = self.BCMatrix_3sec_axt_lambda(self.tau11, self.tau21,
+                                            self.tau12, self.tau22,
+                                            self.tau13, self.tau23,
+                                            self.E_1, self.E_2, self.E_3, 
+                                            self.I_1, self.I_2, self.I_3, 
+                                            self.L_1, self.L_2, self.L_3)
+        det = mp.det(mat)
+        det = np.float64( mp.log(mp.fabs(det))*mp.sign(det) )
+        return det
+
+    def peek_det(self, oms):
+        mp.mp.dps = self.prec
+        det = []
+        for om in oms:
+            self.calc_taus(om)
+            det.append( self.get_BCMatrix_3sec_axt_det() )
+        return np.array(det)
+
+    def peek_det_scalar(self, om):
+        mp.mp.dps = self.prec
+        self.calc_taus(om)
+        return self.get_BCMatrix_3sec_axt_det() 
+        
+
+
+    def lyrd_beam_reduced_params(self, b1, 
+                                 l1, l2, l3, 
+                                 dA, dB, dC, 
+                                 EA=200.0e9, EB=70.0e9, EC=200.0e9,    #Layers
+                                 rhoA=8700.0, rhoB=2700.0, rhoC=8700.0,#Layers
+                                 N=1000):
+        L1 = l1
+        L2 = l1 + l2
+        L3 = l1 + l2 + l3 
+        self.define_layered_beam(b1,                                   #Sections
+                                L1, L2, L3,                           #Sections
+                                dA, dB, dC,                           #Layers
+                                EA=EA, EB=EB, EC=EC,    #Layers
+                                rhoA=rhoA, rhoB=rhoB, rhoC=rhoC,#Layers
+                                N=N                               #uniform
+                                )
+
+    # search angular eigenfrequencies
+    def get_first3_ekf(self):
+        # does not work on random structures
+        det = []
+        om = 100.0
+        while True:
+            det.append(self.peek_det_scalar(om))
+            if len(det)>1 and np.sign(det[-2]) != np.sign(det[-1]):
+                om1 = scipy.optimize.brentq(self.peek_det_scalar,om-100,om)
+                break
+            om += 100
+        om2 = scipy.optimize.brentq(self.peek_det_scalar, om1*2, om1*3, xtol=1e-2)
+        om3 = scipy.optimize.brentq(self.peek_det_scalar, om1*3, om2*3, xtol=1e-2)
+        return np.array([om1, om2, om3])
+
+    def get_first_n_ekf_bruteforce(self, n=3, om=100.0, stepsize=100.0, brentq_xtol=1e-2):
+        det = []
+        oms = []        
+        ekfs = []
+        while True:
+            det.append(self.peek_det_scalar(om))
+            oms.append(om)
+            if len(det)>1 and np.sign(det[-2]) != np.sign(det[-1]):
+                ekfs.append( scipy.optimize.brentq(self.peek_det_scalar,oms[-2],oms[-1], xtol=brentq_xtol) )
+                stepsize = ekfs[0]
+                if len(ekfs) == n:
+                    return np.array(ekfs), det, oms
+                    
+            om += stepsize
+
+            
+                    
+            om += stepsize
+    ### alternative eigenvalue calc
+    def calc_taus_alt(self, omega):
+        mp.mp.dps = self.prec
+        
+        # Section 1
+        self.tau11 = mp.fabs(self.tau1_sec1_axt_mp(omega, self.k_1, self.p_1))
+        self.tau21 = mp.fabs(self.tau2_sec1_axt_mp(omega, self.k_1, self.p_1))
+        # Section 2
+        self.tau12 = mp.fabs(self.tau1_sec2_axt_mp(self.tau11, self.k_1, self.k_2, self.p_1, self.p_2))
+        self.tau22 = mp.fabs(self.tau2_sec2_axt_mp(self.tau21, self.k_1, self.k_2, self.p_1, self.p_2))
+        # Section 3
+        self.tau13 = mp.fabs(self.tau1_sec3_axt_mp(self.tau11, self.k_1, self.k_3, self.p_1, self.p_3))
+        self.tau23 = mp.fabs(self.tau2_23_alt(self.tau21, self.k_1, self.k_3, self.p_1, self.p_3))
+
+    def get_first_n_ekf_bruteforce_alt(self, n=3, om=100.0, stepsize=100.0, brentq_xtol=1e-2):
+        det = []
+        oms = []        
+        ekfs = []
+        while True:
+            det.append(self.peek_det_scalar_alt(om))
+            oms.append(om)
+            if len(det)>1 and np.sign(det[-2]) != np.sign(det[-1]):
+                ekfs.append( scipy.optimize.brentq(self.peek_det_scalar_alt,oms[-2],oms[-1], xtol=brentq_xtol) )
+                stepsize = ekfs[0]
+                if len(ekfs) == n:
+                    return np.array(ekfs), det, oms
+                    
+            om += stepsize
+    def peek_det_scalar_alt(self, om):
+        mp.mp.dps = self.prec
+        self.calc_taus_alt(om)
+        return self.get_BCMatrix_3sec_axt_det() 
+ 
+    
+
+    ### Static Methods
+    @staticmethod
+    def get_approx_ekf(fist_3_ekfs, order, poly_deg=2):
+        coef = np.polyfit(range(1, poly_deg+2), fist_3_ekfs, poly_deg)
+        return np.polyval(coef, order)
+
+    @staticmethod
+    def get_area_and_inertia_rectangle(b, h):
+        A = b * h
+        Iz = b * h**3 / 12
+        return A, Iz
+    
+    @staticmethod
+    def get_k_and_p_value(A, Iz, E, rho, N):
+        k = (E * Iz / rho / A )**0.25
+        p = (N / rho / A)**0.5
+        return k, p
+       
+    @staticmethod
+    def get_centerpoints_of_layers_rectangle(*args):
+        return np.array([d/2+sum(args[:i]) for i, d in enumerate(args)])
+
+    @staticmethod
+    def get_neutral_layer(ys, A_layers, E_layers):
+        helper = np.array(A_layers * E_layers)
+        return np.sum(ys * helper) / np.sum(helper)
+
+
+def plot_beam_geometry(geom_param, hight_factor=10 , colors=['red', 'green', 'orange']):
+    # Plotting Geometry
+    b1, l1, l2, l3, hA, hB, hC = geom_param
+    hA, hB, hC = hA*hight_factor, hB*hight_factor, hC*hight_factor
+    rects = []
+    # layerA
+    rects.append(Rectangle((0, 0), l1+l2+l3, hA, color=colors[0], edgecolor=None,linewidth=0))
+    # layerB
+    rects.append(Rectangle((0, hA), l1+l2+l3, hB, color=colors[1], edgecolor=None, linewidth=0))
+    # layerC
+    rects.append(Rectangle((0, hA+hB), l1, hC, color=colors[2], edgecolor=None, linewidth=0))
+    rects.append(Rectangle((l1+l2,hA+hB), l3, hC, color=colors[2], edgecolor=None, linewidth=0))
+
+    fig, ax = plt.subplots(1, figsize=cm2inch((l1+l2+l3)*3.2, (hA+hB+hC)*1.2), subplot_kw={'xlim':(0,l1+l2+l3), 'ylim':(0,hA+hB+hC)})
+    [ax.add_patch(p) for p in rects]
+    ax.axis('off')
+
+    return fig
+
+    
+def cm2inch(*tupl):
+    inch = 2.54
+    if isinstance(tupl[0], tuple):
+        return tuple(i/inch for i in tupl[0])
+    else:
+        return tuple(i/inch for i in tupl)
+# import time
+# cycls = 200
+
+# # init_time = time.time()
+# # for _ in range(cycls):
+# #     bb = euber()
+# # init_time = (time.time() - init_time)/cycls
+# bb = euber()
+# definetime = time.time()
+# for _ in range(cycls):
+#     bb.define_layered_beam()
+# definetime = (time.time() - definetime)/cycls
+
+# dettime = time.time()
+# for _ in range(cycls):
+#     bb.calc_taus(30)
+#     bb.get_BCMatrix_3sec_axt_det()
+# dettime = (time.time() - dettime)/cycls
+
+# print(definetime, dettime)
+
+# beam = euber()
+# beam.define_layered_beam()
+# bendingstiffness = lambda E,I,y,A: np.sum( np.array(E)*(np.array(I)+np.array(y)**2*np.array(A)) )
+# reduced_mass = lambda rho, A: np.sum(rho*A)
+
+# E = beam.E_layers
+# A = beam.A_layers
+# layers = [0,1,2]
+# helper = np.array(beam.A_layers[layers]) * np.array(beam.E_layers[layers])
+# neutral_layer = np.sum(np.array(beam.ys[layers]) * helper) / np.sum(helper)
+# offset_to_neutral_layer = beam.ys[layers] - neutral_layer
+# I_layers = beam.b * beam.d**3/12
+# EI_from_euber = beam.E_1*beam.I_1
+
+# mss = reduced_mass(beam.rho_layers, A)
+# print(f'oop={beam.rho_1 * beam.A_1}')
+# print(f'bnd={mss}')
+# 1+1
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
```

## pygpc/testfunctions/testfunctions.py

```diff
@@ -1,9003 +1,8751 @@
-00000000: 696d 706f 7274 206f 730d 0a69 6d70 6f72  import os..impor
-00000010: 7420 636f 7079 0d0a 696d 706f 7274 2069  t copy..import i
-00000020: 6e73 7065 6374 0d0a 696d 706f 7274 2077  nspect..import w
-00000030: 6172 6e69 6e67 730d 0a69 6d70 6f72 7420  arnings..import 
-00000040: 6e75 6d70 7920 6173 206e 700d 0a69 6d70  numpy as np..imp
-00000050: 6f72 7420 7363 6970 792e 7370 6563 6961  ort scipy.specia
-00000060: 6c0d 0a66 726f 6d20 7363 6970 792e 696e  l..from scipy.in
-00000070: 7465 6772 6174 6520 696d 706f 7274 206f  tegrate import o
-00000080: 6465 696e 740d 0a66 726f 6d20 636f 6c6c  deint..from coll
-00000090: 6563 7469 6f6e 7320 696d 706f 7274 204f  ections import O
-000000a0: 7264 6572 6564 4469 6374 0d0a 6672 6f6d  rderedDict..from
-000000b0: 2070 7967 7063 2e41 6273 7472 6163 744d   pygpc.AbstractM
-000000c0: 6f64 656c 2069 6d70 6f72 7420 4162 7374  odel import Abst
-000000d0: 7261 6374 4d6f 6465 6c0d 0a23 2066 726f  ractModel..# fro
-000000e0: 6d20 7079 6770 632e 7465 7374 6675 6e63  m pygpc.testfunc
-000000f0: 7469 6f6e 732e 6575 6265 725f 6c69 6256  tions.euber_libV
-00000100: 3320 696d 706f 7274 2a0d 0a0d 0a74 7279  3 import*....try
-00000110: 3a0d 0a20 2020 2069 6d70 6f72 7420 6d61  :..    import ma
-00000120: 7470 6c6f 746c 6962 0d0a 2020 2020 696d  tplotlib..    im
-00000130: 706f 7274 206d 6174 706c 6f74 6c69 622e  port matplotlib.
-00000140: 7079 706c 6f74 2061 7320 706c 740d 0a20  pyplot as plt.. 
-00000150: 2020 2066 726f 6d20 6d70 6c5f 746f 6f6c     from mpl_tool
-00000160: 6b69 7473 2e6d 706c 6f74 3364 2069 6d70  kits.mplot3d imp
-00000170: 6f72 7420 4178 6573 3344 0d0a 6578 6365  ort Axes3D..exce
-00000180: 7074 2049 6d70 6f72 7445 7272 6f72 3a0d  pt ImportError:.
-00000190: 0a20 2020 2070 6173 730d 0a0d 0a0d 0a64  .    pass......d
-000001a0: 6566 2070 6c6f 745f 7465 7374 6675 6e63  ef plot_testfunc
-000001b0: 7469 6f6e 2874 6573 7466 756e 6374 696f  tion(testfunctio
-000001c0: 6e5f 6e61 6d65 3a20 6f62 6a65 6374 2c20  n_name: object, 
-000001d0: 7061 7261 6d65 7465 7273 3a20 6f62 6a65  parameters: obje
-000001e0: 6374 2c20 636f 6e73 7461 6e74 733a 206f  ct, constants: o
-000001f0: 626a 6563 7420 3d20 4e6f 6e65 2c20 6f75  bject = None, ou
-00000200: 7470 7574 5f69 6478 3a20 6f62 6a65 6374  tput_idx: object
-00000210: 203d 2030 2c0d 0a20 2020 2020 2020 2020   = 0,..         
-00000220: 2020 2020 2020 2020 2020 2020 2070 6c6f               plo
-00000230: 745f 3364 3d54 7275 6529 202d 3e20 6f62  t_3d=True) -> ob
-00000240: 6a65 6374 3a0d 0a20 2020 2022 2222 0d0a  ject:..    """..
-00000250: 2020 2020 506c 6f74 2031 4420 6f72 2032      Plot 1D or 2
-00000260: 4420 7465 7374 6675 6e63 7469 6f6e 7320  D testfunctions 
-00000270: 666f 7220 646f 6375 6d65 6e74 6174 696f  for documentatio
-00000280: 6e2e 0d0a 0d0a 2020 2020 5061 7261 6d65  n.....    Parame
-00000290: 7465 7273 0d0a 2020 2020 2d2d 2d2d 2d2d  ters..    ------
-000002a0: 2d2d 2d2d 0d0a 2020 2020 7465 7374 6675  ----..    testfu
-000002b0: 6e63 7469 6f6e 5f6e 616d 6520 3a20 7374  nction_name : st
-000002c0: 720d 0a20 2020 2020 2020 204e 616d 6520  r..        Name 
-000002d0: 6f66 2074 6573 7466 756e 6374 696f 6e20  of testfunction 
-000002e0: 4162 7374 7261 6374 4d6f 6465 6c20 636c  AbstractModel cl
-000002f0: 6173 730d 0a20 2020 2070 6172 616d 6574  ass..    paramet
-00000300: 6572 7320 3a20 4f72 6465 7265 7264 4469  ers : OrdererdDi
-00000310: 6374 0d0a 2020 2020 2020 2020 4469 6374  ct..        Dict
-00000320: 696f 6e61 7279 2063 6f6e 7461 696e 696e  ionary containin
-00000330: 6720 7468 6520 3144 2063 6f6f 7264 696e  g the 1D coordin
-00000340: 6174 6573 2061 7320 6e64 6172 7261 7973  ates as ndarrays
-00000350: 2c20 7768 6572 6520 7468 6520 7465 7374  , where the test
-00000360: 6675 6e63 7469 6f6e 2069 7320 6576 616c  function is eval
-00000370: 7561 7465 6420 2877 696c 6c20 6265 2074  uated (will be t
-00000380: 656e 736f 7269 7a65 6429 0d0a 2020 2020  ensorized)..    
-00000390: 636f 6e73 7461 6e74 7320 3a20 4f72 6465  constants : Orde
-000003a0: 7265 6444 6963 7420 286f 7074 696f 6e61  redDict (optiona
-000003b0: 6c29 0d0a 2020 2020 2020 2020 4469 6374  l)..        Dict
-000003c0: 696f 6e61 7279 2063 6f6e 7461 696e 696e  ionary containin
-000003d0: 6720 7468 6520 2872 656d 6169 6e69 6e67  g the (remaining
-000003e0: 2920 7061 7261 6d65 7465 7273 2074 7265  ) parameters tre
-000003f0: 6174 6564 2061 7320 636f 6e73 7461 6e74  ated as constant
-00000400: 730d 0a20 2020 206f 7574 7075 745f 6964  s..    output_id
-00000410: 7820 3a20 696e 7420 6f72 206c 6973 7420  x : int or list 
-00000420: 6f66 2069 6e74 0d0a 2020 2020 2020 2020  of int..        
-00000430: 496e 6469 6365 7320 6f66 206f 7574 7075  Indices of outpu
-00000440: 7420 7175 616e 7469 7479 2074 6f20 706c  t quantity to pl
-00000450: 6f74 0d0a 2020 2020 706c 6f74 5f33 6420  ot..    plot_3d 
-00000460: 3a20 626f 6f6c 2c20 6f70 7469 6f6e 616c  : bool, optional
-00000470: 2c20 6465 6661 756c 743a 2054 7275 650d  , default: True.
-00000480: 0a20 2020 2020 2020 2050 6c6f 7420 6675  .        Plot fu
-00000490: 6e63 7469 6f6e 2069 6e20 3364 206f 7220  nction in 3d or 
-000004a0: 3264 0d0a 0d0a 2020 2020 5265 7475 726e  2d....    Return
-000004b0: 730d 0a20 2020 202d 2d2d 2d2d 2d2d 0d0a  s..    -------..
-000004c0: 2020 2020 3c70 6c6f 743e 203a 206d 6174      <plot> : mat
-000004d0: 706c 6f74 6c69 6220 6669 6775 7265 0d0a  plotlib figure..
-000004e0: 2020 2020 2020 2020 506c 6f74 2073 686f          Plot sho
-000004f0: 7769 6e67 2074 6865 2051 6f49 206f 6620  wing the QoI of 
-00000500: 7468 6520 7465 7374 6675 6e63 7469 6f6e  the testfunction
-00000510: 2069 6e20 3144 206f 7220 3244 0d0a 2020   in 1D or 2D..  
-00000520: 2020 2222 220d 0a0d 0a20 2020 2066 6f6e    """....    fon
-00000530: 7420 3d20 7b27 6661 6d69 6c79 2720 3a20  t = {'family' : 
-00000540: 2744 656a 6156 7520 5361 6e73 272c 0d0a  'DejaVu Sans',..
-00000550: 2020 2020 2020 2020 2020 2020 2777 6569              'wei
-00000560: 6768 7427 203a 2027 6e6f 726d 616c 272c  ght' : 'normal',
-00000570: 0d0a 2020 2020 2020 2020 2020 2020 2773  ..            's
-00000580: 697a 6527 2020 203a 2031 327d 0d0a 0d0a  ize'   : 12}....
-00000590: 2020 2020 6d61 7470 6c6f 746c 6962 2e72      matplotlib.r
-000005a0: 6328 2766 6f6e 7427 2c20 2a2a 666f 6e74  c('font', **font
-000005b0: 290d 0a0d 0a20 2020 2069 6620 7479 7065  )....    if type
-000005c0: 286f 7574 7075 745f 6964 7829 2069 7320  (output_idx) is 
-000005d0: 6e6f 7420 6c69 7374 3a0d 0a20 2020 2020  not list:..     
-000005e0: 2020 206f 7574 7075 745f 6964 7820 3d20     output_idx = 
-000005f0: 5b6f 7574 7075 745f 6964 785d 0d0a 0d0a  [output_idx]....
-00000600: 2020 2020 6e5f 716f 6920 3d20 6c65 6e28      n_qoi = len(
-00000610: 6f75 7470 7574 5f69 6478 290d 0a0d 0a20  output_idx).... 
-00000620: 2020 2023 2073 6574 7570 2070 6172 616d     # setup param
-00000630: 6574 6572 730d 0a20 2020 2070 5f6e 616d  eters..    p_nam
-00000640: 6573 203d 206c 6973 7428 7061 7261 6d65  es = list(parame
-00000650: 7465 7273 2e6b 6579 7328 2929 0d0a 2020  ters.keys())..  
-00000660: 2020 7020 3d20 4f72 6465 7265 6444 6963    p = OrderedDic
-00000670: 7428 290d 0a0d 0a20 2020 2069 6620 6c65  t()....    if le
-00000680: 6e28 705f 6e61 6d65 7329 203d 3d20 323a  n(p_names) == 2:
-00000690: 0d0a 2020 2020 2020 2020 7831 2c20 7832  ..        x1, x2
-000006a0: 203d 206e 702e 6d65 7368 6772 6964 2870   = np.meshgrid(p
-000006b0: 6172 616d 6574 6572 735b 705f 6e61 6d65  arameters[p_name
-000006c0: 735b 305d 5d2c 2070 6172 616d 6574 6572  s[0]], parameter
-000006d0: 735b 705f 6e61 6d65 735b 315d 5d29 0d0a  s[p_names[1]])..
-000006e0: 2020 2020 2020 2020 705b 705f 6e61 6d65          p[p_name
-000006f0: 735b 305d 5d20 3d20 7831 2e66 6c61 7474  s[0]] = x1.flatt
-00000700: 656e 2829 0d0a 2020 2020 2020 2020 705b  en()..        p[
-00000710: 705f 6e61 6d65 735b 315d 5d20 3d20 7832  p_names[1]] = x2
-00000720: 2e66 6c61 7474 656e 2829 0d0a 0d0a 2020  .flatten()....  
-00000730: 2020 656c 7365 3a0d 0a20 2020 2020 2020    else:..       
-00000740: 2070 5b70 5f6e 616d 6573 5b30 5d5d 203d   p[p_names[0]] =
-00000750: 2070 6172 616d 6574 6572 735b 705f 6e61   parameters[p_na
-00000760: 6d65 735b 305d 5d2e 666c 6174 7465 6e28  mes[0]].flatten(
-00000770: 290d 0a0d 0a20 2020 2023 2061 6464 2063  )....    # add c
-00000780: 6f6e 7374 616e 7473 0d0a 2020 2020 6966  onstants..    if
-00000790: 2074 7970 6528 636f 6e73 7461 6e74 7329   type(constants)
-000007a0: 2069 7320 6469 6374 206f 7220 7479 7065   is dict or type
-000007b0: 2863 6f6e 7374 616e 7473 2920 6973 204f  (constants) is O
-000007c0: 7264 6572 6564 4469 6374 3a0d 0a20 2020  rderedDict:..   
-000007d0: 2020 2020 2063 5f6e 616d 6573 203d 2063       c_names = c
-000007e0: 6f6e 7374 616e 7473 2e6b 6579 7328 290d  onstants.keys().
-000007f0: 0a20 2020 2020 2020 2066 6f72 2063 5f6e  .        for c_n
-00000800: 616d 6520 696e 2063 5f6e 616d 6573 3a0d  ame in c_names:.
-00000810: 0a20 2020 2020 2020 2020 2020 2070 5b63  .            p[c
-00000820: 5f6e 616d 655d 203d 206e 702e 7469 6c65  _name] = np.tile
-00000830: 2863 6f6e 7374 616e 7473 5b63 5f6e 616d  (constants[c_nam
-00000840: 655d 2c20 286c 656e 2870 5b70 5f6e 616d  e], (len(p[p_nam
-00000850: 6573 5b30 5d5d 292c 2031 2929 0d0a 0d0a  es[0]]), 1))....
-00000860: 2020 2020 6d6f 6465 6c20 3d20 6576 616c      model = eval
-00000870: 2822 7b7d 2829 2e73 6574 5f70 6172 616d  ("{}().set_param
-00000880: 6574 6572 7328 7029 222e 666f 726d 6174  eters(p)".format
-00000890: 2874 6573 7466 756e 6374 696f 6e5f 6e61  (testfunction_na
-000008a0: 6d65 2929 0d0a 0d0a 2020 2020 7920 3d20  me))....    y = 
-000008b0: 6d6f 6465 6c2e 7369 6d75 6c61 7465 2829  model.simulate()
-000008c0: 0d0a 0d0a 2020 2020 6669 6720 3d20 706c  ....    fig = pl
-000008d0: 742e 6669 6775 7265 2866 6967 7369 7a65  t.figure(figsize
-000008e0: 3d28 362c 2028 286e 5f71 6f69 2d31 292a  =(6, ((n_qoi-1)*
-000008f0: 302e 3835 2b31 2920 2a20 3529 290d 0a0d  0.85+1) * 5))...
-00000900: 0a20 2020 2066 6f72 2069 2c20 6f20 696e  .    for i, o in
-00000910: 2065 6e75 6d65 7261 7465 286f 7574 7075   enumerate(outpu
-00000920: 745f 6964 7829 3a0d 0a20 2020 2020 2020  t_idx):..       
-00000930: 2069 6620 706c 6f74 5f33 643a 0d0a 2020   if plot_3d:..  
-00000940: 2020 2020 2020 2020 2020 6178 203d 2066            ax = f
-00000950: 6967 2e61 6464 5f73 7562 706c 6f74 286e  ig.add_subplot(n
-00000960: 5f71 6f69 2c20 312c 2069 2b31 2c20 7072  _qoi, 1, i+1, pr
-00000970: 6f6a 6563 7469 6f6e 3d27 3364 2729 0d0a  ojection='3d')..
-00000980: 2020 2020 2020 2020 656c 7365 3a0d 0a20          else:.. 
-00000990: 2020 2020 2020 2020 2020 2061 7820 3d20             ax = 
-000009a0: 6669 672e 6164 645f 7375 6270 6c6f 7428  fig.add_subplot(
-000009b0: 6e5f 716f 692c 2031 2c20 692b 3129 0d0a  n_qoi, 1, i+1)..
-000009c0: 0d0a 2020 2020 2020 2020 2320 6f6d 6974  ..        # omit
-000009d0: 2022 6164 6469 7469 6f6e 616c 5f64 6174   "additional_dat
-000009e0: 6122 2069 6620 7072 6573 656e 740d 0a20  a" if present.. 
-000009f0: 2020 2020 2020 2069 6620 7479 7065 2879         if type(y
-00000a00: 2920 6973 2074 7570 6c65 3a0d 0a20 2020  ) is tuple:..   
-00000a10: 2020 2020 2020 2020 2079 203d 2079 5b30           y = y[0
-00000a20: 5d0d 0a0d 0a20 2020 2020 2020 2069 6620  ]....        if 
-00000a30: 6c65 6e28 705f 6e61 6d65 7329 203d 3d20  len(p_names) == 
-00000a40: 323a 0d0a 2020 2020 2020 2020 2020 2020  2:..            
-00000a50: 6966 2070 6c6f 745f 3364 3a0d 0a20 2020  if plot_3d:..   
-00000a60: 2020 2020 2020 2020 2020 2020 2069 6d20               im 
-00000a70: 3d20 6178 2e70 6c6f 745f 7375 7266 6163  = ax.plot_surfac
-00000a80: 6528 7831 2c0d 0a20 2020 2020 2020 2020  e(x1,..         
+00000000: 696d 706f 7274 206f 730a 696d 706f 7274  import os.import
+00000010: 2063 6f70 790a 696d 706f 7274 2069 6e73   copy.import ins
+00000020: 7065 6374 0a69 6d70 6f72 7420 7761 726e  pect.import warn
+00000030: 696e 6773 0a69 6d70 6f72 7420 6e75 6d70  ings.import nump
+00000040: 7920 6173 206e 700a 696d 706f 7274 2073  y as np.import s
+00000050: 6369 7079 2e73 7065 6369 616c 0a66 726f  cipy.special.fro
+00000060: 6d20 7363 6970 792e 696e 7465 6772 6174  m scipy.integrat
+00000070: 6520 696d 706f 7274 206f 6465 696e 740a  e import odeint.
+00000080: 6672 6f6d 2063 6f6c 6c65 6374 696f 6e73  from collections
+00000090: 2069 6d70 6f72 7420 4f72 6465 7265 6444   import OrderedD
+000000a0: 6963 740a 6672 6f6d 2070 7967 7063 2e41  ict.from pygpc.A
+000000b0: 6273 7472 6163 744d 6f64 656c 2069 6d70  bstractModel imp
+000000c0: 6f72 7420 4162 7374 7261 6374 4d6f 6465  ort AbstractMode
+000000d0: 6c0a 2320 6672 6f6d 2070 7967 7063 2e74  l.# from pygpc.t
+000000e0: 6573 7466 756e 6374 696f 6e73 2e65 7562  estfunctions.eub
+000000f0: 6572 5f6c 6962 5633 2069 6d70 6f72 742a  er_libV3 import*
+00000100: 0a0a 7472 793a 0a20 2020 2069 6d70 6f72  ..try:.    impor
+00000110: 7420 6d61 7470 6c6f 746c 6962 0a20 2020  t matplotlib.   
+00000120: 2069 6d70 6f72 7420 6d61 7470 6c6f 746c   import matplotl
+00000130: 6962 2e70 7970 6c6f 7420 6173 2070 6c74  ib.pyplot as plt
+00000140: 0a20 2020 2066 726f 6d20 6d70 6c5f 746f  .    from mpl_to
+00000150: 6f6c 6b69 7473 2e6d 706c 6f74 3364 2069  olkits.mplot3d i
+00000160: 6d70 6f72 7420 4178 6573 3344 0a65 7863  mport Axes3D.exc
+00000170: 6570 7420 496d 706f 7274 4572 726f 723a  ept ImportError:
+00000180: 0a20 2020 2070 6173 730a 0a0a 6465 6620  .    pass...def 
+00000190: 706c 6f74 5f74 6573 7466 756e 6374 696f  plot_testfunctio
+000001a0: 6e28 7465 7374 6675 6e63 7469 6f6e 5f6e  n(testfunction_n
+000001b0: 616d 653a 206f 626a 6563 742c 2070 6172  ame: object, par
+000001c0: 616d 6574 6572 733a 206f 626a 6563 742c  ameters: object,
+000001d0: 2063 6f6e 7374 616e 7473 3a20 6f62 6a65   constants: obje
+000001e0: 6374 203d 204e 6f6e 652c 206f 7574 7075  ct = None, outpu
+000001f0: 745f 6964 783a 206f 626a 6563 7420 3d20  t_idx: object = 
+00000200: 302c 0a20 2020 2020 2020 2020 2020 2020  0,.             
+00000210: 2020 2020 2020 2020 2070 6c6f 745f 3364           plot_3d
+00000220: 3d54 7275 6529 202d 3e20 6f62 6a65 6374  =True) -> object
+00000230: 3a0a 2020 2020 2222 220a 2020 2020 506c  :.    """.    Pl
+00000240: 6f74 2031 4420 6f72 2032 4420 7465 7374  ot 1D or 2D test
+00000250: 6675 6e63 7469 6f6e 7320 666f 7220 646f  functions for do
+00000260: 6375 6d65 6e74 6174 696f 6e2e 0a0a 2020  cumentation...  
+00000270: 2020 5061 7261 6d65 7465 7273 0a20 2020    Parameters.   
+00000280: 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020 2020   ----------.    
+00000290: 7465 7374 6675 6e63 7469 6f6e 5f6e 616d  testfunction_nam
+000002a0: 6520 3a20 7374 720a 2020 2020 2020 2020  e : str.        
+000002b0: 4e61 6d65 206f 6620 7465 7374 6675 6e63  Name of testfunc
+000002c0: 7469 6f6e 2041 6273 7472 6163 744d 6f64  tion AbstractMod
+000002d0: 656c 2063 6c61 7373 0a20 2020 2070 6172  el class.    par
+000002e0: 616d 6574 6572 7320 3a20 4f72 6465 7265  ameters : Ordere
+000002f0: 7264 4469 6374 0a20 2020 2020 2020 2044  rdDict.        D
+00000300: 6963 7469 6f6e 6172 7920 636f 6e74 6169  ictionary contai
+00000310: 6e69 6e67 2074 6865 2031 4420 636f 6f72  ning the 1D coor
+00000320: 6469 6e61 7465 7320 6173 206e 6461 7272  dinates as ndarr
+00000330: 6179 732c 2077 6865 7265 2074 6865 2074  ays, where the t
+00000340: 6573 7466 756e 6374 696f 6e20 6973 2065  estfunction is e
+00000350: 7661 6c75 6174 6564 2028 7769 6c6c 2062  valuated (will b
+00000360: 6520 7465 6e73 6f72 697a 6564 290a 2020  e tensorized).  
+00000370: 2020 636f 6e73 7461 6e74 7320 3a20 4f72    constants : Or
+00000380: 6465 7265 6444 6963 7420 286f 7074 696f  deredDict (optio
+00000390: 6e61 6c29 0a20 2020 2020 2020 2044 6963  nal).        Dic
+000003a0: 7469 6f6e 6172 7920 636f 6e74 6169 6e69  tionary containi
+000003b0: 6e67 2074 6865 2028 7265 6d61 696e 696e  ng the (remainin
+000003c0: 6729 2070 6172 616d 6574 6572 7320 7472  g) parameters tr
+000003d0: 6561 7465 6420 6173 2063 6f6e 7374 616e  eated as constan
+000003e0: 7473 0a20 2020 206f 7574 7075 745f 6964  ts.    output_id
+000003f0: 7820 3a20 696e 7420 6f72 206c 6973 7420  x : int or list 
+00000400: 6f66 2069 6e74 0a20 2020 2020 2020 2049  of int.        I
+00000410: 6e64 6963 6573 206f 6620 6f75 7470 7574  ndices of output
+00000420: 2071 7561 6e74 6974 7920 746f 2070 6c6f   quantity to plo
+00000430: 740a 2020 2020 706c 6f74 5f33 6420 3a20  t.    plot_3d : 
+00000440: 626f 6f6c 2c20 6f70 7469 6f6e 616c 2c20  bool, optional, 
+00000450: 6465 6661 756c 743a 2054 7275 650a 2020  default: True.  
+00000460: 2020 2020 2020 506c 6f74 2066 756e 6374        Plot funct
+00000470: 696f 6e20 696e 2033 6420 6f72 2032 640a  ion in 3d or 2d.
+00000480: 0a20 2020 2052 6574 7572 6e73 0a20 2020  .    Returns.   
+00000490: 202d 2d2d 2d2d 2d2d 0a20 2020 203c 706c   -------.    <pl
+000004a0: 6f74 3e20 3a20 6d61 7470 6c6f 746c 6962  ot> : matplotlib
+000004b0: 2066 6967 7572 650a 2020 2020 2020 2020   figure.        
+000004c0: 506c 6f74 2073 686f 7769 6e67 2074 6865  Plot showing the
+000004d0: 2051 6f49 206f 6620 7468 6520 7465 7374   QoI of the test
+000004e0: 6675 6e63 7469 6f6e 2069 6e20 3144 206f  function in 1D o
+000004f0: 7220 3244 0a20 2020 2022 2222 0a0a 2020  r 2D.    """..  
+00000500: 2020 666f 6e74 203d 207b 2766 616d 696c    font = {'famil
+00000510: 7927 203a 2027 4465 6a61 5675 2053 616e  y' : 'DejaVu San
+00000520: 7327 2c0a 2020 2020 2020 2020 2020 2020  s',.            
+00000530: 2777 6569 6768 7427 203a 2027 6e6f 726d  'weight' : 'norm
+00000540: 616c 272c 0a20 2020 2020 2020 2020 2020  al',.           
+00000550: 2027 7369 7a65 2720 2020 3a20 3132 7d0a   'size'   : 12}.
+00000560: 0a20 2020 206d 6174 706c 6f74 6c69 622e  .    matplotlib.
+00000570: 7263 2827 666f 6e74 272c 202a 2a66 6f6e  rc('font', **fon
+00000580: 7429 0a0a 2020 2020 6966 2074 7970 6528  t)..    if type(
+00000590: 6f75 7470 7574 5f69 6478 2920 6973 206e  output_idx) is n
+000005a0: 6f74 206c 6973 743a 0a20 2020 2020 2020  ot list:.       
+000005b0: 206f 7574 7075 745f 6964 7820 3d20 5b6f   output_idx = [o
+000005c0: 7574 7075 745f 6964 785d 0a0a 2020 2020  utput_idx]..    
+000005d0: 6e5f 716f 6920 3d20 6c65 6e28 6f75 7470  n_qoi = len(outp
+000005e0: 7574 5f69 6478 290a 0a20 2020 2023 2073  ut_idx)..    # s
+000005f0: 6574 7570 2070 6172 616d 6574 6572 730a  etup parameters.
+00000600: 2020 2020 705f 6e61 6d65 7320 3d20 6c69      p_names = li
+00000610: 7374 2870 6172 616d 6574 6572 732e 6b65  st(parameters.ke
+00000620: 7973 2829 290a 2020 2020 7020 3d20 4f72  ys()).    p = Or
+00000630: 6465 7265 6444 6963 7428 290a 0a20 2020  deredDict()..   
+00000640: 2069 6620 6c65 6e28 705f 6e61 6d65 7329   if len(p_names)
+00000650: 203d 3d20 323a 0a20 2020 2020 2020 2078   == 2:.        x
+00000660: 312c 2078 3220 3d20 6e70 2e6d 6573 6867  1, x2 = np.meshg
+00000670: 7269 6428 7061 7261 6d65 7465 7273 5b70  rid(parameters[p
+00000680: 5f6e 616d 6573 5b30 5d5d 2c20 7061 7261  _names[0]], para
+00000690: 6d65 7465 7273 5b70 5f6e 616d 6573 5b31  meters[p_names[1
+000006a0: 5d5d 290a 2020 2020 2020 2020 705b 705f  ]]).        p[p_
+000006b0: 6e61 6d65 735b 305d 5d20 3d20 7831 2e66  names[0]] = x1.f
+000006c0: 6c61 7474 656e 2829 0a20 2020 2020 2020  latten().       
+000006d0: 2070 5b70 5f6e 616d 6573 5b31 5d5d 203d   p[p_names[1]] =
+000006e0: 2078 322e 666c 6174 7465 6e28 290a 0a20   x2.flatten().. 
+000006f0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00000700: 2070 5b70 5f6e 616d 6573 5b30 5d5d 203d   p[p_names[0]] =
+00000710: 2070 6172 616d 6574 6572 735b 705f 6e61   parameters[p_na
+00000720: 6d65 735b 305d 5d2e 666c 6174 7465 6e28  mes[0]].flatten(
+00000730: 290a 0a20 2020 2023 2061 6464 2063 6f6e  )..    # add con
+00000740: 7374 616e 7473 0a20 2020 2069 6620 7479  stants.    if ty
+00000750: 7065 2863 6f6e 7374 616e 7473 2920 6973  pe(constants) is
+00000760: 2064 6963 7420 6f72 2074 7970 6528 636f   dict or type(co
+00000770: 6e73 7461 6e74 7329 2069 7320 4f72 6465  nstants) is Orde
+00000780: 7265 6444 6963 743a 0a20 2020 2020 2020  redDict:.       
+00000790: 2063 5f6e 616d 6573 203d 2063 6f6e 7374   c_names = const
+000007a0: 616e 7473 2e6b 6579 7328 290a 2020 2020  ants.keys().    
+000007b0: 2020 2020 666f 7220 635f 6e61 6d65 2069      for c_name i
+000007c0: 6e20 635f 6e61 6d65 733a 0a20 2020 2020  n c_names:.     
+000007d0: 2020 2020 2020 2070 5b63 5f6e 616d 655d         p[c_name]
+000007e0: 203d 206e 702e 7469 6c65 2863 6f6e 7374   = np.tile(const
+000007f0: 616e 7473 5b63 5f6e 616d 655d 2c20 286c  ants[c_name], (l
+00000800: 656e 2870 5b70 5f6e 616d 6573 5b30 5d5d  en(p[p_names[0]]
+00000810: 292c 2031 2929 0a0a 2020 2020 6d6f 6465  ), 1))..    mode
+00000820: 6c20 3d20 6576 616c 2822 7b7d 2829 2e73  l = eval("{}().s
+00000830: 6574 5f70 6172 616d 6574 6572 7328 7029  et_parameters(p)
+00000840: 222e 666f 726d 6174 2874 6573 7466 756e  ".format(testfun
+00000850: 6374 696f 6e5f 6e61 6d65 2929 0a0a 2020  ction_name))..  
+00000860: 2020 7920 3d20 6d6f 6465 6c2e 7369 6d75    y = model.simu
+00000870: 6c61 7465 2829 0a0a 2020 2020 6669 6720  late()..    fig 
+00000880: 3d20 706c 742e 6669 6775 7265 2866 6967  = plt.figure(fig
+00000890: 7369 7a65 3d28 362c 2028 286e 5f71 6f69  size=(6, ((n_qoi
+000008a0: 2d31 292a 302e 3835 2b31 2920 2a20 3529  -1)*0.85+1) * 5)
+000008b0: 290a 0a20 2020 2066 6f72 2069 2c20 6f20  )..    for i, o 
+000008c0: 696e 2065 6e75 6d65 7261 7465 286f 7574  in enumerate(out
+000008d0: 7075 745f 6964 7829 3a0a 2020 2020 2020  put_idx):.      
+000008e0: 2020 6966 2070 6c6f 745f 3364 3a0a 2020    if plot_3d:.  
+000008f0: 2020 2020 2020 2020 2020 6178 203d 2066            ax = f
+00000900: 6967 2e61 6464 5f73 7562 706c 6f74 286e  ig.add_subplot(n
+00000910: 5f71 6f69 2c20 312c 2069 2b31 2c20 7072  _qoi, 1, i+1, pr
+00000920: 6f6a 6563 7469 6f6e 3d27 3364 2729 0a20  ojection='3d'). 
+00000930: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+00000940: 2020 2020 2020 2020 2061 7820 3d20 6669           ax = fi
+00000950: 672e 6164 645f 7375 6270 6c6f 7428 6e5f  g.add_subplot(n_
+00000960: 716f 692c 2031 2c20 692b 3129 0a0a 2020  qoi, 1, i+1)..  
+00000970: 2020 2020 2020 2320 6f6d 6974 2022 6164        # omit "ad
+00000980: 6469 7469 6f6e 616c 5f64 6174 6122 2069  ditional_data" i
+00000990: 6620 7072 6573 656e 740a 2020 2020 2020  f present.      
+000009a0: 2020 6966 2074 7970 6528 7929 2069 7320    if type(y) is 
+000009b0: 7475 706c 653a 0a20 2020 2020 2020 2020  tuple:.         
+000009c0: 2020 2079 203d 2079 5b30 5d0a 0a20 2020     y = y[0]..   
+000009d0: 2020 2020 2069 6620 6c65 6e28 705f 6e61       if len(p_na
+000009e0: 6d65 7329 203d 3d20 323a 0a20 2020 2020  mes) == 2:.     
+000009f0: 2020 2020 2020 2069 6620 706c 6f74 5f33         if plot_3
+00000a00: 643a 0a20 2020 2020 2020 2020 2020 2020  d:.             
+00000a10: 2020 2069 6d20 3d20 6178 2e70 6c6f 745f     im = ax.plot_
+00000a20: 7375 7266 6163 6528 7831 2c0a 2020 2020  surface(x1,.    
+00000a30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000a40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000a50: 2078 322c 0a20 2020 2020 2020 2020 2020   x2,.           
+00000a60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000a70: 2020 2020 2020 2020 2020 6e70 2e72 6573            np.res
+00000a80: 6861 7065 2879 5b3a 2c20 6f5d 2c0a 2020  hape(y[:, o],.  
 00000a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000aa0: 2020 2020 2020 2020 2020 2020 7832 2c0d              x2,.
-00000ab0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00000ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000ad0: 2020 2020 2020 6e70 2e72 6573 6861 7065        np.reshape
-00000ae0: 2879 5b3a 2c20 6f5d 2c0d 0a20 2020 2020  (y[:, o],..     
-00000af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000ab0: 2020 2020 2020 2020 2020 2020 2020 286c                (l
+00000ac0: 656e 2870 6172 616d 6574 6572 735b 705f  en(parameters[p_
+00000ad0: 6e61 6d65 735b 315d 5d29 2c20 6c65 6e28  names[1]]), len(
+00000ae0: 7061 7261 6d65 7465 7273 5b70 5f6e 616d  parameters[p_nam
+00000af0: 6573 5b30 5d5d 2929 2c0a 2020 2020 2020  es[0]])),.      
 00000b00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000b10: 2020 2020 2020 2020 2020 2028 6c65 6e28             (len(
-00000b20: 7061 7261 6d65 7465 7273 5b70 5f6e 616d  parameters[p_nam
-00000b30: 6573 5b31 5d5d 292c 206c 656e 2870 6172  es[1]]), len(par
-00000b40: 616d 6574 6572 735b 705f 6e61 6d65 735b  ameters[p_names[
-00000b50: 305d 5d29 292c 0d0a 2020 2020 2020 2020  0]])),..        
-00000b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000b80: 2020 2020 2020 2020 6f72 6465 723d 2763          order='c
-00000b90: 2729 2c0d 0a20 2020 2020 2020 2020 2020  '),..           
+00000b10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000b20: 2020 2020 2020 2020 2020 6f72 6465 723d            order=
+00000b30: 2763 2729 2c0a 2020 2020 2020 2020 2020  'c'),.          
+00000b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000b50: 2020 2020 2020 2020 2020 2063 6d61 703d             cmap=
+00000b60: 226a 6574 2229 0a20 2020 2020 2020 2020  "jet").         
+00000b70: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00000b80: 2020 2020 2020 2020 2069 6d20 3d20 6178           im = ax
+00000b90: 2e70 636f 6c6f 7228 7831 2c0a 2020 2020  .pcolor(x1,.    
 00000ba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000bb0: 2020 2020 2020 2020 2020 636d 6170 3d22            cmap="
-00000bc0: 6a65 7422 290d 0a20 2020 2020 2020 2020  jet")..         
-00000bd0: 2020 2065 6c73 653a 0d0a 2020 2020 2020     else:..      
-00000be0: 2020 2020 2020 2020 2020 696d 203d 2061            im = a
-00000bf0: 782e 7063 6f6c 6f72 2878 312c 0d0a 2020  x.pcolor(x1,..  
+00000bb0: 2020 2020 2020 2020 2020 2078 322c 0a20             x2,. 
+00000bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000bd0: 2020 2020 2020 2020 2020 2020 2020 6e70                np
+00000be0: 2e72 6573 6861 7065 2879 5b3a 2c20 6f5d  .reshape(y[:, o]
+00000bf0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
 00000c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000c10: 2020 2020 2020 2020 2020 2020 2078 322c               x2,
-00000c20: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00000c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000c40: 206e 702e 7265 7368 6170 6528 795b 3a2c   np.reshape(y[:,
-00000c50: 206f 5d2c 0d0a 2020 2020 2020 2020 2020   o],..          
+00000c10: 2020 2020 2020 2020 2020 2020 286c 656e              (len
+00000c20: 2870 6172 616d 6574 6572 735b 705f 6e61  (parameters[p_na
+00000c30: 6d65 735b 315d 5d29 2c20 6c65 6e28 7061  mes[1]]), len(pa
+00000c40: 7261 6d65 7465 7273 5b70 5f6e 616d 6573  rameters[p_names
+00000c50: 5b30 5d5d 2929 2c0a 2020 2020 2020 2020  [0]])),.        
 00000c60: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00000c70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000c80: 286c 656e 2870 6172 616d 6574 6572 735b  (len(parameters[
-00000c90: 705f 6e61 6d65 735b 315d 5d29 2c20 6c65  p_names[1]]), le
-00000ca0: 6e28 7061 7261 6d65 7465 7273 5b70 5f6e  n(parameters[p_n
-00000cb0: 616d 6573 5b30 5d5d 2929 2c0d 0a20 2020  ames[0]])),..   
-00000cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000cd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000ce0: 2020 2020 2020 206f 7264 6572 3d27 6327         order='c'
-00000cf0: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
-00000d00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000d10: 2020 2063 6d61 703d 226a 6574 2229 0d0a     cmap="jet")..
-00000d20: 0d0a 2020 2020 2020 2020 2020 2020 6178  ..            ax
-00000d30: 2e73 6574 5f79 6c61 6265 6c28 7222 247b  .set_ylabel(r"${
-00000d40: 7d24 222e 666f 726d 6174 2870 5f6e 616d  }$".format(p_nam
-00000d50: 6573 5b31 5d29 2c20 666f 6e74 7369 7a65  es[1]), fontsize
-00000d60: 3d31 3329 0d0a 2020 2020 2020 2020 2020  =13)..          
-00000d70: 2020 6669 672e 636f 6c6f 7262 6172 2869    fig.colorbar(i
-00000d80: 6d2c 2061 783d 6178 2c20 6f72 6965 6e74  m, ax=ax, orient
-00000d90: 6174 696f 6e3d 2776 6572 7469 6361 6c27  ation='vertical'
-00000da0: 290d 0a0d 0a20 2020 2020 2020 2065 6c73  )....        els
-00000db0: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-00000dc0: 6178 2e70 6c6f 7428 7061 7261 6d65 7465  ax.plot(paramete
-00000dd0: 7273 5b70 5f6e 616d 6573 5b30 5d5d 2c20  rs[p_names[0]], 
-00000de0: 7929 0d0a 2020 2020 2020 2020 2020 2020  y)..            
-00000df0: 6178 2e73 6574 5f79 6c61 6265 6c28 7222  ax.set_ylabel(r"
-00000e00: 2479 287b 7d29 2422 2e66 6f72 6d61 7428  $y({})$".format(
-00000e10: 705f 6e61 6d65 735b 305d 292c 2066 6f6e  p_names[0]), fon
-00000e20: 7473 697a 653d 3133 290d 0a0d 0a20 2020  tsize=13)....   
-00000e30: 2020 2020 2061 782e 7365 745f 786c 6162       ax.set_xlab
-00000e40: 656c 2872 2224 7b7d 2422 2e66 6f72 6d61  el(r"${}$".forma
-00000e50: 7428 705f 6e61 6d65 735b 305d 292c 2066  t(p_names[0]), f
-00000e60: 6f6e 7473 697a 653d 3133 290d 0a0d 0a20  ontsize=13).... 
-00000e70: 2020 2061 782e 7365 745f 7469 746c 6528     ax.set_title(
-00000e80: 227b 7d20 6675 6e63 7469 6f6e 222e 666f  "{} function".fo
-00000e90: 726d 6174 286d 6f64 656c 2e5f 5f63 6c61  rmat(model.__cla
-00000ea0: 7373 5f5f 2e5f 5f6e 616d 655f 5f29 290d  ss__.__name__)).
-00000eb0: 0a20 2020 2070 6c74 2e74 6967 6874 5f6c  .    plt.tight_l
-00000ec0: 6179 6f75 7428 290d 0a20 2020 2070 6c74  ayout()..    plt
-00000ed0: 2e73 686f 7728 290d 0a0d 0a0d 0a63 6c61  .show()......cla
-00000ee0: 7373 2044 756d 6d79 2841 6273 7472 6163  ss Dummy(Abstrac
-00000ef0: 744d 6f64 656c 293a 0d0a 2020 2020 2222  tModel):..    ""
-00000f00: 220d 0a20 2020 2044 756d 6d79 206d 6f64  "..    Dummy mod
-00000f10: 656c 0d0a 0d0a 2020 2020 5061 7261 6d65  el....    Parame
-00000f20: 7465 7273 0d0a 2020 2020 2d2d 2d2d 2d2d  ters..    ------
-00000f30: 2d2d 2d2d 0d0a 2020 2020 705b 222e 2e2e  ----..    p["...
-00000f40: 225d 3a20 666c 6f61 7420 6f72 206e 6461  "]: float or nda
-00000f50: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
-00000f60: 5f67 7269 645d 0d0a 2020 2020 2020 2020  _grid]..        
-00000f70: 416e 7920 6669 7273 7420 7061 7261 6d65  Any first parame
-00000f80: 7465 720d 0a20 2020 2070 5b22 2e2e 2e22  ter..    p["..."
-00000f90: 5d3a 2066 6c6f 6174 206f 7220 6e64 6172  ]: float or ndar
-00000fa0: 7261 7920 6f66 2066 6c6f 6174 205b 6e5f  ray of float [n_
-00000fb0: 6772 6964 5d0d 0a20 2020 2020 2020 2041  grid]..        A
-00000fc0: 6e79 2073 6563 6f6e 6420 7061 7261 6d65  ny second parame
-00000fd0: 7465 720d 0a0d 0a20 2020 2052 6574 7572  ter....    Retur
-00000fe0: 6e73 0d0a 2020 2020 2d2d 2d2d 2d2d 2d0d  ns..    -------.
-00000ff0: 0a20 2020 2079 3a20 6e64 6172 7261 7920  .    y: ndarray 
-00001000: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
-00001010: 2078 2031 5d0d 0a20 2020 2020 2020 2041   x 1]..        A
-00001020: 6e79 206f 7574 7075 740d 0a20 2020 2022  ny output..    "
-00001030: 2222 0d0a 0d0a 2020 2020 6465 6620 5f5f  ""....    def __
-00001040: 696e 6974 5f5f 2873 656c 662c 206d 6174  init__(self, mat
-00001050: 6c61 625f 6d6f 6465 6c3d 4661 6c73 6529  lab_model=False)
-00001060: 3a0d 0a20 2020 2020 2020 2073 7570 6572  :..        super
-00001070: 2874 7970 6528 7365 6c66 292c 2073 656c  (type(self), sel
-00001080: 6629 2e5f 5f69 6e69 745f 5f28 6d61 746c  f).__init__(matl
-00001090: 6162 5f6d 6f64 656c 3d6d 6174 6c61 625f  ab_model=matlab_
-000010a0: 6d6f 6465 6c29 0d0a 2020 2020 2020 2020  model)..        
-000010b0: 7365 6c66 2e66 6e61 6d65 203d 2069 6e73  self.fname = ins
-000010c0: 7065 6374 2e67 6574 6669 6c65 2869 6e73  pect.getfile(ins
-000010d0: 7065 6374 2e63 7572 7265 6e74 6672 616d  pect.currentfram
-000010e0: 6528 2929 0d0a 0d0a 2020 2020 6465 6620  e())....    def 
-000010f0: 7661 6c69 6461 7465 2873 656c 6629 3a0d  validate(self):.
-00001100: 0a20 2020 2020 2020 2070 6173 730d 0a0d  .        pass...
-00001110: 0a20 2020 2064 6566 2073 696d 756c 6174  .    def simulat
-00001120: 6528 7365 6c66 2c20 7072 6f63 6573 735f  e(self, process_
-00001130: 6964 3d4e 6f6e 652c 206d 6174 6c61 625f  id=None, matlab_
-00001140: 656e 6769 6e65 3d4e 6f6e 6529 3a0d 0a20  engine=None):.. 
-00001150: 2020 2020 2020 2070 6173 730d 0a0d 0a0d         pass.....
-00001160: 0a63 6c61 7373 2041 636b 6c65 7928 4162  .class Ackley(Ab
-00001170: 7374 7261 6374 4d6f 6465 6c29 3a0d 0a20  stractModel):.. 
-00001180: 2020 2022 2222 0d0a 2020 2020 4e2d 6469     """..    N-di
-00001190: 6d65 6e73 696f 6e61 6c20 4163 6b6c 6579  mensional Ackley
-000011a0: 2066 756e 6374 696f 6e20 5b31 5d5b 325d   function [1][2]
-000011b0: 5b33 5d5b 345d 2e0d 0a20 2020 2054 6865  [3][4]...    The
-000011c0: 2041 636b 6c65 7920 6675 6e63 7469 6f6e   Ackley function
-000011d0: 2069 7320 7769 6465 6c79 2075 7365 6420   is widely used 
-000011e0: 666f 7220 7465 7374 696e 6720 6f70 7469  for testing opti
-000011f0: 6d69 7a61 7469 6f6e 2061 6c67 6f72 6974  mization algorit
-00001200: 686d 732e 0d0a 2020 2020 496e 2069 7473  hms...    In its
-00001210: 2074 776f 2d64 696d 656e 7369 6f6e 616c   two-dimensional
-00001220: 2066 6f72 6d2c 2061 7320 7368 6f77 6e20   form, as shown 
-00001230: 696e 2074 6865 2070 6c6f 7420 6162 6f76  in the plot abov
-00001240: 652c 2069 7420 6973 2063 6861 7261 6374  e, it is charact
-00001250: 6572 697a 6564 0d0a 2020 2020 6279 2061  erized..    by a
-00001260: 206e 6561 726c 7920 666c 6174 206f 7574   nearly flat out
-00001270: 6572 2072 6567 696f 6e2c 2061 6e64 2061  er region, and a
-00001280: 206c 6172 6765 2068 6f6c 6520 6174 2074   large hole at t
-00001290: 6865 2063 656e 7472 652e 0d0a 2020 2020  he centre...    
-000012a0: 5468 6520 6675 6e63 7469 6f6e 2070 6f73  The function pos
-000012b0: 6573 2061 2072 6973 6b20 666f 7220 6f70  es a risk for op
-000012c0: 7469 6d69 7a61 7469 6f6e 2061 6c67 6f72  timization algor
-000012d0: 6974 686d 732c 2070 6172 7469 6375 6c61  ithms, particula
-000012e0: 726c 790d 0a20 2020 2068 696c 6c63 6c69  rly..    hillcli
-000012f0: 6d62 696e 6720 616c 676f 7269 7468 6d73  mbing algorithms
-00001300: 2c20 746f 2062 6520 7472 6170 7065 6420  , to be trapped 
-00001310: 696e 206f 6e65 206f 6620 6974 7320 6d61  in one of its ma
-00001320: 6e79 206c 6f63 616c 206d 696e 696d 612e  ny local minima.
-00001330: 0d0a 0d0a 2020 2020 5265 636f 6d6d 656e  ....    Recommen
-00001340: 6465 6420 7661 7269 6162 6c65 2076 616c  ded variable val
-00001350: 7565 7320 6172 653a 2061 203d 2032 302c  ues are: a = 20,
-00001360: 2062 203d 2030 2e32 2061 6e64 2063 203d   b = 0.2 and c =
-00001370: 2030 2e35 2a70 692e 0d0a 0d0a 2020 2020   0.5*pi.....    
-00001380: 2e2e 206d 6174 683a 3a0d 0a20 2020 2020  .. math::..     
-00001390: 2020 7920 3d20 2d61 5c5c 6578 707b 5c5c    y = -a\\exp{\\
-000013a0: 6c65 6674 282d 625c 5c73 7172 747b 5c5c  left(-b\\sqrt{\\
-000013b0: 6672 6163 7b31 7d7b 647d 5c5c 7375 6d5f  frac{1}{d}\\sum_
-000013c0: 7b69 3d31 7d5e 7b4e 7d20 785f 695e 327d  {i=1}^{N} x_i^2}
-000013d0: 5c5c 7269 6768 7429 7d20 2d0d 0a20 2020  \\right)} -..   
-000013e0: 2020 2020 5c5c 6578 707b 5c5c 6c65 6674      \\exp{\\left
-000013f0: 285c 5c66 7261 637b 317d 7b64 7d5c 5c73  (\\frac{1}{d}\\s
-00001400: 756d 5f7b 693d 317d 5e7b 4e7d 205c 5c63  um_{i=1}^{N} \\c
-00001410: 6f73 7b28 6378 5f69 297d 5c5c 7269 6768  os{(cx_i)}\\righ
-00001420: 7429 7d20 2b20 6120 2b20 5c5c 6578 707b  t)} + a + \\exp{
-00001430: 2831 297d 0d0a 0d0a 2020 2020 5061 7261  (1)}....    Para
-00001440: 6d65 7465 7273 0d0a 2020 2020 2d2d 2d2d  meters..    ----
-00001450: 2d2d 2d2d 2d2d 0d0a 2020 2020 705b 2278  ------..    p["x
-00001460: 3122 5d3a 2066 6c6f 6174 206f 7220 6e64  1"]: float or nd
-00001470: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
-00001480: 6e5f 6772 6964 5d0d 0a20 2020 2020 2020  n_grid]..       
-00001490: 2046 6972 7374 2070 6172 616d 6574 6572   First parameter
-000014a0: 2064 6566 696e 6564 2069 6e20 5b2d 3332   defined in [-32
-000014b0: 2e37 3638 2c20 3332 2e37 3638 5d0d 0a20  .768, 32.768].. 
-000014c0: 2020 2070 5b22 7869 225d 3a20 666c 6f61     p["xi"]: floa
-000014d0: 7420 6f72 206e 6461 7272 6179 206f 6620  t or ndarray of 
-000014e0: 666c 6f61 7420 5b6e 5f67 7269 645d 0d0a  float [n_grid]..
-000014f0: 2020 2020 2020 2020 692d 7468 2070 6172          i-th par
-00001500: 616d 6574 6572 2064 6566 696e 6564 2069  ameter defined i
-00001510: 6e20 5b2d 3332 2e37 3638 2c20 3332 2e37  n [-32.768, 32.7
-00001520: 3638 5d0d 0a20 2020 2070 5b22 784e 225d  68]..    p["xN"]
-00001530: 3a20 666c 6f61 7420 6f72 206e 6461 7272  : float or ndarr
-00001540: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
-00001550: 7269 645d 0d0a 2020 2020 2020 2020 4e74  rid]..        Nt
-00001560: 6820 7061 7261 6d65 7465 7220 6465 6669  h parameter defi
-00001570: 6e65 6420 696e 205b 2d33 322e 3736 382c  ned in [-32.768,
-00001580: 2033 322e 3736 385d 0d0a 0d0a 2020 2020   32.768]....    
-00001590: 5265 7475 726e 730d 0a20 2020 202d 2d2d  Returns..    ---
-000015a0: 2d2d 2d2d 0d0a 2020 2020 793a 206e 6461  ----..    y: nda
-000015b0: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
-000015c0: 5f67 7269 6420 7820 315d 0d0a 2020 2020  _grid x 1]..    
-000015d0: 2020 2020 4f75 7470 7574 0d0a 0d0a 2020      Output....  
-000015e0: 2020 4e6f 7465 730d 0a20 2020 202d 2d2d    Notes..    ---
-000015f0: 2d2d 0d0a 2020 2020 2e2e 2070 6c6f 743a  --..    .. plot:
-00001600: 3a0d 0a0d 0a20 2020 2020 2020 696d 706f  :....       impo
-00001610: 7274 206e 756d 7079 2061 7320 6e70 0d0a  rt numpy as np..
-00001620: 2020 2020 2020 2066 726f 6d20 7079 6770         from pygp
-00001630: 632e 7465 7374 6675 6e63 7469 6f6e 7320  c.testfunctions 
-00001640: 696d 706f 7274 2070 6c6f 745f 7465 7374  import plot_test
-00001650: 6675 6e63 7469 6f6e 2061 7320 706c 6f74  function as plot
-00001660: 0d0a 2020 2020 2020 2066 726f 6d20 636f  ..       from co
-00001670: 6c6c 6563 7469 6f6e 7320 696d 706f 7274  llections import
-00001680: 204f 7264 6572 6564 4469 6374 0d0a 0d0a   OrderedDict....
-00001690: 2020 2020 2020 2070 6172 616d 6574 6572         parameter
-000016a0: 7320 3d20 4f72 6465 7265 6444 6963 7428  s = OrderedDict(
-000016b0: 290d 0a20 2020 2020 2020 7061 7261 6d65  )..       parame
-000016c0: 7465 7273 5b22 7831 225d 203d 206e 702e  ters["x1"] = np.
-000016d0: 6c69 6e73 7061 6365 282d 3332 2e37 3638  linspace(-32.768
-000016e0: 2c20 3332 2e37 3638 2c20 3130 3029 0d0a  , 32.768, 100)..
-000016f0: 2020 2020 2020 2070 6172 616d 6574 6572         parameter
-00001700: 735b 2278 3222 5d20 3d20 6e70 2e6c 696e  s["x2"] = np.lin
-00001710: 7370 6163 6528 2d33 322e 3736 382c 2033  space(-32.768, 3
-00001720: 322e 3736 382c 2031 3030 290d 0a0d 0a20  2.768, 100).... 
-00001730: 2020 2020 2020 636f 6e73 7461 6e74 7320        constants 
-00001740: 3d20 4f72 6465 7265 6444 6963 7428 290d  = OrderedDict().
-00001750: 0a20 2020 2020 2020 636f 6e73 7461 6e74  .       constant
-00001760: 735b 2261 225d 203d 2032 302e 0d0a 2020  s["a"] = 20...  
-00001770: 2020 2020 2063 6f6e 7374 616e 7473 5b22       constants["
-00001780: 6222 5d20 3d20 302e 320d 0a20 2020 2020  b"] = 0.2..     
-00001790: 2020 636f 6e73 7461 6e74 735b 2263 225d    constants["c"]
-000017a0: 203d 2030 2e35 2a6e 702e 7069 0d0a 0d0a   = 0.5*np.pi....
-000017b0: 2020 2020 2020 2070 6c6f 7428 2241 636b         plot("Ack
-000017c0: 6c65 7922 2c20 7061 7261 6d65 7465 7273  ley", parameters
-000017d0: 2c20 636f 6e73 7461 6e74 732c 2070 6c6f  , constants, plo
-000017e0: 745f 3364 3d46 616c 7365 290d 0a0d 0a20  t_3d=False).... 
-000017f0: 2020 202e 2e20 5b31 5d20 4164 6f72 696f     .. [1] Adorio
-00001800: 2c20 452e 2050 2e2c 2026 2044 696c 696d  , E. P., & Dilim
-00001810: 616e 2c20 552e 2050 2e20 4d56 4620 2d20  an, U. P. MVF - 
-00001820: 4d75 6c74 6976 6172 6961 7465 2054 6573  Multivariate Tes
-00001830: 7420 4675 6e63 7469 6f6e 7320 4c69 6272  t Functions Libr
-00001840: 6172 7920 696e 2043 0d0a 2020 2020 2020  ary in C..      
-00001850: 2066 6f72 2055 6e63 6f6e 7374 7261 696e   for Unconstrain
-00001860: 6564 2047 6c6f 6261 6c20 4f70 7469 6d69  ed Global Optimi
-00001870: 7a61 7469 6f6e 2028 3230 3035 292e 2052  zation (2005). R
-00001880: 6574 7269 6576 6564 204a 756e 6520 3230  etrieved June 20
-00001890: 3133 2c0d 0a20 2020 2020 2020 6672 6f6d  13,..       from
-000018a0: 2068 7474 703a 2f2f 6874 7470 3a2f 2f77   http://http://w
-000018b0: 7777 2e67 656f 6369 7469 6573 2e77 732f  ww.geocities.ws/
-000018c0: 6561 646f 7269 6f2f 6d76 662e 7064 660d  eadorio/mvf.pdf.
-000018d0: 0a0d 0a20 2020 202e 2e20 5b32 5d20 4d6f  ...    .. [2] Mo
-000018e0: 6c67 612c 204d 2e2c 2026 2053 6d75 746e  lga, M., & Smutn
-000018f0: 6963 6b69 2c20 432e 2054 6573 7420 6675  icki, C. Test fu
-00001900: 6e63 7469 6f6e 7320 666f 7220 6f70 7469  nctions for opti
-00001910: 6d69 7a61 7469 6f6e 206e 6565 6473 2028  mization needs (
-00001920: 3230 3035 292e 0d0a 2020 2020 2020 2052  2005)...       R
-00001930: 6574 7269 6576 6564 204a 756e 6520 3230  etrieved June 20
-00001940: 3133 2c20 6672 6f6d 2068 7474 703a 2f2f  13, from http://
-00001950: 7777 772e 7a73 642e 6963 742e 7077 722e  www.zsd.ict.pwr.
-00001960: 7772 6f63 2e70 6c2f 6669 6c65 732f 646f  wroc.pl/files/do
-00001970: 6373 2f66 756e 6374 696f 6e73 2e70 6466  cs/functions.pdf
-00001980: 0d0a 0d0a 2020 2020 2e2e 205b 335d 2042  ....    .. [3] B
-00001990: 6163 6b2c 2054 2e20 2831 3939 3629 2e20  ack, T. (1996). 
-000019a0: 4576 6f6c 7574 696f 6e61 7279 2061 6c67  Evolutionary alg
-000019b0: 6f72 6974 686d 7320 696e 2074 6865 6f72  orithms in theor
-000019c0: 7920 616e 6420 7072 6163 7469 6365 3a20  y and practice: 
-000019d0: 6576 6f6c 7574 696f 6e20 7374 7261 7465  evolution strate
-000019e0: 6769 6573 2c0d 0a20 2020 2020 2020 6576  gies,..       ev
-000019f0: 6f6c 7574 696f 6e61 7279 2070 726f 6772  olutionary progr
-00001a00: 616d 6d69 6e67 2c20 6765 6e65 7469 6320  amming, genetic 
-00001a10: 616c 676f 7269 7468 6d73 2e20 4f78 666f  algorithms. Oxfo
-00001a20: 7264 2055 6e69 7665 7273 6974 7920 5072  rd University Pr
-00001a30: 6573 7320 6f6e 2044 656d 616e 640d 0a0d  ess on Demand...
-00001a40: 0a20 2020 202e 2e20 5b34 5d20 6874 7470  .    .. [4] http
-00001a50: 733a 2f2f 7777 772e 7366 752e 6361 2f7e  s://www.sfu.ca/~
-00001a60: 7373 7572 6a61 6e6f 2f61 636b 6c65 792e  ssurjano/ackley.
-00001a70: 6874 6d6c 0d0a 2020 2020 2222 220d 0a0d  html..    """...
-00001a80: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
-00001a90: 5f28 7365 6c66 2c20 6d61 746c 6162 5f6d  _(self, matlab_m
-00001aa0: 6f64 656c 3d46 616c 7365 293a 0d0a 2020  odel=False):..  
-00001ab0: 2020 2020 2020 7375 7065 7228 7479 7065        super(type
-00001ac0: 2873 656c 6629 2c20 7365 6c66 292e 5f5f  (self), self).__
-00001ad0: 696e 6974 5f5f 286d 6174 6c61 625f 6d6f  init__(matlab_mo
-00001ae0: 6465 6c3d 6d61 746c 6162 5f6d 6f64 656c  del=matlab_model
-00001af0: 290d 0a20 2020 2020 2020 2073 656c 662e  )..        self.
-00001b00: 666e 616d 6520 3d20 696e 7370 6563 742e  fname = inspect.
-00001b10: 6765 7466 696c 6528 696e 7370 6563 742e  getfile(inspect.
-00001b20: 6375 7272 656e 7466 7261 6d65 2829 290d  currentframe()).
-00001b30: 0a0d 0a20 2020 2064 6566 2076 616c 6964  ...    def valid
-00001b40: 6174 6528 7365 6c66 293a 0d0a 2020 2020  ate(self):..    
-00001b50: 2020 2020 7061 7373 0d0a 0d0a 2020 2020      pass....    
-00001b60: 6465 6620 7369 6d75 6c61 7465 2873 656c  def simulate(sel
-00001b70: 662c 2070 726f 6365 7373 5f69 643d 4e6f  f, process_id=No
-00001b80: 6e65 2c20 6d61 746c 6162 5f65 6e67 696e  ne, matlab_engin
-00001b90: 653d 4e6f 6e65 293a 0d0a 0d0a 2020 2020  e=None):....    
-00001ba0: 2020 2020 666f 7220 692c 206b 6579 2069      for i, key i
-00001bb0: 6e20 656e 756d 6572 6174 6528 7365 6c66  n enumerate(self
-00001bc0: 2e70 2e6b 6579 7328 2929 3a0d 0a20 2020  .p.keys()):..   
-00001bd0: 2020 2020 2020 2020 2069 6620 7479 7065           if type
-00001be0: 2873 656c 662e 705b 6b65 795d 2920 6973  (self.p[key]) is
-00001bf0: 206e 702e 6e64 6172 7261 793a 0d0a 2020   np.ndarray:..  
-00001c00: 2020 2020 2020 2020 2020 2020 2020 7365                se
-00001c10: 6c66 2e70 5b6b 6579 5d20 3d20 7365 6c66  lf.p[key] = self
-00001c20: 2e70 5b6b 6579 5d2e 666c 6174 7465 6e28  .p[key].flatten(
-00001c30: 290d 0a0d 0a20 2020 2020 2020 2023 2073  )....        # s
-00001c40: 6574 2063 6f6e 7374 616e 7473 0d0a 2020  et constants..  
-00001c50: 2020 2020 2020 7020 3d20 636f 7079 2e64        p = copy.d
-00001c60: 6565 7063 6f70 7928 7365 6c66 2e70 290d  eepcopy(self.p).
-00001c70: 0a20 2020 2020 2020 2061 203d 2073 656c  .        a = sel
-00001c80: 662e 705b 2261 225d 0d0a 2020 2020 2020  f.p["a"]..      
-00001c90: 2020 6220 3d20 7365 6c66 2e70 5b22 6222    b = self.p["b"
-00001ca0: 5d0d 0a20 2020 2020 2020 2063 203d 2073  ]..        c = s
-00001cb0: 656c 662e 705b 2263 225d 0d0a 2020 2020  elf.p["c"]..    
-00001cc0: 2020 2020 6465 6c20 705b 2261 225d 2c20      del p["a"], 
-00001cd0: 705b 2262 225d 2c20 705b 2263 225d 0d0a  p["b"], p["c"]..
-00001ce0: 0d0a 2020 2020 2020 2020 6e20 3d20 6c65  ..        n = le
-00001cf0: 6e28 702e 6b65 7973 2829 290d 0a0d 0a20  n(p.keys()).... 
-00001d00: 2020 2020 2020 2023 2064 6574 6572 6d69         # determi
-00001d10: 6e65 2073 756d 2069 6e20 6578 706f 6e65  ne sum in expone
-00001d20: 6e74 0d0a 2020 2020 2020 2020 7331 203d  nt..        s1 =
-00001d30: 206e 702e 7a65 726f 7328 6e70 2e61 7272   np.zeros(np.arr
-00001d40: 6179 2870 5b6c 6973 7428 702e 6b65 7973  ay(p[list(p.keys
-00001d50: 2829 295b 305d 5d29 2e73 697a 6529 0d0a  ())[0]]).size)..
-00001d60: 2020 2020 2020 2020 7332 203d 206e 702e          s2 = np.
-00001d70: 7a65 726f 7328 6e70 2e61 7272 6179 2870  zeros(np.array(p
-00001d80: 5b6c 6973 7428 702e 6b65 7973 2829 295b  [list(p.keys())[
-00001d90: 305d 5d29 2e73 697a 6529 0d0a 0d0a 2020  0]]).size)....  
-00001da0: 2020 2020 2020 666f 7220 692c 206b 6579        for i, key
-00001db0: 2069 6e20 656e 756d 6572 6174 6528 702e   in enumerate(p.
-00001dc0: 6b65 7973 2829 293a 0d0a 2020 2020 2020  keys()):..      
-00001dd0: 2020 2020 2020 7331 202b 3d20 705b 6b65        s1 += p[ke
-00001de0: 795d 2a2a 320d 0a20 2020 2020 2020 2020  y]**2..         
-00001df0: 2020 2073 3220 2b3d 206e 702e 636f 7328     s2 += np.cos(
-00001e00: 632a 705b 6b65 795d 290d 0a0d 0a20 2020  c*p[key])....   
-00001e10: 2020 2020 2073 3120 3d20 2d61 202a 206e       s1 = -a * n
-00001e20: 702e 6578 7028 2d62 202a 206e 702e 7371  p.exp(-b * np.sq
-00001e30: 7274 2831 2f6e 202a 2073 3129 290d 0a20  rt(1/n * s1)).. 
-00001e40: 2020 2020 2020 2073 3220 3d20 6e70 2e65         s2 = np.e
-00001e50: 7870 2831 2f6e 202a 2073 3229 0d0a 0d0a  xp(1/n * s2)....
-00001e60: 2020 2020 2020 2020 2320 6465 7465 726d          # determ
-00001e70: 696e 6520 6f75 7470 7574 0d0a 2020 2020  ine output..    
-00001e80: 2020 2020 7920 3d20 7331 202d 2073 3220      y = s1 - s2 
-00001e90: 2b20 6120 2b20 6e70 2e65 7870 2831 290d  + a + np.exp(1).
-00001ea0: 0a0d 0a20 2020 2020 2020 2079 5f6f 7574  ...        y_out
-00001eb0: 203d 2079 5b3a 2c20 6e70 2e6e 6577 6178   = y[:, np.newax
-00001ec0: 6973 5d0d 0a0d 0a20 2020 2020 2020 2072  is]....        r
-00001ed0: 6574 7572 6e20 795f 6f75 740d 0a0d 0a0d  eturn y_out.....
-00001ee0: 0a63 6c61 7373 2042 756b 696e 4675 6e63  .class BukinFunc
-00001ef0: 7469 6f6e 4e75 6d62 6572 3628 4162 7374  tionNumber6(Abst
-00001f00: 7261 6374 4d6f 6465 6c29 3a0d 0a20 2020  ractModel):..   
-00001f10: 2022 2222 0d0a 2020 2020 322d 6469 6d65   """..    2-dime
-00001f20: 6e73 696f 6e61 6c20 4275 6b69 6e20 4675  nsional Bukin Fu
-00001f30: 6e63 7469 6f6e 204e 2e20 3620 5b31 5d5b  nction N. 6 [1][
-00001f40: 325d 2e0d 0a20 2020 2054 6865 2073 6978  2]...    The six
-00001f50: 7468 2042 756b 696e 2046 756e 6374 696f  th Bukin Functio
-00001f60: 6e20 6861 7320 6d61 6e79 206c 6f63 616c  n has many local
-00001f70: 206d 696e 696d 612c 2061 6c6c 206f 6620   minima, all of 
-00001f80: 7768 6963 6820 6c69 6520 696e 2061 2072  which lie in a r
-00001f90: 6964 6765 2e0d 0a0d 0a20 2020 202e 2e20  idge.....    .. 
-00001fa0: 6d61 7468 3a3a 0d0a 2020 2020 2020 2079  math::..       y
-00001fb0: 203d 2031 3030 5c5c 7371 7274 7b5c 5c6d   = 100\\sqrt{\\m
-00001fc0: 6964 2078 5f32 202d 2030 2e30 3120 785f  id x_2 - 0.01 x_
-00001fd0: 315e 3220 5c5c 6d69 647d 202b 2030 2e30  1^2 \\mid} + 0.0
-00001fe0: 315c 5c6d 6964 2078 5f31 202b 2031 3020  1\\mid x_1 + 10 
-00001ff0: 5c5c 6d69 640d 0a0d 0a20 2020 2050 6172  \\mid....    Par
-00002000: 616d 6574 6572 730d 0a20 2020 202d 2d2d  ameters..    ---
-00002010: 2d2d 2d2d 2d2d 2d0d 0a20 2020 2070 5b22  -------..    p["
-00002020: 7831 225d 3a20 666c 6f61 7420 6f72 206e  x1"]: float or n
-00002030: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-00002040: 5b6e 5f67 7269 645d 0d0a 2020 2020 2020  [n_grid]..      
-00002050: 2020 4669 7273 7420 7061 7261 6d65 7465    First paramete
-00002060: 7220 6465 6669 6e65 6420 696e 205b 2d31  r defined in [-1
-00002070: 352c 202d 355d 0d0a 2020 2020 705b 2278  5, -5]..    p["x
-00002080: 3222 5d3a 2066 6c6f 6174 206f 7220 6e64  2"]: float or nd
-00002090: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
-000020a0: 6e5f 6772 6964 5d0d 0a20 2020 2020 2020  n_grid]..       
-000020b0: 2073 6563 6f6e 6420 7061 7261 6d65 7465   second paramete
-000020c0: 7220 6465 6669 6e65 6420 696e 205b 2d33  r defined in [-3
-000020d0: 2c20 335d 0d0a 0d0a 2020 2020 5265 7475  , 3]....    Retu
-000020e0: 726e 730d 0a20 2020 202d 2d2d 2d2d 2d2d  rns..    -------
-000020f0: 0d0a 2020 2020 793a 206e 6461 7272 6179  ..    y: ndarray
-00002100: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
-00002110: 6420 7820 315d 0d0a 2020 2020 2020 2020  d x 1]..        
-00002120: 4f75 7470 7574 0d0a 0d0a 2020 2020 4e6f  Output....    No
-00002130: 7465 730d 0a20 2020 202d 2d2d 2d2d 0d0a  tes..    -----..
-00002140: 2020 2020 2e2e 2070 6c6f 743a 3a0d 0a0d      .. plot::...
-00002150: 0a20 2020 2020 2020 696d 706f 7274 206e  .       import n
-00002160: 756d 7079 2061 7320 6e70 0d0a 2020 2020  umpy as np..    
-00002170: 2020 2066 726f 6d20 7079 6770 632e 7465     from pygpc.te
-00002180: 7374 6675 6e63 7469 6f6e 7320 696d 706f  stfunctions impo
-00002190: 7274 2070 6c6f 745f 7465 7374 6675 6e63  rt plot_testfunc
-000021a0: 7469 6f6e 2061 7320 706c 6f74 0d0a 2020  tion as plot..  
-000021b0: 2020 2020 2066 726f 6d20 636f 6c6c 6563       from collec
-000021c0: 7469 6f6e 7320 696d 706f 7274 204f 7264  tions import Ord
-000021d0: 6572 6564 4469 6374 0d0a 0d0a 2020 2020  eredDict....    
-000021e0: 2020 2070 6172 616d 6574 6572 7320 3d20     parameters = 
-000021f0: 4f72 6465 7265 6444 6963 7428 290d 0a20  OrderedDict().. 
-00002200: 2020 2020 2020 7061 7261 6d65 7465 7273        parameters
-00002210: 5b22 7831 225d 203d 206e 702e 6c69 6e73  ["x1"] = np.lins
-00002220: 7061 6365 282d 3135 2c20 2d35 2c20 3130  pace(-15, -5, 10
-00002230: 3029 0d0a 2020 2020 2020 2070 6172 616d  0)..       param
-00002240: 6574 6572 735b 2278 3222 5d20 3d20 6e70  eters["x2"] = np
-00002250: 2e6c 696e 7370 6163 6528 2d33 2c20 332c  .linspace(-3, 3,
-00002260: 2031 3030 290d 0a0d 0a20 2020 2020 2020   100)....       
-00002270: 636f 6e73 7461 6e74 7320 3d20 4e6f 6e65  constants = None
-00002280: 0d0a 0d0a 2020 2020 2020 2070 6c6f 7428  ....       plot(
-00002290: 2242 756b 696e 4675 6e63 7469 6f6e 4e75  "BukinFunctionNu
-000022a0: 6d62 6572 3622 2c20 7061 7261 6d65 7465  mber6", paramete
-000022b0: 7273 2c20 636f 6e73 7461 6e74 732c 2070  rs, constants, p
-000022c0: 6c6f 745f 3364 3d46 616c 7365 290d 0a0d  lot_3d=False)...
-000022d0: 0a20 2020 202e 2e20 5b31 5d20 476c 6f62  .    .. [1] Glob
-000022e0: 616c 204f 7074 696d 697a 6174 696f 6e20  al Optimization 
-000022f0: 5465 7374 2046 756e 6374 696f 6e73 2049  Test Functions I
-00002300: 6e64 6578 2e20 5265 7472 6965 7665 6420  ndex. Retrieved 
-00002310: 4a75 6e65 2032 3031 332c 2066 726f 6d0d  June 2013, from.
-00002320: 0a20 2020 2020 2020 6874 7470 3a2f 2f69  .       http://i
-00002330: 6e66 696e 6974 7937 372e 6e65 742f 676c  nfinity77.net/gl
-00002340: 6f62 616c 5f6f 7074 696d 697a 6174 696f  obal_optimizatio
-00002350: 6e2f 7465 7374 5f66 756e 6374 696f 6e73  n/test_functions
-00002360: 2e68 746d 6c23 7465 7374 2d66 756e 6374  .html#test-funct
-00002370: 696f 6e73 2d69 6e64 6578 2e0d 0a0d 0a20  ions-index..... 
-00002380: 2020 202e 2e20 5b32 5d20 6874 7470 733a     .. [2] https:
-00002390: 2f2f 7777 772e 7366 752e 6361 2f7e 7373  //www.sfu.ca/~ss
-000023a0: 7572 6a61 6e6f 2f62 756b 696e 362e 6874  urjano/bukin6.ht
-000023b0: 6d6c 0d0a 0d0a 2020 2020 2222 220d 0a0d  ml....    """...
-000023c0: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
-000023d0: 5f28 7365 6c66 2c20 6d61 746c 6162 5f6d  _(self, matlab_m
-000023e0: 6f64 656c 3d46 616c 7365 293a 0d0a 2020  odel=False):..  
-000023f0: 2020 2020 2020 7375 7065 7228 7479 7065        super(type
-00002400: 2873 656c 6629 2c20 7365 6c66 292e 5f5f  (self), self).__
-00002410: 696e 6974 5f5f 286d 6174 6c61 625f 6d6f  init__(matlab_mo
-00002420: 6465 6c3d 6d61 746c 6162 5f6d 6f64 656c  del=matlab_model
-00002430: 290d 0a20 2020 2020 2020 2073 656c 662e  )..        self.
-00002440: 666e 616d 6520 3d20 696e 7370 6563 742e  fname = inspect.
-00002450: 6765 7466 696c 6528 696e 7370 6563 742e  getfile(inspect.
-00002460: 6375 7272 656e 7466 7261 6d65 2829 290d  currentframe()).
-00002470: 0a0d 0a20 2020 2064 6566 2076 616c 6964  ...    def valid
-00002480: 6174 6528 7365 6c66 293a 0d0a 2020 2020  ate(self):..    
-00002490: 2020 2020 7061 7373 0d0a 0d0a 2020 2020      pass....    
-000024a0: 6465 6620 7369 6d75 6c61 7465 2873 656c  def simulate(sel
-000024b0: 662c 2070 726f 6365 7373 5f69 643d 4e6f  f, process_id=No
-000024c0: 6e65 2c20 6d61 746c 6162 5f65 6e67 696e  ne, matlab_engin
-000024d0: 653d 4e6f 6e65 293a 0d0a 0d0a 2020 2020  e=None):....    
-000024e0: 2020 2020 7920 3d20 3130 3020 2a20 6e70      y = 100 * np
-000024f0: 2e73 7172 7428 6162 7328 7365 6c66 2e70  .sqrt(abs(self.p
-00002500: 5b22 7832 225d 202d 2030 2e30 3120 2a20  ["x2"] - 0.01 * 
-00002510: 7365 6c66 2e70 5b22 7831 225d 202a 2a20  self.p["x1"] ** 
-00002520: 3229 2920 2b20 302e 3031 202a 2061 6273  2)) + 0.01 * abs
-00002530: 2873 656c 662e 705b 2278 3122 5d20 2b20  (self.p["x1"] + 
-00002540: 3130 290d 0a0d 0a20 2020 2020 2020 2079  10)....        y
-00002550: 5f6f 7574 203d 2079 5b3a 2c20 6e70 2e6e  _out = y[:, np.n
-00002560: 6577 6178 6973 5d0d 0a0d 0a20 2020 2020  ewaxis]....     
-00002570: 2020 2072 6574 7572 6e20 795f 6f75 740d     return y_out.
-00002580: 0a0d 0a0d 0a63 6c61 7373 2043 726f 7373  .....class Cross
-00002590: 696e 5472 6179 4675 6e63 7469 6f6e 2841  inTrayFunction(A
-000025a0: 6273 7472 6163 744d 6f64 656c 293a 0d0a  bstractModel):..
-000025b0: 2020 2020 2222 220d 0a20 2020 2032 2d64      """..    2-d
-000025c0: 696d 656e 7369 6f6e 616c 2043 726f 7373  imensional Cross
-000025d0: 2d69 6e2d 5472 6179 2046 756e 6374 696f  -in-Tray Functio
-000025e0: 6e20 5b31 5d5b 325d 2e0d 0a20 2020 2054  n [1][2]...    T
-000025f0: 6865 2043 726f 7373 2d69 6e2d 5472 6179  he Cross-in-Tray
-00002600: 2066 756e 6374 696f 6e20 6861 7320 6d75   function has mu
-00002610: 6c74 6970 6c65 2067 6c6f 6261 6c20 6d69  ltiple global mi
-00002620: 6e69 6d61 2e0d 0a20 2020 2049 7420 6973  nima...    It is
-00002630: 2073 686f 776e 2068 6572 6520 7769 7468   shown here with
-00002640: 2061 2073 6d61 6c6c 6572 2064 6f6d 6169   a smaller domai
-00002650: 6e20 696e 2074 6865 2073 6563 6f6e 6420  n in the second 
-00002660: 706c 6f74 2c0d 0a20 2020 2073 6f20 7468  plot,..    so th
-00002670: 6174 2069 7473 2063 6861 7261 6374 6572  at its character
-00002680: 6973 7469 6320 2263 726f 7373 2220 7769  istic "cross" wi
-00002690: 6c6c 2062 6520 7669 7369 626c 652e 0d0a  ll be visible...
-000026a0: 0d0a 2020 2020 2e2e 206d 6174 683a 3a0d  ..    .. math::.
-000026b0: 0a20 2020 2020 2079 203d 202d 302e 3030  .      y = -0.00
-000026c0: 3031 5c5c 6c65 6674 285c 5c6d 6964 5c5c  01\\left(\\mid\\
-000026d0: 7369 6e28 785f 3129 5c5c 7369 6e28 785f  sin(x_1)\\sin(x_
-000026e0: 3229 5c5c 6578 705c 5c6c 6566 7428 5c5c  2)\\exp\\left(\\
-000026f0: 6d69 6420 3130 302d 5c5c 6672 6163 7b5c  mid 100-\\frac{\
-00002700: 5c73 7172 747b 785f 315e 3220 2b20 785f  \sqrt{x_1^2 + x_
-00002710: 325e 327d 7d7b 5c5c 7069 7d5c 5c6d 6964  2^2}}{\\pi}\\mid
-00002720: 5c5c 7269 6768 7429 5c5c 6d69 6420 2b20  \\right)\\mid + 
-00002730: 315c 5c72 6967 6874 295e 7b30 2e31 7d0d  1\\right)^{0.1}.
-00002740: 0a0d 0a20 2020 2050 6172 616d 6574 6572  ...    Parameter
-00002750: 730d 0a20 2020 202d 2d2d 2d2d 2d2d 2d2d  s..    ---------
-00002760: 2d0d 0a20 2020 2070 5b22 7831 225d 3a20  -..    p["x1"]: 
-00002770: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
-00002780: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
-00002790: 645d 0d0a 2020 2020 2020 2020 4669 7273  d]..        Firs
-000027a0: 7420 7061 7261 6d65 7465 7220 6465 6669  t parameter defi
-000027b0: 6e65 6420 696e 205b 2d31 302c 2031 305d  ned in [-10, 10]
-000027c0: 0d0a 2020 2020 705b 2278 3222 5d3a 2066  ..    p["x2"]: f
-000027d0: 6c6f 6174 206f 7220 6e64 6172 7261 7920  loat or ndarray 
-000027e0: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
-000027f0: 5d0d 0a20 2020 2020 2020 2073 6563 6f6e  ]..        secon
-00002800: 6420 7061 7261 6d65 7465 7220 6465 6669  d parameter defi
-00002810: 6e65 6420 696e 205b 2d31 302c 2031 305d  ned in [-10, 10]
-00002820: 0d0a 2020 2020 705b 2278 6922 5d3a 2066  ..    p["xi"]: f
-00002830: 6c6f 6174 206f 7220 6e64 6172 7261 7920  loat or ndarray 
-00002840: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
-00002850: 5d0d 0a20 2020 2020 2020 2069 2d74 6820  ]..        i-th 
-00002860: 7061 7261 6d65 7465 7220 6465 6669 6e65  parameter define
-00002870: 6420 696e 205b 2d31 302c 2031 305d 0d0a  d in [-10, 10]..
-00002880: 0d0a 2020 2020 5265 7475 726e 730d 0a20  ..    Returns.. 
-00002890: 2020 202d 2d2d 2d2d 2d2d 0d0a 2020 2020     -------..    
-000028a0: 793a 206e 6461 7272 6179 206f 6620 666c  y: ndarray of fl
-000028b0: 6f61 7420 5b6e 5f67 7269 6420 7820 315d  oat [n_grid x 1]
-000028c0: 0d0a 2020 2020 2020 2020 4f75 7470 7574  ..        Output
-000028d0: 0d0a 0d0a 2020 2020 4e6f 7465 730d 0a20  ....    Notes.. 
-000028e0: 2020 202d 2d2d 2d2d 0d0a 2020 2020 2e2e     -----..    ..
-000028f0: 2070 6c6f 743a 3a0d 0a0d 0a20 2020 2020   plot::....     
-00002900: 2020 696d 706f 7274 206e 756d 7079 2061    import numpy a
-00002910: 7320 6e70 0d0a 2020 2020 2020 2066 726f  s np..       fro
-00002920: 6d20 7079 6770 632e 7465 7374 6675 6e63  m pygpc.testfunc
-00002930: 7469 6f6e 7320 696d 706f 7274 2070 6c6f  tions import plo
-00002940: 745f 7465 7374 6675 6e63 7469 6f6e 2061  t_testfunction a
-00002950: 7320 706c 6f74 0d0a 2020 2020 2020 2066  s plot..       f
-00002960: 726f 6d20 636f 6c6c 6563 7469 6f6e 7320  rom collections 
-00002970: 696d 706f 7274 204f 7264 6572 6564 4469  import OrderedDi
-00002980: 6374 0d0a 0d0a 2020 2020 2020 2070 6172  ct....       par
-00002990: 616d 6574 6572 7320 3d20 4f72 6465 7265  ameters = Ordere
-000029a0: 6444 6963 7428 290d 0a20 2020 2020 2020  dDict()..       
-000029b0: 7061 7261 6d65 7465 7273 5b22 7831 225d  parameters["x1"]
-000029c0: 203d 206e 702e 6c69 6e73 7061 6365 282d   = np.linspace(-
-000029d0: 3130 2c20 3130 2c20 3130 3029 0d0a 2020  10, 10, 100)..  
-000029e0: 2020 2020 2070 6172 616d 6574 6572 735b       parameters[
-000029f0: 2278 3222 5d20 3d20 6e70 2e6c 696e 7370  "x2"] = np.linsp
-00002a00: 6163 6528 2d31 302c 2031 302c 2031 3030  ace(-10, 10, 100
-00002a10: 290d 0a0d 0a20 2020 2020 2020 636f 6e73  )....       cons
-00002a20: 7461 6e74 7320 3d20 4e6f 6e65 0d0a 0d0a  tants = None....
-00002a30: 2020 2020 2020 2070 6c6f 7428 2243 726f         plot("Cro
-00002a40: 7373 696e 5472 6179 4675 6e63 7469 6f6e  ssinTrayFunction
-00002a50: 222c 2070 6172 616d 6574 6572 732c 2063  ", parameters, c
-00002a60: 6f6e 7374 616e 7473 2c20 706c 6f74 5f33  onstants, plot_3
-00002a70: 643d 4661 6c73 6529 0d0a 0d0a 2020 2020  d=False)....    
-00002a80: 2e2e 205b 315d 2054 6573 7420 6675 6e63  .. [1] Test func
-00002a90: 7469 6f6e 7320 666f 7220 6f70 7469 6d69  tions for optimi
-00002aa0: 7a61 7469 6f6e 2e20 496e 2057 696b 6970  zation. In Wikip
-00002ab0: 6564 6961 2e20 5265 7472 6965 7665 6420  edia. Retrieved 
-00002ac0: 4a75 6e65 2032 3031 332c 2066 726f 6d0d  June 2013, from.
-00002ad0: 0a20 2020 2020 2020 6874 7470 733a 2f2f  .       https://
-00002ae0: 656e 2e77 696b 6970 6564 6961 2e6f 7267  en.wikipedia.org
-00002af0: 2f77 696b 692f 5465 7374 5f66 756e 6374  /wiki/Test_funct
-00002b00: 696f 6e73 5f66 6f72 5f6f 7074 696d 697a  ions_for_optimiz
-00002b10: 6174 696f 6e2e 0d0a 2020 2020 2e2e 205b  ation...    .. [
-00002b20: 325d 2068 7474 7073 3a2f 2f77 7777 2e73  2] https://www.s
-00002b30: 6675 2e63 612f 7e73 7375 726a 616e 6f2f  fu.ca/~ssurjano/
-00002b40: 6372 6f73 7369 742e 6874 6d6c 0d0a 2020  crossit.html..  
-00002b50: 2020 2222 220d 0a0d 0a20 2020 2064 6566    """....    def
-00002b60: 205f 5f69 6e69 745f 5f28 7365 6c66 2c20   __init__(self, 
-00002b70: 6d61 746c 6162 5f6d 6f64 656c 3d46 616c  matlab_model=Fal
-00002b80: 7365 293a 0d0a 2020 2020 2020 2020 7375  se):..        su
-00002b90: 7065 7228 7479 7065 2873 656c 6629 2c20  per(type(self), 
-00002ba0: 7365 6c66 292e 5f5f 696e 6974 5f5f 286d  self).__init__(m
-00002bb0: 6174 6c61 625f 6d6f 6465 6c3d 6d61 746c  atlab_model=matl
-00002bc0: 6162 5f6d 6f64 656c 290d 0a20 2020 2020  ab_model)..     
-00002bd0: 2020 2073 656c 662e 666e 616d 6520 3d20     self.fname = 
-00002be0: 696e 7370 6563 742e 6765 7466 696c 6528  inspect.getfile(
-00002bf0: 696e 7370 6563 742e 6375 7272 656e 7466  inspect.currentf
-00002c00: 7261 6d65 2829 290d 0a0d 0a20 2020 2064  rame())....    d
-00002c10: 6566 2076 616c 6964 6174 6528 7365 6c66  ef validate(self
-00002c20: 293a 0d0a 2020 2020 2020 2020 7061 7373  ):..        pass
-00002c30: 0d0a 0d0a 2020 2020 6465 6620 7369 6d75  ....    def simu
-00002c40: 6c61 7465 2873 656c 662c 2070 726f 6365  late(self, proce
-00002c50: 7373 5f69 643d 4e6f 6e65 2c20 6d61 746c  ss_id=None, matl
-00002c60: 6162 5f65 6e67 696e 653d 4e6f 6e65 293a  ab_engine=None):
-00002c70: 0d0a 0d0a 2020 2020 2020 2020 7920 3d20  ....        y = 
-00002c80: 2d30 2e30 3030 3120 2a20 286e 702e 6162  -0.0001 * (np.ab
-00002c90: 7328 6e70 2e73 696e 2873 656c 662e 705b  s(np.sin(self.p[
-00002ca0: 2278 3122 5d29 202a 206e 702e 7369 6e28  "x1"]) * np.sin(
-00002cb0: 7365 6c66 2e70 5b22 7832 225d 2920 2a0d  self.p["x2"]) *.
-00002cc0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00002cd0: 2020 2020 2020 2020 2020 2020 2020 206e                 n
-00002ce0: 702e 6578 7028 6e70 2e61 6273 2831 3030  p.exp(np.abs(100
-00002cf0: 202d 2028 6e70 2e73 7172 7428 7365 6c66   - (np.sqrt(self
-00002d00: 2e70 5b22 7831 225d 2a2a 3220 2b20 7365  .p["x1"]**2 + se
-00002d10: 6c66 2e70 5b22 7832 225d 2a2a 3229 2920  lf.p["x2"]**2)) 
-00002d20: 2f20 6e70 2e70 6929 2929 202b 2031 2920  / np.pi))) + 1) 
-00002d30: 2a2a 302e 310d 0a0d 0a20 2020 2020 2020  **0.1....       
-00002d40: 2079 5f6f 7574 203d 2079 5b3a 2c20 6e70   y_out = y[:, np
-00002d50: 2e6e 6577 6178 6973 5d0d 0a0d 0a20 2020  .newaxis]....   
-00002d60: 2020 2020 2072 6574 7572 6e20 795f 6f75       return y_ou
-00002d70: 740d 0a0d 0a0d 0a63 6c61 7373 2042 6f68  t......class Boh
-00002d80: 6163 6865 7673 6b79 4675 6e63 7469 6f6e  achevskyFunction
-00002d90: 3128 4162 7374 7261 6374 4d6f 6465 6c29  1(AbstractModel)
-00002da0: 3a0d 0a20 2020 2022 2222 0d0a 2020 2020  :..    """..    
-00002db0: 322d 6469 6d65 6e73 696f 6e61 6c20 6669  2-dimensional fi
-00002dc0: 7273 7420 426f 6861 6368 6576 736b 7920  rst Bohachevsky 
-00002dd0: 6675 6e63 7469 6f6e 205b 315d 5b32 5d2e  function [1][2].
-00002de0: 0d0a 2020 2020 5468 6520 426f 6861 6368  ..    The Bohach
-00002df0: 6576 736b 7920 6675 6e63 7469 6f6e 7320  evsky functions 
-00002e00: 616c 6c20 6861 7665 2074 6865 2073 616d  all have the sam
-00002e10: 6520 7369 6d69 6c61 7220 626f 776c 2073  e similar bowl s
-00002e20: 6861 7065 2e20 5468 6520 6f6e 6520 7368  hape. The one sh
-00002e30: 6f77 6e20 6162 6f76 6520 6973 2074 6865  own above is the
-00002e40: 2066 6972 7374 2066 756e 6374 696f 6e2e   first function.
-00002e50: 0d0a 0d0a 2020 2020 2e2e 206d 6174 683a  ....    .. math:
-00002e60: 3a0d 0a20 2020 2020 7920 3d20 785f 315e  :..     y = x_1^
-00002e70: 3220 2b20 3278 5f32 5e32 202d 2030 2e33  2 + 2x_2^2 - 0.3
-00002e80: 5c5c 636f 7328 335c 5c70 6920 785f 3129  \\cos(3\\pi x_1)
-00002e90: 202d 2030 2e34 5c5c 636f 7328 345c 5c70   - 0.4\\cos(4\\p
-00002ea0: 6920 785f 3229 202b 2030 2e37 0d0a 0d0a  i x_2) + 0.7....
-00002eb0: 2020 2020 5061 7261 6d65 7465 7273 0d0a      Parameters..
-00002ec0: 2020 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0d0a      ----------..
-00002ed0: 2020 2020 705b 2278 3122 5d3a 2066 6c6f      p["x1"]: flo
-00002ee0: 6174 206f 7220 6e64 6172 7261 7920 6f66  at or ndarray of
-00002ef0: 2066 6c6f 6174 205b 6e5f 6772 6964 5d0d   float [n_grid].
-00002f00: 0a20 2020 2020 2020 2046 6972 7374 2070  .        First p
-00002f10: 6172 616d 6574 6572 2064 6566 696e 6564  arameter defined
-00002f20: 2069 6e20 5b2d 3130 302c 2031 3030 5d0d   in [-100, 100].
-00002f30: 0a20 2020 2070 5b22 7832 225d 3a20 666c  .    p["x2"]: fl
-00002f40: 6f61 7420 6f72 206e 6461 7272 6179 206f  oat or ndarray o
-00002f50: 6620 666c 6f61 7420 5b6e 5f67 7269 645d  f float [n_grid]
-00002f60: 0d0a 2020 2020 2020 2020 7365 636f 6e64  ..        second
-00002f70: 2070 6172 616d 6574 6572 2064 6566 696e   parameter defin
-00002f80: 6564 2069 6e20 5b2d 3130 302c 2031 3030  ed in [-100, 100
-00002f90: 5d0d 0a20 2020 2070 5b22 7869 225d 3a20  ]..    p["xi"]: 
-00002fa0: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
-00002fb0: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
-00002fc0: 645d 0d0a 2020 2020 2020 2020 692d 7468  d]..        i-th
-00002fd0: 2070 6172 616d 6574 6572 2064 6566 696e   parameter defin
-00002fe0: 6564 2069 6e20 5b2d 3130 302c 2031 3030  ed in [-100, 100
-00002ff0: 5d0d 0a0d 0a20 2020 2052 6574 7572 6e73  ]....    Returns
-00003000: 0d0a 2020 2020 2d2d 2d2d 2d2d 2d0d 0a20  ..    -------.. 
-00003010: 2020 2079 3a20 6e64 6172 7261 7920 6f66     y: ndarray of
-00003020: 2066 6c6f 6174 205b 6e5f 6772 6964 2078   float [n_grid x
-00003030: 2031 5d0d 0a20 2020 2020 2020 204f 7574   1]..        Out
-00003040: 7075 740d 0a0d 0a20 2020 204e 6f74 6573  put....    Notes
-00003050: 0d0a 2020 2020 2d2d 2d2d 2d0d 0a20 2020  ..    -----..   
-00003060: 202e 2e20 706c 6f74 3a3a 0d0a 0d0a 2020   .. plot::....  
-00003070: 2020 2020 2069 6d70 6f72 7420 6e75 6d70       import nump
-00003080: 7920 6173 206e 700d 0a20 2020 2020 2020  y as np..       
-00003090: 6672 6f6d 2070 7967 7063 2e74 6573 7466  from pygpc.testf
-000030a0: 756e 6374 696f 6e73 2069 6d70 6f72 7420  unctions import 
-000030b0: 706c 6f74 5f74 6573 7466 756e 6374 696f  plot_testfunctio
-000030c0: 6e20 6173 2070 6c6f 740d 0a20 2020 2020  n as plot..     
-000030d0: 2020 6672 6f6d 2063 6f6c 6c65 6374 696f    from collectio
-000030e0: 6e73 2069 6d70 6f72 7420 4f72 6465 7265  ns import Ordere
-000030f0: 6444 6963 740d 0a0d 0a20 2020 2020 2020  dDict....       
-00003100: 7061 7261 6d65 7465 7273 203d 204f 7264  parameters = Ord
-00003110: 6572 6564 4469 6374 2829 0d0a 2020 2020  eredDict()..    
-00003120: 2020 2070 6172 616d 6574 6572 735b 2278     parameters["x
-00003130: 3122 5d20 3d20 6e70 2e6c 696e 7370 6163  1"] = np.linspac
-00003140: 6528 2d31 3030 2c20 3130 3020 2c20 3130  e(-100, 100 , 10
-00003150: 3029 0d0a 2020 2020 2020 2070 6172 616d  0)..       param
-00003160: 6574 6572 735b 2278 3222 5d20 3d20 6e70  eters["x2"] = np
-00003170: 2e6c 696e 7370 6163 6528 2d31 3030 2c20  .linspace(-100, 
-00003180: 3130 3020 2c20 3130 3029 0d0a 0d0a 2020  100 , 100)....  
-00003190: 2020 2020 2063 6f6e 7374 616e 7473 203d       constants =
-000031a0: 204e 6f6e 650d 0a0d 0a20 2020 2020 2020   None....       
-000031b0: 706c 6f74 2822 426f 6861 6368 6576 736b  plot("Bohachevsk
-000031c0: 7946 756e 6374 696f 6e31 222c 2070 6172  yFunction1", par
-000031d0: 616d 6574 6572 732c 2063 6f6e 7374 616e  ameters, constan
-000031e0: 7473 2c20 706c 6f74 5f33 643d 4661 6c73  ts, plot_3d=Fals
-000031f0: 6529 0d0a 0d0a 2020 2020 2e2e 205b 315d  e)....    .. [1]
-00003200: 2047 6c6f 6261 6c20 4f70 7469 6d69 7a61   Global Optimiza
-00003210: 7469 6f6e 2078 5f31 202a 2a32 202b 2032  tion x_1 **2 + 2
-00003220: 785f 3220 2a2a 3220 2d20 302e 3320 2a20  x_2 **2 - 0.3 * 
-00003230: 636f 7328 3370 6920 2a20 785f 3129 202d  cos(3pi * x_1) -
-00003240: 2030 2e34 202a 2063 6f73 2834 7069 202a   0.4 * cos(4pi *
-00003250: 2078 5f32 2920 2b20 302e 3720 5465 7374   x_2) + 0.7 Test
-00003260: 2050 726f 626c 656d 732e 0d0a 2020 2020   Problems...    
-00003270: 2020 2052 6574 7269 6576 6564 204a 756e     Retrieved Jun
-00003280: 6520 3230 3133 2c20 6672 6f6d 2068 7474  e 2013, from htt
-00003290: 703a 2f2f 7777 772d 6f70 7469 6d61 2e61  p://www-optima.a
-000032a0: 6d70 2e69 2e6b 796f 746f 2d75 2e61 632e  mp.i.kyoto-u.ac.
-000032b0: 6a70 2f6d 656d 6265 722f 7374 7564 656e  jp/member/studen
-000032c0: 742f 6865 6461 722f 4865 6461 725f 6669  t/hedar/Hedar_fi
-000032d0: 6c65 732f 5465 7374 474f 2e68 746d 2e0d  les/TestGO.htm..
-000032e0: 0a20 2020 202e 2e20 5b32 5d20 6874 7470  .    .. [2] http
-000032f0: 733a 2f2f 7777 772e 7366 752e 6361 2f7e  s://www.sfu.ca/~
-00003300: 7373 7572 6a61 6e6f 2f62 6f68 612e 6874  ssurjano/boha.ht
-00003310: 6d6c 0d0a 2020 2020 2222 220d 0a0d 0a20  ml..    """.... 
-00003320: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
-00003330: 7365 6c66 2c20 6d61 746c 6162 5f6d 6f64  self, matlab_mod
-00003340: 656c 3d46 616c 7365 293a 0d0a 2020 2020  el=False):..    
-00003350: 2020 2020 7375 7065 7228 7479 7065 2873      super(type(s
-00003360: 656c 6629 2c20 7365 6c66 292e 5f5f 696e  elf), self).__in
-00003370: 6974 5f5f 286d 6174 6c61 625f 6d6f 6465  it__(matlab_mode
-00003380: 6c3d 6d61 746c 6162 5f6d 6f64 656c 290d  l=matlab_model).
-00003390: 0a20 2020 2020 2020 2073 656c 662e 666e  .        self.fn
-000033a0: 616d 6520 3d20 696e 7370 6563 742e 6765  ame = inspect.ge
-000033b0: 7466 696c 6528 696e 7370 6563 742e 6375  tfile(inspect.cu
-000033c0: 7272 656e 7466 7261 6d65 2829 290d 0a0d  rrentframe())...
-000033d0: 0a20 2020 2064 6566 2076 616c 6964 6174  .    def validat
-000033e0: 6528 7365 6c66 293a 0d0a 2020 2020 2020  e(self):..      
-000033f0: 2020 7061 7373 0d0a 0d0a 2020 2020 6465    pass....    de
-00003400: 6620 7369 6d75 6c61 7465 2873 656c 662c  f simulate(self,
-00003410: 2070 726f 6365 7373 5f69 643d 4e6f 6e65   process_id=None
-00003420: 2c20 6d61 746c 6162 5f65 6e67 696e 653d  , matlab_engine=
-00003430: 4e6f 6e65 293a 0d0a 0d0a 2020 2020 2020  None):....      
-00003440: 2020 7920 3d20 2873 656c 662e 705b 2278    y = (self.p["x
-00003450: 3122 5d20 2a2a 3229 202b 2028 7365 6c66  1"] **2) + (self
-00003460: 2e70 5b22 7832 225d 202a 2a32 2920 2d20  .p["x2"] **2) - 
-00003470: 302e 3320 2a20 6e70 2e63 6f73 2833 202a  0.3 * np.cos(3 *
-00003480: 206e 702e 7069 202a 2073 656c 662e 705b   np.pi * self.p[
-00003490: 2278 3122 5d29 5c0d 0a20 2020 2020 2020  "x1"])\..       
-000034a0: 2020 2020 202d 2030 2e34 202a 206e 702e       - 0.4 * np.
-000034b0: 636f 7328 3420 2a20 6e70 2e70 6920 2a20  cos(4 * np.pi * 
-000034c0: 7365 6c66 2e70 5b22 7832 225d 2920 2b20  self.p["x2"]) + 
-000034d0: 302e 370d 0a0d 0a20 2020 2020 2020 2079  0.7....        y
-000034e0: 5f6f 7574 203d 2079 5b3a 2c20 6e70 2e6e  _out = y[:, np.n
-000034f0: 6577 6178 6973 5d0d 0a0d 0a20 2020 2020  ewaxis]....     
-00003500: 2020 2072 6574 7572 6e20 795f 6f75 740d     return y_out.
-00003510: 0a0d 0a0d 0a63 6c61 7373 2050 6572 6d46  .....class PermF
-00003520: 756e 6374 696f 6e28 4162 7374 7261 6374  unction(Abstract
-00003530: 4d6f 6465 6c29 3a0d 0a20 2020 2022 2222  Model):..    """
-00003540: 0d0a 2020 2020 642d 6469 6d65 6e73 696f  ..    d-dimensio
-00003550: 6e61 6c20 5065 726d 2066 756e 6374 696f  nal Perm functio
-00003560: 6e20 302c 2044 2c20 6220 2862 6574 6129  n 0, D, b (beta)
-00003570: 205b 315d 5b32 5d2e 2054 6865 2070 6172   [1][2]. The par
-00003580: 616d 6574 6572 2062 2028 6265 7461 2920  ameter b (beta) 
-00003590: 6973 206f 6674 656e 2061 7373 756d 6564  is often assumed
-000035a0: 2074 6f20 6265 2062 3d31 302e 0d0a 0d0a   to be b=10.....
-000035b0: 2020 2020 2e2e 206d 6174 683a 3a0d 0a20      .. math::.. 
-000035c0: 2020 2020 2079 203d 205c 5c73 756d 5f7b       y = \\sum_{
-000035d0: 693d 317d 5e7b 647d 5c5c 6c65 6674 285c  i=1}^{d}\\left(\
-000035e0: 5c73 756d 5f7b 6a3d 317d 5e7b 647d 286a  \sum_{j=1}^{d}(j
-000035f0: 202b 205c 5c62 6574 6129 5c5c 6c65 6674   + \\beta)\\left
-00003600: 2878 5f6a 5e69 2d5c 5c66 7261 637b 317d  (x_j^i-\\frac{1}
-00003610: 7b6a 5e69 7d5c 5c72 6967 6874 295c 5c72  {j^i}\\right)\\r
-00003620: 6967 6874 295e 320d 0a0d 0a20 2020 2050  ight)^2....    P
-00003630: 6172 616d 6574 6572 730d 0a20 2020 202d  arameters..    -
-00003640: 2d2d 2d2d 2d2d 2d2d 2d0d 0a20 2020 2070  ---------..    p
-00003650: 5b22 7831 225d 3a20 666c 6f61 7420 6f72  ["x1"]: float or
-00003660: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-00003670: 7420 5b6e 5f67 7269 645d 0d0a 2020 2020  t [n_grid]..    
-00003680: 2020 2020 4669 7273 7420 7061 7261 6d65      First parame
-00003690: 7465 7220 6465 6669 6e65 6420 696e 205b  ter defined in [
-000036a0: 2d64 2c20 645d 0d0a 2020 2020 705b 2278  -d, d]..    p["x
-000036b0: 6922 5d3a 2066 6c6f 6174 206f 7220 6e64  i"]: float or nd
-000036c0: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
-000036d0: 6e5f 6772 6964 5d0d 0a20 2020 2020 2020  n_grid]..       
-000036e0: 2069 2070 6172 616d 6574 6572 2064 6566   i parameter def
-000036f0: 696e 6564 2069 6e20 5b2d 642c 2064 5d0d  ined in [-d, d].
-00003700: 0a20 2020 2070 5b22 786a 225d 3a20 666c  .    p["xj"]: fl
-00003710: 6f61 7420 6f72 206e 6461 7272 6179 206f  oat or ndarray o
-00003720: 6620 666c 6f61 7420 5b6e 5f67 7269 645d  f float [n_grid]
-00003730: 0d0a 2020 2020 2020 2020 6a20 7061 7261  ..        j para
-00003740: 6d65 7465 7220 6465 6669 6e65 6420 696e  meter defined in
-00003750: 205b 2d64 2c20 645d 0d0a 0d0a 2020 2020   [-d, d]....    
-00003760: 5265 7475 726e 730d 0a20 2020 202d 2d2d  Returns..    ---
-00003770: 2d2d 2d2d 0d0a 2020 2020 793a 206e 6461  ----..    y: nda
-00003780: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
-00003790: 5f67 7269 6420 7820 315d 0d0a 2020 2020  _grid x 1]..    
-000037a0: 2020 2020 4f75 7470 7574 0d0a 0d0a 2020      Output....  
-000037b0: 2020 4e6f 7465 730d 0a20 2020 202d 2d2d    Notes..    ---
-000037c0: 2d2d 0d0a 2020 2020 2e2e 2070 6c6f 743a  --..    .. plot:
-000037d0: 3a0d 0a0d 0a20 2020 2020 2020 696d 706f  :....       impo
-000037e0: 7274 206e 756d 7079 2061 7320 6e70 0d0a  rt numpy as np..
-000037f0: 2020 2020 2020 2066 726f 6d20 7079 6770         from pygp
-00003800: 632e 7465 7374 6675 6e63 7469 6f6e 7320  c.testfunctions 
-00003810: 696d 706f 7274 2070 6c6f 745f 7465 7374  import plot_test
-00003820: 6675 6e63 7469 6f6e 2061 7320 706c 6f74  function as plot
-00003830: 0d0a 2020 2020 2020 2066 726f 6d20 636f  ..       from co
-00003840: 6c6c 6563 7469 6f6e 7320 696d 706f 7274  llections import
-00003850: 204f 7264 6572 6564 4469 6374 0d0a 0d0a   OrderedDict....
-00003860: 2020 2020 2020 2070 6172 616d 6574 6572         parameter
-00003870: 7320 3d20 4f72 6465 7265 6444 6963 7428  s = OrderedDict(
-00003880: 290d 0a20 2020 2020 2020 7061 7261 6d65  )..       parame
-00003890: 7465 7273 5b22 7831 225d 203d 206e 702e  ters["x1"] = np.
-000038a0: 6c69 6e73 7061 6365 282d 322c 2032 2c20  linspace(-2, 2, 
-000038b0: 3130 3029 0d0a 2020 2020 2020 2070 6172  100)..       par
-000038c0: 616d 6574 6572 735b 2278 3222 5d20 3d20  ameters["x2"] = 
-000038d0: 6e70 2e6c 696e 7370 6163 6528 2d32 2c20  np.linspace(-2, 
-000038e0: 322c 2031 3030 290d 0a0d 0a20 2020 2020  2, 100)....     
-000038f0: 2020 636f 6e73 7461 6e74 7320 3d20 4f72    constants = Or
-00003900: 6465 7265 6444 6963 7428 290d 0a20 2020  deredDict()..   
-00003910: 2020 2020 636f 6e73 7461 6e74 735b 2262      constants["b
-00003920: 225d 203d 2031 300d 0a0d 0a20 2020 2020  "] = 10....     
-00003930: 2020 706c 6f74 2822 5065 726d 4675 6e63    plot("PermFunc
-00003940: 7469 6f6e 222c 2070 6172 616d 6574 6572  tion", parameter
-00003950: 732c 2063 6f6e 7374 616e 7473 2c20 706c  s, constants, pl
-00003960: 6f74 5f33 643d 4661 6c73 6529 0d0a 0d0a  ot_3d=False)....
-00003970: 2020 2020 2e2e 205b 315d 2047 6c6f 6261      .. [1] Globa
-00003980: 6c20 4f70 7469 6d69 7a61 7469 6f6e 2054  l Optimization T
-00003990: 6573 7420 5072 6f62 6c65 6d73 2e20 5265  est Problems. Re
-000039a0: 7472 6965 7665 6420 4a75 6e65 2032 3031  trieved June 201
-000039b0: 332c 2066 726f 6d0d 0a20 2020 2020 2020  3, from..       
-000039c0: 6874 7470 3a2f 2f77 7777 2d6f 7074 696d  http://www-optim
-000039d0: 612e 616d 702e 692e 6b79 6f74 6f2d 752e  a.amp.i.kyoto-u.
-000039e0: 6163 2e6a 702f 6d65 6d62 6572 2f73 7475  ac.jp/member/stu
-000039f0: 6465 6e74 2f68 6564 6172 2f48 6564 6172  dent/hedar/Hedar
-00003a00: 5f66 696c 6573 2f54 6573 7447 4f2e 6874  _files/TestGO.ht
-00003a10: 6d2e 0d0a 2020 2020 2e2e 205b 325d 2068  m...    .. [2] h
-00003a20: 7474 7073 3a2f 2f77 7777 2e73 6675 2e63  ttps://www.sfu.c
-00003a30: 612f 7e73 7375 726a 616e 6f2f 7065 726d  a/~ssurjano/perm
-00003a40: 3064 622e 6874 6d6c 0d0a 2020 2020 2222  0db.html..    ""
-00003a50: 220d 0a0d 0a20 2020 2064 6566 205f 5f69  "....    def __i
-00003a60: 6e69 745f 5f28 7365 6c66 2c20 6d61 746c  nit__(self, matl
-00003a70: 6162 5f6d 6f64 656c 3d46 616c 7365 293a  ab_model=False):
-00003a80: 0d0a 2020 2020 2020 2020 7375 7065 7228  ..        super(
-00003a90: 7479 7065 2873 656c 6629 2c20 7365 6c66  type(self), self
-00003aa0: 292e 5f5f 696e 6974 5f5f 286d 6174 6c61  ).__init__(matla
-00003ab0: 625f 6d6f 6465 6c3d 6d61 746c 6162 5f6d  b_model=matlab_m
-00003ac0: 6f64 656c 290d 0a20 2020 2020 2020 2073  odel)..        s
-00003ad0: 656c 662e 666e 616d 6520 3d20 696e 7370  elf.fname = insp
-00003ae0: 6563 742e 6765 7466 696c 6528 696e 7370  ect.getfile(insp
-00003af0: 6563 742e 6375 7272 656e 7466 7261 6d65  ect.currentframe
-00003b00: 2829 290d 0a0d 0a20 2020 2064 6566 2076  ())....    def v
-00003b10: 616c 6964 6174 6528 7365 6c66 293a 0d0a  alidate(self):..
-00003b20: 2020 2020 2020 2020 7061 7373 0d0a 0d0a          pass....
-00003b30: 2020 2020 6465 6620 7369 6d75 6c61 7465      def simulate
-00003b40: 2873 656c 662c 2070 726f 6365 7373 5f69  (self, process_i
-00003b50: 643d 4e6f 6e65 2c20 6d61 746c 6162 5f65  d=None, matlab_e
-00003b60: 6e67 696e 653d 4e6f 6e65 293a 0d0a 0d0a  ngine=None):....
-00003b70: 2020 2020 2020 2020 666f 7220 692c 206b          for i, k
-00003b80: 6579 2069 6e20 656e 756d 6572 6174 6528  ey in enumerate(
-00003b90: 7365 6c66 2e70 2e6b 6579 7328 2929 3a0d  self.p.keys()):.
-00003ba0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-00003bb0: 7479 7065 2873 656c 662e 705b 6b65 795d  type(self.p[key]
-00003bc0: 2920 6973 206e 702e 6e64 6172 7261 793a  ) is np.ndarray:
-00003bd0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00003be0: 2020 7365 6c66 2e70 5b6b 6579 5d20 3d20    self.p[key] = 
-00003bf0: 7365 6c66 2e70 5b6b 6579 5d2e 666c 6174  self.p[key].flat
-00003c00: 7465 6e28 290d 0a0d 0a20 2020 2020 2020  ten()....       
-00003c10: 2023 2073 6574 2063 6f6e 7374 616e 7473   # set constants
-00003c20: 0d0a 2020 2020 2020 2020 7020 3d20 636f  ..        p = co
-00003c30: 7079 2e64 6565 7063 6f70 7928 7365 6c66  py.deepcopy(self
-00003c40: 2e70 290d 0a20 2020 2020 2020 2062 203d  .p)..        b =
-00003c50: 2073 656c 662e 705b 2262 225d 0d0a 2020   self.p["b"]..  
-00003c60: 2020 2020 2020 6465 6c20 705b 2262 225d        del p["b"]
-00003c70: 0d0a 0d0a 2020 2020 2020 2020 6e20 3d20  ....        n = 
-00003c80: 6c65 6e28 702e 6b65 7973 2829 290d 0a0d  len(p.keys())...
-00003c90: 0a20 2020 2020 2020 2023 2064 6574 6572  .        # deter
-00003ca0: 6d69 6e65 2073 756d 0d0a 2020 2020 2020  mine sum..      
-00003cb0: 2020 7920 3d20 6e70 2e7a 6572 6f73 286e    y = np.zeros(n
-00003cc0: 702e 6172 7261 7928 705b 6c69 7374 2870  p.array(p[list(p
-00003cd0: 2e6b 6579 7328 2929 5b30 5d5d 292e 7369  .keys())[0]]).si
-00003ce0: 7a65 290d 0a20 2020 2020 2020 2074 6d70  ze)..        tmp
-00003cf0: 203d 206e 702e 7a65 726f 7328 6e70 2e61   = np.zeros(np.a
-00003d00: 7272 6179 2870 5b6c 6973 7428 702e 6b65  rray(p[list(p.ke
-00003d10: 7973 2829 295b 305d 5d29 2e73 697a 6529  ys())[0]]).size)
-00003d20: 0d0a 0d0a 2020 2020 2020 2020 666f 7220  ....        for 
-00003d30: 692c 2069 5f6b 6579 2069 6e20 656e 756d  i, i_key in enum
-00003d40: 6572 6174 6528 702e 6b65 7973 2829 293a  erate(p.keys()):
-00003d50: 0d0a 2020 2020 2020 2020 2020 2020 666f  ..            fo
-00003d60: 7220 6a2c 206a 5f6b 6579 2069 6e20 656e  r j, j_key in en
-00003d70: 756d 6572 6174 6528 702e 6b65 7973 2829  umerate(p.keys()
-00003d80: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
-00003d90: 2020 2020 746d 7020 2b3d 2028 6a2b 312b      tmp += (j+1+
-00003da0: 6229 2a28 705b 6a5f 6b65 795d 2a2a 2869  b)*(p[j_key]**(i
-00003db0: 2b31 292d 312f 2828 6a2b 3129 2a2a 2869  +1)-1/((j+1)**(i
-00003dc0: 2b31 2929 290d 0a20 2020 2020 2020 2020  +1)))..         
-00003dd0: 2020 2079 202b 3d20 746d 702a 2a32 0d0a     y += tmp**2..
-00003de0: 2020 2020 2020 2020 2020 2020 746d 7020              tmp 
-00003df0: 3d20 6e70 2e7a 6572 6f73 286e 702e 6172  = np.zeros(np.ar
-00003e00: 7261 7928 705b 6c69 7374 2870 2e6b 6579  ray(p[list(p.key
-00003e10: 7328 2929 5b30 5d5d 292e 7369 7a65 290d  s())[0]]).size).
-00003e20: 0a0d 0a20 2020 2020 2020 2079 5f6f 7574  ...        y_out
-00003e30: 203d 2079 5b3a 2c20 6e70 2e6e 6577 6178   = y[:, np.newax
-00003e40: 6973 5d0d 0a0d 0a20 2020 2020 2020 2072  is]....        r
-00003e50: 6574 7572 6e20 795f 6f75 740d 0a0d 0a0d  eturn y_out.....
-00003e60: 0a63 6c61 7373 2053 6978 4875 6d70 4361  .class SixHumpCa
-00003e70: 6d65 6c46 756e 6374 696f 6e28 4162 7374  melFunction(Abst
-00003e80: 7261 6374 4d6f 6465 6c29 3a0d 0a20 2020  ractModel):..   
-00003e90: 2022 2222 0d0a 2020 2020 322d 6469 6d65   """..    2-dime
-00003ea0: 6e73 696f 6e61 6c20 5369 7820 2d20 4875  nsional Six - Hu
-00003eb0: 6d70 2043 616d 656c 2066 756e 6374 696f  mp Camel functio
-00003ec0: 6e20 5b31 5d5b 325d 2e0d 0a20 2020 2054  n [1][2]...    T
-00003ed0: 6865 2070 6c6f 7420 6f6e 2074 6865 206c  he plot on the l
-00003ee0: 6566 7420 7368 6f77 7320 7468 6520 7369  eft shows the si
-00003ef0: 782d 6875 6d70 2043 616d 656c 2066 756e  x-hump Camel fun
-00003f00: 6374 696f 6e20 6f6e 2069 7473 2072 6563  ction on its rec
-00003f10: 6f6d 6d65 6e64 6564 2069 6e70 7574 2064  ommended input d
-00003f20: 6f6d 6169 6e2c 0d0a 2020 2020 616e 6420  omain,..    and 
-00003f30: 7468 6520 706c 6f74 206f 6e20 7468 6520  the plot on the 
-00003f40: 7269 6768 7420 7368 6f77 7320 6f6e 6c79  right shows only
-00003f50: 2061 2070 6f72 7469 6f6e 206f 6620 7468   a portion of th
-00003f60: 6973 2064 6f6d 6169 6e2c 0d0a 2020 2020  is domain,..    
-00003f70: 746f 2061 6c6c 6f77 2066 6f72 2065 6173  to allow for eas
-00003f80: 6965 7220 7669 6577 696e 6720 6f66 2074  ier viewing of t
-00003f90: 6865 2066 756e 6374 696f 6e27 7320 6b65  he function's ke
-00003fa0: 7920 6368 6172 6163 7465 7269 7374 6963  y characteristic
-00003fb0: 732e 0d0a 2020 2020 5468 6520 6675 6e63  s...    The func
-00003fc0: 7469 6f6e 2068 6173 2073 6978 206c 6f63  tion has six loc
-00003fd0: 616c 206d 696e 696d 612c 2074 776f 206f  al minima, two o
-00003fe0: 6620 7768 6963 6820 6172 6520 676c 6f62  f which are glob
-00003ff0: 616c 2e0d 0a0d 0a20 2020 202e 2e20 6d61  al.....    .. ma
-00004000: 7468 3a3a 0d0a 2020 2020 2020 7920 3d20  th::..      y = 
-00004010: 5c5c 6c65 6674 2834 202d 2032 2e31 785f  \\left(4 - 2.1x_
-00004020: 315e 3220 2b20 5c5c 6672 6163 7b78 5f31  1^2 + \\frac{x_1
-00004030: 5e34 7d7b 337d 5c5c 7269 6768 7429 785f  ^4}{3}\\right)x_
-00004040: 315e 3220 2b20 785f 3178 5f32 202b 2028  1^2 + x_1x_2 + (
-00004050: 2d34 202b 2034 785f 325e 3229 785f 325e  -4 + 4x_2^2)x_2^
-00004060: 320d 0a0d 0a20 2020 2050 6172 616d 6574  2....    Paramet
-00004070: 6572 730d 0a20 2020 202d 2d2d 2d2d 2d2d  ers..    -------
-00004080: 2d2d 2d0d 0a20 2020 2070 5b22 7831 225d  ---..    p["x1"]
-00004090: 3a20 666c 6f61 7420 6f72 206e 6461 7272  : float or ndarr
-000040a0: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
-000040b0: 7269 645d 0d0a 2020 2020 2020 2020 4669  rid]..        Fi
-000040c0: 7273 7420 7061 7261 6d65 7465 7220 6465  rst parameter de
-000040d0: 6669 6e65 6420 696e 205b 2d33 2c20 335d  fined in [-3, 3]
-000040e0: 0d0a 2020 2020 705b 2278 3222 5d3a 2066  ..    p["x2"]: f
-000040f0: 6c6f 6174 206f 7220 6e64 6172 7261 7920  loat or ndarray 
-00004100: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
-00004110: 5d0d 0a20 2020 2020 2020 2073 6563 6f6e  ]..        secon
-00004120: 6420 7061 7261 6d65 7465 7220 6465 6669  d parameter defi
-00004130: 6e65 6420 696e 205b 2d32 2c20 325d 0d0a  ned in [-2, 2]..
-00004140: 0d0a 2020 2020 5265 7475 726e 730d 0a20  ..    Returns.. 
-00004150: 2020 202d 2d2d 2d2d 2d2d 0d0a 2020 2020     -------..    
-00004160: 793a 206e 6461 7272 6179 206f 6620 666c  y: ndarray of fl
-00004170: 6f61 7420 5b6e 5f67 7269 6420 7820 315d  oat [n_grid x 1]
-00004180: 0d0a 2020 2020 2020 2020 4f75 7470 7574  ..        Output
-00004190: 0d0a 0d0a 2020 2020 4e6f 7465 730d 0a20  ....    Notes.. 
-000041a0: 2020 202d 2d2d 2d2d 0d0a 2020 2020 2e2e     -----..    ..
-000041b0: 2070 6c6f 743a 3a0d 0a0d 0a20 2020 2020   plot::....     
-000041c0: 2020 696d 706f 7274 206e 756d 7079 2061    import numpy a
-000041d0: 7320 6e70 0d0a 2020 2020 2020 2066 726f  s np..       fro
-000041e0: 6d20 7079 6770 632e 7465 7374 6675 6e63  m pygpc.testfunc
-000041f0: 7469 6f6e 7320 696d 706f 7274 2070 6c6f  tions import plo
-00004200: 745f 7465 7374 6675 6e63 7469 6f6e 2061  t_testfunction a
-00004210: 7320 706c 6f74 0d0a 2020 2020 2020 2066  s plot..       f
-00004220: 726f 6d20 636f 6c6c 6563 7469 6f6e 7320  rom collections 
-00004230: 696d 706f 7274 204f 7264 6572 6564 4469  import OrderedDi
-00004240: 6374 0d0a 0d0a 2020 2020 2020 2070 6172  ct....       par
-00004250: 616d 6574 6572 7320 3d20 4f72 6465 7265  ameters = Ordere
-00004260: 6444 6963 7428 290d 0a20 2020 2020 2020  dDict()..       
-00004270: 7061 7261 6d65 7465 7273 5b22 7831 225d  parameters["x1"]
-00004280: 203d 206e 702e 6c69 6e73 7061 6365 282d   = np.linspace(-
-00004290: 332c 2033 202c 2031 3030 290d 0a20 2020  3, 3 , 100)..   
-000042a0: 2020 2020 7061 7261 6d65 7465 7273 5b22      parameters["
-000042b0: 7832 225d 203d 206e 702e 6c69 6e73 7061  x2"] = np.linspa
-000042c0: 6365 282d 322c 2032 202c 2031 3030 290d  ce(-2, 2 , 100).
-000042d0: 0a0d 0a20 2020 2020 2020 636f 6e73 7461  ...       consta
-000042e0: 6e74 7320 3d20 4e6f 6e65 0d0a 0d0a 2020  nts = None....  
-000042f0: 2020 2020 2070 6c6f 7428 2253 6978 4875       plot("SixHu
-00004300: 6d70 4361 6d65 6c46 756e 6374 696f 6e22  mpCamelFunction"
-00004310: 2c20 7061 7261 6d65 7465 7273 2c20 636f  , parameters, co
-00004320: 6e73 7461 6e74 732c 2070 6c6f 745f 3364  nstants, plot_3d
-00004330: 3d46 616c 7365 290d 0a0d 0a20 2020 202e  =False)....    .
-00004340: 2e20 5b31 5d20 4d6f 6c67 612c 204d 2e2c  . [1] Molga, M.,
-00004350: 2026 2053 6d75 746e 6963 6b69 2c20 432e   & Smutnicki, C.
-00004360: 2054 6573 7420 6675 6e63 7469 6f6e 7320   Test functions 
-00004370: 666f 7220 6f70 7469 6d69 7a61 7469 6f6e  for optimization
-00004380: 206e 6565 6473 2028 3230 3035 292e 2052   needs (2005). R
-00004390: 6574 7269 6576 6564 204a 756e 6520 3230  etrieved June 20
-000043a0: 3133 2c20 6672 6f6d 0d0a 2020 2020 2020  13, from..      
-000043b0: 2068 7474 703a 2f2f 7777 772e 7a73 642e   http://www.zsd.
-000043c0: 6963 742e 7077 722e 7772 6f63 2e70 6c2f  ict.pwr.wroc.pl/
-000043d0: 6669 6c65 732f 646f 6373 2f66 756e 6374  files/docs/funct
-000043e0: 696f 6e73 2e70 6466 2e0d 0a20 2020 202e  ions.pdf...    .
-000043f0: 2e20 5b32 5d20 6874 7470 733a 2f2f 7777  . [2] https://ww
-00004400: 772e 7366 752e 6361 2f7e 7373 7572 6a61  w.sfu.ca/~ssurja
-00004410: 6e6f 2f63 616d 656c 362e 6874 6d6c 0d0a  no/camel6.html..
-00004420: 2020 2020 2222 220d 0a0d 0a20 2020 2064      """....    d
-00004430: 6566 205f 5f69 6e69 745f 5f28 7365 6c66  ef __init__(self
-00004440: 2c20 6d61 746c 6162 5f6d 6f64 656c 3d46  , matlab_model=F
-00004450: 616c 7365 293a 0d0a 2020 2020 2020 2020  alse):..        
-00004460: 7375 7065 7228 7479 7065 2873 656c 6629  super(type(self)
-00004470: 2c20 7365 6c66 292e 5f5f 696e 6974 5f5f  , self).__init__
-00004480: 286d 6174 6c61 625f 6d6f 6465 6c3d 6d61  (matlab_model=ma
-00004490: 746c 6162 5f6d 6f64 656c 290d 0a20 2020  tlab_model)..   
-000044a0: 2020 2020 2073 656c 662e 666e 616d 6520       self.fname 
-000044b0: 3d20 696e 7370 6563 742e 6765 7466 696c  = inspect.getfil
-000044c0: 6528 696e 7370 6563 742e 6375 7272 656e  e(inspect.curren
-000044d0: 7466 7261 6d65 2829 290d 0a0d 0a20 2020  tframe())....   
-000044e0: 2064 6566 2076 616c 6964 6174 6528 7365   def validate(se
-000044f0: 6c66 293a 0d0a 2020 2020 2020 2020 7061  lf):..        pa
-00004500: 7373 0d0a 0d0a 2020 2020 6465 6620 7369  ss....    def si
-00004510: 6d75 6c61 7465 2873 656c 662c 2070 726f  mulate(self, pro
-00004520: 6365 7373 5f69 643d 4e6f 6e65 2c20 6d61  cess_id=None, ma
-00004530: 746c 6162 5f65 6e67 696e 653d 4e6f 6e65  tlab_engine=None
-00004540: 293a 0d0a 0d0a 2020 2020 2020 2020 7920  ):....        y 
-00004550: 3d20 2834 202d 2032 2e31 2a28 7365 6c66  = (4 - 2.1*(self
-00004560: 2e70 5b22 7831 225d 202a 2a32 2920 2b20  .p["x1"] **2) + 
-00004570: 2873 656c 662e 705b 2278 3122 5d20 2a2a  (self.p["x1"] **
-00004580: 3429 2f33 2920 2a20 2873 656c 662e 705b  4)/3) * (self.p[
-00004590: 2278 3122 5d20 2a2a 3229 202b 2073 656c  "x1"] **2) + sel
-000045a0: 662e 705b 2278 3122 5d20 2a20 7365 6c66  f.p["x1"] * self
-000045b0: 2e70 5b22 7832 225d 202b 205c 0d0a 2020  .p["x2"] + \..  
-000045c0: 2020 2020 2020 2020 2020 282d 3420 2b20            (-4 + 
-000045d0: 3420 2a20 2873 656c 662e 705b 2278 3222  4 * (self.p["x2"
-000045e0: 5d20 2a2a 3229 2920 2a20 2873 656c 662e  ] **2)) * (self.
-000045f0: 705b 2278 3222 5d20 2a2a 3229 0d0a 0d0a  p["x2"] **2)....
-00004600: 2020 2020 2020 2020 795f 6f75 7420 3d20          y_out = 
-00004610: 795b 3a2c 206e 702e 6e65 7761 7869 735d  y[:, np.newaxis]
-00004620: 0d0a 0d0a 2020 2020 2020 2020 7265 7475  ....        retu
-00004630: 726e 2079 5f6f 7574 0d0a 0d0a 0d0a 636c  rn y_out......cl
-00004640: 6173 7320 526f 7461 7465 6448 7970 6572  ass RotatedHyper
-00004650: 456c 6c69 7073 6f69 6428 4162 7374 7261  Ellipsoid(Abstra
-00004660: 6374 4d6f 6465 6c29 3a0d 0a20 2020 2022  ctModel):..    "
-00004670: 2222 0d0a 2020 2020 642d 6469 6d65 6e73  ""..    d-dimens
-00004680: 696f 6e61 6c20 526f 7461 7465 642d 4879  ional Rotated-Hy
-00004690: 7065 7220 456c 6c69 7073 6f69 6420 4675  per Ellipsoid Fu
-000046a0: 6e63 7469 6f6e 205b 315d 5b32 5d2e 0d0a  nction [1][2]...
-000046b0: 2020 2020 5468 6520 526f 7461 7465 6420      The Rotated 
-000046c0: 4879 7065 722d 456c 6c69 7073 6f69 6420  Hyper-Ellipsoid 
-000046d0: 6675 6e63 7469 6f6e 2069 7320 636f 6e74  function is cont
-000046e0: 696e 756f 7573 2c20 636f 6e76 6578 2061  inuous, convex a
-000046f0: 6e64 2075 6e69 6d6f 6461 6c2e 0d0a 2020  nd unimodal...  
-00004700: 2020 4974 2069 7320 616e 2065 7874 656e    It is an exten
-00004710: 7369 6f6e 206f 6620 7468 6520 4178 6973  sion of the Axis
-00004720: 2050 6172 616c 6c65 6c20 4879 7065 722d   Parallel Hyper-
-00004730: 456c 6c69 7073 6f69 6420 6675 6e63 7469  Ellipsoid functi
-00004740: 6f6e 2c20 616c 736f 2072 6566 6572 7265  on, also referre
-00004750: 6420 746f 2061 7320 7468 6520 5375 6d20  d to as the Sum 
-00004760: 5371 7561 7265 7320 6675 6e63 7469 6f6e  Squares function
-00004770: 2e0d 0a20 2020 2054 6865 2070 6c6f 7420  ...    The plot 
-00004780: 7368 6f77 7320 6974 7320 7477 6f2d 6469  shows its two-di
-00004790: 6d65 6e73 696f 6e61 6c20 666f 726d 2e0d  mensional form..
-000047a0: 0a0d 0a20 2020 202e 2e20 6d61 7468 3a3a  ...    .. math::
-000047b0: 0d0a 2020 2020 2020 2079 203d 205c 5c73  ..       y = \\s
-000047c0: 756d 5f7b 693d 317d 5e7b 647d 5c5c 7375  um_{i=1}^{d}\\su
-000047d0: 6d5f 7b6a 3d31 7d5e 7b69 7d5c 5c2a 2078  m_{j=1}^{i}\\* x
-000047e0: 5f6a 5e32 0d0a 0d0a 2020 2020 5061 7261  _j^2....    Para
-000047f0: 6d65 7465 7273 0d0a 2020 2020 2d2d 2d2d  meters..    ----
-00004800: 2d2d 2d2d 2d2d 0d0a 2020 2020 705b 2278  ------..    p["x
-00004810: 6922 5d3a 2066 6c6f 6174 206f 7220 6e64  i"]: float or nd
-00004820: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
-00004830: 6e5f 6772 6964 5d0d 0a20 2020 2020 2020  n_grid]..       
-00004840: 2069 2070 6172 616d 6574 6572 2064 6566   i parameter def
-00004850: 696e 6564 2069 6e20 5b2d 3635 2e35 3336  ined in [-65.536
-00004860: 2c20 3635 2e35 3336 5d0d 0a20 2020 2070  , 65.536]..    p
-00004870: 5b22 786a 225d 3a20 666c 6f61 7420 6f72  ["xj"]: float or
-00004880: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-00004890: 7420 5b6e 5f67 7269 645d 0d0a 2020 2020  t [n_grid]..    
-000048a0: 2020 2020 6a20 7061 7261 6d65 7465 7220      j parameter 
-000048b0: 6465 6669 6e65 6420 696e 205b 2d36 352e  defined in [-65.
-000048c0: 3533 362c 2036 352e 3533 365d 0d0a 0d0a  536, 65.536]....
-000048d0: 2020 2020 5265 7475 726e 730d 0a20 2020      Returns..   
-000048e0: 202d 2d2d 2d2d 2d2d 0d0a 2020 2020 793a   -------..    y:
-000048f0: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-00004900: 7420 5b6e 5f67 7269 6420 7820 315d 0d0a  t [n_grid x 1]..
-00004910: 2020 2020 2020 2020 4f75 7470 7574 0d0a          Output..
-00004920: 0d0a 2020 2020 4e6f 7465 730d 0a20 2020  ..    Notes..   
-00004930: 202d 2d2d 2d2d 0d0a 2020 2020 2e2e 2070   -----..    .. p
-00004940: 6c6f 743a 3a0d 0a0d 0a20 2020 2020 2020  lot::....       
-00004950: 696d 706f 7274 206e 756d 7079 2061 7320  import numpy as 
-00004960: 6e70 0d0a 2020 2020 2020 2066 726f 6d20  np..       from 
-00004970: 7079 6770 632e 7465 7374 6675 6e63 7469  pygpc.testfuncti
-00004980: 6f6e 7320 696d 706f 7274 2070 6c6f 745f  ons import plot_
-00004990: 7465 7374 6675 6e63 7469 6f6e 2061 7320  testfunction as 
-000049a0: 706c 6f74 0d0a 2020 2020 2020 2066 726f  plot..       fro
-000049b0: 6d20 636f 6c6c 6563 7469 6f6e 7320 696d  m collections im
-000049c0: 706f 7274 204f 7264 6572 6564 4469 6374  port OrderedDict
-000049d0: 0d0a 0d0a 2020 2020 2020 2070 6172 616d  ....       param
-000049e0: 6574 6572 7320 3d20 4f72 6465 7265 6444  eters = OrderedD
-000049f0: 6963 7428 290d 0a20 2020 2020 2020 7061  ict()..       pa
-00004a00: 7261 6d65 7465 7273 5b22 7831 225d 203d  rameters["x1"] =
-00004a10: 206e 702e 6c69 6e73 7061 6365 282d 3635   np.linspace(-65
-00004a20: 2e35 3336 2c20 3635 2e35 3336 2c20 3130  .536, 65.536, 10
-00004a30: 3029 0d0a 2020 2020 2020 2070 6172 616d  0)..       param
-00004a40: 6574 6572 735b 2278 3222 5d20 3d20 6e70  eters["x2"] = np
-00004a50: 2e6c 696e 7370 6163 6528 2d36 352e 3533  .linspace(-65.53
-00004a60: 362c 2036 352e 3533 362c 2031 3030 290d  6, 65.536, 100).
-00004a70: 0a0d 0a20 2020 2020 2020 636f 6e73 7461  ...       consta
-00004a80: 6e74 7320 3d20 4e6f 6e65 0d0a 0d0a 2020  nts = None....  
-00004a90: 2020 2020 2070 6c6f 7428 2252 6f74 6174       plot("Rotat
-00004aa0: 6564 4879 7065 7245 6c6c 6970 736f 6964  edHyperEllipsoid
-00004ab0: 222c 2070 6172 616d 6574 6572 732c 2063  ", parameters, c
-00004ac0: 6f6e 7374 616e 7473 2c20 706c 6f74 5f33  onstants, plot_3
-00004ad0: 643d 4661 6c73 6529 0d0a 0d0a 2020 2020  d=False)....    
-00004ae0: 2e2e 205b 315d 204d 6f6c 6761 2c20 4d2e  .. [1] Molga, M.
-00004af0: 2c20 2620 536d 7574 6e69 636b 692c 2043  , & Smutnicki, C
-00004b00: 2e20 5465 7374 2066 756e 6374 696f 6e73  . Test functions
-00004b10: 2066 6f72 206f 7074 696d 697a 6174 696f   for optimizatio
-00004b20: 6e20 6e65 6564 7320 2832 3030 3529 2e0d  n needs (2005)..
-00004b30: 0a20 2020 2020 2020 5265 7472 6965 7665  .       Retrieve
-00004b40: 6420 4a75 6e65 2032 3031 332c 2066 726f  d June 2013, fro
-00004b50: 6d20 6874 7470 3a2f 2f77 7777 2e7a 7364  m http://www.zsd
-00004b60: 2e69 6374 2e70 7772 2e77 726f 632e 706c  .ict.pwr.wroc.pl
-00004b70: 2f66 696c 6573 2f64 6f63 732f 6675 6e63  /files/docs/func
-00004b80: 7469 6f6e 732e 7064 662e 0d0a 2020 2020  tions.pdf...    
-00004b90: 2e2e 205b 325d 2068 7474 7073 3a2f 2f77  .. [2] https://w
-00004ba0: 7777 2e73 6675 2e63 612f 7e73 7375 726a  ww.sfu.ca/~ssurj
-00004bb0: 616e 6f2f 726f 7468 7970 2e68 746d 6c0d  ano/rothyp.html.
-00004bc0: 0a20 2020 2022 2222 0d0a 0d0a 2020 2020  .    """....    
-00004bd0: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
-00004be0: 662c 206d 6174 6c61 625f 6d6f 6465 6c3d  f, matlab_model=
-00004bf0: 4661 6c73 6529 3a0d 0a20 2020 2020 2020  False):..       
-00004c00: 2073 7570 6572 2874 7970 6528 7365 6c66   super(type(self
-00004c10: 292c 2073 656c 6629 2e5f 5f69 6e69 745f  ), self).__init_
-00004c20: 5f28 6d61 746c 6162 5f6d 6f64 656c 3d6d  _(matlab_model=m
-00004c30: 6174 6c61 625f 6d6f 6465 6c29 0d0a 2020  atlab_model)..  
-00004c40: 2020 2020 2020 7365 6c66 2e66 6e61 6d65        self.fname
-00004c50: 203d 2069 6e73 7065 6374 2e67 6574 6669   = inspect.getfi
-00004c60: 6c65 2869 6e73 7065 6374 2e63 7572 7265  le(inspect.curre
-00004c70: 6e74 6672 616d 6528 2929 0d0a 0d0a 2020  ntframe())....  
-00004c80: 2020 6465 6620 7661 6c69 6461 7465 2873    def validate(s
-00004c90: 656c 6629 3a0d 0a20 2020 2020 2020 2070  elf):..        p
-00004ca0: 6173 730d 0a0d 0a20 2020 2064 6566 2073  ass....    def s
-00004cb0: 696d 756c 6174 6528 7365 6c66 2c20 7072  imulate(self, pr
-00004cc0: 6f63 6573 735f 6964 3d4e 6f6e 652c 206d  ocess_id=None, m
-00004cd0: 6174 6c61 625f 656e 6769 6e65 3d4e 6f6e  atlab_engine=Non
-00004ce0: 6529 3a0d 0a0d 0a20 2020 2020 2020 2066  e):....        f
-00004cf0: 6f72 2069 2c20 6b65 7920 696e 2065 6e75  or i, key in enu
-00004d00: 6d65 7261 7465 2873 656c 662e 702e 6b65  merate(self.p.ke
-00004d10: 7973 2829 293a 0d0a 2020 2020 2020 2020  ys()):..        
-00004d20: 2020 2020 6966 2074 7970 6528 7365 6c66      if type(self
-00004d30: 2e70 5b6b 6579 5d29 2069 7320 6e70 2e6e  .p[key]) is np.n
-00004d40: 6461 7272 6179 3a0d 0a20 2020 2020 2020  darray:..       
-00004d50: 2020 2020 2020 2020 2073 656c 662e 705b           self.p[
-00004d60: 6b65 795d 203d 2073 656c 662e 705b 6b65  key] = self.p[ke
-00004d70: 795d 2e66 6c61 7474 656e 2829 0d0a 0d0a  y].flatten()....
-00004d80: 2020 2020 2020 2020 2320 6465 7465 726d          # determ
-00004d90: 696e 6520 7375 6d0d 0a20 2020 2020 2020  ine sum..       
-00004da0: 2079 203d 206e 702e 7a65 726f 7328 6e70   y = np.zeros(np
-00004db0: 2e61 7272 6179 2873 656c 662e 705b 6c69  .array(self.p[li
-00004dc0: 7374 2873 656c 662e 702e 6b65 7973 2829  st(self.p.keys()
-00004dd0: 295b 305d 5d29 2e73 697a 6529 0d0a 2020  )[0]]).size)..  
-00004de0: 2020 2020 2020 6b65 7973 203d 206c 6973        keys = lis
-00004df0: 7428 7365 6c66 2e70 2e6b 6579 7328 2929  t(self.p.keys())
-00004e00: 0d0a 0d0a 2020 2020 2020 2020 666f 7220  ....        for 
-00004e10: 692c 2069 5f6b 6579 2069 6e20 656e 756d  i, i_key in enum
-00004e20: 6572 6174 6528 6b65 7973 293a 0d0a 2020  erate(keys):..  
-00004e30: 2020 2020 2020 2020 2020 666f 7220 6a2c            for j,
-00004e40: 206a 5f6b 6579 2069 6e20 656e 756d 6572   j_key in enumer
-00004e50: 6174 6528 6b65 7973 5b30 3a69 2b31 5d29  ate(keys[0:i+1])
-00004e60: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-00004e70: 2020 7920 2b3d 2073 656c 662e 705b 6a5f    y += self.p[j_
-00004e80: 6b65 795d 2a2a 320d 0a0d 0a20 2020 2020  key]**2....     
-00004e90: 2020 2079 5f6f 7574 203d 2079 5b3a 2c20     y_out = y[:, 
-00004ea0: 6e70 2e6e 6577 6178 6973 5d0d 0a0d 0a20  np.newaxis].... 
-00004eb0: 2020 2020 2020 2072 6574 7572 6e20 795f         return y_
-00004ec0: 6f75 740d 0a0d 0a0d 0a63 6c61 7373 2053  out......class S
-00004ed0: 756d 4f66 4469 6666 6572 656e 7450 6f77  umOfDifferentPow
-00004ee0: 6572 7346 756e 6374 696f 6e28 4162 7374  ersFunction(Abst
-00004ef0: 7261 6374 4d6f 6465 6c29 3a0d 0a20 2020  ractModel):..   
-00004f00: 2022 2222 0d0a 2020 2020 642d 6469 6d65   """..    d-dime
-00004f10: 6e73 696f 6e61 6c20 5375 6d20 4f66 2044  nsional Sum Of D
-00004f20: 6966 6665 7265 6e74 2050 6f77 6572 7320  ifferent Powers 
-00004f30: 4675 6e63 7469 6f6e 205b 315d 5b32 5d2e  Function [1][2].
-00004f40: 0d0a 2020 2020 5468 6520 5375 6d20 6f66  ..    The Sum of
-00004f50: 2044 6966 6665 7265 6e74 2050 6f77 6572   Different Power
-00004f60: 7320 6675 6e63 7469 6f6e 2069 7320 756e  s function is un
-00004f70: 696d 6f64 616c 2e20 4974 2069 7320 7368  imodal. It is sh
-00004f80: 6f77 6e20 6865 7265 2069 6e20 6974 7320  own here in its 
-00004f90: 7477 6f2d 6469 6d65 6e73 696f 6e61 6c20  two-dimensional 
-00004fa0: 666f 726d 2e0d 0a0d 0a20 2020 202e 2e20  form.....    .. 
-00004fb0: 6d61 7468 3a3a 0d0a 2020 2020 2020 2020  math::..        
-00004fc0: 2079 203d 205c 5c73 756d 5f7b 693d 317d   y = \\sum_{i=1}
-00004fd0: 5e7b 647d 5c5c 6d69 6420 785f 6920 5c5c  ^{d}\\mid x_i \\
-00004fe0: 6d69 6420 5e7b 692b 317d 0d0a 0d0a 2020  mid ^{i+1}....  
-00004ff0: 2020 5061 7261 6d65 7465 7273 0d0a 2020    Parameters..  
-00005000: 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0d0a 2020    ----------..  
-00005010: 2020 705b 2278 3122 5d3a 2066 6c6f 6174    p["x1"]: float
-00005020: 206f 7220 6e64 6172 7261 7920 6f66 2066   or ndarray of f
-00005030: 6c6f 6174 205b 6e5f 6772 6964 5d0d 0a20  loat [n_grid].. 
-00005040: 2020 2020 2020 2046 6972 7374 2070 6172         First par
-00005050: 616d 6574 6572 2064 6566 696e 6564 2069  ameter defined i
-00005060: 6e20 5b2d 312c 2031 5d0d 0a20 2020 2070  n [-1, 1]..    p
-00005070: 5b22 786a 225d 3a20 666c 6f61 7420 6f72  ["xj"]: float or
-00005080: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-00005090: 7420 5b6e 5f67 7269 645d 0d0a 2020 2020  t [n_grid]..    
-000050a0: 2020 2020 6a2d 7468 2070 6172 616d 6574      j-th paramet
-000050b0: 6572 2064 6566 696e 6564 2069 6e20 5b2d  er defined in [-
-000050c0: 312c 2031 5d0d 0a0d 0a20 2020 2052 6574  1, 1]....    Ret
-000050d0: 7572 6e73 0d0a 2020 2020 2d2d 2d2d 2d2d  urns..    ------
-000050e0: 2d0d 0a20 2020 2079 3a20 6e64 6172 7261  -..    y: ndarra
-000050f0: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
-00005100: 6964 2078 2031 5d0d 0a20 2020 2020 2020  id x 1]..       
-00005110: 204f 7574 7075 740d 0a0d 0a20 2020 204e   Output....    N
-00005120: 6f74 6573 0d0a 2020 2020 2d2d 2d2d 2d0d  otes..    -----.
-00005130: 0a20 2020 202e 2e20 706c 6f74 3a3a 0d0a  .    .. plot::..
-00005140: 0d0a 2020 2020 2020 2069 6d70 6f72 7420  ..       import 
-00005150: 6e75 6d70 7920 6173 206e 700d 0a20 2020  numpy as np..   
-00005160: 2020 2020 6672 6f6d 2070 7967 7063 2e74      from pygpc.t
-00005170: 6573 7466 756e 6374 696f 6e73 2069 6d70  estfunctions imp
-00005180: 6f72 7420 706c 6f74 5f74 6573 7466 756e  ort plot_testfun
-00005190: 6374 696f 6e20 6173 2070 6c6f 740d 0a20  ction as plot.. 
-000051a0: 2020 2020 2020 6672 6f6d 2063 6f6c 6c65        from colle
-000051b0: 6374 696f 6e73 2069 6d70 6f72 7420 4f72  ctions import Or
-000051c0: 6465 7265 6444 6963 740d 0a0d 0a20 2020  deredDict....   
-000051d0: 2020 2020 7061 7261 6d65 7465 7273 203d      parameters =
-000051e0: 204f 7264 6572 6564 4469 6374 2829 0d0a   OrderedDict()..
-000051f0: 2020 2020 2020 2070 6172 616d 6574 6572         parameter
-00005200: 735b 2278 3122 5d20 3d20 6e70 2e6c 696e  s["x1"] = np.lin
-00005210: 7370 6163 6528 2d31 2c20 312c 2031 3030  space(-1, 1, 100
-00005220: 290d 0a20 2020 2020 2020 7061 7261 6d65  )..       parame
-00005230: 7465 7273 5b22 7832 225d 203d 206e 702e  ters["x2"] = np.
-00005240: 6c69 6e73 7061 6365 282d 312c 2031 2c20  linspace(-1, 1, 
-00005250: 3130 3029 0d0a 0d0a 2020 2020 2020 2063  100)....       c
-00005260: 6f6e 7374 616e 7473 203d 204e 6f6e 650d  onstants = None.
-00005270: 0a0d 0a20 2020 2020 2020 706c 6f74 2822  ...       plot("
-00005280: 5375 6d4f 6644 6966 6665 7265 6e74 506f  SumOfDifferentPo
-00005290: 7765 7273 4675 6e63 7469 6f6e 222c 2070  wersFunction", p
-000052a0: 6172 616d 6574 6572 732c 2063 6f6e 7374  arameters, const
-000052b0: 616e 7473 2c20 706c 6f74 5f33 643d 4661  ants, plot_3d=Fa
-000052c0: 6c73 6529 0d0a 0d0a 2020 2020 2e2e 205b  lse)....    .. [
-000052d0: 315d 204d 6f6c 6761 2c20 4d2e 2c20 2620  1] Molga, M., & 
-000052e0: 536d 7574 6e69 636b 692c 2043 2e20 5465  Smutnicki, C. Te
-000052f0: 7374 2066 756e 6374 696f 6e73 2066 6f72  st functions for
-00005300: 206f 7074 696d 697a 6174 696f 6e20 6e65   optimization ne
-00005310: 6564 7320 2832 3030 3529 2e0d 0a20 2020  eds (2005)...   
-00005320: 2020 2020 5265 7472 6965 7665 6420 4a75      Retrieved Ju
-00005330: 6e65 2032 3031 332c 2066 726f 6d20 6874  ne 2013, from ht
-00005340: 7470 3a2f 2f77 7777 2e7a 7364 2e69 6374  tp://www.zsd.ict
-00005350: 2e70 7772 2e77 726f 632e 706c 2f66 696c  .pwr.wroc.pl/fil
-00005360: 6573 2f64 6f63 732f 6675 6e63 7469 6f6e  es/docs/function
-00005370: 732e 7064 662e 0d0a 2020 2020 2e2e 205b  s.pdf...    .. [
-00005380: 325d 2068 7474 7073 3a2f 2f77 7777 2e73  2] https://www.s
-00005390: 6675 2e63 612f 7e73 7375 726a 616e 6f2f  fu.ca/~ssurjano/
-000053a0: 7375 6d70 6f77 2e68 746d 6c0d 0a20 2020  sumpow.html..   
-000053b0: 2022 2222 0d0a 0d0a 2020 2020 6465 6620   """....    def 
-000053c0: 5f5f 696e 6974 5f5f 2873 656c 662c 206d  __init__(self, m
-000053d0: 6174 6c61 625f 6d6f 6465 6c3d 4661 6c73  atlab_model=Fals
-000053e0: 6529 3a0d 0a20 2020 2020 2020 2073 7570  e):..        sup
-000053f0: 6572 2874 7970 6528 7365 6c66 292c 2073  er(type(self), s
-00005400: 656c 6629 2e5f 5f69 6e69 745f 5f28 6d61  elf).__init__(ma
-00005410: 746c 6162 5f6d 6f64 656c 3d6d 6174 6c61  tlab_model=matla
-00005420: 625f 6d6f 6465 6c29 0d0a 2020 2020 2020  b_model)..      
-00005430: 2020 7365 6c66 2e66 6e61 6d65 203d 2069    self.fname = i
-00005440: 6e73 7065 6374 2e67 6574 6669 6c65 2869  nspect.getfile(i
-00005450: 6e73 7065 6374 2e63 7572 7265 6e74 6672  nspect.currentfr
-00005460: 616d 6528 2929 0d0a 0d0a 2020 2020 6465  ame())....    de
-00005470: 6620 7661 6c69 6461 7465 2873 656c 6629  f validate(self)
-00005480: 3a0d 0a20 2020 2020 2020 2070 6173 730d  :..        pass.
-00005490: 0a0d 0a20 2020 2064 6566 2073 696d 756c  ...    def simul
-000054a0: 6174 6528 7365 6c66 2c20 7072 6f63 6573  ate(self, proces
-000054b0: 735f 6964 3d4e 6f6e 652c 206d 6174 6c61  s_id=None, matla
-000054c0: 625f 656e 6769 6e65 3d4e 6f6e 6529 3a0d  b_engine=None):.
-000054d0: 0a0d 0a20 2020 2020 2020 2066 6f72 2069  ...        for i
-000054e0: 2c20 6b65 7920 696e 2065 6e75 6d65 7261  , key in enumera
-000054f0: 7465 2873 656c 662e 702e 6b65 7973 2829  te(self.p.keys()
-00005500: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
-00005510: 6966 2074 7970 6528 7365 6c66 2e70 5b6b  if type(self.p[k
-00005520: 6579 5d29 2069 7320 6e70 2e6e 6461 7272  ey]) is np.ndarr
-00005530: 6179 3a0d 0a20 2020 2020 2020 2020 2020  ay:..           
-00005540: 2020 2020 2073 656c 662e 705b 6b65 795d       self.p[key]
-00005550: 203d 2073 656c 662e 705b 6b65 795d 2e66   = self.p[key].f
-00005560: 6c61 7474 656e 2829 0d0a 0d0a 2020 2020  latten()....    
-00005570: 2020 2020 2320 6465 7465 726d 696e 6520      # determine 
-00005580: 7375 6d0d 0a20 2020 2020 2020 2079 203d  sum..        y =
-00005590: 206e 702e 7a65 726f 7328 6e70 2e61 7272   np.zeros(np.arr
-000055a0: 6179 2873 656c 662e 705b 6c69 7374 2873  ay(self.p[list(s
-000055b0: 656c 662e 702e 6b65 7973 2829 295b 305d  elf.p.keys())[0]
-000055c0: 5d29 2e73 697a 6529 0d0a 2020 2020 2020  ]).size)..      
-000055d0: 2020 6b65 7973 203d 206c 6973 7428 7365    keys = list(se
-000055e0: 6c66 2e70 2e6b 6579 7328 2929 0d0a 0d0a  lf.p.keys())....
-000055f0: 2020 2020 2020 2020 666f 7220 692c 2069          for i, i
-00005600: 5f6b 6579 2069 6e20 656e 756d 6572 6174  _key in enumerat
-00005610: 6528 6b65 7973 293a 0d0a 2020 2020 2020  e(keys):..      
-00005620: 2020 2020 2020 2020 2079 202b 3d20 6e70           y += np
-00005630: 2e61 6273 2873 656c 662e 705b 695f 6b65  .abs(self.p[i_ke
-00005640: 795d 202a 2a28 692b 3229 290d 0a0d 0a20  y] **(i+2)).... 
-00005650: 2020 2020 2020 2079 5f6f 7574 203d 2079         y_out = y
-00005660: 5b3a 2c20 6e70 2e6e 6577 6178 6973 5d0d  [:, np.newaxis].
-00005670: 0a0d 0a20 2020 2020 2020 2072 6574 7572  ...        retur
-00005680: 6e20 795f 6f75 740d 0a0d 0a0d 0a63 6c61  n y_out......cla
-00005690: 7373 205a 616b 6861 726f 7646 756e 6374  ss ZakharovFunct
-000056a0: 696f 6e28 4162 7374 7261 6374 4d6f 6465  ion(AbstractMode
-000056b0: 6c29 3a0d 0a20 2020 2022 2222 0d0a 2020  l):..    """..  
-000056c0: 2020 642d 6469 6d65 6e73 696f 6e61 6c20    d-dimensional 
-000056d0: 5a61 6b68 6172 6f76 2046 756e 6374 696f  Zakharov Functio
-000056e0: 6e20 5b31 5d5b 325d 2e0d 0a20 2020 2054  n [1][2]...    T
-000056f0: 6865 205a 616b 6861 726f 7620 6675 6e63  he Zakharov func
-00005700: 7469 6f6e 2068 6173 206e 6f20 6c6f 6361  tion has no loca
-00005710: 6c20 6d69 6e69 6d61 2065 7863 6570 7420  l minima except 
-00005720: 7468 6520 676c 6f62 616c 206f 6e65 2e20  the global one. 
-00005730: 4974 2069 7320 7368 6f77 6e20 6865 7265  It is shown here
-00005740: 2069 6e20 6974 7320 7477 6f2d 6469 6d65   in its two-dime
-00005750: 6e73 696f 6e61 6c20 666f 726d 2e0d 0a0d  nsional form....
-00005760: 0a20 2020 202e 2e20 6d61 7468 3a3a 0d0a  .    .. math::..
-00005770: 2020 2020 2020 2079 203d 205c 5c73 756d         y = \\sum
-00005780: 5f7b 693d 317d 5e7b 647d 2078 5f69 5e32  _{i=1}^{d} x_i^2
-00005790: 2b5c 5c6c 6566 7428 5c5c 7375 6d5f 7b69  +\\left(\\sum_{i
-000057a0: 2b31 7d5e 7b64 7d30 2e35 6978 5f69 5c5c  +1}^{d}0.5ix_i\\
-000057b0: 7269 6768 7429 5e32 2b5c 5c6c 6566 7428  right)^2+\\left(
-000057c0: 5c5c 7375 6d5f 7b69 2b31 7d5e 6430 2e35  \\sum_{i+1}^d0.5
-000057d0: 6978 5f69 5c5c 7269 6768 7429 5e34 0d0a  ix_i\\right)^4..
-000057e0: 0d0a 2020 2020 5061 7261 6d65 7465 7273  ..    Parameters
-000057f0: 0d0a 2020 2020 2d2d 2d2d 2d2d 2d2d 2d2d  ..    ----------
-00005800: 0d0a 2020 2020 705b 2278 3122 5d3a 2066  ..    p["x1"]: f
-00005810: 6c6f 6174 206f 7220 6e64 6172 7261 7920  loat or ndarray 
-00005820: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
-00005830: 5d0d 0a20 2020 2020 2020 2046 6972 7374  ]..        First
-00005840: 2070 6172 616d 6574 6572 2064 6566 696e   parameter defin
-00005850: 6564 2069 6e20 5b2d 352c 2031 305d 0d0a  ed in [-5, 10]..
-00005860: 2020 2020 705b 2278 6922 5d3a 2066 6c6f      p["xi"]: flo
-00005870: 6174 206f 7220 6e64 6172 7261 7920 6f66  at or ndarray of
-00005880: 2066 6c6f 6174 205b 6e5f 6772 6964 5d0d   float [n_grid].
-00005890: 0a20 2020 2020 2020 2069 2d74 6820 7061  .        i-th pa
-000058a0: 7261 6d65 7465 7220 6465 6669 6e65 6420  rameter defined 
-000058b0: 696e 205b 2d35 2c20 3130 5d0d 0a0d 0a20  in [-5, 10].... 
-000058c0: 2020 2052 6574 7572 6e73 0d0a 2020 2020     Returns..    
-000058d0: 2d2d 2d2d 2d2d 2d0d 0a20 2020 2079 3a20  -------..    y: 
-000058e0: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-000058f0: 205b 6e5f 6772 6964 2078 2031 5d0d 0a20   [n_grid x 1].. 
-00005900: 2020 2020 2020 204f 7574 7075 740d 0a0d         Output...
-00005910: 0a20 2020 204e 6f74 6573 0d0a 2020 2020  .    Notes..    
-00005920: 2d2d 2d2d 2d0d 0a20 2020 202e 2e20 706c  -----..    .. pl
-00005930: 6f74 3a3a 0d0a 0d0a 2020 2020 2020 2069  ot::....       i
-00005940: 6d70 6f72 7420 6e75 6d70 7920 6173 206e  mport numpy as n
-00005950: 700d 0a20 2020 2020 2020 6672 6f6d 2070  p..       from p
-00005960: 7967 7063 2e74 6573 7466 756e 6374 696f  ygpc.testfunctio
-00005970: 6e73 2069 6d70 6f72 7420 706c 6f74 5f74  ns import plot_t
-00005980: 6573 7466 756e 6374 696f 6e20 6173 2070  estfunction as p
-00005990: 6c6f 740d 0a20 2020 2020 2020 6672 6f6d  lot..       from
-000059a0: 2063 6f6c 6c65 6374 696f 6e73 2069 6d70   collections imp
-000059b0: 6f72 7420 4f72 6465 7265 6444 6963 740d  ort OrderedDict.
-000059c0: 0a0d 0a20 2020 2020 2020 7061 7261 6d65  ...       parame
-000059d0: 7465 7273 203d 204f 7264 6572 6564 4469  ters = OrderedDi
-000059e0: 6374 2829 0d0a 2020 2020 2020 2070 6172  ct()..       par
-000059f0: 616d 6574 6572 735b 2278 3122 5d20 3d20  ameters["x1"] = 
-00005a00: 6e70 2e6c 696e 7370 6163 6528 2d35 2c20  np.linspace(-5, 
-00005a10: 3130 2c20 3130 3029 0d0a 2020 2020 2020  10, 100)..      
-00005a20: 2070 6172 616d 6574 6572 735b 2278 6922   parameters["xi"
-00005a30: 5d20 3d20 6e70 2e6c 696e 7370 6163 6528  ] = np.linspace(
-00005a40: 2d35 2c20 3130 2c20 3130 3029 0d0a 0d0a  -5, 10, 100)....
-00005a50: 2020 2020 2020 2063 6f6e 7374 616e 7473         constants
-00005a60: 203d 204e 6f6e 650d 0a0d 0a20 2020 2020   = None....     
-00005a70: 2020 706c 6f74 2822 5a61 6b68 6172 6f76    plot("Zakharov
-00005a80: 4675 6e63 7469 6f6e 222c 2070 6172 616d  Function", param
-00005a90: 6574 6572 732c 2063 6f6e 7374 616e 7473  eters, constants
-00005aa0: 2c20 706c 6f74 5f33 643d 4661 6c73 6529  , plot_3d=False)
-00005ab0: 0d0a 0d0a 2020 2020 2e2e 205b 315d 2047  ....    .. [1] G
-00005ac0: 6c6f 6261 6c20 4f70 7469 6d69 7a61 7469  lobal Optimizati
-00005ad0: 6f6e 2054 6573 7420 5072 6f62 6c65 6d73  on Test Problems
-00005ae0: 2e20 5265 7472 6965 7665 6420 4a75 6e65  . Retrieved June
-00005af0: 2032 3031 332c 2066 726f 6d0d 0a20 2020   2013, from..   
-00005b00: 2020 2020 6874 7470 3a2f 2f77 7777 2d6f      http://www-o
-00005b10: 7074 696d 612e 616d 702e 692e 6b79 6f74  ptima.amp.i.kyot
-00005b20: 6f2d 752e 6163 2e6a 702f 6d65 6d62 6572  o-u.ac.jp/member
-00005b30: 2f73 7475 6465 6e74 2f68 6564 6172 2f48  /student/hedar/H
-00005b40: 6564 6172 5f66 696c 6573 2f54 6573 7447  edar_files/TestG
-00005b50: 4f2e 6874 6d2e 0d0a 0d0a 2020 2020 2e2e  O.htm.....    ..
-00005b60: 205b 325d 2068 7474 7073 3a2f 2f77 7777   [2] https://www
-00005b70: 2e73 6675 2e63 612f 7e73 7375 726a 616e  .sfu.ca/~ssurjan
-00005b80: 6f2f 7a61 6b68 6172 6f76 2e68 746d 6c0d  o/zakharov.html.
-00005b90: 0a0d 0a20 2020 2022 2222 0d0a 0d0a 2020  ...    """....  
-00005ba0: 2020 6465 6620 5f5f 696e 6974 5f5f 2873    def __init__(s
-00005bb0: 656c 662c 206d 6174 6c61 625f 6d6f 6465  elf, matlab_mode
-00005bc0: 6c3d 4661 6c73 6529 3a0d 0a20 2020 2020  l=False):..     
-00005bd0: 2020 2073 7570 6572 2874 7970 6528 7365     super(type(se
-00005be0: 6c66 292c 2073 656c 6629 2e5f 5f69 6e69  lf), self).__ini
-00005bf0: 745f 5f28 6d61 746c 6162 5f6d 6f64 656c  t__(matlab_model
-00005c00: 3d6d 6174 6c61 625f 6d6f 6465 6c29 0d0a  =matlab_model)..
-00005c10: 2020 2020 2020 2020 7365 6c66 2e66 6e61          self.fna
-00005c20: 6d65 203d 2069 6e73 7065 6374 2e67 6574  me = inspect.get
-00005c30: 6669 6c65 2869 6e73 7065 6374 2e63 7572  file(inspect.cur
-00005c40: 7265 6e74 6672 616d 6528 2929 0d0a 0d0a  rentframe())....
-00005c50: 2020 2020 6465 6620 7661 6c69 6461 7465      def validate
-00005c60: 2873 656c 6629 3a0d 0a20 2020 2020 2020  (self):..       
-00005c70: 2070 6173 730d 0a0d 0a20 2020 2064 6566   pass....    def
-00005c80: 2073 696d 756c 6174 6528 7365 6c66 2c20   simulate(self, 
-00005c90: 7072 6f63 6573 735f 6964 3d4e 6f6e 652c  process_id=None,
-00005ca0: 206d 6174 6c61 625f 656e 6769 6e65 3d4e   matlab_engine=N
-00005cb0: 6f6e 6529 3a0d 0a0d 0a20 2020 2020 2020  one):....       
-00005cc0: 2066 6f72 2069 2c20 6b65 7920 696e 2065   for i, key in e
-00005cd0: 6e75 6d65 7261 7465 2873 656c 662e 702e  numerate(self.p.
-00005ce0: 6b65 7973 2829 293a 0d0a 2020 2020 2020  keys()):..      
-00005cf0: 2020 2020 2020 6966 2074 7970 6528 7365        if type(se
-00005d00: 6c66 2e70 5b6b 6579 5d29 2069 7320 6e70  lf.p[key]) is np
-00005d10: 2e6e 6461 7272 6179 3a0d 0a20 2020 2020  .ndarray:..     
-00005d20: 2020 2020 2020 2020 2020 7365 6c66 2e70            self.p
-00005d30: 5b6b 6579 5d20 3d20 7365 6c66 2e70 5b6b  [key] = self.p[k
-00005d40: 6579 5d2e 666c 6174 7465 6e28 290d 0a0d  ey].flatten()...
-00005d50: 0a20 2020 2020 2020 2023 2064 6574 6572  .        # deter
-00005d60: 6d69 6e65 2073 756d 0d0a 2020 2020 2020  mine sum..      
-00005d70: 2020 7331 203d 206e 702e 7a65 726f 7328    s1 = np.zeros(
-00005d80: 6e70 2e61 7272 6179 2873 656c 662e 705b  np.array(self.p[
-00005d90: 6c69 7374 2873 656c 662e 702e 6b65 7973  list(self.p.keys
-00005da0: 2829 295b 305d 5d29 2e73 697a 6529 0d0a  ())[0]]).size)..
-00005db0: 2020 2020 2020 2020 7332 203d 206e 702e          s2 = np.
-00005dc0: 7a65 726f 7328 6e70 2e61 7272 6179 2873  zeros(np.array(s
-00005dd0: 656c 662e 705b 6c69 7374 2873 656c 662e  elf.p[list(self.
-00005de0: 702e 6b65 7973 2829 295b 305d 5d29 2e73  p.keys())[0]]).s
-00005df0: 697a 6529 0d0a 2020 2020 2020 2020 7920  ize)..        y 
-00005e00: 3d20 6e70 2e7a 6572 6f73 286e 702e 6172  = np.zeros(np.ar
-00005e10: 7261 7928 7365 6c66 2e70 5b6c 6973 7428  ray(self.p[list(
-00005e20: 7365 6c66 2e70 2e6b 6579 7328 2929 5b30  self.p.keys())[0
-00005e30: 5d5d 292e 7369 7a65 290d 0a20 2020 2020  ]]).size)..     
-00005e40: 2020 206b 6579 7320 3d20 6c69 7374 2873     keys = list(s
-00005e50: 656c 662e 702e 6b65 7973 2829 290d 0a0d  elf.p.keys())...
-00005e60: 0a20 2020 2020 2020 2066 6f72 2069 2c20  .        for i, 
-00005e70: 6b65 7920 696e 2065 6e75 6d65 7261 7465  key in enumerate
-00005e80: 286b 6579 7329 3a0d 0a20 2020 2020 2020  (keys):..       
-00005e90: 2020 2020 2073 3120 2b3d 2028 7365 6c66       s1 += (self
-00005ea0: 2e70 5b6b 6579 5d20 2a2a 2032 290d 0a20  .p[key] ** 2).. 
-00005eb0: 2020 2020 2020 2020 2020 2073 3220 2b3d             s2 +=
-00005ec0: 2030 2e35 202a 2028 692b 3129 202a 2073   0.5 * (i+1) * s
-00005ed0: 656c 662e 705b 6b65 795d 0d0a 0d0a 2020  elf.p[key]....  
-00005ee0: 2020 2020 2020 2320 6465 7465 726d 696e        # determin
-00005ef0: 6520 6f75 7470 7574 0d0a 2020 2020 2020  e output..      
-00005f00: 2020 7920 3d20 7331 202b 2073 3220 2a2a    y = s1 + s2 **
-00005f10: 2032 202b 2073 3220 2a2a 2034 0d0a 0d0a   2 + s2 ** 4....
-00005f20: 2020 2020 2020 2020 795f 6f75 7420 3d20          y_out = 
-00005f30: 795b 3a2c 206e 702e 6e65 7761 7869 735d  y[:, np.newaxis]
-00005f40: 0d0a 0d0a 2020 2020 2020 2020 7265 7475  ....        retu
-00005f50: 726e 2079 5f6f 7574 0d0a 0d0a 0d0a 636c  rn y_out......cl
-00005f60: 6173 7320 4472 6f70 5761 7665 4675 6e63  ass DropWaveFunc
-00005f70: 7469 6f6e 2841 6273 7472 6163 744d 6f64  tion(AbstractMod
-00005f80: 656c 293a 0d0a 2020 2020 2222 220d 0a20  el):..    """.. 
-00005f90: 2020 2032 2d64 696d 656e 7369 6f6e 616c     2-dimensional
-00005fa0: 2044 726f 7057 6176 6546 756e 6374 696f   DropWaveFunctio
-00005fb0: 6e20 5b31 5d5b 325d 2e0d 0a20 2020 2054  n [1][2]...    T
-00005fc0: 6865 2044 726f 702d 5761 7665 2066 756e  he Drop-Wave fun
-00005fd0: 6374 696f 6e20 6973 206d 756c 7469 6d6f  ction is multimo
-00005fe0: 6461 6c20 616e 6420 6869 6768 6c79 2063  dal and highly c
-00005ff0: 6f6d 706c 6578 2e0d 0a20 2020 2054 6865  omplex...    The
-00006000: 2073 6563 6f6e 6420 706c 6f74 2061 626f   second plot abo
-00006010: 7665 2073 686f 7773 2074 6865 2066 756e  ve shows the fun
-00006020: 6374 696f 6e20 6f6e 2061 2073 6d61 6c6c  ction on a small
-00006030: 6572 2069 6e70 7574 2064 6f6d 6169 6e2c  er input domain,
-00006040: 2074 6f20 696c 6c75 7374 7261 7465 2069   to illustrate i
-00006050: 7473 2063 6861 7261 6374 6572 6973 7469  ts characteristi
-00006060: 6320 6665 6174 7572 6573 2e0d 0a0d 0a20  c features..... 
-00006070: 2020 202e 2e20 6d61 7468 3a3a 0d0a 2020     .. math::..  
-00006080: 2020 2020 7920 3d20 2d5c 5c66 7261 637b      y = -\\frac{
-00006090: 312b 5c5c 636f 735c 5c6c 6566 7428 3132  1+\\cos\\left(12
-000060a0: 5c5c 7371 7274 7b78 5f31 5e32 2b78 5f32  \\sqrt{x_1^2+x_2
-000060b0: 5e32 7d5c 5c72 6967 6874 297d 7b30 2e35  ^2}\\right)}{0.5
-000060c0: 2878 5f31 5e32 2b78 5f32 5e32 292b 327d  (x_1^2+x_2^2)+2}
-000060d0: 0d0a 0d0a 2020 2020 5061 7261 6d65 7465  ....    Paramete
-000060e0: 7273 0d0a 2020 2020 2d2d 2d2d 2d2d 2d2d  rs..    --------
-000060f0: 2d2d 0d0a 2020 2020 705b 2278 3122 5d3a  --..    p["x1"]:
-00006100: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
-00006110: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
-00006120: 6964 5d0d 0a20 2020 2020 2020 2046 6972  id]..        Fir
-00006130: 7374 2070 6172 616d 6574 6572 2064 6566  st parameter def
-00006140: 696e 6564 2069 6e20 5b2d 352e 3132 2c20  ined in [-5.12, 
-00006150: 352e 3132 5d0d 0a20 2020 2070 5b22 7832  5.12]..    p["x2
-00006160: 225d 3a20 666c 6f61 7420 6f72 206e 6461  "]: float or nda
-00006170: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
-00006180: 5f67 7269 645d 0d0a 2020 2020 2020 2020  _grid]..        
-00006190: 7365 636f 6e64 2070 6172 616d 6574 6572  second parameter
-000061a0: 2064 6566 696e 6564 2069 6e20 5b2d 352e   defined in [-5.
-000061b0: 3132 2c20 352e 3132 5d0d 0a0d 0a20 2020  12, 5.12]....   
-000061c0: 2052 6574 7572 6e73 0d0a 2020 2020 2d2d   Returns..    --
-000061d0: 2d2d 2d2d 2d0d 0a20 2020 2079 3a20 6e64  -----..    y: nd
-000061e0: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
-000061f0: 6e5f 6772 6964 2078 2031 5d0d 0a20 2020  n_grid x 1]..   
-00006200: 2020 2020 204f 7574 7075 740d 0a0d 0a20       Output.... 
-00006210: 2020 204e 6f74 6573 0d0a 2020 2020 2d2d     Notes..    --
-00006220: 2d2d 2d0d 0a20 2020 202e 2e20 706c 6f74  ---..    .. plot
-00006230: 3a3a 0d0a 0d0a 2020 2020 2020 2069 6d70  ::....       imp
-00006240: 6f72 7420 6e75 6d70 7920 6173 206e 700d  ort numpy as np.
-00006250: 0a20 2020 2020 2020 6672 6f6d 2070 7967  .       from pyg
-00006260: 7063 2e74 6573 7466 756e 6374 696f 6e73  pc.testfunctions
-00006270: 2069 6d70 6f72 7420 706c 6f74 5f74 6573   import plot_tes
-00006280: 7466 756e 6374 696f 6e20 6173 2070 6c6f  tfunction as plo
-00006290: 740d 0a20 2020 2020 2020 6672 6f6d 2063  t..       from c
-000062a0: 6f6c 6c65 6374 696f 6e73 2069 6d70 6f72  ollections impor
-000062b0: 7420 4f72 6465 7265 6444 6963 740d 0a0d  t OrderedDict...
-000062c0: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
-000062d0: 7273 203d 204f 7264 6572 6564 4469 6374  rs = OrderedDict
-000062e0: 2829 0d0a 2020 2020 2020 2070 6172 616d  ()..       param
-000062f0: 6574 6572 735b 2278 3122 5d20 3d20 6e70  eters["x1"] = np
-00006300: 2e6c 696e 7370 6163 6528 2d35 2e31 322c  .linspace(-5.12,
-00006310: 2035 2e31 322c 2031 3030 290d 0a20 2020   5.12, 100)..   
-00006320: 2020 2020 7061 7261 6d65 7465 7273 5b22      parameters["
-00006330: 7832 225d 203d 206e 702e 6c69 6e73 7061  x2"] = np.linspa
-00006340: 6365 282d 352e 3132 2c20 352e 3132 2c20  ce(-5.12, 5.12, 
-00006350: 3130 3029 0d0a 0d0a 2020 2020 2020 2063  100)....       c
-00006360: 6f6e 7374 616e 7473 203d 204e 6f6e 650d  onstants = None.
-00006370: 0a0d 0a20 2020 2020 2020 706c 6f74 2822  ...       plot("
-00006380: 4472 6f70 5761 7665 4675 6e63 7469 6f6e  DropWaveFunction
-00006390: 222c 2070 6172 616d 6574 6572 732c 2063  ", parameters, c
-000063a0: 6f6e 7374 616e 7473 2c20 706c 6f74 5f33  onstants, plot_3
-000063b0: 643d 4661 6c73 6529 0d0a 0d0a 2020 2020  d=False)....    
-000063c0: 2e2e 205b 315d 2047 6c6f 6261 6c20 4f70  .. [1] Global Op
-000063d0: 7469 6d69 7a61 7469 6f6e 2054 6573 7420  timization Test 
-000063e0: 4675 6e63 7469 6f6e 7320 496e 6465 782e  Functions Index.
-000063f0: 0d0a 2020 2020 2020 2052 6574 7269 6576  ..       Retriev
-00006400: 6564 204a 756e 6520 3230 3133 2c20 6672  ed June 2013, fr
-00006410: 6f6d 2068 7474 703a 2f2f 696e 6669 6e69  om http://infini
-00006420: 7479 3737 2e6e 6574 2f67 6c6f 6261 6c5f  ty77.net/global_
-00006430: 6f70 7469 6d69 7a61 7469 6f6e 2f74 6573  optimization/tes
-00006440: 745f 6675 6e63 7469 6f6e 732e 6874 6d6c  t_functions.html
-00006450: 2374 6573 742d 6675 6e63 7469 6f6e 732d  #test-functions-
-00006460: 696e 6465 782e 0d0a 0d0a 2020 2020 2e2e  index.....    ..
-00006470: 205b 325d 2068 7474 7073 3a2f 2f77 7777   [2] https://www
-00006480: 2e73 6675 2e63 612f 7e73 7375 726a 616e  .sfu.ca/~ssurjan
-00006490: 6f2f 6472 6f70 2e68 746d 6c0d 0a20 2020  o/drop.html..   
-000064a0: 2022 2222 0d0a 0d0a 2020 2020 6465 6620   """....    def 
-000064b0: 5f5f 696e 6974 5f5f 2873 656c 662c 206d  __init__(self, m
-000064c0: 6174 6c61 625f 6d6f 6465 6c3d 4661 6c73  atlab_model=Fals
-000064d0: 6529 3a0d 0a20 2020 2020 2020 2073 7570  e):..        sup
-000064e0: 6572 2874 7970 6528 7365 6c66 292c 2073  er(type(self), s
-000064f0: 656c 6629 2e5f 5f69 6e69 745f 5f28 6d61  elf).__init__(ma
-00006500: 746c 6162 5f6d 6f64 656c 3d6d 6174 6c61  tlab_model=matla
-00006510: 625f 6d6f 6465 6c29 0d0a 2020 2020 2020  b_model)..      
-00006520: 2020 7365 6c66 2e66 6e61 6d65 203d 2069    self.fname = i
-00006530: 6e73 7065 6374 2e67 6574 6669 6c65 2869  nspect.getfile(i
-00006540: 6e73 7065 6374 2e63 7572 7265 6e74 6672  nspect.currentfr
-00006550: 616d 6528 2929 0d0a 0d0a 2020 2020 6465  ame())....    de
-00006560: 6620 7661 6c69 6461 7465 2873 656c 6629  f validate(self)
-00006570: 3a0d 0a20 2020 2020 2020 2070 6173 730d  :..        pass.
-00006580: 0a0d 0a20 2020 2064 6566 2073 696d 756c  ...    def simul
-00006590: 6174 6528 7365 6c66 2c20 7072 6f63 6573  ate(self, proces
-000065a0: 735f 6964 3d4e 6f6e 652c 206d 6174 6c61  s_id=None, matla
-000065b0: 625f 656e 6769 6e65 3d4e 6f6e 6529 3a0d  b_engine=None):.
-000065c0: 0a0d 0a20 2020 2020 2020 2079 203d 202d  ...        y = -
-000065d0: 2028 3120 2b20 6e70 2e63 6f73 2831 3220   (1 + np.cos(12 
-000065e0: 2a20 6e70 2e73 7172 7428 7365 6c66 2e70  * np.sqrt(self.p
-000065f0: 5b22 7831 225d 202a 2a20 3220 2b20 7365  ["x1"] ** 2 + se
-00006600: 6c66 2e70 5b22 7832 225d 202a 2a20 3229  lf.p["x2"] ** 2)
-00006610: 2929 205c 0d0a 2020 2020 2020 2020 2020  )) \..          
-00006620: 2020 2f20 2830 2e35 202a 2028 7365 6c66    / (0.5 * (self
-00006630: 2e70 5b22 7831 225d 202a 2a20 3220 2b20  .p["x1"] ** 2 + 
-00006640: 7365 6c66 2e70 5b22 7832 225d 202a 2a20  self.p["x2"] ** 
-00006650: 3229 202b 2032 290d 0a0d 0a20 2020 2020  2) + 2)....     
-00006660: 2020 2079 5f6f 7574 203d 2079 5b3a 2c20     y_out = y[:, 
-00006670: 6e70 2e6e 6577 6178 6973 5d0d 0a0d 0a20  np.newaxis].... 
-00006680: 2020 2020 2020 2072 6574 7572 6e20 795f         return y_
-00006690: 6f75 740d 0a0d 0a0d 0a63 6c61 7373 2044  out......class D
-000066a0: 6978 6f6e 5072 6963 6546 756e 6374 696f  ixonPriceFunctio
-000066b0: 6e28 4162 7374 7261 6374 4d6f 6465 6c29  n(AbstractModel)
-000066c0: 3a0d 0a20 2020 2022 2222 0d0a 2020 2020  :..    """..    
-000066d0: 642d 6469 6d65 6e73 696f 6e61 6c20 4469  d-dimensional Di
-000066e0: 786f 6e2d 5072 6963 6520 4675 6e63 7469  xon-Price Functi
-000066f0: 6f6e 205b 315d 5b32 5d2e 0d0a 0d0a 2020  on [1][2].....  
-00006700: 2020 2e2e 206d 6174 683a 3a0d 0a20 2020    .. math::..   
-00006710: 2020 2079 203d 2028 785f 312d 3129 5e32     y = (x_1-1)^2
-00006720: 2b5c 5c73 756d 5f7b 693d 647d 5e7b 327d  +\\sum_{i=d}^{2}
-00006730: 2832 785f 7b69 7d5e 7b32 7d2d 785f 7b69  (2x_{i}^{2}-x_{i
-00006740: 2d31 7d29 5e32 0d0a 0d0a 2020 2020 5061  -1})^2....    Pa
-00006750: 7261 6d65 7465 7273 0d0a 2020 2020 2d2d  rameters..    --
-00006760: 2d2d 2d2d 2d2d 2d2d 0d0a 2020 2020 705b  --------..    p[
-00006770: 2278 3122 5d3a 2066 6c6f 6174 206f 7220  "x1"]: float or 
-00006780: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-00006790: 205b 6e5f 6772 6964 5d0d 0a20 2020 2020   [n_grid]..     
-000067a0: 2020 2046 6972 7374 2070 6172 616d 6574     First paramet
-000067b0: 6572 2064 6566 696e 6564 2069 6e20 5b2d  er defined in [-
-000067c0: 3130 2c20 3130 5d0d 0a20 2020 2070 5b22  10, 10]..    p["
-000067d0: 7869 225d 3a20 666c 6f61 7420 6f72 206e  xi"]: float or n
-000067e0: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-000067f0: 5b6e 5f67 7269 645d 0d0a 2020 2020 2020  [n_grid]..      
-00006800: 2020 692d 7468 2070 6172 616d 6574 6572    i-th parameter
-00006810: 2064 6566 696e 6564 2069 6e20 5b2d 3130   defined in [-10
-00006820: 2c20 3130 5d0d 0a0d 0a20 2020 2052 6574  , 10]....    Ret
-00006830: 7572 6e73 0d0a 2020 2020 2d2d 2d2d 2d2d  urns..    ------
-00006840: 2d0d 0a20 2020 2079 3a20 6e64 6172 7261  -..    y: ndarra
-00006850: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
-00006860: 6964 2078 2031 5d0d 0a20 2020 2020 2020  id x 1]..       
-00006870: 204f 7574 7075 740d 0a0d 0a20 2020 204e   Output....    N
-00006880: 6f74 6573 0d0a 2020 2020 2d2d 2d2d 2d0d  otes..    -----.
-00006890: 0a20 2020 202e 2e20 706c 6f74 3a3a 0d0a  .    .. plot::..
-000068a0: 0d0a 2020 2020 2020 2069 6d70 6f72 7420  ..       import 
-000068b0: 6e75 6d70 7920 6173 206e 700d 0a20 2020  numpy as np..   
-000068c0: 2020 2020 6672 6f6d 2070 7967 7063 2e74      from pygpc.t
-000068d0: 6573 7466 756e 6374 696f 6e73 2069 6d70  estfunctions imp
-000068e0: 6f72 7420 706c 6f74 5f74 6573 7466 756e  ort plot_testfun
-000068f0: 6374 696f 6e20 6173 2070 6c6f 740d 0a20  ction as plot.. 
-00006900: 2020 2020 2020 6672 6f6d 2063 6f6c 6c65        from colle
-00006910: 6374 696f 6e73 2069 6d70 6f72 7420 4f72  ctions import Or
-00006920: 6465 7265 6444 6963 740d 0a0d 0a20 2020  deredDict....   
-00006930: 2020 2020 7061 7261 6d65 7465 7273 203d      parameters =
-00006940: 204f 7264 6572 6564 4469 6374 2829 0d0a   OrderedDict()..
-00006950: 2020 2020 2020 2070 6172 616d 6574 6572         parameter
-00006960: 735b 2278 3122 5d20 3d20 6e70 2e6c 696e  s["x1"] = np.lin
-00006970: 7370 6163 6528 2d31 302c 2031 302c 2031  space(-10, 10, 1
-00006980: 3030 290d 0a20 2020 2020 2020 7061 7261  00)..       para
-00006990: 6d65 7465 7273 5b22 7832 225d 203d 206e  meters["x2"] = n
-000069a0: 702e 6c69 6e73 7061 6365 282d 3130 2c20  p.linspace(-10, 
-000069b0: 3130 2c20 3130 3029 0d0a 0d0a 2020 2020  10, 100)....    
-000069c0: 2020 2063 6f6e 7374 616e 7473 203d 204e     constants = N
-000069d0: 6f6e 650d 0a0d 0a20 2020 2020 2020 706c  one....       pl
-000069e0: 6f74 2822 4469 786f 6e50 7269 6365 4675  ot("DixonPriceFu
-000069f0: 6e63 7469 6f6e 2022 2c20 7061 7261 6d65  nction ", parame
-00006a00: 7465 7273 2c20 636f 6e73 7461 6e74 732c  ters, constants,
-00006a10: 2070 6c6f 745f 3364 3d46 616c 7365 290d   plot_3d=False).
-00006a20: 0a0d 0a20 2020 202e 2e20 5b31 5d20 476c  ...    .. [1] Gl
-00006a30: 6f62 616c 204f 7074 696d 697a 6174 696f  obal Optimizatio
-00006a40: 6e20 5465 7374 2046 756e 6374 696f 6e73  n Test Functions
-00006a50: 2049 6e64 6578 2e0d 0a20 2020 2020 2020   Index...       
-00006a60: 5265 7472 6965 7665 6420 4a75 6e65 2032  Retrieved June 2
-00006a70: 3031 332c 2066 726f 6d20 6874 7470 3a2f  013, from http:/
-00006a80: 2f69 6e66 696e 6974 7937 372e 6e65 742f  /infinity77.net/
-00006a90: 676c 6f62 616c 5f6f 7074 696d 697a 6174  global_optimizat
-00006aa0: 696f 6e2f 7465 7374 5f66 756e 6374 696f  ion/test_functio
-00006ab0: 6e73 2e68 746d 6c23 7465 7374 2d66 756e  ns.html#test-fun
-00006ac0: 6374 696f 6e73 2d69 6e64 6578 2e0d 0a0d  ctions-index....
-00006ad0: 0a20 2020 202e 2e20 5b32 5d20 6874 7470  .    .. [2] http
-00006ae0: 733a 2f2f 7777 772e 7366 752e 6361 2f7e  s://www.sfu.ca/~
-00006af0: 7373 7572 6a61 6e6f 2f64 6978 6f6e 7072  ssurjano/dixonpr
-00006b00: 2e68 746d 6c0d 0a0d 0a20 2020 2022 2222  .html....    """
-00006b10: 0d0a 0d0a 2020 2020 6465 6620 5f5f 696e  ....    def __in
-00006b20: 6974 5f5f 2873 656c 662c 206d 6174 6c61  it__(self, matla
-00006b30: 625f 6d6f 6465 6c3d 4661 6c73 6529 3a0d  b_model=False):.
-00006b40: 0a20 2020 2020 2020 2073 7570 6572 2874  .        super(t
-00006b50: 7970 6528 7365 6c66 292c 2073 656c 6629  ype(self), self)
-00006b60: 2e5f 5f69 6e69 745f 5f28 6d61 746c 6162  .__init__(matlab
-00006b70: 5f6d 6f64 656c 3d6d 6174 6c61 625f 6d6f  _model=matlab_mo
-00006b80: 6465 6c29 0d0a 2020 2020 2020 2020 7365  del)..        se
-00006b90: 6c66 2e66 6e61 6d65 203d 2069 6e73 7065  lf.fname = inspe
-00006ba0: 6374 2e67 6574 6669 6c65 2869 6e73 7065  ct.getfile(inspe
-00006bb0: 6374 2e63 7572 7265 6e74 6672 616d 6528  ct.currentframe(
-00006bc0: 2929 0d0a 0d0a 2020 2020 6465 6620 7661  ))....    def va
-00006bd0: 6c69 6461 7465 2873 656c 6629 3a0d 0a20  lidate(self):.. 
-00006be0: 2020 2020 2020 2070 6173 730d 0a0d 0a20         pass.... 
-00006bf0: 2020 2064 6566 2073 696d 756c 6174 6528     def simulate(
-00006c00: 7365 6c66 2c20 7072 6f63 6573 735f 6964  self, process_id
-00006c10: 3d4e 6f6e 652c 206d 6174 6c61 625f 656e  =None, matlab_en
-00006c20: 6769 6e65 3d4e 6f6e 6529 3a0d 0a0d 0a20  gine=None):.... 
-00006c30: 2020 2020 2020 2066 6f72 2069 2c20 6b65         for i, ke
-00006c40: 7920 696e 2065 6e75 6d65 7261 7465 2873  y in enumerate(s
-00006c50: 656c 662e 702e 6b65 7973 2829 293a 0d0a  elf.p.keys()):..
-00006c60: 2020 2020 2020 2020 2020 2020 6966 2074              if t
-00006c70: 7970 6528 7365 6c66 2e70 5b6b 6579 5d29  ype(self.p[key])
-00006c80: 2069 7320 6e70 2e6e 6461 7272 6179 3a0d   is np.ndarray:.
-00006c90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00006ca0: 7365 6c66 2e70 5b6b 6579 5d20 3d20 7365  self.p[key] = se
-00006cb0: 6c66 2e70 5b6b 6579 5d2e 666c 6174 7465  lf.p[key].flatte
-00006cc0: 6e28 290d 0a0d 0a20 2020 2020 2020 2073  n()....        s
-00006cd0: 3120 3d20 6e70 2e7a 6572 6f73 286e 702e  1 = np.zeros(np.
-00006ce0: 6172 7261 7928 7365 6c66 2e70 5b6c 6973  array(self.p[lis
-00006cf0: 7428 7365 6c66 2e70 2e6b 6579 7328 2929  t(self.p.keys())
-00006d00: 5b30 5d5d 292e 7369 7a65 290d 0a20 2020  [0]]).size)..   
-00006d10: 2020 2020 206b 6579 7320 3d20 6c69 7374       keys = list
-00006d20: 2873 656c 662e 702e 6b65 7973 2829 290d  (self.p.keys()).
-00006d30: 0a0d 0a20 2020 2020 2020 2066 6f72 2069  ...        for i
-00006d40: 2c20 6b65 7920 696e 2065 6e75 6d65 7261  , key in enumera
-00006d50: 7465 286b 6579 735b 313a 5d29 3a0d 0a20  te(keys[1:]):.. 
-00006d60: 2020 2020 2020 2020 2020 2073 3120 2b3d             s1 +=
-00006d70: 2028 692b 3229 202a 2028 3220 2a20 7365   (i+2) * (2 * se
-00006d80: 6c66 2e70 5b6b 6579 5d20 2a2a 2032 202d  lf.p[key] ** 2 -
-00006d90: 2073 656c 662e 705b 6b65 7973 5b69 5d5d   self.p[keys[i]]
-00006da0: 2920 2a2a 2032 0d0a 0d0a 2020 2020 2020  ) ** 2....      
-00006db0: 2020 2320 6465 7465 726d 696e 6520 6f75    # determine ou
-00006dc0: 7470 7574 0d0a 2020 2020 2020 2020 7920  tput..        y 
-00006dd0: 3d20 2873 656c 662e 705b 6b65 7973 5b30  = (self.p[keys[0
-00006de0: 5d5d 202d 2031 2920 2a2a 2032 202b 2073  ]] - 1) ** 2 + s
-00006df0: 310d 0a0d 0a20 2020 2020 2020 2079 5f6f  1....        y_o
-00006e00: 7574 203d 2079 5b3a 2c20 6e70 2e6e 6577  ut = y[:, np.new
-00006e10: 6178 6973 5d0d 0a0d 0a20 2020 2020 2020  axis]....       
-00006e20: 2072 6574 7572 6e20 795f 6f75 740d 0a0d   return y_out...
-00006e30: 0a0d 0a63 6c61 7373 2052 6f73 656e 6272  ...class Rosenbr
-00006e40: 6f63 6b46 756e 6374 696f 6e28 4162 7374  ockFunction(Abst
-00006e50: 7261 6374 4d6f 6465 6c29 3a0d 0a20 2020  ractModel):..   
-00006e60: 2022 2222 0d0a 2020 2020 642d 6469 6d65   """..    d-dime
-00006e70: 6e73 696f 6e61 6c20 526f 7365 6e62 726f  nsional Rosenbro
-00006e80: 636b 2046 756e 6374 696f 6e20 5b31 5d5b  ck Function [1][
-00006e90: 325d 5b33 5d5b 345d 5b35 5d2e 0d0a 2020  2][3][4][5]...  
-00006ea0: 2020 5468 6520 526f 7365 6e62 726f 636b    The Rosenbrock
-00006eb0: 2066 756e 6374 696f 6e2c 2061 6c73 6f20   function, also 
-00006ec0: 7265 6665 7272 6564 2074 6f20 6173 2074  referred to as t
-00006ed0: 6865 2056 616c 6c65 7920 6f72 2042 616e  he Valley or Ban
-00006ee0: 616e 6120 6675 6e63 7469 6f6e 2c0d 0a20  ana function,.. 
-00006ef0: 2020 2069 7320 6120 706f 7075 6c61 7220     is a popular 
-00006f00: 7465 7374 2070 726f 626c 656d 2066 6f72  test problem for
-00006f10: 2067 7261 6469 656e 742d 6261 7365 6420   gradient-based 
-00006f20: 6f70 7469 6d69 7a61 7469 6f6e 2061 6c67  optimization alg
-00006f30: 6f72 6974 686d 732e 0d0a 2020 2020 4974  orithms...    It
-00006f40: 2069 7320 7368 6f77 6e20 696e 2074 6865   is shown in the
-00006f50: 2070 6c6f 7420 6162 6f76 6520 696e 2069   plot above in i
-00006f60: 7473 2074 776f 2d64 696d 656e 7369 6f6e  ts two-dimension
-00006f70: 616c 2066 6f72 6d2e 0d0a 2020 2020 5468  al form...    Th
-00006f80: 6520 6675 6e63 7469 6f6e 2069 7320 756e  e function is un
-00006f90: 696d 6f64 616c 2c20 616e 6420 7468 6520  imodal, and the 
-00006fa0: 676c 6f62 616c 206d 696e 696d 756d 206c  global minimum l
-00006fb0: 6965 7320 696e 2061 206e 6172 726f 772c  ies in a narrow,
-00006fc0: 2070 6172 6162 6f6c 6963 2076 616c 6c65   parabolic valle
-00006fd0: 792e 0d0a 2020 2020 486f 7765 7665 722c  y...    However,
-00006fe0: 2065 7665 6e20 7468 6f75 6768 2074 6869   even though thi
-00006ff0: 7320 7661 6c6c 6579 2069 7320 6561 7379  s valley is easy
-00007000: 2074 6f20 6669 6e64 2c20 636f 6e76 6572   to find, conver
-00007010: 6765 6e63 6520 746f 2074 6865 206d 696e  gence to the min
-00007020: 696d 756d 2069 7320 6469 6666 6963 756c  imum is difficul
-00007030: 7420 2850 6963 6865 6e79 2065 7420 616c  t (Picheny et al
-00007040: 2e2c 2032 3031 3229 2e0d 0a0d 0a20 2020  ., 2012).....   
-00007050: 202e 2e20 6d61 7468 3a3a 0d0a 2020 2020   .. math::..    
-00007060: 2020 7920 3d20 5c5c 7375 6d5f 7b69 3d31    y = \\sum_{i=1
-00007070: 7d5e 7b64 2d31 7d5b 3130 3028 785f 7b69  }^{d-1}[100(x_{i
-00007080: 2b31 7d2d 785f 695e 3229 5e32 2b28 785f  +1}-x_i^2)^2+(x_
-00007090: 692d 3129 5e32 5d0d 0a0d 0a20 2020 2050  i-1)^2]....    P
-000070a0: 6172 616d 6574 6572 730d 0a20 2020 202d  arameters..    -
-000070b0: 2d2d 2d2d 2d2d 2d2d 2d0d 0a20 2020 2070  ---------..    p
-000070c0: 5b22 7831 225d 3a20 666c 6f61 7420 6f72  ["x1"]: float or
-000070d0: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-000070e0: 7420 5b6e 5f67 7269 645d 0d0a 2020 2020  t [n_grid]..    
-000070f0: 2020 2020 4669 7273 7420 7061 7261 6d65      First parame
-00007100: 7465 7220 6465 6669 6e65 6420 696e 205b  ter defined in [
-00007110: 2d35 2c20 3130 5d0d 0a20 2020 2070 5b22  -5, 10]..    p["
-00007120: 7869 225d 3a20 666c 6f61 7420 6f72 206e  xi"]: float or n
-00007130: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-00007140: 5b6e 5f67 7269 645d 0d0a 2020 2020 2020  [n_grid]..      
-00007150: 2020 692d 7468 2070 6172 616d 6574 6572    i-th parameter
-00007160: 2064 6566 696e 6564 2069 6e20 5b2d 352c   defined in [-5,
-00007170: 2031 305d 0d0a 0d0a 2020 2020 5265 7475   10]....    Retu
-00007180: 726e 730d 0a20 2020 202d 2d2d 2d2d 2d2d  rns..    -------
-00007190: 0d0a 2020 2020 793a 206e 6461 7272 6179  ..    y: ndarray
-000071a0: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
-000071b0: 6420 7820 315d 0d0a 2020 2020 2020 2020  d x 1]..        
-000071c0: 4f75 7470 7574 0d0a 0d0a 2020 2020 4e6f  Output....    No
-000071d0: 7465 730d 0a20 2020 202d 2d2d 2d2d 0d0a  tes..    -----..
-000071e0: 2020 2020 2e2e 2070 6c6f 743a 3a0d 0a0d      .. plot::...
-000071f0: 0a20 2020 2020 2020 696d 706f 7274 206e  .       import n
-00007200: 756d 7079 2061 7320 6e70 0d0a 2020 2020  umpy as np..    
-00007210: 2020 2066 726f 6d20 7079 6770 632e 7465     from pygpc.te
-00007220: 7374 6675 6e63 7469 6f6e 7320 696d 706f  stfunctions impo
-00007230: 7274 2070 6c6f 745f 7465 7374 6675 6e63  rt plot_testfunc
-00007240: 7469 6f6e 2061 7320 706c 6f74 0d0a 2020  tion as plot..  
-00007250: 2020 2020 2066 726f 6d20 636f 6c6c 6563       from collec
-00007260: 7469 6f6e 7320 696d 706f 7274 204f 7264  tions import Ord
-00007270: 6572 6564 4469 6374 0d0a 0d0a 2020 2020  eredDict....    
-00007280: 2020 2070 6172 616d 6574 6572 7320 3d20     parameters = 
-00007290: 4f72 6465 7265 6444 6963 7428 290d 0a20  OrderedDict().. 
-000072a0: 2020 2020 2020 7061 7261 6d65 7465 7273        parameters
-000072b0: 5b22 7831 225d 203d 206e 702e 6c69 6e73  ["x1"] = np.lins
-000072c0: 7061 6365 282d 352c 2031 302c 2031 3030  pace(-5, 10, 100
-000072d0: 290d 0a20 2020 2020 2020 7061 7261 6d65  )..       parame
-000072e0: 7465 7273 5b22 7832 225d 203d 206e 702e  ters["x2"] = np.
-000072f0: 6c69 6e73 7061 6365 282d 352c 2031 302c  linspace(-5, 10,
-00007300: 2031 3030 290d 0a0d 0a20 2020 2020 2020   100)....       
-00007310: 636f 6e73 7461 6e74 7320 3d20 4e6f 6e65  constants = None
-00007320: 0d0a 0d0a 2020 2020 2020 2070 6c6f 7428  ....       plot(
-00007330: 2252 6f73 656e 6272 6f63 6b46 756e 6374  "RosenbrockFunct
-00007340: 696f 6e20 222c 2070 6172 616d 6574 6572  ion ", parameter
-00007350: 732c 2063 6f6e 7374 616e 7473 2c20 706c  s, constants, pl
-00007360: 6f74 5f33 643d 4661 6c73 6529 0d0a 0d0a  ot_3d=False)....
-00007370: 2020 2020 2e2e 205b 315d 2044 6978 6f6e      .. [1] Dixon
-00007380: 2c20 4c2e 2043 2e20 572e 2c20 2620 537a  , L. C. W., & Sz
-00007390: 6567 6f2c 2047 2e20 502e 2028 3139 3738  ego, G. P. (1978
-000073a0: 292e 2054 6865 2067 6c6f 6261 6c20 6f70  ). The global op
-000073b0: 7469 6d69 7a61 7469 6f6e 2070 726f 626c  timization probl
-000073c0: 656d 3a20 616e 2069 6e74 726f 6475 6374  em: an introduct
-000073d0: 696f 6e2e 0d0a 2020 2020 2020 2054 6f77  ion...       Tow
-000073e0: 6172 6473 2067 6c6f 6261 6c20 6f70 7469  ards global opti
-000073f0: 6d69 7a61 7469 6f6e 2c20 322c 2031 2d31  mization, 2, 1-1
-00007400: 352e 0d0a 0d0a 2020 2020 2e2e 205b 325d  5.....    .. [2]
-00007410: 2047 6c6f 6261 6c20 4f70 7469 6d69 7a61   Global Optimiza
-00007420: 7469 6f6e 2054 6573 7420 5072 6f62 6c65  tion Test Proble
-00007430: 6d73 2e20 5265 7472 6965 7665 6420 4a75  ms. Retrieved Ju
-00007440: 6e65 2032 3031 332c 2066 726f 6d0d 0a20  ne 2013, from.. 
-00007450: 2020 2020 2020 6874 7470 3a2f 2f77 7777        http://www
-00007460: 2d6f 7074 696d 612e 616d 702e 692e 6b79  -optima.amp.i.ky
-00007470: 6f74 6f2d 752e 6163 2e6a 702f 6d65 6d62  oto-u.ac.jp/memb
-00007480: 6572 2f73 7475 6465 6e74 2f68 6564 6172  er/student/hedar
-00007490: 2f48 6564 6172 5f66 696c 6573 2f54 6573  /Hedar_files/Tes
-000074a0: 7447 4f2e 6874 6d2e 0d0a 0d0a 2020 2020  tGO.htm.....    
-000074b0: 2e2e 205b 335d 204d 6f6c 6761 2c20 4d2e  .. [3] Molga, M.
-000074c0: 2c20 2620 536d 7574 6e69 636b 692c 2043  , & Smutnicki, C
-000074d0: 2e20 5465 7374 2066 756e 6374 696f 6e73  . Test functions
-000074e0: 2066 6f72 206f 7074 696d 697a 6174 696f   for optimizatio
-000074f0: 6e20 6e65 6564 7320 2832 3030 3529 2e0d  n needs (2005)..
-00007500: 0a20 2020 2020 2020 5265 7472 6965 7665  .       Retrieve
-00007510: 6420 4a75 6e65 2032 3031 332c 2066 726f  d June 2013, fro
-00007520: 6d20 6874 7470 3a2f 2f77 7777 2e7a 7364  m http://www.zsd
-00007530: 2e69 6374 2e70 7772 2e77 726f 632e 706c  .ict.pwr.wroc.pl
-00007540: 2f66 696c 6573 2f64 6f63 732f 6675 6e63  /files/docs/func
-00007550: 7469 6f6e 732e 7064 662e 0d0a 0d0a 2020  tions.pdf.....  
-00007560: 2020 2e2e 205b 345d 2050 6963 6865 6e79    .. [4] Picheny
-00007570: 2c20 562e 2c20 5761 676e 6572 2c20 542e  , V., Wagner, T.
-00007580: 2c20 2620 4769 6e73 626f 7572 6765 722c  , & Ginsbourger,
-00007590: 2044 2e20 2832 3031 3229 2e0d 0a20 2020   D. (2012)...   
-000075a0: 2020 2020 4120 6265 6e63 686d 6172 6b20      A benchmark 
-000075b0: 6f66 206b 7269 6769 6e67 2d62 6173 6564  of kriging-based
-000075c0: 2069 6e66 696c 6c20 6372 6974 6572 6961   infill criteria
-000075d0: 2066 6f72 206e 6f69 7379 206f 7074 696d   for noisy optim
-000075e0: 697a 6174 696f 6e2e 0d0a 0d0a 2020 2020  ization.....    
-000075f0: 2e2e 205b 355d 2068 7474 7073 3a2f 2f77  .. [5] https://w
-00007600: 7777 2e73 6675 2e63 612f 7e73 7375 726a  ww.sfu.ca/~ssurj
-00007610: 616e 6f2f 726f 7365 6e2e 6874 6d6c 0d0a  ano/rosen.html..
-00007620: 0d0a 2020 2020 2222 220d 0a0d 0a20 2020  ..    """....   
-00007630: 2064 6566 205f 5f69 6e69 745f 5f28 7365   def __init__(se
-00007640: 6c66 2c20 6d61 746c 6162 5f6d 6f64 656c  lf, matlab_model
-00007650: 3d46 616c 7365 293a 0d0a 2020 2020 2020  =False):..      
-00007660: 2020 7375 7065 7228 7479 7065 2873 656c    super(type(sel
-00007670: 6629 2c20 7365 6c66 292e 5f5f 696e 6974  f), self).__init
-00007680: 5f5f 286d 6174 6c61 625f 6d6f 6465 6c3d  __(matlab_model=
-00007690: 6d61 746c 6162 5f6d 6f64 656c 290d 0a20  matlab_model).. 
-000076a0: 2020 2020 2020 2073 656c 662e 666e 616d         self.fnam
-000076b0: 6520 3d20 696e 7370 6563 742e 6765 7466  e = inspect.getf
-000076c0: 696c 6528 696e 7370 6563 742e 6375 7272  ile(inspect.curr
-000076d0: 656e 7466 7261 6d65 2829 290d 0a0d 0a20  entframe()).... 
-000076e0: 2020 2064 6566 2076 616c 6964 6174 6528     def validate(
-000076f0: 7365 6c66 293a 0d0a 2020 2020 2020 2020  self):..        
-00007700: 7061 7373 0d0a 0d0a 2020 2020 6465 6620  pass....    def 
-00007710: 7369 6d75 6c61 7465 2873 656c 662c 2070  simulate(self, p
-00007720: 726f 6365 7373 5f69 643d 4e6f 6e65 2c20  rocess_id=None, 
-00007730: 6d61 746c 6162 5f65 6e67 696e 653d 4e6f  matlab_engine=No
-00007740: 6e65 293a 0d0a 0d0a 2020 2020 2020 2020  ne):....        
-00007750: 666f 7220 692c 206b 6579 2069 6e20 656e  for i, key in en
-00007760: 756d 6572 6174 6528 7365 6c66 2e70 2e6b  umerate(self.p.k
-00007770: 6579 7328 2929 3a0d 0a20 2020 2020 2020  eys()):..       
-00007780: 2020 2020 2069 6620 7479 7065 2873 656c       if type(sel
-00007790: 662e 705b 6b65 795d 2920 6973 206e 702e  f.p[key]) is np.
-000077a0: 6e64 6172 7261 793a 0d0a 2020 2020 2020  ndarray:..      
-000077b0: 2020 2020 2020 2020 2073 656c 662e 705b           self.p[
-000077c0: 6b65 795d 203d 2073 656c 662e 705b 6b65  key] = self.p[ke
-000077d0: 795d 2e66 6c61 7474 656e 2829 0d0a 0d0a  y].flatten()....
-000077e0: 2020 2020 2020 2020 7920 3d20 6e70 2e7a          y = np.z
-000077f0: 6572 6f73 286e 702e 6172 7261 7928 7365  eros(np.array(se
-00007800: 6c66 2e70 5b6c 6973 7428 7365 6c66 2e70  lf.p[list(self.p
-00007810: 2e6b 6579 7328 2929 5b30 5d5d 292e 7369  .keys())[0]]).si
-00007820: 7a65 290d 0a20 2020 2020 2020 206b 6579  ze)..        key
-00007830: 7320 3d20 6c69 7374 2873 656c 662e 702e  s = list(self.p.
-00007840: 6b65 7973 2829 290d 0a0d 0a20 2020 2020  keys())....     
-00007850: 2020 2066 6f72 2069 2c20 6b65 7920 696e     for i, key in
-00007860: 2065 6e75 6d65 7261 7465 286b 6579 735b   enumerate(keys[
-00007870: 3a2d 315d 293a 0d0a 2020 2020 2020 2020  :-1]):..        
-00007880: 2020 2020 7920 2b3d 2031 3030 202a 2028      y += 100 * (
-00007890: 7365 6c66 2e70 5b6b 6579 735b 692b 315d  self.p[keys[i+1]
-000078a0: 5d20 2d20 7365 6c66 2e70 5b6b 6579 5d20  ] - self.p[key] 
-000078b0: 2a2a 2032 2920 2a2a 2032 202b 2028 7365  ** 2) ** 2 + (se
-000078c0: 6c66 2e70 5b6b 6579 5d20 2d20 3129 202a  lf.p[key] - 1) *
-000078d0: 2a20 320d 0a0d 0a20 2020 2020 2020 2079  * 2....        y
-000078e0: 5f6f 7574 203d 2079 5b3a 2c20 6e70 2e6e  _out = y[:, np.n
-000078f0: 6577 6178 6973 5d0d 0a0d 0a20 2020 2020  ewaxis]....     
-00007900: 2020 2072 6574 7572 6e20 795f 6f75 740d     return y_out.
-00007910: 0a0d 0a0d 0a63 6c61 7373 204d 6963 6861  .....class Micha
-00007920: 6c65 7769 637a 4675 6e63 7469 6f6e 2841  lewiczFunction(A
-00007930: 6273 7472 6163 744d 6f64 656c 293a 0d0a  bstractModel):..
-00007940: 2020 2020 2222 220d 0a20 2020 2064 2d64      """..    d-d
-00007950: 696d 656e 7369 6f6e 616c 204d 6963 6861  imensional Micha
-00007960: 6c65 7769 637a 2066 756e 6374 696f 6e20  lewicz function 
-00007970: 5b31 5d5b 325d 5b33 5d5b 345d 2e0d 0a20  [1][2][3][4]... 
-00007980: 2020 2054 6865 204d 6963 6861 6c65 7769     The Michalewi
-00007990: 637a 2066 756e 6374 696f 6e20 6861 7320  cz function has 
-000079a0: 6421 206c 6f63 616c 206d 696e 696d 612c  d! local minima,
-000079b0: 2061 6e64 2069 7420 6973 206d 756c 7469   and it is multi
-000079c0: 6d6f 6461 6c2e 0d0a 2020 2020 5468 6520  modal...    The 
-000079d0: 7061 7261 6d65 7465 7220 6d20 6465 6669  parameter m defi
-000079e0: 6e65 7320 7468 6520 7374 6565 706e 6573  nes the steepnes
-000079f0: 7320 6f66 2074 6865 7920 7661 6c6c 6579  s of they valley
-00007a00: 7320 616e 6420 7269 6467 6573 3b20 6120  s and ridges; a 
-00007a10: 6c61 7267 6572 206d 206c 6561 6473 2074  larger m leads t
-00007a20: 6f20 6120 6d6f 7265 2064 6966 6669 6375  o a more difficu
-00007a30: 6c74 2073 6561 7263 682e 0d0a 2020 2020  lt search...    
-00007a40: 5468 6520 7265 636f 6d6d 656e 6465 6420  The recommended 
-00007a50: 7661 6c75 6520 6f66 206d 2069 7320 6d20  value of m is m 
-00007a60: 3d20 3130 2e20 5468 6520 6675 6e63 7469  = 10. The functi
-00007a70: 6f6e 2773 2074 776f 2d64 696d 656e 7369  on's two-dimensi
-00007a80: 6f6e 616c 2066 6f72 6d20 6973 2073 686f  onal form is sho
-00007a90: 776e 2069 6e20 7468 6520 706c 6f74 2061  wn in the plot a
-00007aa0: 626f 7665 2e0d 0a0d 0a20 2020 202e 2e20  bove.....    .. 
-00007ab0: 6d61 7468 3a3a 0d0a 2020 2020 2020 2079  math::..       y
-00007ac0: 3d2d 5c5c 7375 6d5f 7b69 3d31 7d5e 7b64  =-\\sum_{i=1}^{d
-00007ad0: 7d5c 5c73 696e 2878 5f69 295c 5c73 696e  }\\sin(x_i)\\sin
-00007ae0: 5e7b 326d 7d5c 5c6c 6566 7428 5c5c 6672  ^{2m}\\left(\\fr
-00007af0: 6163 7b69 2078 5f69 5e32 7d7b 5c5c 7069  ac{i x_i^2}{\\pi
-00007b00: 7d5c 5c72 6967 6874 290d 0a0d 0a20 2020  }\\right)....   
-00007b10: 2050 6172 616d 6574 6572 730d 0a20 2020   Parameters..   
-00007b20: 202d 2d2d 2d2d 2d2d 2d2d 2d0d 0a20 2020   ----------..   
-00007b30: 2070 5b22 7831 225d 3a20 666c 6f61 7420   p["x1"]: float 
-00007b40: 6f72 206e 6461 7272 6179 206f 6620 666c  or ndarray of fl
-00007b50: 6f61 7420 5b6e 5f67 7269 645d 0d0a 2020  oat [n_grid]..  
-00007b60: 2020 2020 2020 4669 7273 7420 7061 7261        First para
-00007b70: 6d65 7465 7220 6465 6669 6e65 6420 696e  meter defined in
-00007b80: 205b 302c 206e 702e 7069 5d0d 0a20 2020   [0, np.pi]..   
-00007b90: 2070 5b22 7869 225d 3a20 666c 6f61 7420   p["xi"]: float 
-00007ba0: 6f72 206e 6461 7272 6179 206f 6620 666c  or ndarray of fl
-00007bb0: 6f61 7420 5b6e 5f67 7269 645d 0d0a 2020  oat [n_grid]..  
-00007bc0: 2020 2020 2020 692d 7468 2070 6172 616d        i-th param
-00007bd0: 6574 6572 2064 6566 696e 6564 2069 6e20  eter defined in 
-00007be0: 5b30 2c20 6e70 2e70 695d 0d0a 0d0a 2020  [0, np.pi]....  
-00007bf0: 2020 5265 7475 726e 730d 0a20 2020 202d    Returns..    -
-00007c00: 2d2d 2d2d 2d2d 0d0a 2020 2020 793a 206e  ------..    y: n
-00007c10: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-00007c20: 5b6e 5f67 7269 6420 7820 315d 0d0a 2020  [n_grid x 1]..  
-00007c30: 2020 2020 2020 4f75 7470 7574 0d0a 0d0a        Output....
-00007c40: 2020 2020 4e6f 7465 730d 0a20 2020 202d      Notes..    -
-00007c50: 2d2d 2d2d 0d0a 2020 2020 2e2e 2070 6c6f  ----..    .. plo
-00007c60: 743a 3a0d 0a0d 0a20 2020 2020 2020 696d  t::....       im
-00007c70: 706f 7274 206e 756d 7079 2061 7320 6e70  port numpy as np
-00007c80: 0d0a 2020 2020 2020 2066 726f 6d20 7079  ..       from py
-00007c90: 6770 632e 7465 7374 6675 6e63 7469 6f6e  gpc.testfunction
-00007ca0: 7320 696d 706f 7274 2070 6c6f 745f 7465  s import plot_te
-00007cb0: 7374 6675 6e63 7469 6f6e 2061 7320 706c  stfunction as pl
-00007cc0: 6f74 0d0a 2020 2020 2020 2066 726f 6d20  ot..       from 
-00007cd0: 636f 6c6c 6563 7469 6f6e 7320 696d 706f  collections impo
-00007ce0: 7274 204f 7264 6572 6564 4469 6374 0d0a  rt OrderedDict..
-00007cf0: 0d0a 2020 2020 2020 2070 6172 616d 6574  ..       paramet
-00007d00: 6572 7320 3d20 4f72 6465 7265 6444 6963  ers = OrderedDic
-00007d10: 7428 290d 0a20 2020 2020 2020 7061 7261  t()..       para
-00007d20: 6d65 7465 7273 5b22 7831 225d 203d 206e  meters["x1"] = n
-00007d30: 702e 6c69 6e73 7061 6365 2830 2c20 6e70  p.linspace(0, np
-00007d40: 2e70 692c 2031 3030 290d 0a20 2020 2020  .pi, 100)..     
-00007d50: 2020 7061 7261 6d65 7465 7273 5b22 7869    parameters["xi
-00007d60: 225d 203d 206e 702e 6c69 6e73 7061 6365  "] = np.linspace
-00007d70: 2830 2c20 6e70 2e70 692c 2031 3030 290d  (0, np.pi, 100).
-00007d80: 0a0d 0a20 2020 2020 2020 636f 6e73 7461  ...       consta
-00007d90: 6e74 7320 3d20 4f72 6465 7265 6444 6963  nts = OrderedDic
-00007da0: 7428 290d 0a20 2020 2020 2020 636f 6e73  t()..       cons
-00007db0: 7461 6e74 735b 226d 225d 203d 2031 302e  tants["m"] = 10.
-00007dc0: 0d0a 0d0a 2020 2020 2020 2070 6c6f 7428  ....       plot(
-00007dd0: 224d 6963 6861 6c65 7769 637a 4675 6e63  "MichalewiczFunc
-00007de0: 7469 6f6e 222c 2070 6172 616d 6574 6572  tion", parameter
-00007df0: 732c 2063 6f6e 7374 616e 7473 2c20 706c  s, constants, pl
-00007e00: 6f74 5f33 643d 4661 6c73 6529 0d0a 0d0a  ot_3d=False)....
-00007e10: 2020 2020 2e2e 205b 315d 2047 6c6f 6261      .. [1] Globa
-00007e20: 6c20 4f70 7469 6d69 7a61 7469 6f6e 2054  l Optimization T
-00007e30: 6573 7420 4675 6e63 7469 6f6e 7320 496e  est Functions In
-00007e40: 6465 782e 0d0a 2020 2020 2020 2052 6574  dex...       Ret
-00007e50: 7269 6576 6564 204a 756e 6520 3230 3133  rieved June 2013
-00007e60: 2c20 6672 6f6d 2068 7474 703a 2f2f 696e  , from http://in
-00007e70: 6669 6e69 7479 3737 2e6e 6574 2f67 6c6f  finity77.net/glo
-00007e80: 6261 6c5f 6f70 7469 6d69 7a61 7469 6f6e  bal_optimization
-00007e90: 2f74 6573 745f 6675 6e63 7469 6f6e 732e  /test_functions.
-00007ea0: 6874 6d6c 2374 6573 742d 6675 6e63 7469  html#test-functi
-00007eb0: 6f6e 732d 696e 6465 782e 0d0a 0d0a 2020  ons-index.....  
-00007ec0: 2020 2e2e 205b 325d 476c 6f62 616c 204f    .. [2]Global O
-00007ed0: 7074 696d 697a 6174 696f 6e20 5465 7374  ptimization Test
-00007ee0: 2050 726f 626c 656d 732e 2052 6574 7269   Problems. Retri
-00007ef0: 6576 6564 204a 756e 6520 3230 3133 2c20  eved June 2013, 
-00007f00: 6672 6f6d 0d0a 2020 2020 2020 2068 7474  from..       htt
-00007f10: 703a 2f2f 7777 772d 6f70 7469 6d61 2e61  p://www-optima.a
-00007f20: 6d70 2e69 2e6b 796f 746f 2d75 2e61 632e  mp.i.kyoto-u.ac.
-00007f30: 6a70 2f6d 656d 6265 722f 7374 7564 656e  jp/member/studen
-00007f40: 742f 6865 6461 722f 4865 6461 725f 6669  t/hedar/Hedar_fi
-00007f50: 6c65 732f 5465 7374 474f 2e68 746d 2e0d  les/TestGO.htm..
-00007f60: 0a0d 0a20 2020 202e 2e20 5b33 5d20 4d6f  ...    .. [3] Mo
-00007f70: 6c67 612c 204d 2e2c 2026 2053 6d75 746e  lga, M., & Smutn
-00007f80: 6963 6b69 2c20 432e 2054 6573 7420 6675  icki, C. Test fu
-00007f90: 6e63 7469 6f6e 7320 666f 7220 6f70 7469  nctions for opti
-00007fa0: 6d69 7a61 7469 6f6e 206e 6565 6473 2028  mization needs (
-00007fb0: 3230 3035 292e 0d0a 2020 2020 2020 2052  2005)...       R
-00007fc0: 6574 7269 6576 6564 204a 756e 6520 3230  etrieved June 20
-00007fd0: 3133 2c20 6672 6f6d 2068 7474 703a 2f2f  13, from http://
-00007fe0: 7777 772e 7a73 642e 6963 742e 7077 722e  www.zsd.ict.pwr.
-00007ff0: 7772 6f63 2e70 6c2f 6669 6c65 732f 646f  wroc.pl/files/do
-00008000: 6373 2f66 756e 6374 696f 6e73 2e70 6466  cs/functions.pdf
-00008010: 2e0d 0a0d 0a20 2020 202e 2e20 5b34 5d20  .....    .. [4] 
-00008020: 6874 7470 733a 2f2f 7777 772e 7366 752e  https://www.sfu.
-00008030: 6361 2f7e 7373 7572 6a61 6e6f 2f6d 6963  ca/~ssurjano/mic
-00008040: 6861 6c2e 6874 6d6c 0d0a 0d0a 2020 2020  hal.html....    
-00008050: 2222 220d 0a0d 0a20 2020 2064 6566 205f  """....    def _
-00008060: 5f69 6e69 745f 5f28 7365 6c66 2c20 6d61  _init__(self, ma
-00008070: 746c 6162 5f6d 6f64 656c 3d46 616c 7365  tlab_model=False
-00008080: 293a 0d0a 2020 2020 2020 2020 7375 7065  ):..        supe
-00008090: 7228 7479 7065 2873 656c 6629 2c20 7365  r(type(self), se
-000080a0: 6c66 292e 5f5f 696e 6974 5f5f 286d 6174  lf).__init__(mat
-000080b0: 6c61 625f 6d6f 6465 6c3d 6d61 746c 6162  lab_model=matlab
-000080c0: 5f6d 6f64 656c 290d 0a20 2020 2020 2020  _model)..       
-000080d0: 2073 656c 662e 666e 616d 6520 3d20 696e   self.fname = in
-000080e0: 7370 6563 742e 6765 7466 696c 6528 696e  spect.getfile(in
-000080f0: 7370 6563 742e 6375 7272 656e 7466 7261  spect.currentfra
-00008100: 6d65 2829 290d 0a0d 0a20 2020 2064 6566  me())....    def
-00008110: 2076 616c 6964 6174 6528 7365 6c66 293a   validate(self):
-00008120: 0d0a 2020 2020 2020 2020 7061 7373 0d0a  ..        pass..
-00008130: 0d0a 2020 2020 6465 6620 7369 6d75 6c61  ..    def simula
-00008140: 7465 2873 656c 662c 2070 726f 6365 7373  te(self, process
-00008150: 5f69 643d 4e6f 6e65 2c20 6d61 746c 6162  _id=None, matlab
-00008160: 5f65 6e67 696e 653d 4e6f 6e65 293a 0d0a  _engine=None):..
-00008170: 0d0a 2020 2020 2020 2020 666f 7220 692c  ..        for i,
-00008180: 206b 6579 2069 6e20 656e 756d 6572 6174   key in enumerat
-00008190: 6528 7365 6c66 2e70 2e6b 6579 7328 2929  e(self.p.keys())
-000081a0: 3a0d 0a20 2020 2020 2020 2020 2020 2069  :..            i
-000081b0: 6620 7479 7065 2873 656c 662e 705b 6b65  f type(self.p[ke
-000081c0: 795d 2920 6973 206e 702e 6e64 6172 7261  y]) is np.ndarra
-000081d0: 793a 0d0a 2020 2020 2020 2020 2020 2020  y:..            
-000081e0: 2020 2073 656c 662e 705b 6b65 795d 203d     self.p[key] =
-000081f0: 2073 656c 662e 705b 6b65 795d 2e66 6c61   self.p[key].fla
-00008200: 7474 656e 2829 0d0a 0d0a 2020 2020 2020  tten()....      
-00008210: 2020 2320 7365 7420 636f 6e73 7461 6e74    # set constant
-00008220: 730d 0a20 2020 2020 2020 2070 203d 2063  s..        p = c
-00008230: 6f70 792e 6465 6570 636f 7079 2873 656c  opy.deepcopy(sel
-00008240: 662e 7029 0d0a 2020 2020 2020 2020 6d20  f.p)..        m 
-00008250: 3d20 7365 6c66 2e70 5b22 6d22 5d0d 0a20  = self.p["m"].. 
-00008260: 2020 2020 2020 2064 656c 2070 5b22 6d22         del p["m"
-00008270: 5d0d 0a0d 0a20 2020 2020 2020 2023 2064  ]....        # d
-00008280: 6574 6572 6d69 6e65 2073 756d 0d0a 2020  etermine sum..  
-00008290: 2020 2020 2020 7920 3d20 6e70 2e7a 6572        y = np.zer
-000082a0: 6f73 286e 702e 6172 7261 7928 7365 6c66  os(np.array(self
-000082b0: 2e70 5b6c 6973 7428 7365 6c66 2e70 2e6b  .p[list(self.p.k
-000082c0: 6579 7328 2929 5b30 5d5d 292e 7369 7a65  eys())[0]]).size
-000082d0: 290d 0a20 2020 2020 2020 206b 6579 7320  )..        keys 
-000082e0: 3d20 6c69 7374 2873 656c 662e 702e 6b65  = list(self.p.ke
-000082f0: 7973 2829 290d 0a0d 0a20 2020 2020 2020  ys())....       
-00008300: 2066 6f72 2069 2c20 6b65 7920 696e 2065   for i, key in e
-00008310: 6e75 6d65 7261 7465 286b 6579 7329 3a0d  numerate(keys):.
-00008320: 0a20 2020 2020 2020 2020 2020 2079 202b  .            y +
-00008330: 3d20 2d20 6e70 2e73 696e 2873 656c 662e  = - np.sin(self.
-00008340: 705b 6b65 795d 2920 2a20 286e 702e 7369  p[key]) * (np.si
-00008350: 6e28 7365 6c66 2e70 5b6b 6579 735b 695d  n(self.p[keys[i]
-00008360: 5d20 2a20 2873 656c 662e 705b 6b65 795d  ] * (self.p[key]
-00008370: 202a 2a20 3229 202f 206e 702e 7069 2929   ** 2) / np.pi))
-00008380: 202a 2a20 2832 202a 206d 290d 0a0d 0a20   ** (2 * m).... 
-00008390: 2020 2020 2020 2079 5f6f 7574 203d 2079         y_out = y
-000083a0: 5b3a 2c20 6e70 2e6e 6577 6178 6973 5d0d  [:, np.newaxis].
-000083b0: 0a0d 0a20 2020 2020 2020 2072 6574 7572  ...        retur
-000083c0: 6e20 795f 6f75 740d 0a0d 0a0d 0a63 6c61  n y_out......cla
-000083d0: 7373 2044 654a 6f6e 6746 756e 6374 696f  ss DeJongFunctio
-000083e0: 6e46 6976 6528 4162 7374 7261 6374 4d6f  nFive(AbstractMo
-000083f0: 6465 6c29 3a0d 0a20 2020 2022 2222 0d0a  del):..    """..
-00008400: 2020 2020 322d 6469 6d65 6e73 696f 6e61      2-dimensiona
-00008410: 6c20 4465 4a6f 6e67 2046 756e 6374 696f  l DeJong Functio
-00008420: 6e20 4e75 6d62 6572 2046 6976 6520 5b31  n Number Five [1
-00008430: 5d5b 325d 2e0d 0a20 2020 2054 6865 2066  ][2]...    The f
-00008440: 6966 7468 2066 756e 6374 696f 6e20 6f66  ifth function of
-00008450: 2044 6520 4a6f 6e67 2069 7320 6d75 6c74   De Jong is mult
-00008460: 696d 6f64 616c 2c20 7769 7468 2076 6572  imodal, with ver
-00008470: 7920 7368 6172 7020 6472 6f70 7320 6f6e  y sharp drops on
-00008480: 2061 206d 6169 6e6c 7920 666c 6174 2073   a mainly flat s
-00008490: 7572 6661 6365 2e0d 0a0d 0a20 2020 202e  urface.....    .
-000084a0: 2e20 6d61 7468 3a3a 0d0a 2020 2020 2020  . math::..      
-000084b0: 7920 3d20 5c5c 6c65 6674 2830 2e30 3032  y = \\left(0.002
-000084c0: 2b5c 5c73 756d 5f7b 692b 317d 5e7b 3235  +\\sum_{i+1}^{25
-000084d0: 7d5c 5c66 7261 637b 317d 7b69 2b28 785f  }\\frac{1}{i+(x_
-000084e0: 312d 615f 7b31 697d 295e 362b 2878 5f32  1-a_{1i})^6+(x_2
-000084f0: 2d61 5f7b 3269 7d29 5e36 7d5c 5c72 6967  -a_{2i})^6}\\rig
-00008500: 6874 295e 7b2d 317d 0d0a 0d0a 2020 2020  ht)^{-1}....    
-00008510: 5061 7261 6d65 7465 7273 0d0a 2020 2020  Parameters..    
-00008520: 2d2d 2d2d 2d2d 2d2d 2d2d 0d0a 2020 2020  ----------..    
-00008530: 705b 2278 3122 5d3a 2066 6c6f 6174 206f  p["x1"]: float o
-00008540: 7220 6e64 6172 7261 7920 6f66 2066 6c6f  r ndarray of flo
-00008550: 6174 205b 6e5f 6772 6964 5d0d 0a20 2020  at [n_grid]..   
-00008560: 2020 2020 2046 6972 7374 2070 6172 616d       First param
-00008570: 6574 6572 2064 6566 696e 6564 2069 6e20  eter defined in 
-00008580: 5b2d 3635 2e35 3336 2c20 3635 2e35 3336  [-65.536, 65.536
-00008590: 5d0d 0a20 2020 2070 5b22 7832 225d 3a20  ]..    p["x2"]: 
-000085a0: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
-000085b0: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
-000085c0: 645d 0d0a 2020 2020 2020 2020 7365 636f  d]..        seco
-000085d0: 6e64 2070 6172 616d 6574 6572 2064 6566  nd parameter def
-000085e0: 696e 6564 2069 6e20 5b2d 3635 2e35 3336  ined in [-65.536
-000085f0: 2c20 3635 2e35 3336 5d0d 0a0d 0a20 2020  , 65.536]....   
-00008600: 2052 6574 7572 6e73 0d0a 2020 2020 2d2d   Returns..    --
-00008610: 2d2d 2d2d 2d0d 0a20 2020 2079 3a20 6e64  -----..    y: nd
-00008620: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
-00008630: 6e5f 6772 6964 2078 2031 5d0d 0a20 2020  n_grid x 1]..   
-00008640: 2020 2020 204f 7574 7075 740d 0a0d 0a20       Output.... 
-00008650: 2020 204e 6f74 6573 0d0a 2020 2020 2d2d     Notes..    --
-00008660: 2d2d 2d0d 0a20 2020 202e 2e20 706c 6f74  ---..    .. plot
-00008670: 3a3a 0d0a 0d0a 2020 2020 2020 2069 6d70  ::....       imp
-00008680: 6f72 7420 6e75 6d70 7920 6173 206e 700d  ort numpy as np.
-00008690: 0a20 2020 2020 2020 6672 6f6d 2070 7967  .       from pyg
-000086a0: 7063 2e74 6573 7466 756e 6374 696f 6e73  pc.testfunctions
-000086b0: 2069 6d70 6f72 7420 706c 6f74 5f74 6573   import plot_tes
-000086c0: 7466 756e 6374 696f 6e20 6173 2070 6c6f  tfunction as plo
-000086d0: 740d 0a20 2020 2020 2020 6672 6f6d 2063  t..       from c
-000086e0: 6f6c 6c65 6374 696f 6e73 2069 6d70 6f72  ollections impor
-000086f0: 7420 4f72 6465 7265 6444 6963 740d 0a0d  t OrderedDict...
-00008700: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
-00008710: 7273 203d 204f 7264 6572 6564 4469 6374  rs = OrderedDict
-00008720: 2829 0d0a 2020 2020 2020 2070 6172 616d  ()..       param
-00008730: 6574 6572 735b 2278 3122 5d20 3d20 6e70  eters["x1"] = np
-00008740: 2e6c 696e 7370 6163 6528 2d36 352e 3533  .linspace(-65.53
-00008750: 362c 2036 352e 3533 362c 2031 3030 290d  6, 65.536, 100).
-00008760: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
-00008770: 7273 5b22 7832 225d 203d 206e 702e 6c69  rs["x2"] = np.li
-00008780: 6e73 7061 6365 282d 3635 2e35 3336 2c20  nspace(-65.536, 
-00008790: 3635 2e35 3336 2c20 3130 3029 0d0a 0d0a  65.536, 100)....
-000087a0: 2020 2020 2020 2063 6f6e 7374 616e 7473         constants
-000087b0: 203d 204e 6f6e 650d 0a0d 0a20 2020 2020   = None....     
-000087c0: 2020 706c 6f74 2822 4465 4a6f 6e67 4675    plot("DeJongFu
-000087d0: 6e63 7469 6f6e 4669 7665 222c 2070 6172  nctionFive", par
-000087e0: 616d 6574 6572 732c 2063 6f6e 7374 616e  ameters, constan
-000087f0: 7473 2c20 706c 6f74 5f33 643d 4661 6c73  ts, plot_3d=Fals
-00008800: 6529 0d0a 0d0a 2020 2020 2e2e 205b 315d  e)....    .. [1]
-00008810: 204d 6f6c 6761 2c20 4d2e 2c20 2620 536d   Molga, M., & Sm
-00008820: 7574 6e69 636b 692c 2043 2e20 5465 7374  utnicki, C. Test
-00008830: 2066 756e 6374 696f 6e73 2066 6f72 206f   functions for o
-00008840: 7074 696d 697a 6174 696f 6e20 6e65 6564  ptimization need
-00008850: 7320 2832 3030 3529 2e0d 0a20 2020 2020  s (2005)...     
-00008860: 2020 5265 7472 6965 7665 6420 4a75 6e65    Retrieved June
-00008870: 2032 3031 332c 2066 726f 6d20 6874 7470   2013, from http
-00008880: 3a2f 2f77 7777 2e7a 7364 2e69 6374 2e70  ://www.zsd.ict.p
-00008890: 7772 2e77 726f 632e 706c 2f66 696c 6573  wr.wroc.pl/files
-000088a0: 2f64 6f63 732f 6675 6e63 7469 6f6e 732e  /docs/functions.
-000088b0: 7064 662e 0d0a 2020 2020 2e2e 205b 325d  pdf...    .. [2]
-000088c0: 2068 7474 7073 3a2f 2f77 7777 2e73 6675   https://www.sfu
-000088d0: 2e63 612f 7e73 7375 726a 616e 6f2f 6465  .ca/~ssurjano/de
-000088e0: 6a6f 6e67 352e 6874 6d6c 0d0a 0d0a 2020  jong5.html....  
-000088f0: 2020 2222 220d 0a0d 0a20 2020 2064 6566    """....    def
-00008900: 205f 5f69 6e69 745f 5f28 7365 6c66 2c20   __init__(self, 
-00008910: 6d61 746c 6162 5f6d 6f64 656c 3d46 616c  matlab_model=Fal
-00008920: 7365 293a 0d0a 2020 2020 2020 2020 7375  se):..        su
-00008930: 7065 7228 7479 7065 2873 656c 6629 2c20  per(type(self), 
-00008940: 7365 6c66 292e 5f5f 696e 6974 5f5f 286d  self).__init__(m
-00008950: 6174 6c61 625f 6d6f 6465 6c3d 6d61 746c  atlab_model=matl
-00008960: 6162 5f6d 6f64 656c 290d 0a20 2020 2020  ab_model)..     
-00008970: 2020 2073 656c 662e 666e 616d 6520 3d20     self.fname = 
-00008980: 696e 7370 6563 742e 6765 7466 696c 6528  inspect.getfile(
-00008990: 696e 7370 6563 742e 6375 7272 656e 7466  inspect.currentf
-000089a0: 7261 6d65 2829 290d 0a0d 0a20 2020 2064  rame())....    d
-000089b0: 6566 2076 616c 6964 6174 6528 7365 6c66  ef validate(self
-000089c0: 293a 0d0a 2020 2020 2020 2020 7061 7373  ):..        pass
-000089d0: 0d0a 0d0a 2020 2020 6465 6620 7369 6d75  ....    def simu
-000089e0: 6c61 7465 2873 656c 662c 2070 726f 6365  late(self, proce
-000089f0: 7373 5f69 643d 4e6f 6e65 2c20 6d61 746c  ss_id=None, matl
-00008a00: 6162 5f65 6e67 696e 653d 4e6f 6e65 293a  ab_engine=None):
-00008a10: 0d0a 0d0a 2020 2020 2020 2020 666f 7220  ....        for 
-00008a20: 692c 206b 6579 2069 6e20 656e 756d 6572  i, key in enumer
-00008a30: 6174 6528 7365 6c66 2e70 2e6b 6579 7328  ate(self.p.keys(
-00008a40: 2929 3a0d 0a20 2020 2020 2020 2020 2020  )):..           
-00008a50: 2069 6620 7479 7065 2873 656c 662e 705b   if type(self.p[
-00008a60: 6b65 795d 2920 6973 206e 702e 6e64 6172  key]) is np.ndar
-00008a70: 7261 793a 0d0a 2020 2020 2020 2020 2020  ray:..          
-00008a80: 2020 2020 2073 656c 662e 705b 6b65 795d       self.p[key]
-00008a90: 203d 2073 656c 662e 705b 6b65 795d 2e66   = self.p[key].f
-00008aa0: 6c61 7474 656e 2829 0d0a 0d0a 2020 2020  latten()....    
-00008ab0: 2020 2020 2320 7365 7420 636f 6e73 7461      # set consta
-00008ac0: 6e74 730d 0a20 2020 2020 2020 2073 6571  nts..        seq
-00008ad0: 203d 205b 2d33 322c 202d 3136 2c20 302c   = [-32, -16, 0,
-00008ae0: 2031 362c 2033 325d 0d0a 2020 2020 2020   16, 32]..      
-00008af0: 2020 6120 3d20 6e70 2e61 7272 6179 285b    a = np.array([
-00008b00: 7365 7120 2a20 352c 206e 702e 6873 7461  seq * 5, np.hsta
-00008b10: 636b 285b 5b69 5d20 2a20 3520 666f 7220  ck([[i] * 5 for 
-00008b20: 6920 696e 2073 6571 5d29 5d29 0d0a 2020  i in seq])])..  
-00008b30: 2020 2020 2020 7331 203d 206e 702e 7a65        s1 = np.ze
-00008b40: 726f 7328 6e70 2e61 7272 6179 2873 656c  ros(np.array(sel
-00008b50: 662e 705b 6c69 7374 2873 656c 662e 702e  f.p[list(self.p.
-00008b60: 6b65 7973 2829 295b 305d 5d29 2e73 697a  keys())[0]]).siz
-00008b70: 6529 0d0a 2020 2020 2020 2020 6b65 7973  e)..        keys
-00008b80: 203d 206c 6973 7428 7365 6c66 2e70 2e6b   = list(self.p.k
-00008b90: 6579 7328 2929 0d0a 0d0a 2020 2020 2020  eys())....      
-00008ba0: 2020 2320 6465 7465 726d 696e 6520 7375    # determine su
-00008bb0: 6d0d 0a20 2020 2020 2020 2066 6f72 2069  m..        for i
-00008bc0: 2069 6e20 7261 6e67 6528 3235 293a 0d0a   in range(25):..
-00008bd0: 2020 2020 2020 2020 2020 2020 7331 202b              s1 +
-00008be0: 3d20 3120 2f20 2869 2b31 202b 2028 7365  = 1 / (i+1 + (se
-00008bf0: 6c66 2e70 5b6b 6579 735b 305d 5d20 2d20  lf.p[keys[0]] - 
-00008c00: 615b 302c 2069 5d29 202a 2a20 3620 2b20  a[0, i]) ** 6 + 
-00008c10: 2873 656c 662e 705b 6b65 7973 5b31 5d5d  (self.p[keys[1]]
-00008c20: 202d 2061 5b31 2c20 695d 2920 2a2a 2036   - a[1, i]) ** 6
-00008c30: 290d 0a0d 0a20 2020 2020 2020 2079 203d  )....        y =
-00008c40: 2031 202f 2028 302e 3030 3220 2b20 7331   1 / (0.002 + s1
-00008c50: 290d 0a0d 0a20 2020 2020 2020 2079 5f6f  )....        y_o
-00008c60: 7574 203d 2079 5b3a 2c20 6e70 2e6e 6577  ut = y[:, np.new
-00008c70: 6178 6973 5d0d 0a0d 0a20 2020 2020 2020  axis]....       
-00008c80: 2072 6574 7572 6e20 795f 6f75 740d 0a0d   return y_out...
-00008c90: 0a0d 0a63 6c61 7373 204d 6174 7961 7346  ...class MatyasF
-00008ca0: 756e 6374 696f 6e28 4162 7374 7261 6374  unction(Abstract
-00008cb0: 4d6f 6465 6c29 3a0d 0a20 2020 2022 2222  Model):..    """
-00008cc0: 0d0a 2020 2020 322d 6469 6d65 6e73 696f  ..    2-dimensio
-00008cd0: 6e61 6c20 4d61 7479 6173 2066 756e 6374  nal Matyas funct
-00008ce0: 696f 6e20 5b31 5d5b 325d 2e0d 0a20 2020  ion [1][2]...   
-00008cf0: 2054 6865 204d 6174 7961 7320 6675 6e63   The Matyas func
-00008d00: 7469 6f6e 2068 6173 206e 6f20 6c6f 6361  tion has no loca
-00008d10: 6c20 6d69 6e69 6d61 2065 7863 6570 7420  l minima except 
-00008d20: 7468 6520 676c 6f62 616c 206f 6e65 2e0d  the global one..
-00008d30: 0a0d 0a20 2020 202e 2e20 6d61 7468 3a3a  ...    .. math::
-00008d40: 0d0a 2020 2020 2020 7920 3d20 302e 3236  ..      y = 0.26
-00008d50: 2878 5f31 5e32 2b78 5f32 5e32 292d 302e  (x_1^2+x_2^2)-0.
-00008d60: 3438 785f 3178 5f32 0d0a 0d0a 2020 2020  48x_1x_2....    
-00008d70: 5061 7261 6d65 7465 7273 0d0a 2020 2020  Parameters..    
-00008d80: 2d2d 2d2d 2d2d 2d2d 2d2d 0d0a 2020 2020  ----------..    
-00008d90: 705b 2278 3122 5d3a 2066 6c6f 6174 206f  p["x1"]: float o
-00008da0: 7220 6e64 6172 7261 7920 6f66 2066 6c6f  r ndarray of flo
-00008db0: 6174 205b 6e5f 6772 6964 5d0d 0a20 2020  at [n_grid]..   
-00008dc0: 2020 2020 2046 6972 7374 2070 6172 616d       First param
-00008dd0: 6574 6572 2064 6566 696e 6564 2069 6e20  eter defined in 
-00008de0: 5b2d 3130 2c20 3130 5d0d 0a20 2020 2070  [-10, 10]..    p
-00008df0: 5b22 7832 225d 3a20 666c 6f61 7420 6f72  ["x2"]: float or
-00008e00: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-00008e10: 7420 5b6e 5f67 7269 645d 0d0a 2020 2020  t [n_grid]..    
-00008e20: 2020 2020 7365 636f 6e64 2070 6172 616d      second param
-00008e30: 6574 6572 2064 6566 696e 6564 2069 6e20  eter defined in 
-00008e40: 5b2d 3130 2c20 3130 5d0d 0a0d 0a20 2020  [-10, 10]....   
-00008e50: 2052 6574 7572 6e73 0d0a 2020 2020 2d2d   Returns..    --
-00008e60: 2d2d 2d2d 2d0d 0a20 2020 2079 3a20 6e64  -----..    y: nd
-00008e70: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
-00008e80: 6e5f 6772 6964 2078 2031 5d0d 0a20 2020  n_grid x 1]..   
-00008e90: 2020 2020 204f 7574 7075 740d 0a0d 0a20       Output.... 
-00008ea0: 2020 204e 6f74 6573 0d0a 2020 2020 2d2d     Notes..    --
-00008eb0: 2d2d 2d0d 0a20 2020 202e 2e20 706c 6f74  ---..    .. plot
-00008ec0: 3a3a 0d0a 0d0a 2020 2020 2020 2069 6d70  ::....       imp
-00008ed0: 6f72 7420 6e75 6d70 7920 6173 206e 700d  ort numpy as np.
-00008ee0: 0a20 2020 2020 2020 6672 6f6d 2070 7967  .       from pyg
-00008ef0: 7063 2e74 6573 7466 756e 6374 696f 6e73  pc.testfunctions
-00008f00: 2069 6d70 6f72 7420 706c 6f74 5f74 6573   import plot_tes
-00008f10: 7466 756e 6374 696f 6e20 6173 2070 6c6f  tfunction as plo
-00008f20: 740d 0a20 2020 2020 2020 6672 6f6d 2063  t..       from c
-00008f30: 6f6c 6c65 6374 696f 6e73 2069 6d70 6f72  ollections impor
-00008f40: 7420 4f72 6465 7265 6444 6963 740d 0a0d  t OrderedDict...
-00008f50: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
-00008f60: 7273 203d 204f 7264 6572 6564 4469 6374  rs = OrderedDict
-00008f70: 2829 0d0a 2020 2020 2020 2070 6172 616d  ()..       param
-00008f80: 6574 6572 735b 2278 3122 5d20 3d20 6e70  eters["x1"] = np
-00008f90: 2e6c 696e 7370 6163 6528 2d31 302c 2031  .linspace(-10, 1
-00008fa0: 302c 2031 3030 290d 0a20 2020 2020 2020  0, 100)..       
-00008fb0: 7061 7261 6d65 7465 7273 5b22 7832 225d  parameters["x2"]
-00008fc0: 203d 206e 702e 6c69 6e73 7061 6365 282d   = np.linspace(-
-00008fd0: 3130 2c20 3130 2c20 3130 3029 0d0a 0d0a  10, 10, 100)....
-00008fe0: 2020 2020 2020 2063 6f6e 7374 616e 7473         constants
-00008ff0: 203d 204e 6f6e 650d 0a0d 0a20 2020 2020   = None....     
-00009000: 2020 706c 6f74 2822 4d61 7479 6173 4675    plot("MatyasFu
-00009010: 6e63 7469 6f6e 222c 2070 6172 616d 6574  nction", paramet
-00009020: 6572 732c 2063 6f6e 7374 616e 7473 2c20  ers, constants, 
-00009030: 706c 6f74 5f33 643d 4661 6c73 6529 0d0a  plot_3d=False)..
-00009040: 0d0a 2020 2020 2e2e 205b 315d 2047 6c6f  ..    .. [1] Glo
-00009050: 6261 6c20 4f70 7469 6d69 7a61 7469 6f6e  bal Optimization
-00009060: 2054 6573 7420 5072 6f62 6c65 6d73 2e20   Test Problems. 
-00009070: 5265 7472 6965 7665 6420 4a75 6e65 2032  Retrieved June 2
-00009080: 3031 332c 2066 726f 6d0d 0a20 2020 2020  013, from..     
-00009090: 2020 6874 7470 3a2f 2f77 7777 2d6f 7074    http://www-opt
-000090a0: 696d 612e 616d 702e 692e 6b79 6f74 6f2d  ima.amp.i.kyoto-
-000090b0: 752e 6163 2e6a 702f 6d65 6d62 6572 2f73  u.ac.jp/member/s
-000090c0: 7475 6465 6e74 2f68 6564 6172 2f48 6564  tudent/hedar/Hed
-000090d0: 6172 5f66 696c 6573 2f54 6573 7447 4f2e  ar_files/TestGO.
-000090e0: 6874 6d2e 0d0a 0d0a 2020 2020 2e2e 205b  htm.....    .. [
-000090f0: 325d 2068 7474 7073 3a2f 2f77 7777 2e73  2] https://www.s
-00009100: 6675 2e63 612f 7e73 7375 726a 616e 6f2f  fu.ca/~ssurjano/
-00009110: 6d61 7479 612e 6874 6d6c 0d0a 2020 2020  matya.html..    
-00009120: 2222 220d 0a0d 0a20 2020 2064 6566 205f  """....    def _
-00009130: 5f69 6e69 745f 5f28 7365 6c66 2c20 6d61  _init__(self, ma
-00009140: 746c 6162 5f6d 6f64 656c 3d46 616c 7365  tlab_model=False
-00009150: 293a 0d0a 2020 2020 2020 2020 7375 7065  ):..        supe
-00009160: 7228 7479 7065 2873 656c 6629 2c20 7365  r(type(self), se
-00009170: 6c66 292e 5f5f 696e 6974 5f5f 286d 6174  lf).__init__(mat
-00009180: 6c61 625f 6d6f 6465 6c3d 6d61 746c 6162  lab_model=matlab
-00009190: 5f6d 6f64 656c 290d 0a20 2020 2020 2020  _model)..       
-000091a0: 2073 656c 662e 666e 616d 6520 3d20 696e   self.fname = in
-000091b0: 7370 6563 742e 6765 7466 696c 6528 696e  spect.getfile(in
-000091c0: 7370 6563 742e 6375 7272 656e 7466 7261  spect.currentfra
-000091d0: 6d65 2829 290d 0a0d 0a20 2020 2064 6566  me())....    def
-000091e0: 2076 616c 6964 6174 6528 7365 6c66 293a   validate(self):
-000091f0: 0d0a 2020 2020 2020 2020 7061 7373 0d0a  ..        pass..
-00009200: 0d0a 2020 2020 6465 6620 7369 6d75 6c61  ..    def simula
-00009210: 7465 2873 656c 662c 2070 726f 6365 7373  te(self, process
-00009220: 5f69 643d 4e6f 6e65 2c20 6d61 746c 6162  _id=None, matlab
-00009230: 5f65 6e67 696e 653d 4e6f 6e65 293a 0d0a  _engine=None):..
-00009240: 0d0a 2020 2020 2020 2020 7920 3d20 302e  ..        y = 0.
-00009250: 3236 202a 2028 7365 6c66 2e70 5b22 7831  26 * (self.p["x1
-00009260: 225d 202a 2a20 3220 2b20 7365 6c66 2e70  "] ** 2 + self.p
-00009270: 5b22 7832 225d 202a 2a20 3229 202d 2030  ["x2"] ** 2) - 0
-00009280: 2e34 3820 2a20 7365 6c66 2e70 5b22 7831  .48 * self.p["x1
-00009290: 225d 202a 2073 656c 662e 705b 2278 3222  "] * self.p["x2"
-000092a0: 5d0d 0a0d 0a20 2020 2020 2020 2079 5f6f  ]....        y_o
-000092b0: 7574 203d 2079 5b3a 2c20 6e70 2e6e 6577  ut = y[:, np.new
-000092c0: 6178 6973 5d0d 0a0d 0a20 2020 2020 2020  axis]....       
-000092d0: 2072 6574 7572 6e20 795f 6f75 740d 0a0d   return y_out...
-000092e0: 0a0d 0a63 6c61 7373 2047 7261 6d61 6379  ...class Gramacy
-000092f0: 4c65 6546 756e 6374 696f 6e28 4162 7374  LeeFunction(Abst
-00009300: 7261 6374 4d6f 6465 6c29 3a0d 0a20 2020  ractModel):..   
-00009310: 2022 2222 0d0a 2020 2020 312d 6469 6d65   """..    1-dime
-00009320: 6e73 696f 6e61 6c20 4772 616d 6163 7920  nsional Gramacy 
-00009330: 616e 6420 4c65 6520 6675 6e63 7469 6f6e  and Lee function
-00009340: 5b31 5d5b 325d 5b33 5d2e 0d0a 2020 2020  [1][2][3]...    
-00009350: 5468 6973 2069 7320 6120 7369 6d70 6c65  This is a simple
-00009360: 206f 6e65 2d64 696d 656e 7369 6f6e 616c   one-dimensional
-00009370: 2074 6573 7420 6675 6e63 7469 6f6e 2e0d   test function..
-00009380: 0a0d 0a20 2020 202e 2e20 6d61 7468 3a3a  ...    .. math::
-00009390: 0d0a 2020 2020 2020 7920 3d20 5c5c 6672  ..      y = \\fr
-000093a0: 6163 7b5c 5c73 696e 2831 3020 5c5c 7069  ac{\\sin(10 \\pi
-000093b0: 2078 297d 7b32 787d 2b28 782d 3129 5e34   x)}{2x}+(x-1)^4
-000093c0: 0d0a 0d0a 2020 2020 5061 7261 6d65 7465  ....    Paramete
-000093d0: 7273 0d0a 2020 2020 2d2d 2d2d 2d2d 2d2d  rs..    --------
-000093e0: 2d2d 0d0a 2020 2020 705b 2278 3122 5d3a  --..    p["x1"]:
-000093f0: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
-00009400: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
-00009410: 6964 5d0d 0a20 2020 2020 2020 2046 6972  id]..        Fir
-00009420: 7374 2070 6172 616d 6574 6572 2064 6566  st parameter def
-00009430: 696e 6564 2069 6e20 5b30 2e35 2c20 322e  ined in [0.5, 2.
-00009440: 355d 0d0a 2020 2020 705b 2278 3222 5d3a  5]..    p["x2"]:
-00009450: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
-00009460: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
-00009470: 6964 5d0d 0a20 2020 2020 2020 2073 6563  id]..        sec
-00009480: 6f6e 6420 7061 7261 6d65 7465 7220 6465  ond parameter de
-00009490: 6669 6e65 6420 696e 205b 302e 352c 2032  fined in [0.5, 2
-000094a0: 2e35 5d0d 0a0d 0a20 2020 2052 6574 7572  .5]....    Retur
-000094b0: 6e73 0d0a 2020 2020 2d2d 2d2d 2d2d 2d0d  ns..    -------.
-000094c0: 0a20 2020 2079 3a20 6e64 6172 7261 7920  .    y: ndarray 
-000094d0: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
-000094e0: 2078 2031 5d0d 0a20 2020 2020 2020 204f   x 1]..        O
-000094f0: 7574 7075 740d 0a0d 0a20 2020 204e 6f74  utput....    Not
-00009500: 6573 0d0a 2020 2020 2d2d 2d2d 2d0d 0a20  es..    -----.. 
-00009510: 2020 202e 2e20 706c 6f74 3a3a 0d0a 0d0a     .. plot::....
-00009520: 2020 2020 2020 2069 6d70 6f72 7420 6e75         import nu
-00009530: 6d70 7920 6173 206e 700d 0a20 2020 2020  mpy as np..     
-00009540: 2020 6672 6f6d 2070 7967 7063 2e74 6573    from pygpc.tes
-00009550: 7466 756e 6374 696f 6e73 2069 6d70 6f72  tfunctions impor
-00009560: 7420 706c 6f74 5f74 6573 7466 756e 6374  t plot_testfunct
-00009570: 696f 6e20 6173 2070 6c6f 740d 0a20 2020  ion as plot..   
-00009580: 2020 2020 6672 6f6d 2063 6f6c 6c65 6374      from collect
-00009590: 696f 6e73 2069 6d70 6f72 7420 4f72 6465  ions import Orde
-000095a0: 7265 6444 6963 740d 0a0d 0a20 2020 2020  redDict....     
-000095b0: 2020 7061 7261 6d65 7465 7273 203d 204f    parameters = O
-000095c0: 7264 6572 6564 4469 6374 2829 0d0a 2020  rderedDict()..  
-000095d0: 2020 2020 2070 6172 616d 6574 6572 735b       parameters[
-000095e0: 2278 3122 5d20 3d20 6e70 2e6c 696e 7370  "x1"] = np.linsp
-000095f0: 6163 6528 302e 352c 2032 2e35 2c20 3130  ace(0.5, 2.5, 10
-00009600: 3029 0d0a 2020 2020 2020 2070 6172 616d  0)..       param
-00009610: 6574 6572 735b 2278 3222 5d20 3d20 6e70  eters["x2"] = np
-00009620: 2e6c 696e 7370 6163 6528 302e 352c 2032  .linspace(0.5, 2
-00009630: 2e35 2c20 3130 3029 0d0a 0d0a 2020 2020  .5, 100)....    
-00009640: 2020 2063 6f6e 7374 616e 7473 203d 204e     constants = N
-00009650: 6f6e 650d 0a0d 0a20 2020 2020 2020 706c  one....       pl
-00009660: 6f74 2822 4772 616d 6163 794c 6565 4675  ot("GramacyLeeFu
-00009670: 6e63 7469 6f6e 222c 2070 6172 616d 6574  nction", paramet
-00009680: 6572 732c 2063 6f6e 7374 616e 7473 2c20  ers, constants, 
-00009690: 706c 6f74 5f33 643d 4661 6c73 6529 0d0a  plot_3d=False)..
-000096a0: 0d0a 2020 2020 2e2e 205b 315d 2047 7261  ..    .. [1] Gra
-000096b0: 6d61 6379 2c20 522e 2042 2e2c 2026 204c  macy, R. B., & L
-000096c0: 6565 2c20 482e 204b 2e20 2832 3031 3229  ee, H. K. (2012)
-000096d0: 2e20 4361 7365 7320 666f 7220 7468 6520  . Cases for the 
-000096e0: 6e75 6767 6574 2069 6e20 6d6f 6465 6c69  nugget in modeli
-000096f0: 6e67 2063 6f6d 7075 7465 7220 6578 7065  ng computer expe
-00009700: 7269 6d65 6e74 732e 0d0a 2020 2020 2020  riments...      
-00009710: 2053 7461 7469 7374 6963 7320 616e 6420   Statistics and 
-00009720: 436f 6d70 7574 696e 672c 2032 3228 3329  Computing, 22(3)
-00009730: 2c20 3731 332d 3732 322e 0d0a 0d0a 2020  , 713-722.....  
-00009740: 2020 2e2e 205b 325d 2052 616e 6a61 6e2c    .. [2] Ranjan,
-00009750: 2050 2e20 2832 3031 3329 2e20 436f 6d6d   P. (2013). Comm
-00009760: 656e 743a 2045 4920 4372 6974 6572 6961  ent: EI Criteria
-00009770: 2066 6f72 204e 6f69 7379 2043 6f6d 7075   for Noisy Compu
-00009780: 7465 7220 5369 6d75 6c61 746f 7273 2e20  ter Simulators. 
-00009790: 5465 6368 6e6f 6d65 7472 6963 732c 2035  Technometrics, 5
-000097a0: 3528 3129 2c20 3234 2d32 382e 0d0a 0d0a  5(1), 24-28.....
-000097b0: 2020 2020 2e2e 205b 335d 2068 7474 7073      .. [3] https
-000097c0: 3a2f 2f77 7777 2e73 6675 2e63 612f 7e73  ://www.sfu.ca/~s
-000097d0: 7375 726a 616e 6f2f 6772 6c65 6531 322e  surjano/grlee12.
-000097e0: 6874 6d6c 0d0a 0d0a 2020 2020 2222 220d  html....    """.
-000097f0: 0a0d 0a20 2020 2064 6566 205f 5f69 6e69  ...    def __ini
-00009800: 745f 5f28 7365 6c66 2c20 6d61 746c 6162  t__(self, matlab
-00009810: 5f6d 6f64 656c 3d46 616c 7365 293a 0d0a  _model=False):..
-00009820: 2020 2020 2020 2020 7375 7065 7228 7479          super(ty
-00009830: 7065 2873 656c 6629 2c20 7365 6c66 292e  pe(self), self).
-00009840: 5f5f 696e 6974 5f5f 286d 6174 6c61 625f  __init__(matlab_
-00009850: 6d6f 6465 6c3d 6d61 746c 6162 5f6d 6f64  model=matlab_mod
-00009860: 656c 290d 0a20 2020 2020 2020 2073 656c  el)..        sel
-00009870: 662e 666e 616d 6520 3d20 696e 7370 6563  f.fname = inspec
-00009880: 742e 6765 7466 696c 6528 696e 7370 6563  t.getfile(inspec
-00009890: 742e 6375 7272 656e 7466 7261 6d65 2829  t.currentframe()
-000098a0: 290d 0a0d 0a20 2020 2064 6566 2076 616c  )....    def val
-000098b0: 6964 6174 6528 7365 6c66 293a 0d0a 2020  idate(self):..  
-000098c0: 2020 2020 2020 7061 7373 0d0a 0d0a 2020        pass....  
-000098d0: 2020 6465 6620 7369 6d75 6c61 7465 2873    def simulate(s
-000098e0: 656c 662c 2070 726f 6365 7373 5f69 643d  elf, process_id=
-000098f0: 4e6f 6e65 2c20 6d61 746c 6162 5f65 6e67  None, matlab_eng
-00009900: 696e 653d 4e6f 6e65 293a 0d0a 0d0a 2020  ine=None):....  
-00009910: 2020 2020 2020 7920 3d20 286e 702e 7369        y = (np.si
-00009920: 6e28 3130 202a 206e 702e 7069 202a 2073  n(10 * np.pi * s
-00009930: 656c 662e 705b 2278 3122 5d29 202f 2032  elf.p["x1"]) / 2
-00009940: 202a 2073 656c 662e 705b 2278 3122 5d29   * self.p["x1"])
-00009950: 202b 2028 7365 6c66 2e70 5b22 7831 225d   + (self.p["x1"]
-00009960: 202d 2031 2920 2a2a 2034 0d0a 0d0a 2020   - 1) ** 4....  
-00009970: 2020 2020 2020 795f 6f75 7420 3d20 795b        y_out = y[
-00009980: 3a2c 206e 702e 6e65 7761 7869 735d 0d0a  :, np.newaxis]..
-00009990: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-000099a0: 2079 5f6f 7574 0d0a 0d0a 0d0a 636c 6173   y_out......clas
-000099b0: 7320 5363 6861 6666 6572 4675 6e63 7469  s SchafferFuncti
-000099c0: 6f6e 3428 4162 7374 7261 6374 4d6f 6465  on4(AbstractMode
-000099d0: 6c29 3a0d 0a20 2020 2022 2222 0d0a 2020  l):..    """..  
-000099e0: 2020 322d 6469 6d65 6e73 696f 6e61 6c20    2-dimensional 
-000099f0: 5363 6861 6666 6572 2066 756e 6374 696f  Schaffer functio
-00009a00: 6e20 4e6f 2e20 342e 205b 315d 5b32 5d2e  n No. 4. [1][2].
-00009a10: 0d0a 0d0a 2020 2020 2e2e 206d 6174 683a  ....    .. math:
-00009a20: 3a0d 0a20 2020 2020 2079 203d 2030 2e35  :..      y = 0.5
-00009a30: 2b5c 5c66 7261 637b 5c5c 636f 737b 285c  +\\frac{\\cos{(\
-00009a40: 5c73 696e 7b28 5c6d 6964 2078 5f31 5e32  \sin{(\mid x_1^2
-00009a50: 2d78 5f32 5e32 205c 6d69 6420 297d 297d  -x_2^2 \mid )})}
-00009a60: 2d30 2e35 7d7b 2831 2b30 2e30 3031 2878  -0.5}{(1+0.001(x
-00009a70: 5f31 5e32 2b78 5f32 5e32 2929 5e32 7d0d  _1^2+x_2^2))^2}.
-00009a80: 0a0d 0a20 2020 2050 6172 616d 6574 6572  ...    Parameter
-00009a90: 730d 0a20 2020 202d 2d2d 2d2d 2d2d 2d2d  s..    ---------
-00009aa0: 2d0d 0a20 2020 2070 5b22 7831 225d 3a20  -..    p["x1"]: 
-00009ab0: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
-00009ac0: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
-00009ad0: 645d 0d0a 2020 2020 2020 2020 4669 7273  d]..        Firs
-00009ae0: 7420 7061 7261 6d65 7465 7220 6465 6669  t parameter defi
-00009af0: 6e65 6420 696e 205b 2d31 3030 2c20 3130  ned in [-100, 10
-00009b00: 305d 0d0a 2020 2020 705b 2278 3222 5d3a  0]..    p["x2"]:
-00009b10: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
-00009b20: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
-00009b30: 6964 5d0d 0a20 2020 2020 2020 2073 6563  id]..        sec
-00009b40: 6f6e 6420 7061 7261 6d65 7465 7220 6465  ond parameter de
-00009b50: 6669 6e65 6420 696e 205b 2d31 3030 2c20  fined in [-100, 
-00009b60: 3130 305d 0d0a 0d0a 2020 2020 5265 7475  100]....    Retu
-00009b70: 726e 730d 0a20 2020 202d 2d2d 2d2d 2d2d  rns..    -------
-00009b80: 0d0a 2020 2020 793a 206e 6461 7272 6179  ..    y: ndarray
-00009b90: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
-00009ba0: 6420 7820 315d 0d0a 2020 2020 2020 2020  d x 1]..        
-00009bb0: 4f75 7470 7574 0d0a 0d0a 2020 2020 4e6f  Output....    No
-00009bc0: 7465 730d 0a20 2020 202d 2d2d 2d2d 0d0a  tes..    -----..
-00009bd0: 2020 2020 2e2e 2070 6c6f 743a 3a0d 0a0d      .. plot::...
-00009be0: 0a20 2020 2020 2020 696d 706f 7274 206e  .       import n
-00009bf0: 756d 7079 2061 7320 6e70 0d0a 2020 2020  umpy as np..    
-00009c00: 2020 2066 726f 6d20 7079 6770 632e 7465     from pygpc.te
-00009c10: 7374 6675 6e63 7469 6f6e 7320 696d 706f  stfunctions impo
-00009c20: 7274 2070 6c6f 745f 7465 7374 6675 6e63  rt plot_testfunc
-00009c30: 7469 6f6e 2061 7320 706c 6f74 0d0a 2020  tion as plot..  
-00009c40: 2020 2020 2066 726f 6d20 636f 6c6c 6563       from collec
-00009c50: 7469 6f6e 7320 696d 706f 7274 204f 7264  tions import Ord
-00009c60: 6572 6564 4469 6374 0d0a 0d0a 2020 2020  eredDict....    
-00009c70: 2020 2070 6172 616d 6574 6572 7320 3d20     parameters = 
-00009c80: 4f72 6465 7265 6444 6963 7428 290d 0a20  OrderedDict().. 
-00009c90: 2020 2020 2020 7061 7261 6d65 7465 7273        parameters
-00009ca0: 5b22 7831 225d 203d 206e 702e 6c69 6e73  ["x1"] = np.lins
-00009cb0: 7061 6365 282d 3130 302c 2031 3030 2c20  pace(-100, 100, 
-00009cc0: 3130 3029 0d0a 2020 2020 2020 2070 6172  100)..       par
-00009cd0: 616d 6574 6572 735b 2278 3222 5d20 3d20  ameters["x2"] = 
-00009ce0: 6e70 2e6c 696e 7370 6163 6528 2d31 3030  np.linspace(-100
-00009cf0: 2c20 3130 302c 2031 3030 290d 0a0d 0a20  , 100, 100).... 
-00009d00: 2020 2020 2020 636f 6e73 7461 6e74 7320        constants 
-00009d10: 3d20 4e6f 6e65 0d0a 0d0a 2020 2020 2020  = None....      
-00009d20: 2070 6c6f 7428 2253 6368 6166 6665 7246   plot("SchafferF
-00009d30: 756e 6374 696f 6e34 222c 2070 6172 616d  unction4", param
-00009d40: 6574 6572 732c 2063 6f6e 7374 616e 7473  eters, constants
-00009d50: 2c20 706c 6f74 5f33 643d 4661 6c73 6529  , plot_3d=False)
-00009d60: 0d0a 0d0a 2020 2020 2e2e 205b 315d 2054  ....    .. [1] T
-00009d70: 6573 7420 6675 6e63 7469 6f6e 7320 666f  est functions fo
-00009d80: 7220 6f70 7469 6d69 7a61 7469 6f6e 2e20  r optimization. 
-00009d90: 496e 2057 696b 6970 6564 6961 2e0d 0a20  In Wikipedia... 
-00009da0: 2020 2020 2020 5265 7472 6965 7665 6420        Retrieved 
-00009db0: 4a75 6e65 2032 3031 332c 2066 726f 6d20  June 2013, from 
-00009dc0: 6874 7470 733a 2f2f 656e 2e77 696b 6970  https://en.wikip
-00009dd0: 6564 6961 2e6f 7267 2f77 696b 692f 5465  edia.org/wiki/Te
-00009de0: 7374 5f66 756e 6374 696f 6e73 5f66 6f72  st_functions_for
-00009df0: 5f6f 7074 696d 697a 6174 696f 6e2e 0d0a  _optimization...
-00009e00: 0d0a 2020 2020 2e2e 205b 325d 2068 7474  ..    .. [2] htt
-00009e10: 7073 3a2f 2f77 7777 2e73 6675 2e63 612f  ps://www.sfu.ca/
-00009e20: 7e73 7375 726a 616e 6f2f 7363 6861 6666  ~ssurjano/schaff
-00009e30: 6572 342e 6874 6d6c 0d0a 2020 2020 2222  er4.html..    ""
-00009e40: 220d 0a0d 0a20 2020 2064 6566 205f 5f69  "....    def __i
-00009e50: 6e69 745f 5f28 7365 6c66 2c20 6d61 746c  nit__(self, matl
-00009e60: 6162 5f6d 6f64 656c 3d46 616c 7365 293a  ab_model=False):
-00009e70: 0d0a 2020 2020 2020 2020 7375 7065 7228  ..        super(
-00009e80: 7479 7065 2873 656c 6629 2c20 7365 6c66  type(self), self
-00009e90: 292e 5f5f 696e 6974 5f5f 286d 6174 6c61  ).__init__(matla
-00009ea0: 625f 6d6f 6465 6c3d 6d61 746c 6162 5f6d  b_model=matlab_m
-00009eb0: 6f64 656c 290d 0a20 2020 2020 2020 2073  odel)..        s
-00009ec0: 656c 662e 666e 616d 6520 3d20 696e 7370  elf.fname = insp
-00009ed0: 6563 742e 6765 7466 696c 6528 696e 7370  ect.getfile(insp
-00009ee0: 6563 742e 6375 7272 656e 7466 7261 6d65  ect.currentframe
-00009ef0: 2829 290d 0a0d 0a20 2020 2064 6566 2076  ())....    def v
-00009f00: 616c 6964 6174 6528 7365 6c66 293a 0d0a  alidate(self):..
-00009f10: 2020 2020 2020 2020 7061 7373 0d0a 0d0a          pass....
-00009f20: 2020 2020 6465 6620 7369 6d75 6c61 7465      def simulate
-00009f30: 2873 656c 662c 2070 726f 6365 7373 5f69  (self, process_i
-00009f40: 643d 4e6f 6e65 2c20 6d61 746c 6162 5f65  d=None, matlab_e
-00009f50: 6e67 696e 653d 4e6f 6e65 293a 0d0a 0d0a  ngine=None):....
-00009f60: 2020 2020 2020 2020 7920 3d20 302e 3520          y = 0.5 
-00009f70: 2b20 286e 702e 636f 7328 6e70 2e73 696e  + (np.cos(np.sin
-00009f80: 286e 702e 6162 7328 7365 6c66 2e70 5b22  (np.abs(self.p["
-00009f90: 7831 225d 202a 2a20 3220 2d20 7365 6c66  x1"] ** 2 - self
-00009fa0: 2e70 5b22 7832 225d 202a 2a20 3229 2929  .p["x2"] ** 2)))
-00009fb0: 202d 2030 2e35 2920 2f5c 0d0a 2020 2020   - 0.5) /\..    
-00009fc0: 2020 2020 2020 2020 2831 202b 2030 2e30          (1 + 0.0
-00009fd0: 3031 202a 2028 7365 6c66 2e70 5b22 7831  01 * (self.p["x1
-00009fe0: 225d 202a 2a20 3220 2b20 7365 6c66 2e70  "] ** 2 + self.p
-00009ff0: 5b22 7832 225d 202a 2a20 3229 2920 2a2a  ["x2"] ** 2)) **
-0000a000: 2032 0d0a 0d0a 2020 2020 2020 2020 795f   2....        y_
-0000a010: 6f75 7420 3d20 795b 3a2c 206e 702e 6e65  out = y[:, np.ne
-0000a020: 7761 7869 735d 0d0a 0d0a 2020 2020 2020  waxis]....      
-0000a030: 2020 7265 7475 726e 2079 5f6f 7574 0d0a    return y_out..
-0000a040: 0d0a 0d0a 636c 6173 7320 5370 6865 7265  ....class Sphere
-0000a050: 4675 6e63 7469 6f6e 2841 6273 7472 6163  Function(Abstrac
-0000a060: 744d 6f64 656c 293a 0d0a 2020 2020 2222  tModel):..    ""
-0000a070: 220d 0a20 2020 2064 2d64 696d 656e 7369  "..    d-dimensi
-0000a080: 6f6e 616c 2053 7068 6572 6520 4675 6e63  onal Sphere Func
-0000a090: 7469 6f6e 205b 315d 5b32 5d5b 335d 5b34  tion [1][2][3][4
-0000a0a0: 5d2e 0d0a 2020 2020 5468 6520 5370 6865  ]...    The Sphe
-0000a0b0: 7265 2066 756e 6374 696f 6e20 6861 7320  re function has 
-0000a0c0: 6420 6c6f 6361 6c20 6d69 6e69 6d61 2065  d local minima e
-0000a0d0: 7863 6570 7420 666f 7220 7468 6520 676c  xcept for the gl
-0000a0e0: 6f62 616c 206f 6e65 2e20 4974 2069 7320  obal one. It is 
-0000a0f0: 636f 6e74 696e 756f 7573 2c20 636f 6e76  continuous, conv
-0000a100: 6578 2061 6e64 2075 6e69 6d6f 6461 6c2e  ex and unimodal.
-0000a110: 0d0a 2020 2020 5468 6520 706c 6f74 2073  ..    The plot s
-0000a120: 686f 7773 2069 7473 2074 776f 2d64 696d  hows its two-dim
-0000a130: 656e 7369 6f6e 616c 2066 6f72 6d2e 0d0a  ensional form...
-0000a140: 0d0a 2020 2020 2e2e 206d 6174 683a 3a0d  ..    .. math::.
-0000a150: 0a20 2020 2020 2020 2020 7920 3d20 5c5c  .         y = \\
-0000a160: 7375 6d5f 7b69 3d31 7d5e 7b64 7d78 5f69  sum_{i=1}^{d}x_i
-0000a170: 5e32 0d0a 0d0a 2020 2020 5061 7261 6d65  ^2....    Parame
-0000a180: 7465 7273 0d0a 2020 2020 2d2d 2d2d 2d2d  ters..    ------
-0000a190: 2d2d 2d2d 0d0a 2020 2020 705b 2278 3122  ----..    p["x1"
-0000a1a0: 5d3a 2066 6c6f 6174 206f 7220 6e64 6172  ]: float or ndar
-0000a1b0: 7261 7920 6f66 2066 6c6f 6174 205b 6e5f  ray of float [n_
-0000a1c0: 6772 6964 5d0d 0a20 2020 2020 2020 2046  grid]..        F
-0000a1d0: 6972 7374 2070 6172 616d 6574 6572 2064  irst parameter d
-0000a1e0: 6566 696e 6564 2069 6e20 5b2d 352e 3132  efined in [-5.12
-0000a1f0: 2c20 352e 3132 5d0d 0a20 2020 2070 5b22  , 5.12]..    p["
-0000a200: 7832 225d 3a20 666c 6f61 7420 6f72 206e  x2"]: float or n
-0000a210: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-0000a220: 5b6e 5f67 7269 645d 0d0a 2020 2020 2020  [n_grid]..      
-0000a230: 2020 7365 636f 6e64 2070 6172 616d 6574    second paramet
-0000a240: 6572 2064 6566 696e 6564 2069 6e20 5b2d  er defined in [-
-0000a250: 352e 3132 2c20 352e 3132 5d0d 0a0d 0a20  5.12, 5.12].... 
-0000a260: 2020 2052 6574 7572 6e73 0d0a 2020 2020     Returns..    
-0000a270: 2d2d 2d2d 2d2d 2d0d 0a20 2020 2079 3a20  -------..    y: 
-0000a280: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-0000a290: 205b 6e5f 6772 6964 2078 2031 5d0d 0a20   [n_grid x 1].. 
-0000a2a0: 2020 2020 2020 204f 7574 7075 740d 0a0d         Output...
-0000a2b0: 0a20 2020 204e 6f74 6573 0d0a 2020 2020  .    Notes..    
-0000a2c0: 2d2d 2d2d 2d0d 0a20 2020 202e 2e20 706c  -----..    .. pl
-0000a2d0: 6f74 3a3a 0d0a 0d0a 2020 2020 2020 2069  ot::....       i
-0000a2e0: 6d70 6f72 7420 6e75 6d70 7920 6173 206e  mport numpy as n
-0000a2f0: 700d 0a20 2020 2020 2020 6672 6f6d 2070  p..       from p
-0000a300: 7967 7063 2e74 6573 7466 756e 6374 696f  ygpc.testfunctio
-0000a310: 6e73 2069 6d70 6f72 7420 706c 6f74 5f74  ns import plot_t
-0000a320: 6573 7466 756e 6374 696f 6e20 6173 2070  estfunction as p
-0000a330: 6c6f 740d 0a20 2020 2020 2020 6672 6f6d  lot..       from
-0000a340: 2063 6f6c 6c65 6374 696f 6e73 2069 6d70   collections imp
-0000a350: 6f72 7420 4f72 6465 7265 6444 6963 740d  ort OrderedDict.
-0000a360: 0a0d 0a20 2020 2020 2020 7061 7261 6d65  ...       parame
-0000a370: 7465 7273 203d 204f 7264 6572 6564 4469  ters = OrderedDi
-0000a380: 6374 2829 0d0a 2020 2020 2020 2070 6172  ct()..       par
-0000a390: 616d 6574 6572 735b 2278 3122 5d20 3d20  ameters["x1"] = 
-0000a3a0: 6e70 2e6c 696e 7370 6163 6528 2d35 2e31  np.linspace(-5.1
-0000a3b0: 322c 2035 2e31 322c 2031 3030 290d 0a20  2, 5.12, 100).. 
-0000a3c0: 2020 2020 2020 7061 7261 6d65 7465 7273        parameters
-0000a3d0: 5b22 7832 225d 203d 206e 702e 6c69 6e73  ["x2"] = np.lins
-0000a3e0: 7061 6365 282d 352e 3132 2c20 352e 3132  pace(-5.12, 5.12
-0000a3f0: 2c20 3130 3029 0d0a 0d0a 2020 2020 2020  , 100)....      
-0000a400: 2063 6f6e 7374 616e 7473 203d 204e 6f6e   constants = Non
-0000a410: 650d 0a0d 0a20 2020 2020 2020 706c 6f74  e....       plot
-0000a420: 2822 5370 6865 7265 4675 6e63 7469 6f6e  ("SphereFunction
-0000a430: 222c 2070 6172 616d 6574 6572 732c 2063  ", parameters, c
-0000a440: 6f6e 7374 616e 7473 2c20 706c 6f74 5f33  onstants, plot_3
-0000a450: 643d 4661 6c73 6529 0d0a 0d0a 2020 2020  d=False)....    
-0000a460: 2e2e 205b 315d 4469 786f 6e2c 204c 2e20  .. [1]Dixon, L. 
-0000a470: 432e 2057 2e2c 2026 2053 7a65 676f 2c20  C. W., & Szego, 
-0000a480: 472e 2050 2e20 2831 3937 3829 2e20 5468  G. P. (1978). Th
-0000a490: 6520 676c 6f62 616c 206f 7074 696d 697a  e global optimiz
-0000a4a0: 6174 696f 6e20 7072 6f62 6c65 6d3a 2061  ation problem: a
-0000a4b0: 6e20 696e 7472 6f64 7563 7469 6f6e 2e0d  n introduction..
-0000a4c0: 0a20 2020 2020 2020 546f 7761 7264 7320  .       Towards 
-0000a4d0: 676c 6f62 616c 206f 7074 696d 697a 6174  global optimizat
-0000a4e0: 696f 6e2c 2032 2c20 312d 3135 2e0d 0a20  ion, 2, 1-15... 
-0000a4f0: 2020 202e 2e20 5b32 5d20 4d6f 6c67 612c     .. [2] Molga,
-0000a500: 204d 2e2c 2026 2053 6d75 746e 6963 6b69   M., & Smutnicki
-0000a510: 2c20 432e 2054 6573 7420 6675 6e63 7469  , C. Test functi
-0000a520: 6f6e 7320 666f 7220 6f70 7469 6d69 7a61  ons for optimiza
-0000a530: 7469 6f6e 206e 6565 6473 2028 3230 3035  tion needs (2005
-0000a540: 292e 2052 6574 7269 6576 6564 204a 756e  ). Retrieved Jun
-0000a550: 6520 3230 3133 2c0d 0a20 2020 2020 2020  e 2013,..       
-0000a560: 6672 6f6d 2068 7474 703a 2f2f 7777 772e  from http://www.
-0000a570: 7a73 642e 6963 742e 7077 722e 7772 6f63  zsd.ict.pwr.wroc
-0000a580: 2e70 6c2f 6669 6c65 732f 646f 6373 2f66  .pl/files/docs/f
-0000a590: 756e 6374 696f 6e73 2e70 6466 2e0d 0a20  unctions.pdf... 
-0000a5a0: 2020 202e 2e20 5b33 5d50 6963 6865 6e79     .. [3]Picheny
-0000a5b0: 2c20 562e 2c20 5761 676e 6572 2c20 542e  , V., Wagner, T.
-0000a5c0: 2c20 2620 4769 6e73 626f 7572 6765 722c  , & Ginsbourger,
-0000a5d0: 2044 2e20 2832 3031 3229 2e0d 0a20 2020   D. (2012)...   
-0000a5e0: 2020 2020 4120 6265 6e63 686d 6172 6b20      A benchmark 
-0000a5f0: 6f66 206b 7269 6769 6e67 2d62 6173 6564  of kriging-based
-0000a600: 2069 6e66 696c 6c20 6372 6974 6572 6961   infill criteria
-0000a610: 2066 6f72 206e 6f69 7379 206f 7074 696d   for noisy optim
-0000a620: 697a 6174 696f 6e2e 0d0a 2020 2020 2e2e  ization...    ..
-0000a630: 205b 345d 6874 7470 733a 2f2f 7777 772e   [4]https://www.
-0000a640: 7366 752e 6361 2f7e 7373 7572 6a61 6e6f  sfu.ca/~ssurjano
-0000a650: 2f73 7068 6572 6566 2e68 746d 6c0d 0a20  /spheref.html.. 
-0000a660: 2020 2022 2222 0d0a 0d0a 2020 2020 6465     """....    de
-0000a670: 6620 5f5f 696e 6974 5f5f 2873 656c 662c  f __init__(self,
-0000a680: 206d 6174 6c61 625f 6d6f 6465 6c3d 4661   matlab_model=Fa
-0000a690: 6c73 6529 3a0d 0a20 2020 2020 2020 2073  lse):..        s
-0000a6a0: 7570 6572 2874 7970 6528 7365 6c66 292c  uper(type(self),
-0000a6b0: 2073 656c 6629 2e5f 5f69 6e69 745f 5f28   self).__init__(
-0000a6c0: 6d61 746c 6162 5f6d 6f64 656c 3d6d 6174  matlab_model=mat
-0000a6d0: 6c61 625f 6d6f 6465 6c29 0d0a 2020 2020  lab_model)..    
-0000a6e0: 2020 2020 7365 6c66 2e66 6e61 6d65 203d      self.fname =
-0000a6f0: 2069 6e73 7065 6374 2e67 6574 6669 6c65   inspect.getfile
-0000a700: 2869 6e73 7065 6374 2e63 7572 7265 6e74  (inspect.current
-0000a710: 6672 616d 6528 2929 0d0a 0d0a 2020 2020  frame())....    
-0000a720: 6465 6620 7661 6c69 6461 7465 2873 656c  def validate(sel
-0000a730: 6629 3a0d 0a20 2020 2020 2020 2070 6173  f):..        pas
-0000a740: 730d 0a0d 0a20 2020 2064 6566 2073 696d  s....    def sim
-0000a750: 756c 6174 6528 7365 6c66 2c20 7072 6f63  ulate(self, proc
-0000a760: 6573 735f 6964 3d4e 6f6e 652c 206d 6174  ess_id=None, mat
-0000a770: 6c61 625f 656e 6769 6e65 3d4e 6f6e 6529  lab_engine=None)
-0000a780: 3a0d 0a0d 0a20 2020 2020 2020 2066 6f72  :....        for
-0000a790: 2069 2c20 6b65 7920 696e 2065 6e75 6d65   i, key in enume
-0000a7a0: 7261 7465 2873 656c 662e 702e 6b65 7973  rate(self.p.keys
-0000a7b0: 2829 293a 0d0a 2020 2020 2020 2020 2020  ()):..          
-0000a7c0: 2020 6966 2074 7970 6528 7365 6c66 2e70    if type(self.p
-0000a7d0: 5b6b 6579 5d29 2069 7320 6e70 2e6e 6461  [key]) is np.nda
-0000a7e0: 7272 6179 3a0d 0a20 2020 2020 2020 2020  rray:..         
-0000a7f0: 2020 2020 2020 2073 656c 662e 705b 6b65         self.p[ke
-0000a800: 795d 203d 2073 656c 662e 705b 6b65 795d  y] = self.p[key]
-0000a810: 2e66 6c61 7474 656e 2829 0d0a 0d0a 2020  .flatten()....  
-0000a820: 2020 2020 2020 2320 6465 7465 726d 696e        # determin
-0000a830: 6520 7375 6d0d 0a20 2020 2020 2020 2079  e sum..        y
-0000a840: 203d 206e 702e 7a65 726f 7328 6e70 2e61   = np.zeros(np.a
-0000a850: 7272 6179 2873 656c 662e 705b 6c69 7374  rray(self.p[list
-0000a860: 2873 656c 662e 702e 6b65 7973 2829 295b  (self.p.keys())[
-0000a870: 305d 5d29 2e73 697a 6529 0d0a 2020 2020  0]]).size)..    
-0000a880: 2020 2020 6b65 7973 203d 206c 6973 7428      keys = list(
-0000a890: 7365 6c66 2e70 2e6b 6579 7328 2929 0d0a  self.p.keys())..
-0000a8a0: 0d0a 2020 2020 2020 2020 666f 7220 692c  ..        for i,
-0000a8b0: 2069 5f6b 6579 2069 6e20 656e 756d 6572   i_key in enumer
-0000a8c0: 6174 6528 6b65 7973 293a 0d0a 2020 2020  ate(keys):..    
-0000a8d0: 2020 2020 2020 2020 2020 2079 202b 3d20             y += 
-0000a8e0: 7365 6c66 2e70 5b69 5f6b 6579 5d20 2a2a  self.p[i_key] **
-0000a8f0: 2032 0d0a 0d0a 2020 2020 2020 2020 795f   2....        y_
-0000a900: 6f75 7420 3d20 795b 3a2c 206e 702e 6e65  out = y[:, np.ne
-0000a910: 7761 7869 735d 0d0a 0d0a 2020 2020 2020  waxis]....      
-0000a920: 2020 7265 7475 726e 2079 5f6f 7574 0d0a    return y_out..
-0000a930: 0d0a 0d0a 636c 6173 7320 4c69 6e32 436f  ....class Lin2Co
-0000a940: 7570 6c65 6428 4162 7374 7261 6374 4d6f  upled(AbstractMo
-0000a950: 6465 6c29 3a0d 0a20 2020 2022 2222 0d0a  del):..    """..
-0000a960: 2020 2020 642d 6469 6d65 6e73 696f 6e61      d-dimensiona
-0000a970: 6c20 4c69 6e32 436f 7570 6c65 6420 4675  l Lin2Coupled Fu
-0000a980: 6e63 7469 6f6e 2e0d 0a20 2020 2054 6865  nction...    The
-0000a990: 204c 696e 3243 6f75 706c 6564 2066 756e   Lin2Coupled fun
-0000a9a0: 6374 696f 6e20 6973 2063 6f6e 7469 6e75  ction is continu
-0000a9b0: 6f75 732c 2063 6f6e 7665 7820 616e 6420  ous, convex and 
-0000a9c0: 756e 696d 6f64 616c 2e0d 0a20 2020 2054  unimodal...    T
-0000a9d0: 6865 2070 6c6f 7420 7368 6f77 7320 6974  he plot shows it
-0000a9e0: 7320 7477 6f2d 6469 6d65 6e73 696f 6e61  s two-dimensiona
-0000a9f0: 6c20 666f 726d 2e0d 0a0d 0a20 2020 202e  l form.....    .
-0000aa00: 2e20 6d61 7468 3a3a 0d0a 2020 2020 2020  . math::..      
-0000aa10: 2020 2079 203d 205c 5c73 756d 5f7b 693d     y = \\sum_{i=
-0000aa20: 317d 5e7b 647d 785f 6920 785f 7b69 2b31  1}^{d}x_i x_{i+1
-0000aa30: 7d0d 0a0d 0a20 2020 2050 6172 616d 6574  }....    Paramet
-0000aa40: 6572 730d 0a20 2020 202d 2d2d 2d2d 2d2d  ers..    -------
-0000aa50: 2d2d 2d0d 0a20 2020 2070 5b22 7831 225d  ---..    p["x1"]
-0000aa60: 3a20 666c 6f61 7420 6f72 206e 6461 7272  : float or ndarr
-0000aa70: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
-0000aa80: 7269 645d 0d0a 2020 2020 2020 2020 4669  rid]..        Fi
-0000aa90: 7273 7420 7061 7261 6d65 7465 7220 6465  rst parameter de
-0000aaa0: 6669 6e65 6420 696e 205b 2d31 2c20 315d  fined in [-1, 1]
-0000aab0: 0d0a 2020 2020 705b 2278 3222 5d3a 2066  ..    p["x2"]: f
-0000aac0: 6c6f 6174 206f 7220 6e64 6172 7261 7920  loat or ndarray 
-0000aad0: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
-0000aae0: 5d0d 0a20 2020 2020 2020 2073 6563 6f6e  ]..        secon
-0000aaf0: 6420 7061 7261 6d65 7465 7220 6465 6669  d parameter defi
-0000ab00: 6e65 6420 696e 205b 2d31 2c20 315d 0d0a  ned in [-1, 1]..
-0000ab10: 0d0a 2020 2020 5265 7475 726e 730d 0a20  ..    Returns.. 
-0000ab20: 2020 202d 2d2d 2d2d 2d2d 0d0a 2020 2020     -------..    
-0000ab30: 793a 206e 6461 7272 6179 206f 6620 666c  y: ndarray of fl
-0000ab40: 6f61 7420 5b6e 5f67 7269 6420 7820 315d  oat [n_grid x 1]
-0000ab50: 0d0a 2020 2020 2020 2020 4f75 7470 7574  ..        Output
-0000ab60: 0d0a 0d0a 2020 2020 4e6f 7465 730d 0a20  ....    Notes.. 
-0000ab70: 2020 202d 2d2d 2d2d 0d0a 2020 2020 2e2e     -----..    ..
-0000ab80: 2070 6c6f 743a 3a0d 0a0d 0a20 2020 2020   plot::....     
-0000ab90: 2020 696d 706f 7274 206e 756d 7079 2061    import numpy a
-0000aba0: 7320 6e70 0d0a 2020 2020 2020 2066 726f  s np..       fro
-0000abb0: 6d20 7079 6770 632e 7465 7374 6675 6e63  m pygpc.testfunc
-0000abc0: 7469 6f6e 7320 696d 706f 7274 2070 6c6f  tions import plo
-0000abd0: 745f 7465 7374 6675 6e63 7469 6f6e 2061  t_testfunction a
-0000abe0: 7320 706c 6f74 0d0a 2020 2020 2020 2066  s plot..       f
-0000abf0: 726f 6d20 636f 6c6c 6563 7469 6f6e 7320  rom collections 
-0000ac00: 696d 706f 7274 204f 7264 6572 6564 4469  import OrderedDi
-0000ac10: 6374 0d0a 0d0a 2020 2020 2020 2070 6172  ct....       par
-0000ac20: 616d 6574 6572 7320 3d20 4f72 6465 7265  ameters = Ordere
-0000ac30: 6444 6963 7428 290d 0a20 2020 2020 2020  dDict()..       
-0000ac40: 7061 7261 6d65 7465 7273 5b22 7831 225d  parameters["x1"]
-0000ac50: 203d 206e 702e 6c69 6e73 7061 6365 282d   = np.linspace(-
-0000ac60: 312c 2031 2c20 3130 3029 0d0a 2020 2020  1, 1, 100)..    
-0000ac70: 2020 2070 6172 616d 6574 6572 735b 2278     parameters["x
-0000ac80: 3222 5d20 3d20 6e70 2e6c 696e 7370 6163  2"] = np.linspac
-0000ac90: 6528 2d31 2c20 312c 2031 3030 290d 0a0d  e(-1, 1, 100)...
-0000aca0: 0a20 2020 2020 2020 636f 6e73 7461 6e74  .       constant
-0000acb0: 7320 3d20 4e6f 6e65 0d0a 0d0a 2020 2020  s = None....    
-0000acc0: 2020 2070 6c6f 7428 224c 696e 3243 6f75     plot("Lin2Cou
-0000acd0: 706c 6564 222c 2070 6172 616d 6574 6572  pled", parameter
-0000ace0: 732c 2063 6f6e 7374 616e 7473 2c20 706c  s, constants, pl
-0000acf0: 6f74 5f33 643d 4661 6c73 6529 0d0a 0d0a  ot_3d=False)....
-0000ad00: 2020 2020 2e2e 205b 315d 2041 6c65 6d61      .. [1] Alema
-0000ad10: 7a6b 6f6f 722c 204e 2e2c 2026 204d 6569  zkoor, N., & Mei
-0000ad20: 6461 6e69 2c20 482e 2028 3230 3138 292e  dani, H. (2018).
-0000ad30: 2041 206e 6561 722d 6f70 7469 6d61 6c20   A near-optimal 
-0000ad40: 7361 6d70 6c69 6e67 2073 7472 6174 6567  sampling strateg
-0000ad50: 7920 666f 7220 7370 6172 7365 2072 6563  y for sparse rec
-0000ad60: 6f76 6572 7920 6f66 0d0a 2020 2020 2020  overy of..      
-0000ad70: 2070 6f6c 796e 6f6d 6961 6c20 6368 616f   polynomial chao
-0000ad80: 7320 6578 7061 6e73 696f 6e73 2e20 4a6f  s expansions. Jo
-0000ad90: 7572 6e61 6c20 6f66 2043 6f6d 7075 7461  urnal of Computa
-0000ada0: 7469 6f6e 616c 2050 6879 7369 6373 2c20  tional Physics, 
-0000adb0: 3337 312c 2031 3337 2d31 3531 2e0d 0a20  371, 137-151... 
-0000adc0: 2020 2022 2222 0d0a 0d0a 2020 2020 6465     """....    de
-0000add0: 6620 5f5f 696e 6974 5f5f 2873 656c 662c  f __init__(self,
-0000ade0: 206d 6174 6c61 625f 6d6f 6465 6c3d 4661   matlab_model=Fa
-0000adf0: 6c73 6529 3a0d 0a20 2020 2020 2020 2073  lse):..        s
-0000ae00: 7570 6572 2874 7970 6528 7365 6c66 292c  uper(type(self),
-0000ae10: 2073 656c 6629 2e5f 5f69 6e69 745f 5f28   self).__init__(
-0000ae20: 6d61 746c 6162 5f6d 6f64 656c 3d6d 6174  matlab_model=mat
-0000ae30: 6c61 625f 6d6f 6465 6c29 0d0a 2020 2020  lab_model)..    
-0000ae40: 2020 2020 7365 6c66 2e66 6e61 6d65 203d      self.fname =
-0000ae50: 2069 6e73 7065 6374 2e67 6574 6669 6c65   inspect.getfile
-0000ae60: 2869 6e73 7065 6374 2e63 7572 7265 6e74  (inspect.current
-0000ae70: 6672 616d 6528 2929 0d0a 0d0a 2020 2020  frame())....    
-0000ae80: 6465 6620 7661 6c69 6461 7465 2873 656c  def validate(sel
-0000ae90: 6629 3a0d 0a20 2020 2020 2020 2070 6173  f):..        pas
-0000aea0: 730d 0a0d 0a20 2020 2064 6566 2073 696d  s....    def sim
-0000aeb0: 756c 6174 6528 7365 6c66 2c20 7072 6f63  ulate(self, proc
-0000aec0: 6573 735f 6964 3d4e 6f6e 652c 206d 6174  ess_id=None, mat
-0000aed0: 6c61 625f 656e 6769 6e65 3d4e 6f6e 6529  lab_engine=None)
-0000aee0: 3a0d 0a0d 0a20 2020 2020 2020 2066 6f72  :....        for
-0000aef0: 2069 2c20 6b65 7920 696e 2065 6e75 6d65   i, key in enume
-0000af00: 7261 7465 2873 656c 662e 702e 6b65 7973  rate(self.p.keys
-0000af10: 2829 293a 0d0a 2020 2020 2020 2020 2020  ()):..          
-0000af20: 2020 6966 2074 7970 6528 7365 6c66 2e70    if type(self.p
-0000af30: 5b6b 6579 5d29 2069 7320 6e70 2e6e 6461  [key]) is np.nda
-0000af40: 7272 6179 3a0d 0a20 2020 2020 2020 2020  rray:..         
-0000af50: 2020 2020 2020 2073 656c 662e 705b 6b65         self.p[ke
-0000af60: 795d 203d 2073 656c 662e 705b 6b65 795d  y] = self.p[key]
-0000af70: 2e66 6c61 7474 656e 2829 0d0a 0d0a 2020  .flatten()....  
-0000af80: 2020 2020 2020 2320 6465 7465 726d 696e        # determin
-0000af90: 6520 7375 6d0d 0a20 2020 2020 2020 2079  e sum..        y
-0000afa0: 203d 206e 702e 7a65 726f 7328 6e70 2e61   = np.zeros(np.a
-0000afb0: 7272 6179 2873 656c 662e 705b 6c69 7374  rray(self.p[list
-0000afc0: 2873 656c 662e 702e 6b65 7973 2829 295b  (self.p.keys())[
-0000afd0: 305d 5d29 2e73 697a 6529 0d0a 2020 2020  0]]).size)..    
-0000afe0: 2020 2020 6b65 7973 203d 206c 6973 7428      keys = list(
-0000aff0: 7365 6c66 2e70 2e6b 6579 7328 2929 0d0a  self.p.keys())..
-0000b000: 0d0a 2020 2020 2020 2020 666f 7220 692c  ..        for i,
-0000b010: 2069 5f6b 6579 2069 6e20 656e 756d 6572   i_key in enumer
-0000b020: 6174 6528 6b65 7973 293a 0d0a 2020 2020  ate(keys):..    
-0000b030: 2020 2020 2020 2020 6966 2069 203c 2028          if i < (
-0000b040: 6c65 6e28 6b65 7973 292d 3129 3a0d 0a20  len(keys)-1):.. 
-0000b050: 2020 2020 2020 2020 2020 2020 2020 2079                 y
-0000b060: 202b 3d20 7365 6c66 2e70 5b6b 6579 735b   += self.p[keys[
-0000b070: 695d 5d20 2a20 7365 6c66 2e70 5b6b 6579  i]] * self.p[key
-0000b080: 735b 692b 315d 5d0d 0a0d 0a20 2020 2020  s[i+1]]....     
-0000b090: 2020 2079 5f6f 7574 203d 2079 5b3a 2c20     y_out = y[:, 
-0000b0a0: 6e70 2e6e 6577 6178 6973 5d0d 0a0d 0a20  np.newaxis].... 
-0000b0b0: 2020 2020 2020 2072 6574 7572 6e20 795f         return y_
-0000b0c0: 6f75 740d 0a0d 0a0d 0a63 6c61 7373 204d  out......class M
-0000b0d0: 6343 6f72 6d69 636b 4675 6e63 7469 6f6e  cCormickFunction
-0000b0e0: 2841 6273 7472 6163 744d 6f64 656c 293a  (AbstractModel):
-0000b0f0: 0d0a 2020 2020 2222 220d 0a20 2020 2032  ..    """..    2
-0000b100: 2d64 696d 656e 7369 6f6e 616c 204d 6343  -dimensional McC
-0000b110: 6f72 6d69 636b 2046 756e 6374 696f 6e20  ormick Function 
-0000b120: 5b31 5d5b 325d 2e0d 0a0d 0a20 2020 202e  [1][2].....    .
-0000b130: 2e20 6d61 7468 3a3a 0d0a 2020 2020 2020  . math::..      
-0000b140: 7920 3d20 5c5c 7369 6e28 785f 312b 785f  y = \\sin(x_1+x_
-0000b150: 3229 2b28 785f 312d 785f 3229 5e32 2d31  2)+(x_1-x_2)^2-1
-0000b160: 2e35 785f 312b 322e 3578 5f32 2b31 0d0a  .5x_1+2.5x_2+1..
-0000b170: 0d0a 2020 2020 5061 7261 6d65 7465 7273  ..    Parameters
-0000b180: 0d0a 2020 2020 2d2d 2d2d 2d2d 2d2d 2d2d  ..    ----------
-0000b190: 0d0a 2020 2020 705b 2278 3122 5d3a 2066  ..    p["x1"]: f
-0000b1a0: 6c6f 6174 206f 7220 6e64 6172 7261 7920  loat or ndarray 
-0000b1b0: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
-0000b1c0: 5d0d 0a20 2020 2020 2020 2046 6972 7374  ]..        First
-0000b1d0: 2070 6172 616d 6574 6572 2064 6566 696e   parameter defin
-0000b1e0: 6564 2069 6e20 5b2d 312e 352c 2034 5d0d  ed in [-1.5, 4].
-0000b1f0: 0a20 2020 2070 5b22 7832 225d 3a20 666c  .    p["x2"]: fl
-0000b200: 6f61 7420 6f72 206e 6461 7272 6179 206f  oat or ndarray o
-0000b210: 6620 666c 6f61 7420 5b6e 5f67 7269 645d  f float [n_grid]
-0000b220: 0d0a 2020 2020 2020 2020 7365 636f 6e64  ..        second
-0000b230: 2070 6172 616d 6574 6572 2064 6566 696e   parameter defin
-0000b240: 6564 2069 6e20 5b2d 332c 2034 5d0d 0a0d  ed in [-3, 4]...
-0000b250: 0a20 2020 2052 6574 7572 6e73 0d0a 2020  .    Returns..  
-0000b260: 2020 2d2d 2d2d 2d2d 2d0d 0a20 2020 2079    -------..    y
-0000b270: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
-0000b280: 6174 205b 6e5f 6772 6964 2078 2031 5d0d  at [n_grid x 1].
-0000b290: 0a20 2020 2020 2020 204f 7574 7075 740d  .        Output.
-0000b2a0: 0a0d 0a20 2020 204e 6f74 6573 0d0a 2020  ...    Notes..  
-0000b2b0: 2020 2d2d 2d2d 2d0d 0a20 2020 202e 2e20    -----..    .. 
-0000b2c0: 706c 6f74 3a3a 0d0a 0d0a 2020 2020 2020  plot::....      
-0000b2d0: 2069 6d70 6f72 7420 6e75 6d70 7920 6173   import numpy as
-0000b2e0: 206e 700d 0a20 2020 2020 2020 6672 6f6d   np..       from
-0000b2f0: 2070 7967 7063 2e74 6573 7466 756e 6374   pygpc.testfunct
-0000b300: 696f 6e73 2069 6d70 6f72 7420 706c 6f74  ions import plot
-0000b310: 5f74 6573 7466 756e 6374 696f 6e20 6173  _testfunction as
-0000b320: 2070 6c6f 740d 0a20 2020 2020 2020 6672   plot..       fr
-0000b330: 6f6d 2063 6f6c 6c65 6374 696f 6e73 2069  om collections i
-0000b340: 6d70 6f72 7420 4f72 6465 7265 6444 6963  mport OrderedDic
-0000b350: 740d 0a0d 0a20 2020 2020 2020 7061 7261  t....       para
-0000b360: 6d65 7465 7273 203d 204f 7264 6572 6564  meters = Ordered
-0000b370: 4469 6374 2829 0d0a 2020 2020 2020 2070  Dict()..       p
-0000b380: 6172 616d 6574 6572 735b 2278 3122 5d20  arameters["x1"] 
-0000b390: 3d20 6e70 2e6c 696e 7370 6163 6528 2d31  = np.linspace(-1
-0000b3a0: 2e35 2c20 342c 2031 3030 290d 0a20 2020  .5, 4, 100)..   
-0000b3b0: 2020 2020 7061 7261 6d65 7465 7273 5b22      parameters["
-0000b3c0: 7832 225d 203d 206e 702e 6c69 6e73 7061  x2"] = np.linspa
-0000b3d0: 6365 282d 332c 2034 2c20 3130 3029 0d0a  ce(-3, 4, 100)..
-0000b3e0: 0d0a 2020 2020 2020 2063 6f6e 7374 616e  ..       constan
-0000b3f0: 7473 203d 204e 6f6e 650d 0a0d 0a20 2020  ts = None....   
-0000b400: 2020 2020 706c 6f74 2822 4d63 436f 726d      plot("McCorm
-0000b410: 6963 6b46 756e 6374 696f 6e22 2c20 7061  ickFunction", pa
-0000b420: 7261 6d65 7465 7273 2c20 636f 6e73 7461  rameters, consta
-0000b430: 6e74 732c 2070 6c6f 745f 3364 3d46 616c  nts, plot_3d=Fal
-0000b440: 7365 290d 0a0d 0a20 2020 202e 2e20 5b31  se)....    .. [1
-0000b450: 5d20 4164 6f72 696f 2c20 452e 2050 2e2c  ] Adorio, E. P.,
-0000b460: 2026 2044 696c 696d 616e 2c20 552e 2050   & Diliman, U. P
-0000b470: 2e20 4d56 4620 2d20 4d75 6c74 6976 6172  . MVF - Multivar
-0000b480: 6961 7465 2054 6573 7420 4675 6e63 7469  iate Test Functi
-0000b490: 6f6e 7320 4c69 6272 6172 7920 696e 2043  ons Library in C
-0000b4a0: 2066 6f72 2055 6e63 6f6e 7374 7261 696e   for Unconstrain
-0000b4b0: 6564 0d0a 2020 2020 2020 2047 6c6f 6261  ed..       Globa
-0000b4c0: 6c20 4f70 7469 6d69 7a61 7469 6f6e 2028  l Optimization (
-0000b4d0: 3230 3035 292e 2052 6574 7269 6576 6564  2005). Retrieved
-0000b4e0: 204a 756e 6520 3230 3133 2c20 6672 6f6d   June 2013, from
-0000b4f0: 2068 7474 703a 2f2f 6874 7470 3a2f 2f77   http://http://w
-0000b500: 7777 2e67 656f 6369 7469 6573 2e77 732f  ww.geocities.ws/
-0000b510: 6561 646f 7269 6f2f 6d76 662e 7064 662e  eadorio/mvf.pdf.
-0000b520: 0d0a 0d0a 2020 2020 2e2e 205b 325d 2068  ....    .. [2] h
-0000b530: 7474 7073 3a2f 2f77 7777 2e73 6675 2e63  ttps://www.sfu.c
-0000b540: 612f 7e73 7375 726a 616e 6f2f 6d63 636f  a/~ssurjano/mcco
-0000b550: 726d 2e68 746d 6c0d 0a20 2020 2022 2222  rm.html..    """
-0000b560: 0d0a 0d0a 2020 2020 6465 6620 5f5f 696e  ....    def __in
-0000b570: 6974 5f5f 2873 656c 662c 206d 6174 6c61  it__(self, matla
-0000b580: 625f 6d6f 6465 6c3d 4661 6c73 6529 3a0d  b_model=False):.
-0000b590: 0a20 2020 2020 2020 2073 7570 6572 2874  .        super(t
-0000b5a0: 7970 6528 7365 6c66 292c 2073 656c 6629  ype(self), self)
-0000b5b0: 2e5f 5f69 6e69 745f 5f28 6d61 746c 6162  .__init__(matlab
-0000b5c0: 5f6d 6f64 656c 3d6d 6174 6c61 625f 6d6f  _model=matlab_mo
-0000b5d0: 6465 6c29 0d0a 2020 2020 2020 2020 7365  del)..        se
-0000b5e0: 6c66 2e66 6e61 6d65 203d 2069 6e73 7065  lf.fname = inspe
-0000b5f0: 6374 2e67 6574 6669 6c65 2869 6e73 7065  ct.getfile(inspe
-0000b600: 6374 2e63 7572 7265 6e74 6672 616d 6528  ct.currentframe(
-0000b610: 2929 0d0a 0d0a 2020 2020 6465 6620 7661  ))....    def va
-0000b620: 6c69 6461 7465 2873 656c 6629 3a0d 0a20  lidate(self):.. 
-0000b630: 2020 2020 2020 2070 6173 730d 0a0d 0a20         pass.... 
-0000b640: 2020 2064 6566 2073 696d 756c 6174 6528     def simulate(
-0000b650: 7365 6c66 2c20 7072 6f63 6573 735f 6964  self, process_id
-0000b660: 3d4e 6f6e 652c 206d 6174 6c61 625f 656e  =None, matlab_en
-0000b670: 6769 6e65 3d4e 6f6e 6529 3a0d 0a0d 0a20  gine=None):.... 
-0000b680: 2020 2020 2020 2079 203d 206e 702e 7369         y = np.si
-0000b690: 6e28 7365 6c66 2e70 5b22 7831 225d 202b  n(self.p["x1"] +
-0000b6a0: 2073 656c 662e 705b 2278 3222 5d29 202b   self.p["x2"]) +
-0000b6b0: 2028 7365 6c66 2e70 5b22 7831 225d 202d   (self.p["x1"] -
-0000b6c0: 2073 656c 662e 705b 2278 3222 5d29 202a   self.p["x2"]) *
-0000b6d0: 2a20 3220 2d20 312e 3520 2a20 7365 6c66  * 2 - 1.5 * self
-0000b6e0: 2e70 5b22 7831 225d 202b 5c0d 0a20 2020  .p["x1"] +\..   
-0000b6f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b700: 322e 3520 2a20 7365 6c66 2e70 5b22 7832  2.5 * self.p["x2
-0000b710: 225d 202b 2031 0d0a 0d0a 2020 2020 2020  "] + 1....      
-0000b720: 2020 795f 6f75 7420 3d20 795b 3a2c 206e    y_out = y[:, n
-0000b730: 702e 6e65 7761 7869 735d 0d0a 0d0a 2020  p.newaxis]....  
-0000b740: 2020 2020 2020 7265 7475 726e 2079 5f6f        return y_o
-0000b750: 7574 0d0a 0d0a 0d0a 636c 6173 7320 426f  ut......class Bo
-0000b760: 6f74 6846 756e 6374 696f 6e28 4162 7374  othFunction(Abst
-0000b770: 7261 6374 4d6f 6465 6c29 3a0d 0a20 2020  ractModel):..   
-0000b780: 2022 2222 0d0a 2020 2020 322d 6469 6d65   """..    2-dime
-0000b790: 6e73 696f 6e61 6c20 426f 6f74 6846 756e  nsional BoothFun
-0000b7a0: 6374 696f 6e2e 5b31 5d5b 325d 2e0d 0a0d  ction.[1][2]....
-0000b7b0: 0a20 2020 202e 2e20 6d61 7468 3a3a 0d0a  .    .. math::..
-0000b7c0: 2020 2020 2020 7920 3d20 2878 5f31 2b32        y = (x_1+2
-0000b7d0: 785f 322d 3729 5e32 2b28 3278 5f31 2b78  x_2-7)^2+(2x_1+x
-0000b7e0: 5f32 2d35 295e 320d 0a20 2020 2050 6172  _2-5)^2..    Par
-0000b7f0: 616d 6574 6572 730d 0a20 2020 202d 2d2d  ameters..    ---
-0000b800: 2d2d 2d2d 2d2d 2d0d 0a20 2020 2070 5b22  -------..    p["
-0000b810: 7831 225d 3a20 666c 6f61 7420 6f72 206e  x1"]: float or n
-0000b820: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-0000b830: 5b6e 5f67 7269 645d 0d0a 2020 2020 2020  [n_grid]..      
-0000b840: 2020 4669 7273 7420 7061 7261 6d65 7465    First paramete
-0000b850: 7220 6465 6669 6e65 6420 696e 205b 2d31  r defined in [-1
-0000b860: 302c 2031 305d 0d0a 2020 2020 705b 2278  0, 10]..    p["x
-0000b870: 3222 5d3a 2066 6c6f 6174 206f 7220 6e64  2"]: float or nd
-0000b880: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
-0000b890: 6e5f 6772 6964 5d0d 0a20 2020 2020 2020  n_grid]..       
-0000b8a0: 2073 6563 6f6e 6420 7061 7261 6d65 7465   second paramete
-0000b8b0: 7220 6465 6669 6e65 6420 696e 205b 2d31  r defined in [-1
-0000b8c0: 302c 2031 305d 0d0a 0d0a 2020 2020 5265  0, 10]....    Re
-0000b8d0: 7475 726e 730d 0a20 2020 202d 2d2d 2d2d  turns..    -----
-0000b8e0: 2d2d 0d0a 2020 2020 793a 206e 6461 7272  --..    y: ndarr
-0000b8f0: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
-0000b900: 7269 6420 7820 315d 0d0a 2020 2020 2020  rid x 1]..      
-0000b910: 2020 4f75 7470 7574 0d0a 0d0a 2020 2020    Output....    
-0000b920: 4e6f 7465 730d 0a20 2020 202d 2d2d 2d2d  Notes..    -----
-0000b930: 0d0a 2020 2020 2e2e 2070 6c6f 743a 3a0d  ..    .. plot::.
-0000b940: 0a0d 0a20 2020 2020 2020 696d 706f 7274  ...       import
-0000b950: 206e 756d 7079 2061 7320 6e70 0d0a 2020   numpy as np..  
-0000b960: 2020 2020 2066 726f 6d20 7079 6770 632e       from pygpc.
-0000b970: 7465 7374 6675 6e63 7469 6f6e 7320 696d  testfunctions im
-0000b980: 706f 7274 2070 6c6f 745f 7465 7374 6675  port plot_testfu
-0000b990: 6e63 7469 6f6e 2061 7320 706c 6f74 0d0a  nction as plot..
-0000b9a0: 2020 2020 2020 2066 726f 6d20 636f 6c6c         from coll
-0000b9b0: 6563 7469 6f6e 7320 696d 706f 7274 204f  ections import O
-0000b9c0: 7264 6572 6564 4469 6374 0d0a 0d0a 2020  rderedDict....  
-0000b9d0: 2020 2020 2070 6172 616d 6574 6572 7320       parameters 
-0000b9e0: 3d20 4f72 6465 7265 6444 6963 7428 290d  = OrderedDict().
-0000b9f0: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
-0000ba00: 7273 5b22 7831 225d 203d 206e 702e 6c69  rs["x1"] = np.li
-0000ba10: 6e73 7061 6365 282d 3130 2c20 3130 2c20  nspace(-10, 10, 
-0000ba20: 3130 3029 0d0a 2020 2020 2020 2070 6172  100)..       par
-0000ba30: 616d 6574 6572 735b 2278 3222 5d20 3d20  ameters["x2"] = 
-0000ba40: 6e70 2e6c 696e 7370 6163 6528 2d31 302c  np.linspace(-10,
-0000ba50: 2031 302c 2031 3030 290d 0a0d 0a20 2020   10, 100)....   
-0000ba60: 2020 2020 636f 6e73 7461 6e74 7320 3d20      constants = 
-0000ba70: 4e6f 6e65 0d0a 0d0a 2020 2020 2020 2070  None....       p
-0000ba80: 6c6f 7428 2242 6f6f 7468 4675 6e63 7469  lot("BoothFuncti
-0000ba90: 6f6e 222c 2070 6172 616d 6574 6572 732c  on", parameters,
-0000baa0: 2063 6f6e 7374 616e 7473 2c20 706c 6f74   constants, plot
-0000bab0: 5f33 643d 4661 6c73 6529 0d0a 0d0a 2020  _3d=False)....  
-0000bac0: 2020 2e2e 205b 315d 2047 6c6f 6261 6c20    .. [1] Global 
-0000bad0: 4f70 7469 6d69 7a61 7469 6f6e 2054 6573  Optimization Tes
-0000bae0: 7420 5072 6f62 6c65 6d73 2e20 5265 7472  t Problems. Retr
-0000baf0: 6965 7665 6420 4a75 6e65 2032 3031 332c  ieved June 2013,
-0000bb00: 2066 726f 6d0d 0a20 2020 2020 2020 6874   from..       ht
-0000bb10: 7470 3a2f 2f77 7777 2d6f 7074 696d 612e  tp://www-optima.
-0000bb20: 616d 702e 692e 6b79 6f74 6f2d 752e 6163  amp.i.kyoto-u.ac
-0000bb30: 2e6a 702f 6d65 6d62 6572 2f73 7475 6465  .jp/member/stude
-0000bb40: 6e74 2f68 6564 6172 2f48 6564 6172 5f66  nt/hedar/Hedar_f
-0000bb50: 696c 6573 2f54 6573 7447 4f2e 6874 6d2e  iles/TestGO.htm.
-0000bb60: 0d0a 2020 2020 2e2e 205b 325d 2068 7474  ..    .. [2] htt
-0000bb70: 7073 3a2f 2f77 7777 2e73 6675 2e63 612f  ps://www.sfu.ca/
-0000bb80: 7e73 7375 726a 616e 6f2f 626f 6f74 682e  ~ssurjano/booth.
-0000bb90: 6874 6d6c 0d0a 2020 2020 2222 220d 0a0d  html..    """...
-0000bba0: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
-0000bbb0: 5f28 7365 6c66 2c20 6d61 746c 6162 5f6d  _(self, matlab_m
-0000bbc0: 6f64 656c 3d46 616c 7365 293a 0d0a 2020  odel=False):..  
-0000bbd0: 2020 2020 2020 7375 7065 7228 7479 7065        super(type
-0000bbe0: 2873 656c 6629 2c20 7365 6c66 292e 5f5f  (self), self).__
-0000bbf0: 696e 6974 5f5f 286d 6174 6c61 625f 6d6f  init__(matlab_mo
-0000bc00: 6465 6c3d 6d61 746c 6162 5f6d 6f64 656c  del=matlab_model
-0000bc10: 290d 0a20 2020 2020 2020 2073 656c 662e  )..        self.
-0000bc20: 666e 616d 6520 3d20 696e 7370 6563 742e  fname = inspect.
-0000bc30: 6765 7466 696c 6528 696e 7370 6563 742e  getfile(inspect.
-0000bc40: 6375 7272 656e 7466 7261 6d65 2829 290d  currentframe()).
-0000bc50: 0a0d 0a20 2020 2064 6566 2076 616c 6964  ...    def valid
-0000bc60: 6174 6528 7365 6c66 293a 0d0a 2020 2020  ate(self):..    
-0000bc70: 2020 2020 7061 7373 0d0a 0d0a 2020 2020      pass....    
-0000bc80: 6465 6620 7369 6d75 6c61 7465 2873 656c  def simulate(sel
-0000bc90: 662c 2070 726f 6365 7373 5f69 643d 4e6f  f, process_id=No
-0000bca0: 6e65 2c20 6d61 746c 6162 5f65 6e67 696e  ne, matlab_engin
-0000bcb0: 653d 4e6f 6e65 293a 0d0a 0d0a 2020 2020  e=None):....    
-0000bcc0: 2020 2020 7920 3d20 2873 656c 662e 705b      y = (self.p[
-0000bcd0: 2278 3122 5d20 2b20 3220 2a20 7365 6c66  "x1"] + 2 * self
-0000bce0: 2e70 5b22 7832 225d 202d 2037 2920 2a2a  .p["x2"] - 7) **
-0000bcf0: 2032 202b 2028 3220 2a20 7365 6c66 2e70   2 + (2 * self.p
-0000bd00: 5b22 7831 225d 202b 2073 656c 662e 705b  ["x1"] + self.p[
-0000bd10: 2278 3222 5d20 2d20 3529 202a 2a20 320d  "x2"] - 5) ** 2.
-0000bd20: 0a0d 0a20 2020 2020 2020 2079 5f6f 7574  ...        y_out
-0000bd30: 203d 2079 5b3a 2c20 6e70 2e6e 6577 6178   = y[:, np.newax
-0000bd40: 6973 5d0d 0a0d 0a20 2020 2020 2020 2072  is]....        r
-0000bd50: 6574 7572 6e20 795f 6f75 740d 0a0d 0a0d  eturn y_out.....
-0000bd60: 0a63 6c61 7373 2050 6561 6b73 2841 6273  .class Peaks(Abs
-0000bd70: 7472 6163 744d 6f64 656c 293a 0d0a 2020  tractModel):..  
-0000bd80: 2020 2222 220d 0a20 2020 2054 6872 6565    """..    Three
-0000bd90: 2d64 696d 656e 7369 6f6e 616c 2070 6561  -dimensional pea
-0000bda0: 6b73 2066 756e 6374 696f 6e2e 0d0a 0d0a  ks function.....
-0000bdb0: 2020 2020 2e2e 206d 6174 683a 3a0d 0a20      .. math::.. 
-0000bdc0: 2020 2020 2079 203d 2033 2831 2d78 5f31       y = 3(1-x_1
-0000bdd0: 295e 3220 655e 7b2d 2878 5f31 5e32 292d  )^2 e^{-(x_1^2)-
-0000bde0: 2878 5f33 2b31 295e 327d 2d31 3028 5c5c  (x_3+1)^2}-10(\\
-0000bdf0: 6672 6163 7b78 5f31 7d7b 357d 2d78 5f31  frac{x_1}{5}-x_1
-0000be00: 5e33 2d78 5f33 5e35 2920 655e 7b2d 785f  ^3-x_3^5) e^{-x_
-0000be10: 315e 322d 785f 335e 327d 2d0d 0a20 2020  1^2-x_3^2}-..   
-0000be20: 2020 205c 5c66 7261 637b 317d 7b33 7d20     \\frac{1}{3} 
-0000be30: 655e 7b2d 2878 5f31 2b31 295e 3220 2d20  e^{-(x_1+1)^2 - 
-0000be40: 785f 335e 327d 202b 2078 5f32 0d0a 0d0a  x_3^2} + x_2....
-0000be50: 2020 2020 5061 7261 6d65 7465 7273 0d0a      Parameters..
-0000be60: 2020 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0d0a      ----------..
-0000be70: 2020 2020 705b 2278 3122 5d3a 2066 6c6f      p["x1"]: flo
-0000be80: 6174 206f 7220 6e64 6172 7261 7920 6f66  at or ndarray of
-0000be90: 2066 6c6f 6174 205b 6e5f 6772 6964 5d0d   float [n_grid].
-0000bea0: 0a20 2020 2020 2020 2050 6172 616d 6574  .        Paramet
-0000beb0: 6572 2031 0d0a 2020 2020 705b 2278 3222  er 1..    p["x2"
-0000bec0: 5d3a 2066 6c6f 6174 206f 7220 6e64 6172  ]: float or ndar
-0000bed0: 7261 7920 6f66 2066 6c6f 6174 205b 6e5f  ray of float [n_
-0000bee0: 6772 6964 5d0d 0a20 2020 2020 2020 2050  grid]..        P
-0000bef0: 6172 616d 6574 6572 2032 0d0a 2020 2020  arameter 2..    
-0000bf00: 705b 2278 3322 5d3a 2066 6c6f 6174 206f  p["x3"]: float o
-0000bf10: 7220 6e64 6172 7261 7920 6f66 2066 6c6f  r ndarray of flo
-0000bf20: 6174 205b 6e5f 6772 6964 5d0d 0a20 2020  at [n_grid]..   
-0000bf30: 2020 2020 2050 6172 616d 6574 6572 2033       Parameter 3
-0000bf40: 0d0a 0d0a 2020 2020 5265 7475 726e 730d  ....    Returns.
-0000bf50: 0a20 2020 202d 2d2d 2d2d 2d2d 0d0a 2020  .    -------..  
-0000bf60: 2020 793a 206e 6461 7272 6179 206f 6620    y: ndarray of 
-0000bf70: 666c 6f61 7420 5b6e 5f67 7269 6420 7820  float [n_grid x 
-0000bf80: 6e5f 6f75 745d 0d0a 2020 2020 2020 2020  n_out]..        
-0000bf90: 4f75 7470 7574 2064 6174 610d 0a20 2020  Output data..   
-0000bfa0: 206d 6973 633a 2064 6963 7420 6f72 206c   misc: dict or l
-0000bfb0: 6973 7420 6f66 2064 6963 7420 5b6e 5f67  ist of dict [n_g
-0000bfc0: 7269 645d 0d0a 2020 2020 2020 2020 4164  rid]..        Ad
-0000bfd0: 6469 7469 6f6e 616c 2064 6174 612c 2077  ditional data, w
-0000bfe0: 696c 6c20 6265 2073 6176 6564 2075 6e64  ill be saved und
-0000bff0: 6572 2069 7473 206b 6579 7320 696e 2074  er its keys in t
-0000c000: 6865 202e 6864 6635 2066 696c 6520 6475  he .hdf5 file du
-0000c010: 7269 6e67 2067 5043 2073 696d 756c 6174  ring gPC simulat
-0000c020: 696f 6e73 2066 6f72 2065 7665 7279 2067  ions for every g
-0000c030: 7269 6420 706f 696e 740d 0a0d 0a20 2020  rid point....   
-0000c040: 204e 6f74 6573 0d0a 2020 2020 2d2d 2d2d   Notes..    ----
-0000c050: 2d0d 0a20 2020 202e 2e20 706c 6f74 3a3a  -..    .. plot::
-0000c060: 0d0a 0d0a 2020 2020 2020 2069 6d70 6f72  ....       impor
-0000c070: 7420 6e75 6d70 7920 6173 206e 700d 0a20  t numpy as np.. 
-0000c080: 2020 2020 2020 6672 6f6d 2070 7967 7063        from pygpc
-0000c090: 2e74 6573 7466 756e 6374 696f 6e73 2069  .testfunctions i
-0000c0a0: 6d70 6f72 7420 706c 6f74 5f74 6573 7466  mport plot_testf
-0000c0b0: 756e 6374 696f 6e20 6173 2070 6c6f 740d  unction as plot.
-0000c0c0: 0a20 2020 2020 2020 6672 6f6d 2063 6f6c  .       from col
-0000c0d0: 6c65 6374 696f 6e73 2069 6d70 6f72 7420  lections import 
-0000c0e0: 4f72 6465 7265 6444 6963 740d 0a0d 0a20  OrderedDict.... 
-0000c0f0: 2020 2020 2020 7061 7261 6d65 7465 7273        parameters
-0000c100: 203d 204f 7264 6572 6564 4469 6374 2829   = OrderedDict()
-0000c110: 0d0a 2020 2020 2020 2070 6172 616d 6574  ..       paramet
-0000c120: 6572 735b 2278 3122 5d20 3d20 6e70 2e6c  ers["x1"] = np.l
-0000c130: 696e 7370 6163 6528 302c 2031 2c20 3130  inspace(0, 1, 10
-0000c140: 3029 0d0a 2020 2020 2020 2070 6172 616d  0)..       param
-0000c150: 6574 6572 735b 2278 3222 5d20 3d20 6e70  eters["x2"] = np
-0000c160: 2e6c 696e 7370 6163 6528 302c 2031 2c20  .linspace(0, 1, 
-0000c170: 3130 3029 0d0a 0d0a 2020 2020 2020 2063  100)....       c
-0000c180: 6f6e 7374 616e 7473 203d 204f 7264 6572  onstants = Order
-0000c190: 6564 4469 6374 2829 0d0a 2020 2020 2020  edDict()..      
-0000c1a0: 2063 6f6e 7374 616e 7473 5b22 7833 225d   constants["x3"]
-0000c1b0: 203d 2030 2e0d 0a20 2020 2020 2020 706c   = 0...       pl
-0000c1c0: 6f74 2822 5065 616b 7322 2c20 7061 7261  ot("Peaks", para
-0000c1d0: 6d65 7465 7273 2c20 636f 6e73 7461 6e74  meters, constant
-0000c1e0: 732c 2070 6c6f 745f 3364 3d46 616c 7365  s, plot_3d=False
-0000c1f0: 290d 0a20 2020 2022 2222 0d0a 0d0a 2020  )..    """....  
-0000c200: 2020 6465 6620 5f5f 696e 6974 5f5f 2873    def __init__(s
-0000c210: 656c 662c 206d 6174 6c61 625f 6d6f 6465  elf, matlab_mode
-0000c220: 6c3d 4661 6c73 6529 3a0d 0a20 2020 2020  l=False):..     
-0000c230: 2020 2073 7570 6572 2874 7970 6528 7365     super(type(se
-0000c240: 6c66 292c 2073 656c 6629 2e5f 5f69 6e69  lf), self).__ini
-0000c250: 745f 5f28 6d61 746c 6162 5f6d 6f64 656c  t__(matlab_model
-0000c260: 3d6d 6174 6c61 625f 6d6f 6465 6c29 0d0a  =matlab_model)..
-0000c270: 2020 2020 2020 2020 7365 6c66 2e66 6e61          self.fna
-0000c280: 6d65 203d 2069 6e73 7065 6374 2e67 6574  me = inspect.get
-0000c290: 6669 6c65 2869 6e73 7065 6374 2e63 7572  file(inspect.cur
-0000c2a0: 7265 6e74 6672 616d 6528 2929 0d0a 0d0a  rentframe())....
-0000c2b0: 2020 2020 6465 6620 7661 6c69 6461 7465      def validate
-0000c2c0: 2873 656c 6629 3a0d 0a20 2020 2020 2020  (self):..       
-0000c2d0: 2070 6173 730d 0a0d 0a20 2020 2064 6566   pass....    def
-0000c2e0: 2073 696d 756c 6174 6528 7365 6c66 2c20   simulate(self, 
-0000c2f0: 7072 6f63 6573 735f 6964 3d4e 6f6e 652c  process_id=None,
-0000c300: 206d 6174 6c61 625f 656e 6769 6e65 3d4e   matlab_engine=N
-0000c310: 6f6e 6529 3a0d 0a0d 0a20 2020 2020 2020  one):....       
-0000c320: 2069 6620 7479 7065 2873 656c 662e 705b   if type(self.p[
-0000c330: 2278 3122 5d29 2069 7320 6e70 2e6e 6461  "x1"]) is np.nda
-0000c340: 7272 6179 3a0d 0a20 2020 2020 2020 2020  rray:..         
-0000c350: 2020 2073 656c 662e 705b 2278 3122 5d20     self.p["x1"] 
-0000c360: 3d20 7365 6c66 2e70 5b22 7831 225d 2e66  = self.p["x1"].f
-0000c370: 6c61 7474 656e 2829 0d0a 2020 2020 2020  latten()..      
-0000c380: 2020 6966 2074 7970 6528 7365 6c66 2e70    if type(self.p
-0000c390: 5b22 7832 225d 2920 6973 206e 702e 6e64  ["x2"]) is np.nd
-0000c3a0: 6172 7261 793a 0d0a 2020 2020 2020 2020  array:..        
-0000c3b0: 2020 2020 7365 6c66 2e70 5b22 7832 225d      self.p["x2"]
-0000c3c0: 203d 2073 656c 662e 705b 2278 3222 5d2e   = self.p["x2"].
-0000c3d0: 666c 6174 7465 6e28 290d 0a20 2020 2020  flatten()..     
-0000c3e0: 2020 2069 6620 7479 7065 2873 656c 662e     if type(self.
-0000c3f0: 705b 2278 3322 5d29 2069 7320 6e70 2e6e  p["x3"]) is np.n
-0000c400: 6461 7272 6179 3a0d 0a20 2020 2020 2020  darray:..       
-0000c410: 2020 2020 2073 656c 662e 705b 2278 3322       self.p["x3"
-0000c420: 5d20 3d20 7365 6c66 2e70 5b22 7833 225d  ] = self.p["x3"]
-0000c430: 2e66 6c61 7474 656e 2829 0d0a 0d0a 2020  .flatten()....  
-0000c440: 2020 2020 2020 7920 3d20 2833 2e30 202a        y = (3.0 *
-0000c450: 2028 3120 2d20 7365 6c66 2e70 5b22 7831   (1 - self.p["x1
-0000c460: 225d 2920 2a2a 2032 2e20 2a20 6e70 2e65  "]) ** 2. * np.e
-0000c470: 7870 282d 2873 656c 662e 705b 2278 3122  xp(-(self.p["x1"
-0000c480: 5d20 2a2a 2032 2920 2d20 2873 656c 662e  ] ** 2) - (self.
-0000c490: 705b 2278 3322 5d20 2b20 3129 202a 2a20  p["x3"] + 1) ** 
-0000c4a0: 3229 0d0a 2020 2020 2020 2020 2020 2020  2)..            
-0000c4b0: 202d 2031 302e 3020 2a20 2873 656c 662e   - 10.0 * (self.
-0000c4c0: 705b 2278 3122 5d20 2f20 352e 3020 2d20  p["x1"] / 5.0 - 
-0000c4d0: 7365 6c66 2e70 5b22 7831 225d 202a 2a20  self.p["x1"] ** 
-0000c4e0: 3320 2d20 7365 6c66 2e70 5b22 7833 225d  3 - self.p["x3"]
-0000c4f0: 202a 2a20 3529 0d0a 2020 2020 2020 2020   ** 5)..        
-0000c500: 2020 2020 202a 206e 702e 6578 7028 2d73       * np.exp(-s
-0000c510: 656c 662e 705b 2278 3122 5d20 2a2a 2032  elf.p["x1"] ** 2
-0000c520: 202d 2073 656c 662e 705b 2278 3322 5d20   - self.p["x3"] 
-0000c530: 2a2a 2032 2920 2d20 312e 3020 2f20 330d  ** 2) - 1.0 / 3.
-0000c540: 0a20 2020 2020 2020 2020 2020 2020 2a20  .             * 
-0000c550: 6e70 2e65 7870 282d 2873 656c 662e 705b  np.exp(-(self.p[
-0000c560: 2278 3122 5d20 2b20 3129 202a 2a20 3220  "x1"] + 1) ** 2 
-0000c570: 2d20 7365 6c66 2e70 5b22 7833 225d 202a  - self.p["x3"] *
-0000c580: 2a20 3229 2920 2b20 7365 6c66 2e70 5b22  * 2)) + self.p["
-0000c590: 7832 225d 0d0a 0d0a 2020 2020 2020 2020  x2"]....        
-0000c5a0: 6164 6469 7469 6f6e 616c 5f64 6174 6120  additional_data 
-0000c5b0: 3d20 7b22 6164 6469 7469 6f6e 616c 5f64  = {"additional_d
-0000c5c0: 6174 612f 6c69 7374 5f6d 756c 745f 696e  ata/list_mult_in
-0000c5d0: 7422 3a20 5b31 2c20 322c 2033 5d2c 0d0a  t": [1, 2, 3],..
-0000c5e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c5f0: 2020 2020 2020 2020 2020 2022 6164 6469             "addi
-0000c600: 7469 6f6e 616c 5f64 6174 612f 6c69 7374  tional_data/list
-0000c610: 5f73 696e 676c 655f 666c 6f61 7422 3a20  _single_float": 
-0000c620: 5b30 2e32 5d2c 0d0a 2020 2020 2020 2020  [0.2],..        
-0000c630: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c640: 2020 2022 6164 6469 7469 6f6e 616c 5f64     "additional_d
-0000c650: 6174 612f 6c69 7374 5f73 696e 676c 655f  ata/list_single_
-0000c660: 7374 7222 3a20 5b22 7465 7374 225d 2c0d  str": ["test"],.
-0000c670: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000c680: 2020 2020 2020 2020 2020 2020 2261 6464              "add
-0000c690: 6974 696f 6e61 6c5f 6461 7461 2f6c 6973  itional_data/lis
-0000c6a0: 745f 6d75 6c74 5f73 7472 223a 205b 2274  t_mult_str": ["t
-0000c6b0: 6573 7431 222c 2022 7465 7374 3222 5d2c  est1", "test2"],
-0000c6c0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000c6d0: 2020 2020 2020 2020 2020 2020 2022 6164               "ad
-0000c6e0: 6469 7469 6f6e 616c 5f64 6174 612f 7369  ditional_data/si
-0000c6f0: 6e67 6c65 5f66 6c6f 6174 223a 2030 2e32  ngle_float": 0.2
-0000c700: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-0000c710: 2020 2020 2020 2020 2020 2020 2020 2261                "a
-0000c720: 6464 6974 696f 6e61 6c5f 6461 7461 2f73  dditional_data/s
-0000c730: 696e 676c 655f 696e 7422 3a20 322c 0d0a  ingle_int": 2,..
-0000c740: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c750: 2020 2020 2020 2020 2020 2022 6164 6469             "addi
-0000c760: 7469 6f6e 616c 5f64 6174 612f 7369 6e67  tional_data/sing
-0000c770: 6c65 5f73 7472 223a 2022 7465 7374 227d  le_str": "test"}
-0000c780: 0d0a 0d0a 2020 2020 2020 2020 2320 2320  ....        # # 
-0000c790: 7477 6f20 6f75 7470 7574 2076 6172 6961  two output varia
-0000c7a0: 626c 6573 2066 6f72 2074 6573 7469 6e67  bles for testing
-0000c7b0: 0d0a 2020 2020 2020 2020 2320 6966 2079  ..        # if y
-0000c7c0: 2e73 697a 6520 3e20 313a 0d0a 2020 2020  .size > 1:..    
-0000c7d0: 2020 2020 2320 2020 2020 795f 6f75 7420      #     y_out 
-0000c7e0: 3d20 6e70 2e61 7272 6179 285b 792c 2032  = np.array([y, 2
-0000c7f0: 202a 2079 5d29 2e74 7261 6e73 706f 7365   * y]).transpose
-0000c800: 2829 0d0a 2020 2020 2020 2020 2320 2020  ()..        #   
-0000c810: 2020 6164 6469 7469 6f6e 616c 5f64 6174    additional_dat
-0000c820: 6120 3d20 792e 7369 7a65 202a 205b 6164  a = y.size * [ad
-0000c830: 6469 7469 6f6e 616c 5f64 6174 615d 0d0a  ditional_data]..
-0000c840: 2020 2020 2020 2020 2320 656c 7365 3a0d          # else:.
-0000c850: 0a20 2020 2020 2020 2023 2020 2020 2079  .        #     y
-0000c860: 5f6f 7574 203d 206e 702e 6172 7261 7928  _out = np.array(
-0000c870: 5b79 2c20 3220 2a20 795d 290d 0a20 2020  [y, 2 * y])..   
-0000c880: 2020 2020 2069 6620 792e 6e64 696d 203d       if y.ndim =
-0000c890: 3d20 313a 0d0a 2020 2020 2020 2020 2020  = 1:..          
-0000c8a0: 2020 795f 6f75 7420 3d20 795b 3a2c 206e    y_out = y[:, n
-0000c8b0: 702e 6e65 7761 7869 735d 0d0a 0d0a 2020  p.newaxis]....  
-0000c8c0: 2020 2020 2020 7265 7475 726e 2079 5f6f        return y_o
-0000c8d0: 7574 2c20 6164 6469 7469 6f6e 616c 5f64  ut, additional_d
-0000c8e0: 6174 610d 0a0d 0a0d 0a63 6c61 7373 2050  ata......class P
-0000c8f0: 6561 6b73 5f4e 614e 2841 6273 7472 6163  eaks_NaN(Abstrac
-0000c900: 744d 6f64 656c 293a 0d0a 2020 2020 2222  tModel):..    ""
-0000c910: 220d 0a20 2020 2054 6872 6565 2d64 696d  "..    Three-dim
-0000c920: 656e 7369 6f6e 616c 2070 6561 6b73 2066  ensional peaks f
-0000c930: 756e 6374 696f 6e20 7265 7475 726e 696e  unction returnin
-0000c940: 6720 4e61 4e20 7661 6c75 6573 2066 6f72  g NaN values for
-0000c950: 2063 6572 7461 696e 2070 6172 616d 6574   certain paramet
-0000c960: 6572 7320 2866 6f72 2074 6573 7469 6e67  ers (for testing
-0000c970: 292e 0d0a 0d0a 2020 2020 2e2e 206d 6174  ).....    .. mat
-0000c980: 683a 3a0d 0a20 2020 2020 2079 203d 2033  h::..      y = 3
-0000c990: 2831 2d78 5f31 295e 3220 655e 7b2d 2878  (1-x_1)^2 e^{-(x
-0000c9a0: 5f31 5e32 292d 2878 5f33 2b31 295e 327d  _1^2)-(x_3+1)^2}
-0000c9b0: 2d31 3028 5c5c 6672 6163 7b78 5f31 7d7b  -10(\\frac{x_1}{
-0000c9c0: 357d 2d78 5f31 5e33 2d78 5f33 5e35 2920  5}-x_1^3-x_3^5) 
-0000c9d0: 655e 7b2d 785f 315e 322d 785f 335e 327d  e^{-x_1^2-x_3^2}
-0000c9e0: 2d0d 0a20 2020 2020 205c 5c66 7261 637b  -..      \\frac{
-0000c9f0: 317d 7b33 7d20 655e 7b2d 2878 5f31 2b31  1}{3} e^{-(x_1+1
-0000ca00: 295e 3220 2d20 785f 335e 327d 202b 2078  )^2 - x_3^2} + x
-0000ca10: 5f32 0d0a 0d0a 2020 2020 5061 7261 6d65  _2....    Parame
-0000ca20: 7465 7273 0d0a 2020 2020 2d2d 2d2d 2d2d  ters..    ------
-0000ca30: 2d2d 2d2d 0d0a 2020 2020 705b 2278 3122  ----..    p["x1"
-0000ca40: 5d3a 2066 6c6f 6174 206f 7220 6e64 6172  ]: float or ndar
-0000ca50: 7261 7920 6f66 2066 6c6f 6174 205b 6e5f  ray of float [n_
-0000ca60: 6772 6964 5d0d 0a20 2020 2020 2020 2050  grid]..        P
-0000ca70: 6172 616d 6574 6572 2031 0d0a 2020 2020  arameter 1..    
-0000ca80: 705b 2278 3222 5d3a 2066 6c6f 6174 206f  p["x2"]: float o
-0000ca90: 7220 6e64 6172 7261 7920 6f66 2066 6c6f  r ndarray of flo
-0000caa0: 6174 205b 6e5f 6772 6964 5d0d 0a20 2020  at [n_grid]..   
-0000cab0: 2020 2020 2050 6172 616d 6574 6572 2032       Parameter 2
-0000cac0: 0d0a 2020 2020 705b 2278 3322 5d3a 2066  ..    p["x3"]: f
-0000cad0: 6c6f 6174 206f 7220 6e64 6172 7261 7920  loat or ndarray 
-0000cae0: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
-0000caf0: 5d0d 0a20 2020 2020 2020 2050 6172 616d  ]..        Param
-0000cb00: 6574 6572 2033 0d0a 0d0a 2020 2020 5265  eter 3....    Re
-0000cb10: 7475 726e 730d 0a20 2020 202d 2d2d 2d2d  turns..    -----
-0000cb20: 2d2d 0d0a 2020 2020 793a 206e 6461 7272  --..    y: ndarr
-0000cb30: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
-0000cb40: 7269 6420 7820 6e5f 6f75 745d 0d0a 2020  rid x n_out]..  
-0000cb50: 2020 2020 2020 4f75 7470 7574 2064 6174        Output dat
-0000cb60: 610d 0a20 2020 206d 6973 633a 2064 6963  a..    misc: dic
-0000cb70: 7420 6f72 206c 6973 7420 6f66 2064 6963  t or list of dic
-0000cb80: 7420 5b6e 5f67 7269 645d 0d0a 2020 2020  t [n_grid]..    
-0000cb90: 2020 2020 4164 6469 7469 6f6e 616c 2064      Additional d
-0000cba0: 6174 612c 2077 696c 6c20 6265 2073 6176  ata, will be sav
-0000cbb0: 6564 2075 6e64 6572 2069 7473 206b 6579  ed under its key
-0000cbc0: 7320 696e 2074 6865 202e 6864 6635 2066  s in the .hdf5 f
-0000cbd0: 696c 6520 6475 7269 6e67 2067 5043 2073  ile during gPC s
-0000cbe0: 696d 756c 6174 696f 6e73 2066 6f72 2065  imulations for e
-0000cbf0: 7665 7279 2067 7269 6420 706f 696e 740d  very grid point.
-0000cc00: 0a0d 0a20 2020 204e 6f74 6573 0d0a 2020  ...    Notes..  
-0000cc10: 2020 2d2d 2d2d 2d0d 0a20 2020 202e 2e20    -----..    .. 
-0000cc20: 706c 6f74 3a3a 0d0a 0d0a 2020 2020 2020  plot::....      
-0000cc30: 2069 6d70 6f72 7420 6e75 6d70 7920 6173   import numpy as
-0000cc40: 206e 700d 0a20 2020 2020 2020 6672 6f6d   np..       from
-0000cc50: 2070 7967 7063 2e74 6573 7466 756e 6374   pygpc.testfunct
-0000cc60: 696f 6e73 2069 6d70 6f72 7420 706c 6f74  ions import plot
-0000cc70: 5f74 6573 7466 756e 6374 696f 6e20 6173  _testfunction as
-0000cc80: 2070 6c6f 740d 0a20 2020 2020 2020 6672   plot..       fr
-0000cc90: 6f6d 2063 6f6c 6c65 6374 696f 6e73 2069  om collections i
-0000cca0: 6d70 6f72 7420 4f72 6465 7265 6444 6963  mport OrderedDic
-0000ccb0: 740d 0a0d 0a20 2020 2020 2020 7061 7261  t....       para
-0000ccc0: 6d65 7465 7273 203d 204f 7264 6572 6564  meters = Ordered
-0000ccd0: 4469 6374 2829 0d0a 2020 2020 2020 2070  Dict()..       p
-0000cce0: 6172 616d 6574 6572 735b 2278 3122 5d20  arameters["x1"] 
-0000ccf0: 3d20 6e70 2e6c 696e 7370 6163 6528 302c  = np.linspace(0,
-0000cd00: 2031 2c20 3130 3029 0d0a 2020 2020 2020   1, 100)..      
-0000cd10: 2070 6172 616d 6574 6572 735b 2278 3222   parameters["x2"
-0000cd20: 5d20 3d20 6e70 2e6c 696e 7370 6163 6528  ] = np.linspace(
-0000cd30: 302c 2031 2c20 3130 3029 0d0a 0d0a 2020  0, 1, 100)....  
-0000cd40: 2020 2020 2063 6f6e 7374 616e 7473 203d       constants =
-0000cd50: 204f 7264 6572 6564 4469 6374 2829 0d0a   OrderedDict()..
-0000cd60: 2020 2020 2020 2063 6f6e 7374 616e 7473         constants
-0000cd70: 5b22 7833 225d 203d 2030 2e0d 0a20 2020  ["x3"] = 0...   
-0000cd80: 2020 2020 706c 6f74 2822 5065 616b 7322      plot("Peaks"
-0000cd90: 2c20 7061 7261 6d65 7465 7273 2c20 636f  , parameters, co
-0000cda0: 6e73 7461 6e74 732c 2070 6c6f 745f 3364  nstants, plot_3d
-0000cdb0: 3d46 616c 7365 290d 0a20 2020 2022 2222  =False)..    """
-0000cdc0: 0d0a 0d0a 2020 2020 6465 6620 5f5f 696e  ....    def __in
-0000cdd0: 6974 5f5f 2873 656c 662c 206d 6174 6c61  it__(self, matla
-0000cde0: 625f 6d6f 6465 6c3d 4661 6c73 6529 3a0d  b_model=False):.
-0000cdf0: 0a20 2020 2020 2020 2073 7570 6572 2874  .        super(t
-0000ce00: 7970 6528 7365 6c66 292c 2073 656c 6629  ype(self), self)
-0000ce10: 2e5f 5f69 6e69 745f 5f28 6d61 746c 6162  .__init__(matlab
-0000ce20: 5f6d 6f64 656c 3d6d 6174 6c61 625f 6d6f  _model=matlab_mo
-0000ce30: 6465 6c29 0d0a 2020 2020 2020 2020 7365  del)..        se
-0000ce40: 6c66 2e66 6e61 6d65 203d 2069 6e73 7065  lf.fname = inspe
-0000ce50: 6374 2e67 6574 6669 6c65 2869 6e73 7065  ct.getfile(inspe
-0000ce60: 6374 2e63 7572 7265 6e74 6672 616d 6528  ct.currentframe(
-0000ce70: 2929 0d0a 0d0a 2020 2020 6465 6620 7661  ))....    def va
-0000ce80: 6c69 6461 7465 2873 656c 6629 3a0d 0a20  lidate(self):.. 
-0000ce90: 2020 2020 2020 2070 6173 730d 0a0d 0a20         pass.... 
-0000cea0: 2020 2064 6566 2073 696d 756c 6174 6528     def simulate(
-0000ceb0: 7365 6c66 2c20 7072 6f63 6573 735f 6964  self, process_id
-0000cec0: 3d4e 6f6e 652c 206d 6174 6c61 625f 656e  =None, matlab_en
-0000ced0: 6769 6e65 3d4e 6f6e 6529 3a0d 0a0d 0a20  gine=None):.... 
-0000cee0: 2020 2020 2020 2069 6620 7479 7065 2873         if type(s
-0000cef0: 656c 662e 705b 2278 3122 5d29 2069 7320  elf.p["x1"]) is 
-0000cf00: 6e70 2e6e 6461 7272 6179 3a0d 0a20 2020  np.ndarray:..   
-0000cf10: 2020 2020 2020 2020 2073 656c 662e 705b           self.p[
-0000cf20: 2278 3122 5d20 3d20 7365 6c66 2e70 5b22  "x1"] = self.p["
-0000cf30: 7831 225d 2e66 6c61 7474 656e 2829 0d0a  x1"].flatten()..
-0000cf40: 2020 2020 2020 2020 6966 2074 7970 6528          if type(
-0000cf50: 7365 6c66 2e70 5b22 7832 225d 2920 6973  self.p["x2"]) is
-0000cf60: 206e 702e 6e64 6172 7261 793a 0d0a 2020   np.ndarray:..  
-0000cf70: 2020 2020 2020 2020 2020 7365 6c66 2e70            self.p
-0000cf80: 5b22 7832 225d 203d 2073 656c 662e 705b  ["x2"] = self.p[
-0000cf90: 2278 3222 5d2e 666c 6174 7465 6e28 290d  "x2"].flatten().
-0000cfa0: 0a20 2020 2020 2020 2069 6620 7479 7065  .        if type
-0000cfb0: 2873 656c 662e 705b 2278 3322 5d29 2069  (self.p["x3"]) i
-0000cfc0: 7320 6e70 2e6e 6461 7272 6179 3a0d 0a20  s np.ndarray:.. 
-0000cfd0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-0000cfe0: 705b 2278 3322 5d20 3d20 7365 6c66 2e70  p["x3"] = self.p
-0000cff0: 5b22 7833 225d 2e66 6c61 7474 656e 2829  ["x3"].flatten()
-0000d000: 0d0a 0d0a 2020 2020 2020 2020 7920 3d20  ....        y = 
-0000d010: 2833 2e30 202a 2028 3120 2d20 7365 6c66  (3.0 * (1 - self
-0000d020: 2e70 5b22 7831 225d 2920 2a2a 2032 2e20  .p["x1"]) ** 2. 
-0000d030: 2a20 6e70 2e65 7870 282d 2873 656c 662e  * np.exp(-(self.
-0000d040: 705b 2278 3122 5d20 2a2a 2032 2920 2d20  p["x1"] ** 2) - 
-0000d050: 2873 656c 662e 705b 2278 3322 5d20 2b20  (self.p["x3"] + 
-0000d060: 3129 202a 2a20 3229 0d0a 2020 2020 2020  1) ** 2)..      
-0000d070: 2020 2020 2020 202d 2031 302e 3020 2a20         - 10.0 * 
-0000d080: 2873 656c 662e 705b 2278 3122 5d20 2f20  (self.p["x1"] / 
-0000d090: 352e 3020 2d20 7365 6c66 2e70 5b22 7831  5.0 - self.p["x1
-0000d0a0: 225d 202a 2a20 3320 2d20 7365 6c66 2e70  "] ** 3 - self.p
-0000d0b0: 5b22 7833 225d 202a 2a20 3529 0d0a 2020  ["x3"] ** 5)..  
-0000d0c0: 2020 2020 2020 2020 2020 202a 206e 702e             * np.
-0000d0d0: 6578 7028 2d73 656c 662e 705b 2278 3122  exp(-self.p["x1"
-0000d0e0: 5d20 2a2a 2032 202d 2073 656c 662e 705b  ] ** 2 - self.p[
-0000d0f0: 2278 3322 5d20 2a2a 2032 2920 2d20 312e  "x3"] ** 2) - 1.
-0000d100: 3020 2f20 330d 0a20 2020 2020 2020 2020  0 / 3..         
-0000d110: 2020 2020 2a20 6e70 2e65 7870 282d 2873      * np.exp(-(s
-0000d120: 656c 662e 705b 2278 3122 5d20 2b20 3129  elf.p["x1"] + 1)
-0000d130: 202a 2a20 3220 2d20 7365 6c66 2e70 5b22   ** 2 - self.p["
-0000d140: 7833 225d 202a 2a20 3229 2920 2b20 7365  x3"] ** 2)) + se
-0000d150: 6c66 2e70 5b22 7832 225d 0d0a 0d0a 2020  lf.p["x2"]....  
-0000d160: 2020 2020 2020 2320 6164 6420 736f 6d65        # add some
-0000d170: 204e 614e 2076 616c 7565 7320 666f 7220   NaN values for 
-0000d180: 7465 7374 696e 670d 0a20 2020 2020 2020  testing..       
-0000d190: 206d 6173 6b5f 6e61 6e20 3d20 7365 6c66   mask_nan = self
-0000d1a0: 2e70 5b22 7831 225d 203c 2031 2e35 0d0a  .p["x1"] < 1.5..
-0000d1b0: 0d0a 2020 2020 2020 2020 795b 6d61 736b  ..        y[mask
-0000d1c0: 5f6e 616e 5d20 3d20 6e70 2e4e 614e 0d0a  _nan] = np.NaN..
-0000d1d0: 0d0a 2020 2020 2020 2020 6164 6469 7469  ..        additi
-0000d1e0: 6f6e 616c 5f64 6174 6120 3d20 7b22 6164  onal_data = {"ad
-0000d1f0: 6469 7469 6f6e 616c 5f64 6174 612f 6c69  ditional_data/li
-0000d200: 7374 5f6d 756c 745f 696e 7422 3a20 5b31  st_mult_int": [1
-0000d210: 2c20 322c 2033 5d2c 0d0a 2020 2020 2020  , 2, 3],..      
-0000d220: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d230: 2020 2020 2022 6164 6469 7469 6f6e 616c       "additional
-0000d240: 5f64 6174 612f 6c69 7374 5f73 696e 676c  _data/list_singl
-0000d250: 655f 666c 6f61 7422 3a20 5b30 2e32 5d2c  e_float": [0.2],
-0000d260: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000d270: 2020 2020 2020 2020 2020 2020 2022 6164               "ad
-0000d280: 6469 7469 6f6e 616c 5f64 6174 612f 6c69  ditional_data/li
-0000d290: 7374 5f73 696e 676c 655f 7374 7222 3a20  st_single_str": 
-0000d2a0: 5b22 7465 7374 225d 2c0d 0a20 2020 2020  ["test"],..     
-0000d2b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d2c0: 2020 2020 2020 2261 6464 6974 696f 6e61        "additiona
-0000d2d0: 6c5f 6461 7461 2f6c 6973 745f 6d75 6c74  l_data/list_mult
-0000d2e0: 5f73 7472 223a 205b 2274 6573 7431 222c  _str": ["test1",
-0000d2f0: 2022 7465 7374 3222 5d2c 0d0a 2020 2020   "test2"],..    
-0000d300: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d310: 2020 2020 2020 2022 6164 6469 7469 6f6e         "addition
-0000d320: 616c 5f64 6174 612f 7369 6e67 6c65 5f66  al_data/single_f
-0000d330: 6c6f 6174 223a 2030 2e32 2c0d 0a20 2020  loat": 0.2,..   
-0000d340: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d350: 2020 2020 2020 2020 2261 6464 6974 696f          "additio
-0000d360: 6e61 6c5f 6461 7461 2f73 696e 676c 655f  nal_data/single_
-0000d370: 696e 7422 3a20 322c 0d0a 2020 2020 2020  int": 2,..      
-0000d380: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d390: 2020 2020 2022 6164 6469 7469 6f6e 616c       "additional
-0000d3a0: 5f64 6174 612f 7369 6e67 6c65 5f73 7472  _data/single_str
-0000d3b0: 223a 2022 7465 7374 227d 0d0a 0d0a 2020  ": "test"}....  
-0000d3c0: 2020 2020 2020 2320 2320 7477 6f20 6f75        # # two ou
-0000d3d0: 7470 7574 2076 6172 6961 626c 6573 2066  tput variables f
-0000d3e0: 6f72 2074 6573 7469 6e67 0d0a 2020 2020  or testing..    
-0000d3f0: 2020 2020 2320 6966 2079 2e73 697a 6520      # if y.size 
-0000d400: 3e20 313a 0d0a 2020 2020 2020 2020 2320  > 1:..        # 
-0000d410: 2020 2020 795f 6f75 7420 3d20 6e70 2e61      y_out = np.a
-0000d420: 7272 6179 285b 792c 2032 202a 2079 5d29  rray([y, 2 * y])
-0000d430: 2e74 7261 6e73 706f 7365 2829 0d0a 2020  .transpose()..  
-0000d440: 2020 2020 2020 2320 2020 2020 6164 6469        #     addi
-0000d450: 7469 6f6e 616c 5f64 6174 6120 3d20 792e  tional_data = y.
-0000d460: 7369 7a65 202a 205b 6164 6469 7469 6f6e  size * [addition
-0000d470: 616c 5f64 6174 615d 0d0a 2020 2020 2020  al_data]..      
-0000d480: 2020 2320 656c 7365 3a0d 0a20 2020 2020    # else:..     
-0000d490: 2020 2023 2020 2020 2079 5f6f 7574 203d     #     y_out =
-0000d4a0: 206e 702e 6172 7261 7928 5b79 2c20 3220   np.array([y, 2 
-0000d4b0: 2a20 795d 290d 0a20 2020 2020 2020 2069  * y])..        i
-0000d4c0: 6620 792e 6e64 696d 203d 3d20 313a 0d0a  f y.ndim == 1:..
-0000d4d0: 2020 2020 2020 2020 2020 2020 795f 6f75              y_ou
-0000d4e0: 7420 3d20 795b 3a2c 206e 702e 6e65 7761  t = y[:, np.newa
-0000d4f0: 7869 735d 0d0a 0d0a 2020 2020 2020 2020  xis]....        
-0000d500: 7265 7475 726e 2079 5f6f 7574 2c20 6164  return y_out, ad
-0000d510: 6469 7469 6f6e 616c 5f64 6174 610d 0a0d  ditional_data...
-0000d520: 0a0d 0a63 6c61 7373 2044 6973 636f 6e74  ...class Discont
-0000d530: 696e 756f 7573 5269 6467 654d 616e 7566  inuousRidgeManuf
-0000d540: 6163 7475 7265 4465 6361 7947 656e 7a44  actureDecayGenzD
-0000d550: 6973 636f 6e74 696e 756f 7573 2841 6273  iscontinuous(Abs
-0000d560: 7472 6163 744d 6f64 656c 293a 0d0a 2020  tractModel):..  
-0000d570: 2020 2222 220d 0a20 2020 204e 2d64 696d    """..    N-dim
-0000d580: 656e 7369 6f6e 616c 2064 6973 636f 6e74  ensional discont
-0000d590: 696e 756f 7573 2074 6573 7420 6675 6e63  inuous test func
-0000d5a0: 7469 6f6e 2e20 5468 6520 6669 7273 7420  tion. The first 
-0000d5b0: 514f 4920 636f 7272 6573 706f 6e64 7320  QOI corresponds 
-0000d5c0: 746f 2074 6865 0d0a 2020 2020 4469 7363  to the..    Disc
-0000d5d0: 6f6e 7469 6e75 6f75 7352 6964 6765 4d61  ontinuousRidgeMa
-0000d5e0: 6e75 6661 6374 7572 6544 6563 6179 2066  nufactureDecay f
-0000d5f0: 756e 6374 696f 6e20 616e 6420 7468 6520  unction and the 
-0000d600: 7365 636f 6e64 2051 4f49 2074 6f20 4765  second QOI to Ge
-0000d610: 6e7a 4469 7363 6f6e 7469 6e75 6f75 732e  nzDiscontinuous.
-0000d620: 0d0a 0d0a 2020 2020 7920 3d20 4469 7363  ....    y = Disc
-0000d630: 6f6e 7469 6e75 6f75 7352 6964 6765 4d61  ontinuousRidgeMa
-0000d640: 6e75 6661 6374 7572 6544 6563 6179 4765  nufactureDecayGe
-0000d650: 6e7a 4469 7363 6f6e 7469 6e75 6f75 7328  nzDiscontinuous(
-0000d660: 7829 0d0a 0d0a 2020 2020 5061 7261 6d65  x)....    Parame
-0000d670: 7465 7273 0d0a 2020 2020 2d2d 2d2d 2d2d  ters..    ------
-0000d680: 2d2d 2d2d 0d0a 2020 2020 705b 2278 3122  ----..    p["x1"
-0000d690: 5d3a 2066 6c6f 6174 206f 7220 6e64 6172  ]: float or ndar
-0000d6a0: 7261 7920 6f66 2066 6c6f 6174 205b 6e5f  ray of float [n_
-0000d6b0: 6772 6964 5d0d 0a20 2020 2020 2020 2050  grid]..        P
-0000d6c0: 6172 616d 6574 6572 2031 205b 302c 2031  arameter 1 [0, 1
-0000d6d0: 5d0d 0a20 2020 2070 5b22 7832 225d 3a20  ]..    p["x2"]: 
-0000d6e0: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
-0000d6f0: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
-0000d700: 645d 0d0a 2020 2020 2020 2020 5061 7261  d]..        Para
-0000d710: 6d65 7465 7220 3220 5b30 2c20 315d 0d0a  meter 2 [0, 1]..
-0000d720: 2020 2020 705b 2278 3322 5d3a 2066 6c6f      p["x3"]: flo
-0000d730: 6174 206f 7220 6e64 6172 7261 7920 6f66  at or ndarray of
-0000d740: 2066 6c6f 6174 205b 6e5f 6772 6964 5d0d   float [n_grid].
-0000d750: 0a20 2020 2020 2020 2050 6172 616d 6574  .        Paramet
-0000d760: 6572 2033 205b 302c 2031 5d0d 0a0d 0a20  er 3 [0, 1].... 
-0000d770: 2020 2052 6574 7572 6e73 0d0a 2020 2020     Returns..    
-0000d780: 2d2d 2d2d 2d2d 2d0d 0a20 2020 2079 3a20  -------..    y: 
-0000d790: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-0000d7a0: 205b 6e5f 6772 6964 2078 206e 5f6f 7574   [n_grid x n_out
-0000d7b0: 5d0d 0a20 2020 2020 2020 204f 7574 7075  ]..        Outpu
-0000d7c0: 7420 6461 7461 0d0a 0d0a 2020 2020 4e6f  t data....    No
-0000d7d0: 7465 730d 0a20 2020 202d 2d2d 2d2d 0d0a  tes..    -----..
-0000d7e0: 2020 2020 2e2e 2070 6c6f 743a 3a0d 0a0d      .. plot::...
-0000d7f0: 0a20 2020 2020 2020 696d 706f 7274 206e  .       import n
-0000d800: 756d 7079 2061 7320 6e70 0d0a 2020 2020  umpy as np..    
-0000d810: 2020 2066 726f 6d20 7079 6770 632e 7465     from pygpc.te
-0000d820: 7374 6675 6e63 7469 6f6e 7320 696d 706f  stfunctions impo
-0000d830: 7274 2070 6c6f 745f 7465 7374 6675 6e63  rt plot_testfunc
-0000d840: 7469 6f6e 2061 7320 706c 6f74 0d0a 2020  tion as plot..  
-0000d850: 2020 2020 2066 726f 6d20 636f 6c6c 6563       from collec
-0000d860: 7469 6f6e 7320 696d 706f 7274 204f 7264  tions import Ord
-0000d870: 6572 6564 4469 6374 0d0a 0d0a 2020 2020  eredDict....    
-0000d880: 2020 2070 6172 616d 6574 6572 7320 3d20     parameters = 
-0000d890: 4f72 6465 7265 6444 6963 7428 290d 0a20  OrderedDict().. 
-0000d8a0: 2020 2020 2020 7061 7261 6d65 7465 7273        parameters
-0000d8b0: 5b22 7831 225d 203d 206e 702e 6c69 6e73  ["x1"] = np.lins
-0000d8c0: 7061 6365 2830 2c20 312c 2031 3030 290d  pace(0, 1, 100).
-0000d8d0: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
-0000d8e0: 7273 5b22 7832 225d 203d 206e 702e 6c69  rs["x2"] = np.li
-0000d8f0: 6e73 7061 6365 2830 2c20 312c 2031 3030  nspace(0, 1, 100
-0000d900: 290d 0a0d 0a20 2020 2020 2020 706c 6f74  )....       plot
-0000d910: 2822 4469 7363 6f6e 7469 6e75 6f75 7352  ("DiscontinuousR
-0000d920: 6964 6765 4d61 6e75 6661 6374 7572 6544  idgeManufactureD
-0000d930: 6563 6179 4765 6e7a 4469 7363 6f6e 7469  ecayGenzDisconti
-0000d940: 6e75 6f75 7322 2c20 7061 7261 6d65 7465  nuous", paramete
-0000d950: 7273 2c20 6f75 7470 7574 5f69 6478 3d5b  rs, output_idx=[
-0000d960: 302c 2031 5d29 0d0a 2020 2020 2222 220d  0, 1])..    """.
-0000d970: 0a0d 0a20 2020 2064 6566 205f 5f69 6e69  ...    def __ini
-0000d980: 745f 5f28 7365 6c66 2c20 6d61 746c 6162  t__(self, matlab
-0000d990: 5f6d 6f64 656c 3d46 616c 7365 293a 0d0a  _model=False):..
-0000d9a0: 2020 2020 2020 2020 7375 7065 7228 7479          super(ty
-0000d9b0: 7065 2873 656c 6629 2c20 7365 6c66 292e  pe(self), self).
-0000d9c0: 5f5f 696e 6974 5f5f 286d 6174 6c61 625f  __init__(matlab_
-0000d9d0: 6d6f 6465 6c3d 6d61 746c 6162 5f6d 6f64  model=matlab_mod
-0000d9e0: 656c 290d 0a20 2020 2020 2020 2073 656c  el)..        sel
-0000d9f0: 662e 666e 616d 6520 3d20 696e 7370 6563  f.fname = inspec
-0000da00: 742e 6765 7466 696c 6528 696e 7370 6563  t.getfile(inspec
-0000da10: 742e 6375 7272 656e 7466 7261 6d65 2829  t.currentframe()
-0000da20: 290d 0a0d 0a20 2020 2064 6566 2076 616c  )....    def val
-0000da30: 6964 6174 6528 7365 6c66 293a 0d0a 2020  idate(self):..  
-0000da40: 2020 2020 2020 7061 7373 0d0a 0d0a 2020        pass....  
-0000da50: 2020 6465 6620 7369 6d75 6c61 7465 2873    def simulate(s
-0000da60: 656c 662c 2070 726f 6365 7373 5f69 643d  elf, process_id=
-0000da70: 4e6f 6e65 2c20 6d61 746c 6162 5f65 6e67  None, matlab_eng
-0000da80: 696e 653d 4e6f 6e65 293a 0d0a 0d0a 2020  ine=None):....  
-0000da90: 2020 2020 2020 795f 3120 3d20 4469 7363        y_1 = Disc
-0000daa0: 6f6e 7469 6e75 6f75 7352 6964 6765 4d61  ontinuousRidgeMa
-0000dab0: 6e75 6661 6374 7572 6544 6563 6179 2829  nufactureDecay()
-0000dac0: 2e73 6574 5f70 6172 616d 6574 6572 7328  .set_parameters(
-0000dad0: 7365 6c66 2e70 292e 7369 6d75 6c61 7465  self.p).simulate
-0000dae0: 2829 0d0a 2020 2020 2020 2020 795f 3220  ()..        y_2 
-0000daf0: 3d20 4765 6e7a 4469 7363 6f6e 7469 6e75  = GenzDiscontinu
-0000db00: 6f75 7328 292e 7365 745f 7061 7261 6d65  ous().set_parame
-0000db10: 7465 7273 2873 656c 662e 7029 2e73 696d  ters(self.p).sim
-0000db20: 756c 6174 6528 290d 0a0d 0a20 2020 2020  ulate()....     
-0000db30: 2020 2079 203d 206e 702e 6873 7461 636b     y = np.hstack
-0000db40: 2828 795f 312c 2079 5f32 2929 0d0a 0d0a  ((y_1, y_2))....
-0000db50: 2020 2020 2020 2020 7265 7475 726e 2079          return y
-0000db60: 0d0a 0d0a 0d0a 636c 6173 7320 4879 7065  ......class Hype
-0000db70: 7262 6f6c 6963 5461 6e67 656e 7428 4162  rbolicTangent(Ab
-0000db80: 7374 7261 6374 4d6f 6465 6c29 3a0d 0a20  stractModel):.. 
-0000db90: 2020 2022 2222 0d0a 2020 2020 5477 6f2d     """..    Two-
-0000dba0: 6469 6d65 6e73 696f 6e61 6c20 6879 7065  dimensional hype
-0000dbb0: 7262 6f6c 6963 2074 616e 6765 6e74 2066  rbolic tangent f
-0000dbc0: 756e 6374 696f 6e20 5b31 5d20 746f 2073  unction [1] to s
-0000dbd0: 696d 756c 6174 6520 6469 7363 6f6e 7469  imulate disconti
-0000dbe0: 6e75 6974 6965 732e 2044 6973 636f 6e74  nuities. Discont
-0000dbf0: 696e 7569 7479 2061 7420 7831 203d 2030  inuity at x1 = 0
-0000dc00: 2e0d 0a0d 0a20 2020 202e 2e20 6d61 7468  .....    .. math
-0000dc10: 3a3a 0d0a 2020 2020 2020 2079 2878 5f31  ::..       y(x_1
-0000dc20: 2c20 785f 3229 203d 205c 5c74 616e 6828  , x_2) = \\tanh(
-0000dc30: 3130 2078 5f31 2920 2b20 302e 3220 5c73  10 x_1) + 0.2 \s
-0000dc40: 696e 2831 3020 785f 3129 202b 2030 2e33  in(10 x_1) + 0.3
-0000dc50: 2078 5f32 202b 2030 2e31 205c 7369 6e28   x_2 + 0.1 \sin(
-0000dc60: 3520 785f 3129 0d0a 0d0a 2020 2020 5061  5 x_1)....    Pa
-0000dc70: 7261 6d65 7465 7273 0d0a 2020 2020 2d2d  rameters..    --
-0000dc80: 2d2d 2d2d 2d2d 2d2d 0d0a 2020 2020 705b  --------..    p[
-0000dc90: 2278 3122 5d3a 2066 6c6f 6174 206f 7220  "x1"]: float or 
-0000dca0: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-0000dcb0: 205b 6e5f 6772 6964 5d0d 0a20 2020 2020   [n_grid]..     
-0000dcc0: 2020 2050 6172 616d 6574 6572 2031 205b     Parameter 1 [
-0000dcd0: 2d31 2c20 315d 0d0a 2020 2020 705b 2278  -1, 1]..    p["x
-0000dce0: 3222 5d3a 2066 6c6f 6174 206f 7220 6e64  2"]: float or nd
-0000dcf0: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
-0000dd00: 6e5f 6772 6964 5d0d 0a20 2020 2020 2020  n_grid]..       
-0000dd10: 2050 6172 616d 6574 6572 2032 205b 2d31   Parameter 2 [-1
-0000dd20: 2c20 315d 0d0a 0d0a 2020 2020 5265 7475  , 1]....    Retu
-0000dd30: 726e 730d 0a20 2020 202d 2d2d 2d2d 2d2d  rns..    -------
-0000dd40: 0d0a 2020 2020 793a 206e 6461 7272 6179  ..    y: ndarray
-0000dd50: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
-0000dd60: 6420 7820 315d 0d0a 2020 2020 2020 2020  d x 1]..        
-0000dd70: 4f75 7470 7574 2064 6174 610d 0a0d 0a20  Output data.... 
-0000dd80: 2020 204e 6f74 6573 0d0a 2020 2020 2d2d     Notes..    --
-0000dd90: 2d2d 2d0d 0a20 2020 202e 2e20 706c 6f74  ---..    .. plot
-0000dda0: 3a3a 0d0a 0d0a 2020 2020 2020 2069 6d70  ::....       imp
-0000ddb0: 6f72 7420 6e75 6d70 7920 6173 206e 700d  ort numpy as np.
-0000ddc0: 0a20 2020 2020 2020 6672 6f6d 2070 7967  .       from pyg
-0000ddd0: 7063 2e74 6573 7466 756e 6374 696f 6e73  pc.testfunctions
-0000dde0: 2069 6d70 6f72 7420 706c 6f74 5f74 6573   import plot_tes
-0000ddf0: 7466 756e 6374 696f 6e20 6173 2070 6c6f  tfunction as plo
-0000de00: 740d 0a20 2020 2020 2020 6672 6f6d 2063  t..       from c
-0000de10: 6f6c 6c65 6374 696f 6e73 2069 6d70 6f72  ollections impor
-0000de20: 7420 4f72 6465 7265 6444 6963 740d 0a0d  t OrderedDict...
-0000de30: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
-0000de40: 7273 203d 204f 7264 6572 6564 4469 6374  rs = OrderedDict
-0000de50: 2829 0d0a 2020 2020 2020 2070 6172 616d  ()..       param
-0000de60: 6574 6572 735b 2278 3122 5d20 3d20 6e70  eters["x1"] = np
-0000de70: 2e6c 696e 7370 6163 6528 2d31 2c20 312c  .linspace(-1, 1,
-0000de80: 2031 3030 290d 0a20 2020 2020 2020 7061   100)..       pa
-0000de90: 7261 6d65 7465 7273 5b22 7832 225d 203d  rameters["x2"] =
-0000dea0: 206e 702e 6c69 6e73 7061 6365 282d 312c   np.linspace(-1,
-0000deb0: 2031 2c20 3130 3029 0d0a 0d0a 2020 2020   1, 100)....    
-0000dec0: 2020 2070 6c6f 7428 2248 7970 6572 626f     plot("Hyperbo
-0000ded0: 6c69 6354 616e 6765 6e74 222c 2070 6172  licTangent", par
-0000dee0: 616d 6574 6572 7329 0d0a 0d0a 2020 2020  ameters)....    
-0000def0: 2e2e 205b 315d 2041 686c 6665 6c64 2c20  .. [1] Ahlfeld, 
-0000df00: 522e 2c20 4d6f 6e74 6f6d 6f6c 692c 2046  R., Montomoli, F
-0000df10: 2e2c 2043 6172 6e65 7661 6c65 2c20 4d2e  ., Carnevale, M.
-0000df20: 2c20 5361 6c76 6164 6f72 652c 2053 2e20  , Salvadore, S. 
-0000df30: 2832 3031 3829 2e0d 0a20 2020 2020 2020  (2018)...       
-0000df40: 4175 746f 6e6f 6d6f 7573 2055 6e63 6572  Autonomous Uncer
-0000df50: 7461 696e 7479 2051 7561 6e74 6966 6963  tainty Quantific
-0000df60: 6174 696f 6e20 666f 7220 4469 7363 6f6e  ation for Discon
-0000df70: 7469 6e75 6f75 7320 4d6f 6465 6c73 2055  tinuous Models U
-0000df80: 7369 6e67 204d 756c 7469 7661 7269 6174  sing Multivariat
-0000df90: 6520 5061 6465 2041 7070 726f 7869 6d61  e Pade Approxima
-0000dfa0: 7469 6f6e 732e 0d0a 2020 2020 2020 204a  tions...       J
-0000dfb0: 6f75 726e 616c 206f 6620 5475 7262 6f6d  ournal of Turbom
-0000dfc0: 6163 6869 6e65 7279 2c20 3130 342c 2030  achinery, 104, 0
-0000dfd0: 3431 3030 342e 0d0a 2020 2020 2222 220d  41004...    """.
-0000dfe0: 0a0d 0a20 2020 2064 6566 205f 5f69 6e69  ...    def __ini
-0000dff0: 745f 5f28 7365 6c66 2c20 6d61 746c 6162  t__(self, matlab
-0000e000: 5f6d 6f64 656c 3d46 616c 7365 293a 0d0a  _model=False):..
-0000e010: 2020 2020 2020 2020 7375 7065 7228 7479          super(ty
-0000e020: 7065 2873 656c 6629 2c20 7365 6c66 292e  pe(self), self).
-0000e030: 5f5f 696e 6974 5f5f 286d 6174 6c61 625f  __init__(matlab_
-0000e040: 6d6f 6465 6c3d 6d61 746c 6162 5f6d 6f64  model=matlab_mod
-0000e050: 656c 290d 0a20 2020 2020 2020 2073 656c  el)..        sel
-0000e060: 662e 666e 616d 6520 3d20 696e 7370 6563  f.fname = inspec
-0000e070: 742e 6765 7466 696c 6528 696e 7370 6563  t.getfile(inspec
-0000e080: 742e 6375 7272 656e 7466 7261 6d65 2829  t.currentframe()
-0000e090: 290d 0a0d 0a20 2020 2064 6566 2076 616c  )....    def val
-0000e0a0: 6964 6174 6528 7365 6c66 293a 0d0a 2020  idate(self):..  
-0000e0b0: 2020 2020 2020 7061 7373 0d0a 0d0a 2020        pass....  
-0000e0c0: 2020 6465 6620 7369 6d75 6c61 7465 2873    def simulate(s
-0000e0d0: 656c 662c 2070 726f 6365 7373 5f69 643d  elf, process_id=
-0000e0e0: 4e6f 6e65 2c20 6d61 746c 6162 5f65 6e67  None, matlab_eng
-0000e0f0: 696e 653d 4e6f 6e65 293a 0d0a 2020 2020  ine=None):..    
-0000e100: 2020 2020 7920 3d20 6e70 2e61 7272 6179      y = np.array
-0000e110: 286e 702e 7461 6e68 2831 302e 202a 2073  (np.tanh(10. * s
-0000e120: 656c 662e 705b 2278 3122 5d29 202b 2030  elf.p["x1"]) + 0
-0000e130: 2e32 202a 206e 702e 7369 6e28 3130 2e20  .2 * np.sin(10. 
-0000e140: 2a20 7365 6c66 2e70 5b22 7831 225d 2920  * self.p["x1"]) 
-0000e150: 2b20 302e 3320 2a20 7365 6c66 2e70 5b22  + 0.3 * self.p["
-0000e160: 7832 225d 202b 0d0a 2020 2020 2020 2020  x2"] +..        
-0000e170: 2020 2020 2020 2020 2020 2020 2030 2e31               0.1
-0000e180: 202a 206e 702e 7369 6e28 352e 202a 2073   * np.sin(5. * s
-0000e190: 656c 662e 705b 2278 3122 5d29 290d 0a0d  elf.p["x1"]))...
-0000e1a0: 0a20 2020 2020 2020 2069 6620 6c65 6e28  .        if len(
-0000e1b0: 7929 203e 2031 3a0d 0a20 2020 2020 2020  y) > 1:..       
-0000e1c0: 2020 2020 2079 203d 2079 5b3a 2c20 6e70       y = y[:, np
-0000e1d0: 2e6e 6577 6178 6973 5d0d 0a0d 0a20 2020  .newaxis]....   
-0000e1e0: 2020 2020 2072 6574 7572 6e20 790d 0a0d       return y...
-0000e1f0: 0a0d 0a63 6c61 7373 204d 6f76 696e 6750  ...class MovingP
-0000e200: 6172 7469 636c 6546 7269 6374 696f 6e46  articleFrictionF
-0000e210: 6f72 6365 2841 6273 7472 6163 744d 6f64  orce(AbstractMod
-0000e220: 656c 293a 0d0a 2020 2020 2222 220d 0a20  el):..    """.. 
-0000e230: 2020 2044 6966 6665 7265 6e74 6961 6c20     Differential 
-0000e240: 6571 7561 7469 6f6e 2064 6573 6372 6962  equation describ
-0000e250: 696e 6720 6120 7061 7274 6963 6c65 206d  ing a particle m
-0000e260: 6f76 696e 6720 756e 6465 7220 7468 6520  oving under the 
-0000e270: 696e 666c 7565 6e63 6520 6f66 2061 0d0a  influence of a..
-0000e280: 2020 2020 706f 7465 6e74 6961 6c20 6669      potential fi
-0000e290: 656c 6420 616e 6420 6f66 2061 2066 7269  eld and of a fri
-0000e2a0: 6374 696f 6e20 666f 7263 6520 5b31 5d2e  ction force [1].
-0000e2b0: 0d0a 0d0a 2020 2020 2e2e 206d 6174 683a  ....    .. math:
-0000e2c0: 3a20 5c5c 6672 6163 7b64 5e32 2078 7d7b  : \\frac{d^2 x}{
-0000e2d0: 6474 5e32 7d20 2b20 6620 5c5c 6672 6163  dt^2} + f \\frac
-0000e2e0: 7b64 787d 7b64 747d 203d 202d 5c5c 6672  {dx}{dt} = -\\fr
-0000e2f0: 6163 7b33 357d 7b32 7d20 785e 3320 2b20  ac{35}{2} x^3 + 
-0000e300: 5c5c 6672 6163 7b31 357d 7b32 7d20 780d  \\frac{15}{2} x.
-0000e310: 0a0d 0a20 2020 2077 6974 683a 0d0a 0d0a  ...    with:....
-0000e320: 2020 2020 2e2e 206d 6174 683a 3a20 785f      .. math:: x_
-0000e330: 3120 3d20 780d 0a20 2020 202e 2e20 6d61  1 = x..    .. ma
-0000e340: 7468 3a3a 2078 5f32 203d 205c 5c66 7261  th:: x_2 = \\fra
-0000e350: 637b 6478 7d7b 6474 7d0d 0a0d 0a20 2020  c{dx}{dt}....   
-0000e360: 2077 6520 6765 7420 6120 7379 7374 656d   we get a system
-0000e370: 206f 6620 7477 6f20 3173 7420 6f72 6465   of two 1st orde
-0000e380: 7220 4f44 450d 0a0d 0a20 2020 202e 2e20  r ODE....    .. 
-0000e390: 6d61 7468 3a3a 205c 5c66 7261 637b 6420  math:: \\frac{d 
-0000e3a0: 785f 317d 7b64 747d 203d 2078 5f32 0d0a  x_1}{dt} = x_2..
-0000e3b0: 2020 2020 2e2e 206d 6174 683a 3a20 5c5c      .. math:: \\
-0000e3c0: 6672 6163 7b64 2078 5f32 7d7b 6474 7d20  frac{d x_2}{dt} 
-0000e3d0: 3d20 2d5c 5c66 7261 637b 3335 7d7b 327d  = -\\frac{35}{2}
-0000e3e0: 2078 5f31 5e33 202b 205c 5c66 7261 637b   x_1^3 + \\frac{
-0000e3f0: 3135 7d7b 327d 2078 5f31 202d 2066 2078  15}{2} x_1 - f x
-0000e400: 5f32 0d0a 0d0a 2020 2020 4469 7363 6f6e  _2....    Discon
-0000e410: 7469 6e75 6974 7920 6174 2072 616e 646f  tinuity at rando
-0000e420: 6d6c 7920 7065 7274 7572 6265 6420 696e  mly perturbed in
-0000e430: 6974 6961 6c20 7661 6c75 6520 7830 203d  itial value x0 =
-0000e440: 2058 3020 2b20 6465 6c74 615f 5820 2a20   X0 + delta_X * 
-0000e450: 7869 203d 2030 2e30 3520 2d20 302e 3220  xi = 0.05 - 0.2 
-0000e460: 2a20 302e 3235 0d0a 2020 2020 616e 6420  * 0.25..    and 
-0000e470: 7477 6f20 7374 6162 6c65 2066 6978 6564  two stable fixed
-0000e480: 2070 6f69 6e74 733a 0d0a 0d0a 2020 2020   points:....    
-0000e490: 2e2e 206d 6174 683a 3a20 7820 3d20 2d5c  .. math:: x = -\
-0000e4a0: 7371 7274 7b31 352f 3335 7d20 5c3b 205c  sqrt{15/35} \; \
-0000e4b0: 6d61 7468 726d 7b66 6f72 7d20 5c3b 205c  mathrm{for} \; \
-0000e4c0: 5c78 6920 3c20 2d30 2e32 350d 0a20 2020  \xi < -0.25..   
-0000e4d0: 202e 2e20 6d61 7468 3a3a 2078 203d 202b   .. math:: x = +
-0000e4e0: 5c73 7172 747b 3135 2f33 357d 205c 3b20  \sqrt{15/35} \; 
-0000e4f0: 5c6d 6174 6872 6d7b 666f 727d 205c 3b20  \mathrm{for} \; 
-0000e500: 5c5c 7869 203e 202d 302e 3235 0d0a 0d0a  \\xi > -0.25....
-0000e510: 2020 2020 7869 2069 7320 756e 6966 6f72      xi is unifor
-0000e520: 6d20 6469 7374 7269 6275 7465 6420 5b2d  m distributed [-
-0000e530: 312c 2031 5d0d 0a0d 0a20 2020 204d 6561  1, 1]....    Mea
-0000e540: 6e20 7661 6c75 653a 2030 2e31 3633 3636  n value: 0.16366
-0000e550: 330d 0a20 2020 2053 7461 6e64 6172 6420  3..    Standard 
-0000e560: 6465 7669 6174 696f 6e3a 2030 2e36 3333  deviation: 0.633
-0000e570: 3836 3536 3931 0d0a 0d0a 2020 2020 5061  865691....    Pa
-0000e580: 7261 6d65 7465 7273 0d0a 2020 2020 2d2d  rameters..    --
-0000e590: 2d2d 2d2d 2d2d 2d2d 0d0a 2020 2020 705b  --------..    p[
-0000e5a0: 2278 6922 5d3a 206e 6461 7272 6179 206f  "xi"]: ndarray o
-0000e5b0: 6620 666c 6f61 7420 5b31 5d0d 0a20 2020  f float [1]..   
-0000e5c0: 2020 2020 2050 6572 7475 6261 7469 6f6e       Pertubation
-0000e5d0: 2078 6920 6f66 2069 6e69 7469 616c 2076   xi of initial v
-0000e5e0: 616c 7565 2078 3020 2878 3020 3d20 5830  alue x0 (x0 = X0
-0000e5f0: 202b 2078 6929 205b 2d31 2c20 315d 0d0a   + xi) [-1, 1]..
-0000e600: 0d0a 2020 2020 5265 7475 726e 730d 0a20  ..    Returns.. 
-0000e610: 2020 202d 2d2d 2d2d 2d2d 0d0a 2020 2020     -------..    
-0000e620: 793a 206e 6461 7272 6179 206f 6620 666c  y: ndarray of fl
-0000e630: 6f61 7420 5b31 2078 2031 5d0d 0a20 2020  oat [1 x 1]..   
-0000e640: 2020 2020 2078 2874 3d31 302e 290d 0a0d       x(t=10.)...
-0000e650: 0a20 2020 204e 6f74 6573 0d0a 2020 2020  .    Notes..    
-0000e660: 2d2d 2d2d 2d0d 0a20 2020 202e 2e20 706c  -----..    .. pl
-0000e670: 6f74 3a3a 0d0a 0d0a 2020 2020 2020 2069  ot::....       i
-0000e680: 6d70 6f72 7420 6e75 6d70 7920 6173 206e  mport numpy as n
-0000e690: 700d 0a20 2020 2020 2020 6672 6f6d 2070  p..       from p
-0000e6a0: 7967 7063 2e74 6573 7466 756e 6374 696f  ygpc.testfunctio
-0000e6b0: 6e73 2069 6d70 6f72 7420 706c 6f74 5f74  ns import plot_t
-0000e6c0: 6573 7466 756e 6374 696f 6e20 6173 2070  estfunction as p
-0000e6d0: 6c6f 740d 0a20 2020 2020 2020 6672 6f6d  lot..       from
-0000e6e0: 2063 6f6c 6c65 6374 696f 6e73 2069 6d70   collections imp
-0000e6f0: 6f72 7420 4f72 6465 7265 6444 6963 740d  ort OrderedDict.
-0000e700: 0a0d 0a20 2020 2020 2020 7061 7261 6d65  ...       parame
-0000e710: 7465 7273 203d 204f 7264 6572 6564 4469  ters = OrderedDi
-0000e720: 6374 2829 0d0a 2020 2020 2020 2070 6172  ct()..       par
-0000e730: 616d 6574 6572 735b 2278 6922 5d20 3d20  ameters["xi"] = 
-0000e740: 6e70 2e6c 696e 7370 6163 6528 2d31 2c20  np.linspace(-1, 
-0000e750: 312c 2031 3030 290d 0a0d 0a20 2020 2020  1, 100)....     
-0000e760: 2020 706c 6f74 2822 4d6f 7669 6e67 5061    plot("MovingPa
-0000e770: 7274 6963 6c65 4672 6963 7469 6f6e 466f  rticleFrictionFo
-0000e780: 7263 6522 2c20 7061 7261 6d65 7465 7273  rce", parameters
-0000e790: 290d 0a0d 0a20 2020 202e 2e20 5b31 5d20  )....    .. [1] 
-0000e7a0: 4c65 204d 6169 7472 652c 204f 2e50 2e2c  Le Maitre, O.P.,
-0000e7b0: 204b 6e69 6f2c 204f 2e4d 2e2c 204e 616a   Knio, O.M., Naj
-0000e7c0: 6d2c 2048 2e4e 2e2c 2047 6861 6e65 6d2c  m, H.N., Ghanem,
-0000e7d0: 2052 2e47 2e20 2832 3030 3429 2e0d 0a20   R.G. (2004)... 
-0000e7e0: 2020 2020 2020 556e 6365 7274 6169 6e74        Uncertaint
-0000e7f0: 7920 7072 6f70 6167 6174 696f 6e20 7573  y propagation us
-0000e800: 696e 6720 5769 656e 6572 2d48 6161 7220  ing Wiener-Haar 
-0000e810: 6578 7061 6e73 696f 6e73 2e0d 0a20 2020  expansions...   
-0000e820: 2020 2020 4a6f 7572 6e61 6c20 6f66 2043      Journal of C
-0000e830: 6f6d 7075 7461 7469 6f6e 616c 2050 6879  omputational Phy
-0000e840: 7369 6373 2c20 3139 372c 2032 382d 3537  sics, 197, 28-57
-0000e850: 2e0d 0a20 2020 2022 2222 0d0a 0d0a 2020  ...    """....  
-0000e860: 2020 6465 6620 5f5f 696e 6974 5f5f 2873    def __init__(s
-0000e870: 656c 662c 206d 6174 6c61 625f 6d6f 6465  elf, matlab_mode
-0000e880: 6c3d 4661 6c73 6529 3a0d 0a20 2020 2020  l=False):..     
-0000e890: 2020 2073 7570 6572 2874 7970 6528 7365     super(type(se
-0000e8a0: 6c66 292c 2073 656c 6629 2e5f 5f69 6e69  lf), self).__ini
-0000e8b0: 745f 5f28 6d61 746c 6162 5f6d 6f64 656c  t__(matlab_model
-0000e8c0: 3d6d 6174 6c61 625f 6d6f 6465 6c29 0d0a  =matlab_model)..
-0000e8d0: 2020 2020 2020 2020 7365 6c66 2e66 6e61          self.fna
-0000e8e0: 6d65 203d 2069 6e73 7065 6374 2e67 6574  me = inspect.get
-0000e8f0: 6669 6c65 2869 6e73 7065 6374 2e63 7572  file(inspect.cur
-0000e900: 7265 6e74 6672 616d 6528 2929 0d0a 0d0a  rentframe())....
-0000e910: 2020 2020 6465 6620 7661 6c69 6461 7465      def validate
-0000e920: 2873 656c 6629 3a0d 0a20 2020 2020 2020  (self):..       
-0000e930: 2070 6173 730d 0a0d 0a20 2020 2064 6566   pass....    def
-0000e940: 2073 696d 756c 6174 6528 7365 6c66 2c20   simulate(self, 
-0000e950: 7072 6f63 6573 735f 6964 3d4e 6f6e 652c  process_id=None,
-0000e960: 206d 6174 6c61 625f 656e 6769 6e65 3d4e   matlab_engine=N
-0000e970: 6f6e 6529 3a0d 0a20 2020 2020 2020 2023  one):..        #
-0000e980: 2053 7973 7465 6d20 6f66 2031 7374 206f   System of 1st o
-0000e990: 7264 6572 2044 4551 0d0a 2020 2020 2020  rder DEQ..      
-0000e9a0: 2020 6465 6620 6465 7128 782c 2074 2c20    def deq(x, t, 
-0000e9b0: 6629 3a0d 0a20 2020 2020 2020 2020 2020  f):..           
-0000e9c0: 2072 6574 7572 6e20 785b 315d 2c20 2d33   return x[1], -3
-0000e9d0: 352e 202f 2032 2e20 2a20 785b 305d 202a  5. / 2. * x[0] *
-0000e9e0: 2a20 332e 202b 2031 352e 202f 2032 2e20  * 3. + 15. / 2. 
-0000e9f0: 2a20 785b 305d 202d 2066 202a 2078 5b31  * x[0] - f * x[1
-0000ea00: 5d0d 0a0d 0a20 2020 2020 2020 2023 2049  ]....        # I
-0000ea10: 6e69 7469 616c 2076 616c 7565 730d 0a20  nitial values.. 
-0000ea20: 2020 2020 2020 2078 3020 3d20 302e 3035         x0 = 0.05
-0000ea30: 0d0a 2020 2020 2020 2020 6465 6c74 615f  ..        delta_
-0000ea40: 7820 3d20 302e 320d 0a0d 0a20 2020 2020  x = 0.2....     
-0000ea50: 2020 2023 2046 7269 6374 696f 6e20 636f     # Friction co
-0000ea60: 6566 6669 6369 656e 740d 0a20 2020 2020  efficient..     
-0000ea70: 2020 2066 203d 2032 2e0d 0a0d 0a20 2020     f = 2.....   
-0000ea80: 2020 2020 2023 2053 696d 756c 6174 696f       # Simulatio
-0000ea90: 6e20 7061 7261 6d65 7465 7273 0d0a 2020  n parameters..  
-0000eaa0: 2020 2020 2020 6474 203d 2030 2e30 3031        dt = 0.001
-0000eab0: 0d0a 2020 2020 2020 2020 745f 656e 6420  ..        t_end 
-0000eac0: 3d20 3130 2e0d 0a20 2020 2020 2020 2074  = 10...        t
-0000ead0: 203d 206e 702e 6172 616e 6765 2830 2c20   = np.arange(0, 
-0000eae0: 745f 656e 642c 2064 7429 0d0a 0d0a 2020  t_end, dt)....  
-0000eaf0: 2020 2020 2020 2320 536f 6c76 650d 0a20        # Solve.. 
-0000eb00: 2020 2020 2020 2079 5f6f 7574 203d 206e         y_out = n
-0000eb10: 702e 7a65 726f 7328 286c 656e 2873 656c  p.zeros((len(sel
-0000eb20: 662e 705b 2278 6922 5d29 2c20 3129 290d  f.p["xi"]), 1)).
-0000eb30: 0a0d 0a20 2020 2020 2020 2066 6f72 2069  ...        for i
-0000eb40: 2069 6e20 7261 6e67 6528 6c65 6e28 795f   in range(len(y_
-0000eb50: 6f75 7429 293a 0d0a 2020 2020 2020 2020  out)):..        
-0000eb60: 2020 2020 7830 5f69 6e69 7420 3d20 5b78      x0_init = [x
-0000eb70: 3020 2b20 6465 6c74 615f 7820 2a20 7365  0 + delta_x * se
-0000eb80: 6c66 2e70 5b22 7869 225d 2e66 6c61 7474  lf.p["xi"].flatt
-0000eb90: 656e 2829 5b69 5d2c 2030 2e5d 0d0a 2020  en()[i], 0.]..  
-0000eba0: 2020 2020 2020 2020 2020 7920 3d20 6f64            y = od
-0000ebb0: 6569 6e74 2864 6571 2c20 7830 5f69 6e69  eint(deq, x0_ini
-0000ebc0: 742c 2074 2c20 6172 6773 3d28 662c 292c  t, t, args=(f,),
-0000ebd0: 2068 6d69 6e3d 6474 290d 0a20 2020 2020   hmin=dt)..     
-0000ebe0: 2020 2020 2020 2079 5f6f 7574 5b69 2c20         y_out[i, 
-0000ebf0: 305d 203d 206e 702e 6172 7261 7928 5b5b  0] = np.array([[
-0000ec00: 795b 2d31 2c20 305d 5d5d 290d 0a0d 0a20  y[-1, 0]]]).... 
-0000ec10: 2020 2020 2020 2072 6574 7572 6e20 795f         return y_
-0000ec20: 6f75 740d 0a0d 0a0d 0a63 6c61 7373 2053  out......class S
-0000ec30: 7572 6661 6365 436f 7665 7261 6765 5370  urfaceCoverageSp
-0000ec40: 6563 6965 7328 4162 7374 7261 6374 4d6f  ecies(AbstractMo
-0000ec50: 6465 6c29 3a0d 0a20 2020 2022 2222 0d0a  del):..    """..
-0000ec60: 2020 2020 4469 6666 6572 656e 7469 616c      Differential
-0000ec70: 2065 7175 6174 696f 6e20 6465 7363 7269   equation descri
-0000ec80: 6269 6e67 2074 6865 2074 696d 652d 6576  bing the time-ev
-0000ec90: 6f6c 7574 696f 6e20 6f66 2074 6865 2073  olution of the s
-0000eca0: 7572 6661 6365 2063 6f76 6572 6167 6520  urface coverage 
-0000ecb0: 7268 6f20 5b30 2c20 315d 2066 6f72 2061  rho [0, 1] for a
-0000ecc0: 2067 6976 656e 2073 7065 6369 6573 205b   given species [
-0000ecd0: 315d 2e0d 0a20 2020 2054 6869 7320 7072  1]...    This pr
-0000ece0: 6f62 6c65 6d20 6861 7320 6f6e 6520 6f72  oblem has one or
-0000ecf0: 2074 776f 2066 6978 6564 2070 6f69 6e74   two fixed point
-0000ed00: 7320 6163 636f 7264 696e 6720 746f 2074  s according to t
-0000ed10: 6865 2076 616c 7565 206f 6620 7468 6520  he value of the 
-0000ed20: 7265 636f 6d62 696e 6174 696f 6e20 7261  recombination ra
-0000ed30: 7465 2062 6574 6120 616e 6420 6974 2065  te beta and it e
-0000ed40: 7868 6962 6974 730d 0a20 2020 2073 6d6f  xhibits..    smo
-0000ed50: 6f74 6820 6465 7065 6e64 656e 6365 206f  oth dependence o
-0000ed60: 6e20 7468 6520 6f74 6865 7220 7061 7261  n the other para
-0000ed70: 6d65 7465 7273 2e20 5468 6520 7374 6174  meters. The stat
-0000ed80: 6973 7469 6373 206f 6620 7468 6520 736f  istics of the so
-0000ed90: 6c75 7469 6f6e 2061 7420 743d 3120 6172  lution at t=1 ar
-0000eda0: 6520 696e 7665 7374 6967 6174 6564 2063  e investigated c
-0000edb0: 6f6e 7369 6465 7269 6e67 0d0a 2020 2020  onsidering..    
-0000edc0: 756e 6365 7274 6169 6e74 6965 7320 696e  uncertainties in
-0000edd0: 2074 6865 2069 6e69 7469 616c 2063 6f76   the initial cov
-0000ede0: 6572 6167 6520 7268 6f5f 3020 616e 6420  erage rho_0 and 
-0000edf0: 696e 2074 6865 2072 6561 6374 696f 6e20  in the reaction 
-0000ee00: 7061 7261 6d65 7465 7220 6265 7461 2e20  parameter beta. 
-0000ee10: 4164 6469 7469 6f6e 616c 6c79 2075 6e63  Additionally unc
-0000ee20: 6572 7461 696e 7479 0d0a 2020 2020 696e  ertainty..    in
-0000ee30: 2074 6865 2073 7572 6661 6365 2061 6273   the surface abs
-0000ee40: 6f72 7074 696f 6e20 7261 7465 2061 6c70  orption rate alp
-0000ee50: 6861 2063 616e 2062 6520 636f 6e73 6964  ha can be consid
-0000ee60: 6572 6564 2074 6f20 6d61 6b65 2074 6865  ered to make the
-0000ee70: 2070 726f 626c 656d 2033 2d64 696d 656e   problem 3-dimen
-0000ee80: 7369 6f6e 616c 2e0d 0a20 2020 2047 616d  sional...    Gam
-0000ee90: 6d61 3d30 2e30 3120 6465 6e6f 7465 7320  ma=0.01 denotes 
-0000eea0: 7468 6520 6465 736f 7270 7469 6f6e 2072  the desorption r
-0000eeb0: 6174 652e 0d0a 0d0a 2020 2020 2e2e 206d  ate.....    .. m
-0000eec0: 6174 683a 3a20 5c5c 6672 6163 7b64 5c5c  ath:: \\frac{d\\
-0000eed0: 7268 6f7d 7b64 747d 203d 205c 5c61 6c70  rho}{dt} = \\alp
-0000eee0: 6861 2028 3120 2d20 5c5c 7268 6f29 202d  ha (1 - \\rho) -
-0000eef0: 205c 5c67 616d 6d61 205c 5c72 686f 202d   \\gamma \\rho -
-0000ef00: 205c 5c62 6574 6120 285c 5c72 686f 202d   \\beta (\\rho -
-0000ef10: 2031 295e 3220 5c5c 7268 6f0d 0a0d 0a20   1)^2 \\rho.... 
-0000ef20: 2020 2050 6172 616d 6574 6572 730d 0a20     Parameters.. 
-0000ef30: 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0d 0a20     ----------.. 
-0000ef40: 2020 2070 5b22 7268 6f5f 3022 5d3a 206e     p["rho_0"]: n
-0000ef50: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-0000ef60: 5b31 5d0d 0a20 2020 2020 2020 2049 6e69  [1]..        Ini
-0000ef70: 7469 616c 2076 616c 7565 2072 686f 2874  tial value rho(t
-0000ef80: 3d30 2920 2875 6e69 666f 726d 2064 6973  =0) (uniform dis
-0000ef90: 7472 6962 7574 6564 205b 302c 2031 5d29  tributed [0, 1])
-0000efa0: 0d0a 2020 2020 705b 2262 6574 6122 5d3a  ..    p["beta"]:
-0000efb0: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-0000efc0: 7420 5b31 5d0d 0a20 2020 2020 2020 2052  t [1]..        R
-0000efd0: 6563 6f6d 6269 6e61 7469 6f6e 2072 6174  ecombination rat
-0000efe0: 6520 2875 6e69 666f 726d 2064 6973 7472  e (uniform distr
-0000eff0: 6962 7574 6564 205b 302c 2032 305d 290d  ibuted [0, 20]).
-0000f000: 0a20 2020 2070 5b22 616c 7068 6122 5d3a  .    p["alpha"]:
-0000f010: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-0000f020: 7420 5b31 5d0d 0a20 2020 2020 2020 2053  t [1]..        S
-0000f030: 7572 6661 6365 2061 6273 6f72 7074 696f  urface absorptio
-0000f040: 6e20 7261 7465 2028 3120 6f72 2075 6e69  n rate (1 or uni
-0000f050: 666f 726d 2064 6973 7472 6962 7574 6564  form distributed
-0000f060: 205b 302e 312c 2032 5d29 0d0a 0d0a 2020   [0.1, 2])....  
-0000f070: 2020 5265 7475 726e 730d 0a20 2020 202d    Returns..    -
-0000f080: 2d2d 2d2d 2d2d 0d0a 2020 2020 793a 206e  ------..    y: n
-0000f090: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-0000f0a0: 5b31 2078 2031 5d0d 0a20 2020 2020 2020  [1 x 1]..       
-0000f0b0: 2072 686f 2874 2d3e 3129 0d0a 0d0a 2020   rho(t->1)....  
-0000f0c0: 2020 4e6f 7465 730d 0a20 2020 202d 2d2d    Notes..    ---
-0000f0d0: 2d2d 0d0a 2020 2020 2e2e 2070 6c6f 743a  --..    .. plot:
-0000f0e0: 3a0d 0a0d 0a20 2020 2020 2020 696d 706f  :....       impo
-0000f0f0: 7274 206e 756d 7079 2061 7320 6e70 0d0a  rt numpy as np..
-0000f100: 2020 2020 2020 2066 726f 6d20 7079 6770         from pygp
-0000f110: 632e 7465 7374 6675 6e63 7469 6f6e 7320  c.testfunctions 
-0000f120: 696d 706f 7274 2070 6c6f 745f 7465 7374  import plot_test
-0000f130: 6675 6e63 7469 6f6e 2061 7320 706c 6f74  function as plot
-0000f140: 0d0a 2020 2020 2020 2066 726f 6d20 636f  ..       from co
-0000f150: 6c6c 6563 7469 6f6e 7320 696d 706f 7274  llections import
-0000f160: 204f 7264 6572 6564 4469 6374 0d0a 0d0a   OrderedDict....
-0000f170: 2020 2020 2020 2070 6172 616d 6574 6572         parameter
-0000f180: 7320 3d20 4f72 6465 7265 6444 6963 7428  s = OrderedDict(
-0000f190: 290d 0a20 2020 2020 2020 7061 7261 6d65  )..       parame
-0000f1a0: 7465 7273 5b22 7268 6f5f 3022 5d20 3d20  ters["rho_0"] = 
-0000f1b0: 6e70 2e6c 696e 7370 6163 6528 302c 2031  np.linspace(0, 1
-0000f1c0: 2c20 3130 3029 0d0a 2020 2020 2020 2070  , 100)..       p
-0000f1d0: 6172 616d 6574 6572 735b 2262 6574 6122  arameters["beta"
-0000f1e0: 5d20 3d20 6e70 2e6c 696e 7370 6163 6528  ] = np.linspace(
-0000f1f0: 302c 2032 302c 2031 3030 290d 0a0d 0a20  0, 20, 100).... 
-0000f200: 2020 2020 2020 636f 6e73 7461 6e74 7320        constants 
-0000f210: 3d20 4f72 6465 7265 6444 6963 7428 290d  = OrderedDict().
-0000f220: 0a20 2020 2020 2020 636f 6e73 7461 6e74  .       constant
-0000f230: 735b 2261 6c70 6861 225d 203d 2031 2e0d  s["alpha"] = 1..
-0000f240: 0a0d 0a20 2020 2020 2020 706c 6f74 2822  ...       plot("
-0000f250: 5375 7266 6163 6543 6f76 6572 6167 6553  SurfaceCoverageS
-0000f260: 7065 6369 6573 222c 2070 6172 616d 6574  pecies", paramet
-0000f270: 6572 732c 2063 6f6e 7374 616e 7473 2c20  ers, constants, 
-0000f280: 706c 6f74 5f33 643d 4661 6c73 6529 0d0a  plot_3d=False)..
-0000f290: 0d0a 2020 2020 2e2e 205b 315d 204c 6520  ..    .. [1] Le 
-0000f2a0: 4d61 6974 7265 2c20 4f2e 502e 2c20 4e61  Maitre, O.P., Na
-0000f2b0: 6a6d 2c20 482e 4e2e 2c20 4768 616e 656d  jm, H.N., Ghanem
-0000f2c0: 2c20 522e 472e 2c20 4b6e 696f 2c20 4f2e  , R.G., Knio, O.
-0000f2d0: 4d2e 2c20 2832 3030 3429 2e0d 0a20 2020  M., (2004)...   
-0000f2e0: 2020 2020 4d75 6c74 692d 7265 736f 6c75      Multi-resolu
-0000f2f0: 7469 6f6e 2061 6e61 6c79 7369 7320 6f66  tion analysis of
-0000f300: 2057 6965 6e65 722d 7479 7065 2075 6e63   Wiener-type unc
-0000f310: 6572 7461 696e 7479 2070 726f 7061 6761  ertainty propaga
-0000f320: 7469 6f6e 2073 6368 656d 6573 2e0d 0a20  tion schemes... 
-0000f330: 2020 2020 2020 4a6f 7572 6e61 6c20 6f66        Journal of
-0000f340: 2043 6f6d 7075 7461 7469 6f6e 616c 2050   Computational P
-0000f350: 6879 7369 6373 2c20 3139 372c 2035 3032  hysics, 197, 502
-0000f360: 2d35 3331 2e0d 0a20 2020 2022 2222 0d0a  -531...    """..
-0000f370: 0d0a 2020 2020 6465 6620 5f5f 696e 6974  ..    def __init
-0000f380: 5f5f 2873 656c 662c 206d 6174 6c61 625f  __(self, matlab_
-0000f390: 6d6f 6465 6c3d 4661 6c73 6529 3a0d 0a20  model=False):.. 
-0000f3a0: 2020 2020 2020 2073 7570 6572 2874 7970         super(typ
-0000f3b0: 6528 7365 6c66 292c 2073 656c 6629 2e5f  e(self), self)._
-0000f3c0: 5f69 6e69 745f 5f28 6d61 746c 6162 5f6d  _init__(matlab_m
-0000f3d0: 6f64 656c 3d6d 6174 6c61 625f 6d6f 6465  odel=matlab_mode
-0000f3e0: 6c29 0d0a 2020 2020 2020 2020 7365 6c66  l)..        self
-0000f3f0: 2e66 6e61 6d65 203d 2069 6e73 7065 6374  .fname = inspect
-0000f400: 2e67 6574 6669 6c65 2869 6e73 7065 6374  .getfile(inspect
-0000f410: 2e63 7572 7265 6e74 6672 616d 6528 2929  .currentframe())
-0000f420: 0d0a 0d0a 2020 2020 6465 6620 7661 6c69  ....    def vali
-0000f430: 6461 7465 2873 656c 6629 3a0d 0a20 2020  date(self):..   
-0000f440: 2020 2020 2070 6173 730d 0a0d 0a20 2020       pass....   
-0000f450: 2064 6566 2073 696d 756c 6174 6528 7365   def simulate(se
-0000f460: 6c66 2c20 7072 6f63 6573 735f 6964 3d4e  lf, process_id=N
-0000f470: 6f6e 652c 206d 6174 6c61 625f 656e 6769  one, matlab_engi
-0000f480: 6e65 3d4e 6f6e 6529 3a0d 0a20 2020 2020  ne=None):..     
-0000f490: 2020 2023 2053 7973 7465 6d20 6f66 2031     # System of 1
-0000f4a0: 7374 206f 7264 6572 2044 4551 0d0a 2020  st order DEQ..  
-0000f4b0: 2020 2020 2020 6465 6620 6465 7128 7268        def deq(rh
-0000f4c0: 6f2c 2074 2c20 616c 7068 612c 2062 6574  o, t, alpha, bet
-0000f4d0: 612c 2067 616d 6d61 293a 0d0a 2020 2020  a, gamma):..    
-0000f4e0: 2020 2020 2020 2020 7265 7475 726e 2061          return a
-0000f4f0: 6c70 6861 202a 2028 312e 202d 2072 686f  lpha * (1. - rho
-0000f500: 2920 2d20 6761 6d6d 6120 2a20 7268 6f20  ) - gamma * rho 
-0000f510: 2d20 6265 7461 202a 2028 7268 6f20 2d20  - beta * (rho - 
-0000f520: 3129 202a 2a20 3220 2a20 7268 6f0d 0a0d  1) ** 2 * rho...
-0000f530: 0a20 2020 2020 2020 2023 2043 6f6e 7374  .        # Const
-0000f540: 616e 7473 0d0a 2020 2020 2020 2020 6761  ants..        ga
-0000f550: 6d6d 6120 3d20 302e 3031 0d0a 0d0a 2020  mma = 0.01....  
-0000f560: 2020 2020 2020 2320 5369 6d75 6c61 7469        # Simulati
-0000f570: 6f6e 2070 6172 616d 6574 6572 730d 0a20  on parameters.. 
-0000f580: 2020 2020 2020 2064 7420 3d20 302e 3031         dt = 0.01
-0000f590: 0d0a 2020 2020 2020 2020 745f 656e 6420  ..        t_end 
-0000f5a0: 3d20 312e 0d0a 2020 2020 2020 2020 7420  = 1...        t 
-0000f5b0: 3d20 6e70 2e61 7261 6e67 6528 302c 2074  = np.arange(0, t
-0000f5c0: 5f65 6e64 2c20 6474 290d 0a0d 0a20 2020  _end, dt)....   
-0000f5d0: 2020 2020 2023 2053 6f6c 7665 0d0a 2020       # Solve..  
-0000f5e0: 2020 2020 2020 795f 6f75 7420 3d20 6e70        y_out = np
-0000f5f0: 2e7a 6572 6f73 2828 6c65 6e28 7365 6c66  .zeros((len(self
-0000f600: 2e70 5b22 7268 6f5f 3022 5d29 2c20 3129  .p["rho_0"]), 1)
-0000f610: 290d 0a0d 0a20 2020 2020 2020 2066 6f72  )....        for
-0000f620: 2069 2069 6e20 7261 6e67 6528 6c65 6e28   i in range(len(
-0000f630: 795f 6f75 7429 293a 0d0a 2020 2020 2020  y_out)):..      
-0000f640: 2020 2020 2020 7920 3d20 6f64 6569 6e74        y = odeint
-0000f650: 2864 6571 2c20 7365 6c66 2e70 5b22 7268  (deq, self.p["rh
-0000f660: 6f5f 3022 5d2e 666c 6174 7465 6e28 295b  o_0"].flatten()[
-0000f670: 695d 2c20 742c 0d0a 2020 2020 2020 2020  i], t,..        
-0000f680: 2020 2020 2020 2020 2020 2020 2020 2061                 a
-0000f690: 7267 733d 2873 656c 662e 705b 2261 6c70  rgs=(self.p["alp
-0000f6a0: 6861 225d 2e66 6c61 7474 656e 2829 5b69  ha"].flatten()[i
-0000f6b0: 5d2c 2073 656c 662e 705b 2262 6574 6122  ], self.p["beta"
-0000f6c0: 5d2e 666c 6174 7465 6e28 295b 695d 2c20  ].flatten()[i], 
-0000f6d0: 6761 6d6d 612c 2929 0d0a 2020 2020 2020  gamma,))..      
-0000f6e0: 2020 2020 2020 795f 6f75 745b 692c 2030        y_out[i, 0
-0000f6f0: 5d20 3d20 6e70 2e61 7272 6179 285b 795b  ] = np.array([y[
-0000f700: 2d31 5d5d 290d 0a0d 0a20 2020 2020 2020  -1]])....       
-0000f710: 2023 2079 5f6f 7574 203d 206e 702e 6873   # y_out = np.hs
-0000f720: 7461 636b 2828 795f 6f75 742c 2032 2e2a  tack((y_out, 2.*
-0000f730: 795f 6f75 7429 290d 0a0d 0a20 2020 2020  y_out))....     
-0000f740: 2020 2072 6574 7572 6e20 795f 6f75 740d     return y_out.
-0000f750: 0a0d 0a0d 0a63 6c61 7373 2053 7572 6661  .....class Surfa
-0000f760: 6365 436f 7665 7261 6765 5370 6563 6965  ceCoverageSpecie
-0000f770: 735f 4e61 4e28 4162 7374 7261 6374 4d6f  s_NaN(AbstractMo
-0000f780: 6465 6c29 3a0d 0a20 2020 2022 2222 0d0a  del):..    """..
-0000f790: 2020 2020 4469 6666 6572 656e 7469 616c      Differential
-0000f7a0: 2065 7175 6174 696f 6e20 6465 7363 7269   equation descri
-0000f7b0: 6269 6e67 2074 6865 2074 696d 652d 6576  bing the time-ev
-0000f7c0: 6f6c 7574 696f 6e20 6f66 2074 6865 2073  olution of the s
-0000f7d0: 7572 6661 6365 2063 6f76 6572 6167 6520  urface coverage 
-0000f7e0: 7268 6f20 5b30 2c20 315d 2066 6f72 2061  rho [0, 1] for a
-0000f7f0: 2067 6976 656e 2073 7065 6369 6573 205b   given species [
-0000f800: 315d 2e0d 0a20 2020 2054 6869 7320 7072  1]...    This pr
-0000f810: 6f62 6c65 6d20 6861 7320 6f6e 6520 6f72  oblem has one or
-0000f820: 2074 776f 2066 6978 6564 2070 6f69 6e74   two fixed point
-0000f830: 7320 6163 636f 7264 696e 6720 746f 2074  s according to t
-0000f840: 6865 2076 616c 7565 206f 6620 7468 6520  he value of the 
-0000f850: 7265 636f 6d62 696e 6174 696f 6e20 7261  recombination ra
-0000f860: 7465 2062 6574 6120 616e 6420 6974 2065  te beta and it e
-0000f870: 7868 6962 6974 730d 0a20 2020 2073 6d6f  xhibits..    smo
-0000f880: 6f74 6820 6465 7065 6e64 656e 6365 206f  oth dependence o
-0000f890: 6e20 7468 6520 6f74 6865 7220 7061 7261  n the other para
-0000f8a0: 6d65 7465 7273 2e20 5468 6520 7374 6174  meters. The stat
-0000f8b0: 6973 7469 6373 206f 6620 7468 6520 736f  istics of the so
-0000f8c0: 6c75 7469 6f6e 2061 7420 743d 3120 6172  lution at t=1 ar
-0000f8d0: 6520 696e 7665 7374 6967 6174 6564 2063  e investigated c
-0000f8e0: 6f6e 7369 6465 7269 6e67 0d0a 2020 2020  onsidering..    
-0000f8f0: 756e 6365 7274 6169 6e74 6965 7320 696e  uncertainties in
-0000f900: 2074 6865 2069 6e69 7469 616c 2063 6f76   the initial cov
-0000f910: 6572 6167 6520 7268 6f5f 3020 616e 6420  erage rho_0 and 
-0000f920: 696e 2074 6865 2072 6561 6374 696f 6e20  in the reaction 
-0000f930: 7061 7261 6d65 7465 7220 6265 7461 2e20  parameter beta. 
-0000f940: 4164 6469 7469 6f6e 616c 6c79 2075 6e63  Additionally unc
-0000f950: 6572 7461 696e 7479 0d0a 2020 2020 696e  ertainty..    in
-0000f960: 2074 6865 2073 7572 6661 6365 2061 6273   the surface abs
-0000f970: 6f72 7074 696f 6e20 7261 7465 2061 6c70  orption rate alp
-0000f980: 6861 2063 616e 2062 6520 636f 6e73 6964  ha can be consid
-0000f990: 6572 6564 2074 6f20 6d61 6b65 2074 6865  ered to make the
-0000f9a0: 2070 726f 626c 656d 2033 2d64 696d 656e   problem 3-dimen
-0000f9b0: 7369 6f6e 616c 2e0d 0a20 2020 2047 616d  sional...    Gam
-0000f9c0: 6d61 3d30 2e30 3120 6465 6e6f 7465 7320  ma=0.01 denotes 
-0000f9d0: 7468 6520 6465 736f 7270 7469 6f6e 2072  the desorption r
-0000f9e0: 6174 652e 0d0a 0d0a 2020 2020 2e2e 206d  ate.....    .. m
-0000f9f0: 6174 683a 3a20 5c5c 6672 6163 7b64 5c5c  ath:: \\frac{d\\
-0000fa00: 7268 6f7d 7b64 747d 203d 205c 5c61 6c70  rho}{dt} = \\alp
-0000fa10: 6861 2028 3120 2d20 5c5c 7268 6f29 202d  ha (1 - \\rho) -
-0000fa20: 205c 5c67 616d 6d61 205c 5c72 686f 202d   \\gamma \\rho -
-0000fa30: 205c 5c62 6574 6120 285c 5c72 686f 202d   \\beta (\\rho -
-0000fa40: 2031 295e 3220 5c5c 7268 6f0d 0a0d 0a20   1)^2 \\rho.... 
-0000fa50: 2020 2050 6172 616d 6574 6572 730d 0a20     Parameters.. 
-0000fa60: 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0d 0a20     ----------.. 
-0000fa70: 2020 2070 5b22 7268 6f5f 3022 5d3a 206e     p["rho_0"]: n
-0000fa80: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-0000fa90: 5b31 5d0d 0a20 2020 2020 2020 2049 6e69  [1]..        Ini
-0000faa0: 7469 616c 2076 616c 7565 2072 686f 2874  tial value rho(t
-0000fab0: 3d30 2920 2875 6e69 666f 726d 2064 6973  =0) (uniform dis
-0000fac0: 7472 6962 7574 6564 205b 302c 2031 5d29  tributed [0, 1])
-0000fad0: 0d0a 2020 2020 705b 2262 6574 6122 5d3a  ..    p["beta"]:
-0000fae0: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-0000faf0: 7420 5b31 5d0d 0a20 2020 2020 2020 2052  t [1]..        R
-0000fb00: 6563 6f6d 6269 6e61 7469 6f6e 2072 6174  ecombination rat
-0000fb10: 6520 2875 6e69 666f 726d 2064 6973 7472  e (uniform distr
-0000fb20: 6962 7574 6564 205b 302c 2032 305d 290d  ibuted [0, 20]).
-0000fb30: 0a20 2020 2070 5b22 616c 7068 6122 5d3a  .    p["alpha"]:
-0000fb40: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-0000fb50: 7420 5b31 5d0d 0a20 2020 2020 2020 2053  t [1]..        S
-0000fb60: 7572 6661 6365 2061 6273 6f72 7074 696f  urface absorptio
-0000fb70: 6e20 7261 7465 2028 3120 6f72 2075 6e69  n rate (1 or uni
-0000fb80: 666f 726d 2064 6973 7472 6962 7574 6564  form distributed
-0000fb90: 205b 302e 312c 2032 5d29 0d0a 0d0a 2020   [0.1, 2])....  
-0000fba0: 2020 5265 7475 726e 730d 0a20 2020 202d    Returns..    -
-0000fbb0: 2d2d 2d2d 2d2d 0d0a 2020 2020 793a 206e  ------..    y: n
-0000fbc0: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-0000fbd0: 5b31 2078 2031 5d0d 0a20 2020 2020 2020  [1 x 1]..       
-0000fbe0: 2072 686f 2874 2d3e 3129 0d0a 0d0a 2020   rho(t->1)....  
-0000fbf0: 2020 4e6f 7465 730d 0a20 2020 202d 2d2d    Notes..    ---
-0000fc00: 2d2d 0d0a 2020 2020 2e2e 2070 6c6f 743a  --..    .. plot:
-0000fc10: 3a0d 0a0d 0a20 2020 2020 2020 696d 706f  :....       impo
-0000fc20: 7274 206e 756d 7079 2061 7320 6e70 0d0a  rt numpy as np..
-0000fc30: 2020 2020 2020 2066 726f 6d20 7079 6770         from pygp
-0000fc40: 632e 7465 7374 6675 6e63 7469 6f6e 7320  c.testfunctions 
-0000fc50: 696d 706f 7274 2070 6c6f 745f 7465 7374  import plot_test
-0000fc60: 6675 6e63 7469 6f6e 2061 7320 706c 6f74  function as plot
-0000fc70: 0d0a 2020 2020 2020 2066 726f 6d20 636f  ..       from co
-0000fc80: 6c6c 6563 7469 6f6e 7320 696d 706f 7274  llections import
-0000fc90: 204f 7264 6572 6564 4469 6374 0d0a 0d0a   OrderedDict....
-0000fca0: 2020 2020 2020 2070 6172 616d 6574 6572         parameter
-0000fcb0: 7320 3d20 4f72 6465 7265 6444 6963 7428  s = OrderedDict(
-0000fcc0: 290d 0a20 2020 2020 2020 7061 7261 6d65  )..       parame
-0000fcd0: 7465 7273 5b22 7268 6f5f 3022 5d20 3d20  ters["rho_0"] = 
-0000fce0: 6e70 2e6c 696e 7370 6163 6528 302c 2031  np.linspace(0, 1
-0000fcf0: 2c20 3130 3029 0d0a 2020 2020 2020 2070  , 100)..       p
-0000fd00: 6172 616d 6574 6572 735b 2262 6574 6122  arameters["beta"
-0000fd10: 5d20 3d20 6e70 2e6c 696e 7370 6163 6528  ] = np.linspace(
-0000fd20: 302c 2032 302c 2031 3030 290d 0a0d 0a20  0, 20, 100).... 
-0000fd30: 2020 2020 2020 636f 6e73 7461 6e74 7320        constants 
-0000fd40: 3d20 4f72 6465 7265 6444 6963 7428 290d  = OrderedDict().
-0000fd50: 0a20 2020 2020 2020 636f 6e73 7461 6e74  .       constant
-0000fd60: 735b 2261 6c70 6861 225d 203d 2031 2e0d  s["alpha"] = 1..
-0000fd70: 0a0d 0a20 2020 2020 2020 706c 6f74 2822  ...       plot("
-0000fd80: 5375 7266 6163 6543 6f76 6572 6167 6553  SurfaceCoverageS
-0000fd90: 7065 6369 6573 222c 2070 6172 616d 6574  pecies", paramet
-0000fda0: 6572 732c 2063 6f6e 7374 616e 7473 2c20  ers, constants, 
-0000fdb0: 706c 6f74 5f33 643d 4661 6c73 6529 0d0a  plot_3d=False)..
-0000fdc0: 0d0a 2020 2020 2e2e 205b 315d 204c 6520  ..    .. [1] Le 
-0000fdd0: 4d61 6974 7265 2c20 4f2e 502e 2c20 4e61  Maitre, O.P., Na
-0000fde0: 6a6d 2c20 482e 4e2e 2c20 4768 616e 656d  jm, H.N., Ghanem
-0000fdf0: 2c20 522e 472e 2c20 4b6e 696f 2c20 4f2e  , R.G., Knio, O.
-0000fe00: 4d2e 2c20 2832 3030 3429 2e0d 0a20 2020  M., (2004)...   
-0000fe10: 2020 2020 4d75 6c74 692d 7265 736f 6c75      Multi-resolu
-0000fe20: 7469 6f6e 2061 6e61 6c79 7369 7320 6f66  tion analysis of
-0000fe30: 2057 6965 6e65 722d 7479 7065 2075 6e63   Wiener-type unc
-0000fe40: 6572 7461 696e 7479 2070 726f 7061 6761  ertainty propaga
-0000fe50: 7469 6f6e 2073 6368 656d 6573 2e0d 0a20  tion schemes... 
-0000fe60: 2020 2020 2020 4a6f 7572 6e61 6c20 6f66        Journal of
-0000fe70: 2043 6f6d 7075 7461 7469 6f6e 616c 2050   Computational P
-0000fe80: 6879 7369 6373 2c20 3139 372c 2035 3032  hysics, 197, 502
-0000fe90: 2d35 3331 2e0d 0a20 2020 2022 2222 0d0a  -531...    """..
-0000fea0: 0d0a 2020 2020 6465 6620 5f5f 696e 6974  ..    def __init
-0000feb0: 5f5f 2873 656c 662c 206d 6174 6c61 625f  __(self, matlab_
-0000fec0: 6d6f 6465 6c3d 4661 6c73 6529 3a0d 0a20  model=False):.. 
-0000fed0: 2020 2020 2020 2073 7570 6572 2874 7970         super(typ
-0000fee0: 6528 7365 6c66 292c 2073 656c 6629 2e5f  e(self), self)._
-0000fef0: 5f69 6e69 745f 5f28 6d61 746c 6162 5f6d  _init__(matlab_m
-0000ff00: 6f64 656c 3d6d 6174 6c61 625f 6d6f 6465  odel=matlab_mode
-0000ff10: 6c29 0d0a 2020 2020 2020 2020 7365 6c66  l)..        self
-0000ff20: 2e66 6e61 6d65 203d 2069 6e73 7065 6374  .fname = inspect
-0000ff30: 2e67 6574 6669 6c65 2869 6e73 7065 6374  .getfile(inspect
-0000ff40: 2e63 7572 7265 6e74 6672 616d 6528 2929  .currentframe())
-0000ff50: 0d0a 0d0a 2020 2020 6465 6620 7661 6c69  ....    def vali
-0000ff60: 6461 7465 2873 656c 6629 3a0d 0a20 2020  date(self):..   
-0000ff70: 2020 2020 2070 6173 730d 0a0d 0a20 2020       pass....   
-0000ff80: 2064 6566 2073 696d 756c 6174 6528 7365   def simulate(se
-0000ff90: 6c66 2c20 7072 6f63 6573 735f 6964 3d4e  lf, process_id=N
-0000ffa0: 6f6e 652c 206d 6174 6c61 625f 656e 6769  one, matlab_engi
-0000ffb0: 6e65 3d4e 6f6e 6529 3a0d 0a20 2020 2020  ne=None):..     
-0000ffc0: 2020 2023 2053 7973 7465 6d20 6f66 2031     # System of 1
-0000ffd0: 7374 206f 7264 6572 2044 4551 0d0a 2020  st order DEQ..  
-0000ffe0: 2020 2020 2020 6465 6620 6465 7128 7268        def deq(rh
-0000fff0: 6f2c 2074 2c20 616c 7068 612c 2062 6574  o, t, alpha, bet
-00010000: 612c 2067 616d 6d61 293a 0d0a 2020 2020  a, gamma):..    
-00010010: 2020 2020 2020 2020 7265 7475 726e 2061          return a
-00010020: 6c70 6861 202a 2028 312e 202d 2072 686f  lpha * (1. - rho
-00010030: 2920 2d20 6761 6d6d 6120 2a20 7268 6f20  ) - gamma * rho 
-00010040: 2d20 6265 7461 202a 2028 7268 6f20 2d20  - beta * (rho - 
-00010050: 3129 202a 2a20 3220 2a20 7268 6f0d 0a0d  1) ** 2 * rho...
-00010060: 0a20 2020 2020 2020 2023 2043 6f6e 7374  .        # Const
-00010070: 616e 7473 0d0a 2020 2020 2020 2020 6761  ants..        ga
-00010080: 6d6d 6120 3d20 302e 3031 0d0a 0d0a 2020  mma = 0.01....  
-00010090: 2020 2020 2020 2320 5369 6d75 6c61 7469        # Simulati
-000100a0: 6f6e 2070 6172 616d 6574 6572 730d 0a20  on parameters.. 
-000100b0: 2020 2020 2020 2064 7420 3d20 302e 3031         dt = 0.01
-000100c0: 0d0a 2020 2020 2020 2020 745f 656e 6420  ..        t_end 
-000100d0: 3d20 312e 0d0a 2020 2020 2020 2020 7420  = 1...        t 
-000100e0: 3d20 6e70 2e61 7261 6e67 6528 302c 2074  = np.arange(0, t
-000100f0: 5f65 6e64 2c20 6474 290d 0a0d 0a20 2020  _end, dt)....   
-00010100: 2020 2020 2023 2053 6f6c 7665 0d0a 2020       # Solve..  
-00010110: 2020 2020 2020 795f 6f75 7420 3d20 6e70        y_out = np
-00010120: 2e7a 6572 6f73 2828 6c65 6e28 7365 6c66  .zeros((len(self
-00010130: 2e70 5b22 7268 6f5f 3022 5d29 2c20 3129  .p["rho_0"]), 1)
-00010140: 290d 0a0d 0a20 2020 2020 2020 2066 6f72  )....        for
-00010150: 2069 2069 6e20 7261 6e67 6528 6c65 6e28   i in range(len(
-00010160: 795f 6f75 7429 293a 0d0a 2020 2020 2020  y_out)):..      
-00010170: 2020 2020 2020 7920 3d20 6f64 6569 6e74        y = odeint
-00010180: 2864 6571 2c20 7365 6c66 2e70 5b22 7268  (deq, self.p["rh
-00010190: 6f5f 3022 5d2e 666c 6174 7465 6e28 295b  o_0"].flatten()[
-000101a0: 695d 2c20 742c 0d0a 2020 2020 2020 2020  i], t,..        
-000101b0: 2020 2020 2020 2020 2020 2020 2020 2061                 a
-000101c0: 7267 733d 2873 656c 662e 705b 2261 6c70  rgs=(self.p["alp
-000101d0: 6861 225d 2e66 6c61 7474 656e 2829 5b69  ha"].flatten()[i
-000101e0: 5d2c 2073 656c 662e 705b 2262 6574 6122  ], self.p["beta"
-000101f0: 5d2e 666c 6174 7465 6e28 295b 695d 2c20  ].flatten()[i], 
-00010200: 6761 6d6d 612c 2929 0d0a 2020 2020 2020  gamma,))..      
-00010210: 2020 2020 2020 795f 6f75 745b 692c 2030        y_out[i, 0
-00010220: 5d20 3d20 6e70 2e61 7272 6179 285b 795b  ] = np.array([y[
-00010230: 2d31 5d5d 290d 0a0d 0a20 2020 2020 2020  -1]])....       
-00010240: 2023 2061 6464 2073 6f6d 6520 4e61 4e20   # add some NaN 
-00010250: 7661 6c75 6573 2066 6f72 2074 6573 7469  values for testi
-00010260: 6e67 0d0a 2020 2020 2020 2020 6d61 736b  ng..        mask
-00010270: 5f6e 616e 203d 2073 656c 662e 705b 2262  _nan = self.p["b
-00010280: 6574 6122 5d20 3e20 3138 2e35 0d0a 0d0a  eta"] > 18.5....
-00010290: 2020 2020 2020 2020 795f 6f75 745b 6d61          y_out[ma
-000102a0: 736b 5f6e 616e 2c20 305d 203d 206e 702e  sk_nan, 0] = np.
-000102b0: 4e61 4e0d 0a0d 0a20 2020 2020 2020 2072  NaN....        r
-000102c0: 6574 7572 6e20 795f 6f75 740d 0a0d 0a0d  eturn y_out.....
-000102d0: 0a63 6c61 7373 2046 7261 6e6b 6528 4162  .class Franke(Ab
-000102e0: 7374 7261 6374 4d6f 6465 6c29 3a0d 0a20  stractModel):.. 
-000102f0: 2020 2022 2222 0d0a 2020 2020 4672 616e     """..    Fran
-00010300: 6b65 2066 756e 6374 696f 6e20 5b31 5d20  ke function [1] 
-00010310: 7769 7468 2032 2070 6172 616d 6574 6572  with 2 parameter
-00010320: 732e 2049 7420 6973 206f 6674 656e 2075  s. It is often u
-00010330: 7365 6420 696e 2072 6567 7265 7373 696f  sed in regressio
-00010340: 6e20 6f72 2069 6e74 6572 706f 6c61 7469  n or interpolati
-00010350: 6f6e 2061 6e61 6c79 7369 732e 0d0a 2020  on analysis...  
-00010360: 2020 4974 2069 7320 6465 6669 6e65 6420    It is defined 
-00010370: 696e 2074 6865 2069 6e74 6572 7661 6c20  in the interval 
-00010380: 5b30 2c20 315d 2078 205b 302c 2031 5d2e  [0, 1] x [0, 1].
-00010390: 2048 616d 7074 6f6e 2061 6e64 2044 6f6f   Hampton and Doo
-000103a0: 7374 616e 2075 7365 6420 696e 2074 6865  stan used in the
-000103b0: 2066 7261 6d65 776f 726b 206f 6620 4241   framework of BA
-000103c0: 5345 2d50 4320 5b32 5d2e 0d0a 0d0a 2020  SE-PC [2].....  
-000103d0: 2020 2e2e 206d 6174 683a 3a0d 0a20 2020    .. math::..   
-000103e0: 2020 2020 7920 3d20 5c5c 6672 6163 7b33      y = \\frac{3
-000103f0: 7d7b 347d 205c 6578 707b 5c5c 6c65 6674  }{4} \exp{\\left
-00010400: 282d 5c5c 6672 6163 7b28 3920 785f 3120  (-\\frac{(9 x_1 
-00010410: 2d20 3229 5e32 7d7b 347d 202d 205c 5c66  - 2)^2}{4} - \\f
-00010420: 7261 637b 2839 2078 5f32 202d 2032 295e  rac{(9 x_2 - 2)^
-00010430: 327d 7b34 7d5c 5c72 6967 6874 297d 202b  2}{4}\\right)} +
-00010440: 0d0a 2020 2020 2020 205c 5c66 7261 637b  ..       \\frac{
-00010450: 337d 7b34 7d20 5c65 7870 7b5c 5c6c 6566  3}{4} \exp{\\lef
-00010460: 7428 2d5c 5c66 7261 637b 2839 2078 5f31  t(-\\frac{(9 x_1
-00010470: 202b 2031 295e 327d 7b34 397d 202d 205c   + 1)^2}{49} - \
-00010480: 5c66 7261 637b 2839 2078 5f32 202b 2031  \frac{(9 x_2 + 1
-00010490: 297d 7b31 307d 5c5c 7269 6768 7429 7d20  )}{10}\\right)} 
-000104a0: 2b0d 0a20 2020 2020 2020 5c5c 6672 6163  +..       \\frac
-000104b0: 7b31 7d7b 327d 205c 6578 707b 5c5c 6c65  {1}{2} \exp{\\le
-000104c0: 6674 282d 5c5c 6672 6163 7b28 3920 785f  ft(-\\frac{(9 x_
-000104d0: 3120 2d20 3729 5e32 7d7b 347d 202d 205c  1 - 7)^2}{4} - \
-000104e0: 5c66 7261 637b 2839 2078 5f32 202d 2033  \frac{(9 x_2 - 3
-000104f0: 295e 327d 7b34 7d5c 5c72 6967 6874 297d  )^2}{4}\\right)}
-00010500: 202b 0d0a 2020 2020 2020 205c 5c66 7261   +..       \\fra
-00010510: 637b 317d 7b35 7d20 5c65 7870 7b5c 5c6c  c{1}{5} \exp{\\l
-00010520: 6566 7428 2d5c 5c66 7261 637b 2839 2078  eft(-\\frac{(9 x
-00010530: 5f31 202d 2034 295e 327d 7b34 7d20 2d20  _1 - 4)^2}{4} - 
-00010540: 2839 2078 5f32 202d 2037 295e 325c 5c72  (9 x_2 - 7)^2\\r
-00010550: 6967 6874 297d 0d0a 0d0a 2020 2020 5061  ight)}....    Pa
-00010560: 7261 6d65 7465 7273 0d0a 2020 2020 2d2d  rameters..    --
-00010570: 2d2d 2d2d 2d2d 2d2d 0d0a 2020 2020 705b  --------..    p[
-00010580: 2278 3122 5d3a 2066 6c6f 6174 206f 7220  "x1"]: float or 
-00010590: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-000105a0: 205b 6e5f 6772 6964 5d0d 0a20 2020 2020   [n_grid]..     
-000105b0: 2020 2046 6972 7374 2070 6172 616d 6574     First paramet
-000105c0: 6572 205b 302c 2031 5d0d 0a20 2020 2070  er [0, 1]..    p
-000105d0: 5b22 7832 225d 3a20 666c 6f61 7420 6f72  ["x2"]: float or
-000105e0: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-000105f0: 7420 5b6e 5f67 7269 645d 0d0a 2020 2020  t [n_grid]..    
-00010600: 2020 2020 5365 636f 6e64 2070 6172 616d      Second param
-00010610: 6574 6572 205b 302c 2031 5d0d 0a0d 0a20  eter [0, 1].... 
-00010620: 2020 2052 6574 7572 6e73 0d0a 2020 2020     Returns..    
-00010630: 2d2d 2d2d 2d2d 2d0d 0a20 2020 2079 3a20  -------..    y: 
-00010640: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-00010650: 205b 6e5f 6772 6964 2078 2031 5d0d 0a20   [n_grid x 1].. 
-00010660: 2020 2020 2020 204f 7574 7075 740d 0a0d         Output...
-00010670: 0a20 2020 204e 6f74 6573 0d0a 2020 2020  .    Notes..    
-00010680: 2d2d 2d2d 2d0d 0a20 2020 202e 2e20 706c  -----..    .. pl
-00010690: 6f74 3a3a 0d0a 0d0a 2020 2020 2020 2069  ot::....       i
+00000c80: 2020 6f72 6465 723d 2763 2729 2c0a 2020    order='c'),.  
+00000c90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000ca0: 2020 2020 2020 2020 2020 2020 2063 6d61               cma
+00000cb0: 703d 226a 6574 2229 0a0a 2020 2020 2020  p="jet")..      
+00000cc0: 2020 2020 2020 6178 2e73 6574 5f79 6c61        ax.set_yla
+00000cd0: 6265 6c28 7222 247b 7d24 222e 666f 726d  bel(r"${}$".form
+00000ce0: 6174 2870 5f6e 616d 6573 5b31 5d29 2c20  at(p_names[1]), 
+00000cf0: 666f 6e74 7369 7a65 3d31 3329 0a20 2020  fontsize=13).   
+00000d00: 2020 2020 2020 2020 2066 6967 2e63 6f6c           fig.col
+00000d10: 6f72 6261 7228 696d 2c20 6178 3d61 782c  orbar(im, ax=ax,
+00000d20: 206f 7269 656e 7461 7469 6f6e 3d27 7665   orientation='ve
+00000d30: 7274 6963 616c 2729 0a0a 2020 2020 2020  rtical')..      
+00000d40: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00000d50: 2020 2020 6178 2e70 6c6f 7428 7061 7261      ax.plot(para
+00000d60: 6d65 7465 7273 5b70 5f6e 616d 6573 5b30  meters[p_names[0
+00000d70: 5d5d 2c20 7929 0a20 2020 2020 2020 2020  ]], y).         
+00000d80: 2020 2061 782e 7365 745f 796c 6162 656c     ax.set_ylabel
+00000d90: 2872 2224 7928 7b7d 2924 222e 666f 726d  (r"$y({})$".form
+00000da0: 6174 2870 5f6e 616d 6573 5b30 5d29 2c20  at(p_names[0]), 
+00000db0: 666f 6e74 7369 7a65 3d31 3329 0a0a 2020  fontsize=13)..  
+00000dc0: 2020 2020 2020 6178 2e73 6574 5f78 6c61        ax.set_xla
+00000dd0: 6265 6c28 7222 247b 7d24 222e 666f 726d  bel(r"${}$".form
+00000de0: 6174 2870 5f6e 616d 6573 5b30 5d29 2c20  at(p_names[0]), 
+00000df0: 666f 6e74 7369 7a65 3d31 3329 0a0a 2020  fontsize=13)..  
+00000e00: 2020 6178 2e73 6574 5f74 6974 6c65 2822    ax.set_title("
+00000e10: 7b7d 2066 756e 6374 696f 6e22 2e66 6f72  {} function".for
+00000e20: 6d61 7428 6d6f 6465 6c2e 5f5f 636c 6173  mat(model.__clas
+00000e30: 735f 5f2e 5f5f 6e61 6d65 5f5f 2929 0a20  s__.__name__)). 
+00000e40: 2020 2070 6c74 2e74 6967 6874 5f6c 6179     plt.tight_lay
+00000e50: 6f75 7428 290a 2020 2020 706c 742e 7368  out().    plt.sh
+00000e60: 6f77 2829 0a0a 0a63 6c61 7373 2044 756d  ow()...class Dum
+00000e70: 6d79 2841 6273 7472 6163 744d 6f64 656c  my(AbstractModel
+00000e80: 293a 0a20 2020 2022 2222 0a20 2020 2044  ):.    """.    D
+00000e90: 756d 6d79 206d 6f64 656c 0a0a 2020 2020  ummy model..    
+00000ea0: 5061 7261 6d65 7465 7273 0a20 2020 202d  Parameters.    -
+00000eb0: 2d2d 2d2d 2d2d 2d2d 2d0a 2020 2020 705b  ---------.    p[
+00000ec0: 222e 2e2e 225d 3a20 666c 6f61 7420 6f72  "..."]: float or
+00000ed0: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
+00000ee0: 7420 5b6e 5f67 7269 645d 0a20 2020 2020  t [n_grid].     
+00000ef0: 2020 2041 6e79 2066 6972 7374 2070 6172     Any first par
+00000f00: 616d 6574 6572 0a20 2020 2070 5b22 2e2e  ameter.    p["..
+00000f10: 2e22 5d3a 2066 6c6f 6174 206f 7220 6e64  ."]: float or nd
+00000f20: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
+00000f30: 6e5f 6772 6964 5d0a 2020 2020 2020 2020  n_grid].        
+00000f40: 416e 7920 7365 636f 6e64 2070 6172 616d  Any second param
+00000f50: 6574 6572 0a0a 2020 2020 5265 7475 726e  eter..    Return
+00000f60: 730a 2020 2020 2d2d 2d2d 2d2d 2d0a 2020  s.    -------.  
+00000f70: 2020 793a 206e 6461 7272 6179 206f 6620    y: ndarray of 
+00000f80: 666c 6f61 7420 5b6e 5f67 7269 6420 7820  float [n_grid x 
+00000f90: 315d 0a20 2020 2020 2020 2041 6e79 206f  1].        Any o
+00000fa0: 7574 7075 740a 2020 2020 2222 220a 0a20  utput.    """.. 
+00000fb0: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
+00000fc0: 7365 6c66 2c20 6d61 746c 6162 5f6d 6f64  self, matlab_mod
+00000fd0: 656c 3d46 616c 7365 293a 0a20 2020 2020  el=False):.     
+00000fe0: 2020 2073 7570 6572 2874 7970 6528 7365     super(type(se
+00000ff0: 6c66 292c 2073 656c 6629 2e5f 5f69 6e69  lf), self).__ini
+00001000: 745f 5f28 6d61 746c 6162 5f6d 6f64 656c  t__(matlab_model
+00001010: 3d6d 6174 6c61 625f 6d6f 6465 6c29 0a20  =matlab_model). 
+00001020: 2020 2020 2020 2073 656c 662e 666e 616d         self.fnam
+00001030: 6520 3d20 696e 7370 6563 742e 6765 7466  e = inspect.getf
+00001040: 696c 6528 696e 7370 6563 742e 6375 7272  ile(inspect.curr
+00001050: 656e 7466 7261 6d65 2829 290a 0a20 2020  entframe())..   
+00001060: 2064 6566 2076 616c 6964 6174 6528 7365   def validate(se
+00001070: 6c66 293a 0a20 2020 2020 2020 2070 6173  lf):.        pas
+00001080: 730a 0a20 2020 2064 6566 2073 696d 756c  s..    def simul
+00001090: 6174 6528 7365 6c66 2c20 7072 6f63 6573  ate(self, proces
+000010a0: 735f 6964 3d4e 6f6e 652c 206d 6174 6c61  s_id=None, matla
+000010b0: 625f 656e 6769 6e65 3d4e 6f6e 6529 3a0a  b_engine=None):.
+000010c0: 2020 2020 2020 2020 7061 7373 0a0a 0a63          pass...c
+000010d0: 6c61 7373 2041 636b 6c65 7928 4162 7374  lass Ackley(Abst
+000010e0: 7261 6374 4d6f 6465 6c29 3a0a 2020 2020  ractModel):.    
+000010f0: 2222 220a 2020 2020 4e2d 6469 6d65 6e73  """.    N-dimens
+00001100: 696f 6e61 6c20 4163 6b6c 6579 2066 756e  ional Ackley fun
+00001110: 6374 696f 6e20 5b31 5d5b 325d 5b33 5d5b  ction [1][2][3][
+00001120: 345d 2e0a 2020 2020 5468 6520 4163 6b6c  4]..    The Ackl
+00001130: 6579 2066 756e 6374 696f 6e20 6973 2077  ey function is w
+00001140: 6964 656c 7920 7573 6564 2066 6f72 2074  idely used for t
+00001150: 6573 7469 6e67 206f 7074 696d 697a 6174  esting optimizat
+00001160: 696f 6e20 616c 676f 7269 7468 6d73 2e0a  ion algorithms..
+00001170: 2020 2020 496e 2069 7473 2074 776f 2d64      In its two-d
+00001180: 696d 656e 7369 6f6e 616c 2066 6f72 6d2c  imensional form,
+00001190: 2061 7320 7368 6f77 6e20 696e 2074 6865   as shown in the
+000011a0: 2070 6c6f 7420 6162 6f76 652c 2069 7420   plot above, it 
+000011b0: 6973 2063 6861 7261 6374 6572 697a 6564  is characterized
+000011c0: 0a20 2020 2062 7920 6120 6e65 6172 6c79  .    by a nearly
+000011d0: 2066 6c61 7420 6f75 7465 7220 7265 6769   flat outer regi
+000011e0: 6f6e 2c20 616e 6420 6120 6c61 7267 6520  on, and a large 
+000011f0: 686f 6c65 2061 7420 7468 6520 6365 6e74  hole at the cent
+00001200: 7265 2e0a 2020 2020 5468 6520 6675 6e63  re..    The func
+00001210: 7469 6f6e 2070 6f73 6573 2061 2072 6973  tion poses a ris
+00001220: 6b20 666f 7220 6f70 7469 6d69 7a61 7469  k for optimizati
+00001230: 6f6e 2061 6c67 6f72 6974 686d 732c 2070  on algorithms, p
+00001240: 6172 7469 6375 6c61 726c 790a 2020 2020  articularly.    
+00001250: 6869 6c6c 636c 696d 6269 6e67 2061 6c67  hillclimbing alg
+00001260: 6f72 6974 686d 732c 2074 6f20 6265 2074  orithms, to be t
+00001270: 7261 7070 6564 2069 6e20 6f6e 6520 6f66  rapped in one of
+00001280: 2069 7473 206d 616e 7920 6c6f 6361 6c20   its many local 
+00001290: 6d69 6e69 6d61 2e0a 0a20 2020 2052 6563  minima...    Rec
+000012a0: 6f6d 6d65 6e64 6564 2076 6172 6961 626c  ommended variabl
+000012b0: 6520 7661 6c75 6573 2061 7265 3a20 6120  e values are: a 
+000012c0: 3d20 3230 2c20 6220 3d20 302e 3220 616e  = 20, b = 0.2 an
+000012d0: 6420 6320 3d20 302e 352a 7069 2e0a 0a20  d c = 0.5*pi... 
+000012e0: 2020 202e 2e20 6d61 7468 3a3a 0a20 2020     .. math::.   
+000012f0: 2020 2020 7920 3d20 2d61 5c5c 6578 707b      y = -a\\exp{
+00001300: 5c5c 6c65 6674 282d 625c 5c73 7172 747b  \\left(-b\\sqrt{
+00001310: 5c5c 6672 6163 7b31 7d7b 647d 5c5c 7375  \\frac{1}{d}\\su
+00001320: 6d5f 7b69 3d31 7d5e 7b4e 7d20 785f 695e  m_{i=1}^{N} x_i^
+00001330: 327d 5c5c 7269 6768 7429 7d20 2d0a 2020  2}\\right)} -.  
+00001340: 2020 2020 205c 5c65 7870 7b5c 5c6c 6566       \\exp{\\lef
+00001350: 7428 5c5c 6672 6163 7b31 7d7b 647d 5c5c  t(\\frac{1}{d}\\
+00001360: 7375 6d5f 7b69 3d31 7d5e 7b4e 7d20 5c5c  sum_{i=1}^{N} \\
+00001370: 636f 737b 2863 785f 6929 7d5c 5c72 6967  cos{(cx_i)}\\rig
+00001380: 6874 297d 202b 2061 202b 205c 5c65 7870  ht)} + a + \\exp
+00001390: 7b28 3129 7d0a 0a20 2020 2050 6172 616d  {(1)}..    Param
+000013a0: 6574 6572 730a 2020 2020 2d2d 2d2d 2d2d  eters.    ------
+000013b0: 2d2d 2d2d 0a20 2020 2070 5b22 7831 225d  ----.    p["x1"]
+000013c0: 3a20 666c 6f61 7420 6f72 206e 6461 7272  : float or ndarr
+000013d0: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
+000013e0: 7269 645d 0a20 2020 2020 2020 2046 6972  rid].        Fir
+000013f0: 7374 2070 6172 616d 6574 6572 2064 6566  st parameter def
+00001400: 696e 6564 2069 6e20 5b2d 3332 2e37 3638  ined in [-32.768
+00001410: 2c20 3332 2e37 3638 5d0a 2020 2020 705b  , 32.768].    p[
+00001420: 2278 6922 5d3a 2066 6c6f 6174 206f 7220  "xi"]: float or 
+00001430: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
+00001440: 205b 6e5f 6772 6964 5d0a 2020 2020 2020   [n_grid].      
+00001450: 2020 692d 7468 2070 6172 616d 6574 6572    i-th parameter
+00001460: 2064 6566 696e 6564 2069 6e20 5b2d 3332   defined in [-32
+00001470: 2e37 3638 2c20 3332 2e37 3638 5d0a 2020  .768, 32.768].  
+00001480: 2020 705b 2278 4e22 5d3a 2066 6c6f 6174    p["xN"]: float
+00001490: 206f 7220 6e64 6172 7261 7920 6f66 2066   or ndarray of f
+000014a0: 6c6f 6174 205b 6e5f 6772 6964 5d0a 2020  loat [n_grid].  
+000014b0: 2020 2020 2020 4e74 6820 7061 7261 6d65        Nth parame
+000014c0: 7465 7220 6465 6669 6e65 6420 696e 205b  ter defined in [
+000014d0: 2d33 322e 3736 382c 2033 322e 3736 385d  -32.768, 32.768]
+000014e0: 0a0a 2020 2020 5265 7475 726e 730a 2020  ..    Returns.  
+000014f0: 2020 2d2d 2d2d 2d2d 2d0a 2020 2020 793a    -------.    y:
+00001500: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
+00001510: 7420 5b6e 5f67 7269 6420 7820 315d 0a20  t [n_grid x 1]. 
+00001520: 2020 2020 2020 204f 7574 7075 740a 0a20         Output.. 
+00001530: 2020 204e 6f74 6573 0a20 2020 202d 2d2d     Notes.    ---
+00001540: 2d2d 0a20 2020 202e 2e20 706c 6f74 3a3a  --.    .. plot::
+00001550: 0a0a 2020 2020 2020 2069 6d70 6f72 7420  ..       import 
+00001560: 6e75 6d70 7920 6173 206e 700a 2020 2020  numpy as np.    
+00001570: 2020 2066 726f 6d20 7079 6770 632e 7465     from pygpc.te
+00001580: 7374 6675 6e63 7469 6f6e 7320 696d 706f  stfunctions impo
+00001590: 7274 2070 6c6f 745f 7465 7374 6675 6e63  rt plot_testfunc
+000015a0: 7469 6f6e 2061 7320 706c 6f74 0a20 2020  tion as plot.   
+000015b0: 2020 2020 6672 6f6d 2063 6f6c 6c65 6374      from collect
+000015c0: 696f 6e73 2069 6d70 6f72 7420 4f72 6465  ions import Orde
+000015d0: 7265 6444 6963 740a 0a20 2020 2020 2020  redDict..       
+000015e0: 7061 7261 6d65 7465 7273 203d 204f 7264  parameters = Ord
+000015f0: 6572 6564 4469 6374 2829 0a20 2020 2020  eredDict().     
+00001600: 2020 7061 7261 6d65 7465 7273 5b22 7831    parameters["x1
+00001610: 225d 203d 206e 702e 6c69 6e73 7061 6365  "] = np.linspace
+00001620: 282d 3332 2e37 3638 2c20 3332 2e37 3638  (-32.768, 32.768
+00001630: 2c20 3130 3029 0a20 2020 2020 2020 7061  , 100).       pa
+00001640: 7261 6d65 7465 7273 5b22 7832 225d 203d  rameters["x2"] =
+00001650: 206e 702e 6c69 6e73 7061 6365 282d 3332   np.linspace(-32
+00001660: 2e37 3638 2c20 3332 2e37 3638 2c20 3130  .768, 32.768, 10
+00001670: 3029 0a0a 2020 2020 2020 2063 6f6e 7374  0)..       const
+00001680: 616e 7473 203d 204f 7264 6572 6564 4469  ants = OrderedDi
+00001690: 6374 2829 0a20 2020 2020 2020 636f 6e73  ct().       cons
+000016a0: 7461 6e74 735b 2261 225d 203d 2032 302e  tants["a"] = 20.
+000016b0: 0a20 2020 2020 2020 636f 6e73 7461 6e74  .       constant
+000016c0: 735b 2262 225d 203d 2030 2e32 0a20 2020  s["b"] = 0.2.   
+000016d0: 2020 2020 636f 6e73 7461 6e74 735b 2263      constants["c
+000016e0: 225d 203d 2030 2e35 2a6e 702e 7069 0a0a  "] = 0.5*np.pi..
+000016f0: 2020 2020 2020 2070 6c6f 7428 2241 636b         plot("Ack
+00001700: 6c65 7922 2c20 7061 7261 6d65 7465 7273  ley", parameters
+00001710: 2c20 636f 6e73 7461 6e74 732c 2070 6c6f  , constants, plo
+00001720: 745f 3364 3d46 616c 7365 290a 0a20 2020  t_3d=False)..   
+00001730: 202e 2e20 5b31 5d20 4164 6f72 696f 2c20   .. [1] Adorio, 
+00001740: 452e 2050 2e2c 2026 2044 696c 696d 616e  E. P., & Diliman
+00001750: 2c20 552e 2050 2e20 4d56 4620 2d20 4d75  , U. P. MVF - Mu
+00001760: 6c74 6976 6172 6961 7465 2054 6573 7420  ltivariate Test 
+00001770: 4675 6e63 7469 6f6e 7320 4c69 6272 6172  Functions Librar
+00001780: 7920 696e 2043 0a20 2020 2020 2020 666f  y in C.       fo
+00001790: 7220 556e 636f 6e73 7472 6169 6e65 6420  r Unconstrained 
+000017a0: 476c 6f62 616c 204f 7074 696d 697a 6174  Global Optimizat
+000017b0: 696f 6e20 2832 3030 3529 2e20 5265 7472  ion (2005). Retr
+000017c0: 6965 7665 6420 4a75 6e65 2032 3031 332c  ieved June 2013,
+000017d0: 0a20 2020 2020 2020 6672 6f6d 2068 7474  .       from htt
+000017e0: 703a 2f2f 6874 7470 3a2f 2f77 7777 2e67  p://http://www.g
+000017f0: 656f 6369 7469 6573 2e77 732f 6561 646f  eocities.ws/eado
+00001800: 7269 6f2f 6d76 662e 7064 660a 0a20 2020  rio/mvf.pdf..   
+00001810: 202e 2e20 5b32 5d20 4d6f 6c67 612c 204d   .. [2] Molga, M
+00001820: 2e2c 2026 2053 6d75 746e 6963 6b69 2c20  ., & Smutnicki, 
+00001830: 432e 2054 6573 7420 6675 6e63 7469 6f6e  C. Test function
+00001840: 7320 666f 7220 6f70 7469 6d69 7a61 7469  s for optimizati
+00001850: 6f6e 206e 6565 6473 2028 3230 3035 292e  on needs (2005).
+00001860: 0a20 2020 2020 2020 5265 7472 6965 7665  .       Retrieve
+00001870: 6420 4a75 6e65 2032 3031 332c 2066 726f  d June 2013, fro
+00001880: 6d20 6874 7470 3a2f 2f77 7777 2e7a 7364  m http://www.zsd
+00001890: 2e69 6374 2e70 7772 2e77 726f 632e 706c  .ict.pwr.wroc.pl
+000018a0: 2f66 696c 6573 2f64 6f63 732f 6675 6e63  /files/docs/func
+000018b0: 7469 6f6e 732e 7064 660a 0a20 2020 202e  tions.pdf..    .
+000018c0: 2e20 5b33 5d20 4261 636b 2c20 542e 2028  . [3] Back, T. (
+000018d0: 3139 3936 292e 2045 766f 6c75 7469 6f6e  1996). Evolution
+000018e0: 6172 7920 616c 676f 7269 7468 6d73 2069  ary algorithms i
+000018f0: 6e20 7468 656f 7279 2061 6e64 2070 7261  n theory and pra
+00001900: 6374 6963 653a 2065 766f 6c75 7469 6f6e  ctice: evolution
+00001910: 2073 7472 6174 6567 6965 732c 0a20 2020   strategies,.   
+00001920: 2020 2020 6576 6f6c 7574 696f 6e61 7279      evolutionary
+00001930: 2070 726f 6772 616d 6d69 6e67 2c20 6765   programming, ge
+00001940: 6e65 7469 6320 616c 676f 7269 7468 6d73  netic algorithms
+00001950: 2e20 4f78 666f 7264 2055 6e69 7665 7273  . Oxford Univers
+00001960: 6974 7920 5072 6573 7320 6f6e 2044 656d  ity Press on Dem
+00001970: 616e 640a 0a20 2020 202e 2e20 5b34 5d20  and..    .. [4] 
+00001980: 6874 7470 733a 2f2f 7777 772e 7366 752e  https://www.sfu.
+00001990: 6361 2f7e 7373 7572 6a61 6e6f 2f61 636b  ca/~ssurjano/ack
+000019a0: 6c65 792e 6874 6d6c 0a20 2020 2022 2222  ley.html.    """
+000019b0: 0a0a 2020 2020 6465 6620 5f5f 696e 6974  ..    def __init
+000019c0: 5f5f 2873 656c 662c 206d 6174 6c61 625f  __(self, matlab_
+000019d0: 6d6f 6465 6c3d 4661 6c73 6529 3a0a 2020  model=False):.  
+000019e0: 2020 2020 2020 7375 7065 7228 7479 7065        super(type
+000019f0: 2873 656c 6629 2c20 7365 6c66 292e 5f5f  (self), self).__
+00001a00: 696e 6974 5f5f 286d 6174 6c61 625f 6d6f  init__(matlab_mo
+00001a10: 6465 6c3d 6d61 746c 6162 5f6d 6f64 656c  del=matlab_model
+00001a20: 290a 2020 2020 2020 2020 7365 6c66 2e66  ).        self.f
+00001a30: 6e61 6d65 203d 2069 6e73 7065 6374 2e67  name = inspect.g
+00001a40: 6574 6669 6c65 2869 6e73 7065 6374 2e63  etfile(inspect.c
+00001a50: 7572 7265 6e74 6672 616d 6528 2929 0a0a  urrentframe())..
+00001a60: 2020 2020 6465 6620 7661 6c69 6461 7465      def validate
+00001a70: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+00001a80: 7061 7373 0a0a 2020 2020 6465 6620 7369  pass..    def si
+00001a90: 6d75 6c61 7465 2873 656c 662c 2070 726f  mulate(self, pro
+00001aa0: 6365 7373 5f69 643d 4e6f 6e65 2c20 6d61  cess_id=None, ma
+00001ab0: 746c 6162 5f65 6e67 696e 653d 4e6f 6e65  tlab_engine=None
+00001ac0: 293a 0a0a 2020 2020 2020 2020 666f 7220  ):..        for 
+00001ad0: 692c 206b 6579 2069 6e20 656e 756d 6572  i, key in enumer
+00001ae0: 6174 6528 7365 6c66 2e70 2e6b 6579 7328  ate(self.p.keys(
+00001af0: 2929 3a0a 2020 2020 2020 2020 2020 2020  )):.            
+00001b00: 6966 2074 7970 6528 7365 6c66 2e70 5b6b  if type(self.p[k
+00001b10: 6579 5d29 2069 7320 6e70 2e6e 6461 7272  ey]) is np.ndarr
+00001b20: 6179 3a0a 2020 2020 2020 2020 2020 2020  ay:.            
+00001b30: 2020 2020 7365 6c66 2e70 5b6b 6579 5d20      self.p[key] 
+00001b40: 3d20 7365 6c66 2e70 5b6b 6579 5d2e 666c  = self.p[key].fl
+00001b50: 6174 7465 6e28 290a 0a20 2020 2020 2020  atten()..       
+00001b60: 2023 2073 6574 2063 6f6e 7374 616e 7473   # set constants
+00001b70: 0a20 2020 2020 2020 2070 203d 2063 6f70  .        p = cop
+00001b80: 792e 6465 6570 636f 7079 2873 656c 662e  y.deepcopy(self.
+00001b90: 7029 0a20 2020 2020 2020 2061 203d 2073  p).        a = s
+00001ba0: 656c 662e 705b 2261 225d 0a20 2020 2020  elf.p["a"].     
+00001bb0: 2020 2062 203d 2073 656c 662e 705b 2262     b = self.p["b
+00001bc0: 225d 0a20 2020 2020 2020 2063 203d 2073  "].        c = s
+00001bd0: 656c 662e 705b 2263 225d 0a20 2020 2020  elf.p["c"].     
+00001be0: 2020 2064 656c 2070 5b22 6122 5d2c 2070     del p["a"], p
+00001bf0: 5b22 6222 5d2c 2070 5b22 6322 5d0a 0a20  ["b"], p["c"].. 
+00001c00: 2020 2020 2020 206e 203d 206c 656e 2870         n = len(p
+00001c10: 2e6b 6579 7328 2929 0a0a 2020 2020 2020  .keys())..      
+00001c20: 2020 2320 6465 7465 726d 696e 6520 7375    # determine su
+00001c30: 6d20 696e 2065 7870 6f6e 656e 740a 2020  m in exponent.  
+00001c40: 2020 2020 2020 7331 203d 206e 702e 7a65        s1 = np.ze
+00001c50: 726f 7328 6e70 2e61 7272 6179 2870 5b6c  ros(np.array(p[l
+00001c60: 6973 7428 702e 6b65 7973 2829 295b 305d  ist(p.keys())[0]
+00001c70: 5d29 2e73 697a 6529 0a20 2020 2020 2020  ]).size).       
+00001c80: 2073 3220 3d20 6e70 2e7a 6572 6f73 286e   s2 = np.zeros(n
+00001c90: 702e 6172 7261 7928 705b 6c69 7374 2870  p.array(p[list(p
+00001ca0: 2e6b 6579 7328 2929 5b30 5d5d 292e 7369  .keys())[0]]).si
+00001cb0: 7a65 290a 0a20 2020 2020 2020 2066 6f72  ze)..        for
+00001cc0: 2069 2c20 6b65 7920 696e 2065 6e75 6d65   i, key in enume
+00001cd0: 7261 7465 2870 2e6b 6579 7328 2929 3a0a  rate(p.keys()):.
+00001ce0: 2020 2020 2020 2020 2020 2020 7331 202b              s1 +
+00001cf0: 3d20 705b 6b65 795d 2a2a 320a 2020 2020  = p[key]**2.    
+00001d00: 2020 2020 2020 2020 7332 202b 3d20 6e70          s2 += np
+00001d10: 2e63 6f73 2863 2a70 5b6b 6579 5d29 0a0a  .cos(c*p[key])..
+00001d20: 2020 2020 2020 2020 7331 203d 202d 6120          s1 = -a 
+00001d30: 2a20 6e70 2e65 7870 282d 6220 2a20 6e70  * np.exp(-b * np
+00001d40: 2e73 7172 7428 312f 6e20 2a20 7331 2929  .sqrt(1/n * s1))
+00001d50: 0a20 2020 2020 2020 2073 3220 3d20 6e70  .        s2 = np
+00001d60: 2e65 7870 2831 2f6e 202a 2073 3229 0a0a  .exp(1/n * s2)..
+00001d70: 2020 2020 2020 2020 2320 6465 7465 726d          # determ
+00001d80: 696e 6520 6f75 7470 7574 0a20 2020 2020  ine output.     
+00001d90: 2020 2079 203d 2073 3120 2d20 7332 202b     y = s1 - s2 +
+00001da0: 2061 202b 206e 702e 6578 7028 3129 0a0a   a + np.exp(1)..
+00001db0: 2020 2020 2020 2020 795f 6f75 7420 3d20          y_out = 
+00001dc0: 795b 3a2c 206e 702e 6e65 7761 7869 735d  y[:, np.newaxis]
+00001dd0: 0a0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+00001de0: 2079 5f6f 7574 0a0a 0a63 6c61 7373 2042   y_out...class B
+00001df0: 756b 696e 4675 6e63 7469 6f6e 4e75 6d62  ukinFunctionNumb
+00001e00: 6572 3628 4162 7374 7261 6374 4d6f 6465  er6(AbstractMode
+00001e10: 6c29 3a0a 2020 2020 2222 220a 2020 2020  l):.    """.    
+00001e20: 322d 6469 6d65 6e73 696f 6e61 6c20 4275  2-dimensional Bu
+00001e30: 6b69 6e20 4675 6e63 7469 6f6e 204e 2e20  kin Function N. 
+00001e40: 3620 5b31 5d5b 325d 2e0a 2020 2020 5468  6 [1][2]..    Th
+00001e50: 6520 7369 7874 6820 4275 6b69 6e20 4675  e sixth Bukin Fu
+00001e60: 6e63 7469 6f6e 2068 6173 206d 616e 7920  nction has many 
+00001e70: 6c6f 6361 6c20 6d69 6e69 6d61 2c20 616c  local minima, al
+00001e80: 6c20 6f66 2077 6869 6368 206c 6965 2069  l of which lie i
+00001e90: 6e20 6120 7269 6467 652e 0a0a 2020 2020  n a ridge...    
+00001ea0: 2e2e 206d 6174 683a 3a0a 2020 2020 2020  .. math::.      
+00001eb0: 2079 203d 2031 3030 5c5c 7371 7274 7b5c   y = 100\\sqrt{\
+00001ec0: 5c6d 6964 2078 5f32 202d 2030 2e30 3120  \mid x_2 - 0.01 
+00001ed0: 785f 315e 3220 5c5c 6d69 647d 202b 2030  x_1^2 \\mid} + 0
+00001ee0: 2e30 315c 5c6d 6964 2078 5f31 202b 2031  .01\\mid x_1 + 1
+00001ef0: 3020 5c5c 6d69 640a 0a20 2020 2050 6172  0 \\mid..    Par
+00001f00: 616d 6574 6572 730a 2020 2020 2d2d 2d2d  ameters.    ----
+00001f10: 2d2d 2d2d 2d2d 0a20 2020 2070 5b22 7831  ------.    p["x1
+00001f20: 225d 3a20 666c 6f61 7420 6f72 206e 6461  "]: float or nda
+00001f30: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
+00001f40: 5f67 7269 645d 0a20 2020 2020 2020 2046  _grid].        F
+00001f50: 6972 7374 2070 6172 616d 6574 6572 2064  irst parameter d
+00001f60: 6566 696e 6564 2069 6e20 5b2d 3135 2c20  efined in [-15, 
+00001f70: 2d35 5d0a 2020 2020 705b 2278 3222 5d3a  -5].    p["x2"]:
+00001f80: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
+00001f90: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
+00001fa0: 6964 5d0a 2020 2020 2020 2020 7365 636f  id].        seco
+00001fb0: 6e64 2070 6172 616d 6574 6572 2064 6566  nd parameter def
+00001fc0: 696e 6564 2069 6e20 5b2d 332c 2033 5d0a  ined in [-3, 3].
+00001fd0: 0a20 2020 2052 6574 7572 6e73 0a20 2020  .    Returns.   
+00001fe0: 202d 2d2d 2d2d 2d2d 0a20 2020 2079 3a20   -------.    y: 
+00001ff0: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
+00002000: 205b 6e5f 6772 6964 2078 2031 5d0a 2020   [n_grid x 1].  
+00002010: 2020 2020 2020 4f75 7470 7574 0a0a 2020        Output..  
+00002020: 2020 4e6f 7465 730a 2020 2020 2d2d 2d2d    Notes.    ----
+00002030: 2d0a 2020 2020 2e2e 2070 6c6f 743a 3a0a  -.    .. plot::.
+00002040: 0a20 2020 2020 2020 696d 706f 7274 206e  .       import n
+00002050: 756d 7079 2061 7320 6e70 0a20 2020 2020  umpy as np.     
+00002060: 2020 6672 6f6d 2070 7967 7063 2e74 6573    from pygpc.tes
+00002070: 7466 756e 6374 696f 6e73 2069 6d70 6f72  tfunctions impor
+00002080: 7420 706c 6f74 5f74 6573 7466 756e 6374  t plot_testfunct
+00002090: 696f 6e20 6173 2070 6c6f 740a 2020 2020  ion as plot.    
+000020a0: 2020 2066 726f 6d20 636f 6c6c 6563 7469     from collecti
+000020b0: 6f6e 7320 696d 706f 7274 204f 7264 6572  ons import Order
+000020c0: 6564 4469 6374 0a0a 2020 2020 2020 2070  edDict..       p
+000020d0: 6172 616d 6574 6572 7320 3d20 4f72 6465  arameters = Orde
+000020e0: 7265 6444 6963 7428 290a 2020 2020 2020  redDict().      
+000020f0: 2070 6172 616d 6574 6572 735b 2278 3122   parameters["x1"
+00002100: 5d20 3d20 6e70 2e6c 696e 7370 6163 6528  ] = np.linspace(
+00002110: 2d31 352c 202d 352c 2031 3030 290a 2020  -15, -5, 100).  
+00002120: 2020 2020 2070 6172 616d 6574 6572 735b       parameters[
+00002130: 2278 3222 5d20 3d20 6e70 2e6c 696e 7370  "x2"] = np.linsp
+00002140: 6163 6528 2d33 2c20 332c 2031 3030 290a  ace(-3, 3, 100).
+00002150: 0a20 2020 2020 2020 636f 6e73 7461 6e74  .       constant
+00002160: 7320 3d20 4e6f 6e65 0a0a 2020 2020 2020  s = None..      
+00002170: 2070 6c6f 7428 2242 756b 696e 4675 6e63   plot("BukinFunc
+00002180: 7469 6f6e 4e75 6d62 6572 3622 2c20 7061  tionNumber6", pa
+00002190: 7261 6d65 7465 7273 2c20 636f 6e73 7461  rameters, consta
+000021a0: 6e74 732c 2070 6c6f 745f 3364 3d46 616c  nts, plot_3d=Fal
+000021b0: 7365 290a 0a20 2020 202e 2e20 5b31 5d20  se)..    .. [1] 
+000021c0: 476c 6f62 616c 204f 7074 696d 697a 6174  Global Optimizat
+000021d0: 696f 6e20 5465 7374 2046 756e 6374 696f  ion Test Functio
+000021e0: 6e73 2049 6e64 6578 2e20 5265 7472 6965  ns Index. Retrie
+000021f0: 7665 6420 4a75 6e65 2032 3031 332c 2066  ved June 2013, f
+00002200: 726f 6d0a 2020 2020 2020 2068 7474 703a  rom.       http:
+00002210: 2f2f 696e 6669 6e69 7479 3737 2e6e 6574  //infinity77.net
+00002220: 2f67 6c6f 6261 6c5f 6f70 7469 6d69 7a61  /global_optimiza
+00002230: 7469 6f6e 2f74 6573 745f 6675 6e63 7469  tion/test_functi
+00002240: 6f6e 732e 6874 6d6c 2374 6573 742d 6675  ons.html#test-fu
+00002250: 6e63 7469 6f6e 732d 696e 6465 782e 0a0a  nctions-index...
+00002260: 2020 2020 2e2e 205b 325d 2068 7474 7073      .. [2] https
+00002270: 3a2f 2f77 7777 2e73 6675 2e63 612f 7e73  ://www.sfu.ca/~s
+00002280: 7375 726a 616e 6f2f 6275 6b69 6e36 2e68  surjano/bukin6.h
+00002290: 746d 6c0a 0a20 2020 2022 2222 0a0a 2020  tml..    """..  
+000022a0: 2020 6465 6620 5f5f 696e 6974 5f5f 2873    def __init__(s
+000022b0: 656c 662c 206d 6174 6c61 625f 6d6f 6465  elf, matlab_mode
+000022c0: 6c3d 4661 6c73 6529 3a0a 2020 2020 2020  l=False):.      
+000022d0: 2020 7375 7065 7228 7479 7065 2873 656c    super(type(sel
+000022e0: 6629 2c20 7365 6c66 292e 5f5f 696e 6974  f), self).__init
+000022f0: 5f5f 286d 6174 6c61 625f 6d6f 6465 6c3d  __(matlab_model=
+00002300: 6d61 746c 6162 5f6d 6f64 656c 290a 2020  matlab_model).  
+00002310: 2020 2020 2020 7365 6c66 2e66 6e61 6d65        self.fname
+00002320: 203d 2069 6e73 7065 6374 2e67 6574 6669   = inspect.getfi
+00002330: 6c65 2869 6e73 7065 6374 2e63 7572 7265  le(inspect.curre
+00002340: 6e74 6672 616d 6528 2929 0a0a 2020 2020  ntframe())..    
+00002350: 6465 6620 7661 6c69 6461 7465 2873 656c  def validate(sel
+00002360: 6629 3a0a 2020 2020 2020 2020 7061 7373  f):.        pass
+00002370: 0a0a 2020 2020 6465 6620 7369 6d75 6c61  ..    def simula
+00002380: 7465 2873 656c 662c 2070 726f 6365 7373  te(self, process
+00002390: 5f69 643d 4e6f 6e65 2c20 6d61 746c 6162  _id=None, matlab
+000023a0: 5f65 6e67 696e 653d 4e6f 6e65 293a 0a0a  _engine=None):..
+000023b0: 2020 2020 2020 2020 7920 3d20 3130 3020          y = 100 
+000023c0: 2a20 6e70 2e73 7172 7428 6162 7328 7365  * np.sqrt(abs(se
+000023d0: 6c66 2e70 5b22 7832 225d 202d 2030 2e30  lf.p["x2"] - 0.0
+000023e0: 3120 2a20 7365 6c66 2e70 5b22 7831 225d  1 * self.p["x1"]
+000023f0: 202a 2a20 3229 2920 2b20 302e 3031 202a   ** 2)) + 0.01 *
+00002400: 2061 6273 2873 656c 662e 705b 2278 3122   abs(self.p["x1"
+00002410: 5d20 2b20 3130 290a 0a20 2020 2020 2020  ] + 10)..       
+00002420: 2079 5f6f 7574 203d 2079 5b3a 2c20 6e70   y_out = y[:, np
+00002430: 2e6e 6577 6178 6973 5d0a 0a20 2020 2020  .newaxis]..     
+00002440: 2020 2072 6574 7572 6e20 795f 6f75 740a     return y_out.
+00002450: 0a0a 636c 6173 7320 4372 6f73 7369 6e54  ..class CrossinT
+00002460: 7261 7946 756e 6374 696f 6e28 4162 7374  rayFunction(Abst
+00002470: 7261 6374 4d6f 6465 6c29 3a0a 2020 2020  ractModel):.    
+00002480: 2222 220a 2020 2020 322d 6469 6d65 6e73  """.    2-dimens
+00002490: 696f 6e61 6c20 4372 6f73 732d 696e 2d54  ional Cross-in-T
+000024a0: 7261 7920 4675 6e63 7469 6f6e 205b 315d  ray Function [1]
+000024b0: 5b32 5d2e 0a20 2020 2054 6865 2043 726f  [2]..    The Cro
+000024c0: 7373 2d69 6e2d 5472 6179 2066 756e 6374  ss-in-Tray funct
+000024d0: 696f 6e20 6861 7320 6d75 6c74 6970 6c65  ion has multiple
+000024e0: 2067 6c6f 6261 6c20 6d69 6e69 6d61 2e0a   global minima..
+000024f0: 2020 2020 4974 2069 7320 7368 6f77 6e20      It is shown 
+00002500: 6865 7265 2077 6974 6820 6120 736d 616c  here with a smal
+00002510: 6c65 7220 646f 6d61 696e 2069 6e20 7468  ler domain in th
+00002520: 6520 7365 636f 6e64 2070 6c6f 742c 0a20  e second plot,. 
+00002530: 2020 2073 6f20 7468 6174 2069 7473 2063     so that its c
+00002540: 6861 7261 6374 6572 6973 7469 6320 2263  haracteristic "c
+00002550: 726f 7373 2220 7769 6c6c 2062 6520 7669  ross" will be vi
+00002560: 7369 626c 652e 0a0a 2020 2020 2e2e 206d  sible...    .. m
+00002570: 6174 683a 3a0a 2020 2020 2020 7920 3d20  ath::.      y = 
+00002580: 2d30 2e30 3030 315c 5c6c 6566 7428 5c5c  -0.0001\\left(\\
+00002590: 6d69 645c 5c73 696e 2878 5f31 295c 5c73  mid\\sin(x_1)\\s
+000025a0: 696e 2878 5f32 295c 5c65 7870 5c5c 6c65  in(x_2)\\exp\\le
+000025b0: 6674 285c 5c6d 6964 2031 3030 2d5c 5c66  ft(\\mid 100-\\f
+000025c0: 7261 637b 5c5c 7371 7274 7b78 5f31 5e32  rac{\\sqrt{x_1^2
+000025d0: 202b 2078 5f32 5e32 7d7d 7b5c 5c70 697d   + x_2^2}}{\\pi}
+000025e0: 5c5c 6d69 645c 5c72 6967 6874 295c 5c6d  \\mid\\right)\\m
+000025f0: 6964 202b 2031 5c5c 7269 6768 7429 5e7b  id + 1\\right)^{
+00002600: 302e 317d 0a0a 2020 2020 5061 7261 6d65  0.1}..    Parame
+00002610: 7465 7273 0a20 2020 202d 2d2d 2d2d 2d2d  ters.    -------
+00002620: 2d2d 2d0a 2020 2020 705b 2278 3122 5d3a  ---.    p["x1"]:
+00002630: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
+00002640: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
+00002650: 6964 5d0a 2020 2020 2020 2020 4669 7273  id].        Firs
+00002660: 7420 7061 7261 6d65 7465 7220 6465 6669  t parameter defi
+00002670: 6e65 6420 696e 205b 2d31 302c 2031 305d  ned in [-10, 10]
+00002680: 0a20 2020 2070 5b22 7832 225d 3a20 666c  .    p["x2"]: fl
+00002690: 6f61 7420 6f72 206e 6461 7272 6179 206f  oat or ndarray o
+000026a0: 6620 666c 6f61 7420 5b6e 5f67 7269 645d  f float [n_grid]
+000026b0: 0a20 2020 2020 2020 2073 6563 6f6e 6420  .        second 
+000026c0: 7061 7261 6d65 7465 7220 6465 6669 6e65  parameter define
+000026d0: 6420 696e 205b 2d31 302c 2031 305d 0a20  d in [-10, 10]. 
+000026e0: 2020 2070 5b22 7869 225d 3a20 666c 6f61     p["xi"]: floa
+000026f0: 7420 6f72 206e 6461 7272 6179 206f 6620  t or ndarray of 
+00002700: 666c 6f61 7420 5b6e 5f67 7269 645d 0a20  float [n_grid]. 
+00002710: 2020 2020 2020 2069 2d74 6820 7061 7261         i-th para
+00002720: 6d65 7465 7220 6465 6669 6e65 6420 696e  meter defined in
+00002730: 205b 2d31 302c 2031 305d 0a0a 2020 2020   [-10, 10]..    
+00002740: 5265 7475 726e 730a 2020 2020 2d2d 2d2d  Returns.    ----
+00002750: 2d2d 2d0a 2020 2020 793a 206e 6461 7272  ---.    y: ndarr
+00002760: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
+00002770: 7269 6420 7820 315d 0a20 2020 2020 2020  rid x 1].       
+00002780: 204f 7574 7075 740a 0a20 2020 204e 6f74   Output..    Not
+00002790: 6573 0a20 2020 202d 2d2d 2d2d 0a20 2020  es.    -----.   
+000027a0: 202e 2e20 706c 6f74 3a3a 0a0a 2020 2020   .. plot::..    
+000027b0: 2020 2069 6d70 6f72 7420 6e75 6d70 7920     import numpy 
+000027c0: 6173 206e 700a 2020 2020 2020 2066 726f  as np.       fro
+000027d0: 6d20 7079 6770 632e 7465 7374 6675 6e63  m pygpc.testfunc
+000027e0: 7469 6f6e 7320 696d 706f 7274 2070 6c6f  tions import plo
+000027f0: 745f 7465 7374 6675 6e63 7469 6f6e 2061  t_testfunction a
+00002800: 7320 706c 6f74 0a20 2020 2020 2020 6672  s plot.       fr
+00002810: 6f6d 2063 6f6c 6c65 6374 696f 6e73 2069  om collections i
+00002820: 6d70 6f72 7420 4f72 6465 7265 6444 6963  mport OrderedDic
+00002830: 740a 0a20 2020 2020 2020 7061 7261 6d65  t..       parame
+00002840: 7465 7273 203d 204f 7264 6572 6564 4469  ters = OrderedDi
+00002850: 6374 2829 0a20 2020 2020 2020 7061 7261  ct().       para
+00002860: 6d65 7465 7273 5b22 7831 225d 203d 206e  meters["x1"] = n
+00002870: 702e 6c69 6e73 7061 6365 282d 3130 2c20  p.linspace(-10, 
+00002880: 3130 2c20 3130 3029 0a20 2020 2020 2020  10, 100).       
+00002890: 7061 7261 6d65 7465 7273 5b22 7832 225d  parameters["x2"]
+000028a0: 203d 206e 702e 6c69 6e73 7061 6365 282d   = np.linspace(-
+000028b0: 3130 2c20 3130 2c20 3130 3029 0a0a 2020  10, 10, 100)..  
+000028c0: 2020 2020 2063 6f6e 7374 616e 7473 203d       constants =
+000028d0: 204e 6f6e 650a 0a20 2020 2020 2020 706c   None..       pl
+000028e0: 6f74 2822 4372 6f73 7369 6e54 7261 7946  ot("CrossinTrayF
+000028f0: 756e 6374 696f 6e22 2c20 7061 7261 6d65  unction", parame
+00002900: 7465 7273 2c20 636f 6e73 7461 6e74 732c  ters, constants,
+00002910: 2070 6c6f 745f 3364 3d46 616c 7365 290a   plot_3d=False).
+00002920: 0a20 2020 202e 2e20 5b31 5d20 5465 7374  .    .. [1] Test
+00002930: 2066 756e 6374 696f 6e73 2066 6f72 206f   functions for o
+00002940: 7074 696d 697a 6174 696f 6e2e 2049 6e20  ptimization. In 
+00002950: 5769 6b69 7065 6469 612e 2052 6574 7269  Wikipedia. Retri
+00002960: 6576 6564 204a 756e 6520 3230 3133 2c20  eved June 2013, 
+00002970: 6672 6f6d 0a20 2020 2020 2020 6874 7470  from.       http
+00002980: 733a 2f2f 656e 2e77 696b 6970 6564 6961  s://en.wikipedia
+00002990: 2e6f 7267 2f77 696b 692f 5465 7374 5f66  .org/wiki/Test_f
+000029a0: 756e 6374 696f 6e73 5f66 6f72 5f6f 7074  unctions_for_opt
+000029b0: 696d 697a 6174 696f 6e2e 0a20 2020 202e  imization..    .
+000029c0: 2e20 5b32 5d20 6874 7470 733a 2f2f 7777  . [2] https://ww
+000029d0: 772e 7366 752e 6361 2f7e 7373 7572 6a61  w.sfu.ca/~ssurja
+000029e0: 6e6f 2f63 726f 7373 6974 2e68 746d 6c0a  no/crossit.html.
+000029f0: 2020 2020 2222 220a 0a20 2020 2064 6566      """..    def
+00002a00: 205f 5f69 6e69 745f 5f28 7365 6c66 2c20   __init__(self, 
+00002a10: 6d61 746c 6162 5f6d 6f64 656c 3d46 616c  matlab_model=Fal
+00002a20: 7365 293a 0a20 2020 2020 2020 2073 7570  se):.        sup
+00002a30: 6572 2874 7970 6528 7365 6c66 292c 2073  er(type(self), s
+00002a40: 656c 6629 2e5f 5f69 6e69 745f 5f28 6d61  elf).__init__(ma
+00002a50: 746c 6162 5f6d 6f64 656c 3d6d 6174 6c61  tlab_model=matla
+00002a60: 625f 6d6f 6465 6c29 0a20 2020 2020 2020  b_model).       
+00002a70: 2073 656c 662e 666e 616d 6520 3d20 696e   self.fname = in
+00002a80: 7370 6563 742e 6765 7466 696c 6528 696e  spect.getfile(in
+00002a90: 7370 6563 742e 6375 7272 656e 7466 7261  spect.currentfra
+00002aa0: 6d65 2829 290a 0a20 2020 2064 6566 2076  me())..    def v
+00002ab0: 616c 6964 6174 6528 7365 6c66 293a 0a20  alidate(self):. 
+00002ac0: 2020 2020 2020 2070 6173 730a 0a20 2020         pass..   
+00002ad0: 2064 6566 2073 696d 756c 6174 6528 7365   def simulate(se
+00002ae0: 6c66 2c20 7072 6f63 6573 735f 6964 3d4e  lf, process_id=N
+00002af0: 6f6e 652c 206d 6174 6c61 625f 656e 6769  one, matlab_engi
+00002b00: 6e65 3d4e 6f6e 6529 3a0a 0a20 2020 2020  ne=None):..     
+00002b10: 2020 2079 203d 202d 302e 3030 3031 202a     y = -0.0001 *
+00002b20: 2028 6e70 2e61 6273 286e 702e 7369 6e28   (np.abs(np.sin(
+00002b30: 7365 6c66 2e70 5b22 7831 225d 2920 2a20  self.p["x1"]) * 
+00002b40: 6e70 2e73 696e 2873 656c 662e 705b 2278  np.sin(self.p["x
+00002b50: 3222 5d29 202a 0a20 2020 2020 2020 2020  2"]) *.         
+00002b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002b70: 2020 2020 206e 702e 6578 7028 6e70 2e61       np.exp(np.a
+00002b80: 6273 2831 3030 202d 2028 6e70 2e73 7172  bs(100 - (np.sqr
+00002b90: 7428 7365 6c66 2e70 5b22 7831 225d 2a2a  t(self.p["x1"]**
+00002ba0: 3220 2b20 7365 6c66 2e70 5b22 7832 225d  2 + self.p["x2"]
+00002bb0: 2a2a 3229 2920 2f20 6e70 2e70 6929 2929  **2)) / np.pi)))
+00002bc0: 202b 2031 2920 2a2a 302e 310a 0a20 2020   + 1) **0.1..   
+00002bd0: 2020 2020 2079 5f6f 7574 203d 2079 5b3a       y_out = y[:
+00002be0: 2c20 6e70 2e6e 6577 6178 6973 5d0a 0a20  , np.newaxis].. 
+00002bf0: 2020 2020 2020 2072 6574 7572 6e20 795f         return y_
+00002c00: 6f75 740a 0a0a 636c 6173 7320 426f 6861  out...class Boha
+00002c10: 6368 6576 736b 7946 756e 6374 696f 6e31  chevskyFunction1
+00002c20: 2841 6273 7472 6163 744d 6f64 656c 293a  (AbstractModel):
+00002c30: 0a20 2020 2022 2222 0a20 2020 2032 2d64  .    """.    2-d
+00002c40: 696d 656e 7369 6f6e 616c 2066 6972 7374  imensional first
+00002c50: 2042 6f68 6163 6865 7673 6b79 2066 756e   Bohachevsky fun
+00002c60: 6374 696f 6e20 5b31 5d5b 325d 2e0a 2020  ction [1][2]..  
+00002c70: 2020 5468 6520 426f 6861 6368 6576 736b    The Bohachevsk
+00002c80: 7920 6675 6e63 7469 6f6e 7320 616c 6c20  y functions all 
+00002c90: 6861 7665 2074 6865 2073 616d 6520 7369  have the same si
+00002ca0: 6d69 6c61 7220 626f 776c 2073 6861 7065  milar bowl shape
+00002cb0: 2e20 5468 6520 6f6e 6520 7368 6f77 6e20  . The one shown 
+00002cc0: 6162 6f76 6520 6973 2074 6865 2066 6972  above is the fir
+00002cd0: 7374 2066 756e 6374 696f 6e2e 0a0a 2020  st function...  
+00002ce0: 2020 2e2e 206d 6174 683a 3a0a 2020 2020    .. math::.    
+00002cf0: 2079 203d 2078 5f31 5e32 202b 2032 785f   y = x_1^2 + 2x_
+00002d00: 325e 3220 2d20 302e 335c 5c63 6f73 2833  2^2 - 0.3\\cos(3
+00002d10: 5c5c 7069 2078 5f31 2920 2d20 302e 345c  \\pi x_1) - 0.4\
+00002d20: 5c63 6f73 2834 5c5c 7069 2078 5f32 2920  \cos(4\\pi x_2) 
+00002d30: 2b20 302e 370a 0a20 2020 2050 6172 616d  + 0.7..    Param
+00002d40: 6574 6572 730a 2020 2020 2d2d 2d2d 2d2d  eters.    ------
+00002d50: 2d2d 2d2d 0a20 2020 2070 5b22 7831 225d  ----.    p["x1"]
+00002d60: 3a20 666c 6f61 7420 6f72 206e 6461 7272  : float or ndarr
+00002d70: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
+00002d80: 7269 645d 0a20 2020 2020 2020 2046 6972  rid].        Fir
+00002d90: 7374 2070 6172 616d 6574 6572 2064 6566  st parameter def
+00002da0: 696e 6564 2069 6e20 5b2d 3130 302c 2031  ined in [-100, 1
+00002db0: 3030 5d0a 2020 2020 705b 2278 3222 5d3a  00].    p["x2"]:
+00002dc0: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
+00002dd0: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
+00002de0: 6964 5d0a 2020 2020 2020 2020 7365 636f  id].        seco
+00002df0: 6e64 2070 6172 616d 6574 6572 2064 6566  nd parameter def
+00002e00: 696e 6564 2069 6e20 5b2d 3130 302c 2031  ined in [-100, 1
+00002e10: 3030 5d0a 2020 2020 705b 2278 6922 5d3a  00].    p["xi"]:
+00002e20: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
+00002e30: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
+00002e40: 6964 5d0a 2020 2020 2020 2020 692d 7468  id].        i-th
+00002e50: 2070 6172 616d 6574 6572 2064 6566 696e   parameter defin
+00002e60: 6564 2069 6e20 5b2d 3130 302c 2031 3030  ed in [-100, 100
+00002e70: 5d0a 0a20 2020 2052 6574 7572 6e73 0a20  ]..    Returns. 
+00002e80: 2020 202d 2d2d 2d2d 2d2d 0a20 2020 2079     -------.    y
+00002e90: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
+00002ea0: 6174 205b 6e5f 6772 6964 2078 2031 5d0a  at [n_grid x 1].
+00002eb0: 2020 2020 2020 2020 4f75 7470 7574 0a0a          Output..
+00002ec0: 2020 2020 4e6f 7465 730a 2020 2020 2d2d      Notes.    --
+00002ed0: 2d2d 2d0a 2020 2020 2e2e 2070 6c6f 743a  ---.    .. plot:
+00002ee0: 3a0a 0a20 2020 2020 2020 696d 706f 7274  :..       import
+00002ef0: 206e 756d 7079 2061 7320 6e70 0a20 2020   numpy as np.   
+00002f00: 2020 2020 6672 6f6d 2070 7967 7063 2e74      from pygpc.t
+00002f10: 6573 7466 756e 6374 696f 6e73 2069 6d70  estfunctions imp
+00002f20: 6f72 7420 706c 6f74 5f74 6573 7466 756e  ort plot_testfun
+00002f30: 6374 696f 6e20 6173 2070 6c6f 740a 2020  ction as plot.  
+00002f40: 2020 2020 2066 726f 6d20 636f 6c6c 6563       from collec
+00002f50: 7469 6f6e 7320 696d 706f 7274 204f 7264  tions import Ord
+00002f60: 6572 6564 4469 6374 0a0a 2020 2020 2020  eredDict..      
+00002f70: 2070 6172 616d 6574 6572 7320 3d20 4f72   parameters = Or
+00002f80: 6465 7265 6444 6963 7428 290a 2020 2020  deredDict().    
+00002f90: 2020 2070 6172 616d 6574 6572 735b 2278     parameters["x
+00002fa0: 3122 5d20 3d20 6e70 2e6c 696e 7370 6163  1"] = np.linspac
+00002fb0: 6528 2d31 3030 2c20 3130 3020 2c20 3130  e(-100, 100 , 10
+00002fc0: 3029 0a20 2020 2020 2020 7061 7261 6d65  0).       parame
+00002fd0: 7465 7273 5b22 7832 225d 203d 206e 702e  ters["x2"] = np.
+00002fe0: 6c69 6e73 7061 6365 282d 3130 302c 2031  linspace(-100, 1
+00002ff0: 3030 202c 2031 3030 290a 0a20 2020 2020  00 , 100)..     
+00003000: 2020 636f 6e73 7461 6e74 7320 3d20 4e6f    constants = No
+00003010: 6e65 0a0a 2020 2020 2020 2070 6c6f 7428  ne..       plot(
+00003020: 2242 6f68 6163 6865 7673 6b79 4675 6e63  "BohachevskyFunc
+00003030: 7469 6f6e 3122 2c20 7061 7261 6d65 7465  tion1", paramete
+00003040: 7273 2c20 636f 6e73 7461 6e74 732c 2070  rs, constants, p
+00003050: 6c6f 745f 3364 3d46 616c 7365 290a 0a20  lot_3d=False).. 
+00003060: 2020 202e 2e20 5b31 5d20 476c 6f62 616c     .. [1] Global
+00003070: 204f 7074 696d 697a 6174 696f 6e20 785f   Optimization x_
+00003080: 3120 2a2a 3220 2b20 3278 5f32 202a 2a32  1 **2 + 2x_2 **2
+00003090: 202d 2030 2e33 202a 2063 6f73 2833 7069   - 0.3 * cos(3pi
+000030a0: 202a 2078 5f31 2920 2d20 302e 3420 2a20   * x_1) - 0.4 * 
+000030b0: 636f 7328 3470 6920 2a20 785f 3229 202b  cos(4pi * x_2) +
+000030c0: 2030 2e37 2054 6573 7420 5072 6f62 6c65   0.7 Test Proble
+000030d0: 6d73 2e0a 2020 2020 2020 2052 6574 7269  ms..       Retri
+000030e0: 6576 6564 204a 756e 6520 3230 3133 2c20  eved June 2013, 
+000030f0: 6672 6f6d 2068 7474 703a 2f2f 7777 772d  from http://www-
+00003100: 6f70 7469 6d61 2e61 6d70 2e69 2e6b 796f  optima.amp.i.kyo
+00003110: 746f 2d75 2e61 632e 6a70 2f6d 656d 6265  to-u.ac.jp/membe
+00003120: 722f 7374 7564 656e 742f 6865 6461 722f  r/student/hedar/
+00003130: 4865 6461 725f 6669 6c65 732f 5465 7374  Hedar_files/Test
+00003140: 474f 2e68 746d 2e0a 2020 2020 2e2e 205b  GO.htm..    .. [
+00003150: 325d 2068 7474 7073 3a2f 2f77 7777 2e73  2] https://www.s
+00003160: 6675 2e63 612f 7e73 7375 726a 616e 6f2f  fu.ca/~ssurjano/
+00003170: 626f 6861 2e68 746d 6c0a 2020 2020 2222  boha.html.    ""
+00003180: 220a 0a20 2020 2064 6566 205f 5f69 6e69  "..    def __ini
+00003190: 745f 5f28 7365 6c66 2c20 6d61 746c 6162  t__(self, matlab
+000031a0: 5f6d 6f64 656c 3d46 616c 7365 293a 0a20  _model=False):. 
+000031b0: 2020 2020 2020 2073 7570 6572 2874 7970         super(typ
+000031c0: 6528 7365 6c66 292c 2073 656c 6629 2e5f  e(self), self)._
+000031d0: 5f69 6e69 745f 5f28 6d61 746c 6162 5f6d  _init__(matlab_m
+000031e0: 6f64 656c 3d6d 6174 6c61 625f 6d6f 6465  odel=matlab_mode
+000031f0: 6c29 0a20 2020 2020 2020 2073 656c 662e  l).        self.
+00003200: 666e 616d 6520 3d20 696e 7370 6563 742e  fname = inspect.
+00003210: 6765 7466 696c 6528 696e 7370 6563 742e  getfile(inspect.
+00003220: 6375 7272 656e 7466 7261 6d65 2829 290a  currentframe()).
+00003230: 0a20 2020 2064 6566 2076 616c 6964 6174  .    def validat
+00003240: 6528 7365 6c66 293a 0a20 2020 2020 2020  e(self):.       
+00003250: 2070 6173 730a 0a20 2020 2064 6566 2073   pass..    def s
+00003260: 696d 756c 6174 6528 7365 6c66 2c20 7072  imulate(self, pr
+00003270: 6f63 6573 735f 6964 3d4e 6f6e 652c 206d  ocess_id=None, m
+00003280: 6174 6c61 625f 656e 6769 6e65 3d4e 6f6e  atlab_engine=Non
+00003290: 6529 3a0a 0a20 2020 2020 2020 2079 203d  e):..        y =
+000032a0: 2028 7365 6c66 2e70 5b22 7831 225d 202a   (self.p["x1"] *
+000032b0: 2a32 2920 2b20 2873 656c 662e 705b 2278  *2) + (self.p["x
+000032c0: 3222 5d20 2a2a 3229 202d 2030 2e33 202a  2"] **2) - 0.3 *
+000032d0: 206e 702e 636f 7328 3320 2a20 6e70 2e70   np.cos(3 * np.p
+000032e0: 6920 2a20 7365 6c66 2e70 5b22 7831 225d  i * self.p["x1"]
+000032f0: 295c 0a20 2020 2020 2020 2020 2020 202d  )\.            -
+00003300: 2030 2e34 202a 206e 702e 636f 7328 3420   0.4 * np.cos(4 
+00003310: 2a20 6e70 2e70 6920 2a20 7365 6c66 2e70  * np.pi * self.p
+00003320: 5b22 7832 225d 2920 2b20 302e 370a 0a20  ["x2"]) + 0.7.. 
+00003330: 2020 2020 2020 2079 5f6f 7574 203d 2079         y_out = y
+00003340: 5b3a 2c20 6e70 2e6e 6577 6178 6973 5d0a  [:, np.newaxis].
+00003350: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00003360: 795f 6f75 740a 0a0a 636c 6173 7320 5065  y_out...class Pe
+00003370: 726d 4675 6e63 7469 6f6e 2841 6273 7472  rmFunction(Abstr
+00003380: 6163 744d 6f64 656c 293a 0a20 2020 2022  actModel):.    "
+00003390: 2222 0a20 2020 2064 2d64 696d 656e 7369  "".    d-dimensi
+000033a0: 6f6e 616c 2050 6572 6d20 6675 6e63 7469  onal Perm functi
+000033b0: 6f6e 2030 2c20 442c 2062 2028 6265 7461  on 0, D, b (beta
+000033c0: 2920 5b31 5d5b 325d 2e20 5468 6520 7061  ) [1][2]. The pa
+000033d0: 7261 6d65 7465 7220 6220 2862 6574 6129  rameter b (beta)
+000033e0: 2069 7320 6f66 7465 6e20 6173 7375 6d65   is often assume
+000033f0: 6420 746f 2062 6520 623d 3130 2e0a 0a20  d to be b=10... 
+00003400: 2020 202e 2e20 6d61 7468 3a3a 0a20 2020     .. math::.   
+00003410: 2020 2079 203d 205c 5c73 756d 5f7b 693d     y = \\sum_{i=
+00003420: 317d 5e7b 647d 5c5c 6c65 6674 285c 5c73  1}^{d}\\left(\\s
+00003430: 756d 5f7b 6a3d 317d 5e7b 647d 286a 202b  um_{j=1}^{d}(j +
+00003440: 205c 5c62 6574 6129 5c5c 6c65 6674 2878   \\beta)\\left(x
+00003450: 5f6a 5e69 2d5c 5c66 7261 637b 317d 7b6a  _j^i-\\frac{1}{j
+00003460: 5e69 7d5c 5c72 6967 6874 295c 5c72 6967  ^i}\\right)\\rig
+00003470: 6874 295e 320a 0a20 2020 2050 6172 616d  ht)^2..    Param
+00003480: 6574 6572 730a 2020 2020 2d2d 2d2d 2d2d  eters.    ------
+00003490: 2d2d 2d2d 0a20 2020 2070 5b22 7831 225d  ----.    p["x1"]
+000034a0: 3a20 666c 6f61 7420 6f72 206e 6461 7272  : float or ndarr
+000034b0: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
+000034c0: 7269 645d 0a20 2020 2020 2020 2046 6972  rid].        Fir
+000034d0: 7374 2070 6172 616d 6574 6572 2064 6566  st parameter def
+000034e0: 696e 6564 2069 6e20 5b2d 642c 2064 5d0a  ined in [-d, d].
+000034f0: 2020 2020 705b 2278 6922 5d3a 2066 6c6f      p["xi"]: flo
+00003500: 6174 206f 7220 6e64 6172 7261 7920 6f66  at or ndarray of
+00003510: 2066 6c6f 6174 205b 6e5f 6772 6964 5d0a   float [n_grid].
+00003520: 2020 2020 2020 2020 6920 7061 7261 6d65          i parame
+00003530: 7465 7220 6465 6669 6e65 6420 696e 205b  ter defined in [
+00003540: 2d64 2c20 645d 0a20 2020 2070 5b22 786a  -d, d].    p["xj
+00003550: 225d 3a20 666c 6f61 7420 6f72 206e 6461  "]: float or nda
+00003560: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
+00003570: 5f67 7269 645d 0a20 2020 2020 2020 206a  _grid].        j
+00003580: 2070 6172 616d 6574 6572 2064 6566 696e   parameter defin
+00003590: 6564 2069 6e20 5b2d 642c 2064 5d0a 0a20  ed in [-d, d].. 
+000035a0: 2020 2052 6574 7572 6e73 0a20 2020 202d     Returns.    -
+000035b0: 2d2d 2d2d 2d2d 0a20 2020 2079 3a20 6e64  ------.    y: nd
+000035c0: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
+000035d0: 6e5f 6772 6964 2078 2031 5d0a 2020 2020  n_grid x 1].    
+000035e0: 2020 2020 4f75 7470 7574 0a0a 2020 2020      Output..    
+000035f0: 4e6f 7465 730a 2020 2020 2d2d 2d2d 2d0a  Notes.    -----.
+00003600: 2020 2020 2e2e 2070 6c6f 743a 3a0a 0a20      .. plot::.. 
+00003610: 2020 2020 2020 696d 706f 7274 206e 756d        import num
+00003620: 7079 2061 7320 6e70 0a20 2020 2020 2020  py as np.       
+00003630: 6672 6f6d 2070 7967 7063 2e74 6573 7466  from pygpc.testf
+00003640: 756e 6374 696f 6e73 2069 6d70 6f72 7420  unctions import 
+00003650: 706c 6f74 5f74 6573 7466 756e 6374 696f  plot_testfunctio
+00003660: 6e20 6173 2070 6c6f 740a 2020 2020 2020  n as plot.      
+00003670: 2066 726f 6d20 636f 6c6c 6563 7469 6f6e   from collection
+00003680: 7320 696d 706f 7274 204f 7264 6572 6564  s import Ordered
+00003690: 4469 6374 0a0a 2020 2020 2020 2070 6172  Dict..       par
+000036a0: 616d 6574 6572 7320 3d20 4f72 6465 7265  ameters = Ordere
+000036b0: 6444 6963 7428 290a 2020 2020 2020 2070  dDict().       p
+000036c0: 6172 616d 6574 6572 735b 2278 3122 5d20  arameters["x1"] 
+000036d0: 3d20 6e70 2e6c 696e 7370 6163 6528 2d32  = np.linspace(-2
+000036e0: 2c20 322c 2031 3030 290a 2020 2020 2020  , 2, 100).      
+000036f0: 2070 6172 616d 6574 6572 735b 2278 3222   parameters["x2"
+00003700: 5d20 3d20 6e70 2e6c 696e 7370 6163 6528  ] = np.linspace(
+00003710: 2d32 2c20 322c 2031 3030 290a 0a20 2020  -2, 2, 100)..   
+00003720: 2020 2020 636f 6e73 7461 6e74 7320 3d20      constants = 
+00003730: 4f72 6465 7265 6444 6963 7428 290a 2020  OrderedDict().  
+00003740: 2020 2020 2063 6f6e 7374 616e 7473 5b22       constants["
+00003750: 6222 5d20 3d20 3130 0a0a 2020 2020 2020  b"] = 10..      
+00003760: 2070 6c6f 7428 2250 6572 6d46 756e 6374   plot("PermFunct
+00003770: 696f 6e22 2c20 7061 7261 6d65 7465 7273  ion", parameters
+00003780: 2c20 636f 6e73 7461 6e74 732c 2070 6c6f  , constants, plo
+00003790: 745f 3364 3d46 616c 7365 290a 0a20 2020  t_3d=False)..   
+000037a0: 202e 2e20 5b31 5d20 476c 6f62 616c 204f   .. [1] Global O
+000037b0: 7074 696d 697a 6174 696f 6e20 5465 7374  ptimization Test
+000037c0: 2050 726f 626c 656d 732e 2052 6574 7269   Problems. Retri
+000037d0: 6576 6564 204a 756e 6520 3230 3133 2c20  eved June 2013, 
+000037e0: 6672 6f6d 0a20 2020 2020 2020 6874 7470  from.       http
+000037f0: 3a2f 2f77 7777 2d6f 7074 696d 612e 616d  ://www-optima.am
+00003800: 702e 692e 6b79 6f74 6f2d 752e 6163 2e6a  p.i.kyoto-u.ac.j
+00003810: 702f 6d65 6d62 6572 2f73 7475 6465 6e74  p/member/student
+00003820: 2f68 6564 6172 2f48 6564 6172 5f66 696c  /hedar/Hedar_fil
+00003830: 6573 2f54 6573 7447 4f2e 6874 6d2e 0a20  es/TestGO.htm.. 
+00003840: 2020 202e 2e20 5b32 5d20 6874 7470 733a     .. [2] https:
+00003850: 2f2f 7777 772e 7366 752e 6361 2f7e 7373  //www.sfu.ca/~ss
+00003860: 7572 6a61 6e6f 2f70 6572 6d30 6462 2e68  urjano/perm0db.h
+00003870: 746d 6c0a 2020 2020 2222 220a 0a20 2020  tml.    """..   
+00003880: 2064 6566 205f 5f69 6e69 745f 5f28 7365   def __init__(se
+00003890: 6c66 2c20 6d61 746c 6162 5f6d 6f64 656c  lf, matlab_model
+000038a0: 3d46 616c 7365 293a 0a20 2020 2020 2020  =False):.       
+000038b0: 2073 7570 6572 2874 7970 6528 7365 6c66   super(type(self
+000038c0: 292c 2073 656c 6629 2e5f 5f69 6e69 745f  ), self).__init_
+000038d0: 5f28 6d61 746c 6162 5f6d 6f64 656c 3d6d  _(matlab_model=m
+000038e0: 6174 6c61 625f 6d6f 6465 6c29 0a20 2020  atlab_model).   
+000038f0: 2020 2020 2073 656c 662e 666e 616d 6520       self.fname 
+00003900: 3d20 696e 7370 6563 742e 6765 7466 696c  = inspect.getfil
+00003910: 6528 696e 7370 6563 742e 6375 7272 656e  e(inspect.curren
+00003920: 7466 7261 6d65 2829 290a 0a20 2020 2064  tframe())..    d
+00003930: 6566 2076 616c 6964 6174 6528 7365 6c66  ef validate(self
+00003940: 293a 0a20 2020 2020 2020 2070 6173 730a  ):.        pass.
+00003950: 0a20 2020 2064 6566 2073 696d 756c 6174  .    def simulat
+00003960: 6528 7365 6c66 2c20 7072 6f63 6573 735f  e(self, process_
+00003970: 6964 3d4e 6f6e 652c 206d 6174 6c61 625f  id=None, matlab_
+00003980: 656e 6769 6e65 3d4e 6f6e 6529 3a0a 0a20  engine=None):.. 
+00003990: 2020 2020 2020 2066 6f72 2069 2c20 6b65         for i, ke
+000039a0: 7920 696e 2065 6e75 6d65 7261 7465 2873  y in enumerate(s
+000039b0: 656c 662e 702e 6b65 7973 2829 293a 0a20  elf.p.keys()):. 
+000039c0: 2020 2020 2020 2020 2020 2069 6620 7479             if ty
+000039d0: 7065 2873 656c 662e 705b 6b65 795d 2920  pe(self.p[key]) 
+000039e0: 6973 206e 702e 6e64 6172 7261 793a 0a20  is np.ndarray:. 
+000039f0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00003a00: 656c 662e 705b 6b65 795d 203d 2073 656c  elf.p[key] = sel
+00003a10: 662e 705b 6b65 795d 2e66 6c61 7474 656e  f.p[key].flatten
+00003a20: 2829 0a0a 2020 2020 2020 2020 2320 7365  ()..        # se
+00003a30: 7420 636f 6e73 7461 6e74 730a 2020 2020  t constants.    
+00003a40: 2020 2020 7020 3d20 636f 7079 2e64 6565      p = copy.dee
+00003a50: 7063 6f70 7928 7365 6c66 2e70 290a 2020  pcopy(self.p).  
+00003a60: 2020 2020 2020 6220 3d20 7365 6c66 2e70        b = self.p
+00003a70: 5b22 6222 5d0a 2020 2020 2020 2020 6465  ["b"].        de
+00003a80: 6c20 705b 2262 225d 0a0a 2020 2020 2020  l p["b"]..      
+00003a90: 2020 6e20 3d20 6c65 6e28 702e 6b65 7973    n = len(p.keys
+00003aa0: 2829 290a 0a20 2020 2020 2020 2023 2064  ())..        # d
+00003ab0: 6574 6572 6d69 6e65 2073 756d 0a20 2020  etermine sum.   
+00003ac0: 2020 2020 2079 203d 206e 702e 7a65 726f       y = np.zero
+00003ad0: 7328 6e70 2e61 7272 6179 2870 5b6c 6973  s(np.array(p[lis
+00003ae0: 7428 702e 6b65 7973 2829 295b 305d 5d29  t(p.keys())[0]])
+00003af0: 2e73 697a 6529 0a20 2020 2020 2020 2074  .size).        t
+00003b00: 6d70 203d 206e 702e 7a65 726f 7328 6e70  mp = np.zeros(np
+00003b10: 2e61 7272 6179 2870 5b6c 6973 7428 702e  .array(p[list(p.
+00003b20: 6b65 7973 2829 295b 305d 5d29 2e73 697a  keys())[0]]).siz
+00003b30: 6529 0a0a 2020 2020 2020 2020 666f 7220  e)..        for 
+00003b40: 692c 2069 5f6b 6579 2069 6e20 656e 756d  i, i_key in enum
+00003b50: 6572 6174 6528 702e 6b65 7973 2829 293a  erate(p.keys()):
+00003b60: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
+00003b70: 206a 2c20 6a5f 6b65 7920 696e 2065 6e75   j, j_key in enu
+00003b80: 6d65 7261 7465 2870 2e6b 6579 7328 2929  merate(p.keys())
+00003b90: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00003ba0: 2020 746d 7020 2b3d 2028 6a2b 312b 6229    tmp += (j+1+b)
+00003bb0: 2a28 705b 6a5f 6b65 795d 2a2a 2869 2b31  *(p[j_key]**(i+1
+00003bc0: 292d 312f 2828 6a2b 3129 2a2a 2869 2b31  )-1/((j+1)**(i+1
+00003bd0: 2929 290a 2020 2020 2020 2020 2020 2020  ))).            
+00003be0: 7920 2b3d 2074 6d70 2a2a 320a 2020 2020  y += tmp**2.    
+00003bf0: 2020 2020 2020 2020 746d 7020 3d20 6e70          tmp = np
+00003c00: 2e7a 6572 6f73 286e 702e 6172 7261 7928  .zeros(np.array(
+00003c10: 705b 6c69 7374 2870 2e6b 6579 7328 2929  p[list(p.keys())
+00003c20: 5b30 5d5d 292e 7369 7a65 290a 0a20 2020  [0]]).size)..   
+00003c30: 2020 2020 2079 5f6f 7574 203d 2079 5b3a       y_out = y[:
+00003c40: 2c20 6e70 2e6e 6577 6178 6973 5d0a 0a20  , np.newaxis].. 
+00003c50: 2020 2020 2020 2072 6574 7572 6e20 795f         return y_
+00003c60: 6f75 740a 0a0a 636c 6173 7320 5369 7848  out...class SixH
+00003c70: 756d 7043 616d 656c 4675 6e63 7469 6f6e  umpCamelFunction
+00003c80: 2841 6273 7472 6163 744d 6f64 656c 293a  (AbstractModel):
+00003c90: 0a20 2020 2022 2222 0a20 2020 2032 2d64  .    """.    2-d
+00003ca0: 696d 656e 7369 6f6e 616c 2053 6978 202d  imensional Six -
+00003cb0: 2048 756d 7020 4361 6d65 6c20 6675 6e63   Hump Camel func
+00003cc0: 7469 6f6e 205b 315d 5b32 5d2e 0a20 2020  tion [1][2]..   
+00003cd0: 2054 6865 2070 6c6f 7420 6f6e 2074 6865   The plot on the
+00003ce0: 206c 6566 7420 7368 6f77 7320 7468 6520   left shows the 
+00003cf0: 7369 782d 6875 6d70 2043 616d 656c 2066  six-hump Camel f
+00003d00: 756e 6374 696f 6e20 6f6e 2069 7473 2072  unction on its r
+00003d10: 6563 6f6d 6d65 6e64 6564 2069 6e70 7574  ecommended input
+00003d20: 2064 6f6d 6169 6e2c 0a20 2020 2061 6e64   domain,.    and
+00003d30: 2074 6865 2070 6c6f 7420 6f6e 2074 6865   the plot on the
+00003d40: 2072 6967 6874 2073 686f 7773 206f 6e6c   right shows onl
+00003d50: 7920 6120 706f 7274 696f 6e20 6f66 2074  y a portion of t
+00003d60: 6869 7320 646f 6d61 696e 2c0a 2020 2020  his domain,.    
+00003d70: 746f 2061 6c6c 6f77 2066 6f72 2065 6173  to allow for eas
+00003d80: 6965 7220 7669 6577 696e 6720 6f66 2074  ier viewing of t
+00003d90: 6865 2066 756e 6374 696f 6e27 7320 6b65  he function's ke
+00003da0: 7920 6368 6172 6163 7465 7269 7374 6963  y characteristic
+00003db0: 732e 0a20 2020 2054 6865 2066 756e 6374  s..    The funct
+00003dc0: 696f 6e20 6861 7320 7369 7820 6c6f 6361  ion has six loca
+00003dd0: 6c20 6d69 6e69 6d61 2c20 7477 6f20 6f66  l minima, two of
+00003de0: 2077 6869 6368 2061 7265 2067 6c6f 6261   which are globa
+00003df0: 6c2e 0a0a 2020 2020 2e2e 206d 6174 683a  l...    .. math:
+00003e00: 3a0a 2020 2020 2020 7920 3d20 5c5c 6c65  :.      y = \\le
+00003e10: 6674 2834 202d 2032 2e31 785f 315e 3220  ft(4 - 2.1x_1^2 
+00003e20: 2b20 5c5c 6672 6163 7b78 5f31 5e34 7d7b  + \\frac{x_1^4}{
+00003e30: 337d 5c5c 7269 6768 7429 785f 315e 3220  3}\\right)x_1^2 
+00003e40: 2b20 785f 3178 5f32 202b 2028 2d34 202b  + x_1x_2 + (-4 +
+00003e50: 2034 785f 325e 3229 785f 325e 320a 0a20   4x_2^2)x_2^2.. 
+00003e60: 2020 2050 6172 616d 6574 6572 730a 2020     Parameters.  
+00003e70: 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0a20 2020    ----------.   
+00003e80: 2070 5b22 7831 225d 3a20 666c 6f61 7420   p["x1"]: float 
+00003e90: 6f72 206e 6461 7272 6179 206f 6620 666c  or ndarray of fl
+00003ea0: 6f61 7420 5b6e 5f67 7269 645d 0a20 2020  oat [n_grid].   
+00003eb0: 2020 2020 2046 6972 7374 2070 6172 616d       First param
+00003ec0: 6574 6572 2064 6566 696e 6564 2069 6e20  eter defined in 
+00003ed0: 5b2d 332c 2033 5d0a 2020 2020 705b 2278  [-3, 3].    p["x
+00003ee0: 3222 5d3a 2066 6c6f 6174 206f 7220 6e64  2"]: float or nd
+00003ef0: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
+00003f00: 6e5f 6772 6964 5d0a 2020 2020 2020 2020  n_grid].        
+00003f10: 7365 636f 6e64 2070 6172 616d 6574 6572  second parameter
+00003f20: 2064 6566 696e 6564 2069 6e20 5b2d 322c   defined in [-2,
+00003f30: 2032 5d0a 0a20 2020 2052 6574 7572 6e73   2]..    Returns
+00003f40: 0a20 2020 202d 2d2d 2d2d 2d2d 0a20 2020  .    -------.   
+00003f50: 2079 3a20 6e64 6172 7261 7920 6f66 2066   y: ndarray of f
+00003f60: 6c6f 6174 205b 6e5f 6772 6964 2078 2031  loat [n_grid x 1
+00003f70: 5d0a 2020 2020 2020 2020 4f75 7470 7574  ].        Output
+00003f80: 0a0a 2020 2020 4e6f 7465 730a 2020 2020  ..    Notes.    
+00003f90: 2d2d 2d2d 2d0a 2020 2020 2e2e 2070 6c6f  -----.    .. plo
+00003fa0: 743a 3a0a 0a20 2020 2020 2020 696d 706f  t::..       impo
+00003fb0: 7274 206e 756d 7079 2061 7320 6e70 0a20  rt numpy as np. 
+00003fc0: 2020 2020 2020 6672 6f6d 2070 7967 7063        from pygpc
+00003fd0: 2e74 6573 7466 756e 6374 696f 6e73 2069  .testfunctions i
+00003fe0: 6d70 6f72 7420 706c 6f74 5f74 6573 7466  mport plot_testf
+00003ff0: 756e 6374 696f 6e20 6173 2070 6c6f 740a  unction as plot.
+00004000: 2020 2020 2020 2066 726f 6d20 636f 6c6c         from coll
+00004010: 6563 7469 6f6e 7320 696d 706f 7274 204f  ections import O
+00004020: 7264 6572 6564 4469 6374 0a0a 2020 2020  rderedDict..    
+00004030: 2020 2070 6172 616d 6574 6572 7320 3d20     parameters = 
+00004040: 4f72 6465 7265 6444 6963 7428 290a 2020  OrderedDict().  
+00004050: 2020 2020 2070 6172 616d 6574 6572 735b       parameters[
+00004060: 2278 3122 5d20 3d20 6e70 2e6c 696e 7370  "x1"] = np.linsp
+00004070: 6163 6528 2d33 2c20 3320 2c20 3130 3029  ace(-3, 3 , 100)
+00004080: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
+00004090: 7273 5b22 7832 225d 203d 206e 702e 6c69  rs["x2"] = np.li
+000040a0: 6e73 7061 6365 282d 322c 2032 202c 2031  nspace(-2, 2 , 1
+000040b0: 3030 290a 0a20 2020 2020 2020 636f 6e73  00)..       cons
+000040c0: 7461 6e74 7320 3d20 4e6f 6e65 0a0a 2020  tants = None..  
+000040d0: 2020 2020 2070 6c6f 7428 2253 6978 4875       plot("SixHu
+000040e0: 6d70 4361 6d65 6c46 756e 6374 696f 6e22  mpCamelFunction"
+000040f0: 2c20 7061 7261 6d65 7465 7273 2c20 636f  , parameters, co
+00004100: 6e73 7461 6e74 732c 2070 6c6f 745f 3364  nstants, plot_3d
+00004110: 3d46 616c 7365 290a 0a20 2020 202e 2e20  =False)..    .. 
+00004120: 5b31 5d20 4d6f 6c67 612c 204d 2e2c 2026  [1] Molga, M., &
+00004130: 2053 6d75 746e 6963 6b69 2c20 432e 2054   Smutnicki, C. T
+00004140: 6573 7420 6675 6e63 7469 6f6e 7320 666f  est functions fo
+00004150: 7220 6f70 7469 6d69 7a61 7469 6f6e 206e  r optimization n
+00004160: 6565 6473 2028 3230 3035 292e 2052 6574  eeds (2005). Ret
+00004170: 7269 6576 6564 204a 756e 6520 3230 3133  rieved June 2013
+00004180: 2c20 6672 6f6d 0a20 2020 2020 2020 6874  , from.       ht
+00004190: 7470 3a2f 2f77 7777 2e7a 7364 2e69 6374  tp://www.zsd.ict
+000041a0: 2e70 7772 2e77 726f 632e 706c 2f66 696c  .pwr.wroc.pl/fil
+000041b0: 6573 2f64 6f63 732f 6675 6e63 7469 6f6e  es/docs/function
+000041c0: 732e 7064 662e 0a20 2020 202e 2e20 5b32  s.pdf..    .. [2
+000041d0: 5d20 6874 7470 733a 2f2f 7777 772e 7366  ] https://www.sf
+000041e0: 752e 6361 2f7e 7373 7572 6a61 6e6f 2f63  u.ca/~ssurjano/c
+000041f0: 616d 656c 362e 6874 6d6c 0a20 2020 2022  amel6.html.    "
+00004200: 2222 0a0a 2020 2020 6465 6620 5f5f 696e  ""..    def __in
+00004210: 6974 5f5f 2873 656c 662c 206d 6174 6c61  it__(self, matla
+00004220: 625f 6d6f 6465 6c3d 4661 6c73 6529 3a0a  b_model=False):.
+00004230: 2020 2020 2020 2020 7375 7065 7228 7479          super(ty
+00004240: 7065 2873 656c 6629 2c20 7365 6c66 292e  pe(self), self).
+00004250: 5f5f 696e 6974 5f5f 286d 6174 6c61 625f  __init__(matlab_
+00004260: 6d6f 6465 6c3d 6d61 746c 6162 5f6d 6f64  model=matlab_mod
+00004270: 656c 290a 2020 2020 2020 2020 7365 6c66  el).        self
+00004280: 2e66 6e61 6d65 203d 2069 6e73 7065 6374  .fname = inspect
+00004290: 2e67 6574 6669 6c65 2869 6e73 7065 6374  .getfile(inspect
+000042a0: 2e63 7572 7265 6e74 6672 616d 6528 2929  .currentframe())
+000042b0: 0a0a 2020 2020 6465 6620 7661 6c69 6461  ..    def valida
+000042c0: 7465 2873 656c 6629 3a0a 2020 2020 2020  te(self):.      
+000042d0: 2020 7061 7373 0a0a 2020 2020 6465 6620    pass..    def 
+000042e0: 7369 6d75 6c61 7465 2873 656c 662c 2070  simulate(self, p
+000042f0: 726f 6365 7373 5f69 643d 4e6f 6e65 2c20  rocess_id=None, 
+00004300: 6d61 746c 6162 5f65 6e67 696e 653d 4e6f  matlab_engine=No
+00004310: 6e65 293a 0a0a 2020 2020 2020 2020 7920  ne):..        y 
+00004320: 3d20 2834 202d 2032 2e31 2a28 7365 6c66  = (4 - 2.1*(self
+00004330: 2e70 5b22 7831 225d 202a 2a32 2920 2b20  .p["x1"] **2) + 
+00004340: 2873 656c 662e 705b 2278 3122 5d20 2a2a  (self.p["x1"] **
+00004350: 3429 2f33 2920 2a20 2873 656c 662e 705b  4)/3) * (self.p[
+00004360: 2278 3122 5d20 2a2a 3229 202b 2073 656c  "x1"] **2) + sel
+00004370: 662e 705b 2278 3122 5d20 2a20 7365 6c66  f.p["x1"] * self
+00004380: 2e70 5b22 7832 225d 202b 205c 0a20 2020  .p["x2"] + \.   
+00004390: 2020 2020 2020 2020 2028 2d34 202b 2034           (-4 + 4
+000043a0: 202a 2028 7365 6c66 2e70 5b22 7832 225d   * (self.p["x2"]
+000043b0: 202a 2a32 2929 202a 2028 7365 6c66 2e70   **2)) * (self.p
+000043c0: 5b22 7832 225d 202a 2a32 290a 0a20 2020  ["x2"] **2)..   
+000043d0: 2020 2020 2079 5f6f 7574 203d 2079 5b3a       y_out = y[:
+000043e0: 2c20 6e70 2e6e 6577 6178 6973 5d0a 0a20  , np.newaxis].. 
+000043f0: 2020 2020 2020 2072 6574 7572 6e20 795f         return y_
+00004400: 6f75 740a 0a0a 636c 6173 7320 526f 7461  out...class Rota
+00004410: 7465 6448 7970 6572 456c 6c69 7073 6f69  tedHyperEllipsoi
+00004420: 6428 4162 7374 7261 6374 4d6f 6465 6c29  d(AbstractModel)
+00004430: 3a0a 2020 2020 2222 220a 2020 2020 642d  :.    """.    d-
+00004440: 6469 6d65 6e73 696f 6e61 6c20 526f 7461  dimensional Rota
+00004450: 7465 642d 4879 7065 7220 456c 6c69 7073  ted-Hyper Ellips
+00004460: 6f69 6420 4675 6e63 7469 6f6e 205b 315d  oid Function [1]
+00004470: 5b32 5d2e 0a20 2020 2054 6865 2052 6f74  [2]..    The Rot
+00004480: 6174 6564 2048 7970 6572 2d45 6c6c 6970  ated Hyper-Ellip
+00004490: 736f 6964 2066 756e 6374 696f 6e20 6973  soid function is
+000044a0: 2063 6f6e 7469 6e75 6f75 732c 2063 6f6e   continuous, con
+000044b0: 7665 7820 616e 6420 756e 696d 6f64 616c  vex and unimodal
+000044c0: 2e0a 2020 2020 4974 2069 7320 616e 2065  ..    It is an e
+000044d0: 7874 656e 7369 6f6e 206f 6620 7468 6520  xtension of the 
+000044e0: 4178 6973 2050 6172 616c 6c65 6c20 4879  Axis Parallel Hy
+000044f0: 7065 722d 456c 6c69 7073 6f69 6420 6675  per-Ellipsoid fu
+00004500: 6e63 7469 6f6e 2c20 616c 736f 2072 6566  nction, also ref
+00004510: 6572 7265 6420 746f 2061 7320 7468 6520  erred to as the 
+00004520: 5375 6d20 5371 7561 7265 7320 6675 6e63  Sum Squares func
+00004530: 7469 6f6e 2e0a 2020 2020 5468 6520 706c  tion..    The pl
+00004540: 6f74 2073 686f 7773 2069 7473 2074 776f  ot shows its two
+00004550: 2d64 696d 656e 7369 6f6e 616c 2066 6f72  -dimensional for
+00004560: 6d2e 0a0a 2020 2020 2e2e 206d 6174 683a  m...    .. math:
+00004570: 3a0a 2020 2020 2020 2079 203d 205c 5c73  :.       y = \\s
+00004580: 756d 5f7b 693d 317d 5e7b 647d 5c5c 7375  um_{i=1}^{d}\\su
+00004590: 6d5f 7b6a 3d31 7d5e 7b69 7d5c 5c2a 2078  m_{j=1}^{i}\\* x
+000045a0: 5f6a 5e32 0a0a 2020 2020 5061 7261 6d65  _j^2..    Parame
+000045b0: 7465 7273 0a20 2020 202d 2d2d 2d2d 2d2d  ters.    -------
+000045c0: 2d2d 2d0a 2020 2020 705b 2278 6922 5d3a  ---.    p["xi"]:
+000045d0: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
+000045e0: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
+000045f0: 6964 5d0a 2020 2020 2020 2020 6920 7061  id].        i pa
+00004600: 7261 6d65 7465 7220 6465 6669 6e65 6420  rameter defined 
+00004610: 696e 205b 2d36 352e 3533 362c 2036 352e  in [-65.536, 65.
+00004620: 3533 365d 0a20 2020 2070 5b22 786a 225d  536].    p["xj"]
+00004630: 3a20 666c 6f61 7420 6f72 206e 6461 7272  : float or ndarr
+00004640: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
+00004650: 7269 645d 0a20 2020 2020 2020 206a 2070  rid].        j p
+00004660: 6172 616d 6574 6572 2064 6566 696e 6564  arameter defined
+00004670: 2069 6e20 5b2d 3635 2e35 3336 2c20 3635   in [-65.536, 65
+00004680: 2e35 3336 5d0a 0a20 2020 2052 6574 7572  .536]..    Retur
+00004690: 6e73 0a20 2020 202d 2d2d 2d2d 2d2d 0a20  ns.    -------. 
+000046a0: 2020 2079 3a20 6e64 6172 7261 7920 6f66     y: ndarray of
+000046b0: 2066 6c6f 6174 205b 6e5f 6772 6964 2078   float [n_grid x
+000046c0: 2031 5d0a 2020 2020 2020 2020 4f75 7470   1].        Outp
+000046d0: 7574 0a0a 2020 2020 4e6f 7465 730a 2020  ut..    Notes.  
+000046e0: 2020 2d2d 2d2d 2d0a 2020 2020 2e2e 2070    -----.    .. p
+000046f0: 6c6f 743a 3a0a 0a20 2020 2020 2020 696d  lot::..       im
+00004700: 706f 7274 206e 756d 7079 2061 7320 6e70  port numpy as np
+00004710: 0a20 2020 2020 2020 6672 6f6d 2070 7967  .       from pyg
+00004720: 7063 2e74 6573 7466 756e 6374 696f 6e73  pc.testfunctions
+00004730: 2069 6d70 6f72 7420 706c 6f74 5f74 6573   import plot_tes
+00004740: 7466 756e 6374 696f 6e20 6173 2070 6c6f  tfunction as plo
+00004750: 740a 2020 2020 2020 2066 726f 6d20 636f  t.       from co
+00004760: 6c6c 6563 7469 6f6e 7320 696d 706f 7274  llections import
+00004770: 204f 7264 6572 6564 4469 6374 0a0a 2020   OrderedDict..  
+00004780: 2020 2020 2070 6172 616d 6574 6572 7320       parameters 
+00004790: 3d20 4f72 6465 7265 6444 6963 7428 290a  = OrderedDict().
+000047a0: 2020 2020 2020 2070 6172 616d 6574 6572         parameter
+000047b0: 735b 2278 3122 5d20 3d20 6e70 2e6c 696e  s["x1"] = np.lin
+000047c0: 7370 6163 6528 2d36 352e 3533 362c 2036  space(-65.536, 6
+000047d0: 352e 3533 362c 2031 3030 290a 2020 2020  5.536, 100).    
+000047e0: 2020 2070 6172 616d 6574 6572 735b 2278     parameters["x
+000047f0: 3222 5d20 3d20 6e70 2e6c 696e 7370 6163  2"] = np.linspac
+00004800: 6528 2d36 352e 3533 362c 2036 352e 3533  e(-65.536, 65.53
+00004810: 362c 2031 3030 290a 0a20 2020 2020 2020  6, 100)..       
+00004820: 636f 6e73 7461 6e74 7320 3d20 4e6f 6e65  constants = None
+00004830: 0a0a 2020 2020 2020 2070 6c6f 7428 2252  ..       plot("R
+00004840: 6f74 6174 6564 4879 7065 7245 6c6c 6970  otatedHyperEllip
+00004850: 736f 6964 222c 2070 6172 616d 6574 6572  soid", parameter
+00004860: 732c 2063 6f6e 7374 616e 7473 2c20 706c  s, constants, pl
+00004870: 6f74 5f33 643d 4661 6c73 6529 0a0a 2020  ot_3d=False)..  
+00004880: 2020 2e2e 205b 315d 204d 6f6c 6761 2c20    .. [1] Molga, 
+00004890: 4d2e 2c20 2620 536d 7574 6e69 636b 692c  M., & Smutnicki,
+000048a0: 2043 2e20 5465 7374 2066 756e 6374 696f   C. Test functio
+000048b0: 6e73 2066 6f72 206f 7074 696d 697a 6174  ns for optimizat
+000048c0: 696f 6e20 6e65 6564 7320 2832 3030 3529  ion needs (2005)
+000048d0: 2e0a 2020 2020 2020 2052 6574 7269 6576  ..       Retriev
+000048e0: 6564 204a 756e 6520 3230 3133 2c20 6672  ed June 2013, fr
+000048f0: 6f6d 2068 7474 703a 2f2f 7777 772e 7a73  om http://www.zs
+00004900: 642e 6963 742e 7077 722e 7772 6f63 2e70  d.ict.pwr.wroc.p
+00004910: 6c2f 6669 6c65 732f 646f 6373 2f66 756e  l/files/docs/fun
+00004920: 6374 696f 6e73 2e70 6466 2e0a 2020 2020  ctions.pdf..    
+00004930: 2e2e 205b 325d 2068 7474 7073 3a2f 2f77  .. [2] https://w
+00004940: 7777 2e73 6675 2e63 612f 7e73 7375 726a  ww.sfu.ca/~ssurj
+00004950: 616e 6f2f 726f 7468 7970 2e68 746d 6c0a  ano/rothyp.html.
+00004960: 2020 2020 2222 220a 0a20 2020 2064 6566      """..    def
+00004970: 205f 5f69 6e69 745f 5f28 7365 6c66 2c20   __init__(self, 
+00004980: 6d61 746c 6162 5f6d 6f64 656c 3d46 616c  matlab_model=Fal
+00004990: 7365 293a 0a20 2020 2020 2020 2073 7570  se):.        sup
+000049a0: 6572 2874 7970 6528 7365 6c66 292c 2073  er(type(self), s
+000049b0: 656c 6629 2e5f 5f69 6e69 745f 5f28 6d61  elf).__init__(ma
+000049c0: 746c 6162 5f6d 6f64 656c 3d6d 6174 6c61  tlab_model=matla
+000049d0: 625f 6d6f 6465 6c29 0a20 2020 2020 2020  b_model).       
+000049e0: 2073 656c 662e 666e 616d 6520 3d20 696e   self.fname = in
+000049f0: 7370 6563 742e 6765 7466 696c 6528 696e  spect.getfile(in
+00004a00: 7370 6563 742e 6375 7272 656e 7466 7261  spect.currentfra
+00004a10: 6d65 2829 290a 0a20 2020 2064 6566 2076  me())..    def v
+00004a20: 616c 6964 6174 6528 7365 6c66 293a 0a20  alidate(self):. 
+00004a30: 2020 2020 2020 2070 6173 730a 0a20 2020         pass..   
+00004a40: 2064 6566 2073 696d 756c 6174 6528 7365   def simulate(se
+00004a50: 6c66 2c20 7072 6f63 6573 735f 6964 3d4e  lf, process_id=N
+00004a60: 6f6e 652c 206d 6174 6c61 625f 656e 6769  one, matlab_engi
+00004a70: 6e65 3d4e 6f6e 6529 3a0a 0a20 2020 2020  ne=None):..     
+00004a80: 2020 2066 6f72 2069 2c20 6b65 7920 696e     for i, key in
+00004a90: 2065 6e75 6d65 7261 7465 2873 656c 662e   enumerate(self.
+00004aa0: 702e 6b65 7973 2829 293a 0a20 2020 2020  p.keys()):.     
+00004ab0: 2020 2020 2020 2069 6620 7479 7065 2873         if type(s
+00004ac0: 656c 662e 705b 6b65 795d 2920 6973 206e  elf.p[key]) is n
+00004ad0: 702e 6e64 6172 7261 793a 0a20 2020 2020  p.ndarray:.     
+00004ae0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+00004af0: 705b 6b65 795d 203d 2073 656c 662e 705b  p[key] = self.p[
+00004b00: 6b65 795d 2e66 6c61 7474 656e 2829 0a0a  key].flatten()..
+00004b10: 2020 2020 2020 2020 2320 6465 7465 726d          # determ
+00004b20: 696e 6520 7375 6d0a 2020 2020 2020 2020  ine sum.        
+00004b30: 7920 3d20 6e70 2e7a 6572 6f73 286e 702e  y = np.zeros(np.
+00004b40: 6172 7261 7928 7365 6c66 2e70 5b6c 6973  array(self.p[lis
+00004b50: 7428 7365 6c66 2e70 2e6b 6579 7328 2929  t(self.p.keys())
+00004b60: 5b30 5d5d 292e 7369 7a65 290a 2020 2020  [0]]).size).    
+00004b70: 2020 2020 6b65 7973 203d 206c 6973 7428      keys = list(
+00004b80: 7365 6c66 2e70 2e6b 6579 7328 2929 0a0a  self.p.keys())..
+00004b90: 2020 2020 2020 2020 666f 7220 692c 2069          for i, i
+00004ba0: 5f6b 6579 2069 6e20 656e 756d 6572 6174  _key in enumerat
+00004bb0: 6528 6b65 7973 293a 0a20 2020 2020 2020  e(keys):.       
+00004bc0: 2020 2020 2066 6f72 206a 2c20 6a5f 6b65       for j, j_ke
+00004bd0: 7920 696e 2065 6e75 6d65 7261 7465 286b  y in enumerate(k
+00004be0: 6579 735b 303a 692b 315d 293a 0a20 2020  eys[0:i+1]):.   
+00004bf0: 2020 2020 2020 2020 2020 2020 7920 2b3d              y +=
+00004c00: 2073 656c 662e 705b 6a5f 6b65 795d 2a2a   self.p[j_key]**
+00004c10: 320a 0a20 2020 2020 2020 2079 5f6f 7574  2..        y_out
+00004c20: 203d 2079 5b3a 2c20 6e70 2e6e 6577 6178   = y[:, np.newax
+00004c30: 6973 5d0a 0a20 2020 2020 2020 2072 6574  is]..        ret
+00004c40: 7572 6e20 795f 6f75 740a 0a0a 636c 6173  urn y_out...clas
+00004c50: 7320 5375 6d4f 6644 6966 6665 7265 6e74  s SumOfDifferent
+00004c60: 506f 7765 7273 4675 6e63 7469 6f6e 2841  PowersFunction(A
+00004c70: 6273 7472 6163 744d 6f64 656c 293a 0a20  bstractModel):. 
+00004c80: 2020 2022 2222 0a20 2020 2064 2d64 696d     """.    d-dim
+00004c90: 656e 7369 6f6e 616c 2053 756d 204f 6620  ensional Sum Of 
+00004ca0: 4469 6666 6572 656e 7420 506f 7765 7273  Different Powers
+00004cb0: 2046 756e 6374 696f 6e20 5b31 5d5b 325d   Function [1][2]
+00004cc0: 2e0a 2020 2020 5468 6520 5375 6d20 6f66  ..    The Sum of
+00004cd0: 2044 6966 6665 7265 6e74 2050 6f77 6572   Different Power
+00004ce0: 7320 6675 6e63 7469 6f6e 2069 7320 756e  s function is un
+00004cf0: 696d 6f64 616c 2e20 4974 2069 7320 7368  imodal. It is sh
+00004d00: 6f77 6e20 6865 7265 2069 6e20 6974 7320  own here in its 
+00004d10: 7477 6f2d 6469 6d65 6e73 696f 6e61 6c20  two-dimensional 
+00004d20: 666f 726d 2e0a 0a20 2020 202e 2e20 6d61  form...    .. ma
+00004d30: 7468 3a3a 0a20 2020 2020 2020 2020 7920  th::.         y 
+00004d40: 3d20 5c5c 7375 6d5f 7b69 3d31 7d5e 7b64  = \\sum_{i=1}^{d
+00004d50: 7d5c 5c6d 6964 2078 5f69 205c 5c6d 6964  }\\mid x_i \\mid
+00004d60: 205e 7b69 2b31 7d0a 0a20 2020 2050 6172   ^{i+1}..    Par
+00004d70: 616d 6574 6572 730a 2020 2020 2d2d 2d2d  ameters.    ----
+00004d80: 2d2d 2d2d 2d2d 0a20 2020 2070 5b22 7831  ------.    p["x1
+00004d90: 225d 3a20 666c 6f61 7420 6f72 206e 6461  "]: float or nda
+00004da0: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
+00004db0: 5f67 7269 645d 0a20 2020 2020 2020 2046  _grid].        F
+00004dc0: 6972 7374 2070 6172 616d 6574 6572 2064  irst parameter d
+00004dd0: 6566 696e 6564 2069 6e20 5b2d 312c 2031  efined in [-1, 1
+00004de0: 5d0a 2020 2020 705b 2278 6a22 5d3a 2066  ].    p["xj"]: f
+00004df0: 6c6f 6174 206f 7220 6e64 6172 7261 7920  loat or ndarray 
+00004e00: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
+00004e10: 5d0a 2020 2020 2020 2020 6a2d 7468 2070  ].        j-th p
+00004e20: 6172 616d 6574 6572 2064 6566 696e 6564  arameter defined
+00004e30: 2069 6e20 5b2d 312c 2031 5d0a 0a20 2020   in [-1, 1]..   
+00004e40: 2052 6574 7572 6e73 0a20 2020 202d 2d2d   Returns.    ---
+00004e50: 2d2d 2d2d 0a20 2020 2079 3a20 6e64 6172  ----.    y: ndar
+00004e60: 7261 7920 6f66 2066 6c6f 6174 205b 6e5f  ray of float [n_
+00004e70: 6772 6964 2078 2031 5d0a 2020 2020 2020  grid x 1].      
+00004e80: 2020 4f75 7470 7574 0a0a 2020 2020 4e6f    Output..    No
+00004e90: 7465 730a 2020 2020 2d2d 2d2d 2d0a 2020  tes.    -----.  
+00004ea0: 2020 2e2e 2070 6c6f 743a 3a0a 0a20 2020    .. plot::..   
+00004eb0: 2020 2020 696d 706f 7274 206e 756d 7079      import numpy
+00004ec0: 2061 7320 6e70 0a20 2020 2020 2020 6672   as np.       fr
+00004ed0: 6f6d 2070 7967 7063 2e74 6573 7466 756e  om pygpc.testfun
+00004ee0: 6374 696f 6e73 2069 6d70 6f72 7420 706c  ctions import pl
+00004ef0: 6f74 5f74 6573 7466 756e 6374 696f 6e20  ot_testfunction 
+00004f00: 6173 2070 6c6f 740a 2020 2020 2020 2066  as plot.       f
+00004f10: 726f 6d20 636f 6c6c 6563 7469 6f6e 7320  rom collections 
+00004f20: 696d 706f 7274 204f 7264 6572 6564 4469  import OrderedDi
+00004f30: 6374 0a0a 2020 2020 2020 2070 6172 616d  ct..       param
+00004f40: 6574 6572 7320 3d20 4f72 6465 7265 6444  eters = OrderedD
+00004f50: 6963 7428 290a 2020 2020 2020 2070 6172  ict().       par
+00004f60: 616d 6574 6572 735b 2278 3122 5d20 3d20  ameters["x1"] = 
+00004f70: 6e70 2e6c 696e 7370 6163 6528 2d31 2c20  np.linspace(-1, 
+00004f80: 312c 2031 3030 290a 2020 2020 2020 2070  1, 100).       p
+00004f90: 6172 616d 6574 6572 735b 2278 3222 5d20  arameters["x2"] 
+00004fa0: 3d20 6e70 2e6c 696e 7370 6163 6528 2d31  = np.linspace(-1
+00004fb0: 2c20 312c 2031 3030 290a 0a20 2020 2020  , 1, 100)..     
+00004fc0: 2020 636f 6e73 7461 6e74 7320 3d20 4e6f    constants = No
+00004fd0: 6e65 0a0a 2020 2020 2020 2070 6c6f 7428  ne..       plot(
+00004fe0: 2253 756d 4f66 4469 6666 6572 656e 7450  "SumOfDifferentP
+00004ff0: 6f77 6572 7346 756e 6374 696f 6e22 2c20  owersFunction", 
+00005000: 7061 7261 6d65 7465 7273 2c20 636f 6e73  parameters, cons
+00005010: 7461 6e74 732c 2070 6c6f 745f 3364 3d46  tants, plot_3d=F
+00005020: 616c 7365 290a 0a20 2020 202e 2e20 5b31  alse)..    .. [1
+00005030: 5d20 4d6f 6c67 612c 204d 2e2c 2026 2053  ] Molga, M., & S
+00005040: 6d75 746e 6963 6b69 2c20 432e 2054 6573  mutnicki, C. Tes
+00005050: 7420 6675 6e63 7469 6f6e 7320 666f 7220  t functions for 
+00005060: 6f70 7469 6d69 7a61 7469 6f6e 206e 6565  optimization nee
+00005070: 6473 2028 3230 3035 292e 0a20 2020 2020  ds (2005)..     
+00005080: 2020 5265 7472 6965 7665 6420 4a75 6e65    Retrieved June
+00005090: 2032 3031 332c 2066 726f 6d20 6874 7470   2013, from http
+000050a0: 3a2f 2f77 7777 2e7a 7364 2e69 6374 2e70  ://www.zsd.ict.p
+000050b0: 7772 2e77 726f 632e 706c 2f66 696c 6573  wr.wroc.pl/files
+000050c0: 2f64 6f63 732f 6675 6e63 7469 6f6e 732e  /docs/functions.
+000050d0: 7064 662e 0a20 2020 202e 2e20 5b32 5d20  pdf..    .. [2] 
+000050e0: 6874 7470 733a 2f2f 7777 772e 7366 752e  https://www.sfu.
+000050f0: 6361 2f7e 7373 7572 6a61 6e6f 2f73 756d  ca/~ssurjano/sum
+00005100: 706f 772e 6874 6d6c 0a20 2020 2022 2222  pow.html.    """
+00005110: 0a0a 2020 2020 6465 6620 5f5f 696e 6974  ..    def __init
+00005120: 5f5f 2873 656c 662c 206d 6174 6c61 625f  __(self, matlab_
+00005130: 6d6f 6465 6c3d 4661 6c73 6529 3a0a 2020  model=False):.  
+00005140: 2020 2020 2020 7375 7065 7228 7479 7065        super(type
+00005150: 2873 656c 6629 2c20 7365 6c66 292e 5f5f  (self), self).__
+00005160: 696e 6974 5f5f 286d 6174 6c61 625f 6d6f  init__(matlab_mo
+00005170: 6465 6c3d 6d61 746c 6162 5f6d 6f64 656c  del=matlab_model
+00005180: 290a 2020 2020 2020 2020 7365 6c66 2e66  ).        self.f
+00005190: 6e61 6d65 203d 2069 6e73 7065 6374 2e67  name = inspect.g
+000051a0: 6574 6669 6c65 2869 6e73 7065 6374 2e63  etfile(inspect.c
+000051b0: 7572 7265 6e74 6672 616d 6528 2929 0a0a  urrentframe())..
+000051c0: 2020 2020 6465 6620 7661 6c69 6461 7465      def validate
+000051d0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+000051e0: 7061 7373 0a0a 2020 2020 6465 6620 7369  pass..    def si
+000051f0: 6d75 6c61 7465 2873 656c 662c 2070 726f  mulate(self, pro
+00005200: 6365 7373 5f69 643d 4e6f 6e65 2c20 6d61  cess_id=None, ma
+00005210: 746c 6162 5f65 6e67 696e 653d 4e6f 6e65  tlab_engine=None
+00005220: 293a 0a0a 2020 2020 2020 2020 666f 7220  ):..        for 
+00005230: 692c 206b 6579 2069 6e20 656e 756d 6572  i, key in enumer
+00005240: 6174 6528 7365 6c66 2e70 2e6b 6579 7328  ate(self.p.keys(
+00005250: 2929 3a0a 2020 2020 2020 2020 2020 2020  )):.            
+00005260: 6966 2074 7970 6528 7365 6c66 2e70 5b6b  if type(self.p[k
+00005270: 6579 5d29 2069 7320 6e70 2e6e 6461 7272  ey]) is np.ndarr
+00005280: 6179 3a0a 2020 2020 2020 2020 2020 2020  ay:.            
+00005290: 2020 2020 7365 6c66 2e70 5b6b 6579 5d20      self.p[key] 
+000052a0: 3d20 7365 6c66 2e70 5b6b 6579 5d2e 666c  = self.p[key].fl
+000052b0: 6174 7465 6e28 290a 0a20 2020 2020 2020  atten()..       
+000052c0: 2023 2064 6574 6572 6d69 6e65 2073 756d   # determine sum
+000052d0: 0a20 2020 2020 2020 2079 203d 206e 702e  .        y = np.
+000052e0: 7a65 726f 7328 6e70 2e61 7272 6179 2873  zeros(np.array(s
+000052f0: 656c 662e 705b 6c69 7374 2873 656c 662e  elf.p[list(self.
+00005300: 702e 6b65 7973 2829 295b 305d 5d29 2e73  p.keys())[0]]).s
+00005310: 697a 6529 0a20 2020 2020 2020 206b 6579  ize).        key
+00005320: 7320 3d20 6c69 7374 2873 656c 662e 702e  s = list(self.p.
+00005330: 6b65 7973 2829 290a 0a20 2020 2020 2020  keys())..       
+00005340: 2066 6f72 2069 2c20 695f 6b65 7920 696e   for i, i_key in
+00005350: 2065 6e75 6d65 7261 7465 286b 6579 7329   enumerate(keys)
+00005360: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00005370: 2079 202b 3d20 6e70 2e61 6273 2873 656c   y += np.abs(sel
+00005380: 662e 705b 695f 6b65 795d 202a 2a28 692b  f.p[i_key] **(i+
+00005390: 3229 290a 0a20 2020 2020 2020 2079 5f6f  2))..        y_o
+000053a0: 7574 203d 2079 5b3a 2c20 6e70 2e6e 6577  ut = y[:, np.new
+000053b0: 6178 6973 5d0a 0a20 2020 2020 2020 2072  axis]..        r
+000053c0: 6574 7572 6e20 795f 6f75 740a 0a0a 636c  eturn y_out...cl
+000053d0: 6173 7320 5a61 6b68 6172 6f76 4675 6e63  ass ZakharovFunc
+000053e0: 7469 6f6e 2841 6273 7472 6163 744d 6f64  tion(AbstractMod
+000053f0: 656c 293a 0a20 2020 2022 2222 0a20 2020  el):.    """.   
+00005400: 2064 2d64 696d 656e 7369 6f6e 616c 205a   d-dimensional Z
+00005410: 616b 6861 726f 7620 4675 6e63 7469 6f6e  akharov Function
+00005420: 205b 315d 5b32 5d2e 0a20 2020 2054 6865   [1][2]..    The
+00005430: 205a 616b 6861 726f 7620 6675 6e63 7469   Zakharov functi
+00005440: 6f6e 2068 6173 206e 6f20 6c6f 6361 6c20  on has no local 
+00005450: 6d69 6e69 6d61 2065 7863 6570 7420 7468  minima except th
+00005460: 6520 676c 6f62 616c 206f 6e65 2e20 4974  e global one. It
+00005470: 2069 7320 7368 6f77 6e20 6865 7265 2069   is shown here i
+00005480: 6e20 6974 7320 7477 6f2d 6469 6d65 6e73  n its two-dimens
+00005490: 696f 6e61 6c20 666f 726d 2e0a 0a20 2020  ional form...   
+000054a0: 202e 2e20 6d61 7468 3a3a 0a20 2020 2020   .. math::.     
+000054b0: 2020 7920 3d20 5c5c 7375 6d5f 7b69 3d31    y = \\sum_{i=1
+000054c0: 7d5e 7b64 7d20 785f 695e 322b 5c5c 6c65  }^{d} x_i^2+\\le
+000054d0: 6674 285c 5c73 756d 5f7b 692b 317d 5e7b  ft(\\sum_{i+1}^{
+000054e0: 647d 302e 3569 785f 695c 5c72 6967 6874  d}0.5ix_i\\right
+000054f0: 295e 322b 5c5c 6c65 6674 285c 5c73 756d  )^2+\\left(\\sum
+00005500: 5f7b 692b 317d 5e64 302e 3569 785f 695c  _{i+1}^d0.5ix_i\
+00005510: 5c72 6967 6874 295e 340a 0a20 2020 2050  \right)^4..    P
+00005520: 6172 616d 6574 6572 730a 2020 2020 2d2d  arameters.    --
+00005530: 2d2d 2d2d 2d2d 2d2d 0a20 2020 2070 5b22  --------.    p["
+00005540: 7831 225d 3a20 666c 6f61 7420 6f72 206e  x1"]: float or n
+00005550: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+00005560: 5b6e 5f67 7269 645d 0a20 2020 2020 2020  [n_grid].       
+00005570: 2046 6972 7374 2070 6172 616d 6574 6572   First parameter
+00005580: 2064 6566 696e 6564 2069 6e20 5b2d 352c   defined in [-5,
+00005590: 2031 305d 0a20 2020 2070 5b22 7869 225d   10].    p["xi"]
+000055a0: 3a20 666c 6f61 7420 6f72 206e 6461 7272  : float or ndarr
+000055b0: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
+000055c0: 7269 645d 0a20 2020 2020 2020 2069 2d74  rid].        i-t
+000055d0: 6820 7061 7261 6d65 7465 7220 6465 6669  h parameter defi
+000055e0: 6e65 6420 696e 205b 2d35 2c20 3130 5d0a  ned in [-5, 10].
+000055f0: 0a20 2020 2052 6574 7572 6e73 0a20 2020  .    Returns.   
+00005600: 202d 2d2d 2d2d 2d2d 0a20 2020 2079 3a20   -------.    y: 
+00005610: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
+00005620: 205b 6e5f 6772 6964 2078 2031 5d0a 2020   [n_grid x 1].  
+00005630: 2020 2020 2020 4f75 7470 7574 0a0a 2020        Output..  
+00005640: 2020 4e6f 7465 730a 2020 2020 2d2d 2d2d    Notes.    ----
+00005650: 2d0a 2020 2020 2e2e 2070 6c6f 743a 3a0a  -.    .. plot::.
+00005660: 0a20 2020 2020 2020 696d 706f 7274 206e  .       import n
+00005670: 756d 7079 2061 7320 6e70 0a20 2020 2020  umpy as np.     
+00005680: 2020 6672 6f6d 2070 7967 7063 2e74 6573    from pygpc.tes
+00005690: 7466 756e 6374 696f 6e73 2069 6d70 6f72  tfunctions impor
+000056a0: 7420 706c 6f74 5f74 6573 7466 756e 6374  t plot_testfunct
+000056b0: 696f 6e20 6173 2070 6c6f 740a 2020 2020  ion as plot.    
+000056c0: 2020 2066 726f 6d20 636f 6c6c 6563 7469     from collecti
+000056d0: 6f6e 7320 696d 706f 7274 204f 7264 6572  ons import Order
+000056e0: 6564 4469 6374 0a0a 2020 2020 2020 2070  edDict..       p
+000056f0: 6172 616d 6574 6572 7320 3d20 4f72 6465  arameters = Orde
+00005700: 7265 6444 6963 7428 290a 2020 2020 2020  redDict().      
+00005710: 2070 6172 616d 6574 6572 735b 2278 3122   parameters["x1"
+00005720: 5d20 3d20 6e70 2e6c 696e 7370 6163 6528  ] = np.linspace(
+00005730: 2d35 2c20 3130 2c20 3130 3029 0a20 2020  -5, 10, 100).   
+00005740: 2020 2020 7061 7261 6d65 7465 7273 5b22      parameters["
+00005750: 7869 225d 203d 206e 702e 6c69 6e73 7061  xi"] = np.linspa
+00005760: 6365 282d 352c 2031 302c 2031 3030 290a  ce(-5, 10, 100).
+00005770: 0a20 2020 2020 2020 636f 6e73 7461 6e74  .       constant
+00005780: 7320 3d20 4e6f 6e65 0a0a 2020 2020 2020  s = None..      
+00005790: 2070 6c6f 7428 225a 616b 6861 726f 7646   plot("ZakharovF
+000057a0: 756e 6374 696f 6e22 2c20 7061 7261 6d65  unction", parame
+000057b0: 7465 7273 2c20 636f 6e73 7461 6e74 732c  ters, constants,
+000057c0: 2070 6c6f 745f 3364 3d46 616c 7365 290a   plot_3d=False).
+000057d0: 0a20 2020 202e 2e20 5b31 5d20 476c 6f62  .    .. [1] Glob
+000057e0: 616c 204f 7074 696d 697a 6174 696f 6e20  al Optimization 
+000057f0: 5465 7374 2050 726f 626c 656d 732e 2052  Test Problems. R
+00005800: 6574 7269 6576 6564 204a 756e 6520 3230  etrieved June 20
+00005810: 3133 2c20 6672 6f6d 0a20 2020 2020 2020  13, from.       
+00005820: 6874 7470 3a2f 2f77 7777 2d6f 7074 696d  http://www-optim
+00005830: 612e 616d 702e 692e 6b79 6f74 6f2d 752e  a.amp.i.kyoto-u.
+00005840: 6163 2e6a 702f 6d65 6d62 6572 2f73 7475  ac.jp/member/stu
+00005850: 6465 6e74 2f68 6564 6172 2f48 6564 6172  dent/hedar/Hedar
+00005860: 5f66 696c 6573 2f54 6573 7447 4f2e 6874  _files/TestGO.ht
+00005870: 6d2e 0a0a 2020 2020 2e2e 205b 325d 2068  m...    .. [2] h
+00005880: 7474 7073 3a2f 2f77 7777 2e73 6675 2e63  ttps://www.sfu.c
+00005890: 612f 7e73 7375 726a 616e 6f2f 7a61 6b68  a/~ssurjano/zakh
+000058a0: 6172 6f76 2e68 746d 6c0a 0a20 2020 2022  arov.html..    "
+000058b0: 2222 0a0a 2020 2020 6465 6620 5f5f 696e  ""..    def __in
+000058c0: 6974 5f5f 2873 656c 662c 206d 6174 6c61  it__(self, matla
+000058d0: 625f 6d6f 6465 6c3d 4661 6c73 6529 3a0a  b_model=False):.
+000058e0: 2020 2020 2020 2020 7375 7065 7228 7479          super(ty
+000058f0: 7065 2873 656c 6629 2c20 7365 6c66 292e  pe(self), self).
+00005900: 5f5f 696e 6974 5f5f 286d 6174 6c61 625f  __init__(matlab_
+00005910: 6d6f 6465 6c3d 6d61 746c 6162 5f6d 6f64  model=matlab_mod
+00005920: 656c 290a 2020 2020 2020 2020 7365 6c66  el).        self
+00005930: 2e66 6e61 6d65 203d 2069 6e73 7065 6374  .fname = inspect
+00005940: 2e67 6574 6669 6c65 2869 6e73 7065 6374  .getfile(inspect
+00005950: 2e63 7572 7265 6e74 6672 616d 6528 2929  .currentframe())
+00005960: 0a0a 2020 2020 6465 6620 7661 6c69 6461  ..    def valida
+00005970: 7465 2873 656c 6629 3a0a 2020 2020 2020  te(self):.      
+00005980: 2020 7061 7373 0a0a 2020 2020 6465 6620    pass..    def 
+00005990: 7369 6d75 6c61 7465 2873 656c 662c 2070  simulate(self, p
+000059a0: 726f 6365 7373 5f69 643d 4e6f 6e65 2c20  rocess_id=None, 
+000059b0: 6d61 746c 6162 5f65 6e67 696e 653d 4e6f  matlab_engine=No
+000059c0: 6e65 293a 0a0a 2020 2020 2020 2020 666f  ne):..        fo
+000059d0: 7220 692c 206b 6579 2069 6e20 656e 756d  r i, key in enum
+000059e0: 6572 6174 6528 7365 6c66 2e70 2e6b 6579  erate(self.p.key
+000059f0: 7328 2929 3a0a 2020 2020 2020 2020 2020  s()):.          
+00005a00: 2020 6966 2074 7970 6528 7365 6c66 2e70    if type(self.p
+00005a10: 5b6b 6579 5d29 2069 7320 6e70 2e6e 6461  [key]) is np.nda
+00005a20: 7272 6179 3a0a 2020 2020 2020 2020 2020  rray:.          
+00005a30: 2020 2020 2073 656c 662e 705b 6b65 795d       self.p[key]
+00005a40: 203d 2073 656c 662e 705b 6b65 795d 2e66   = self.p[key].f
+00005a50: 6c61 7474 656e 2829 0a0a 2020 2020 2020  latten()..      
+00005a60: 2020 2320 6465 7465 726d 696e 6520 7375    # determine su
+00005a70: 6d0a 2020 2020 2020 2020 7331 203d 206e  m.        s1 = n
+00005a80: 702e 7a65 726f 7328 6e70 2e61 7272 6179  p.zeros(np.array
+00005a90: 2873 656c 662e 705b 6c69 7374 2873 656c  (self.p[list(sel
+00005aa0: 662e 702e 6b65 7973 2829 295b 305d 5d29  f.p.keys())[0]])
+00005ab0: 2e73 697a 6529 0a20 2020 2020 2020 2073  .size).        s
+00005ac0: 3220 3d20 6e70 2e7a 6572 6f73 286e 702e  2 = np.zeros(np.
+00005ad0: 6172 7261 7928 7365 6c66 2e70 5b6c 6973  array(self.p[lis
+00005ae0: 7428 7365 6c66 2e70 2e6b 6579 7328 2929  t(self.p.keys())
+00005af0: 5b30 5d5d 292e 7369 7a65 290a 2020 2020  [0]]).size).    
+00005b00: 2020 2020 7920 3d20 6e70 2e7a 6572 6f73      y = np.zeros
+00005b10: 286e 702e 6172 7261 7928 7365 6c66 2e70  (np.array(self.p
+00005b20: 5b6c 6973 7428 7365 6c66 2e70 2e6b 6579  [list(self.p.key
+00005b30: 7328 2929 5b30 5d5d 292e 7369 7a65 290a  s())[0]]).size).
+00005b40: 2020 2020 2020 2020 6b65 7973 203d 206c          keys = l
+00005b50: 6973 7428 7365 6c66 2e70 2e6b 6579 7328  ist(self.p.keys(
+00005b60: 2929 0a0a 2020 2020 2020 2020 666f 7220  ))..        for 
+00005b70: 692c 206b 6579 2069 6e20 656e 756d 6572  i, key in enumer
+00005b80: 6174 6528 6b65 7973 293a 0a20 2020 2020  ate(keys):.     
+00005b90: 2020 2020 2020 2073 3120 2b3d 2028 7365         s1 += (se
+00005ba0: 6c66 2e70 5b6b 6579 5d20 2a2a 2032 290a  lf.p[key] ** 2).
+00005bb0: 2020 2020 2020 2020 2020 2020 7332 202b              s2 +
+00005bc0: 3d20 302e 3520 2a20 2869 2b31 2920 2a20  = 0.5 * (i+1) * 
+00005bd0: 7365 6c66 2e70 5b6b 6579 5d0a 0a20 2020  self.p[key]..   
+00005be0: 2020 2020 2023 2064 6574 6572 6d69 6e65       # determine
+00005bf0: 206f 7574 7075 740a 2020 2020 2020 2020   output.        
+00005c00: 7920 3d20 7331 202b 2073 3220 2a2a 2032  y = s1 + s2 ** 2
+00005c10: 202b 2073 3220 2a2a 2034 0a0a 2020 2020   + s2 ** 4..    
+00005c20: 2020 2020 795f 6f75 7420 3d20 795b 3a2c      y_out = y[:,
+00005c30: 206e 702e 6e65 7761 7869 735d 0a0a 2020   np.newaxis]..  
+00005c40: 2020 2020 2020 7265 7475 726e 2079 5f6f        return y_o
+00005c50: 7574 0a0a 0a63 6c61 7373 2044 726f 7057  ut...class DropW
+00005c60: 6176 6546 756e 6374 696f 6e28 4162 7374  aveFunction(Abst
+00005c70: 7261 6374 4d6f 6465 6c29 3a0a 2020 2020  ractModel):.    
+00005c80: 2222 220a 2020 2020 322d 6469 6d65 6e73  """.    2-dimens
+00005c90: 696f 6e61 6c20 4472 6f70 5761 7665 4675  ional DropWaveFu
+00005ca0: 6e63 7469 6f6e 205b 315d 5b32 5d2e 0a20  nction [1][2].. 
+00005cb0: 2020 2054 6865 2044 726f 702d 5761 7665     The Drop-Wave
+00005cc0: 2066 756e 6374 696f 6e20 6973 206d 756c   function is mul
+00005cd0: 7469 6d6f 6461 6c20 616e 6420 6869 6768  timodal and high
+00005ce0: 6c79 2063 6f6d 706c 6578 2e0a 2020 2020  ly complex..    
+00005cf0: 5468 6520 7365 636f 6e64 2070 6c6f 7420  The second plot 
+00005d00: 6162 6f76 6520 7368 6f77 7320 7468 6520  above shows the 
+00005d10: 6675 6e63 7469 6f6e 206f 6e20 6120 736d  function on a sm
+00005d20: 616c 6c65 7220 696e 7075 7420 646f 6d61  aller input doma
+00005d30: 696e 2c20 746f 2069 6c6c 7573 7472 6174  in, to illustrat
+00005d40: 6520 6974 7320 6368 6172 6163 7465 7269  e its characteri
+00005d50: 7374 6963 2066 6561 7475 7265 732e 0a0a  stic features...
+00005d60: 2020 2020 2e2e 206d 6174 683a 3a0a 2020      .. math::.  
+00005d70: 2020 2020 7920 3d20 2d5c 5c66 7261 637b      y = -\\frac{
+00005d80: 312b 5c5c 636f 735c 5c6c 6566 7428 3132  1+\\cos\\left(12
+00005d90: 5c5c 7371 7274 7b78 5f31 5e32 2b78 5f32  \\sqrt{x_1^2+x_2
+00005da0: 5e32 7d5c 5c72 6967 6874 297d 7b30 2e35  ^2}\\right)}{0.5
+00005db0: 2878 5f31 5e32 2b78 5f32 5e32 292b 327d  (x_1^2+x_2^2)+2}
+00005dc0: 0a0a 2020 2020 5061 7261 6d65 7465 7273  ..    Parameters
+00005dd0: 0a20 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0a  .    ----------.
+00005de0: 2020 2020 705b 2278 3122 5d3a 2066 6c6f      p["x1"]: flo
+00005df0: 6174 206f 7220 6e64 6172 7261 7920 6f66  at or ndarray of
+00005e00: 2066 6c6f 6174 205b 6e5f 6772 6964 5d0a   float [n_grid].
+00005e10: 2020 2020 2020 2020 4669 7273 7420 7061          First pa
+00005e20: 7261 6d65 7465 7220 6465 6669 6e65 6420  rameter defined 
+00005e30: 696e 205b 2d35 2e31 322c 2035 2e31 325d  in [-5.12, 5.12]
+00005e40: 0a20 2020 2070 5b22 7832 225d 3a20 666c  .    p["x2"]: fl
+00005e50: 6f61 7420 6f72 206e 6461 7272 6179 206f  oat or ndarray o
+00005e60: 6620 666c 6f61 7420 5b6e 5f67 7269 645d  f float [n_grid]
+00005e70: 0a20 2020 2020 2020 2073 6563 6f6e 6420  .        second 
+00005e80: 7061 7261 6d65 7465 7220 6465 6669 6e65  parameter define
+00005e90: 6420 696e 205b 2d35 2e31 322c 2035 2e31  d in [-5.12, 5.1
+00005ea0: 325d 0a0a 2020 2020 5265 7475 726e 730a  2]..    Returns.
+00005eb0: 2020 2020 2d2d 2d2d 2d2d 2d0a 2020 2020      -------.    
+00005ec0: 793a 206e 6461 7272 6179 206f 6620 666c  y: ndarray of fl
+00005ed0: 6f61 7420 5b6e 5f67 7269 6420 7820 315d  oat [n_grid x 1]
+00005ee0: 0a20 2020 2020 2020 204f 7574 7075 740a  .        Output.
+00005ef0: 0a20 2020 204e 6f74 6573 0a20 2020 202d  .    Notes.    -
+00005f00: 2d2d 2d2d 0a20 2020 202e 2e20 706c 6f74  ----.    .. plot
+00005f10: 3a3a 0a0a 2020 2020 2020 2069 6d70 6f72  ::..       impor
+00005f20: 7420 6e75 6d70 7920 6173 206e 700a 2020  t numpy as np.  
+00005f30: 2020 2020 2066 726f 6d20 7079 6770 632e       from pygpc.
+00005f40: 7465 7374 6675 6e63 7469 6f6e 7320 696d  testfunctions im
+00005f50: 706f 7274 2070 6c6f 745f 7465 7374 6675  port plot_testfu
+00005f60: 6e63 7469 6f6e 2061 7320 706c 6f74 0a20  nction as plot. 
+00005f70: 2020 2020 2020 6672 6f6d 2063 6f6c 6c65        from colle
+00005f80: 6374 696f 6e73 2069 6d70 6f72 7420 4f72  ctions import Or
+00005f90: 6465 7265 6444 6963 740a 0a20 2020 2020  deredDict..     
+00005fa0: 2020 7061 7261 6d65 7465 7273 203d 204f    parameters = O
+00005fb0: 7264 6572 6564 4469 6374 2829 0a20 2020  rderedDict().   
+00005fc0: 2020 2020 7061 7261 6d65 7465 7273 5b22      parameters["
+00005fd0: 7831 225d 203d 206e 702e 6c69 6e73 7061  x1"] = np.linspa
+00005fe0: 6365 282d 352e 3132 2c20 352e 3132 2c20  ce(-5.12, 5.12, 
+00005ff0: 3130 3029 0a20 2020 2020 2020 7061 7261  100).       para
+00006000: 6d65 7465 7273 5b22 7832 225d 203d 206e  meters["x2"] = n
+00006010: 702e 6c69 6e73 7061 6365 282d 352e 3132  p.linspace(-5.12
+00006020: 2c20 352e 3132 2c20 3130 3029 0a0a 2020  , 5.12, 100)..  
+00006030: 2020 2020 2063 6f6e 7374 616e 7473 203d       constants =
+00006040: 204e 6f6e 650a 0a20 2020 2020 2020 706c   None..       pl
+00006050: 6f74 2822 4472 6f70 5761 7665 4675 6e63  ot("DropWaveFunc
+00006060: 7469 6f6e 222c 2070 6172 616d 6574 6572  tion", parameter
+00006070: 732c 2063 6f6e 7374 616e 7473 2c20 706c  s, constants, pl
+00006080: 6f74 5f33 643d 4661 6c73 6529 0a0a 2020  ot_3d=False)..  
+00006090: 2020 2e2e 205b 315d 2047 6c6f 6261 6c20    .. [1] Global 
+000060a0: 4f70 7469 6d69 7a61 7469 6f6e 2054 6573  Optimization Tes
+000060b0: 7420 4675 6e63 7469 6f6e 7320 496e 6465  t Functions Inde
+000060c0: 782e 0a20 2020 2020 2020 5265 7472 6965  x..       Retrie
+000060d0: 7665 6420 4a75 6e65 2032 3031 332c 2066  ved June 2013, f
+000060e0: 726f 6d20 6874 7470 3a2f 2f69 6e66 696e  rom http://infin
+000060f0: 6974 7937 372e 6e65 742f 676c 6f62 616c  ity77.net/global
+00006100: 5f6f 7074 696d 697a 6174 696f 6e2f 7465  _optimization/te
+00006110: 7374 5f66 756e 6374 696f 6e73 2e68 746d  st_functions.htm
+00006120: 6c23 7465 7374 2d66 756e 6374 696f 6e73  l#test-functions
+00006130: 2d69 6e64 6578 2e0a 0a20 2020 202e 2e20  -index...    .. 
+00006140: 5b32 5d20 6874 7470 733a 2f2f 7777 772e  [2] https://www.
+00006150: 7366 752e 6361 2f7e 7373 7572 6a61 6e6f  sfu.ca/~ssurjano
+00006160: 2f64 726f 702e 6874 6d6c 0a20 2020 2022  /drop.html.    "
+00006170: 2222 0a0a 2020 2020 6465 6620 5f5f 696e  ""..    def __in
+00006180: 6974 5f5f 2873 656c 662c 206d 6174 6c61  it__(self, matla
+00006190: 625f 6d6f 6465 6c3d 4661 6c73 6529 3a0a  b_model=False):.
+000061a0: 2020 2020 2020 2020 7375 7065 7228 7479          super(ty
+000061b0: 7065 2873 656c 6629 2c20 7365 6c66 292e  pe(self), self).
+000061c0: 5f5f 696e 6974 5f5f 286d 6174 6c61 625f  __init__(matlab_
+000061d0: 6d6f 6465 6c3d 6d61 746c 6162 5f6d 6f64  model=matlab_mod
+000061e0: 656c 290a 2020 2020 2020 2020 7365 6c66  el).        self
+000061f0: 2e66 6e61 6d65 203d 2069 6e73 7065 6374  .fname = inspect
+00006200: 2e67 6574 6669 6c65 2869 6e73 7065 6374  .getfile(inspect
+00006210: 2e63 7572 7265 6e74 6672 616d 6528 2929  .currentframe())
+00006220: 0a0a 2020 2020 6465 6620 7661 6c69 6461  ..    def valida
+00006230: 7465 2873 656c 6629 3a0a 2020 2020 2020  te(self):.      
+00006240: 2020 7061 7373 0a0a 2020 2020 6465 6620    pass..    def 
+00006250: 7369 6d75 6c61 7465 2873 656c 662c 2070  simulate(self, p
+00006260: 726f 6365 7373 5f69 643d 4e6f 6e65 2c20  rocess_id=None, 
+00006270: 6d61 746c 6162 5f65 6e67 696e 653d 4e6f  matlab_engine=No
+00006280: 6e65 293a 0a0a 2020 2020 2020 2020 7920  ne):..        y 
+00006290: 3d20 2d20 2831 202b 206e 702e 636f 7328  = - (1 + np.cos(
+000062a0: 3132 202a 206e 702e 7371 7274 2873 656c  12 * np.sqrt(sel
+000062b0: 662e 705b 2278 3122 5d20 2a2a 2032 202b  f.p["x1"] ** 2 +
+000062c0: 2073 656c 662e 705b 2278 3222 5d20 2a2a   self.p["x2"] **
+000062d0: 2032 2929 2920 5c0a 2020 2020 2020 2020   2))) \.        
+000062e0: 2020 2020 2f20 2830 2e35 202a 2028 7365      / (0.5 * (se
+000062f0: 6c66 2e70 5b22 7831 225d 202a 2a20 3220  lf.p["x1"] ** 2 
+00006300: 2b20 7365 6c66 2e70 5b22 7832 225d 202a  + self.p["x2"] *
+00006310: 2a20 3229 202b 2032 290a 0a20 2020 2020  * 2) + 2)..     
+00006320: 2020 2079 5f6f 7574 203d 2079 5b3a 2c20     y_out = y[:, 
+00006330: 6e70 2e6e 6577 6178 6973 5d0a 0a20 2020  np.newaxis]..   
+00006340: 2020 2020 2072 6574 7572 6e20 795f 6f75       return y_ou
+00006350: 740a 0a0a 636c 6173 7320 4469 786f 6e50  t...class DixonP
+00006360: 7269 6365 4675 6e63 7469 6f6e 2841 6273  riceFunction(Abs
+00006370: 7472 6163 744d 6f64 656c 293a 0a20 2020  tractModel):.   
+00006380: 2022 2222 0a20 2020 2064 2d64 696d 656e   """.    d-dimen
+00006390: 7369 6f6e 616c 2044 6978 6f6e 2d50 7269  sional Dixon-Pri
+000063a0: 6365 2046 756e 6374 696f 6e20 5b31 5d5b  ce Function [1][
+000063b0: 325d 2e0a 0a20 2020 202e 2e20 6d61 7468  2]...    .. math
+000063c0: 3a3a 0a20 2020 2020 2079 203d 2028 785f  ::.      y = (x_
+000063d0: 312d 3129 5e32 2b5c 5c73 756d 5f7b 693d  1-1)^2+\\sum_{i=
+000063e0: 647d 5e7b 327d 2832 785f 7b69 7d5e 7b32  d}^{2}(2x_{i}^{2
+000063f0: 7d2d 785f 7b69 2d31 7d29 5e32 0a0a 2020  }-x_{i-1})^2..  
+00006400: 2020 5061 7261 6d65 7465 7273 0a20 2020    Parameters.   
+00006410: 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020 2020   ----------.    
+00006420: 705b 2278 3122 5d3a 2066 6c6f 6174 206f  p["x1"]: float o
+00006430: 7220 6e64 6172 7261 7920 6f66 2066 6c6f  r ndarray of flo
+00006440: 6174 205b 6e5f 6772 6964 5d0a 2020 2020  at [n_grid].    
+00006450: 2020 2020 4669 7273 7420 7061 7261 6d65      First parame
+00006460: 7465 7220 6465 6669 6e65 6420 696e 205b  ter defined in [
+00006470: 2d31 302c 2031 305d 0a20 2020 2070 5b22  -10, 10].    p["
+00006480: 7869 225d 3a20 666c 6f61 7420 6f72 206e  xi"]: float or n
+00006490: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+000064a0: 5b6e 5f67 7269 645d 0a20 2020 2020 2020  [n_grid].       
+000064b0: 2069 2d74 6820 7061 7261 6d65 7465 7220   i-th parameter 
+000064c0: 6465 6669 6e65 6420 696e 205b 2d31 302c  defined in [-10,
+000064d0: 2031 305d 0a0a 2020 2020 5265 7475 726e   10]..    Return
+000064e0: 730a 2020 2020 2d2d 2d2d 2d2d 2d0a 2020  s.    -------.  
+000064f0: 2020 793a 206e 6461 7272 6179 206f 6620    y: ndarray of 
+00006500: 666c 6f61 7420 5b6e 5f67 7269 6420 7820  float [n_grid x 
+00006510: 315d 0a20 2020 2020 2020 204f 7574 7075  1].        Outpu
+00006520: 740a 0a20 2020 204e 6f74 6573 0a20 2020  t..    Notes.   
+00006530: 202d 2d2d 2d2d 0a20 2020 202e 2e20 706c   -----.    .. pl
+00006540: 6f74 3a3a 0a0a 2020 2020 2020 2069 6d70  ot::..       imp
+00006550: 6f72 7420 6e75 6d70 7920 6173 206e 700a  ort numpy as np.
+00006560: 2020 2020 2020 2066 726f 6d20 7079 6770         from pygp
+00006570: 632e 7465 7374 6675 6e63 7469 6f6e 7320  c.testfunctions 
+00006580: 696d 706f 7274 2070 6c6f 745f 7465 7374  import plot_test
+00006590: 6675 6e63 7469 6f6e 2061 7320 706c 6f74  function as plot
+000065a0: 0a20 2020 2020 2020 6672 6f6d 2063 6f6c  .       from col
+000065b0: 6c65 6374 696f 6e73 2069 6d70 6f72 7420  lections import 
+000065c0: 4f72 6465 7265 6444 6963 740a 0a20 2020  OrderedDict..   
+000065d0: 2020 2020 7061 7261 6d65 7465 7273 203d      parameters =
+000065e0: 204f 7264 6572 6564 4469 6374 2829 0a20   OrderedDict(). 
+000065f0: 2020 2020 2020 7061 7261 6d65 7465 7273        parameters
+00006600: 5b22 7831 225d 203d 206e 702e 6c69 6e73  ["x1"] = np.lins
+00006610: 7061 6365 282d 3130 2c20 3130 2c20 3130  pace(-10, 10, 10
+00006620: 3029 0a20 2020 2020 2020 7061 7261 6d65  0).       parame
+00006630: 7465 7273 5b22 7832 225d 203d 206e 702e  ters["x2"] = np.
+00006640: 6c69 6e73 7061 6365 282d 3130 2c20 3130  linspace(-10, 10
+00006650: 2c20 3130 3029 0a0a 2020 2020 2020 2063  , 100)..       c
+00006660: 6f6e 7374 616e 7473 203d 204e 6f6e 650a  onstants = None.
+00006670: 0a20 2020 2020 2020 706c 6f74 2822 4469  .       plot("Di
+00006680: 786f 6e50 7269 6365 4675 6e63 7469 6f6e  xonPriceFunction
+00006690: 2022 2c20 7061 7261 6d65 7465 7273 2c20   ", parameters, 
+000066a0: 636f 6e73 7461 6e74 732c 2070 6c6f 745f  constants, plot_
+000066b0: 3364 3d46 616c 7365 290a 0a20 2020 202e  3d=False)..    .
+000066c0: 2e20 5b31 5d20 476c 6f62 616c 204f 7074  . [1] Global Opt
+000066d0: 696d 697a 6174 696f 6e20 5465 7374 2046  imization Test F
+000066e0: 756e 6374 696f 6e73 2049 6e64 6578 2e0a  unctions Index..
+000066f0: 2020 2020 2020 2052 6574 7269 6576 6564         Retrieved
+00006700: 204a 756e 6520 3230 3133 2c20 6672 6f6d   June 2013, from
+00006710: 2068 7474 703a 2f2f 696e 6669 6e69 7479   http://infinity
+00006720: 3737 2e6e 6574 2f67 6c6f 6261 6c5f 6f70  77.net/global_op
+00006730: 7469 6d69 7a61 7469 6f6e 2f74 6573 745f  timization/test_
+00006740: 6675 6e63 7469 6f6e 732e 6874 6d6c 2374  functions.html#t
+00006750: 6573 742d 6675 6e63 7469 6f6e 732d 696e  est-functions-in
+00006760: 6465 782e 0a0a 2020 2020 2e2e 205b 325d  dex...    .. [2]
+00006770: 2068 7474 7073 3a2f 2f77 7777 2e73 6675   https://www.sfu
+00006780: 2e63 612f 7e73 7375 726a 616e 6f2f 6469  .ca/~ssurjano/di
+00006790: 786f 6e70 722e 6874 6d6c 0a0a 2020 2020  xonpr.html..    
+000067a0: 2222 220a 0a20 2020 2064 6566 205f 5f69  """..    def __i
+000067b0: 6e69 745f 5f28 7365 6c66 2c20 6d61 746c  nit__(self, matl
+000067c0: 6162 5f6d 6f64 656c 3d46 616c 7365 293a  ab_model=False):
+000067d0: 0a20 2020 2020 2020 2073 7570 6572 2874  .        super(t
+000067e0: 7970 6528 7365 6c66 292c 2073 656c 6629  ype(self), self)
+000067f0: 2e5f 5f69 6e69 745f 5f28 6d61 746c 6162  .__init__(matlab
+00006800: 5f6d 6f64 656c 3d6d 6174 6c61 625f 6d6f  _model=matlab_mo
+00006810: 6465 6c29 0a20 2020 2020 2020 2073 656c  del).        sel
+00006820: 662e 666e 616d 6520 3d20 696e 7370 6563  f.fname = inspec
+00006830: 742e 6765 7466 696c 6528 696e 7370 6563  t.getfile(inspec
+00006840: 742e 6375 7272 656e 7466 7261 6d65 2829  t.currentframe()
+00006850: 290a 0a20 2020 2064 6566 2076 616c 6964  )..    def valid
+00006860: 6174 6528 7365 6c66 293a 0a20 2020 2020  ate(self):.     
+00006870: 2020 2070 6173 730a 0a20 2020 2064 6566     pass..    def
+00006880: 2073 696d 756c 6174 6528 7365 6c66 2c20   simulate(self, 
+00006890: 7072 6f63 6573 735f 6964 3d4e 6f6e 652c  process_id=None,
+000068a0: 206d 6174 6c61 625f 656e 6769 6e65 3d4e   matlab_engine=N
+000068b0: 6f6e 6529 3a0a 0a20 2020 2020 2020 2066  one):..        f
+000068c0: 6f72 2069 2c20 6b65 7920 696e 2065 6e75  or i, key in enu
+000068d0: 6d65 7261 7465 2873 656c 662e 702e 6b65  merate(self.p.ke
+000068e0: 7973 2829 293a 0a20 2020 2020 2020 2020  ys()):.         
+000068f0: 2020 2069 6620 7479 7065 2873 656c 662e     if type(self.
+00006900: 705b 6b65 795d 2920 6973 206e 702e 6e64  p[key]) is np.nd
+00006910: 6172 7261 793a 0a20 2020 2020 2020 2020  array:.         
+00006920: 2020 2020 2020 7365 6c66 2e70 5b6b 6579        self.p[key
+00006930: 5d20 3d20 7365 6c66 2e70 5b6b 6579 5d2e  ] = self.p[key].
+00006940: 666c 6174 7465 6e28 290a 0a20 2020 2020  flatten()..     
+00006950: 2020 2073 3120 3d20 6e70 2e7a 6572 6f73     s1 = np.zeros
+00006960: 286e 702e 6172 7261 7928 7365 6c66 2e70  (np.array(self.p
+00006970: 5b6c 6973 7428 7365 6c66 2e70 2e6b 6579  [list(self.p.key
+00006980: 7328 2929 5b30 5d5d 292e 7369 7a65 290a  s())[0]]).size).
+00006990: 2020 2020 2020 2020 6b65 7973 203d 206c          keys = l
+000069a0: 6973 7428 7365 6c66 2e70 2e6b 6579 7328  ist(self.p.keys(
+000069b0: 2929 0a0a 2020 2020 2020 2020 666f 7220  ))..        for 
+000069c0: 692c 206b 6579 2069 6e20 656e 756d 6572  i, key in enumer
+000069d0: 6174 6528 6b65 7973 5b31 3a5d 293a 0a20  ate(keys[1:]):. 
+000069e0: 2020 2020 2020 2020 2020 2073 3120 2b3d             s1 +=
+000069f0: 2028 692b 3229 202a 2028 3220 2a20 7365   (i+2) * (2 * se
+00006a00: 6c66 2e70 5b6b 6579 5d20 2a2a 2032 202d  lf.p[key] ** 2 -
+00006a10: 2073 656c 662e 705b 6b65 7973 5b69 5d5d   self.p[keys[i]]
+00006a20: 2920 2a2a 2032 0a0a 2020 2020 2020 2020  ) ** 2..        
+00006a30: 2320 6465 7465 726d 696e 6520 6f75 7470  # determine outp
+00006a40: 7574 0a20 2020 2020 2020 2079 203d 2028  ut.        y = (
+00006a50: 7365 6c66 2e70 5b6b 6579 735b 305d 5d20  self.p[keys[0]] 
+00006a60: 2d20 3129 202a 2a20 3220 2b20 7331 0a0a  - 1) ** 2 + s1..
+00006a70: 2020 2020 2020 2020 795f 6f75 7420 3d20          y_out = 
+00006a80: 795b 3a2c 206e 702e 6e65 7761 7869 735d  y[:, np.newaxis]
+00006a90: 0a0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+00006aa0: 2079 5f6f 7574 0a0a 0a63 6c61 7373 2052   y_out...class R
+00006ab0: 6f73 656e 6272 6f63 6b46 756e 6374 696f  osenbrockFunctio
+00006ac0: 6e28 4162 7374 7261 6374 4d6f 6465 6c29  n(AbstractModel)
+00006ad0: 3a0a 2020 2020 2222 220a 2020 2020 642d  :.    """.    d-
+00006ae0: 6469 6d65 6e73 696f 6e61 6c20 526f 7365  dimensional Rose
+00006af0: 6e62 726f 636b 2046 756e 6374 696f 6e20  nbrock Function 
+00006b00: 5b31 5d5b 325d 5b33 5d5b 345d 5b35 5d2e  [1][2][3][4][5].
+00006b10: 0a20 2020 2054 6865 2052 6f73 656e 6272  .    The Rosenbr
+00006b20: 6f63 6b20 6675 6e63 7469 6f6e 2c20 616c  ock function, al
+00006b30: 736f 2072 6566 6572 7265 6420 746f 2061  so referred to a
+00006b40: 7320 7468 6520 5661 6c6c 6579 206f 7220  s the Valley or 
+00006b50: 4261 6e61 6e61 2066 756e 6374 696f 6e2c  Banana function,
+00006b60: 0a20 2020 2069 7320 6120 706f 7075 6c61  .    is a popula
+00006b70: 7220 7465 7374 2070 726f 626c 656d 2066  r test problem f
+00006b80: 6f72 2067 7261 6469 656e 742d 6261 7365  or gradient-base
+00006b90: 6420 6f70 7469 6d69 7a61 7469 6f6e 2061  d optimization a
+00006ba0: 6c67 6f72 6974 686d 732e 0a20 2020 2049  lgorithms..    I
+00006bb0: 7420 6973 2073 686f 776e 2069 6e20 7468  t is shown in th
+00006bc0: 6520 706c 6f74 2061 626f 7665 2069 6e20  e plot above in 
+00006bd0: 6974 7320 7477 6f2d 6469 6d65 6e73 696f  its two-dimensio
+00006be0: 6e61 6c20 666f 726d 2e0a 2020 2020 5468  nal form..    Th
+00006bf0: 6520 6675 6e63 7469 6f6e 2069 7320 756e  e function is un
+00006c00: 696d 6f64 616c 2c20 616e 6420 7468 6520  imodal, and the 
+00006c10: 676c 6f62 616c 206d 696e 696d 756d 206c  global minimum l
+00006c20: 6965 7320 696e 2061 206e 6172 726f 772c  ies in a narrow,
+00006c30: 2070 6172 6162 6f6c 6963 2076 616c 6c65   parabolic valle
+00006c40: 792e 0a20 2020 2048 6f77 6576 6572 2c20  y..    However, 
+00006c50: 6576 656e 2074 686f 7567 6820 7468 6973  even though this
+00006c60: 2076 616c 6c65 7920 6973 2065 6173 7920   valley is easy 
+00006c70: 746f 2066 696e 642c 2063 6f6e 7665 7267  to find, converg
+00006c80: 656e 6365 2074 6f20 7468 6520 6d69 6e69  ence to the mini
+00006c90: 6d75 6d20 6973 2064 6966 6669 6375 6c74  mum is difficult
+00006ca0: 2028 5069 6368 656e 7920 6574 2061 6c2e   (Picheny et al.
+00006cb0: 2c20 3230 3132 292e 0a0a 2020 2020 2e2e  , 2012)...    ..
+00006cc0: 206d 6174 683a 3a0a 2020 2020 2020 7920   math::.      y 
+00006cd0: 3d20 5c5c 7375 6d5f 7b69 3d31 7d5e 7b64  = \\sum_{i=1}^{d
+00006ce0: 2d31 7d5b 3130 3028 785f 7b69 2b31 7d2d  -1}[100(x_{i+1}-
+00006cf0: 785f 695e 3229 5e32 2b28 785f 692d 3129  x_i^2)^2+(x_i-1)
+00006d00: 5e32 5d0a 0a20 2020 2050 6172 616d 6574  ^2]..    Paramet
+00006d10: 6572 730a 2020 2020 2d2d 2d2d 2d2d 2d2d  ers.    --------
+00006d20: 2d2d 0a20 2020 2070 5b22 7831 225d 3a20  --.    p["x1"]: 
+00006d30: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
+00006d40: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
+00006d50: 645d 0a20 2020 2020 2020 2046 6972 7374  d].        First
+00006d60: 2070 6172 616d 6574 6572 2064 6566 696e   parameter defin
+00006d70: 6564 2069 6e20 5b2d 352c 2031 305d 0a20  ed in [-5, 10]. 
+00006d80: 2020 2070 5b22 7869 225d 3a20 666c 6f61     p["xi"]: floa
+00006d90: 7420 6f72 206e 6461 7272 6179 206f 6620  t or ndarray of 
+00006da0: 666c 6f61 7420 5b6e 5f67 7269 645d 0a20  float [n_grid]. 
+00006db0: 2020 2020 2020 2069 2d74 6820 7061 7261         i-th para
+00006dc0: 6d65 7465 7220 6465 6669 6e65 6420 696e  meter defined in
+00006dd0: 205b 2d35 2c20 3130 5d0a 0a20 2020 2052   [-5, 10]..    R
+00006de0: 6574 7572 6e73 0a20 2020 202d 2d2d 2d2d  eturns.    -----
+00006df0: 2d2d 0a20 2020 2079 3a20 6e64 6172 7261  --.    y: ndarra
+00006e00: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
+00006e10: 6964 2078 2031 5d0a 2020 2020 2020 2020  id x 1].        
+00006e20: 4f75 7470 7574 0a0a 2020 2020 4e6f 7465  Output..    Note
+00006e30: 730a 2020 2020 2d2d 2d2d 2d0a 2020 2020  s.    -----.    
+00006e40: 2e2e 2070 6c6f 743a 3a0a 0a20 2020 2020  .. plot::..     
+00006e50: 2020 696d 706f 7274 206e 756d 7079 2061    import numpy a
+00006e60: 7320 6e70 0a20 2020 2020 2020 6672 6f6d  s np.       from
+00006e70: 2070 7967 7063 2e74 6573 7466 756e 6374   pygpc.testfunct
+00006e80: 696f 6e73 2069 6d70 6f72 7420 706c 6f74  ions import plot
+00006e90: 5f74 6573 7466 756e 6374 696f 6e20 6173  _testfunction as
+00006ea0: 2070 6c6f 740a 2020 2020 2020 2066 726f   plot.       fro
+00006eb0: 6d20 636f 6c6c 6563 7469 6f6e 7320 696d  m collections im
+00006ec0: 706f 7274 204f 7264 6572 6564 4469 6374  port OrderedDict
+00006ed0: 0a0a 2020 2020 2020 2070 6172 616d 6574  ..       paramet
+00006ee0: 6572 7320 3d20 4f72 6465 7265 6444 6963  ers = OrderedDic
+00006ef0: 7428 290a 2020 2020 2020 2070 6172 616d  t().       param
+00006f00: 6574 6572 735b 2278 3122 5d20 3d20 6e70  eters["x1"] = np
+00006f10: 2e6c 696e 7370 6163 6528 2d35 2c20 3130  .linspace(-5, 10
+00006f20: 2c20 3130 3029 0a20 2020 2020 2020 7061  , 100).       pa
+00006f30: 7261 6d65 7465 7273 5b22 7832 225d 203d  rameters["x2"] =
+00006f40: 206e 702e 6c69 6e73 7061 6365 282d 352c   np.linspace(-5,
+00006f50: 2031 302c 2031 3030 290a 0a20 2020 2020   10, 100)..     
+00006f60: 2020 636f 6e73 7461 6e74 7320 3d20 4e6f    constants = No
+00006f70: 6e65 0a0a 2020 2020 2020 2070 6c6f 7428  ne..       plot(
+00006f80: 2252 6f73 656e 6272 6f63 6b46 756e 6374  "RosenbrockFunct
+00006f90: 696f 6e20 222c 2070 6172 616d 6574 6572  ion ", parameter
+00006fa0: 732c 2063 6f6e 7374 616e 7473 2c20 706c  s, constants, pl
+00006fb0: 6f74 5f33 643d 4661 6c73 6529 0a0a 2020  ot_3d=False)..  
+00006fc0: 2020 2e2e 205b 315d 2044 6978 6f6e 2c20    .. [1] Dixon, 
+00006fd0: 4c2e 2043 2e20 572e 2c20 2620 537a 6567  L. C. W., & Szeg
+00006fe0: 6f2c 2047 2e20 502e 2028 3139 3738 292e  o, G. P. (1978).
+00006ff0: 2054 6865 2067 6c6f 6261 6c20 6f70 7469   The global opti
+00007000: 6d69 7a61 7469 6f6e 2070 726f 626c 656d  mization problem
+00007010: 3a20 616e 2069 6e74 726f 6475 6374 696f  : an introductio
+00007020: 6e2e 0a20 2020 2020 2020 546f 7761 7264  n..       Toward
+00007030: 7320 676c 6f62 616c 206f 7074 696d 697a  s global optimiz
+00007040: 6174 696f 6e2c 2032 2c20 312d 3135 2e0a  ation, 2, 1-15..
+00007050: 0a20 2020 202e 2e20 5b32 5d20 476c 6f62  .    .. [2] Glob
+00007060: 616c 204f 7074 696d 697a 6174 696f 6e20  al Optimization 
+00007070: 5465 7374 2050 726f 626c 656d 732e 2052  Test Problems. R
+00007080: 6574 7269 6576 6564 204a 756e 6520 3230  etrieved June 20
+00007090: 3133 2c20 6672 6f6d 0a20 2020 2020 2020  13, from.       
+000070a0: 6874 7470 3a2f 2f77 7777 2d6f 7074 696d  http://www-optim
+000070b0: 612e 616d 702e 692e 6b79 6f74 6f2d 752e  a.amp.i.kyoto-u.
+000070c0: 6163 2e6a 702f 6d65 6d62 6572 2f73 7475  ac.jp/member/stu
+000070d0: 6465 6e74 2f68 6564 6172 2f48 6564 6172  dent/hedar/Hedar
+000070e0: 5f66 696c 6573 2f54 6573 7447 4f2e 6874  _files/TestGO.ht
+000070f0: 6d2e 0a0a 2020 2020 2e2e 205b 335d 204d  m...    .. [3] M
+00007100: 6f6c 6761 2c20 4d2e 2c20 2620 536d 7574  olga, M., & Smut
+00007110: 6e69 636b 692c 2043 2e20 5465 7374 2066  nicki, C. Test f
+00007120: 756e 6374 696f 6e73 2066 6f72 206f 7074  unctions for opt
+00007130: 696d 697a 6174 696f 6e20 6e65 6564 7320  imization needs 
+00007140: 2832 3030 3529 2e0a 2020 2020 2020 2052  (2005)..       R
+00007150: 6574 7269 6576 6564 204a 756e 6520 3230  etrieved June 20
+00007160: 3133 2c20 6672 6f6d 2068 7474 703a 2f2f  13, from http://
+00007170: 7777 772e 7a73 642e 6963 742e 7077 722e  www.zsd.ict.pwr.
+00007180: 7772 6f63 2e70 6c2f 6669 6c65 732f 646f  wroc.pl/files/do
+00007190: 6373 2f66 756e 6374 696f 6e73 2e70 6466  cs/functions.pdf
+000071a0: 2e0a 0a20 2020 202e 2e20 5b34 5d20 5069  ...    .. [4] Pi
+000071b0: 6368 656e 792c 2056 2e2c 2057 6167 6e65  cheny, V., Wagne
+000071c0: 722c 2054 2e2c 2026 2047 696e 7362 6f75  r, T., & Ginsbou
+000071d0: 7267 6572 2c20 442e 2028 3230 3132 292e  rger, D. (2012).
+000071e0: 0a20 2020 2020 2020 4120 6265 6e63 686d  .       A benchm
+000071f0: 6172 6b20 6f66 206b 7269 6769 6e67 2d62  ark of kriging-b
+00007200: 6173 6564 2069 6e66 696c 6c20 6372 6974  ased infill crit
+00007210: 6572 6961 2066 6f72 206e 6f69 7379 206f  eria for noisy o
+00007220: 7074 696d 697a 6174 696f 6e2e 0a0a 2020  ptimization...  
+00007230: 2020 2e2e 205b 355d 2068 7474 7073 3a2f    .. [5] https:/
+00007240: 2f77 7777 2e73 6675 2e63 612f 7e73 7375  /www.sfu.ca/~ssu
+00007250: 726a 616e 6f2f 726f 7365 6e2e 6874 6d6c  rjano/rosen.html
+00007260: 0a0a 2020 2020 2222 220a 0a20 2020 2064  ..    """..    d
+00007270: 6566 205f 5f69 6e69 745f 5f28 7365 6c66  ef __init__(self
+00007280: 2c20 6d61 746c 6162 5f6d 6f64 656c 3d46  , matlab_model=F
+00007290: 616c 7365 293a 0a20 2020 2020 2020 2073  alse):.        s
+000072a0: 7570 6572 2874 7970 6528 7365 6c66 292c  uper(type(self),
+000072b0: 2073 656c 6629 2e5f 5f69 6e69 745f 5f28   self).__init__(
+000072c0: 6d61 746c 6162 5f6d 6f64 656c 3d6d 6174  matlab_model=mat
+000072d0: 6c61 625f 6d6f 6465 6c29 0a20 2020 2020  lab_model).     
+000072e0: 2020 2073 656c 662e 666e 616d 6520 3d20     self.fname = 
+000072f0: 696e 7370 6563 742e 6765 7466 696c 6528  inspect.getfile(
+00007300: 696e 7370 6563 742e 6375 7272 656e 7466  inspect.currentf
+00007310: 7261 6d65 2829 290a 0a20 2020 2064 6566  rame())..    def
+00007320: 2076 616c 6964 6174 6528 7365 6c66 293a   validate(self):
+00007330: 0a20 2020 2020 2020 2070 6173 730a 0a20  .        pass.. 
+00007340: 2020 2064 6566 2073 696d 756c 6174 6528     def simulate(
+00007350: 7365 6c66 2c20 7072 6f63 6573 735f 6964  self, process_id
+00007360: 3d4e 6f6e 652c 206d 6174 6c61 625f 656e  =None, matlab_en
+00007370: 6769 6e65 3d4e 6f6e 6529 3a0a 0a20 2020  gine=None):..   
+00007380: 2020 2020 2066 6f72 2069 2c20 6b65 7920       for i, key 
+00007390: 696e 2065 6e75 6d65 7261 7465 2873 656c  in enumerate(sel
+000073a0: 662e 702e 6b65 7973 2829 293a 0a20 2020  f.p.keys()):.   
+000073b0: 2020 2020 2020 2020 2069 6620 7479 7065           if type
+000073c0: 2873 656c 662e 705b 6b65 795d 2920 6973  (self.p[key]) is
+000073d0: 206e 702e 6e64 6172 7261 793a 0a20 2020   np.ndarray:.   
+000073e0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+000073f0: 2e70 5b6b 6579 5d20 3d20 7365 6c66 2e70  .p[key] = self.p
+00007400: 5b6b 6579 5d2e 666c 6174 7465 6e28 290a  [key].flatten().
+00007410: 0a20 2020 2020 2020 2079 203d 206e 702e  .        y = np.
+00007420: 7a65 726f 7328 6e70 2e61 7272 6179 2873  zeros(np.array(s
+00007430: 656c 662e 705b 6c69 7374 2873 656c 662e  elf.p[list(self.
+00007440: 702e 6b65 7973 2829 295b 305d 5d29 2e73  p.keys())[0]]).s
+00007450: 697a 6529 0a20 2020 2020 2020 206b 6579  ize).        key
+00007460: 7320 3d20 6c69 7374 2873 656c 662e 702e  s = list(self.p.
+00007470: 6b65 7973 2829 290a 0a20 2020 2020 2020  keys())..       
+00007480: 2066 6f72 2069 2c20 6b65 7920 696e 2065   for i, key in e
+00007490: 6e75 6d65 7261 7465 286b 6579 735b 3a2d  numerate(keys[:-
+000074a0: 315d 293a 0a20 2020 2020 2020 2020 2020  1]):.           
+000074b0: 2079 202b 3d20 3130 3020 2a20 2873 656c   y += 100 * (sel
+000074c0: 662e 705b 6b65 7973 5b69 2b31 5d5d 202d  f.p[keys[i+1]] -
+000074d0: 2073 656c 662e 705b 6b65 795d 202a 2a20   self.p[key] ** 
+000074e0: 3229 202a 2a20 3220 2b20 2873 656c 662e  2) ** 2 + (self.
+000074f0: 705b 6b65 795d 202d 2031 2920 2a2a 2032  p[key] - 1) ** 2
+00007500: 0a0a 2020 2020 2020 2020 795f 6f75 7420  ..        y_out 
+00007510: 3d20 795b 3a2c 206e 702e 6e65 7761 7869  = y[:, np.newaxi
+00007520: 735d 0a0a 2020 2020 2020 2020 7265 7475  s]..        retu
+00007530: 726e 2079 5f6f 7574 0a0a 0a63 6c61 7373  rn y_out...class
+00007540: 204d 6963 6861 6c65 7769 637a 4675 6e63   MichalewiczFunc
+00007550: 7469 6f6e 2841 6273 7472 6163 744d 6f64  tion(AbstractMod
+00007560: 656c 293a 0a20 2020 2022 2222 0a20 2020  el):.    """.   
+00007570: 2064 2d64 696d 656e 7369 6f6e 616c 204d   d-dimensional M
+00007580: 6963 6861 6c65 7769 637a 2066 756e 6374  ichalewicz funct
+00007590: 696f 6e20 5b31 5d5b 325d 5b33 5d5b 345d  ion [1][2][3][4]
+000075a0: 2e0a 2020 2020 5468 6520 4d69 6368 616c  ..    The Michal
+000075b0: 6577 6963 7a20 6675 6e63 7469 6f6e 2068  ewicz function h
+000075c0: 6173 2064 2120 6c6f 6361 6c20 6d69 6e69  as d! local mini
+000075d0: 6d61 2c20 616e 6420 6974 2069 7320 6d75  ma, and it is mu
+000075e0: 6c74 696d 6f64 616c 2e0a 2020 2020 5468  ltimodal..    Th
+000075f0: 6520 7061 7261 6d65 7465 7220 6d20 6465  e parameter m de
+00007600: 6669 6e65 7320 7468 6520 7374 6565 706e  fines the steepn
+00007610: 6573 7320 6f66 2074 6865 7920 7661 6c6c  ess of they vall
+00007620: 6579 7320 616e 6420 7269 6467 6573 3b20  eys and ridges; 
+00007630: 6120 6c61 7267 6572 206d 206c 6561 6473  a larger m leads
+00007640: 2074 6f20 6120 6d6f 7265 2064 6966 6669   to a more diffi
+00007650: 6375 6c74 2073 6561 7263 682e 0a20 2020  cult search..   
+00007660: 2054 6865 2072 6563 6f6d 6d65 6e64 6564   The recommended
+00007670: 2076 616c 7565 206f 6620 6d20 6973 206d   value of m is m
+00007680: 203d 2031 302e 2054 6865 2066 756e 6374   = 10. The funct
+00007690: 696f 6e27 7320 7477 6f2d 6469 6d65 6e73  ion's two-dimens
+000076a0: 696f 6e61 6c20 666f 726d 2069 7320 7368  ional form is sh
+000076b0: 6f77 6e20 696e 2074 6865 2070 6c6f 7420  own in the plot 
+000076c0: 6162 6f76 652e 0a0a 2020 2020 2e2e 206d  above...    .. m
+000076d0: 6174 683a 3a0a 2020 2020 2020 2079 3d2d  ath::.       y=-
+000076e0: 5c5c 7375 6d5f 7b69 3d31 7d5e 7b64 7d5c  \\sum_{i=1}^{d}\
+000076f0: 5c73 696e 2878 5f69 295c 5c73 696e 5e7b  \sin(x_i)\\sin^{
+00007700: 326d 7d5c 5c6c 6566 7428 5c5c 6672 6163  2m}\\left(\\frac
+00007710: 7b69 2078 5f69 5e32 7d7b 5c5c 7069 7d5c  {i x_i^2}{\\pi}\
+00007720: 5c72 6967 6874 290a 0a20 2020 2050 6172  \right)..    Par
+00007730: 616d 6574 6572 730a 2020 2020 2d2d 2d2d  ameters.    ----
+00007740: 2d2d 2d2d 2d2d 0a20 2020 2070 5b22 7831  ------.    p["x1
+00007750: 225d 3a20 666c 6f61 7420 6f72 206e 6461  "]: float or nda
+00007760: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
+00007770: 5f67 7269 645d 0a20 2020 2020 2020 2046  _grid].        F
+00007780: 6972 7374 2070 6172 616d 6574 6572 2064  irst parameter d
+00007790: 6566 696e 6564 2069 6e20 5b30 2c20 6e70  efined in [0, np
+000077a0: 2e70 695d 0a20 2020 2070 5b22 7869 225d  .pi].    p["xi"]
+000077b0: 3a20 666c 6f61 7420 6f72 206e 6461 7272  : float or ndarr
+000077c0: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
+000077d0: 7269 645d 0a20 2020 2020 2020 2069 2d74  rid].        i-t
+000077e0: 6820 7061 7261 6d65 7465 7220 6465 6669  h parameter defi
+000077f0: 6e65 6420 696e 205b 302c 206e 702e 7069  ned in [0, np.pi
+00007800: 5d0a 0a20 2020 2052 6574 7572 6e73 0a20  ]..    Returns. 
+00007810: 2020 202d 2d2d 2d2d 2d2d 0a20 2020 2079     -------.    y
+00007820: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
+00007830: 6174 205b 6e5f 6772 6964 2078 2031 5d0a  at [n_grid x 1].
+00007840: 2020 2020 2020 2020 4f75 7470 7574 0a0a          Output..
+00007850: 2020 2020 4e6f 7465 730a 2020 2020 2d2d      Notes.    --
+00007860: 2d2d 2d0a 2020 2020 2e2e 2070 6c6f 743a  ---.    .. plot:
+00007870: 3a0a 0a20 2020 2020 2020 696d 706f 7274  :..       import
+00007880: 206e 756d 7079 2061 7320 6e70 0a20 2020   numpy as np.   
+00007890: 2020 2020 6672 6f6d 2070 7967 7063 2e74      from pygpc.t
+000078a0: 6573 7466 756e 6374 696f 6e73 2069 6d70  estfunctions imp
+000078b0: 6f72 7420 706c 6f74 5f74 6573 7466 756e  ort plot_testfun
+000078c0: 6374 696f 6e20 6173 2070 6c6f 740a 2020  ction as plot.  
+000078d0: 2020 2020 2066 726f 6d20 636f 6c6c 6563       from collec
+000078e0: 7469 6f6e 7320 696d 706f 7274 204f 7264  tions import Ord
+000078f0: 6572 6564 4469 6374 0a0a 2020 2020 2020  eredDict..      
+00007900: 2070 6172 616d 6574 6572 7320 3d20 4f72   parameters = Or
+00007910: 6465 7265 6444 6963 7428 290a 2020 2020  deredDict().    
+00007920: 2020 2070 6172 616d 6574 6572 735b 2278     parameters["x
+00007930: 3122 5d20 3d20 6e70 2e6c 696e 7370 6163  1"] = np.linspac
+00007940: 6528 302c 206e 702e 7069 2c20 3130 3029  e(0, np.pi, 100)
+00007950: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
+00007960: 7273 5b22 7869 225d 203d 206e 702e 6c69  rs["xi"] = np.li
+00007970: 6e73 7061 6365 2830 2c20 6e70 2e70 692c  nspace(0, np.pi,
+00007980: 2031 3030 290a 0a20 2020 2020 2020 636f   100)..       co
+00007990: 6e73 7461 6e74 7320 3d20 4f72 6465 7265  nstants = Ordere
+000079a0: 6444 6963 7428 290a 2020 2020 2020 2063  dDict().       c
+000079b0: 6f6e 7374 616e 7473 5b22 6d22 5d20 3d20  onstants["m"] = 
+000079c0: 3130 2e0a 0a20 2020 2020 2020 706c 6f74  10...       plot
+000079d0: 2822 4d69 6368 616c 6577 6963 7a46 756e  ("MichalewiczFun
+000079e0: 6374 696f 6e22 2c20 7061 7261 6d65 7465  ction", paramete
+000079f0: 7273 2c20 636f 6e73 7461 6e74 732c 2070  rs, constants, p
+00007a00: 6c6f 745f 3364 3d46 616c 7365 290a 0a20  lot_3d=False).. 
+00007a10: 2020 202e 2e20 5b31 5d20 476c 6f62 616c     .. [1] Global
+00007a20: 204f 7074 696d 697a 6174 696f 6e20 5465   Optimization Te
+00007a30: 7374 2046 756e 6374 696f 6e73 2049 6e64  st Functions Ind
+00007a40: 6578 2e0a 2020 2020 2020 2052 6574 7269  ex..       Retri
+00007a50: 6576 6564 204a 756e 6520 3230 3133 2c20  eved June 2013, 
+00007a60: 6672 6f6d 2068 7474 703a 2f2f 696e 6669  from http://infi
+00007a70: 6e69 7479 3737 2e6e 6574 2f67 6c6f 6261  nity77.net/globa
+00007a80: 6c5f 6f70 7469 6d69 7a61 7469 6f6e 2f74  l_optimization/t
+00007a90: 6573 745f 6675 6e63 7469 6f6e 732e 6874  est_functions.ht
+00007aa0: 6d6c 2374 6573 742d 6675 6e63 7469 6f6e  ml#test-function
+00007ab0: 732d 696e 6465 782e 0a0a 2020 2020 2e2e  s-index...    ..
+00007ac0: 205b 325d 476c 6f62 616c 204f 7074 696d   [2]Global Optim
+00007ad0: 697a 6174 696f 6e20 5465 7374 2050 726f  ization Test Pro
+00007ae0: 626c 656d 732e 2052 6574 7269 6576 6564  blems. Retrieved
+00007af0: 204a 756e 6520 3230 3133 2c20 6672 6f6d   June 2013, from
+00007b00: 0a20 2020 2020 2020 6874 7470 3a2f 2f77  .       http://w
+00007b10: 7777 2d6f 7074 696d 612e 616d 702e 692e  ww-optima.amp.i.
+00007b20: 6b79 6f74 6f2d 752e 6163 2e6a 702f 6d65  kyoto-u.ac.jp/me
+00007b30: 6d62 6572 2f73 7475 6465 6e74 2f68 6564  mber/student/hed
+00007b40: 6172 2f48 6564 6172 5f66 696c 6573 2f54  ar/Hedar_files/T
+00007b50: 6573 7447 4f2e 6874 6d2e 0a0a 2020 2020  estGO.htm...    
+00007b60: 2e2e 205b 335d 204d 6f6c 6761 2c20 4d2e  .. [3] Molga, M.
+00007b70: 2c20 2620 536d 7574 6e69 636b 692c 2043  , & Smutnicki, C
+00007b80: 2e20 5465 7374 2066 756e 6374 696f 6e73  . Test functions
+00007b90: 2066 6f72 206f 7074 696d 697a 6174 696f   for optimizatio
+00007ba0: 6e20 6e65 6564 7320 2832 3030 3529 2e0a  n needs (2005)..
+00007bb0: 2020 2020 2020 2052 6574 7269 6576 6564         Retrieved
+00007bc0: 204a 756e 6520 3230 3133 2c20 6672 6f6d   June 2013, from
+00007bd0: 2068 7474 703a 2f2f 7777 772e 7a73 642e   http://www.zsd.
+00007be0: 6963 742e 7077 722e 7772 6f63 2e70 6c2f  ict.pwr.wroc.pl/
+00007bf0: 6669 6c65 732f 646f 6373 2f66 756e 6374  files/docs/funct
+00007c00: 696f 6e73 2e70 6466 2e0a 0a20 2020 202e  ions.pdf...    .
+00007c10: 2e20 5b34 5d20 6874 7470 733a 2f2f 7777  . [4] https://ww
+00007c20: 772e 7366 752e 6361 2f7e 7373 7572 6a61  w.sfu.ca/~ssurja
+00007c30: 6e6f 2f6d 6963 6861 6c2e 6874 6d6c 0a0a  no/michal.html..
+00007c40: 2020 2020 2222 220a 0a20 2020 2064 6566      """..    def
+00007c50: 205f 5f69 6e69 745f 5f28 7365 6c66 2c20   __init__(self, 
+00007c60: 6d61 746c 6162 5f6d 6f64 656c 3d46 616c  matlab_model=Fal
+00007c70: 7365 293a 0a20 2020 2020 2020 2073 7570  se):.        sup
+00007c80: 6572 2874 7970 6528 7365 6c66 292c 2073  er(type(self), s
+00007c90: 656c 6629 2e5f 5f69 6e69 745f 5f28 6d61  elf).__init__(ma
+00007ca0: 746c 6162 5f6d 6f64 656c 3d6d 6174 6c61  tlab_model=matla
+00007cb0: 625f 6d6f 6465 6c29 0a20 2020 2020 2020  b_model).       
+00007cc0: 2073 656c 662e 666e 616d 6520 3d20 696e   self.fname = in
+00007cd0: 7370 6563 742e 6765 7466 696c 6528 696e  spect.getfile(in
+00007ce0: 7370 6563 742e 6375 7272 656e 7466 7261  spect.currentfra
+00007cf0: 6d65 2829 290a 0a20 2020 2064 6566 2076  me())..    def v
+00007d00: 616c 6964 6174 6528 7365 6c66 293a 0a20  alidate(self):. 
+00007d10: 2020 2020 2020 2070 6173 730a 0a20 2020         pass..   
+00007d20: 2064 6566 2073 696d 756c 6174 6528 7365   def simulate(se
+00007d30: 6c66 2c20 7072 6f63 6573 735f 6964 3d4e  lf, process_id=N
+00007d40: 6f6e 652c 206d 6174 6c61 625f 656e 6769  one, matlab_engi
+00007d50: 6e65 3d4e 6f6e 6529 3a0a 0a20 2020 2020  ne=None):..     
+00007d60: 2020 2066 6f72 2069 2c20 6b65 7920 696e     for i, key in
+00007d70: 2065 6e75 6d65 7261 7465 2873 656c 662e   enumerate(self.
+00007d80: 702e 6b65 7973 2829 293a 0a20 2020 2020  p.keys()):.     
+00007d90: 2020 2020 2020 2069 6620 7479 7065 2873         if type(s
+00007da0: 656c 662e 705b 6b65 795d 2920 6973 206e  elf.p[key]) is n
+00007db0: 702e 6e64 6172 7261 793a 0a20 2020 2020  p.ndarray:.     
+00007dc0: 2020 2020 2020 2020 2020 7365 6c66 2e70            self.p
+00007dd0: 5b6b 6579 5d20 3d20 7365 6c66 2e70 5b6b  [key] = self.p[k
+00007de0: 6579 5d2e 666c 6174 7465 6e28 290a 0a20  ey].flatten().. 
+00007df0: 2020 2020 2020 2023 2073 6574 2063 6f6e         # set con
+00007e00: 7374 616e 7473 0a20 2020 2020 2020 2070  stants.        p
+00007e10: 203d 2063 6f70 792e 6465 6570 636f 7079   = copy.deepcopy
+00007e20: 2873 656c 662e 7029 0a20 2020 2020 2020  (self.p).       
+00007e30: 206d 203d 2073 656c 662e 705b 226d 225d   m = self.p["m"]
+00007e40: 0a20 2020 2020 2020 2064 656c 2070 5b22  .        del p["
+00007e50: 6d22 5d0a 0a20 2020 2020 2020 2023 2064  m"]..        # d
+00007e60: 6574 6572 6d69 6e65 2073 756d 0a20 2020  etermine sum.   
+00007e70: 2020 2020 2079 203d 206e 702e 7a65 726f       y = np.zero
+00007e80: 7328 6e70 2e61 7272 6179 2873 656c 662e  s(np.array(self.
+00007e90: 705b 6c69 7374 2873 656c 662e 702e 6b65  p[list(self.p.ke
+00007ea0: 7973 2829 295b 305d 5d29 2e73 697a 6529  ys())[0]]).size)
+00007eb0: 0a20 2020 2020 2020 206b 6579 7320 3d20  .        keys = 
+00007ec0: 6c69 7374 2873 656c 662e 702e 6b65 7973  list(self.p.keys
+00007ed0: 2829 290a 0a20 2020 2020 2020 2066 6f72  ())..        for
+00007ee0: 2069 2c20 6b65 7920 696e 2065 6e75 6d65   i, key in enume
+00007ef0: 7261 7465 286b 6579 7329 3a0a 2020 2020  rate(keys):.    
+00007f00: 2020 2020 2020 2020 7920 2b3d 202d 206e          y += - n
+00007f10: 702e 7369 6e28 7365 6c66 2e70 5b6b 6579  p.sin(self.p[key
+00007f20: 5d29 202a 2028 6e70 2e73 696e 2873 656c  ]) * (np.sin(sel
+00007f30: 662e 705b 6b65 7973 5b69 5d5d 202a 2028  f.p[keys[i]] * (
+00007f40: 7365 6c66 2e70 5b6b 6579 5d20 2a2a 2032  self.p[key] ** 2
+00007f50: 2920 2f20 6e70 2e70 6929 2920 2a2a 2028  ) / np.pi)) ** (
+00007f60: 3220 2a20 6d29 0a0a 2020 2020 2020 2020  2 * m)..        
+00007f70: 795f 6f75 7420 3d20 795b 3a2c 206e 702e  y_out = y[:, np.
+00007f80: 6e65 7761 7869 735d 0a0a 2020 2020 2020  newaxis]..      
+00007f90: 2020 7265 7475 726e 2079 5f6f 7574 0a0a    return y_out..
+00007fa0: 0a63 6c61 7373 2044 654a 6f6e 6746 756e  .class DeJongFun
+00007fb0: 6374 696f 6e46 6976 6528 4162 7374 7261  ctionFive(Abstra
+00007fc0: 6374 4d6f 6465 6c29 3a0a 2020 2020 2222  ctModel):.    ""
+00007fd0: 220a 2020 2020 322d 6469 6d65 6e73 696f  ".    2-dimensio
+00007fe0: 6e61 6c20 4465 4a6f 6e67 2046 756e 6374  nal DeJong Funct
+00007ff0: 696f 6e20 4e75 6d62 6572 2046 6976 6520  ion Number Five 
+00008000: 5b31 5d5b 325d 2e0a 2020 2020 5468 6520  [1][2]..    The 
+00008010: 6669 6674 6820 6675 6e63 7469 6f6e 206f  fifth function o
+00008020: 6620 4465 204a 6f6e 6720 6973 206d 756c  f De Jong is mul
+00008030: 7469 6d6f 6461 6c2c 2077 6974 6820 7665  timodal, with ve
+00008040: 7279 2073 6861 7270 2064 726f 7073 206f  ry sharp drops o
+00008050: 6e20 6120 6d61 696e 6c79 2066 6c61 7420  n a mainly flat 
+00008060: 7375 7266 6163 652e 0a0a 2020 2020 2e2e  surface...    ..
+00008070: 206d 6174 683a 3a0a 2020 2020 2020 7920   math::.      y 
+00008080: 3d20 5c5c 6c65 6674 2830 2e30 3032 2b5c  = \\left(0.002+\
+00008090: 5c73 756d 5f7b 692b 317d 5e7b 3235 7d5c  \sum_{i+1}^{25}\
+000080a0: 5c66 7261 637b 317d 7b69 2b28 785f 312d  \frac{1}{i+(x_1-
+000080b0: 615f 7b31 697d 295e 362b 2878 5f32 2d61  a_{1i})^6+(x_2-a
+000080c0: 5f7b 3269 7d29 5e36 7d5c 5c72 6967 6874  _{2i})^6}\\right
+000080d0: 295e 7b2d 317d 0a0a 2020 2020 5061 7261  )^{-1}..    Para
+000080e0: 6d65 7465 7273 0a20 2020 202d 2d2d 2d2d  meters.    -----
+000080f0: 2d2d 2d2d 2d0a 2020 2020 705b 2278 3122  -----.    p["x1"
+00008100: 5d3a 2066 6c6f 6174 206f 7220 6e64 6172  ]: float or ndar
+00008110: 7261 7920 6f66 2066 6c6f 6174 205b 6e5f  ray of float [n_
+00008120: 6772 6964 5d0a 2020 2020 2020 2020 4669  grid].        Fi
+00008130: 7273 7420 7061 7261 6d65 7465 7220 6465  rst parameter de
+00008140: 6669 6e65 6420 696e 205b 2d36 352e 3533  fined in [-65.53
+00008150: 362c 2036 352e 3533 365d 0a20 2020 2070  6, 65.536].    p
+00008160: 5b22 7832 225d 3a20 666c 6f61 7420 6f72  ["x2"]: float or
+00008170: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
+00008180: 7420 5b6e 5f67 7269 645d 0a20 2020 2020  t [n_grid].     
+00008190: 2020 2073 6563 6f6e 6420 7061 7261 6d65     second parame
+000081a0: 7465 7220 6465 6669 6e65 6420 696e 205b  ter defined in [
+000081b0: 2d36 352e 3533 362c 2036 352e 3533 365d  -65.536, 65.536]
+000081c0: 0a0a 2020 2020 5265 7475 726e 730a 2020  ..    Returns.  
+000081d0: 2020 2d2d 2d2d 2d2d 2d0a 2020 2020 793a    -------.    y:
+000081e0: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
+000081f0: 7420 5b6e 5f67 7269 6420 7820 315d 0a20  t [n_grid x 1]. 
+00008200: 2020 2020 2020 204f 7574 7075 740a 0a20         Output.. 
+00008210: 2020 204e 6f74 6573 0a20 2020 202d 2d2d     Notes.    ---
+00008220: 2d2d 0a20 2020 202e 2e20 706c 6f74 3a3a  --.    .. plot::
+00008230: 0a0a 2020 2020 2020 2069 6d70 6f72 7420  ..       import 
+00008240: 6e75 6d70 7920 6173 206e 700a 2020 2020  numpy as np.    
+00008250: 2020 2066 726f 6d20 7079 6770 632e 7465     from pygpc.te
+00008260: 7374 6675 6e63 7469 6f6e 7320 696d 706f  stfunctions impo
+00008270: 7274 2070 6c6f 745f 7465 7374 6675 6e63  rt plot_testfunc
+00008280: 7469 6f6e 2061 7320 706c 6f74 0a20 2020  tion as plot.   
+00008290: 2020 2020 6672 6f6d 2063 6f6c 6c65 6374      from collect
+000082a0: 696f 6e73 2069 6d70 6f72 7420 4f72 6465  ions import Orde
+000082b0: 7265 6444 6963 740a 0a20 2020 2020 2020  redDict..       
+000082c0: 7061 7261 6d65 7465 7273 203d 204f 7264  parameters = Ord
+000082d0: 6572 6564 4469 6374 2829 0a20 2020 2020  eredDict().     
+000082e0: 2020 7061 7261 6d65 7465 7273 5b22 7831    parameters["x1
+000082f0: 225d 203d 206e 702e 6c69 6e73 7061 6365  "] = np.linspace
+00008300: 282d 3635 2e35 3336 2c20 3635 2e35 3336  (-65.536, 65.536
+00008310: 2c20 3130 3029 0a20 2020 2020 2020 7061  , 100).       pa
+00008320: 7261 6d65 7465 7273 5b22 7832 225d 203d  rameters["x2"] =
+00008330: 206e 702e 6c69 6e73 7061 6365 282d 3635   np.linspace(-65
+00008340: 2e35 3336 2c20 3635 2e35 3336 2c20 3130  .536, 65.536, 10
+00008350: 3029 0a0a 2020 2020 2020 2063 6f6e 7374  0)..       const
+00008360: 616e 7473 203d 204e 6f6e 650a 0a20 2020  ants = None..   
+00008370: 2020 2020 706c 6f74 2822 4465 4a6f 6e67      plot("DeJong
+00008380: 4675 6e63 7469 6f6e 4669 7665 222c 2070  FunctionFive", p
+00008390: 6172 616d 6574 6572 732c 2063 6f6e 7374  arameters, const
+000083a0: 616e 7473 2c20 706c 6f74 5f33 643d 4661  ants, plot_3d=Fa
+000083b0: 6c73 6529 0a0a 2020 2020 2e2e 205b 315d  lse)..    .. [1]
+000083c0: 204d 6f6c 6761 2c20 4d2e 2c20 2620 536d   Molga, M., & Sm
+000083d0: 7574 6e69 636b 692c 2043 2e20 5465 7374  utnicki, C. Test
+000083e0: 2066 756e 6374 696f 6e73 2066 6f72 206f   functions for o
+000083f0: 7074 696d 697a 6174 696f 6e20 6e65 6564  ptimization need
+00008400: 7320 2832 3030 3529 2e0a 2020 2020 2020  s (2005)..      
+00008410: 2052 6574 7269 6576 6564 204a 756e 6520   Retrieved June 
+00008420: 3230 3133 2c20 6672 6f6d 2068 7474 703a  2013, from http:
+00008430: 2f2f 7777 772e 7a73 642e 6963 742e 7077  //www.zsd.ict.pw
+00008440: 722e 7772 6f63 2e70 6c2f 6669 6c65 732f  r.wroc.pl/files/
+00008450: 646f 6373 2f66 756e 6374 696f 6e73 2e70  docs/functions.p
+00008460: 6466 2e0a 2020 2020 2e2e 205b 325d 2068  df..    .. [2] h
+00008470: 7474 7073 3a2f 2f77 7777 2e73 6675 2e63  ttps://www.sfu.c
+00008480: 612f 7e73 7375 726a 616e 6f2f 6465 6a6f  a/~ssurjano/dejo
+00008490: 6e67 352e 6874 6d6c 0a0a 2020 2020 2222  ng5.html..    ""
+000084a0: 220a 0a20 2020 2064 6566 205f 5f69 6e69  "..    def __ini
+000084b0: 745f 5f28 7365 6c66 2c20 6d61 746c 6162  t__(self, matlab
+000084c0: 5f6d 6f64 656c 3d46 616c 7365 293a 0a20  _model=False):. 
+000084d0: 2020 2020 2020 2073 7570 6572 2874 7970         super(typ
+000084e0: 6528 7365 6c66 292c 2073 656c 6629 2e5f  e(self), self)._
+000084f0: 5f69 6e69 745f 5f28 6d61 746c 6162 5f6d  _init__(matlab_m
+00008500: 6f64 656c 3d6d 6174 6c61 625f 6d6f 6465  odel=matlab_mode
+00008510: 6c29 0a20 2020 2020 2020 2073 656c 662e  l).        self.
+00008520: 666e 616d 6520 3d20 696e 7370 6563 742e  fname = inspect.
+00008530: 6765 7466 696c 6528 696e 7370 6563 742e  getfile(inspect.
+00008540: 6375 7272 656e 7466 7261 6d65 2829 290a  currentframe()).
+00008550: 0a20 2020 2064 6566 2076 616c 6964 6174  .    def validat
+00008560: 6528 7365 6c66 293a 0a20 2020 2020 2020  e(self):.       
+00008570: 2070 6173 730a 0a20 2020 2064 6566 2073   pass..    def s
+00008580: 696d 756c 6174 6528 7365 6c66 2c20 7072  imulate(self, pr
+00008590: 6f63 6573 735f 6964 3d4e 6f6e 652c 206d  ocess_id=None, m
+000085a0: 6174 6c61 625f 656e 6769 6e65 3d4e 6f6e  atlab_engine=Non
+000085b0: 6529 3a0a 0a20 2020 2020 2020 2066 6f72  e):..        for
+000085c0: 2069 2c20 6b65 7920 696e 2065 6e75 6d65   i, key in enume
+000085d0: 7261 7465 2873 656c 662e 702e 6b65 7973  rate(self.p.keys
+000085e0: 2829 293a 0a20 2020 2020 2020 2020 2020  ()):.           
+000085f0: 2069 6620 7479 7065 2873 656c 662e 705b   if type(self.p[
+00008600: 6b65 795d 2920 6973 206e 702e 6e64 6172  key]) is np.ndar
+00008610: 7261 793a 0a20 2020 2020 2020 2020 2020  ray:.           
+00008620: 2020 2020 7365 6c66 2e70 5b6b 6579 5d20      self.p[key] 
+00008630: 3d20 7365 6c66 2e70 5b6b 6579 5d2e 666c  = self.p[key].fl
+00008640: 6174 7465 6e28 290a 0a20 2020 2020 2020  atten()..       
+00008650: 2023 2073 6574 2063 6f6e 7374 616e 7473   # set constants
+00008660: 0a20 2020 2020 2020 2073 6571 203d 205b  .        seq = [
+00008670: 2d33 322c 202d 3136 2c20 302c 2031 362c  -32, -16, 0, 16,
+00008680: 2033 325d 0a20 2020 2020 2020 2061 203d   32].        a =
+00008690: 206e 702e 6172 7261 7928 5b73 6571 202a   np.array([seq *
+000086a0: 2035 2c20 6e70 2e68 7374 6163 6b28 5b5b   5, np.hstack([[
+000086b0: 695d 202a 2035 2066 6f72 2069 2069 6e20  i] * 5 for i in 
+000086c0: 7365 715d 295d 290a 2020 2020 2020 2020  seq])]).        
+000086d0: 7331 203d 206e 702e 7a65 726f 7328 6e70  s1 = np.zeros(np
+000086e0: 2e61 7272 6179 2873 656c 662e 705b 6c69  .array(self.p[li
+000086f0: 7374 2873 656c 662e 702e 6b65 7973 2829  st(self.p.keys()
+00008700: 295b 305d 5d29 2e73 697a 6529 0a20 2020  )[0]]).size).   
+00008710: 2020 2020 206b 6579 7320 3d20 6c69 7374       keys = list
+00008720: 2873 656c 662e 702e 6b65 7973 2829 290a  (self.p.keys()).
+00008730: 0a20 2020 2020 2020 2023 2064 6574 6572  .        # deter
+00008740: 6d69 6e65 2073 756d 0a20 2020 2020 2020  mine sum.       
+00008750: 2066 6f72 2069 2069 6e20 7261 6e67 6528   for i in range(
+00008760: 3235 293a 0a20 2020 2020 2020 2020 2020  25):.           
+00008770: 2073 3120 2b3d 2031 202f 2028 692b 3120   s1 += 1 / (i+1 
+00008780: 2b20 2873 656c 662e 705b 6b65 7973 5b30  + (self.p[keys[0
+00008790: 5d5d 202d 2061 5b30 2c20 695d 2920 2a2a  ]] - a[0, i]) **
+000087a0: 2036 202b 2028 7365 6c66 2e70 5b6b 6579   6 + (self.p[key
+000087b0: 735b 315d 5d20 2d20 615b 312c 2069 5d29  s[1]] - a[1, i])
+000087c0: 202a 2a20 3629 0a0a 2020 2020 2020 2020   ** 6)..        
+000087d0: 7920 3d20 3120 2f20 2830 2e30 3032 202b  y = 1 / (0.002 +
+000087e0: 2073 3129 0a0a 2020 2020 2020 2020 795f   s1)..        y_
+000087f0: 6f75 7420 3d20 795b 3a2c 206e 702e 6e65  out = y[:, np.ne
+00008800: 7761 7869 735d 0a0a 2020 2020 2020 2020  waxis]..        
+00008810: 7265 7475 726e 2079 5f6f 7574 0a0a 0a63  return y_out...c
+00008820: 6c61 7373 204d 6174 7961 7346 756e 6374  lass MatyasFunct
+00008830: 696f 6e28 4162 7374 7261 6374 4d6f 6465  ion(AbstractMode
+00008840: 6c29 3a0a 2020 2020 2222 220a 2020 2020  l):.    """.    
+00008850: 322d 6469 6d65 6e73 696f 6e61 6c20 4d61  2-dimensional Ma
+00008860: 7479 6173 2066 756e 6374 696f 6e20 5b31  tyas function [1
+00008870: 5d5b 325d 2e0a 2020 2020 5468 6520 4d61  ][2]..    The Ma
+00008880: 7479 6173 2066 756e 6374 696f 6e20 6861  tyas function ha
+00008890: 7320 6e6f 206c 6f63 616c 206d 696e 696d  s no local minim
+000088a0: 6120 6578 6365 7074 2074 6865 2067 6c6f  a except the glo
+000088b0: 6261 6c20 6f6e 652e 0a0a 2020 2020 2e2e  bal one...    ..
+000088c0: 206d 6174 683a 3a0a 2020 2020 2020 7920   math::.      y 
+000088d0: 3d20 302e 3236 2878 5f31 5e32 2b78 5f32  = 0.26(x_1^2+x_2
+000088e0: 5e32 292d 302e 3438 785f 3178 5f32 0a0a  ^2)-0.48x_1x_2..
+000088f0: 2020 2020 5061 7261 6d65 7465 7273 0a20      Parameters. 
+00008900: 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020     ----------.  
+00008910: 2020 705b 2278 3122 5d3a 2066 6c6f 6174    p["x1"]: float
+00008920: 206f 7220 6e64 6172 7261 7920 6f66 2066   or ndarray of f
+00008930: 6c6f 6174 205b 6e5f 6772 6964 5d0a 2020  loat [n_grid].  
+00008940: 2020 2020 2020 4669 7273 7420 7061 7261        First para
+00008950: 6d65 7465 7220 6465 6669 6e65 6420 696e  meter defined in
+00008960: 205b 2d31 302c 2031 305d 0a20 2020 2070   [-10, 10].    p
+00008970: 5b22 7832 225d 3a20 666c 6f61 7420 6f72  ["x2"]: float or
+00008980: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
+00008990: 7420 5b6e 5f67 7269 645d 0a20 2020 2020  t [n_grid].     
+000089a0: 2020 2073 6563 6f6e 6420 7061 7261 6d65     second parame
+000089b0: 7465 7220 6465 6669 6e65 6420 696e 205b  ter defined in [
+000089c0: 2d31 302c 2031 305d 0a0a 2020 2020 5265  -10, 10]..    Re
+000089d0: 7475 726e 730a 2020 2020 2d2d 2d2d 2d2d  turns.    ------
+000089e0: 2d0a 2020 2020 793a 206e 6461 7272 6179  -.    y: ndarray
+000089f0: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
+00008a00: 6420 7820 315d 0a20 2020 2020 2020 204f  d x 1].        O
+00008a10: 7574 7075 740a 0a20 2020 204e 6f74 6573  utput..    Notes
+00008a20: 0a20 2020 202d 2d2d 2d2d 0a20 2020 202e  .    -----.    .
+00008a30: 2e20 706c 6f74 3a3a 0a0a 2020 2020 2020  . plot::..      
+00008a40: 2069 6d70 6f72 7420 6e75 6d70 7920 6173   import numpy as
+00008a50: 206e 700a 2020 2020 2020 2066 726f 6d20   np.       from 
+00008a60: 7079 6770 632e 7465 7374 6675 6e63 7469  pygpc.testfuncti
+00008a70: 6f6e 7320 696d 706f 7274 2070 6c6f 745f  ons import plot_
+00008a80: 7465 7374 6675 6e63 7469 6f6e 2061 7320  testfunction as 
+00008a90: 706c 6f74 0a20 2020 2020 2020 6672 6f6d  plot.       from
+00008aa0: 2063 6f6c 6c65 6374 696f 6e73 2069 6d70   collections imp
+00008ab0: 6f72 7420 4f72 6465 7265 6444 6963 740a  ort OrderedDict.
+00008ac0: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
+00008ad0: 7273 203d 204f 7264 6572 6564 4469 6374  rs = OrderedDict
+00008ae0: 2829 0a20 2020 2020 2020 7061 7261 6d65  ().       parame
+00008af0: 7465 7273 5b22 7831 225d 203d 206e 702e  ters["x1"] = np.
+00008b00: 6c69 6e73 7061 6365 282d 3130 2c20 3130  linspace(-10, 10
+00008b10: 2c20 3130 3029 0a20 2020 2020 2020 7061  , 100).       pa
+00008b20: 7261 6d65 7465 7273 5b22 7832 225d 203d  rameters["x2"] =
+00008b30: 206e 702e 6c69 6e73 7061 6365 282d 3130   np.linspace(-10
+00008b40: 2c20 3130 2c20 3130 3029 0a0a 2020 2020  , 10, 100)..    
+00008b50: 2020 2063 6f6e 7374 616e 7473 203d 204e     constants = N
+00008b60: 6f6e 650a 0a20 2020 2020 2020 706c 6f74  one..       plot
+00008b70: 2822 4d61 7479 6173 4675 6e63 7469 6f6e  ("MatyasFunction
+00008b80: 222c 2070 6172 616d 6574 6572 732c 2063  ", parameters, c
+00008b90: 6f6e 7374 616e 7473 2c20 706c 6f74 5f33  onstants, plot_3
+00008ba0: 643d 4661 6c73 6529 0a0a 2020 2020 2e2e  d=False)..    ..
+00008bb0: 205b 315d 2047 6c6f 6261 6c20 4f70 7469   [1] Global Opti
+00008bc0: 6d69 7a61 7469 6f6e 2054 6573 7420 5072  mization Test Pr
+00008bd0: 6f62 6c65 6d73 2e20 5265 7472 6965 7665  oblems. Retrieve
+00008be0: 6420 4a75 6e65 2032 3031 332c 2066 726f  d June 2013, fro
+00008bf0: 6d0a 2020 2020 2020 2068 7474 703a 2f2f  m.       http://
+00008c00: 7777 772d 6f70 7469 6d61 2e61 6d70 2e69  www-optima.amp.i
+00008c10: 2e6b 796f 746f 2d75 2e61 632e 6a70 2f6d  .kyoto-u.ac.jp/m
+00008c20: 656d 6265 722f 7374 7564 656e 742f 6865  ember/student/he
+00008c30: 6461 722f 4865 6461 725f 6669 6c65 732f  dar/Hedar_files/
+00008c40: 5465 7374 474f 2e68 746d 2e0a 0a20 2020  TestGO.htm...   
+00008c50: 202e 2e20 5b32 5d20 6874 7470 733a 2f2f   .. [2] https://
+00008c60: 7777 772e 7366 752e 6361 2f7e 7373 7572  www.sfu.ca/~ssur
+00008c70: 6a61 6e6f 2f6d 6174 7961 2e68 746d 6c0a  jano/matya.html.
+00008c80: 2020 2020 2222 220a 0a20 2020 2064 6566      """..    def
+00008c90: 205f 5f69 6e69 745f 5f28 7365 6c66 2c20   __init__(self, 
+00008ca0: 6d61 746c 6162 5f6d 6f64 656c 3d46 616c  matlab_model=Fal
+00008cb0: 7365 293a 0a20 2020 2020 2020 2073 7570  se):.        sup
+00008cc0: 6572 2874 7970 6528 7365 6c66 292c 2073  er(type(self), s
+00008cd0: 656c 6629 2e5f 5f69 6e69 745f 5f28 6d61  elf).__init__(ma
+00008ce0: 746c 6162 5f6d 6f64 656c 3d6d 6174 6c61  tlab_model=matla
+00008cf0: 625f 6d6f 6465 6c29 0a20 2020 2020 2020  b_model).       
+00008d00: 2073 656c 662e 666e 616d 6520 3d20 696e   self.fname = in
+00008d10: 7370 6563 742e 6765 7466 696c 6528 696e  spect.getfile(in
+00008d20: 7370 6563 742e 6375 7272 656e 7466 7261  spect.currentfra
+00008d30: 6d65 2829 290a 0a20 2020 2064 6566 2076  me())..    def v
+00008d40: 616c 6964 6174 6528 7365 6c66 293a 0a20  alidate(self):. 
+00008d50: 2020 2020 2020 2070 6173 730a 0a20 2020         pass..   
+00008d60: 2064 6566 2073 696d 756c 6174 6528 7365   def simulate(se
+00008d70: 6c66 2c20 7072 6f63 6573 735f 6964 3d4e  lf, process_id=N
+00008d80: 6f6e 652c 206d 6174 6c61 625f 656e 6769  one, matlab_engi
+00008d90: 6e65 3d4e 6f6e 6529 3a0a 0a20 2020 2020  ne=None):..     
+00008da0: 2020 2079 203d 2030 2e32 3620 2a20 2873     y = 0.26 * (s
+00008db0: 656c 662e 705b 2278 3122 5d20 2a2a 2032  elf.p["x1"] ** 2
+00008dc0: 202b 2073 656c 662e 705b 2278 3222 5d20   + self.p["x2"] 
+00008dd0: 2a2a 2032 2920 2d20 302e 3438 202a 2073  ** 2) - 0.48 * s
+00008de0: 656c 662e 705b 2278 3122 5d20 2a20 7365  elf.p["x1"] * se
+00008df0: 6c66 2e70 5b22 7832 225d 0a0a 2020 2020  lf.p["x2"]..    
+00008e00: 2020 2020 795f 6f75 7420 3d20 795b 3a2c      y_out = y[:,
+00008e10: 206e 702e 6e65 7761 7869 735d 0a0a 2020   np.newaxis]..  
+00008e20: 2020 2020 2020 7265 7475 726e 2079 5f6f        return y_o
+00008e30: 7574 0a0a 0a63 6c61 7373 2047 7261 6d61  ut...class Grama
+00008e40: 6379 4c65 6546 756e 6374 696f 6e28 4162  cyLeeFunction(Ab
+00008e50: 7374 7261 6374 4d6f 6465 6c29 3a0a 2020  stractModel):.  
+00008e60: 2020 2222 220a 2020 2020 312d 6469 6d65    """.    1-dime
+00008e70: 6e73 696f 6e61 6c20 4772 616d 6163 7920  nsional Gramacy 
+00008e80: 616e 6420 4c65 6520 6675 6e63 7469 6f6e  and Lee function
+00008e90: 5b31 5d5b 325d 5b33 5d2e 0a20 2020 2054  [1][2][3]..    T
+00008ea0: 6869 7320 6973 2061 2073 696d 706c 6520  his is a simple 
+00008eb0: 6f6e 652d 6469 6d65 6e73 696f 6e61 6c20  one-dimensional 
+00008ec0: 7465 7374 2066 756e 6374 696f 6e2e 0a0a  test function...
+00008ed0: 2020 2020 2e2e 206d 6174 683a 3a0a 2020      .. math::.  
+00008ee0: 2020 2020 7920 3d20 5c5c 6672 6163 7b5c      y = \\frac{\
+00008ef0: 5c73 696e 2831 3020 5c5c 7069 2078 297d  \sin(10 \\pi x)}
+00008f00: 7b32 787d 2b28 782d 3129 5e34 0a0a 2020  {2x}+(x-1)^4..  
+00008f10: 2020 5061 7261 6d65 7465 7273 0a20 2020    Parameters.   
+00008f20: 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020 2020   ----------.    
+00008f30: 705b 2278 3122 5d3a 2066 6c6f 6174 206f  p["x1"]: float o
+00008f40: 7220 6e64 6172 7261 7920 6f66 2066 6c6f  r ndarray of flo
+00008f50: 6174 205b 6e5f 6772 6964 5d0a 2020 2020  at [n_grid].    
+00008f60: 2020 2020 4669 7273 7420 7061 7261 6d65      First parame
+00008f70: 7465 7220 6465 6669 6e65 6420 696e 205b  ter defined in [
+00008f80: 302e 352c 2032 2e35 5d0a 2020 2020 705b  0.5, 2.5].    p[
+00008f90: 2278 3222 5d3a 2066 6c6f 6174 206f 7220  "x2"]: float or 
+00008fa0: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
+00008fb0: 205b 6e5f 6772 6964 5d0a 2020 2020 2020   [n_grid].      
+00008fc0: 2020 7365 636f 6e64 2070 6172 616d 6574    second paramet
+00008fd0: 6572 2064 6566 696e 6564 2069 6e20 5b30  er defined in [0
+00008fe0: 2e35 2c20 322e 355d 0a0a 2020 2020 5265  .5, 2.5]..    Re
+00008ff0: 7475 726e 730a 2020 2020 2d2d 2d2d 2d2d  turns.    ------
+00009000: 2d0a 2020 2020 793a 206e 6461 7272 6179  -.    y: ndarray
+00009010: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
+00009020: 6420 7820 315d 0a20 2020 2020 2020 204f  d x 1].        O
+00009030: 7574 7075 740a 0a20 2020 204e 6f74 6573  utput..    Notes
+00009040: 0a20 2020 202d 2d2d 2d2d 0a20 2020 202e  .    -----.    .
+00009050: 2e20 706c 6f74 3a3a 0a0a 2020 2020 2020  . plot::..      
+00009060: 2069 6d70 6f72 7420 6e75 6d70 7920 6173   import numpy as
+00009070: 206e 700a 2020 2020 2020 2066 726f 6d20   np.       from 
+00009080: 7079 6770 632e 7465 7374 6675 6e63 7469  pygpc.testfuncti
+00009090: 6f6e 7320 696d 706f 7274 2070 6c6f 745f  ons import plot_
+000090a0: 7465 7374 6675 6e63 7469 6f6e 2061 7320  testfunction as 
+000090b0: 706c 6f74 0a20 2020 2020 2020 6672 6f6d  plot.       from
+000090c0: 2063 6f6c 6c65 6374 696f 6e73 2069 6d70   collections imp
+000090d0: 6f72 7420 4f72 6465 7265 6444 6963 740a  ort OrderedDict.
+000090e0: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
+000090f0: 7273 203d 204f 7264 6572 6564 4469 6374  rs = OrderedDict
+00009100: 2829 0a20 2020 2020 2020 7061 7261 6d65  ().       parame
+00009110: 7465 7273 5b22 7831 225d 203d 206e 702e  ters["x1"] = np.
+00009120: 6c69 6e73 7061 6365 2830 2e35 2c20 322e  linspace(0.5, 2.
+00009130: 352c 2031 3030 290a 2020 2020 2020 2070  5, 100).       p
+00009140: 6172 616d 6574 6572 735b 2278 3222 5d20  arameters["x2"] 
+00009150: 3d20 6e70 2e6c 696e 7370 6163 6528 302e  = np.linspace(0.
+00009160: 352c 2032 2e35 2c20 3130 3029 0a0a 2020  5, 2.5, 100)..  
+00009170: 2020 2020 2063 6f6e 7374 616e 7473 203d       constants =
+00009180: 204e 6f6e 650a 0a20 2020 2020 2020 706c   None..       pl
+00009190: 6f74 2822 4772 616d 6163 794c 6565 4675  ot("GramacyLeeFu
+000091a0: 6e63 7469 6f6e 222c 2070 6172 616d 6574  nction", paramet
+000091b0: 6572 732c 2063 6f6e 7374 616e 7473 2c20  ers, constants, 
+000091c0: 706c 6f74 5f33 643d 4661 6c73 6529 0a0a  plot_3d=False)..
+000091d0: 2020 2020 2e2e 205b 315d 2047 7261 6d61      .. [1] Grama
+000091e0: 6379 2c20 522e 2042 2e2c 2026 204c 6565  cy, R. B., & Lee
+000091f0: 2c20 482e 204b 2e20 2832 3031 3229 2e20  , H. K. (2012). 
+00009200: 4361 7365 7320 666f 7220 7468 6520 6e75  Cases for the nu
+00009210: 6767 6574 2069 6e20 6d6f 6465 6c69 6e67  gget in modeling
+00009220: 2063 6f6d 7075 7465 7220 6578 7065 7269   computer experi
+00009230: 6d65 6e74 732e 0a20 2020 2020 2020 5374  ments..       St
+00009240: 6174 6973 7469 6373 2061 6e64 2043 6f6d  atistics and Com
+00009250: 7075 7469 6e67 2c20 3232 2833 292c 2037  puting, 22(3), 7
+00009260: 3133 2d37 3232 2e0a 0a20 2020 202e 2e20  13-722...    .. 
+00009270: 5b32 5d20 5261 6e6a 616e 2c20 502e 2028  [2] Ranjan, P. (
+00009280: 3230 3133 292e 2043 6f6d 6d65 6e74 3a20  2013). Comment: 
+00009290: 4549 2043 7269 7465 7269 6120 666f 7220  EI Criteria for 
+000092a0: 4e6f 6973 7920 436f 6d70 7574 6572 2053  Noisy Computer S
+000092b0: 696d 756c 6174 6f72 732e 2054 6563 686e  imulators. Techn
+000092c0: 6f6d 6574 7269 6373 2c20 3535 2831 292c  ometrics, 55(1),
+000092d0: 2032 342d 3238 2e0a 0a20 2020 202e 2e20   24-28...    .. 
+000092e0: 5b33 5d20 6874 7470 733a 2f2f 7777 772e  [3] https://www.
+000092f0: 7366 752e 6361 2f7e 7373 7572 6a61 6e6f  sfu.ca/~ssurjano
+00009300: 2f67 726c 6565 3132 2e68 746d 6c0a 0a20  /grlee12.html.. 
+00009310: 2020 2022 2222 0a0a 2020 2020 6465 6620     """..    def 
+00009320: 5f5f 696e 6974 5f5f 2873 656c 662c 206d  __init__(self, m
+00009330: 6174 6c61 625f 6d6f 6465 6c3d 4661 6c73  atlab_model=Fals
+00009340: 6529 3a0a 2020 2020 2020 2020 7375 7065  e):.        supe
+00009350: 7228 7479 7065 2873 656c 6629 2c20 7365  r(type(self), se
+00009360: 6c66 292e 5f5f 696e 6974 5f5f 286d 6174  lf).__init__(mat
+00009370: 6c61 625f 6d6f 6465 6c3d 6d61 746c 6162  lab_model=matlab
+00009380: 5f6d 6f64 656c 290a 2020 2020 2020 2020  _model).        
+00009390: 7365 6c66 2e66 6e61 6d65 203d 2069 6e73  self.fname = ins
+000093a0: 7065 6374 2e67 6574 6669 6c65 2869 6e73  pect.getfile(ins
+000093b0: 7065 6374 2e63 7572 7265 6e74 6672 616d  pect.currentfram
+000093c0: 6528 2929 0a0a 2020 2020 6465 6620 7661  e())..    def va
+000093d0: 6c69 6461 7465 2873 656c 6629 3a0a 2020  lidate(self):.  
+000093e0: 2020 2020 2020 7061 7373 0a0a 2020 2020        pass..    
+000093f0: 6465 6620 7369 6d75 6c61 7465 2873 656c  def simulate(sel
+00009400: 662c 2070 726f 6365 7373 5f69 643d 4e6f  f, process_id=No
+00009410: 6e65 2c20 6d61 746c 6162 5f65 6e67 696e  ne, matlab_engin
+00009420: 653d 4e6f 6e65 293a 0a0a 2020 2020 2020  e=None):..      
+00009430: 2020 7920 3d20 286e 702e 7369 6e28 3130    y = (np.sin(10
+00009440: 202a 206e 702e 7069 202a 2073 656c 662e   * np.pi * self.
+00009450: 705b 2278 3122 5d29 202f 2032 202a 2073  p["x1"]) / 2 * s
+00009460: 656c 662e 705b 2278 3122 5d29 202b 2028  elf.p["x1"]) + (
+00009470: 7365 6c66 2e70 5b22 7831 225d 202d 2031  self.p["x1"] - 1
+00009480: 2920 2a2a 2034 0a0a 2020 2020 2020 2020  ) ** 4..        
+00009490: 795f 6f75 7420 3d20 795b 3a2c 206e 702e  y_out = y[:, np.
+000094a0: 6e65 7761 7869 735d 0a0a 2020 2020 2020  newaxis]..      
+000094b0: 2020 7265 7475 726e 2079 5f6f 7574 0a0a    return y_out..
+000094c0: 0a63 6c61 7373 2053 6368 6166 6665 7246  .class SchafferF
+000094d0: 756e 6374 696f 6e34 2841 6273 7472 6163  unction4(Abstrac
+000094e0: 744d 6f64 656c 293a 0a20 2020 2022 2222  tModel):.    """
+000094f0: 0a20 2020 2032 2d64 696d 656e 7369 6f6e  .    2-dimension
+00009500: 616c 2053 6368 6166 6665 7220 6675 6e63  al Schaffer func
+00009510: 7469 6f6e 204e 6f2e 2034 2e20 5b31 5d5b  tion No. 4. [1][
+00009520: 325d 2e0a 0a20 2020 202e 2e20 6d61 7468  2]...    .. math
+00009530: 3a3a 0a20 2020 2020 2079 203d 2030 2e35  ::.      y = 0.5
+00009540: 2b5c 5c66 7261 637b 5c5c 636f 737b 285c  +\\frac{\\cos{(\
+00009550: 5c73 696e 7b28 5c6d 6964 2078 5f31 5e32  \sin{(\mid x_1^2
+00009560: 2d78 5f32 5e32 205c 6d69 6420 297d 297d  -x_2^2 \mid )})}
+00009570: 2d30 2e35 7d7b 2831 2b30 2e30 3031 2878  -0.5}{(1+0.001(x
+00009580: 5f31 5e32 2b78 5f32 5e32 2929 5e32 7d0a  _1^2+x_2^2))^2}.
+00009590: 0a20 2020 2050 6172 616d 6574 6572 730a  .    Parameters.
+000095a0: 2020 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0a20      ----------. 
+000095b0: 2020 2070 5b22 7831 225d 3a20 666c 6f61     p["x1"]: floa
+000095c0: 7420 6f72 206e 6461 7272 6179 206f 6620  t or ndarray of 
+000095d0: 666c 6f61 7420 5b6e 5f67 7269 645d 0a20  float [n_grid]. 
+000095e0: 2020 2020 2020 2046 6972 7374 2070 6172         First par
+000095f0: 616d 6574 6572 2064 6566 696e 6564 2069  ameter defined i
+00009600: 6e20 5b2d 3130 302c 2031 3030 5d0a 2020  n [-100, 100].  
+00009610: 2020 705b 2278 3222 5d3a 2066 6c6f 6174    p["x2"]: float
+00009620: 206f 7220 6e64 6172 7261 7920 6f66 2066   or ndarray of f
+00009630: 6c6f 6174 205b 6e5f 6772 6964 5d0a 2020  loat [n_grid].  
+00009640: 2020 2020 2020 7365 636f 6e64 2070 6172        second par
+00009650: 616d 6574 6572 2064 6566 696e 6564 2069  ameter defined i
+00009660: 6e20 5b2d 3130 302c 2031 3030 5d0a 0a20  n [-100, 100].. 
+00009670: 2020 2052 6574 7572 6e73 0a20 2020 202d     Returns.    -
+00009680: 2d2d 2d2d 2d2d 0a20 2020 2079 3a20 6e64  ------.    y: nd
+00009690: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
+000096a0: 6e5f 6772 6964 2078 2031 5d0a 2020 2020  n_grid x 1].    
+000096b0: 2020 2020 4f75 7470 7574 0a0a 2020 2020      Output..    
+000096c0: 4e6f 7465 730a 2020 2020 2d2d 2d2d 2d0a  Notes.    -----.
+000096d0: 2020 2020 2e2e 2070 6c6f 743a 3a0a 0a20      .. plot::.. 
+000096e0: 2020 2020 2020 696d 706f 7274 206e 756d        import num
+000096f0: 7079 2061 7320 6e70 0a20 2020 2020 2020  py as np.       
+00009700: 6672 6f6d 2070 7967 7063 2e74 6573 7466  from pygpc.testf
+00009710: 756e 6374 696f 6e73 2069 6d70 6f72 7420  unctions import 
+00009720: 706c 6f74 5f74 6573 7466 756e 6374 696f  plot_testfunctio
+00009730: 6e20 6173 2070 6c6f 740a 2020 2020 2020  n as plot.      
+00009740: 2066 726f 6d20 636f 6c6c 6563 7469 6f6e   from collection
+00009750: 7320 696d 706f 7274 204f 7264 6572 6564  s import Ordered
+00009760: 4469 6374 0a0a 2020 2020 2020 2070 6172  Dict..       par
+00009770: 616d 6574 6572 7320 3d20 4f72 6465 7265  ameters = Ordere
+00009780: 6444 6963 7428 290a 2020 2020 2020 2070  dDict().       p
+00009790: 6172 616d 6574 6572 735b 2278 3122 5d20  arameters["x1"] 
+000097a0: 3d20 6e70 2e6c 696e 7370 6163 6528 2d31  = np.linspace(-1
+000097b0: 3030 2c20 3130 302c 2031 3030 290a 2020  00, 100, 100).  
+000097c0: 2020 2020 2070 6172 616d 6574 6572 735b       parameters[
+000097d0: 2278 3222 5d20 3d20 6e70 2e6c 696e 7370  "x2"] = np.linsp
+000097e0: 6163 6528 2d31 3030 2c20 3130 302c 2031  ace(-100, 100, 1
+000097f0: 3030 290a 0a20 2020 2020 2020 636f 6e73  00)..       cons
+00009800: 7461 6e74 7320 3d20 4e6f 6e65 0a0a 2020  tants = None..  
+00009810: 2020 2020 2070 6c6f 7428 2253 6368 6166       plot("Schaf
+00009820: 6665 7246 756e 6374 696f 6e34 222c 2070  ferFunction4", p
+00009830: 6172 616d 6574 6572 732c 2063 6f6e 7374  arameters, const
+00009840: 616e 7473 2c20 706c 6f74 5f33 643d 4661  ants, plot_3d=Fa
+00009850: 6c73 6529 0a0a 2020 2020 2e2e 205b 315d  lse)..    .. [1]
+00009860: 2054 6573 7420 6675 6e63 7469 6f6e 7320   Test functions 
+00009870: 666f 7220 6f70 7469 6d69 7a61 7469 6f6e  for optimization
+00009880: 2e20 496e 2057 696b 6970 6564 6961 2e0a  . In Wikipedia..
+00009890: 2020 2020 2020 2052 6574 7269 6576 6564         Retrieved
+000098a0: 204a 756e 6520 3230 3133 2c20 6672 6f6d   June 2013, from
+000098b0: 2068 7474 7073 3a2f 2f65 6e2e 7769 6b69   https://en.wiki
+000098c0: 7065 6469 612e 6f72 672f 7769 6b69 2f54  pedia.org/wiki/T
+000098d0: 6573 745f 6675 6e63 7469 6f6e 735f 666f  est_functions_fo
+000098e0: 725f 6f70 7469 6d69 7a61 7469 6f6e 2e0a  r_optimization..
+000098f0: 0a20 2020 202e 2e20 5b32 5d20 6874 7470  .    .. [2] http
+00009900: 733a 2f2f 7777 772e 7366 752e 6361 2f7e  s://www.sfu.ca/~
+00009910: 7373 7572 6a61 6e6f 2f73 6368 6166 6665  ssurjano/schaffe
+00009920: 7234 2e68 746d 6c0a 2020 2020 2222 220a  r4.html.    """.
+00009930: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
+00009940: 5f28 7365 6c66 2c20 6d61 746c 6162 5f6d  _(self, matlab_m
+00009950: 6f64 656c 3d46 616c 7365 293a 0a20 2020  odel=False):.   
+00009960: 2020 2020 2073 7570 6572 2874 7970 6528       super(type(
+00009970: 7365 6c66 292c 2073 656c 6629 2e5f 5f69  self), self).__i
+00009980: 6e69 745f 5f28 6d61 746c 6162 5f6d 6f64  nit__(matlab_mod
+00009990: 656c 3d6d 6174 6c61 625f 6d6f 6465 6c29  el=matlab_model)
+000099a0: 0a20 2020 2020 2020 2073 656c 662e 666e  .        self.fn
+000099b0: 616d 6520 3d20 696e 7370 6563 742e 6765  ame = inspect.ge
+000099c0: 7466 696c 6528 696e 7370 6563 742e 6375  tfile(inspect.cu
+000099d0: 7272 656e 7466 7261 6d65 2829 290a 0a20  rrentframe()).. 
+000099e0: 2020 2064 6566 2076 616c 6964 6174 6528     def validate(
+000099f0: 7365 6c66 293a 0a20 2020 2020 2020 2070  self):.        p
+00009a00: 6173 730a 0a20 2020 2064 6566 2073 696d  ass..    def sim
+00009a10: 756c 6174 6528 7365 6c66 2c20 7072 6f63  ulate(self, proc
+00009a20: 6573 735f 6964 3d4e 6f6e 652c 206d 6174  ess_id=None, mat
+00009a30: 6c61 625f 656e 6769 6e65 3d4e 6f6e 6529  lab_engine=None)
+00009a40: 3a0a 0a20 2020 2020 2020 2079 203d 2030  :..        y = 0
+00009a50: 2e35 202b 2028 6e70 2e63 6f73 286e 702e  .5 + (np.cos(np.
+00009a60: 7369 6e28 6e70 2e61 6273 2873 656c 662e  sin(np.abs(self.
+00009a70: 705b 2278 3122 5d20 2a2a 2032 202d 2073  p["x1"] ** 2 - s
+00009a80: 656c 662e 705b 2278 3222 5d20 2a2a 2032  elf.p["x2"] ** 2
+00009a90: 2929 2920 2d20 302e 3529 202f 5c0a 2020  ))) - 0.5) /\.  
+00009aa0: 2020 2020 2020 2020 2020 2831 202b 2030            (1 + 0
+00009ab0: 2e30 3031 202a 2028 7365 6c66 2e70 5b22  .001 * (self.p["
+00009ac0: 7831 225d 202a 2a20 3220 2b20 7365 6c66  x1"] ** 2 + self
+00009ad0: 2e70 5b22 7832 225d 202a 2a20 3229 2920  .p["x2"] ** 2)) 
+00009ae0: 2a2a 2032 0a0a 2020 2020 2020 2020 795f  ** 2..        y_
+00009af0: 6f75 7420 3d20 795b 3a2c 206e 702e 6e65  out = y[:, np.ne
+00009b00: 7761 7869 735d 0a0a 2020 2020 2020 2020  waxis]..        
+00009b10: 7265 7475 726e 2079 5f6f 7574 0a0a 0a63  return y_out...c
+00009b20: 6c61 7373 2053 7068 6572 6546 756e 6374  lass SphereFunct
+00009b30: 696f 6e28 4162 7374 7261 6374 4d6f 6465  ion(AbstractMode
+00009b40: 6c29 3a0a 2020 2020 2222 220a 2020 2020  l):.    """.    
+00009b50: 642d 6469 6d65 6e73 696f 6e61 6c20 5370  d-dimensional Sp
+00009b60: 6865 7265 2046 756e 6374 696f 6e20 5b31  here Function [1
+00009b70: 5d5b 325d 5b33 5d5b 345d 2e0a 2020 2020  ][2][3][4]..    
+00009b80: 5468 6520 5370 6865 7265 2066 756e 6374  The Sphere funct
+00009b90: 696f 6e20 6861 7320 6420 6c6f 6361 6c20  ion has d local 
+00009ba0: 6d69 6e69 6d61 2065 7863 6570 7420 666f  minima except fo
+00009bb0: 7220 7468 6520 676c 6f62 616c 206f 6e65  r the global one
+00009bc0: 2e20 4974 2069 7320 636f 6e74 696e 756f  . It is continuo
+00009bd0: 7573 2c20 636f 6e76 6578 2061 6e64 2075  us, convex and u
+00009be0: 6e69 6d6f 6461 6c2e 0a20 2020 2054 6865  nimodal..    The
+00009bf0: 2070 6c6f 7420 7368 6f77 7320 6974 7320   plot shows its 
+00009c00: 7477 6f2d 6469 6d65 6e73 696f 6e61 6c20  two-dimensional 
+00009c10: 666f 726d 2e0a 0a20 2020 202e 2e20 6d61  form...    .. ma
+00009c20: 7468 3a3a 0a20 2020 2020 2020 2020 7920  th::.         y 
+00009c30: 3d20 5c5c 7375 6d5f 7b69 3d31 7d5e 7b64  = \\sum_{i=1}^{d
+00009c40: 7d78 5f69 5e32 0a0a 2020 2020 5061 7261  }x_i^2..    Para
+00009c50: 6d65 7465 7273 0a20 2020 202d 2d2d 2d2d  meters.    -----
+00009c60: 2d2d 2d2d 2d0a 2020 2020 705b 2278 3122  -----.    p["x1"
+00009c70: 5d3a 2066 6c6f 6174 206f 7220 6e64 6172  ]: float or ndar
+00009c80: 7261 7920 6f66 2066 6c6f 6174 205b 6e5f  ray of float [n_
+00009c90: 6772 6964 5d0a 2020 2020 2020 2020 4669  grid].        Fi
+00009ca0: 7273 7420 7061 7261 6d65 7465 7220 6465  rst parameter de
+00009cb0: 6669 6e65 6420 696e 205b 2d35 2e31 322c  fined in [-5.12,
+00009cc0: 2035 2e31 325d 0a20 2020 2070 5b22 7832   5.12].    p["x2
+00009cd0: 225d 3a20 666c 6f61 7420 6f72 206e 6461  "]: float or nda
+00009ce0: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
+00009cf0: 5f67 7269 645d 0a20 2020 2020 2020 2073  _grid].        s
+00009d00: 6563 6f6e 6420 7061 7261 6d65 7465 7220  econd parameter 
+00009d10: 6465 6669 6e65 6420 696e 205b 2d35 2e31  defined in [-5.1
+00009d20: 322c 2035 2e31 325d 0a0a 2020 2020 5265  2, 5.12]..    Re
+00009d30: 7475 726e 730a 2020 2020 2d2d 2d2d 2d2d  turns.    ------
+00009d40: 2d0a 2020 2020 793a 206e 6461 7272 6179  -.    y: ndarray
+00009d50: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
+00009d60: 6420 7820 315d 0a20 2020 2020 2020 204f  d x 1].        O
+00009d70: 7574 7075 740a 0a20 2020 204e 6f74 6573  utput..    Notes
+00009d80: 0a20 2020 202d 2d2d 2d2d 0a20 2020 202e  .    -----.    .
+00009d90: 2e20 706c 6f74 3a3a 0a0a 2020 2020 2020  . plot::..      
+00009da0: 2069 6d70 6f72 7420 6e75 6d70 7920 6173   import numpy as
+00009db0: 206e 700a 2020 2020 2020 2066 726f 6d20   np.       from 
+00009dc0: 7079 6770 632e 7465 7374 6675 6e63 7469  pygpc.testfuncti
+00009dd0: 6f6e 7320 696d 706f 7274 2070 6c6f 745f  ons import plot_
+00009de0: 7465 7374 6675 6e63 7469 6f6e 2061 7320  testfunction as 
+00009df0: 706c 6f74 0a20 2020 2020 2020 6672 6f6d  plot.       from
+00009e00: 2063 6f6c 6c65 6374 696f 6e73 2069 6d70   collections imp
+00009e10: 6f72 7420 4f72 6465 7265 6444 6963 740a  ort OrderedDict.
+00009e20: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
+00009e30: 7273 203d 204f 7264 6572 6564 4469 6374  rs = OrderedDict
+00009e40: 2829 0a20 2020 2020 2020 7061 7261 6d65  ().       parame
+00009e50: 7465 7273 5b22 7831 225d 203d 206e 702e  ters["x1"] = np.
+00009e60: 6c69 6e73 7061 6365 282d 352e 3132 2c20  linspace(-5.12, 
+00009e70: 352e 3132 2c20 3130 3029 0a20 2020 2020  5.12, 100).     
+00009e80: 2020 7061 7261 6d65 7465 7273 5b22 7832    parameters["x2
+00009e90: 225d 203d 206e 702e 6c69 6e73 7061 6365  "] = np.linspace
+00009ea0: 282d 352e 3132 2c20 352e 3132 2c20 3130  (-5.12, 5.12, 10
+00009eb0: 3029 0a0a 2020 2020 2020 2063 6f6e 7374  0)..       const
+00009ec0: 616e 7473 203d 204e 6f6e 650a 0a20 2020  ants = None..   
+00009ed0: 2020 2020 706c 6f74 2822 5370 6865 7265      plot("Sphere
+00009ee0: 4675 6e63 7469 6f6e 222c 2070 6172 616d  Function", param
+00009ef0: 6574 6572 732c 2063 6f6e 7374 616e 7473  eters, constants
+00009f00: 2c20 706c 6f74 5f33 643d 4661 6c73 6529  , plot_3d=False)
+00009f10: 0a0a 2020 2020 2e2e 205b 315d 4469 786f  ..    .. [1]Dixo
+00009f20: 6e2c 204c 2e20 432e 2057 2e2c 2026 2053  n, L. C. W., & S
+00009f30: 7a65 676f 2c20 472e 2050 2e20 2831 3937  zego, G. P. (197
+00009f40: 3829 2e20 5468 6520 676c 6f62 616c 206f  8). The global o
+00009f50: 7074 696d 697a 6174 696f 6e20 7072 6f62  ptimization prob
+00009f60: 6c65 6d3a 2061 6e20 696e 7472 6f64 7563  lem: an introduc
+00009f70: 7469 6f6e 2e0a 2020 2020 2020 2054 6f77  tion..       Tow
+00009f80: 6172 6473 2067 6c6f 6261 6c20 6f70 7469  ards global opti
+00009f90: 6d69 7a61 7469 6f6e 2c20 322c 2031 2d31  mization, 2, 1-1
+00009fa0: 352e 0a20 2020 202e 2e20 5b32 5d20 4d6f  5..    .. [2] Mo
+00009fb0: 6c67 612c 204d 2e2c 2026 2053 6d75 746e  lga, M., & Smutn
+00009fc0: 6963 6b69 2c20 432e 2054 6573 7420 6675  icki, C. Test fu
+00009fd0: 6e63 7469 6f6e 7320 666f 7220 6f70 7469  nctions for opti
+00009fe0: 6d69 7a61 7469 6f6e 206e 6565 6473 2028  mization needs (
+00009ff0: 3230 3035 292e 2052 6574 7269 6576 6564  2005). Retrieved
+0000a000: 204a 756e 6520 3230 3133 2c0a 2020 2020   June 2013,.    
+0000a010: 2020 2066 726f 6d20 6874 7470 3a2f 2f77     from http://w
+0000a020: 7777 2e7a 7364 2e69 6374 2e70 7772 2e77  ww.zsd.ict.pwr.w
+0000a030: 726f 632e 706c 2f66 696c 6573 2f64 6f63  roc.pl/files/doc
+0000a040: 732f 6675 6e63 7469 6f6e 732e 7064 662e  s/functions.pdf.
+0000a050: 0a20 2020 202e 2e20 5b33 5d50 6963 6865  .    .. [3]Piche
+0000a060: 6e79 2c20 562e 2c20 5761 676e 6572 2c20  ny, V., Wagner, 
+0000a070: 542e 2c20 2620 4769 6e73 626f 7572 6765  T., & Ginsbourge
+0000a080: 722c 2044 2e20 2832 3031 3229 2e0a 2020  r, D. (2012)..  
+0000a090: 2020 2020 2041 2062 656e 6368 6d61 726b       A benchmark
+0000a0a0: 206f 6620 6b72 6967 696e 672d 6261 7365   of kriging-base
+0000a0b0: 6420 696e 6669 6c6c 2063 7269 7465 7269  d infill criteri
+0000a0c0: 6120 666f 7220 6e6f 6973 7920 6f70 7469  a for noisy opti
+0000a0d0: 6d69 7a61 7469 6f6e 2e0a 2020 2020 2e2e  mization..    ..
+0000a0e0: 205b 345d 6874 7470 733a 2f2f 7777 772e   [4]https://www.
+0000a0f0: 7366 752e 6361 2f7e 7373 7572 6a61 6e6f  sfu.ca/~ssurjano
+0000a100: 2f73 7068 6572 6566 2e68 746d 6c0a 2020  /spheref.html.  
+0000a110: 2020 2222 220a 0a20 2020 2064 6566 205f    """..    def _
+0000a120: 5f69 6e69 745f 5f28 7365 6c66 2c20 6d61  _init__(self, ma
+0000a130: 746c 6162 5f6d 6f64 656c 3d46 616c 7365  tlab_model=False
+0000a140: 293a 0a20 2020 2020 2020 2073 7570 6572  ):.        super
+0000a150: 2874 7970 6528 7365 6c66 292c 2073 656c  (type(self), sel
+0000a160: 6629 2e5f 5f69 6e69 745f 5f28 6d61 746c  f).__init__(matl
+0000a170: 6162 5f6d 6f64 656c 3d6d 6174 6c61 625f  ab_model=matlab_
+0000a180: 6d6f 6465 6c29 0a20 2020 2020 2020 2073  model).        s
+0000a190: 656c 662e 666e 616d 6520 3d20 696e 7370  elf.fname = insp
+0000a1a0: 6563 742e 6765 7466 696c 6528 696e 7370  ect.getfile(insp
+0000a1b0: 6563 742e 6375 7272 656e 7466 7261 6d65  ect.currentframe
+0000a1c0: 2829 290a 0a20 2020 2064 6566 2076 616c  ())..    def val
+0000a1d0: 6964 6174 6528 7365 6c66 293a 0a20 2020  idate(self):.   
+0000a1e0: 2020 2020 2070 6173 730a 0a20 2020 2064       pass..    d
+0000a1f0: 6566 2073 696d 756c 6174 6528 7365 6c66  ef simulate(self
+0000a200: 2c20 7072 6f63 6573 735f 6964 3d4e 6f6e  , process_id=Non
+0000a210: 652c 206d 6174 6c61 625f 656e 6769 6e65  e, matlab_engine
+0000a220: 3d4e 6f6e 6529 3a0a 0a20 2020 2020 2020  =None):..       
+0000a230: 2066 6f72 2069 2c20 6b65 7920 696e 2065   for i, key in e
+0000a240: 6e75 6d65 7261 7465 2873 656c 662e 702e  numerate(self.p.
+0000a250: 6b65 7973 2829 293a 0a20 2020 2020 2020  keys()):.       
+0000a260: 2020 2020 2069 6620 7479 7065 2873 656c       if type(sel
+0000a270: 662e 705b 6b65 795d 2920 6973 206e 702e  f.p[key]) is np.
+0000a280: 6e64 6172 7261 793a 0a20 2020 2020 2020  ndarray:.       
+0000a290: 2020 2020 2020 2020 2073 656c 662e 705b           self.p[
+0000a2a0: 6b65 795d 203d 2073 656c 662e 705b 6b65  key] = self.p[ke
+0000a2b0: 795d 2e66 6c61 7474 656e 2829 0a0a 2020  y].flatten()..  
+0000a2c0: 2020 2020 2020 2320 6465 7465 726d 696e        # determin
+0000a2d0: 6520 7375 6d0a 2020 2020 2020 2020 7920  e sum.        y 
+0000a2e0: 3d20 6e70 2e7a 6572 6f73 286e 702e 6172  = np.zeros(np.ar
+0000a2f0: 7261 7928 7365 6c66 2e70 5b6c 6973 7428  ray(self.p[list(
+0000a300: 7365 6c66 2e70 2e6b 6579 7328 2929 5b30  self.p.keys())[0
+0000a310: 5d5d 292e 7369 7a65 290a 2020 2020 2020  ]]).size).      
+0000a320: 2020 6b65 7973 203d 206c 6973 7428 7365    keys = list(se
+0000a330: 6c66 2e70 2e6b 6579 7328 2929 0a0a 2020  lf.p.keys())..  
+0000a340: 2020 2020 2020 666f 7220 692c 2069 5f6b        for i, i_k
+0000a350: 6579 2069 6e20 656e 756d 6572 6174 6528  ey in enumerate(
+0000a360: 6b65 7973 293a 0a20 2020 2020 2020 2020  keys):.         
+0000a370: 2020 2020 2020 7920 2b3d 2073 656c 662e        y += self.
+0000a380: 705b 695f 6b65 795d 202a 2a20 320a 0a20  p[i_key] ** 2.. 
+0000a390: 2020 2020 2020 2079 5f6f 7574 203d 2079         y_out = y
+0000a3a0: 5b3a 2c20 6e70 2e6e 6577 6178 6973 5d0a  [:, np.newaxis].
+0000a3b0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0000a3c0: 795f 6f75 740a 0a0a 636c 6173 7320 4c69  y_out...class Li
+0000a3d0: 6e32 436f 7570 6c65 6428 4162 7374 7261  n2Coupled(Abstra
+0000a3e0: 6374 4d6f 6465 6c29 3a0a 2020 2020 2222  ctModel):.    ""
+0000a3f0: 220a 2020 2020 642d 6469 6d65 6e73 696f  ".    d-dimensio
+0000a400: 6e61 6c20 4c69 6e32 436f 7570 6c65 6420  nal Lin2Coupled 
+0000a410: 4675 6e63 7469 6f6e 2e0a 2020 2020 5468  Function..    Th
+0000a420: 6520 4c69 6e32 436f 7570 6c65 6420 6675  e Lin2Coupled fu
+0000a430: 6e63 7469 6f6e 2069 7320 636f 6e74 696e  nction is contin
+0000a440: 756f 7573 2c20 636f 6e76 6578 2061 6e64  uous, convex and
+0000a450: 2075 6e69 6d6f 6461 6c2e 0a20 2020 2054   unimodal..    T
+0000a460: 6865 2070 6c6f 7420 7368 6f77 7320 6974  he plot shows it
+0000a470: 7320 7477 6f2d 6469 6d65 6e73 696f 6e61  s two-dimensiona
+0000a480: 6c20 666f 726d 2e0a 0a20 2020 202e 2e20  l form...    .. 
+0000a490: 6d61 7468 3a3a 0a20 2020 2020 2020 2020  math::.         
+0000a4a0: 7920 3d20 5c5c 7375 6d5f 7b69 3d31 7d5e  y = \\sum_{i=1}^
+0000a4b0: 7b64 7d78 5f69 2078 5f7b 692b 317d 0a0a  {d}x_i x_{i+1}..
+0000a4c0: 2020 2020 5061 7261 6d65 7465 7273 0a20      Parameters. 
+0000a4d0: 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020     ----------.  
+0000a4e0: 2020 705b 2278 3122 5d3a 2066 6c6f 6174    p["x1"]: float
+0000a4f0: 206f 7220 6e64 6172 7261 7920 6f66 2066   or ndarray of f
+0000a500: 6c6f 6174 205b 6e5f 6772 6964 5d0a 2020  loat [n_grid].  
+0000a510: 2020 2020 2020 4669 7273 7420 7061 7261        First para
+0000a520: 6d65 7465 7220 6465 6669 6e65 6420 696e  meter defined in
+0000a530: 205b 2d31 2c20 315d 0a20 2020 2070 5b22   [-1, 1].    p["
+0000a540: 7832 225d 3a20 666c 6f61 7420 6f72 206e  x2"]: float or n
+0000a550: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+0000a560: 5b6e 5f67 7269 645d 0a20 2020 2020 2020  [n_grid].       
+0000a570: 2073 6563 6f6e 6420 7061 7261 6d65 7465   second paramete
+0000a580: 7220 6465 6669 6e65 6420 696e 205b 2d31  r defined in [-1
+0000a590: 2c20 315d 0a0a 2020 2020 5265 7475 726e  , 1]..    Return
+0000a5a0: 730a 2020 2020 2d2d 2d2d 2d2d 2d0a 2020  s.    -------.  
+0000a5b0: 2020 793a 206e 6461 7272 6179 206f 6620    y: ndarray of 
+0000a5c0: 666c 6f61 7420 5b6e 5f67 7269 6420 7820  float [n_grid x 
+0000a5d0: 315d 0a20 2020 2020 2020 204f 7574 7075  1].        Outpu
+0000a5e0: 740a 0a20 2020 204e 6f74 6573 0a20 2020  t..    Notes.   
+0000a5f0: 202d 2d2d 2d2d 0a20 2020 202e 2e20 706c   -----.    .. pl
+0000a600: 6f74 3a3a 0a0a 2020 2020 2020 2069 6d70  ot::..       imp
+0000a610: 6f72 7420 6e75 6d70 7920 6173 206e 700a  ort numpy as np.
+0000a620: 2020 2020 2020 2066 726f 6d20 7079 6770         from pygp
+0000a630: 632e 7465 7374 6675 6e63 7469 6f6e 7320  c.testfunctions 
+0000a640: 696d 706f 7274 2070 6c6f 745f 7465 7374  import plot_test
+0000a650: 6675 6e63 7469 6f6e 2061 7320 706c 6f74  function as plot
+0000a660: 0a20 2020 2020 2020 6672 6f6d 2063 6f6c  .       from col
+0000a670: 6c65 6374 696f 6e73 2069 6d70 6f72 7420  lections import 
+0000a680: 4f72 6465 7265 6444 6963 740a 0a20 2020  OrderedDict..   
+0000a690: 2020 2020 7061 7261 6d65 7465 7273 203d      parameters =
+0000a6a0: 204f 7264 6572 6564 4469 6374 2829 0a20   OrderedDict(). 
+0000a6b0: 2020 2020 2020 7061 7261 6d65 7465 7273        parameters
+0000a6c0: 5b22 7831 225d 203d 206e 702e 6c69 6e73  ["x1"] = np.lins
+0000a6d0: 7061 6365 282d 312c 2031 2c20 3130 3029  pace(-1, 1, 100)
+0000a6e0: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
+0000a6f0: 7273 5b22 7832 225d 203d 206e 702e 6c69  rs["x2"] = np.li
+0000a700: 6e73 7061 6365 282d 312c 2031 2c20 3130  nspace(-1, 1, 10
+0000a710: 3029 0a0a 2020 2020 2020 2063 6f6e 7374  0)..       const
+0000a720: 616e 7473 203d 204e 6f6e 650a 0a20 2020  ants = None..   
+0000a730: 2020 2020 706c 6f74 2822 4c69 6e32 436f      plot("Lin2Co
+0000a740: 7570 6c65 6422 2c20 7061 7261 6d65 7465  upled", paramete
+0000a750: 7273 2c20 636f 6e73 7461 6e74 732c 2070  rs, constants, p
+0000a760: 6c6f 745f 3364 3d46 616c 7365 290a 0a20  lot_3d=False).. 
+0000a770: 2020 202e 2e20 5b31 5d20 416c 656d 617a     .. [1] Alemaz
+0000a780: 6b6f 6f72 2c20 4e2e 2c20 2620 4d65 6964  koor, N., & Meid
+0000a790: 616e 692c 2048 2e20 2832 3031 3829 2e20  ani, H. (2018). 
+0000a7a0: 4120 6e65 6172 2d6f 7074 696d 616c 2073  A near-optimal s
+0000a7b0: 616d 706c 696e 6720 7374 7261 7465 6779  ampling strategy
+0000a7c0: 2066 6f72 2073 7061 7273 6520 7265 636f   for sparse reco
+0000a7d0: 7665 7279 206f 660a 2020 2020 2020 2070  very of.       p
+0000a7e0: 6f6c 796e 6f6d 6961 6c20 6368 616f 7320  olynomial chaos 
+0000a7f0: 6578 7061 6e73 696f 6e73 2e20 4a6f 7572  expansions. Jour
+0000a800: 6e61 6c20 6f66 2043 6f6d 7075 7461 7469  nal of Computati
+0000a810: 6f6e 616c 2050 6879 7369 6373 2c20 3337  onal Physics, 37
+0000a820: 312c 2031 3337 2d31 3531 2e0a 2020 2020  1, 137-151..    
+0000a830: 2222 220a 0a20 2020 2064 6566 205f 5f69  """..    def __i
+0000a840: 6e69 745f 5f28 7365 6c66 2c20 6d61 746c  nit__(self, matl
+0000a850: 6162 5f6d 6f64 656c 3d46 616c 7365 293a  ab_model=False):
+0000a860: 0a20 2020 2020 2020 2073 7570 6572 2874  .        super(t
+0000a870: 7970 6528 7365 6c66 292c 2073 656c 6629  ype(self), self)
+0000a880: 2e5f 5f69 6e69 745f 5f28 6d61 746c 6162  .__init__(matlab
+0000a890: 5f6d 6f64 656c 3d6d 6174 6c61 625f 6d6f  _model=matlab_mo
+0000a8a0: 6465 6c29 0a20 2020 2020 2020 2073 656c  del).        sel
+0000a8b0: 662e 666e 616d 6520 3d20 696e 7370 6563  f.fname = inspec
+0000a8c0: 742e 6765 7466 696c 6528 696e 7370 6563  t.getfile(inspec
+0000a8d0: 742e 6375 7272 656e 7466 7261 6d65 2829  t.currentframe()
+0000a8e0: 290a 0a20 2020 2064 6566 2076 616c 6964  )..    def valid
+0000a8f0: 6174 6528 7365 6c66 293a 0a20 2020 2020  ate(self):.     
+0000a900: 2020 2070 6173 730a 0a20 2020 2064 6566     pass..    def
+0000a910: 2073 696d 756c 6174 6528 7365 6c66 2c20   simulate(self, 
+0000a920: 7072 6f63 6573 735f 6964 3d4e 6f6e 652c  process_id=None,
+0000a930: 206d 6174 6c61 625f 656e 6769 6e65 3d4e   matlab_engine=N
+0000a940: 6f6e 6529 3a0a 0a20 2020 2020 2020 2066  one):..        f
+0000a950: 6f72 2069 2c20 6b65 7920 696e 2065 6e75  or i, key in enu
+0000a960: 6d65 7261 7465 2873 656c 662e 702e 6b65  merate(self.p.ke
+0000a970: 7973 2829 293a 0a20 2020 2020 2020 2020  ys()):.         
+0000a980: 2020 2069 6620 7479 7065 2873 656c 662e     if type(self.
+0000a990: 705b 6b65 795d 2920 6973 206e 702e 6e64  p[key]) is np.nd
+0000a9a0: 6172 7261 793a 0a20 2020 2020 2020 2020  array:.         
+0000a9b0: 2020 2020 2020 2073 656c 662e 705b 6b65         self.p[ke
+0000a9c0: 795d 203d 2073 656c 662e 705b 6b65 795d  y] = self.p[key]
+0000a9d0: 2e66 6c61 7474 656e 2829 0a0a 2020 2020  .flatten()..    
+0000a9e0: 2020 2020 2320 6465 7465 726d 696e 6520      # determine 
+0000a9f0: 7375 6d0a 2020 2020 2020 2020 7920 3d20  sum.        y = 
+0000aa00: 6e70 2e7a 6572 6f73 286e 702e 6172 7261  np.zeros(np.arra
+0000aa10: 7928 7365 6c66 2e70 5b6c 6973 7428 7365  y(self.p[list(se
+0000aa20: 6c66 2e70 2e6b 6579 7328 2929 5b30 5d5d  lf.p.keys())[0]]
+0000aa30: 292e 7369 7a65 290a 2020 2020 2020 2020  ).size).        
+0000aa40: 6b65 7973 203d 206c 6973 7428 7365 6c66  keys = list(self
+0000aa50: 2e70 2e6b 6579 7328 2929 0a0a 2020 2020  .p.keys())..    
+0000aa60: 2020 2020 666f 7220 692c 2069 5f6b 6579      for i, i_key
+0000aa70: 2069 6e20 656e 756d 6572 6174 6528 6b65   in enumerate(ke
+0000aa80: 7973 293a 0a20 2020 2020 2020 2020 2020  ys):.           
+0000aa90: 2069 6620 6920 3c20 286c 656e 286b 6579   if i < (len(key
+0000aaa0: 7329 2d31 293a 0a20 2020 2020 2020 2020  s)-1):.         
+0000aab0: 2020 2020 2020 2079 202b 3d20 7365 6c66         y += self
+0000aac0: 2e70 5b6b 6579 735b 695d 5d20 2a20 7365  .p[keys[i]] * se
+0000aad0: 6c66 2e70 5b6b 6579 735b 692b 315d 5d0a  lf.p[keys[i+1]].
+0000aae0: 0a20 2020 2020 2020 2079 5f6f 7574 203d  .        y_out =
+0000aaf0: 2079 5b3a 2c20 6e70 2e6e 6577 6178 6973   y[:, np.newaxis
+0000ab00: 5d0a 0a20 2020 2020 2020 2072 6574 7572  ]..        retur
+0000ab10: 6e20 795f 6f75 740a 0a0a 636c 6173 7320  n y_out...class 
+0000ab20: 4d63 436f 726d 6963 6b46 756e 6374 696f  McCormickFunctio
+0000ab30: 6e28 4162 7374 7261 6374 4d6f 6465 6c29  n(AbstractModel)
+0000ab40: 3a0a 2020 2020 2222 220a 2020 2020 322d  :.    """.    2-
+0000ab50: 6469 6d65 6e73 696f 6e61 6c20 4d63 436f  dimensional McCo
+0000ab60: 726d 6963 6b20 4675 6e63 7469 6f6e 205b  rmick Function [
+0000ab70: 315d 5b32 5d2e 0a0a 2020 2020 2e2e 206d  1][2]...    .. m
+0000ab80: 6174 683a 3a0a 2020 2020 2020 7920 3d20  ath::.      y = 
+0000ab90: 5c5c 7369 6e28 785f 312b 785f 3229 2b28  \\sin(x_1+x_2)+(
+0000aba0: 785f 312d 785f 3229 5e32 2d31 2e35 785f  x_1-x_2)^2-1.5x_
+0000abb0: 312b 322e 3578 5f32 2b31 0a0a 2020 2020  1+2.5x_2+1..    
+0000abc0: 5061 7261 6d65 7465 7273 0a20 2020 202d  Parameters.    -
+0000abd0: 2d2d 2d2d 2d2d 2d2d 2d0a 2020 2020 705b  ---------.    p[
+0000abe0: 2278 3122 5d3a 2066 6c6f 6174 206f 7220  "x1"]: float or 
+0000abf0: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
+0000ac00: 205b 6e5f 6772 6964 5d0a 2020 2020 2020   [n_grid].      
+0000ac10: 2020 4669 7273 7420 7061 7261 6d65 7465    First paramete
+0000ac20: 7220 6465 6669 6e65 6420 696e 205b 2d31  r defined in [-1
+0000ac30: 2e35 2c20 345d 0a20 2020 2070 5b22 7832  .5, 4].    p["x2
+0000ac40: 225d 3a20 666c 6f61 7420 6f72 206e 6461  "]: float or nda
+0000ac50: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
+0000ac60: 5f67 7269 645d 0a20 2020 2020 2020 2073  _grid].        s
+0000ac70: 6563 6f6e 6420 7061 7261 6d65 7465 7220  econd parameter 
+0000ac80: 6465 6669 6e65 6420 696e 205b 2d33 2c20  defined in [-3, 
+0000ac90: 345d 0a0a 2020 2020 5265 7475 726e 730a  4]..    Returns.
+0000aca0: 2020 2020 2d2d 2d2d 2d2d 2d0a 2020 2020      -------.    
+0000acb0: 793a 206e 6461 7272 6179 206f 6620 666c  y: ndarray of fl
+0000acc0: 6f61 7420 5b6e 5f67 7269 6420 7820 315d  oat [n_grid x 1]
+0000acd0: 0a20 2020 2020 2020 204f 7574 7075 740a  .        Output.
+0000ace0: 0a20 2020 204e 6f74 6573 0a20 2020 202d  .    Notes.    -
+0000acf0: 2d2d 2d2d 0a20 2020 202e 2e20 706c 6f74  ----.    .. plot
+0000ad00: 3a3a 0a0a 2020 2020 2020 2069 6d70 6f72  ::..       impor
+0000ad10: 7420 6e75 6d70 7920 6173 206e 700a 2020  t numpy as np.  
+0000ad20: 2020 2020 2066 726f 6d20 7079 6770 632e       from pygpc.
+0000ad30: 7465 7374 6675 6e63 7469 6f6e 7320 696d  testfunctions im
+0000ad40: 706f 7274 2070 6c6f 745f 7465 7374 6675  port plot_testfu
+0000ad50: 6e63 7469 6f6e 2061 7320 706c 6f74 0a20  nction as plot. 
+0000ad60: 2020 2020 2020 6672 6f6d 2063 6f6c 6c65        from colle
+0000ad70: 6374 696f 6e73 2069 6d70 6f72 7420 4f72  ctions import Or
+0000ad80: 6465 7265 6444 6963 740a 0a20 2020 2020  deredDict..     
+0000ad90: 2020 7061 7261 6d65 7465 7273 203d 204f    parameters = O
+0000ada0: 7264 6572 6564 4469 6374 2829 0a20 2020  rderedDict().   
+0000adb0: 2020 2020 7061 7261 6d65 7465 7273 5b22      parameters["
+0000adc0: 7831 225d 203d 206e 702e 6c69 6e73 7061  x1"] = np.linspa
+0000add0: 6365 282d 312e 352c 2034 2c20 3130 3029  ce(-1.5, 4, 100)
+0000ade0: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
+0000adf0: 7273 5b22 7832 225d 203d 206e 702e 6c69  rs["x2"] = np.li
+0000ae00: 6e73 7061 6365 282d 332c 2034 2c20 3130  nspace(-3, 4, 10
+0000ae10: 3029 0a0a 2020 2020 2020 2063 6f6e 7374  0)..       const
+0000ae20: 616e 7473 203d 204e 6f6e 650a 0a20 2020  ants = None..   
+0000ae30: 2020 2020 706c 6f74 2822 4d63 436f 726d      plot("McCorm
+0000ae40: 6963 6b46 756e 6374 696f 6e22 2c20 7061  ickFunction", pa
+0000ae50: 7261 6d65 7465 7273 2c20 636f 6e73 7461  rameters, consta
+0000ae60: 6e74 732c 2070 6c6f 745f 3364 3d46 616c  nts, plot_3d=Fal
+0000ae70: 7365 290a 0a20 2020 202e 2e20 5b31 5d20  se)..    .. [1] 
+0000ae80: 4164 6f72 696f 2c20 452e 2050 2e2c 2026  Adorio, E. P., &
+0000ae90: 2044 696c 696d 616e 2c20 552e 2050 2e20   Diliman, U. P. 
+0000aea0: 4d56 4620 2d20 4d75 6c74 6976 6172 6961  MVF - Multivaria
+0000aeb0: 7465 2054 6573 7420 4675 6e63 7469 6f6e  te Test Function
+0000aec0: 7320 4c69 6272 6172 7920 696e 2043 2066  s Library in C f
+0000aed0: 6f72 2055 6e63 6f6e 7374 7261 696e 6564  or Unconstrained
+0000aee0: 0a20 2020 2020 2020 476c 6f62 616c 204f  .       Global O
+0000aef0: 7074 696d 697a 6174 696f 6e20 2832 3030  ptimization (200
+0000af00: 3529 2e20 5265 7472 6965 7665 6420 4a75  5). Retrieved Ju
+0000af10: 6e65 2032 3031 332c 2066 726f 6d20 6874  ne 2013, from ht
+0000af20: 7470 3a2f 2f68 7474 703a 2f2f 7777 772e  tp://http://www.
+0000af30: 6765 6f63 6974 6965 732e 7773 2f65 6164  geocities.ws/ead
+0000af40: 6f72 696f 2f6d 7666 2e70 6466 2e0a 0a20  orio/mvf.pdf... 
+0000af50: 2020 202e 2e20 5b32 5d20 6874 7470 733a     .. [2] https:
+0000af60: 2f2f 7777 772e 7366 752e 6361 2f7e 7373  //www.sfu.ca/~ss
+0000af70: 7572 6a61 6e6f 2f6d 6363 6f72 6d2e 6874  urjano/mccorm.ht
+0000af80: 6d6c 0a20 2020 2022 2222 0a0a 2020 2020  ml.    """..    
+0000af90: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
+0000afa0: 662c 206d 6174 6c61 625f 6d6f 6465 6c3d  f, matlab_model=
+0000afb0: 4661 6c73 6529 3a0a 2020 2020 2020 2020  False):.        
+0000afc0: 7375 7065 7228 7479 7065 2873 656c 6629  super(type(self)
+0000afd0: 2c20 7365 6c66 292e 5f5f 696e 6974 5f5f  , self).__init__
+0000afe0: 286d 6174 6c61 625f 6d6f 6465 6c3d 6d61  (matlab_model=ma
+0000aff0: 746c 6162 5f6d 6f64 656c 290a 2020 2020  tlab_model).    
+0000b000: 2020 2020 7365 6c66 2e66 6e61 6d65 203d      self.fname =
+0000b010: 2069 6e73 7065 6374 2e67 6574 6669 6c65   inspect.getfile
+0000b020: 2869 6e73 7065 6374 2e63 7572 7265 6e74  (inspect.current
+0000b030: 6672 616d 6528 2929 0a0a 2020 2020 6465  frame())..    de
+0000b040: 6620 7661 6c69 6461 7465 2873 656c 6629  f validate(self)
+0000b050: 3a0a 2020 2020 2020 2020 7061 7373 0a0a  :.        pass..
+0000b060: 2020 2020 6465 6620 7369 6d75 6c61 7465      def simulate
+0000b070: 2873 656c 662c 2070 726f 6365 7373 5f69  (self, process_i
+0000b080: 643d 4e6f 6e65 2c20 6d61 746c 6162 5f65  d=None, matlab_e
+0000b090: 6e67 696e 653d 4e6f 6e65 293a 0a0a 2020  ngine=None):..  
+0000b0a0: 2020 2020 2020 7920 3d20 6e70 2e73 696e        y = np.sin
+0000b0b0: 2873 656c 662e 705b 2278 3122 5d20 2b20  (self.p["x1"] + 
+0000b0c0: 7365 6c66 2e70 5b22 7832 225d 2920 2b20  self.p["x2"]) + 
+0000b0d0: 2873 656c 662e 705b 2278 3122 5d20 2d20  (self.p["x1"] - 
+0000b0e0: 7365 6c66 2e70 5b22 7832 225d 2920 2a2a  self.p["x2"]) **
+0000b0f0: 2032 202d 2031 2e35 202a 2073 656c 662e   2 - 1.5 * self.
+0000b100: 705b 2278 3122 5d20 2b5c 0a20 2020 2020  p["x1"] +\.     
+0000b110: 2020 2020 2020 2020 2020 2020 2020 322e                2.
+0000b120: 3520 2a20 7365 6c66 2e70 5b22 7832 225d  5 * self.p["x2"]
+0000b130: 202b 2031 0a0a 2020 2020 2020 2020 795f   + 1..        y_
+0000b140: 6f75 7420 3d20 795b 3a2c 206e 702e 6e65  out = y[:, np.ne
+0000b150: 7761 7869 735d 0a0a 2020 2020 2020 2020  waxis]..        
+0000b160: 7265 7475 726e 2079 5f6f 7574 0a0a 0a63  return y_out...c
+0000b170: 6c61 7373 2042 6f6f 7468 4675 6e63 7469  lass BoothFuncti
+0000b180: 6f6e 2841 6273 7472 6163 744d 6f64 656c  on(AbstractModel
+0000b190: 293a 0a20 2020 2022 2222 0a20 2020 2032  ):.    """.    2
+0000b1a0: 2d64 696d 656e 7369 6f6e 616c 2042 6f6f  -dimensional Boo
+0000b1b0: 7468 4675 6e63 7469 6f6e 2e5b 315d 5b32  thFunction.[1][2
+0000b1c0: 5d2e 0a0a 2020 2020 2e2e 206d 6174 683a  ]...    .. math:
+0000b1d0: 3a0a 2020 2020 2020 7920 3d20 2878 5f31  :.      y = (x_1
+0000b1e0: 2b32 785f 322d 3729 5e32 2b28 3278 5f31  +2x_2-7)^2+(2x_1
+0000b1f0: 2b78 5f32 2d35 295e 320a 2020 2020 5061  +x_2-5)^2.    Pa
+0000b200: 7261 6d65 7465 7273 0a20 2020 202d 2d2d  rameters.    ---
+0000b210: 2d2d 2d2d 2d2d 2d0a 2020 2020 705b 2278  -------.    p["x
+0000b220: 3122 5d3a 2066 6c6f 6174 206f 7220 6e64  1"]: float or nd
+0000b230: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
+0000b240: 6e5f 6772 6964 5d0a 2020 2020 2020 2020  n_grid].        
+0000b250: 4669 7273 7420 7061 7261 6d65 7465 7220  First parameter 
+0000b260: 6465 6669 6e65 6420 696e 205b 2d31 302c  defined in [-10,
+0000b270: 2031 305d 0a20 2020 2070 5b22 7832 225d   10].    p["x2"]
+0000b280: 3a20 666c 6f61 7420 6f72 206e 6461 7272  : float or ndarr
+0000b290: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
+0000b2a0: 7269 645d 0a20 2020 2020 2020 2073 6563  rid].        sec
+0000b2b0: 6f6e 6420 7061 7261 6d65 7465 7220 6465  ond parameter de
+0000b2c0: 6669 6e65 6420 696e 205b 2d31 302c 2031  fined in [-10, 1
+0000b2d0: 305d 0a0a 2020 2020 5265 7475 726e 730a  0]..    Returns.
+0000b2e0: 2020 2020 2d2d 2d2d 2d2d 2d0a 2020 2020      -------.    
+0000b2f0: 793a 206e 6461 7272 6179 206f 6620 666c  y: ndarray of fl
+0000b300: 6f61 7420 5b6e 5f67 7269 6420 7820 315d  oat [n_grid x 1]
+0000b310: 0a20 2020 2020 2020 204f 7574 7075 740a  .        Output.
+0000b320: 0a20 2020 204e 6f74 6573 0a20 2020 202d  .    Notes.    -
+0000b330: 2d2d 2d2d 0a20 2020 202e 2e20 706c 6f74  ----.    .. plot
+0000b340: 3a3a 0a0a 2020 2020 2020 2069 6d70 6f72  ::..       impor
+0000b350: 7420 6e75 6d70 7920 6173 206e 700a 2020  t numpy as np.  
+0000b360: 2020 2020 2066 726f 6d20 7079 6770 632e       from pygpc.
+0000b370: 7465 7374 6675 6e63 7469 6f6e 7320 696d  testfunctions im
+0000b380: 706f 7274 2070 6c6f 745f 7465 7374 6675  port plot_testfu
+0000b390: 6e63 7469 6f6e 2061 7320 706c 6f74 0a20  nction as plot. 
+0000b3a0: 2020 2020 2020 6672 6f6d 2063 6f6c 6c65        from colle
+0000b3b0: 6374 696f 6e73 2069 6d70 6f72 7420 4f72  ctions import Or
+0000b3c0: 6465 7265 6444 6963 740a 0a20 2020 2020  deredDict..     
+0000b3d0: 2020 7061 7261 6d65 7465 7273 203d 204f    parameters = O
+0000b3e0: 7264 6572 6564 4469 6374 2829 0a20 2020  rderedDict().   
+0000b3f0: 2020 2020 7061 7261 6d65 7465 7273 5b22      parameters["
+0000b400: 7831 225d 203d 206e 702e 6c69 6e73 7061  x1"] = np.linspa
+0000b410: 6365 282d 3130 2c20 3130 2c20 3130 3029  ce(-10, 10, 100)
+0000b420: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
+0000b430: 7273 5b22 7832 225d 203d 206e 702e 6c69  rs["x2"] = np.li
+0000b440: 6e73 7061 6365 282d 3130 2c20 3130 2c20  nspace(-10, 10, 
+0000b450: 3130 3029 0a0a 2020 2020 2020 2063 6f6e  100)..       con
+0000b460: 7374 616e 7473 203d 204e 6f6e 650a 0a20  stants = None.. 
+0000b470: 2020 2020 2020 706c 6f74 2822 426f 6f74        plot("Boot
+0000b480: 6846 756e 6374 696f 6e22 2c20 7061 7261  hFunction", para
+0000b490: 6d65 7465 7273 2c20 636f 6e73 7461 6e74  meters, constant
+0000b4a0: 732c 2070 6c6f 745f 3364 3d46 616c 7365  s, plot_3d=False
+0000b4b0: 290a 0a20 2020 202e 2e20 5b31 5d20 476c  )..    .. [1] Gl
+0000b4c0: 6f62 616c 204f 7074 696d 697a 6174 696f  obal Optimizatio
+0000b4d0: 6e20 5465 7374 2050 726f 626c 656d 732e  n Test Problems.
+0000b4e0: 2052 6574 7269 6576 6564 204a 756e 6520   Retrieved June 
+0000b4f0: 3230 3133 2c20 6672 6f6d 0a20 2020 2020  2013, from.     
+0000b500: 2020 6874 7470 3a2f 2f77 7777 2d6f 7074    http://www-opt
+0000b510: 696d 612e 616d 702e 692e 6b79 6f74 6f2d  ima.amp.i.kyoto-
+0000b520: 752e 6163 2e6a 702f 6d65 6d62 6572 2f73  u.ac.jp/member/s
+0000b530: 7475 6465 6e74 2f68 6564 6172 2f48 6564  tudent/hedar/Hed
+0000b540: 6172 5f66 696c 6573 2f54 6573 7447 4f2e  ar_files/TestGO.
+0000b550: 6874 6d2e 0a20 2020 202e 2e20 5b32 5d20  htm..    .. [2] 
+0000b560: 6874 7470 733a 2f2f 7777 772e 7366 752e  https://www.sfu.
+0000b570: 6361 2f7e 7373 7572 6a61 6e6f 2f62 6f6f  ca/~ssurjano/boo
+0000b580: 7468 2e68 746d 6c0a 2020 2020 2222 220a  th.html.    """.
+0000b590: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
+0000b5a0: 5f28 7365 6c66 2c20 6d61 746c 6162 5f6d  _(self, matlab_m
+0000b5b0: 6f64 656c 3d46 616c 7365 293a 0a20 2020  odel=False):.   
+0000b5c0: 2020 2020 2073 7570 6572 2874 7970 6528       super(type(
+0000b5d0: 7365 6c66 292c 2073 656c 6629 2e5f 5f69  self), self).__i
+0000b5e0: 6e69 745f 5f28 6d61 746c 6162 5f6d 6f64  nit__(matlab_mod
+0000b5f0: 656c 3d6d 6174 6c61 625f 6d6f 6465 6c29  el=matlab_model)
+0000b600: 0a20 2020 2020 2020 2073 656c 662e 666e  .        self.fn
+0000b610: 616d 6520 3d20 696e 7370 6563 742e 6765  ame = inspect.ge
+0000b620: 7466 696c 6528 696e 7370 6563 742e 6375  tfile(inspect.cu
+0000b630: 7272 656e 7466 7261 6d65 2829 290a 0a20  rrentframe()).. 
+0000b640: 2020 2064 6566 2076 616c 6964 6174 6528     def validate(
+0000b650: 7365 6c66 293a 0a20 2020 2020 2020 2070  self):.        p
+0000b660: 6173 730a 0a20 2020 2064 6566 2073 696d  ass..    def sim
+0000b670: 756c 6174 6528 7365 6c66 2c20 7072 6f63  ulate(self, proc
+0000b680: 6573 735f 6964 3d4e 6f6e 652c 206d 6174  ess_id=None, mat
+0000b690: 6c61 625f 656e 6769 6e65 3d4e 6f6e 6529  lab_engine=None)
+0000b6a0: 3a0a 0a20 2020 2020 2020 2079 203d 2028  :..        y = (
+0000b6b0: 7365 6c66 2e70 5b22 7831 225d 202b 2032  self.p["x1"] + 2
+0000b6c0: 202a 2073 656c 662e 705b 2278 3222 5d20   * self.p["x2"] 
+0000b6d0: 2d20 3729 202a 2a20 3220 2b20 2832 202a  - 7) ** 2 + (2 *
+0000b6e0: 2073 656c 662e 705b 2278 3122 5d20 2b20   self.p["x1"] + 
+0000b6f0: 7365 6c66 2e70 5b22 7832 225d 202d 2035  self.p["x2"] - 5
+0000b700: 2920 2a2a 2032 0a0a 2020 2020 2020 2020  ) ** 2..        
+0000b710: 795f 6f75 7420 3d20 795b 3a2c 206e 702e  y_out = y[:, np.
+0000b720: 6e65 7761 7869 735d 0a0a 2020 2020 2020  newaxis]..      
+0000b730: 2020 7265 7475 726e 2079 5f6f 7574 0a0a    return y_out..
+0000b740: 0a63 6c61 7373 2050 6561 6b73 2841 6273  .class Peaks(Abs
+0000b750: 7472 6163 744d 6f64 656c 293a 0a20 2020  tractModel):.   
+0000b760: 2022 2222 0a20 2020 2054 6872 6565 2d64   """.    Three-d
+0000b770: 696d 656e 7369 6f6e 616c 2070 6561 6b73  imensional peaks
+0000b780: 2066 756e 6374 696f 6e2e 0a0a 2020 2020   function...    
+0000b790: 2e2e 206d 6174 683a 3a0a 2020 2020 2020  .. math::.      
+0000b7a0: 7920 3d20 3328 312d 785f 3129 5e32 2065  y = 3(1-x_1)^2 e
+0000b7b0: 5e7b 2d28 785f 315e 3229 2d28 785f 332b  ^{-(x_1^2)-(x_3+
+0000b7c0: 3129 5e32 7d2d 3130 285c 5c66 7261 637b  1)^2}-10(\\frac{
+0000b7d0: 785f 317d 7b35 7d2d 785f 315e 332d 785f  x_1}{5}-x_1^3-x_
+0000b7e0: 335e 3529 2065 5e7b 2d78 5f31 5e32 2d78  3^5) e^{-x_1^2-x
+0000b7f0: 5f33 5e32 7d2d 0a20 2020 2020 205c 5c66  _3^2}-.      \\f
+0000b800: 7261 637b 317d 7b33 7d20 655e 7b2d 2878  rac{1}{3} e^{-(x
+0000b810: 5f31 2b31 295e 3220 2d20 785f 335e 327d  _1+1)^2 - x_3^2}
+0000b820: 202b 2078 5f32 0a0a 2020 2020 5061 7261   + x_2..    Para
+0000b830: 6d65 7465 7273 0a20 2020 202d 2d2d 2d2d  meters.    -----
+0000b840: 2d2d 2d2d 2d0a 2020 2020 705b 2278 3122  -----.    p["x1"
+0000b850: 5d3a 2066 6c6f 6174 206f 7220 6e64 6172  ]: float or ndar
+0000b860: 7261 7920 6f66 2066 6c6f 6174 205b 6e5f  ray of float [n_
+0000b870: 6772 6964 5d0a 2020 2020 2020 2020 5061  grid].        Pa
+0000b880: 7261 6d65 7465 7220 310a 2020 2020 705b  rameter 1.    p[
+0000b890: 2278 3222 5d3a 2066 6c6f 6174 206f 7220  "x2"]: float or 
+0000b8a0: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
+0000b8b0: 205b 6e5f 6772 6964 5d0a 2020 2020 2020   [n_grid].      
+0000b8c0: 2020 5061 7261 6d65 7465 7220 320a 2020    Parameter 2.  
+0000b8d0: 2020 705b 2278 3322 5d3a 2066 6c6f 6174    p["x3"]: float
+0000b8e0: 206f 7220 6e64 6172 7261 7920 6f66 2066   or ndarray of f
+0000b8f0: 6c6f 6174 205b 6e5f 6772 6964 5d0a 2020  loat [n_grid].  
+0000b900: 2020 2020 2020 5061 7261 6d65 7465 7220        Parameter 
+0000b910: 330a 0a20 2020 2052 6574 7572 6e73 0a20  3..    Returns. 
+0000b920: 2020 202d 2d2d 2d2d 2d2d 0a20 2020 2079     -------.    y
+0000b930: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
+0000b940: 6174 205b 6e5f 6772 6964 2078 206e 5f6f  at [n_grid x n_o
+0000b950: 7574 5d0a 2020 2020 2020 2020 4f75 7470  ut].        Outp
+0000b960: 7574 2064 6174 610a 2020 2020 6d69 7363  ut data.    misc
+0000b970: 3a20 6469 6374 206f 7220 6c69 7374 206f  : dict or list o
+0000b980: 6620 6469 6374 205b 6e5f 6772 6964 5d0a  f dict [n_grid].
+0000b990: 2020 2020 2020 2020 4164 6469 7469 6f6e          Addition
+0000b9a0: 616c 2064 6174 612c 2077 696c 6c20 6265  al data, will be
+0000b9b0: 2073 6176 6564 2075 6e64 6572 2069 7473   saved under its
+0000b9c0: 206b 6579 7320 696e 2074 6865 202e 6864   keys in the .hd
+0000b9d0: 6635 2066 696c 6520 6475 7269 6e67 2067  f5 file during g
+0000b9e0: 5043 2073 696d 756c 6174 696f 6e73 2066  PC simulations f
+0000b9f0: 6f72 2065 7665 7279 2067 7269 6420 706f  or every grid po
+0000ba00: 696e 740a 0a20 2020 204e 6f74 6573 0a20  int..    Notes. 
+0000ba10: 2020 202d 2d2d 2d2d 0a20 2020 202e 2e20     -----.    .. 
+0000ba20: 706c 6f74 3a3a 0a0a 2020 2020 2020 2069  plot::..       i
+0000ba30: 6d70 6f72 7420 6e75 6d70 7920 6173 206e  mport numpy as n
+0000ba40: 700a 2020 2020 2020 2066 726f 6d20 7079  p.       from py
+0000ba50: 6770 632e 7465 7374 6675 6e63 7469 6f6e  gpc.testfunction
+0000ba60: 7320 696d 706f 7274 2070 6c6f 745f 7465  s import plot_te
+0000ba70: 7374 6675 6e63 7469 6f6e 2061 7320 706c  stfunction as pl
+0000ba80: 6f74 0a20 2020 2020 2020 6672 6f6d 2063  ot.       from c
+0000ba90: 6f6c 6c65 6374 696f 6e73 2069 6d70 6f72  ollections impor
+0000baa0: 7420 4f72 6465 7265 6444 6963 740a 0a20  t OrderedDict.. 
+0000bab0: 2020 2020 2020 7061 7261 6d65 7465 7273        parameters
+0000bac0: 203d 204f 7264 6572 6564 4469 6374 2829   = OrderedDict()
+0000bad0: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
+0000bae0: 7273 5b22 7831 225d 203d 206e 702e 6c69  rs["x1"] = np.li
+0000baf0: 6e73 7061 6365 2830 2c20 312c 2031 3030  nspace(0, 1, 100
+0000bb00: 290a 2020 2020 2020 2070 6172 616d 6574  ).       paramet
+0000bb10: 6572 735b 2278 3222 5d20 3d20 6e70 2e6c  ers["x2"] = np.l
+0000bb20: 696e 7370 6163 6528 302c 2031 2c20 3130  inspace(0, 1, 10
+0000bb30: 3029 0a0a 2020 2020 2020 2063 6f6e 7374  0)..       const
+0000bb40: 616e 7473 203d 204f 7264 6572 6564 4469  ants = OrderedDi
+0000bb50: 6374 2829 0a20 2020 2020 2020 636f 6e73  ct().       cons
+0000bb60: 7461 6e74 735b 2278 3322 5d20 3d20 302e  tants["x3"] = 0.
+0000bb70: 0a20 2020 2020 2020 706c 6f74 2822 5065  .       plot("Pe
+0000bb80: 616b 7322 2c20 7061 7261 6d65 7465 7273  aks", parameters
+0000bb90: 2c20 636f 6e73 7461 6e74 732c 2070 6c6f  , constants, plo
+0000bba0: 745f 3364 3d46 616c 7365 290a 2020 2020  t_3d=False).    
+0000bbb0: 2222 220a 0a20 2020 2064 6566 205f 5f69  """..    def __i
+0000bbc0: 6e69 745f 5f28 7365 6c66 2c20 6d61 746c  nit__(self, matl
+0000bbd0: 6162 5f6d 6f64 656c 3d46 616c 7365 293a  ab_model=False):
+0000bbe0: 0a20 2020 2020 2020 2073 7570 6572 2874  .        super(t
+0000bbf0: 7970 6528 7365 6c66 292c 2073 656c 6629  ype(self), self)
+0000bc00: 2e5f 5f69 6e69 745f 5f28 6d61 746c 6162  .__init__(matlab
+0000bc10: 5f6d 6f64 656c 3d6d 6174 6c61 625f 6d6f  _model=matlab_mo
+0000bc20: 6465 6c29 0a20 2020 2020 2020 2073 656c  del).        sel
+0000bc30: 662e 666e 616d 6520 3d20 696e 7370 6563  f.fname = inspec
+0000bc40: 742e 6765 7466 696c 6528 696e 7370 6563  t.getfile(inspec
+0000bc50: 742e 6375 7272 656e 7466 7261 6d65 2829  t.currentframe()
+0000bc60: 290a 0a20 2020 2064 6566 2076 616c 6964  )..    def valid
+0000bc70: 6174 6528 7365 6c66 293a 0a20 2020 2020  ate(self):.     
+0000bc80: 2020 2070 6173 730a 0a20 2020 2064 6566     pass..    def
+0000bc90: 2073 696d 756c 6174 6528 7365 6c66 2c20   simulate(self, 
+0000bca0: 7072 6f63 6573 735f 6964 3d4e 6f6e 652c  process_id=None,
+0000bcb0: 206d 6174 6c61 625f 656e 6769 6e65 3d4e   matlab_engine=N
+0000bcc0: 6f6e 6529 3a0a 0a20 2020 2020 2020 2069  one):..        i
+0000bcd0: 6620 7479 7065 2873 656c 662e 705b 2278  f type(self.p["x
+0000bce0: 3122 5d29 2069 7320 6e70 2e6e 6461 7272  1"]) is np.ndarr
+0000bcf0: 6179 3a0a 2020 2020 2020 2020 2020 2020  ay:.            
+0000bd00: 7365 6c66 2e70 5b22 7831 225d 203d 2073  self.p["x1"] = s
+0000bd10: 656c 662e 705b 2278 3122 5d2e 666c 6174  elf.p["x1"].flat
+0000bd20: 7465 6e28 290a 2020 2020 2020 2020 6966  ten().        if
+0000bd30: 2074 7970 6528 7365 6c66 2e70 5b22 7832   type(self.p["x2
+0000bd40: 225d 2920 6973 206e 702e 6e64 6172 7261  "]) is np.ndarra
+0000bd50: 793a 0a20 2020 2020 2020 2020 2020 2073  y:.            s
+0000bd60: 656c 662e 705b 2278 3222 5d20 3d20 7365  elf.p["x2"] = se
+0000bd70: 6c66 2e70 5b22 7832 225d 2e66 6c61 7474  lf.p["x2"].flatt
+0000bd80: 656e 2829 0a20 2020 2020 2020 2069 6620  en().        if 
+0000bd90: 7479 7065 2873 656c 662e 705b 2278 3322  type(self.p["x3"
+0000bda0: 5d29 2069 7320 6e70 2e6e 6461 7272 6179  ]) is np.ndarray
+0000bdb0: 3a0a 2020 2020 2020 2020 2020 2020 7365  :.            se
+0000bdc0: 6c66 2e70 5b22 7833 225d 203d 2073 656c  lf.p["x3"] = sel
+0000bdd0: 662e 705b 2278 3322 5d2e 666c 6174 7465  f.p["x3"].flatte
+0000bde0: 6e28 290a 0a20 2020 2020 2020 2079 203d  n()..        y =
+0000bdf0: 2028 332e 3020 2a20 2831 202d 2073 656c   (3.0 * (1 - sel
+0000be00: 662e 705b 2278 3122 5d29 202a 2a20 322e  f.p["x1"]) ** 2.
+0000be10: 202a 206e 702e 6578 7028 2d28 7365 6c66   * np.exp(-(self
+0000be20: 2e70 5b22 7831 225d 202a 2a20 3229 202d  .p["x1"] ** 2) -
+0000be30: 2028 7365 6c66 2e70 5b22 7833 225d 202b   (self.p["x3"] +
+0000be40: 2031 2920 2a2a 2032 290a 2020 2020 2020   1) ** 2).      
+0000be50: 2020 2020 2020 202d 2031 302e 3020 2a20         - 10.0 * 
+0000be60: 2873 656c 662e 705b 2278 3122 5d20 2f20  (self.p["x1"] / 
+0000be70: 352e 3020 2d20 7365 6c66 2e70 5b22 7831  5.0 - self.p["x1
+0000be80: 225d 202a 2a20 3320 2d20 7365 6c66 2e70  "] ** 3 - self.p
+0000be90: 5b22 7833 225d 202a 2a20 3529 0a20 2020  ["x3"] ** 5).   
+0000bea0: 2020 2020 2020 2020 2020 2a20 6e70 2e65            * np.e
+0000beb0: 7870 282d 7365 6c66 2e70 5b22 7831 225d  xp(-self.p["x1"]
+0000bec0: 202a 2a20 3220 2d20 7365 6c66 2e70 5b22   ** 2 - self.p["
+0000bed0: 7833 225d 202a 2a20 3229 202d 2031 2e30  x3"] ** 2) - 1.0
+0000bee0: 202f 2033 0a20 2020 2020 2020 2020 2020   / 3.           
+0000bef0: 2020 2a20 6e70 2e65 7870 282d 2873 656c    * np.exp(-(sel
+0000bf00: 662e 705b 2278 3122 5d20 2b20 3129 202a  f.p["x1"] + 1) *
+0000bf10: 2a20 3220 2d20 7365 6c66 2e70 5b22 7833  * 2 - self.p["x3
+0000bf20: 225d 202a 2a20 3229 2920 2b20 7365 6c66  "] ** 2)) + self
+0000bf30: 2e70 5b22 7832 225d 0a0a 2020 2020 2020  .p["x2"]..      
+0000bf40: 2020 6164 6469 7469 6f6e 616c 5f64 6174    additional_dat
+0000bf50: 6120 3d20 7b22 6164 6469 7469 6f6e 616c  a = {"additional
+0000bf60: 5f64 6174 612f 6c69 7374 5f6d 756c 745f  _data/list_mult_
+0000bf70: 696e 7422 3a20 5b31 2c20 322c 2033 5d2c  int": [1, 2, 3],
+0000bf80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000bf90: 2020 2020 2020 2020 2020 2020 2261 6464              "add
+0000bfa0: 6974 696f 6e61 6c5f 6461 7461 2f6c 6973  itional_data/lis
+0000bfb0: 745f 7369 6e67 6c65 5f66 6c6f 6174 223a  t_single_float":
+0000bfc0: 205b 302e 325d 2c0a 2020 2020 2020 2020   [0.2],.        
+0000bfd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000bfe0: 2020 2022 6164 6469 7469 6f6e 616c 5f64     "additional_d
+0000bff0: 6174 612f 6c69 7374 5f73 696e 676c 655f  ata/list_single_
+0000c000: 7374 7222 3a20 5b22 7465 7374 225d 2c0a  str": ["test"],.
+0000c010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c020: 2020 2020 2020 2020 2020 2022 6164 6469             "addi
+0000c030: 7469 6f6e 616c 5f64 6174 612f 6c69 7374  tional_data/list
+0000c040: 5f6d 756c 745f 7374 7222 3a20 5b22 7465  _mult_str": ["te
+0000c050: 7374 3122 2c20 2274 6573 7432 225d 2c0a  st1", "test2"],.
+0000c060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c070: 2020 2020 2020 2020 2020 2022 6164 6469             "addi
+0000c080: 7469 6f6e 616c 5f64 6174 612f 7369 6e67  tional_data/sing
+0000c090: 6c65 5f66 6c6f 6174 223a 2030 2e32 2c0a  le_float": 0.2,.
+0000c0a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c0b0: 2020 2020 2020 2020 2020 2022 6164 6469             "addi
+0000c0c0: 7469 6f6e 616c 5f64 6174 612f 7369 6e67  tional_data/sing
+0000c0d0: 6c65 5f69 6e74 223a 2032 2c0a 2020 2020  le_int": 2,.    
+0000c0e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c0f0: 2020 2020 2020 2022 6164 6469 7469 6f6e         "addition
+0000c100: 616c 5f64 6174 612f 7369 6e67 6c65 5f73  al_data/single_s
+0000c110: 7472 223a 2022 7465 7374 227d 0a0a 2020  tr": "test"}..  
+0000c120: 2020 2020 2020 2320 2320 7477 6f20 6f75        # # two ou
+0000c130: 7470 7574 2076 6172 6961 626c 6573 2066  tput variables f
+0000c140: 6f72 2074 6573 7469 6e67 0a20 2020 2020  or testing.     
+0000c150: 2020 2023 2069 6620 792e 7369 7a65 203e     # if y.size >
+0000c160: 2031 3a0a 2020 2020 2020 2020 2320 2020   1:.        #   
+0000c170: 2020 795f 6f75 7420 3d20 6e70 2e61 7272    y_out = np.arr
+0000c180: 6179 285b 792c 2032 202a 2079 5d29 2e74  ay([y, 2 * y]).t
+0000c190: 7261 6e73 706f 7365 2829 0a20 2020 2020  ranspose().     
+0000c1a0: 2020 2023 2020 2020 2061 6464 6974 696f     #     additio
+0000c1b0: 6e61 6c5f 6461 7461 203d 2079 2e73 697a  nal_data = y.siz
+0000c1c0: 6520 2a20 5b61 6464 6974 696f 6e61 6c5f  e * [additional_
+0000c1d0: 6461 7461 5d0a 2020 2020 2020 2020 2320  data].        # 
+0000c1e0: 656c 7365 3a0a 2020 2020 2020 2020 2320  else:.        # 
+0000c1f0: 2020 2020 795f 6f75 7420 3d20 6e70 2e61      y_out = np.a
+0000c200: 7272 6179 285b 792c 2032 202a 2079 5d29  rray([y, 2 * y])
+0000c210: 0a20 2020 2020 2020 2069 6620 792e 6e64  .        if y.nd
+0000c220: 696d 203d 3d20 313a 0a20 2020 2020 2020  im == 1:.       
+0000c230: 2020 2020 2079 5f6f 7574 203d 2079 5b3a       y_out = y[:
+0000c240: 2c20 6e70 2e6e 6577 6178 6973 5d0a 0a20  , np.newaxis].. 
+0000c250: 2020 2020 2020 2072 6574 7572 6e20 795f         return y_
+0000c260: 6f75 742c 2061 6464 6974 696f 6e61 6c5f  out, additional_
+0000c270: 6461 7461 0a0a 0a63 6c61 7373 2050 6561  data...class Pea
+0000c280: 6b73 5f4e 614e 2841 6273 7472 6163 744d  ks_NaN(AbstractM
+0000c290: 6f64 656c 293a 0a20 2020 2022 2222 0a20  odel):.    """. 
+0000c2a0: 2020 2054 6872 6565 2d64 696d 656e 7369     Three-dimensi
+0000c2b0: 6f6e 616c 2070 6561 6b73 2066 756e 6374  onal peaks funct
+0000c2c0: 696f 6e20 7265 7475 726e 696e 6720 4e61  ion returning Na
+0000c2d0: 4e20 7661 6c75 6573 2066 6f72 2063 6572  N values for cer
+0000c2e0: 7461 696e 2070 6172 616d 6574 6572 7320  tain parameters 
+0000c2f0: 2866 6f72 2074 6573 7469 6e67 292e 0a0a  (for testing)...
+0000c300: 2020 2020 2e2e 206d 6174 683a 3a0a 2020      .. math::.  
+0000c310: 2020 2020 7920 3d20 3328 312d 785f 3129      y = 3(1-x_1)
+0000c320: 5e32 2065 5e7b 2d28 785f 315e 3229 2d28  ^2 e^{-(x_1^2)-(
+0000c330: 785f 332b 3129 5e32 7d2d 3130 285c 5c66  x_3+1)^2}-10(\\f
+0000c340: 7261 637b 785f 317d 7b35 7d2d 785f 315e  rac{x_1}{5}-x_1^
+0000c350: 332d 785f 335e 3529 2065 5e7b 2d78 5f31  3-x_3^5) e^{-x_1
+0000c360: 5e32 2d78 5f33 5e32 7d2d 0a20 2020 2020  ^2-x_3^2}-.     
+0000c370: 205c 5c66 7261 637b 317d 7b33 7d20 655e   \\frac{1}{3} e^
+0000c380: 7b2d 2878 5f31 2b31 295e 3220 2d20 785f  {-(x_1+1)^2 - x_
+0000c390: 335e 327d 202b 2078 5f32 0a0a 2020 2020  3^2} + x_2..    
+0000c3a0: 5061 7261 6d65 7465 7273 0a20 2020 202d  Parameters.    -
+0000c3b0: 2d2d 2d2d 2d2d 2d2d 2d0a 2020 2020 705b  ---------.    p[
+0000c3c0: 2278 3122 5d3a 2066 6c6f 6174 206f 7220  "x1"]: float or 
+0000c3d0: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
+0000c3e0: 205b 6e5f 6772 6964 5d0a 2020 2020 2020   [n_grid].      
+0000c3f0: 2020 5061 7261 6d65 7465 7220 310a 2020    Parameter 1.  
+0000c400: 2020 705b 2278 3222 5d3a 2066 6c6f 6174    p["x2"]: float
+0000c410: 206f 7220 6e64 6172 7261 7920 6f66 2066   or ndarray of f
+0000c420: 6c6f 6174 205b 6e5f 6772 6964 5d0a 2020  loat [n_grid].  
+0000c430: 2020 2020 2020 5061 7261 6d65 7465 7220        Parameter 
+0000c440: 320a 2020 2020 705b 2278 3322 5d3a 2066  2.    p["x3"]: f
+0000c450: 6c6f 6174 206f 7220 6e64 6172 7261 7920  loat or ndarray 
+0000c460: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
+0000c470: 5d0a 2020 2020 2020 2020 5061 7261 6d65  ].        Parame
+0000c480: 7465 7220 330a 0a20 2020 2052 6574 7572  ter 3..    Retur
+0000c490: 6e73 0a20 2020 202d 2d2d 2d2d 2d2d 0a20  ns.    -------. 
+0000c4a0: 2020 2079 3a20 6e64 6172 7261 7920 6f66     y: ndarray of
+0000c4b0: 2066 6c6f 6174 205b 6e5f 6772 6964 2078   float [n_grid x
+0000c4c0: 206e 5f6f 7574 5d0a 2020 2020 2020 2020   n_out].        
+0000c4d0: 4f75 7470 7574 2064 6174 610a 2020 2020  Output data.    
+0000c4e0: 6d69 7363 3a20 6469 6374 206f 7220 6c69  misc: dict or li
+0000c4f0: 7374 206f 6620 6469 6374 205b 6e5f 6772  st of dict [n_gr
+0000c500: 6964 5d0a 2020 2020 2020 2020 4164 6469  id].        Addi
+0000c510: 7469 6f6e 616c 2064 6174 612c 2077 696c  tional data, wil
+0000c520: 6c20 6265 2073 6176 6564 2075 6e64 6572  l be saved under
+0000c530: 2069 7473 206b 6579 7320 696e 2074 6865   its keys in the
+0000c540: 202e 6864 6635 2066 696c 6520 6475 7269   .hdf5 file duri
+0000c550: 6e67 2067 5043 2073 696d 756c 6174 696f  ng gPC simulatio
+0000c560: 6e73 2066 6f72 2065 7665 7279 2067 7269  ns for every gri
+0000c570: 6420 706f 696e 740a 0a20 2020 204e 6f74  d point..    Not
+0000c580: 6573 0a20 2020 202d 2d2d 2d2d 0a20 2020  es.    -----.   
+0000c590: 202e 2e20 706c 6f74 3a3a 0a0a 2020 2020   .. plot::..    
+0000c5a0: 2020 2069 6d70 6f72 7420 6e75 6d70 7920     import numpy 
+0000c5b0: 6173 206e 700a 2020 2020 2020 2066 726f  as np.       fro
+0000c5c0: 6d20 7079 6770 632e 7465 7374 6675 6e63  m pygpc.testfunc
+0000c5d0: 7469 6f6e 7320 696d 706f 7274 2070 6c6f  tions import plo
+0000c5e0: 745f 7465 7374 6675 6e63 7469 6f6e 2061  t_testfunction a
+0000c5f0: 7320 706c 6f74 0a20 2020 2020 2020 6672  s plot.       fr
+0000c600: 6f6d 2063 6f6c 6c65 6374 696f 6e73 2069  om collections i
+0000c610: 6d70 6f72 7420 4f72 6465 7265 6444 6963  mport OrderedDic
+0000c620: 740a 0a20 2020 2020 2020 7061 7261 6d65  t..       parame
+0000c630: 7465 7273 203d 204f 7264 6572 6564 4469  ters = OrderedDi
+0000c640: 6374 2829 0a20 2020 2020 2020 7061 7261  ct().       para
+0000c650: 6d65 7465 7273 5b22 7831 225d 203d 206e  meters["x1"] = n
+0000c660: 702e 6c69 6e73 7061 6365 2830 2c20 312c  p.linspace(0, 1,
+0000c670: 2031 3030 290a 2020 2020 2020 2070 6172   100).       par
+0000c680: 616d 6574 6572 735b 2278 3222 5d20 3d20  ameters["x2"] = 
+0000c690: 6e70 2e6c 696e 7370 6163 6528 302c 2031  np.linspace(0, 1
+0000c6a0: 2c20 3130 3029 0a0a 2020 2020 2020 2063  , 100)..       c
+0000c6b0: 6f6e 7374 616e 7473 203d 204f 7264 6572  onstants = Order
+0000c6c0: 6564 4469 6374 2829 0a20 2020 2020 2020  edDict().       
+0000c6d0: 636f 6e73 7461 6e74 735b 2278 3322 5d20  constants["x3"] 
+0000c6e0: 3d20 302e 0a20 2020 2020 2020 706c 6f74  = 0..       plot
+0000c6f0: 2822 5065 616b 7322 2c20 7061 7261 6d65  ("Peaks", parame
+0000c700: 7465 7273 2c20 636f 6e73 7461 6e74 732c  ters, constants,
+0000c710: 2070 6c6f 745f 3364 3d46 616c 7365 290a   plot_3d=False).
+0000c720: 2020 2020 2222 220a 0a20 2020 2064 6566      """..    def
+0000c730: 205f 5f69 6e69 745f 5f28 7365 6c66 2c20   __init__(self, 
+0000c740: 6d61 746c 6162 5f6d 6f64 656c 3d46 616c  matlab_model=Fal
+0000c750: 7365 293a 0a20 2020 2020 2020 2073 7570  se):.        sup
+0000c760: 6572 2874 7970 6528 7365 6c66 292c 2073  er(type(self), s
+0000c770: 656c 6629 2e5f 5f69 6e69 745f 5f28 6d61  elf).__init__(ma
+0000c780: 746c 6162 5f6d 6f64 656c 3d6d 6174 6c61  tlab_model=matla
+0000c790: 625f 6d6f 6465 6c29 0a20 2020 2020 2020  b_model).       
+0000c7a0: 2073 656c 662e 666e 616d 6520 3d20 696e   self.fname = in
+0000c7b0: 7370 6563 742e 6765 7466 696c 6528 696e  spect.getfile(in
+0000c7c0: 7370 6563 742e 6375 7272 656e 7466 7261  spect.currentfra
+0000c7d0: 6d65 2829 290a 0a20 2020 2064 6566 2076  me())..    def v
+0000c7e0: 616c 6964 6174 6528 7365 6c66 293a 0a20  alidate(self):. 
+0000c7f0: 2020 2020 2020 2070 6173 730a 0a20 2020         pass..   
+0000c800: 2064 6566 2073 696d 756c 6174 6528 7365   def simulate(se
+0000c810: 6c66 2c20 7072 6f63 6573 735f 6964 3d4e  lf, process_id=N
+0000c820: 6f6e 652c 206d 6174 6c61 625f 656e 6769  one, matlab_engi
+0000c830: 6e65 3d4e 6f6e 6529 3a0a 0a20 2020 2020  ne=None):..     
+0000c840: 2020 2069 6620 7479 7065 2873 656c 662e     if type(self.
+0000c850: 705b 2278 3122 5d29 2069 7320 6e70 2e6e  p["x1"]) is np.n
+0000c860: 6461 7272 6179 3a0a 2020 2020 2020 2020  darray:.        
+0000c870: 2020 2020 7365 6c66 2e70 5b22 7831 225d      self.p["x1"]
+0000c880: 203d 2073 656c 662e 705b 2278 3122 5d2e   = self.p["x1"].
+0000c890: 666c 6174 7465 6e28 290a 2020 2020 2020  flatten().      
+0000c8a0: 2020 6966 2074 7970 6528 7365 6c66 2e70    if type(self.p
+0000c8b0: 5b22 7832 225d 2920 6973 206e 702e 6e64  ["x2"]) is np.nd
+0000c8c0: 6172 7261 793a 0a20 2020 2020 2020 2020  array:.         
+0000c8d0: 2020 2073 656c 662e 705b 2278 3222 5d20     self.p["x2"] 
+0000c8e0: 3d20 7365 6c66 2e70 5b22 7832 225d 2e66  = self.p["x2"].f
+0000c8f0: 6c61 7474 656e 2829 0a20 2020 2020 2020  latten().       
+0000c900: 2069 6620 7479 7065 2873 656c 662e 705b   if type(self.p[
+0000c910: 2278 3322 5d29 2069 7320 6e70 2e6e 6461  "x3"]) is np.nda
+0000c920: 7272 6179 3a0a 2020 2020 2020 2020 2020  rray:.          
+0000c930: 2020 7365 6c66 2e70 5b22 7833 225d 203d    self.p["x3"] =
+0000c940: 2073 656c 662e 705b 2278 3322 5d2e 666c   self.p["x3"].fl
+0000c950: 6174 7465 6e28 290a 0a20 2020 2020 2020  atten()..       
+0000c960: 2079 203d 2028 332e 3020 2a20 2831 202d   y = (3.0 * (1 -
+0000c970: 2073 656c 662e 705b 2278 3122 5d29 202a   self.p["x1"]) *
+0000c980: 2a20 322e 202a 206e 702e 6578 7028 2d28  * 2. * np.exp(-(
+0000c990: 7365 6c66 2e70 5b22 7831 225d 202a 2a20  self.p["x1"] ** 
+0000c9a0: 3229 202d 2028 7365 6c66 2e70 5b22 7833  2) - (self.p["x3
+0000c9b0: 225d 202b 2031 2920 2a2a 2032 290a 2020  "] + 1) ** 2).  
+0000c9c0: 2020 2020 2020 2020 2020 202d 2031 302e             - 10.
+0000c9d0: 3020 2a20 2873 656c 662e 705b 2278 3122  0 * (self.p["x1"
+0000c9e0: 5d20 2f20 352e 3020 2d20 7365 6c66 2e70  ] / 5.0 - self.p
+0000c9f0: 5b22 7831 225d 202a 2a20 3320 2d20 7365  ["x1"] ** 3 - se
+0000ca00: 6c66 2e70 5b22 7833 225d 202a 2a20 3529  lf.p["x3"] ** 5)
+0000ca10: 0a20 2020 2020 2020 2020 2020 2020 2a20  .             * 
+0000ca20: 6e70 2e65 7870 282d 7365 6c66 2e70 5b22  np.exp(-self.p["
+0000ca30: 7831 225d 202a 2a20 3220 2d20 7365 6c66  x1"] ** 2 - self
+0000ca40: 2e70 5b22 7833 225d 202a 2a20 3229 202d  .p["x3"] ** 2) -
+0000ca50: 2031 2e30 202f 2033 0a20 2020 2020 2020   1.0 / 3.       
+0000ca60: 2020 2020 2020 2a20 6e70 2e65 7870 282d        * np.exp(-
+0000ca70: 2873 656c 662e 705b 2278 3122 5d20 2b20  (self.p["x1"] + 
+0000ca80: 3129 202a 2a20 3220 2d20 7365 6c66 2e70  1) ** 2 - self.p
+0000ca90: 5b22 7833 225d 202a 2a20 3229 2920 2b20  ["x3"] ** 2)) + 
+0000caa0: 7365 6c66 2e70 5b22 7832 225d 0a0a 2020  self.p["x2"]..  
+0000cab0: 2020 2020 2020 2320 6164 6420 736f 6d65        # add some
+0000cac0: 204e 614e 2076 616c 7565 7320 666f 7220   NaN values for 
+0000cad0: 7465 7374 696e 670a 2020 2020 2020 2020  testing.        
+0000cae0: 6d61 736b 5f6e 616e 203d 2073 656c 662e  mask_nan = self.
+0000caf0: 705b 2278 3122 5d20 3c20 312e 350a 0a20  p["x1"] < 1.5.. 
+0000cb00: 2020 2020 2020 2079 5b6d 6173 6b5f 6e61         y[mask_na
+0000cb10: 6e5d 203d 206e 702e 4e61 4e0a 0a20 2020  n] = np.NaN..   
+0000cb20: 2020 2020 2061 6464 6974 696f 6e61 6c5f       additional_
+0000cb30: 6461 7461 203d 207b 2261 6464 6974 696f  data = {"additio
+0000cb40: 6e61 6c5f 6461 7461 2f6c 6973 745f 6d75  nal_data/list_mu
+0000cb50: 6c74 5f69 6e74 223a 205b 312c 2032 2c20  lt_int": [1, 2, 
+0000cb60: 335d 2c0a 2020 2020 2020 2020 2020 2020  3],.            
+0000cb70: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+0000cb80: 6164 6469 7469 6f6e 616c 5f64 6174 612f  additional_data/
+0000cb90: 6c69 7374 5f73 696e 676c 655f 666c 6f61  list_single_floa
+0000cba0: 7422 3a20 5b30 2e32 5d2c 0a20 2020 2020  t": [0.2],.     
+0000cbb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cbc0: 2020 2020 2020 2261 6464 6974 696f 6e61        "additiona
+0000cbd0: 6c5f 6461 7461 2f6c 6973 745f 7369 6e67  l_data/list_sing
+0000cbe0: 6c65 5f73 7472 223a 205b 2274 6573 7422  le_str": ["test"
+0000cbf0: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+0000cc00: 2020 2020 2020 2020 2020 2020 2020 2261                "a
+0000cc10: 6464 6974 696f 6e61 6c5f 6461 7461 2f6c  dditional_data/l
+0000cc20: 6973 745f 6d75 6c74 5f73 7472 223a 205b  ist_mult_str": [
+0000cc30: 2274 6573 7431 222c 2022 7465 7374 3222  "test1", "test2"
+0000cc40: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+0000cc50: 2020 2020 2020 2020 2020 2020 2020 2261                "a
+0000cc60: 6464 6974 696f 6e61 6c5f 6461 7461 2f73  dditional_data/s
+0000cc70: 696e 676c 655f 666c 6f61 7422 3a20 302e  ingle_float": 0.
+0000cc80: 322c 0a20 2020 2020 2020 2020 2020 2020  2,.             
+0000cc90: 2020 2020 2020 2020 2020 2020 2020 2261                "a
+0000cca0: 6464 6974 696f 6e61 6c5f 6461 7461 2f73  dditional_data/s
+0000ccb0: 696e 676c 655f 696e 7422 3a20 322c 0a20  ingle_int": 2,. 
+0000ccc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ccd0: 2020 2020 2020 2020 2020 2261 6464 6974            "addit
+0000cce0: 696f 6e61 6c5f 6461 7461 2f73 696e 676c  ional_data/singl
+0000ccf0: 655f 7374 7222 3a20 2274 6573 7422 7d0a  e_str": "test"}.
+0000cd00: 0a20 2020 2020 2020 2023 2023 2074 776f  .        # # two
+0000cd10: 206f 7574 7075 7420 7661 7269 6162 6c65   output variable
+0000cd20: 7320 666f 7220 7465 7374 696e 670a 2020  s for testing.  
+0000cd30: 2020 2020 2020 2320 6966 2079 2e73 697a        # if y.siz
+0000cd40: 6520 3e20 313a 0a20 2020 2020 2020 2023  e > 1:.        #
+0000cd50: 2020 2020 2079 5f6f 7574 203d 206e 702e       y_out = np.
+0000cd60: 6172 7261 7928 5b79 2c20 3220 2a20 795d  array([y, 2 * y]
+0000cd70: 292e 7472 616e 7370 6f73 6528 290a 2020  ).transpose().  
+0000cd80: 2020 2020 2020 2320 2020 2020 6164 6469        #     addi
+0000cd90: 7469 6f6e 616c 5f64 6174 6120 3d20 792e  tional_data = y.
+0000cda0: 7369 7a65 202a 205b 6164 6469 7469 6f6e  size * [addition
+0000cdb0: 616c 5f64 6174 615d 0a20 2020 2020 2020  al_data].       
+0000cdc0: 2023 2065 6c73 653a 0a20 2020 2020 2020   # else:.       
+0000cdd0: 2023 2020 2020 2079 5f6f 7574 203d 206e   #     y_out = n
+0000cde0: 702e 6172 7261 7928 5b79 2c20 3220 2a20  p.array([y, 2 * 
+0000cdf0: 795d 290a 2020 2020 2020 2020 6966 2079  y]).        if y
+0000ce00: 2e6e 6469 6d20 3d3d 2031 3a0a 2020 2020  .ndim == 1:.    
+0000ce10: 2020 2020 2020 2020 795f 6f75 7420 3d20          y_out = 
+0000ce20: 795b 3a2c 206e 702e 6e65 7761 7869 735d  y[:, np.newaxis]
+0000ce30: 0a0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+0000ce40: 2079 5f6f 7574 2c20 6164 6469 7469 6f6e   y_out, addition
+0000ce50: 616c 5f64 6174 610a 0a0a 636c 6173 7320  al_data...class 
+0000ce60: 4469 7363 6f6e 7469 6e75 6f75 7352 6964  DiscontinuousRid
+0000ce70: 6765 4d61 6e75 6661 6374 7572 6544 6563  geManufactureDec
+0000ce80: 6179 4765 6e7a 4469 7363 6f6e 7469 6e75  ayGenzDiscontinu
+0000ce90: 6f75 7328 4162 7374 7261 6374 4d6f 6465  ous(AbstractMode
+0000cea0: 6c29 3a0a 2020 2020 2222 220a 2020 2020  l):.    """.    
+0000ceb0: 4e2d 6469 6d65 6e73 696f 6e61 6c20 6469  N-dimensional di
+0000cec0: 7363 6f6e 7469 6e75 6f75 7320 7465 7374  scontinuous test
+0000ced0: 2066 756e 6374 696f 6e2e 2054 6865 2066   function. The f
+0000cee0: 6972 7374 2051 4f49 2063 6f72 7265 7370  irst QOI corresp
+0000cef0: 6f6e 6473 2074 6f20 7468 650a 2020 2020  onds to the.    
+0000cf00: 4469 7363 6f6e 7469 6e75 6f75 7352 6964  DiscontinuousRid
+0000cf10: 6765 4d61 6e75 6661 6374 7572 6544 6563  geManufactureDec
+0000cf20: 6179 2066 756e 6374 696f 6e20 616e 6420  ay function and 
+0000cf30: 7468 6520 7365 636f 6e64 2051 4f49 2074  the second QOI t
+0000cf40: 6f20 4765 6e7a 4469 7363 6f6e 7469 6e75  o GenzDiscontinu
+0000cf50: 6f75 732e 0a0a 2020 2020 7920 3d20 4469  ous...    y = Di
+0000cf60: 7363 6f6e 7469 6e75 6f75 7352 6964 6765  scontinuousRidge
+0000cf70: 4d61 6e75 6661 6374 7572 6544 6563 6179  ManufactureDecay
+0000cf80: 4765 6e7a 4469 7363 6f6e 7469 6e75 6f75  GenzDiscontinuou
+0000cf90: 7328 7829 0a0a 2020 2020 5061 7261 6d65  s(x)..    Parame
+0000cfa0: 7465 7273 0a20 2020 202d 2d2d 2d2d 2d2d  ters.    -------
+0000cfb0: 2d2d 2d0a 2020 2020 705b 2278 3122 5d3a  ---.    p["x1"]:
+0000cfc0: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
+0000cfd0: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
+0000cfe0: 6964 5d0a 2020 2020 2020 2020 5061 7261  id].        Para
+0000cff0: 6d65 7465 7220 3120 5b30 2c20 315d 0a20  meter 1 [0, 1]. 
+0000d000: 2020 2070 5b22 7832 225d 3a20 666c 6f61     p["x2"]: floa
+0000d010: 7420 6f72 206e 6461 7272 6179 206f 6620  t or ndarray of 
+0000d020: 666c 6f61 7420 5b6e 5f67 7269 645d 0a20  float [n_grid]. 
+0000d030: 2020 2020 2020 2050 6172 616d 6574 6572         Parameter
+0000d040: 2032 205b 302c 2031 5d0a 2020 2020 705b   2 [0, 1].    p[
+0000d050: 2278 3322 5d3a 2066 6c6f 6174 206f 7220  "x3"]: float or 
+0000d060: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
+0000d070: 205b 6e5f 6772 6964 5d0a 2020 2020 2020   [n_grid].      
+0000d080: 2020 5061 7261 6d65 7465 7220 3320 5b30    Parameter 3 [0
+0000d090: 2c20 315d 0a0a 2020 2020 5265 7475 726e  , 1]..    Return
+0000d0a0: 730a 2020 2020 2d2d 2d2d 2d2d 2d0a 2020  s.    -------.  
+0000d0b0: 2020 793a 206e 6461 7272 6179 206f 6620    y: ndarray of 
+0000d0c0: 666c 6f61 7420 5b6e 5f67 7269 6420 7820  float [n_grid x 
+0000d0d0: 6e5f 6f75 745d 0a20 2020 2020 2020 204f  n_out].        O
+0000d0e0: 7574 7075 7420 6461 7461 0a0a 2020 2020  utput data..    
+0000d0f0: 4e6f 7465 730a 2020 2020 2d2d 2d2d 2d0a  Notes.    -----.
+0000d100: 2020 2020 2e2e 2070 6c6f 743a 3a0a 0a20      .. plot::.. 
+0000d110: 2020 2020 2020 696d 706f 7274 206e 756d        import num
+0000d120: 7079 2061 7320 6e70 0a20 2020 2020 2020  py as np.       
+0000d130: 6672 6f6d 2070 7967 7063 2e74 6573 7466  from pygpc.testf
+0000d140: 756e 6374 696f 6e73 2069 6d70 6f72 7420  unctions import 
+0000d150: 706c 6f74 5f74 6573 7466 756e 6374 696f  plot_testfunctio
+0000d160: 6e20 6173 2070 6c6f 740a 2020 2020 2020  n as plot.      
+0000d170: 2066 726f 6d20 636f 6c6c 6563 7469 6f6e   from collection
+0000d180: 7320 696d 706f 7274 204f 7264 6572 6564  s import Ordered
+0000d190: 4469 6374 0a0a 2020 2020 2020 2070 6172  Dict..       par
+0000d1a0: 616d 6574 6572 7320 3d20 4f72 6465 7265  ameters = Ordere
+0000d1b0: 6444 6963 7428 290a 2020 2020 2020 2070  dDict().       p
+0000d1c0: 6172 616d 6574 6572 735b 2278 3122 5d20  arameters["x1"] 
+0000d1d0: 3d20 6e70 2e6c 696e 7370 6163 6528 302c  = np.linspace(0,
+0000d1e0: 2031 2c20 3130 3029 0a20 2020 2020 2020   1, 100).       
+0000d1f0: 7061 7261 6d65 7465 7273 5b22 7832 225d  parameters["x2"]
+0000d200: 203d 206e 702e 6c69 6e73 7061 6365 2830   = np.linspace(0
+0000d210: 2c20 312c 2031 3030 290a 0a20 2020 2020  , 1, 100)..     
+0000d220: 2020 706c 6f74 2822 4469 7363 6f6e 7469    plot("Disconti
+0000d230: 6e75 6f75 7352 6964 6765 4d61 6e75 6661  nuousRidgeManufa
+0000d240: 6374 7572 6544 6563 6179 4765 6e7a 4469  ctureDecayGenzDi
+0000d250: 7363 6f6e 7469 6e75 6f75 7322 2c20 7061  scontinuous", pa
+0000d260: 7261 6d65 7465 7273 2c20 6f75 7470 7574  rameters, output
+0000d270: 5f69 6478 3d5b 302c 2031 5d29 0a20 2020  _idx=[0, 1]).   
+0000d280: 2022 2222 0a0a 2020 2020 6465 6620 5f5f   """..    def __
+0000d290: 696e 6974 5f5f 2873 656c 662c 206d 6174  init__(self, mat
+0000d2a0: 6c61 625f 6d6f 6465 6c3d 4661 6c73 6529  lab_model=False)
+0000d2b0: 3a0a 2020 2020 2020 2020 7375 7065 7228  :.        super(
+0000d2c0: 7479 7065 2873 656c 6629 2c20 7365 6c66  type(self), self
+0000d2d0: 292e 5f5f 696e 6974 5f5f 286d 6174 6c61  ).__init__(matla
+0000d2e0: 625f 6d6f 6465 6c3d 6d61 746c 6162 5f6d  b_model=matlab_m
+0000d2f0: 6f64 656c 290a 2020 2020 2020 2020 7365  odel).        se
+0000d300: 6c66 2e66 6e61 6d65 203d 2069 6e73 7065  lf.fname = inspe
+0000d310: 6374 2e67 6574 6669 6c65 2869 6e73 7065  ct.getfile(inspe
+0000d320: 6374 2e63 7572 7265 6e74 6672 616d 6528  ct.currentframe(
+0000d330: 2929 0a0a 2020 2020 6465 6620 7661 6c69  ))..    def vali
+0000d340: 6461 7465 2873 656c 6629 3a0a 2020 2020  date(self):.    
+0000d350: 2020 2020 7061 7373 0a0a 2020 2020 6465      pass..    de
+0000d360: 6620 7369 6d75 6c61 7465 2873 656c 662c  f simulate(self,
+0000d370: 2070 726f 6365 7373 5f69 643d 4e6f 6e65   process_id=None
+0000d380: 2c20 6d61 746c 6162 5f65 6e67 696e 653d  , matlab_engine=
+0000d390: 4e6f 6e65 293a 0a0a 2020 2020 2020 2020  None):..        
+0000d3a0: 795f 3120 3d20 4469 7363 6f6e 7469 6e75  y_1 = Discontinu
+0000d3b0: 6f75 7352 6964 6765 4d61 6e75 6661 6374  ousRidgeManufact
+0000d3c0: 7572 6544 6563 6179 2829 2e73 6574 5f70  ureDecay().set_p
+0000d3d0: 6172 616d 6574 6572 7328 7365 6c66 2e70  arameters(self.p
+0000d3e0: 292e 7369 6d75 6c61 7465 2829 0a20 2020  ).simulate().   
+0000d3f0: 2020 2020 2079 5f32 203d 2047 656e 7a44       y_2 = GenzD
+0000d400: 6973 636f 6e74 696e 756f 7573 2829 2e73  iscontinuous().s
+0000d410: 6574 5f70 6172 616d 6574 6572 7328 7365  et_parameters(se
+0000d420: 6c66 2e70 292e 7369 6d75 6c61 7465 2829  lf.p).simulate()
+0000d430: 0a0a 2020 2020 2020 2020 7920 3d20 6e70  ..        y = np
+0000d440: 2e68 7374 6163 6b28 2879 5f31 2c20 795f  .hstack((y_1, y_
+0000d450: 3229 290a 0a20 2020 2020 2020 2072 6574  2))..        ret
+0000d460: 7572 6e20 790a 0a0a 636c 6173 7320 4879  urn y...class Hy
+0000d470: 7065 7262 6f6c 6963 5461 6e67 656e 7428  perbolicTangent(
+0000d480: 4162 7374 7261 6374 4d6f 6465 6c29 3a0a  AbstractModel):.
+0000d490: 2020 2020 2222 220a 2020 2020 5477 6f2d      """.    Two-
+0000d4a0: 6469 6d65 6e73 696f 6e61 6c20 6879 7065  dimensional hype
+0000d4b0: 7262 6f6c 6963 2074 616e 6765 6e74 2066  rbolic tangent f
+0000d4c0: 756e 6374 696f 6e20 5b31 5d20 746f 2073  unction [1] to s
+0000d4d0: 696d 756c 6174 6520 6469 7363 6f6e 7469  imulate disconti
+0000d4e0: 6e75 6974 6965 732e 2044 6973 636f 6e74  nuities. Discont
+0000d4f0: 696e 7569 7479 2061 7420 7831 203d 2030  inuity at x1 = 0
+0000d500: 2e0a 0a20 2020 202e 2e20 6d61 7468 3a3a  ...    .. math::
+0000d510: 0a20 2020 2020 2020 7928 785f 312c 2078  .       y(x_1, x
+0000d520: 5f32 2920 3d20 5c5c 7461 6e68 2831 3020  _2) = \\tanh(10 
+0000d530: 785f 3129 202b 2030 2e32 205c 7369 6e28  x_1) + 0.2 \sin(
+0000d540: 3130 2078 5f31 2920 2b20 302e 3320 785f  10 x_1) + 0.3 x_
+0000d550: 3220 2b20 302e 3120 5c73 696e 2835 2078  2 + 0.1 \sin(5 x
+0000d560: 5f31 290a 0a20 2020 2050 6172 616d 6574  _1)..    Paramet
+0000d570: 6572 730a 2020 2020 2d2d 2d2d 2d2d 2d2d  ers.    --------
+0000d580: 2d2d 0a20 2020 2070 5b22 7831 225d 3a20  --.    p["x1"]: 
+0000d590: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
+0000d5a0: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
+0000d5b0: 645d 0a20 2020 2020 2020 2050 6172 616d  d].        Param
+0000d5c0: 6574 6572 2031 205b 2d31 2c20 315d 0a20  eter 1 [-1, 1]. 
+0000d5d0: 2020 2070 5b22 7832 225d 3a20 666c 6f61     p["x2"]: floa
+0000d5e0: 7420 6f72 206e 6461 7272 6179 206f 6620  t or ndarray of 
+0000d5f0: 666c 6f61 7420 5b6e 5f67 7269 645d 0a20  float [n_grid]. 
+0000d600: 2020 2020 2020 2050 6172 616d 6574 6572         Parameter
+0000d610: 2032 205b 2d31 2c20 315d 0a0a 2020 2020   2 [-1, 1]..    
+0000d620: 5265 7475 726e 730a 2020 2020 2d2d 2d2d  Returns.    ----
+0000d630: 2d2d 2d0a 2020 2020 793a 206e 6461 7272  ---.    y: ndarr
+0000d640: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
+0000d650: 7269 6420 7820 315d 0a20 2020 2020 2020  rid x 1].       
+0000d660: 204f 7574 7075 7420 6461 7461 0a0a 2020   Output data..  
+0000d670: 2020 4e6f 7465 730a 2020 2020 2d2d 2d2d    Notes.    ----
+0000d680: 2d0a 2020 2020 2e2e 2070 6c6f 743a 3a0a  -.    .. plot::.
+0000d690: 0a20 2020 2020 2020 696d 706f 7274 206e  .       import n
+0000d6a0: 756d 7079 2061 7320 6e70 0a20 2020 2020  umpy as np.     
+0000d6b0: 2020 6672 6f6d 2070 7967 7063 2e74 6573    from pygpc.tes
+0000d6c0: 7466 756e 6374 696f 6e73 2069 6d70 6f72  tfunctions impor
+0000d6d0: 7420 706c 6f74 5f74 6573 7466 756e 6374  t plot_testfunct
+0000d6e0: 696f 6e20 6173 2070 6c6f 740a 2020 2020  ion as plot.    
+0000d6f0: 2020 2066 726f 6d20 636f 6c6c 6563 7469     from collecti
+0000d700: 6f6e 7320 696d 706f 7274 204f 7264 6572  ons import Order
+0000d710: 6564 4469 6374 0a0a 2020 2020 2020 2070  edDict..       p
+0000d720: 6172 616d 6574 6572 7320 3d20 4f72 6465  arameters = Orde
+0000d730: 7265 6444 6963 7428 290a 2020 2020 2020  redDict().      
+0000d740: 2070 6172 616d 6574 6572 735b 2278 3122   parameters["x1"
+0000d750: 5d20 3d20 6e70 2e6c 696e 7370 6163 6528  ] = np.linspace(
+0000d760: 2d31 2c20 312c 2031 3030 290a 2020 2020  -1, 1, 100).    
+0000d770: 2020 2070 6172 616d 6574 6572 735b 2278     parameters["x
+0000d780: 3222 5d20 3d20 6e70 2e6c 696e 7370 6163  2"] = np.linspac
+0000d790: 6528 2d31 2c20 312c 2031 3030 290a 0a20  e(-1, 1, 100).. 
+0000d7a0: 2020 2020 2020 706c 6f74 2822 4879 7065        plot("Hype
+0000d7b0: 7262 6f6c 6963 5461 6e67 656e 7422 2c20  rbolicTangent", 
+0000d7c0: 7061 7261 6d65 7465 7273 290a 0a20 2020  parameters)..   
+0000d7d0: 202e 2e20 5b31 5d20 4168 6c66 656c 642c   .. [1] Ahlfeld,
+0000d7e0: 2052 2e2c 204d 6f6e 746f 6d6f 6c69 2c20   R., Montomoli, 
+0000d7f0: 462e 2c20 4361 726e 6576 616c 652c 204d  F., Carnevale, M
+0000d800: 2e2c 2053 616c 7661 646f 7265 2c20 532e  ., Salvadore, S.
+0000d810: 2028 3230 3138 292e 0a20 2020 2020 2020   (2018)..       
+0000d820: 4175 746f 6e6f 6d6f 7573 2055 6e63 6572  Autonomous Uncer
+0000d830: 7461 696e 7479 2051 7561 6e74 6966 6963  tainty Quantific
+0000d840: 6174 696f 6e20 666f 7220 4469 7363 6f6e  ation for Discon
+0000d850: 7469 6e75 6f75 7320 4d6f 6465 6c73 2055  tinuous Models U
+0000d860: 7369 6e67 204d 756c 7469 7661 7269 6174  sing Multivariat
+0000d870: 6520 5061 6465 2041 7070 726f 7869 6d61  e Pade Approxima
+0000d880: 7469 6f6e 732e 0a20 2020 2020 2020 4a6f  tions..       Jo
+0000d890: 7572 6e61 6c20 6f66 2054 7572 626f 6d61  urnal of Turboma
+0000d8a0: 6368 696e 6572 792c 2031 3034 2c20 3034  chinery, 104, 04
+0000d8b0: 3130 3034 2e0a 2020 2020 2222 220a 0a20  1004..    """.. 
+0000d8c0: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
+0000d8d0: 7365 6c66 2c20 6d61 746c 6162 5f6d 6f64  self, matlab_mod
+0000d8e0: 656c 3d46 616c 7365 293a 0a20 2020 2020  el=False):.     
+0000d8f0: 2020 2073 7570 6572 2874 7970 6528 7365     super(type(se
+0000d900: 6c66 292c 2073 656c 6629 2e5f 5f69 6e69  lf), self).__ini
+0000d910: 745f 5f28 6d61 746c 6162 5f6d 6f64 656c  t__(matlab_model
+0000d920: 3d6d 6174 6c61 625f 6d6f 6465 6c29 0a20  =matlab_model). 
+0000d930: 2020 2020 2020 2073 656c 662e 666e 616d         self.fnam
+0000d940: 6520 3d20 696e 7370 6563 742e 6765 7466  e = inspect.getf
+0000d950: 696c 6528 696e 7370 6563 742e 6375 7272  ile(inspect.curr
+0000d960: 656e 7466 7261 6d65 2829 290a 0a20 2020  entframe())..   
+0000d970: 2064 6566 2076 616c 6964 6174 6528 7365   def validate(se
+0000d980: 6c66 293a 0a20 2020 2020 2020 2070 6173  lf):.        pas
+0000d990: 730a 0a20 2020 2064 6566 2073 696d 756c  s..    def simul
+0000d9a0: 6174 6528 7365 6c66 2c20 7072 6f63 6573  ate(self, proces
+0000d9b0: 735f 6964 3d4e 6f6e 652c 206d 6174 6c61  s_id=None, matla
+0000d9c0: 625f 656e 6769 6e65 3d4e 6f6e 6529 3a0a  b_engine=None):.
+0000d9d0: 2020 2020 2020 2020 7920 3d20 6e70 2e61          y = np.a
+0000d9e0: 7272 6179 286e 702e 7461 6e68 2831 302e  rray(np.tanh(10.
+0000d9f0: 202a 2073 656c 662e 705b 2278 3122 5d29   * self.p["x1"])
+0000da00: 202b 2030 2e32 202a 206e 702e 7369 6e28   + 0.2 * np.sin(
+0000da10: 3130 2e20 2a20 7365 6c66 2e70 5b22 7831  10. * self.p["x1
+0000da20: 225d 2920 2b20 302e 3320 2a20 7365 6c66  "]) + 0.3 * self
+0000da30: 2e70 5b22 7832 225d 202b 0a20 2020 2020  .p["x2"] +.     
+0000da40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000da50: 302e 3120 2a20 6e70 2e73 696e 2835 2e20  0.1 * np.sin(5. 
+0000da60: 2a20 7365 6c66 2e70 5b22 7831 225d 2929  * self.p["x1"]))
+0000da70: 0a0a 2020 2020 2020 2020 6966 206c 656e  ..        if len
+0000da80: 2879 2920 3e20 313a 0a20 2020 2020 2020  (y) > 1:.       
+0000da90: 2020 2020 2079 203d 2079 5b3a 2c20 6e70       y = y[:, np
+0000daa0: 2e6e 6577 6178 6973 5d0a 0a20 2020 2020  .newaxis]..     
+0000dab0: 2020 2072 6574 7572 6e20 790a 0a0a 636c     return y...cl
+0000dac0: 6173 7320 4d6f 7669 6e67 5061 7274 6963  ass MovingPartic
+0000dad0: 6c65 4672 6963 7469 6f6e 466f 7263 6528  leFrictionForce(
+0000dae0: 4162 7374 7261 6374 4d6f 6465 6c29 3a0a  AbstractModel):.
+0000daf0: 2020 2020 2222 220a 2020 2020 4469 6666      """.    Diff
+0000db00: 6572 656e 7469 616c 2065 7175 6174 696f  erential equatio
+0000db10: 6e20 6465 7363 7269 6269 6e67 2061 2070  n describing a p
+0000db20: 6172 7469 636c 6520 6d6f 7669 6e67 2075  article moving u
+0000db30: 6e64 6572 2074 6865 2069 6e66 6c75 656e  nder the influen
+0000db40: 6365 206f 6620 610a 2020 2020 706f 7465  ce of a.    pote
+0000db50: 6e74 6961 6c20 6669 656c 6420 616e 6420  ntial field and 
+0000db60: 6f66 2061 2066 7269 6374 696f 6e20 666f  of a friction fo
+0000db70: 7263 6520 5b31 5d2e 0a0a 2020 2020 2e2e  rce [1]...    ..
+0000db80: 206d 6174 683a 3a20 5c5c 6672 6163 7b64   math:: \\frac{d
+0000db90: 5e32 2078 7d7b 6474 5e32 7d20 2b20 6620  ^2 x}{dt^2} + f 
+0000dba0: 5c5c 6672 6163 7b64 787d 7b64 747d 203d  \\frac{dx}{dt} =
+0000dbb0: 202d 5c5c 6672 6163 7b33 357d 7b32 7d20   -\\frac{35}{2} 
+0000dbc0: 785e 3320 2b20 5c5c 6672 6163 7b31 357d  x^3 + \\frac{15}
+0000dbd0: 7b32 7d20 780a 0a20 2020 2077 6974 683a  {2} x..    with:
+0000dbe0: 0a0a 2020 2020 2e2e 206d 6174 683a 3a20  ..    .. math:: 
+0000dbf0: 785f 3120 3d20 780a 2020 2020 2e2e 206d  x_1 = x.    .. m
+0000dc00: 6174 683a 3a20 785f 3220 3d20 5c5c 6672  ath:: x_2 = \\fr
+0000dc10: 6163 7b64 787d 7b64 747d 0a0a 2020 2020  ac{dx}{dt}..    
+0000dc20: 7765 2067 6574 2061 2073 7973 7465 6d20  we get a system 
+0000dc30: 6f66 2074 776f 2031 7374 206f 7264 6572  of two 1st order
+0000dc40: 204f 4445 0a0a 2020 2020 2e2e 206d 6174   ODE..    .. mat
+0000dc50: 683a 3a20 5c5c 6672 6163 7b64 2078 5f31  h:: \\frac{d x_1
+0000dc60: 7d7b 6474 7d20 3d20 785f 320a 2020 2020  }{dt} = x_2.    
+0000dc70: 2e2e 206d 6174 683a 3a20 5c5c 6672 6163  .. math:: \\frac
+0000dc80: 7b64 2078 5f32 7d7b 6474 7d20 3d20 2d5c  {d x_2}{dt} = -\
+0000dc90: 5c66 7261 637b 3335 7d7b 327d 2078 5f31  \frac{35}{2} x_1
+0000dca0: 5e33 202b 205c 5c66 7261 637b 3135 7d7b  ^3 + \\frac{15}{
+0000dcb0: 327d 2078 5f31 202d 2066 2078 5f32 0a0a  2} x_1 - f x_2..
+0000dcc0: 2020 2020 4469 7363 6f6e 7469 6e75 6974      Discontinuit
+0000dcd0: 7920 6174 2072 616e 646f 6d6c 7920 7065  y at randomly pe
+0000dce0: 7274 7572 6265 6420 696e 6974 6961 6c20  rturbed initial 
+0000dcf0: 7661 6c75 6520 7830 203d 2058 3020 2b20  value x0 = X0 + 
+0000dd00: 6465 6c74 615f 5820 2a20 7869 203d 2030  delta_X * xi = 0
+0000dd10: 2e30 3520 2d20 302e 3220 2a20 302e 3235  .05 - 0.2 * 0.25
+0000dd20: 0a20 2020 2061 6e64 2074 776f 2073 7461  .    and two sta
+0000dd30: 626c 6520 6669 7865 6420 706f 696e 7473  ble fixed points
+0000dd40: 3a0a 0a20 2020 202e 2e20 6d61 7468 3a3a  :..    .. math::
+0000dd50: 2078 203d 202d 5c73 7172 747b 3135 2f33   x = -\sqrt{15/3
+0000dd60: 357d 205c 3b20 5c6d 6174 6872 6d7b 666f  5} \; \mathrm{fo
+0000dd70: 727d 205c 3b20 5c5c 7869 203c 202d 302e  r} \; \\xi < -0.
+0000dd80: 3235 0a20 2020 202e 2e20 6d61 7468 3a3a  25.    .. math::
+0000dd90: 2078 203d 202b 5c73 7172 747b 3135 2f33   x = +\sqrt{15/3
+0000dda0: 357d 205c 3b20 5c6d 6174 6872 6d7b 666f  5} \; \mathrm{fo
+0000ddb0: 727d 205c 3b20 5c5c 7869 203e 202d 302e  r} \; \\xi > -0.
+0000ddc0: 3235 0a0a 2020 2020 7869 2069 7320 756e  25..    xi is un
+0000ddd0: 6966 6f72 6d20 6469 7374 7269 6275 7465  iform distribute
+0000dde0: 6420 5b2d 312c 2031 5d0a 0a20 2020 204d  d [-1, 1]..    M
+0000ddf0: 6561 6e20 7661 6c75 653a 2030 2e31 3633  ean value: 0.163
+0000de00: 3636 330a 2020 2020 5374 616e 6461 7264  663.    Standard
+0000de10: 2064 6576 6961 7469 6f6e 3a20 302e 3633   deviation: 0.63
+0000de20: 3338 3635 3639 310a 0a20 2020 2050 6172  3865691..    Par
+0000de30: 616d 6574 6572 730a 2020 2020 2d2d 2d2d  ameters.    ----
+0000de40: 2d2d 2d2d 2d2d 0a20 2020 2070 5b22 7869  ------.    p["xi
+0000de50: 225d 3a20 6e64 6172 7261 7920 6f66 2066  "]: ndarray of f
+0000de60: 6c6f 6174 205b 315d 0a20 2020 2020 2020  loat [1].       
+0000de70: 2050 6572 7475 6261 7469 6f6e 2078 6920   Pertubation xi 
+0000de80: 6f66 2069 6e69 7469 616c 2076 616c 7565  of initial value
+0000de90: 2078 3020 2878 3020 3d20 5830 202b 2078   x0 (x0 = X0 + x
+0000dea0: 6929 205b 2d31 2c20 315d 0a0a 2020 2020  i) [-1, 1]..    
+0000deb0: 5265 7475 726e 730a 2020 2020 2d2d 2d2d  Returns.    ----
+0000dec0: 2d2d 2d0a 2020 2020 793a 206e 6461 7272  ---.    y: ndarr
+0000ded0: 6179 206f 6620 666c 6f61 7420 5b31 2078  ay of float [1 x
+0000dee0: 2031 5d0a 2020 2020 2020 2020 7828 743d   1].        x(t=
+0000def0: 3130 2e29 0a0a 2020 2020 4e6f 7465 730a  10.)..    Notes.
+0000df00: 2020 2020 2d2d 2d2d 2d0a 2020 2020 2e2e      -----.    ..
+0000df10: 2070 6c6f 743a 3a0a 0a20 2020 2020 2020   plot::..       
+0000df20: 696d 706f 7274 206e 756d 7079 2061 7320  import numpy as 
+0000df30: 6e70 0a20 2020 2020 2020 6672 6f6d 2070  np.       from p
+0000df40: 7967 7063 2e74 6573 7466 756e 6374 696f  ygpc.testfunctio
+0000df50: 6e73 2069 6d70 6f72 7420 706c 6f74 5f74  ns import plot_t
+0000df60: 6573 7466 756e 6374 696f 6e20 6173 2070  estfunction as p
+0000df70: 6c6f 740a 2020 2020 2020 2066 726f 6d20  lot.       from 
+0000df80: 636f 6c6c 6563 7469 6f6e 7320 696d 706f  collections impo
+0000df90: 7274 204f 7264 6572 6564 4469 6374 0a0a  rt OrderedDict..
+0000dfa0: 2020 2020 2020 2070 6172 616d 6574 6572         parameter
+0000dfb0: 7320 3d20 4f72 6465 7265 6444 6963 7428  s = OrderedDict(
+0000dfc0: 290a 2020 2020 2020 2070 6172 616d 6574  ).       paramet
+0000dfd0: 6572 735b 2278 6922 5d20 3d20 6e70 2e6c  ers["xi"] = np.l
+0000dfe0: 696e 7370 6163 6528 2d31 2c20 312c 2031  inspace(-1, 1, 1
+0000dff0: 3030 290a 0a20 2020 2020 2020 706c 6f74  00)..       plot
+0000e000: 2822 4d6f 7669 6e67 5061 7274 6963 6c65  ("MovingParticle
+0000e010: 4672 6963 7469 6f6e 466f 7263 6522 2c20  FrictionForce", 
+0000e020: 7061 7261 6d65 7465 7273 290a 0a20 2020  parameters)..   
+0000e030: 202e 2e20 5b31 5d20 4c65 204d 6169 7472   .. [1] Le Maitr
+0000e040: 652c 204f 2e50 2e2c 204b 6e69 6f2c 204f  e, O.P., Knio, O
+0000e050: 2e4d 2e2c 204e 616a 6d2c 2048 2e4e 2e2c  .M., Najm, H.N.,
+0000e060: 2047 6861 6e65 6d2c 2052 2e47 2e20 2832   Ghanem, R.G. (2
+0000e070: 3030 3429 2e0a 2020 2020 2020 2055 6e63  004)..       Unc
+0000e080: 6572 7461 696e 7479 2070 726f 7061 6761  ertainty propaga
+0000e090: 7469 6f6e 2075 7369 6e67 2057 6965 6e65  tion using Wiene
+0000e0a0: 722d 4861 6172 2065 7870 616e 7369 6f6e  r-Haar expansion
+0000e0b0: 732e 0a20 2020 2020 2020 4a6f 7572 6e61  s..       Journa
+0000e0c0: 6c20 6f66 2043 6f6d 7075 7461 7469 6f6e  l of Computation
+0000e0d0: 616c 2050 6879 7369 6373 2c20 3139 372c  al Physics, 197,
+0000e0e0: 2032 382d 3537 2e0a 2020 2020 2222 220a   28-57..    """.
+0000e0f0: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
+0000e100: 5f28 7365 6c66 2c20 6d61 746c 6162 5f6d  _(self, matlab_m
+0000e110: 6f64 656c 3d46 616c 7365 293a 0a20 2020  odel=False):.   
+0000e120: 2020 2020 2073 7570 6572 2874 7970 6528       super(type(
+0000e130: 7365 6c66 292c 2073 656c 6629 2e5f 5f69  self), self).__i
+0000e140: 6e69 745f 5f28 6d61 746c 6162 5f6d 6f64  nit__(matlab_mod
+0000e150: 656c 3d6d 6174 6c61 625f 6d6f 6465 6c29  el=matlab_model)
+0000e160: 0a20 2020 2020 2020 2073 656c 662e 666e  .        self.fn
+0000e170: 616d 6520 3d20 696e 7370 6563 742e 6765  ame = inspect.ge
+0000e180: 7466 696c 6528 696e 7370 6563 742e 6375  tfile(inspect.cu
+0000e190: 7272 656e 7466 7261 6d65 2829 290a 0a20  rrentframe()).. 
+0000e1a0: 2020 2064 6566 2076 616c 6964 6174 6528     def validate(
+0000e1b0: 7365 6c66 293a 0a20 2020 2020 2020 2070  self):.        p
+0000e1c0: 6173 730a 0a20 2020 2064 6566 2073 696d  ass..    def sim
+0000e1d0: 756c 6174 6528 7365 6c66 2c20 7072 6f63  ulate(self, proc
+0000e1e0: 6573 735f 6964 3d4e 6f6e 652c 206d 6174  ess_id=None, mat
+0000e1f0: 6c61 625f 656e 6769 6e65 3d4e 6f6e 6529  lab_engine=None)
+0000e200: 3a0a 2020 2020 2020 2020 2320 5379 7374  :.        # Syst
+0000e210: 656d 206f 6620 3173 7420 6f72 6465 7220  em of 1st order 
+0000e220: 4445 510a 2020 2020 2020 2020 6465 6620  DEQ.        def 
+0000e230: 6465 7128 782c 2074 2c20 6629 3a0a 2020  deq(x, t, f):.  
+0000e240: 2020 2020 2020 2020 2020 7265 7475 726e            return
+0000e250: 2078 5b31 5d2c 202d 3335 2e20 2f20 322e   x[1], -35. / 2.
+0000e260: 202a 2078 5b30 5d20 2a2a 2033 2e20 2b20   * x[0] ** 3. + 
+0000e270: 3135 2e20 2f20 322e 202a 2078 5b30 5d20  15. / 2. * x[0] 
+0000e280: 2d20 6620 2a20 785b 315d 0a0a 2020 2020  - f * x[1]..    
+0000e290: 2020 2020 2320 496e 6974 6961 6c20 7661      # Initial va
+0000e2a0: 6c75 6573 0a20 2020 2020 2020 2078 3020  lues.        x0 
+0000e2b0: 3d20 302e 3035 0a20 2020 2020 2020 2064  = 0.05.        d
+0000e2c0: 656c 7461 5f78 203d 2030 2e32 0a0a 2020  elta_x = 0.2..  
+0000e2d0: 2020 2020 2020 2320 4672 6963 7469 6f6e        # Friction
+0000e2e0: 2063 6f65 6666 6963 6965 6e74 0a20 2020   coefficient.   
+0000e2f0: 2020 2020 2066 203d 2032 2e0a 0a20 2020       f = 2...   
+0000e300: 2020 2020 2023 2053 696d 756c 6174 696f       # Simulatio
+0000e310: 6e20 7061 7261 6d65 7465 7273 0a20 2020  n parameters.   
+0000e320: 2020 2020 2064 7420 3d20 302e 3030 310a       dt = 0.001.
+0000e330: 2020 2020 2020 2020 745f 656e 6420 3d20          t_end = 
+0000e340: 3130 2e0a 2020 2020 2020 2020 7420 3d20  10..        t = 
+0000e350: 6e70 2e61 7261 6e67 6528 302c 2074 5f65  np.arange(0, t_e
+0000e360: 6e64 2c20 6474 290a 0a20 2020 2020 2020  nd, dt)..       
+0000e370: 2023 2053 6f6c 7665 0a20 2020 2020 2020   # Solve.       
+0000e380: 2079 5f6f 7574 203d 206e 702e 7a65 726f   y_out = np.zero
+0000e390: 7328 286c 656e 2873 656c 662e 705b 2278  s((len(self.p["x
+0000e3a0: 6922 5d29 2c20 3129 290a 0a20 2020 2020  i"]), 1))..     
+0000e3b0: 2020 2066 6f72 2069 2069 6e20 7261 6e67     for i in rang
+0000e3c0: 6528 6c65 6e28 795f 6f75 7429 293a 0a20  e(len(y_out)):. 
+0000e3d0: 2020 2020 2020 2020 2020 2078 305f 696e             x0_in
+0000e3e0: 6974 203d 205b 7830 202b 2064 656c 7461  it = [x0 + delta
+0000e3f0: 5f78 202a 2073 656c 662e 705b 2278 6922  _x * self.p["xi"
+0000e400: 5d2e 666c 6174 7465 6e28 295b 695d 2c20  ].flatten()[i], 
+0000e410: 302e 5d0a 2020 2020 2020 2020 2020 2020  0.].            
+0000e420: 7920 3d20 6f64 6569 6e74 2864 6571 2c20  y = odeint(deq, 
+0000e430: 7830 5f69 6e69 742c 2074 2c20 6172 6773  x0_init, t, args
+0000e440: 3d28 662c 292c 2068 6d69 6e3d 6474 290a  =(f,), hmin=dt).
+0000e450: 2020 2020 2020 2020 2020 2020 795f 6f75              y_ou
+0000e460: 745b 692c 2030 5d20 3d20 6e70 2e61 7272  t[i, 0] = np.arr
+0000e470: 6179 285b 5b79 5b2d 312c 2030 5d5d 5d29  ay([[y[-1, 0]]])
+0000e480: 0a0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+0000e490: 2079 5f6f 7574 0a0a 0a63 6c61 7373 2053   y_out...class S
+0000e4a0: 7572 6661 6365 436f 7665 7261 6765 5370  urfaceCoverageSp
+0000e4b0: 6563 6965 7328 4162 7374 7261 6374 4d6f  ecies(AbstractMo
+0000e4c0: 6465 6c29 3a0a 2020 2020 2222 220a 2020  del):.    """.  
+0000e4d0: 2020 4469 6666 6572 656e 7469 616c 2065    Differential e
+0000e4e0: 7175 6174 696f 6e20 6465 7363 7269 6269  quation describi
+0000e4f0: 6e67 2074 6865 2074 696d 652d 6576 6f6c  ng the time-evol
+0000e500: 7574 696f 6e20 6f66 2074 6865 2073 7572  ution of the sur
+0000e510: 6661 6365 2063 6f76 6572 6167 6520 7268  face coverage rh
+0000e520: 6f20 5b30 2c20 315d 2066 6f72 2061 2067  o [0, 1] for a g
+0000e530: 6976 656e 2073 7065 6369 6573 205b 315d  iven species [1]
+0000e540: 2e0a 2020 2020 5468 6973 2070 726f 626c  ..    This probl
+0000e550: 656d 2068 6173 206f 6e65 206f 7220 7477  em has one or tw
+0000e560: 6f20 6669 7865 6420 706f 696e 7473 2061  o fixed points a
+0000e570: 6363 6f72 6469 6e67 2074 6f20 7468 6520  ccording to the 
+0000e580: 7661 6c75 6520 6f66 2074 6865 2072 6563  value of the rec
+0000e590: 6f6d 6269 6e61 7469 6f6e 2072 6174 6520  ombination rate 
+0000e5a0: 6265 7461 2061 6e64 2069 7420 6578 6869  beta and it exhi
+0000e5b0: 6269 7473 0a20 2020 2073 6d6f 6f74 6820  bits.    smooth 
+0000e5c0: 6465 7065 6e64 656e 6365 206f 6e20 7468  dependence on th
+0000e5d0: 6520 6f74 6865 7220 7061 7261 6d65 7465  e other paramete
+0000e5e0: 7273 2e20 5468 6520 7374 6174 6973 7469  rs. The statisti
+0000e5f0: 6373 206f 6620 7468 6520 736f 6c75 7469  cs of the soluti
+0000e600: 6f6e 2061 7420 743d 3120 6172 6520 696e  on at t=1 are in
+0000e610: 7665 7374 6967 6174 6564 2063 6f6e 7369  vestigated consi
+0000e620: 6465 7269 6e67 0a20 2020 2075 6e63 6572  dering.    uncer
+0000e630: 7461 696e 7469 6573 2069 6e20 7468 6520  tainties in the 
+0000e640: 696e 6974 6961 6c20 636f 7665 7261 6765  initial coverage
+0000e650: 2072 686f 5f30 2061 6e64 2069 6e20 7468   rho_0 and in th
+0000e660: 6520 7265 6163 7469 6f6e 2070 6172 616d  e reaction param
+0000e670: 6574 6572 2062 6574 612e 2041 6464 6974  eter beta. Addit
+0000e680: 696f 6e61 6c6c 7920 756e 6365 7274 6169  ionally uncertai
+0000e690: 6e74 790a 2020 2020 696e 2074 6865 2073  nty.    in the s
+0000e6a0: 7572 6661 6365 2061 6273 6f72 7074 696f  urface absorptio
+0000e6b0: 6e20 7261 7465 2061 6c70 6861 2063 616e  n rate alpha can
+0000e6c0: 2062 6520 636f 6e73 6964 6572 6564 2074   be considered t
+0000e6d0: 6f20 6d61 6b65 2074 6865 2070 726f 626c  o make the probl
+0000e6e0: 656d 2033 2d64 696d 656e 7369 6f6e 616c  em 3-dimensional
+0000e6f0: 2e0a 2020 2020 4761 6d6d 613d 302e 3031  ..    Gamma=0.01
+0000e700: 2064 656e 6f74 6573 2074 6865 2064 6573   denotes the des
+0000e710: 6f72 7074 696f 6e20 7261 7465 2e0a 0a20  orption rate... 
+0000e720: 2020 202e 2e20 6d61 7468 3a3a 205c 5c66     .. math:: \\f
+0000e730: 7261 637b 645c 5c72 686f 7d7b 6474 7d20  rac{d\\rho}{dt} 
+0000e740: 3d20 5c5c 616c 7068 6120 2831 202d 205c  = \\alpha (1 - \
+0000e750: 5c72 686f 2920 2d20 5c5c 6761 6d6d 6120  \rho) - \\gamma 
+0000e760: 5c5c 7268 6f20 2d20 5c5c 6265 7461 2028  \\rho - \\beta (
+0000e770: 5c5c 7268 6f20 2d20 3129 5e32 205c 5c72  \\rho - 1)^2 \\r
+0000e780: 686f 0a0a 2020 2020 5061 7261 6d65 7465  ho..    Paramete
+0000e790: 7273 0a20 2020 202d 2d2d 2d2d 2d2d 2d2d  rs.    ---------
+0000e7a0: 2d0a 2020 2020 705b 2272 686f 5f30 225d  -.    p["rho_0"]
+0000e7b0: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
+0000e7c0: 6174 205b 315d 0a20 2020 2020 2020 2049  at [1].        I
+0000e7d0: 6e69 7469 616c 2076 616c 7565 2072 686f  nitial value rho
+0000e7e0: 2874 3d30 2920 2875 6e69 666f 726d 2064  (t=0) (uniform d
+0000e7f0: 6973 7472 6962 7574 6564 205b 302c 2031  istributed [0, 1
+0000e800: 5d29 0a20 2020 2070 5b22 6265 7461 225d  ]).    p["beta"]
+0000e810: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
+0000e820: 6174 205b 315d 0a20 2020 2020 2020 2052  at [1].        R
+0000e830: 6563 6f6d 6269 6e61 7469 6f6e 2072 6174  ecombination rat
+0000e840: 6520 2875 6e69 666f 726d 2064 6973 7472  e (uniform distr
+0000e850: 6962 7574 6564 205b 302c 2032 305d 290a  ibuted [0, 20]).
+0000e860: 2020 2020 705b 2261 6c70 6861 225d 3a20      p["alpha"]: 
+0000e870: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
+0000e880: 205b 315d 0a20 2020 2020 2020 2053 7572   [1].        Sur
+0000e890: 6661 6365 2061 6273 6f72 7074 696f 6e20  face absorption 
+0000e8a0: 7261 7465 2028 3120 6f72 2075 6e69 666f  rate (1 or unifo
+0000e8b0: 726d 2064 6973 7472 6962 7574 6564 205b  rm distributed [
+0000e8c0: 302e 312c 2032 5d29 0a0a 2020 2020 5265  0.1, 2])..    Re
+0000e8d0: 7475 726e 730a 2020 2020 2d2d 2d2d 2d2d  turns.    ------
+0000e8e0: 2d0a 2020 2020 793a 206e 6461 7272 6179  -.    y: ndarray
+0000e8f0: 206f 6620 666c 6f61 7420 5b31 2078 2031   of float [1 x 1
+0000e900: 5d0a 2020 2020 2020 2020 7268 6f28 742d  ].        rho(t-
+0000e910: 3e31 290a 0a20 2020 204e 6f74 6573 0a20  >1)..    Notes. 
+0000e920: 2020 202d 2d2d 2d2d 0a20 2020 202e 2e20     -----.    .. 
+0000e930: 706c 6f74 3a3a 0a0a 2020 2020 2020 2069  plot::..       i
+0000e940: 6d70 6f72 7420 6e75 6d70 7920 6173 206e  mport numpy as n
+0000e950: 700a 2020 2020 2020 2066 726f 6d20 7079  p.       from py
+0000e960: 6770 632e 7465 7374 6675 6e63 7469 6f6e  gpc.testfunction
+0000e970: 7320 696d 706f 7274 2070 6c6f 745f 7465  s import plot_te
+0000e980: 7374 6675 6e63 7469 6f6e 2061 7320 706c  stfunction as pl
+0000e990: 6f74 0a20 2020 2020 2020 6672 6f6d 2063  ot.       from c
+0000e9a0: 6f6c 6c65 6374 696f 6e73 2069 6d70 6f72  ollections impor
+0000e9b0: 7420 4f72 6465 7265 6444 6963 740a 0a20  t OrderedDict.. 
+0000e9c0: 2020 2020 2020 7061 7261 6d65 7465 7273        parameters
+0000e9d0: 203d 204f 7264 6572 6564 4469 6374 2829   = OrderedDict()
+0000e9e0: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
+0000e9f0: 7273 5b22 7268 6f5f 3022 5d20 3d20 6e70  rs["rho_0"] = np
+0000ea00: 2e6c 696e 7370 6163 6528 302c 2031 2c20  .linspace(0, 1, 
+0000ea10: 3130 3029 0a20 2020 2020 2020 7061 7261  100).       para
+0000ea20: 6d65 7465 7273 5b22 6265 7461 225d 203d  meters["beta"] =
+0000ea30: 206e 702e 6c69 6e73 7061 6365 2830 2c20   np.linspace(0, 
+0000ea40: 3230 2c20 3130 3029 0a0a 2020 2020 2020  20, 100)..      
+0000ea50: 2063 6f6e 7374 616e 7473 203d 204f 7264   constants = Ord
+0000ea60: 6572 6564 4469 6374 2829 0a20 2020 2020  eredDict().     
+0000ea70: 2020 636f 6e73 7461 6e74 735b 2261 6c70    constants["alp
+0000ea80: 6861 225d 203d 2031 2e0a 0a20 2020 2020  ha"] = 1...     
+0000ea90: 2020 706c 6f74 2822 5375 7266 6163 6543    plot("SurfaceC
+0000eaa0: 6f76 6572 6167 6553 7065 6369 6573 222c  overageSpecies",
+0000eab0: 2070 6172 616d 6574 6572 732c 2063 6f6e   parameters, con
+0000eac0: 7374 616e 7473 2c20 706c 6f74 5f33 643d  stants, plot_3d=
+0000ead0: 4661 6c73 6529 0a0a 2020 2020 2e2e 205b  False)..    .. [
+0000eae0: 315d 204c 6520 4d61 6974 7265 2c20 4f2e  1] Le Maitre, O.
+0000eaf0: 502e 2c20 4e61 6a6d 2c20 482e 4e2e 2c20  P., Najm, H.N., 
+0000eb00: 4768 616e 656d 2c20 522e 472e 2c20 4b6e  Ghanem, R.G., Kn
+0000eb10: 696f 2c20 4f2e 4d2e 2c20 2832 3030 3429  io, O.M., (2004)
+0000eb20: 2e0a 2020 2020 2020 204d 756c 7469 2d72  ..       Multi-r
+0000eb30: 6573 6f6c 7574 696f 6e20 616e 616c 7973  esolution analys
+0000eb40: 6973 206f 6620 5769 656e 6572 2d74 7970  is of Wiener-typ
+0000eb50: 6520 756e 6365 7274 6169 6e74 7920 7072  e uncertainty pr
+0000eb60: 6f70 6167 6174 696f 6e20 7363 6865 6d65  opagation scheme
+0000eb70: 732e 0a20 2020 2020 2020 4a6f 7572 6e61  s..       Journa
+0000eb80: 6c20 6f66 2043 6f6d 7075 7461 7469 6f6e  l of Computation
+0000eb90: 616c 2050 6879 7369 6373 2c20 3139 372c  al Physics, 197,
+0000eba0: 2035 3032 2d35 3331 2e0a 2020 2020 2222   502-531..    ""
+0000ebb0: 220a 0a20 2020 2064 6566 205f 5f69 6e69  "..    def __ini
+0000ebc0: 745f 5f28 7365 6c66 2c20 6d61 746c 6162  t__(self, matlab
+0000ebd0: 5f6d 6f64 656c 3d46 616c 7365 293a 0a20  _model=False):. 
+0000ebe0: 2020 2020 2020 2073 7570 6572 2874 7970         super(typ
+0000ebf0: 6528 7365 6c66 292c 2073 656c 6629 2e5f  e(self), self)._
+0000ec00: 5f69 6e69 745f 5f28 6d61 746c 6162 5f6d  _init__(matlab_m
+0000ec10: 6f64 656c 3d6d 6174 6c61 625f 6d6f 6465  odel=matlab_mode
+0000ec20: 6c29 0a20 2020 2020 2020 2073 656c 662e  l).        self.
+0000ec30: 666e 616d 6520 3d20 696e 7370 6563 742e  fname = inspect.
+0000ec40: 6765 7466 696c 6528 696e 7370 6563 742e  getfile(inspect.
+0000ec50: 6375 7272 656e 7466 7261 6d65 2829 290a  currentframe()).
+0000ec60: 0a20 2020 2064 6566 2076 616c 6964 6174  .    def validat
+0000ec70: 6528 7365 6c66 293a 0a20 2020 2020 2020  e(self):.       
+0000ec80: 2070 6173 730a 0a20 2020 2064 6566 2073   pass..    def s
+0000ec90: 696d 756c 6174 6528 7365 6c66 2c20 7072  imulate(self, pr
+0000eca0: 6f63 6573 735f 6964 3d4e 6f6e 652c 206d  ocess_id=None, m
+0000ecb0: 6174 6c61 625f 656e 6769 6e65 3d4e 6f6e  atlab_engine=Non
+0000ecc0: 6529 3a0a 2020 2020 2020 2020 2320 5379  e):.        # Sy
+0000ecd0: 7374 656d 206f 6620 3173 7420 6f72 6465  stem of 1st orde
+0000ece0: 7220 4445 510a 2020 2020 2020 2020 6465  r DEQ.        de
+0000ecf0: 6620 6465 7128 7268 6f2c 2074 2c20 616c  f deq(rho, t, al
+0000ed00: 7068 612c 2062 6574 612c 2067 616d 6d61  pha, beta, gamma
+0000ed10: 293a 0a20 2020 2020 2020 2020 2020 2072  ):.            r
+0000ed20: 6574 7572 6e20 616c 7068 6120 2a20 2831  eturn alpha * (1
+0000ed30: 2e20 2d20 7268 6f29 202d 2067 616d 6d61  . - rho) - gamma
+0000ed40: 202a 2072 686f 202d 2062 6574 6120 2a20   * rho - beta * 
+0000ed50: 2872 686f 202d 2031 2920 2a2a 2032 202a  (rho - 1) ** 2 *
+0000ed60: 2072 686f 0a0a 2020 2020 2020 2020 2320   rho..        # 
+0000ed70: 436f 6e73 7461 6e74 730a 2020 2020 2020  Constants.      
+0000ed80: 2020 6761 6d6d 6120 3d20 302e 3031 0a0a    gamma = 0.01..
+0000ed90: 2020 2020 2020 2020 2320 5369 6d75 6c61          # Simula
+0000eda0: 7469 6f6e 2070 6172 616d 6574 6572 730a  tion parameters.
+0000edb0: 2020 2020 2020 2020 6474 203d 2030 2e30          dt = 0.0
+0000edc0: 310a 2020 2020 2020 2020 745f 656e 6420  1.        t_end 
+0000edd0: 3d20 312e 0a20 2020 2020 2020 2074 203d  = 1..        t =
+0000ede0: 206e 702e 6172 616e 6765 2830 2c20 745f   np.arange(0, t_
+0000edf0: 656e 642c 2064 7429 0a0a 2020 2020 2020  end, dt)..      
+0000ee00: 2020 2320 536f 6c76 650a 2020 2020 2020    # Solve.      
+0000ee10: 2020 795f 6f75 7420 3d20 6e70 2e7a 6572    y_out = np.zer
+0000ee20: 6f73 2828 6c65 6e28 7365 6c66 2e70 5b22  os((len(self.p["
+0000ee30: 7268 6f5f 3022 5d29 2c20 3129 290a 0a20  rho_0"]), 1)).. 
+0000ee40: 2020 2020 2020 2066 6f72 2069 2069 6e20         for i in 
+0000ee50: 7261 6e67 6528 6c65 6e28 795f 6f75 7429  range(len(y_out)
+0000ee60: 293a 0a20 2020 2020 2020 2020 2020 2079  ):.            y
+0000ee70: 203d 206f 6465 696e 7428 6465 712c 2073   = odeint(deq, s
+0000ee80: 656c 662e 705b 2272 686f 5f30 225d 2e66  elf.p["rho_0"].f
+0000ee90: 6c61 7474 656e 2829 5b69 5d2c 2074 2c0a  latten()[i], t,.
+0000eea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000eeb0: 2020 2020 2020 2061 7267 733d 2873 656c         args=(sel
+0000eec0: 662e 705b 2261 6c70 6861 225d 2e66 6c61  f.p["alpha"].fla
+0000eed0: 7474 656e 2829 5b69 5d2c 2073 656c 662e  tten()[i], self.
+0000eee0: 705b 2262 6574 6122 5d2e 666c 6174 7465  p["beta"].flatte
+0000eef0: 6e28 295b 695d 2c20 6761 6d6d 612c 2929  n()[i], gamma,))
+0000ef00: 0a20 2020 2020 2020 2020 2020 2079 5f6f  .            y_o
+0000ef10: 7574 5b69 2c20 305d 203d 206e 702e 6172  ut[i, 0] = np.ar
+0000ef20: 7261 7928 5b79 5b2d 315d 5d29 0a0a 2020  ray([y[-1]])..  
+0000ef30: 2020 2020 2020 2320 795f 6f75 7420 3d20        # y_out = 
+0000ef40: 6e70 2e68 7374 6163 6b28 2879 5f6f 7574  np.hstack((y_out
+0000ef50: 2c20 322e 2a79 5f6f 7574 2929 0a0a 2020  , 2.*y_out))..  
+0000ef60: 2020 2020 2020 7265 7475 726e 2079 5f6f        return y_o
+0000ef70: 7574 0a0a 0a63 6c61 7373 2053 7572 6661  ut...class Surfa
+0000ef80: 6365 436f 7665 7261 6765 5370 6563 6965  ceCoverageSpecie
+0000ef90: 735f 4e61 4e28 4162 7374 7261 6374 4d6f  s_NaN(AbstractMo
+0000efa0: 6465 6c29 3a0a 2020 2020 2222 220a 2020  del):.    """.  
+0000efb0: 2020 4469 6666 6572 656e 7469 616c 2065    Differential e
+0000efc0: 7175 6174 696f 6e20 6465 7363 7269 6269  quation describi
+0000efd0: 6e67 2074 6865 2074 696d 652d 6576 6f6c  ng the time-evol
+0000efe0: 7574 696f 6e20 6f66 2074 6865 2073 7572  ution of the sur
+0000eff0: 6661 6365 2063 6f76 6572 6167 6520 7268  face coverage rh
+0000f000: 6f20 5b30 2c20 315d 2066 6f72 2061 2067  o [0, 1] for a g
+0000f010: 6976 656e 2073 7065 6369 6573 205b 315d  iven species [1]
+0000f020: 2e0a 2020 2020 5468 6973 2070 726f 626c  ..    This probl
+0000f030: 656d 2068 6173 206f 6e65 206f 7220 7477  em has one or tw
+0000f040: 6f20 6669 7865 6420 706f 696e 7473 2061  o fixed points a
+0000f050: 6363 6f72 6469 6e67 2074 6f20 7468 6520  ccording to the 
+0000f060: 7661 6c75 6520 6f66 2074 6865 2072 6563  value of the rec
+0000f070: 6f6d 6269 6e61 7469 6f6e 2072 6174 6520  ombination rate 
+0000f080: 6265 7461 2061 6e64 2069 7420 6578 6869  beta and it exhi
+0000f090: 6269 7473 0a20 2020 2073 6d6f 6f74 6820  bits.    smooth 
+0000f0a0: 6465 7065 6e64 656e 6365 206f 6e20 7468  dependence on th
+0000f0b0: 6520 6f74 6865 7220 7061 7261 6d65 7465  e other paramete
+0000f0c0: 7273 2e20 5468 6520 7374 6174 6973 7469  rs. The statisti
+0000f0d0: 6373 206f 6620 7468 6520 736f 6c75 7469  cs of the soluti
+0000f0e0: 6f6e 2061 7420 743d 3120 6172 6520 696e  on at t=1 are in
+0000f0f0: 7665 7374 6967 6174 6564 2063 6f6e 7369  vestigated consi
+0000f100: 6465 7269 6e67 0a20 2020 2075 6e63 6572  dering.    uncer
+0000f110: 7461 696e 7469 6573 2069 6e20 7468 6520  tainties in the 
+0000f120: 696e 6974 6961 6c20 636f 7665 7261 6765  initial coverage
+0000f130: 2072 686f 5f30 2061 6e64 2069 6e20 7468   rho_0 and in th
+0000f140: 6520 7265 6163 7469 6f6e 2070 6172 616d  e reaction param
+0000f150: 6574 6572 2062 6574 612e 2041 6464 6974  eter beta. Addit
+0000f160: 696f 6e61 6c6c 7920 756e 6365 7274 6169  ionally uncertai
+0000f170: 6e74 790a 2020 2020 696e 2074 6865 2073  nty.    in the s
+0000f180: 7572 6661 6365 2061 6273 6f72 7074 696f  urface absorptio
+0000f190: 6e20 7261 7465 2061 6c70 6861 2063 616e  n rate alpha can
+0000f1a0: 2062 6520 636f 6e73 6964 6572 6564 2074   be considered t
+0000f1b0: 6f20 6d61 6b65 2074 6865 2070 726f 626c  o make the probl
+0000f1c0: 656d 2033 2d64 696d 656e 7369 6f6e 616c  em 3-dimensional
+0000f1d0: 2e0a 2020 2020 4761 6d6d 613d 302e 3031  ..    Gamma=0.01
+0000f1e0: 2064 656e 6f74 6573 2074 6865 2064 6573   denotes the des
+0000f1f0: 6f72 7074 696f 6e20 7261 7465 2e0a 0a20  orption rate... 
+0000f200: 2020 202e 2e20 6d61 7468 3a3a 205c 5c66     .. math:: \\f
+0000f210: 7261 637b 645c 5c72 686f 7d7b 6474 7d20  rac{d\\rho}{dt} 
+0000f220: 3d20 5c5c 616c 7068 6120 2831 202d 205c  = \\alpha (1 - \
+0000f230: 5c72 686f 2920 2d20 5c5c 6761 6d6d 6120  \rho) - \\gamma 
+0000f240: 5c5c 7268 6f20 2d20 5c5c 6265 7461 2028  \\rho - \\beta (
+0000f250: 5c5c 7268 6f20 2d20 3129 5e32 205c 5c72  \\rho - 1)^2 \\r
+0000f260: 686f 0a0a 2020 2020 5061 7261 6d65 7465  ho..    Paramete
+0000f270: 7273 0a20 2020 202d 2d2d 2d2d 2d2d 2d2d  rs.    ---------
+0000f280: 2d0a 2020 2020 705b 2272 686f 5f30 225d  -.    p["rho_0"]
+0000f290: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
+0000f2a0: 6174 205b 315d 0a20 2020 2020 2020 2049  at [1].        I
+0000f2b0: 6e69 7469 616c 2076 616c 7565 2072 686f  nitial value rho
+0000f2c0: 2874 3d30 2920 2875 6e69 666f 726d 2064  (t=0) (uniform d
+0000f2d0: 6973 7472 6962 7574 6564 205b 302c 2031  istributed [0, 1
+0000f2e0: 5d29 0a20 2020 2070 5b22 6265 7461 225d  ]).    p["beta"]
+0000f2f0: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
+0000f300: 6174 205b 315d 0a20 2020 2020 2020 2052  at [1].        R
+0000f310: 6563 6f6d 6269 6e61 7469 6f6e 2072 6174  ecombination rat
+0000f320: 6520 2875 6e69 666f 726d 2064 6973 7472  e (uniform distr
+0000f330: 6962 7574 6564 205b 302c 2032 305d 290a  ibuted [0, 20]).
+0000f340: 2020 2020 705b 2261 6c70 6861 225d 3a20      p["alpha"]: 
+0000f350: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
+0000f360: 205b 315d 0a20 2020 2020 2020 2053 7572   [1].        Sur
+0000f370: 6661 6365 2061 6273 6f72 7074 696f 6e20  face absorption 
+0000f380: 7261 7465 2028 3120 6f72 2075 6e69 666f  rate (1 or unifo
+0000f390: 726d 2064 6973 7472 6962 7574 6564 205b  rm distributed [
+0000f3a0: 302e 312c 2032 5d29 0a0a 2020 2020 5265  0.1, 2])..    Re
+0000f3b0: 7475 726e 730a 2020 2020 2d2d 2d2d 2d2d  turns.    ------
+0000f3c0: 2d0a 2020 2020 793a 206e 6461 7272 6179  -.    y: ndarray
+0000f3d0: 206f 6620 666c 6f61 7420 5b31 2078 2031   of float [1 x 1
+0000f3e0: 5d0a 2020 2020 2020 2020 7268 6f28 742d  ].        rho(t-
+0000f3f0: 3e31 290a 0a20 2020 204e 6f74 6573 0a20  >1)..    Notes. 
+0000f400: 2020 202d 2d2d 2d2d 0a20 2020 202e 2e20     -----.    .. 
+0000f410: 706c 6f74 3a3a 0a0a 2020 2020 2020 2069  plot::..       i
+0000f420: 6d70 6f72 7420 6e75 6d70 7920 6173 206e  mport numpy as n
+0000f430: 700a 2020 2020 2020 2066 726f 6d20 7079  p.       from py
+0000f440: 6770 632e 7465 7374 6675 6e63 7469 6f6e  gpc.testfunction
+0000f450: 7320 696d 706f 7274 2070 6c6f 745f 7465  s import plot_te
+0000f460: 7374 6675 6e63 7469 6f6e 2061 7320 706c  stfunction as pl
+0000f470: 6f74 0a20 2020 2020 2020 6672 6f6d 2063  ot.       from c
+0000f480: 6f6c 6c65 6374 696f 6e73 2069 6d70 6f72  ollections impor
+0000f490: 7420 4f72 6465 7265 6444 6963 740a 0a20  t OrderedDict.. 
+0000f4a0: 2020 2020 2020 7061 7261 6d65 7465 7273        parameters
+0000f4b0: 203d 204f 7264 6572 6564 4469 6374 2829   = OrderedDict()
+0000f4c0: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
+0000f4d0: 7273 5b22 7268 6f5f 3022 5d20 3d20 6e70  rs["rho_0"] = np
+0000f4e0: 2e6c 696e 7370 6163 6528 302c 2031 2c20  .linspace(0, 1, 
+0000f4f0: 3130 3029 0a20 2020 2020 2020 7061 7261  100).       para
+0000f500: 6d65 7465 7273 5b22 6265 7461 225d 203d  meters["beta"] =
+0000f510: 206e 702e 6c69 6e73 7061 6365 2830 2c20   np.linspace(0, 
+0000f520: 3230 2c20 3130 3029 0a0a 2020 2020 2020  20, 100)..      
+0000f530: 2063 6f6e 7374 616e 7473 203d 204f 7264   constants = Ord
+0000f540: 6572 6564 4469 6374 2829 0a20 2020 2020  eredDict().     
+0000f550: 2020 636f 6e73 7461 6e74 735b 2261 6c70    constants["alp
+0000f560: 6861 225d 203d 2031 2e0a 0a20 2020 2020  ha"] = 1...     
+0000f570: 2020 706c 6f74 2822 5375 7266 6163 6543    plot("SurfaceC
+0000f580: 6f76 6572 6167 6553 7065 6369 6573 222c  overageSpecies",
+0000f590: 2070 6172 616d 6574 6572 732c 2063 6f6e   parameters, con
+0000f5a0: 7374 616e 7473 2c20 706c 6f74 5f33 643d  stants, plot_3d=
+0000f5b0: 4661 6c73 6529 0a0a 2020 2020 2e2e 205b  False)..    .. [
+0000f5c0: 315d 204c 6520 4d61 6974 7265 2c20 4f2e  1] Le Maitre, O.
+0000f5d0: 502e 2c20 4e61 6a6d 2c20 482e 4e2e 2c20  P., Najm, H.N., 
+0000f5e0: 4768 616e 656d 2c20 522e 472e 2c20 4b6e  Ghanem, R.G., Kn
+0000f5f0: 696f 2c20 4f2e 4d2e 2c20 2832 3030 3429  io, O.M., (2004)
+0000f600: 2e0a 2020 2020 2020 204d 756c 7469 2d72  ..       Multi-r
+0000f610: 6573 6f6c 7574 696f 6e20 616e 616c 7973  esolution analys
+0000f620: 6973 206f 6620 5769 656e 6572 2d74 7970  is of Wiener-typ
+0000f630: 6520 756e 6365 7274 6169 6e74 7920 7072  e uncertainty pr
+0000f640: 6f70 6167 6174 696f 6e20 7363 6865 6d65  opagation scheme
+0000f650: 732e 0a20 2020 2020 2020 4a6f 7572 6e61  s..       Journa
+0000f660: 6c20 6f66 2043 6f6d 7075 7461 7469 6f6e  l of Computation
+0000f670: 616c 2050 6879 7369 6373 2c20 3139 372c  al Physics, 197,
+0000f680: 2035 3032 2d35 3331 2e0a 2020 2020 2222   502-531..    ""
+0000f690: 220a 0a20 2020 2064 6566 205f 5f69 6e69  "..    def __ini
+0000f6a0: 745f 5f28 7365 6c66 2c20 6d61 746c 6162  t__(self, matlab
+0000f6b0: 5f6d 6f64 656c 3d46 616c 7365 293a 0a20  _model=False):. 
+0000f6c0: 2020 2020 2020 2073 7570 6572 2874 7970         super(typ
+0000f6d0: 6528 7365 6c66 292c 2073 656c 6629 2e5f  e(self), self)._
+0000f6e0: 5f69 6e69 745f 5f28 6d61 746c 6162 5f6d  _init__(matlab_m
+0000f6f0: 6f64 656c 3d6d 6174 6c61 625f 6d6f 6465  odel=matlab_mode
+0000f700: 6c29 0a20 2020 2020 2020 2073 656c 662e  l).        self.
+0000f710: 666e 616d 6520 3d20 696e 7370 6563 742e  fname = inspect.
+0000f720: 6765 7466 696c 6528 696e 7370 6563 742e  getfile(inspect.
+0000f730: 6375 7272 656e 7466 7261 6d65 2829 290a  currentframe()).
+0000f740: 0a20 2020 2064 6566 2076 616c 6964 6174  .    def validat
+0000f750: 6528 7365 6c66 293a 0a20 2020 2020 2020  e(self):.       
+0000f760: 2070 6173 730a 0a20 2020 2064 6566 2073   pass..    def s
+0000f770: 696d 756c 6174 6528 7365 6c66 2c20 7072  imulate(self, pr
+0000f780: 6f63 6573 735f 6964 3d4e 6f6e 652c 206d  ocess_id=None, m
+0000f790: 6174 6c61 625f 656e 6769 6e65 3d4e 6f6e  atlab_engine=Non
+0000f7a0: 6529 3a0a 2020 2020 2020 2020 2320 5379  e):.        # Sy
+0000f7b0: 7374 656d 206f 6620 3173 7420 6f72 6465  stem of 1st orde
+0000f7c0: 7220 4445 510a 2020 2020 2020 2020 6465  r DEQ.        de
+0000f7d0: 6620 6465 7128 7268 6f2c 2074 2c20 616c  f deq(rho, t, al
+0000f7e0: 7068 612c 2062 6574 612c 2067 616d 6d61  pha, beta, gamma
+0000f7f0: 293a 0a20 2020 2020 2020 2020 2020 2072  ):.            r
+0000f800: 6574 7572 6e20 616c 7068 6120 2a20 2831  eturn alpha * (1
+0000f810: 2e20 2d20 7268 6f29 202d 2067 616d 6d61  . - rho) - gamma
+0000f820: 202a 2072 686f 202d 2062 6574 6120 2a20   * rho - beta * 
+0000f830: 2872 686f 202d 2031 2920 2a2a 2032 202a  (rho - 1) ** 2 *
+0000f840: 2072 686f 0a0a 2020 2020 2020 2020 2320   rho..        # 
+0000f850: 436f 6e73 7461 6e74 730a 2020 2020 2020  Constants.      
+0000f860: 2020 6761 6d6d 6120 3d20 302e 3031 0a0a    gamma = 0.01..
+0000f870: 2020 2020 2020 2020 2320 5369 6d75 6c61          # Simula
+0000f880: 7469 6f6e 2070 6172 616d 6574 6572 730a  tion parameters.
+0000f890: 2020 2020 2020 2020 6474 203d 2030 2e30          dt = 0.0
+0000f8a0: 310a 2020 2020 2020 2020 745f 656e 6420  1.        t_end 
+0000f8b0: 3d20 312e 0a20 2020 2020 2020 2074 203d  = 1..        t =
+0000f8c0: 206e 702e 6172 616e 6765 2830 2c20 745f   np.arange(0, t_
+0000f8d0: 656e 642c 2064 7429 0a0a 2020 2020 2020  end, dt)..      
+0000f8e0: 2020 2320 536f 6c76 650a 2020 2020 2020    # Solve.      
+0000f8f0: 2020 795f 6f75 7420 3d20 6e70 2e7a 6572    y_out = np.zer
+0000f900: 6f73 2828 6c65 6e28 7365 6c66 2e70 5b22  os((len(self.p["
+0000f910: 7268 6f5f 3022 5d29 2c20 3129 290a 0a20  rho_0"]), 1)).. 
+0000f920: 2020 2020 2020 2066 6f72 2069 2069 6e20         for i in 
+0000f930: 7261 6e67 6528 6c65 6e28 795f 6f75 7429  range(len(y_out)
+0000f940: 293a 0a20 2020 2020 2020 2020 2020 2079  ):.            y
+0000f950: 203d 206f 6465 696e 7428 6465 712c 2073   = odeint(deq, s
+0000f960: 656c 662e 705b 2272 686f 5f30 225d 2e66  elf.p["rho_0"].f
+0000f970: 6c61 7474 656e 2829 5b69 5d2c 2074 2c0a  latten()[i], t,.
+0000f980: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f990: 2020 2020 2020 2061 7267 733d 2873 656c         args=(sel
+0000f9a0: 662e 705b 2261 6c70 6861 225d 2e66 6c61  f.p["alpha"].fla
+0000f9b0: 7474 656e 2829 5b69 5d2c 2073 656c 662e  tten()[i], self.
+0000f9c0: 705b 2262 6574 6122 5d2e 666c 6174 7465  p["beta"].flatte
+0000f9d0: 6e28 295b 695d 2c20 6761 6d6d 612c 2929  n()[i], gamma,))
+0000f9e0: 0a20 2020 2020 2020 2020 2020 2079 5f6f  .            y_o
+0000f9f0: 7574 5b69 2c20 305d 203d 206e 702e 6172  ut[i, 0] = np.ar
+0000fa00: 7261 7928 5b79 5b2d 315d 5d29 0a0a 2020  ray([y[-1]])..  
+0000fa10: 2020 2020 2020 2320 6164 6420 736f 6d65        # add some
+0000fa20: 204e 614e 2076 616c 7565 7320 666f 7220   NaN values for 
+0000fa30: 7465 7374 696e 670a 2020 2020 2020 2020  testing.        
+0000fa40: 6d61 736b 5f6e 616e 203d 2073 656c 662e  mask_nan = self.
+0000fa50: 705b 2262 6574 6122 5d20 3e20 3138 2e35  p["beta"] > 18.5
+0000fa60: 0a0a 2020 2020 2020 2020 795f 6f75 745b  ..        y_out[
+0000fa70: 6d61 736b 5f6e 616e 2c20 305d 203d 206e  mask_nan, 0] = n
+0000fa80: 702e 4e61 4e0a 0a20 2020 2020 2020 2072  p.NaN..        r
+0000fa90: 6574 7572 6e20 795f 6f75 740a 0a0a 636c  eturn y_out...cl
+0000faa0: 6173 7320 4672 616e 6b65 2841 6273 7472  ass Franke(Abstr
+0000fab0: 6163 744d 6f64 656c 293a 0a20 2020 2022  actModel):.    "
+0000fac0: 2222 0a20 2020 2046 7261 6e6b 6520 6675  "".    Franke fu
+0000fad0: 6e63 7469 6f6e 205b 315d 2077 6974 6820  nction [1] with 
+0000fae0: 3220 7061 7261 6d65 7465 7273 2e20 4974  2 parameters. It
+0000faf0: 2069 7320 6f66 7465 6e20 7573 6564 2069   is often used i
+0000fb00: 6e20 7265 6772 6573 7369 6f6e 206f 7220  n regression or 
+0000fb10: 696e 7465 7270 6f6c 6174 696f 6e20 616e  interpolation an
+0000fb20: 616c 7973 6973 2e0a 2020 2020 4974 2069  alysis..    It i
+0000fb30: 7320 6465 6669 6e65 6420 696e 2074 6865  s defined in the
+0000fb40: 2069 6e74 6572 7661 6c20 5b30 2c20 315d   interval [0, 1]
+0000fb50: 2078 205b 302c 2031 5d2e 2048 616d 7074   x [0, 1]. Hampt
+0000fb60: 6f6e 2061 6e64 2044 6f6f 7374 616e 2075  on and Doostan u
+0000fb70: 7365 6420 696e 2074 6865 2066 7261 6d65  sed in the frame
+0000fb80: 776f 726b 206f 6620 4241 5345 2d50 4320  work of BASE-PC 
+0000fb90: 5b32 5d2e 0a0a 2020 2020 2e2e 206d 6174  [2]...    .. mat
+0000fba0: 683a 3a0a 2020 2020 2020 2079 203d 205c  h::.       y = \
+0000fbb0: 5c66 7261 637b 337d 7b34 7d20 5c65 7870  \frac{3}{4} \exp
+0000fbc0: 7b5c 5c6c 6566 7428 2d5c 5c66 7261 637b  {\\left(-\\frac{
+0000fbd0: 2839 2078 5f31 202d 2032 295e 327d 7b34  (9 x_1 - 2)^2}{4
+0000fbe0: 7d20 2d20 5c5c 6672 6163 7b28 3920 785f  } - \\frac{(9 x_
+0000fbf0: 3220 2d20 3229 5e32 7d7b 347d 5c5c 7269  2 - 2)^2}{4}\\ri
+0000fc00: 6768 7429 7d20 2b0a 2020 2020 2020 205c  ght)} +.       \
+0000fc10: 5c66 7261 637b 337d 7b34 7d20 5c65 7870  \frac{3}{4} \exp
+0000fc20: 7b5c 5c6c 6566 7428 2d5c 5c66 7261 637b  {\\left(-\\frac{
+0000fc30: 2839 2078 5f31 202b 2031 295e 327d 7b34  (9 x_1 + 1)^2}{4
+0000fc40: 397d 202d 205c 5c66 7261 637b 2839 2078  9} - \\frac{(9 x
+0000fc50: 5f32 202b 2031 297d 7b31 307d 5c5c 7269  _2 + 1)}{10}\\ri
+0000fc60: 6768 7429 7d20 2b0a 2020 2020 2020 205c  ght)} +.       \
+0000fc70: 5c66 7261 637b 317d 7b32 7d20 5c65 7870  \frac{1}{2} \exp
+0000fc80: 7b5c 5c6c 6566 7428 2d5c 5c66 7261 637b  {\\left(-\\frac{
+0000fc90: 2839 2078 5f31 202d 2037 295e 327d 7b34  (9 x_1 - 7)^2}{4
+0000fca0: 7d20 2d20 5c5c 6672 6163 7b28 3920 785f  } - \\frac{(9 x_
+0000fcb0: 3220 2d20 3329 5e32 7d7b 347d 5c5c 7269  2 - 3)^2}{4}\\ri
+0000fcc0: 6768 7429 7d20 2b0a 2020 2020 2020 205c  ght)} +.       \
+0000fcd0: 5c66 7261 637b 317d 7b35 7d20 5c65 7870  \frac{1}{5} \exp
+0000fce0: 7b5c 5c6c 6566 7428 2d5c 5c66 7261 637b  {\\left(-\\frac{
+0000fcf0: 2839 2078 5f31 202d 2034 295e 327d 7b34  (9 x_1 - 4)^2}{4
+0000fd00: 7d20 2d20 2839 2078 5f32 202d 2037 295e  } - (9 x_2 - 7)^
+0000fd10: 325c 5c72 6967 6874 297d 0a0a 2020 2020  2\\right)}..    
+0000fd20: 5061 7261 6d65 7465 7273 0a20 2020 202d  Parameters.    -
+0000fd30: 2d2d 2d2d 2d2d 2d2d 2d0a 2020 2020 705b  ---------.    p[
+0000fd40: 2278 3122 5d3a 2066 6c6f 6174 206f 7220  "x1"]: float or 
+0000fd50: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
+0000fd60: 205b 6e5f 6772 6964 5d0a 2020 2020 2020   [n_grid].      
+0000fd70: 2020 4669 7273 7420 7061 7261 6d65 7465    First paramete
+0000fd80: 7220 5b30 2c20 315d 0a20 2020 2070 5b22  r [0, 1].    p["
+0000fd90: 7832 225d 3a20 666c 6f61 7420 6f72 206e  x2"]: float or n
+0000fda0: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+0000fdb0: 5b6e 5f67 7269 645d 0a20 2020 2020 2020  [n_grid].       
+0000fdc0: 2053 6563 6f6e 6420 7061 7261 6d65 7465   Second paramete
+0000fdd0: 7220 5b30 2c20 315d 0a0a 2020 2020 5265  r [0, 1]..    Re
+0000fde0: 7475 726e 730a 2020 2020 2d2d 2d2d 2d2d  turns.    ------
+0000fdf0: 2d0a 2020 2020 793a 206e 6461 7272 6179  -.    y: ndarray
+0000fe00: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
+0000fe10: 6420 7820 315d 0a20 2020 2020 2020 204f  d x 1].        O
+0000fe20: 7574 7075 740a 0a20 2020 204e 6f74 6573  utput..    Notes
+0000fe30: 0a20 2020 202d 2d2d 2d2d 0a20 2020 202e  .    -----.    .
+0000fe40: 2e20 706c 6f74 3a3a 0a0a 2020 2020 2020  . plot::..      
+0000fe50: 2069 6d70 6f72 7420 6e75 6d70 7920 6173   import numpy as
+0000fe60: 206e 700a 2020 2020 2020 2066 726f 6d20   np.       from 
+0000fe70: 7079 6770 632e 7465 7374 6675 6e63 7469  pygpc.testfuncti
+0000fe80: 6f6e 7320 696d 706f 7274 2070 6c6f 745f  ons import plot_
+0000fe90: 7465 7374 6675 6e63 7469 6f6e 2061 7320  testfunction as 
+0000fea0: 706c 6f74 0a20 2020 2020 2020 6672 6f6d  plot.       from
+0000feb0: 2063 6f6c 6c65 6374 696f 6e73 2069 6d70   collections imp
+0000fec0: 6f72 7420 4f72 6465 7265 6444 6963 740a  ort OrderedDict.
+0000fed0: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
+0000fee0: 7273 203d 204f 7264 6572 6564 4469 6374  rs = OrderedDict
+0000fef0: 2829 0a20 2020 2020 2020 7061 7261 6d65  ().       parame
+0000ff00: 7465 7273 5b22 7831 225d 203d 206e 702e  ters["x1"] = np.
+0000ff10: 6c69 6e73 7061 6365 2830 2c20 312c 2031  linspace(0, 1, 1
+0000ff20: 3030 290a 2020 2020 2020 2070 6172 616d  00).       param
+0000ff30: 6574 6572 735b 2278 3222 5d20 3d20 6e70  eters["x2"] = np
+0000ff40: 2e6c 696e 7370 6163 6528 302c 2031 2c20  .linspace(0, 1, 
+0000ff50: 3130 3029 0a0a 2020 2020 2020 2070 6c6f  100)..       plo
+0000ff60: 7428 2246 7261 6e6b 6522 2c20 7061 7261  t("Franke", para
+0000ff70: 6d65 7465 7273 290a 0a20 2020 202e 2e20  meters)..    .. 
+0000ff80: 5b31 5d20 4672 616e 6b65 2c20 522e 2c20  [1] Franke, R., 
+0000ff90: 2831 3937 3929 2041 2043 7269 7469 6361  (1979) A Critica
+0000ffa0: 6c20 436f 6d70 6172 6973 6f6e 206f 6620  l Comparison of 
+0000ffb0: 736f 6d65 204d 6574 686f 6473 2066 6f72  some Methods for
+0000ffc0: 2049 6e74 6572 706f 6c61 7469 6f6e 206f   Interpolation o
+0000ffd0: 6620 5363 6174 7465 7265 6420 4461 7461  f Scattered Data
+0000ffe0: 2c0a 2020 2020 2020 2054 6563 682e 2072  ,.       Tech. r
+0000fff0: 6570 2e2c 2044 5449 4320 446f 6375 6d65  ep., DTIC Docume
+00010000: 6e74 0a0a 2020 2020 2e2e 205b 325d 2048  nt..    .. [2] H
+00010010: 616d 7074 6f6e 2c20 4a2e 2c20 446f 6f73  ampton, J., Doos
+00010020: 7461 6e2c 2041 2e2c 2028 3230 3138 292c  tan, A., (2018),
+00010030: 2042 6173 6973 2061 6461 7074 6976 6520   Basis adaptive 
+00010040: 7361 6d70 6c65 2065 6666 6963 6965 6e74  sample efficient
+00010050: 2070 6f6c 796e 6f6d 6961 6c20 6368 616f   polynomial chao
+00010060: 7320 2842 4153 452d 5043 292c 0a20 2020  s (BASE-PC),.   
+00010070: 2020 2020 4a6f 7572 6e61 6c20 6f66 2043      Journal of C
+00010080: 6f6d 7075 7461 7469 6f6e 616c 2050 6879  omputational Phy
+00010090: 7369 6373 2c20 3337 312c 2032 302d 3439  sics, 371, 20-49
+000100a0: 2e0a 2020 2020 2222 220a 0a20 2020 2064  ..    """..    d
+000100b0: 6566 205f 5f69 6e69 745f 5f28 7365 6c66  ef __init__(self
+000100c0: 2c20 6d61 746c 6162 5f6d 6f64 656c 3d46  , matlab_model=F
+000100d0: 616c 7365 293a 0a20 2020 2020 2020 2073  alse):.        s
+000100e0: 7570 6572 2874 7970 6528 7365 6c66 292c  uper(type(self),
+000100f0: 2073 656c 6629 2e5f 5f69 6e69 745f 5f28   self).__init__(
+00010100: 6d61 746c 6162 5f6d 6f64 656c 3d6d 6174  matlab_model=mat
+00010110: 6c61 625f 6d6f 6465 6c29 0a20 2020 2020  lab_model).     
+00010120: 2020 2073 656c 662e 666e 616d 6520 3d20     self.fname = 
+00010130: 696e 7370 6563 742e 6765 7466 696c 6528  inspect.getfile(
+00010140: 696e 7370 6563 742e 6375 7272 656e 7466  inspect.currentf
+00010150: 7261 6d65 2829 290a 0a20 2020 2064 6566  rame())..    def
+00010160: 2076 616c 6964 6174 6528 7365 6c66 293a   validate(self):
+00010170: 0a20 2020 2020 2020 2070 6173 730a 0a20  .        pass.. 
+00010180: 2020 2064 6566 2073 696d 756c 6174 6528     def simulate(
+00010190: 7365 6c66 2c20 7072 6f63 6573 735f 6964  self, process_id
+000101a0: 3d4e 6f6e 652c 206d 6174 6c61 625f 656e  =None, matlab_en
+000101b0: 6769 6e65 3d4e 6f6e 6529 3a0a 2020 2020  gine=None):.    
+000101c0: 2020 2020 7920 3d20 332e 202f 2034 2e20      y = 3. / 4. 
+000101d0: 2a20 6e70 2e65 7870 282d 2828 3920 2a20  * np.exp(-((9 * 
+000101e0: 7365 6c66 2e70 5b22 7831 225d 202d 2032  self.p["x1"] - 2
+000101f0: 2920 2a2a 2032 2920 2f20 342e 202d 2028  ) ** 2) / 4. - (
+00010200: 2839 202a 2073 656c 662e 705b 2278 3222  (9 * self.p["x2"
+00010210: 5d20 2d20 3229 202a 2a20 3229 202f 2034  ] - 2) ** 2) / 4
+00010220: 2e29 202b 205c 0a20 2020 2020 2020 2020  .) + \.         
+00010230: 2020 2033 2e20 2f20 342e 202a 206e 702e     3. / 4. * np.
+00010240: 6578 7028 2d28 2839 202a 2073 656c 662e  exp(-((9 * self.
+00010250: 705b 2278 3122 5d20 2b20 3129 202a 2a20  p["x1"] + 1) ** 
+00010260: 3229 202f 2034 392e 202d 2028 3920 2a20  2) / 49. - (9 * 
+00010270: 7365 6c66 2e70 5b22 7832 225d 202b 2031  self.p["x2"] + 1
+00010280: 2920 2f20 3130 2e29 202b 205c 0a20 2020  ) / 10.) + \.   
+00010290: 2020 2020 2020 2020 2031 2e20 2f20 322e           1. / 2.
+000102a0: 202a 206e 702e 6578 7028 2d28 2839 202a   * np.exp(-((9 *
+000102b0: 2073 656c 662e 705b 2278 3122 5d20 2d20   self.p["x1"] - 
+000102c0: 3729 202a 2a20 3229 202f 2034 2e20 2d20  7) ** 2) / 4. - 
+000102d0: 2828 3920 2a20 7365 6c66 2e70 5b22 7832  ((9 * self.p["x2
+000102e0: 225d 202d 2033 2920 2a2a 2032 2920 2f20  "] - 3) ** 2) / 
+000102f0: 342e 2920 2d20 5c0a 2020 2020 2020 2020  4.) - \.        
+00010300: 2020 2020 312e 202f 2035 2e20 2a20 6e70      1. / 5. * np
+00010310: 2e65 7870 282d 2839 202a 2073 656c 662e  .exp(-(9 * self.
+00010320: 705b 2278 3122 5d20 2d20 3429 202a 2a20  p["x1"] - 4) ** 
+00010330: 3220 2d20 2839 202a 2073 656c 662e 705b  2 - (9 * self.p[
+00010340: 2278 3222 5d20 2d20 3729 202a 2a20 3229  "x2"] - 7) ** 2)
+00010350: 0a0a 2020 2020 2020 2020 6966 2074 7970  ..        if typ
+00010360: 6528 7929 2069 7320 6e6f 7420 6e70 2e6e  e(y) is not np.n
+00010370: 6461 7272 6179 3a0a 2020 2020 2020 2020  darray:.        
+00010380: 2020 2020 7920 3d20 6e70 2e61 7272 6179      y = np.array
+00010390: 285b 795d 290a 0a20 2020 2020 2020 2079  ([y])..        y
+000103a0: 5f6f 7574 203d 2079 5b3a 2c20 6e70 2e6e  _out = y[:, np.n
+000103b0: 6577 6178 6973 5d0a 0a20 2020 2020 2020  ewaxis]..       
+000103c0: 2072 6574 7572 6e20 795f 6f75 740a 0a0a   return y_out...
+000103d0: 636c 6173 7320 4d61 6e75 6661 6374 7572  class Manufactur
+000103e0: 6544 6563 6179 2841 6273 7472 6163 744d  eDecay(AbstractM
+000103f0: 6f64 656c 293a 0a20 2020 2022 2222 0a20  odel):.    """. 
+00010400: 2020 204e 2d64 696d 656e 7369 6f6e 616c     N-dimensional
+00010410: 206d 616e 7566 6163 7475 7265 2064 6563   manufacture dec
+00010420: 6179 2066 756e 6374 696f 6e20 5b31 5d2e  ay function [1].
+00010430: 2049 7420 6973 2064 6566 696e 6564 2069   It is defined i
+00010440: 6e20 7468 6520 696e 7465 7276 616c 205b  n the interval [
+00010450: 302c 2031 5d20 7820 2e2e 2e20 7820 5b30  0, 1] x ... x [0
+00010460: 2c20 315d 2e0a 2020 2020 4861 6d70 746f  , 1]..    Hampto
+00010470: 6e20 616e 6420 446f 6f73 7461 6e20 7573  n and Doostan us
+00010480: 6564 2069 6e20 7468 6520 6672 616d 6577  ed in the framew
+00010490: 6f72 6b20 6f66 2042 4153 452d 5043 205b  ork of BASE-PC [
+000104a0: 315d 2e0a 0a20 2020 202e 2e20 6d61 7468  1]...    .. math
+000104b0: 3a3a 2079 203d 205c 5c65 7870 7b5c 5c6c  :: y = \\exp{\\l
+000104c0: 6566 7428 3220 2d20 5c73 756d 5f7b 693d  eft(2 - \sum_{i=
+000104d0: 317d 5e7b 4e7d 2078 5f69 205c 5c66 7261  1}^{N} x_i \\fra
+000104e0: 637b 5c73 696e 2869 2b31 297d 7b69 202b  c{\sin(i+1)}{i +
+000104f0: 2031 7d5c 5c72 6967 6874 297d 0a0a 2020   1}\\right)}..  
+00010500: 2020 5061 7261 6d65 7465 7273 0a20 2020    Parameters.   
+00010510: 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020 2020   ----------.    
+00010520: 705b 2278 3122 5d3a 2066 6c6f 6174 206f  p["x1"]: float o
+00010530: 7220 6e64 6172 7261 7920 6f66 2066 6c6f  r ndarray of flo
+00010540: 6174 205b 6e5f 6772 6964 5d0a 2020 2020  at [n_grid].    
+00010550: 2020 2020 4669 7273 7420 7061 7261 6d65      First parame
+00010560: 7465 7220 6465 6669 6e65 6420 696e 205b  ter defined in [
+00010570: 302c 2031 5d0a 2020 2020 705b 2278 6922  0, 1].    p["xi"
+00010580: 5d3a 2066 6c6f 6174 206f 7220 6e64 6172  ]: float or ndar
+00010590: 7261 7920 6f66 2066 6c6f 6174 205b 6e5f  ray of float [n_
+000105a0: 6772 6964 5d0a 2020 2020 2020 2020 692d  grid].        i-
+000105b0: 7468 2070 6172 616d 6574 6572 2064 6566  th parameter def
+000105c0: 696e 6564 2069 6e20 5b30 2c20 315d 0a20  ined in [0, 1]. 
+000105d0: 2020 2070 5b22 784e 225d 3a20 666c 6f61     p["xN"]: floa
+000105e0: 7420 6f72 206e 6461 7272 6179 206f 6620  t or ndarray of 
+000105f0: 666c 6f61 7420 5b6e 5f67 7269 645d 0a20  float [n_grid]. 
+00010600: 2020 2020 2020 204e 7468 2070 6172 616d         Nth param
+00010610: 6574 6572 2064 6566 696e 6564 2069 6e20  eter defined in 
+00010620: 5b30 2c20 315d 0a0a 2020 2020 5265 7475  [0, 1]..    Retu
+00010630: 726e 730a 2020 2020 2d2d 2d2d 2d2d 2d0a  rns.    -------.
+00010640: 2020 2020 793a 206e 6461 7272 6179 206f      y: ndarray o
+00010650: 6620 666c 6f61 7420 5b6e 5f67 7269 6420  f float [n_grid 
+00010660: 7820 315d 0a20 2020 2020 2020 204f 7574  x 1].        Out
+00010670: 7075 740a 0a20 2020 204e 6f74 6573 0a20  put..    Notes. 
+00010680: 2020 202d 2d2d 2d2d 0a20 2020 202e 2e20     -----.    .. 
+00010690: 706c 6f74 3a3a 0a0a 2020 2020 2020 2069  plot::..       i
 000106a0: 6d70 6f72 7420 6e75 6d70 7920 6173 206e  mport numpy as n
-000106b0: 700d 0a20 2020 2020 2020 6672 6f6d 2070  p..       from p
-000106c0: 7967 7063 2e74 6573 7466 756e 6374 696f  ygpc.testfunctio
-000106d0: 6e73 2069 6d70 6f72 7420 706c 6f74 5f74  ns import plot_t
-000106e0: 6573 7466 756e 6374 696f 6e20 6173 2070  estfunction as p
-000106f0: 6c6f 740d 0a20 2020 2020 2020 6672 6f6d  lot..       from
-00010700: 2063 6f6c 6c65 6374 696f 6e73 2069 6d70   collections imp
-00010710: 6f72 7420 4f72 6465 7265 6444 6963 740d  ort OrderedDict.
-00010720: 0a0d 0a20 2020 2020 2020 7061 7261 6d65  ...       parame
-00010730: 7465 7273 203d 204f 7264 6572 6564 4469  ters = OrderedDi
-00010740: 6374 2829 0d0a 2020 2020 2020 2070 6172  ct()..       par
-00010750: 616d 6574 6572 735b 2278 3122 5d20 3d20  ameters["x1"] = 
-00010760: 6e70 2e6c 696e 7370 6163 6528 302c 2031  np.linspace(0, 1
-00010770: 2c20 3130 3029 0d0a 2020 2020 2020 2070  , 100)..       p
-00010780: 6172 616d 6574 6572 735b 2278 3222 5d20  arameters["x2"] 
-00010790: 3d20 6e70 2e6c 696e 7370 6163 6528 302c  = np.linspace(0,
-000107a0: 2031 2c20 3130 3029 0d0a 0d0a 2020 2020   1, 100)....    
-000107b0: 2020 2070 6c6f 7428 2246 7261 6e6b 6522     plot("Franke"
-000107c0: 2c20 7061 7261 6d65 7465 7273 290d 0a0d  , parameters)...
-000107d0: 0a20 2020 202e 2e20 5b31 5d20 4672 616e  .    .. [1] Fran
-000107e0: 6b65 2c20 522e 2c20 2831 3937 3929 2041  ke, R., (1979) A
-000107f0: 2043 7269 7469 6361 6c20 436f 6d70 6172   Critical Compar
-00010800: 6973 6f6e 206f 6620 736f 6d65 204d 6574  ison of some Met
-00010810: 686f 6473 2066 6f72 2049 6e74 6572 706f  hods for Interpo
-00010820: 6c61 7469 6f6e 206f 6620 5363 6174 7465  lation of Scatte
-00010830: 7265 6420 4461 7461 2c0d 0a20 2020 2020  red Data,..     
-00010840: 2020 5465 6368 2e20 7265 702e 2c20 4454    Tech. rep., DT
-00010850: 4943 2044 6f63 756d 656e 740d 0a0d 0a20  IC Document.... 
-00010860: 2020 202e 2e20 5b32 5d20 4861 6d70 746f     .. [2] Hampto
-00010870: 6e2c 204a 2e2c 2044 6f6f 7374 616e 2c20  n, J., Doostan, 
-00010880: 412e 2c20 2832 3031 3829 2c20 4261 7369  A., (2018), Basi
-00010890: 7320 6164 6170 7469 7665 2073 616d 706c  s adaptive sampl
-000108a0: 6520 6566 6669 6369 656e 7420 706f 6c79  e efficient poly
-000108b0: 6e6f 6d69 616c 2063 6861 6f73 2028 4241  nomial chaos (BA
-000108c0: 5345 2d50 4329 2c0d 0a20 2020 2020 2020  SE-PC),..       
-000108d0: 4a6f 7572 6e61 6c20 6f66 2043 6f6d 7075  Journal of Compu
-000108e0: 7461 7469 6f6e 616c 2050 6879 7369 6373  tational Physics
-000108f0: 2c20 3337 312c 2032 302d 3439 2e0d 0a20  , 371, 20-49... 
-00010900: 2020 2022 2222 0d0a 0d0a 2020 2020 6465     """....    de
-00010910: 6620 5f5f 696e 6974 5f5f 2873 656c 662c  f __init__(self,
-00010920: 206d 6174 6c61 625f 6d6f 6465 6c3d 4661   matlab_model=Fa
-00010930: 6c73 6529 3a0d 0a20 2020 2020 2020 2073  lse):..        s
-00010940: 7570 6572 2874 7970 6528 7365 6c66 292c  uper(type(self),
-00010950: 2073 656c 6629 2e5f 5f69 6e69 745f 5f28   self).__init__(
-00010960: 6d61 746c 6162 5f6d 6f64 656c 3d6d 6174  matlab_model=mat
-00010970: 6c61 625f 6d6f 6465 6c29 0d0a 2020 2020  lab_model)..    
-00010980: 2020 2020 7365 6c66 2e66 6e61 6d65 203d      self.fname =
-00010990: 2069 6e73 7065 6374 2e67 6574 6669 6c65   inspect.getfile
-000109a0: 2869 6e73 7065 6374 2e63 7572 7265 6e74  (inspect.current
-000109b0: 6672 616d 6528 2929 0d0a 0d0a 2020 2020  frame())....    
-000109c0: 6465 6620 7661 6c69 6461 7465 2873 656c  def validate(sel
-000109d0: 6629 3a0d 0a20 2020 2020 2020 2070 6173  f):..        pas
-000109e0: 730d 0a0d 0a20 2020 2064 6566 2073 696d  s....    def sim
-000109f0: 756c 6174 6528 7365 6c66 2c20 7072 6f63  ulate(self, proc
-00010a00: 6573 735f 6964 3d4e 6f6e 652c 206d 6174  ess_id=None, mat
-00010a10: 6c61 625f 656e 6769 6e65 3d4e 6f6e 6529  lab_engine=None)
-00010a20: 3a0d 0a20 2020 2020 2020 2079 203d 2033  :..        y = 3
-00010a30: 2e20 2f20 342e 202a 206e 702e 6578 7028  . / 4. * np.exp(
-00010a40: 2d28 2839 202a 2073 656c 662e 705b 2278  -((9 * self.p["x
-00010a50: 3122 5d20 2d20 3229 202a 2a20 3229 202f  1"] - 2) ** 2) /
-00010a60: 2034 2e20 2d20 2828 3920 2a20 7365 6c66   4. - ((9 * self
-00010a70: 2e70 5b22 7832 225d 202d 2032 2920 2a2a  .p["x2"] - 2) **
-00010a80: 2032 2920 2f20 342e 2920 2b20 5c0d 0a20   2) / 4.) + \.. 
-00010a90: 2020 2020 2020 2020 2020 2033 2e20 2f20             3. / 
-00010aa0: 342e 202a 206e 702e 6578 7028 2d28 2839  4. * np.exp(-((9
-00010ab0: 202a 2073 656c 662e 705b 2278 3122 5d20   * self.p["x1"] 
-00010ac0: 2b20 3129 202a 2a20 3229 202f 2034 392e  + 1) ** 2) / 49.
-00010ad0: 202d 2028 3920 2a20 7365 6c66 2e70 5b22   - (9 * self.p["
-00010ae0: 7832 225d 202b 2031 2920 2f20 3130 2e29  x2"] + 1) / 10.)
-00010af0: 202b 205c 0d0a 2020 2020 2020 2020 2020   + \..          
-00010b00: 2020 312e 202f 2032 2e20 2a20 6e70 2e65    1. / 2. * np.e
-00010b10: 7870 282d 2828 3920 2a20 7365 6c66 2e70  xp(-((9 * self.p
-00010b20: 5b22 7831 225d 202d 2037 2920 2a2a 2032  ["x1"] - 7) ** 2
-00010b30: 2920 2f20 342e 202d 2028 2839 202a 2073  ) / 4. - ((9 * s
-00010b40: 656c 662e 705b 2278 3222 5d20 2d20 3329  elf.p["x2"] - 3)
-00010b50: 202a 2a20 3229 202f 2034 2e29 202d 205c   ** 2) / 4.) - \
-00010b60: 0d0a 2020 2020 2020 2020 2020 2020 312e  ..            1.
-00010b70: 202f 2035 2e20 2a20 6e70 2e65 7870 282d   / 5. * np.exp(-
-00010b80: 2839 202a 2073 656c 662e 705b 2278 3122  (9 * self.p["x1"
-00010b90: 5d20 2d20 3429 202a 2a20 3220 2d20 2839  ] - 4) ** 2 - (9
-00010ba0: 202a 2073 656c 662e 705b 2278 3222 5d20   * self.p["x2"] 
-00010bb0: 2d20 3729 202a 2a20 3229 0d0a 0d0a 2020  - 7) ** 2)....  
-00010bc0: 2020 2020 2020 6966 2074 7970 6528 7929        if type(y)
-00010bd0: 2069 7320 6e6f 7420 6e70 2e6e 6461 7272   is not np.ndarr
-00010be0: 6179 3a0d 0a20 2020 2020 2020 2020 2020  ay:..           
-00010bf0: 2079 203d 206e 702e 6172 7261 7928 5b79   y = np.array([y
-00010c00: 5d29 0d0a 0d0a 2020 2020 2020 2020 795f  ])....        y_
-00010c10: 6f75 7420 3d20 795b 3a2c 206e 702e 6e65  out = y[:, np.ne
-00010c20: 7761 7869 735d 0d0a 0d0a 2020 2020 2020  waxis]....      
-00010c30: 2020 7265 7475 726e 2079 5f6f 7574 0d0a    return y_out..
-00010c40: 0d0a 0d0a 636c 6173 7320 4d61 6e75 6661  ....class Manufa
-00010c50: 6374 7572 6544 6563 6179 2841 6273 7472  ctureDecay(Abstr
-00010c60: 6163 744d 6f64 656c 293a 0d0a 2020 2020  actModel):..    
-00010c70: 2222 220d 0a20 2020 204e 2d64 696d 656e  """..    N-dimen
-00010c80: 7369 6f6e 616c 206d 616e 7566 6163 7475  sional manufactu
-00010c90: 7265 2064 6563 6179 2066 756e 6374 696f  re decay functio
-00010ca0: 6e20 5b31 5d2e 2049 7420 6973 2064 6566  n [1]. It is def
-00010cb0: 696e 6564 2069 6e20 7468 6520 696e 7465  ined in the inte
-00010cc0: 7276 616c 205b 302c 2031 5d20 7820 2e2e  rval [0, 1] x ..
-00010cd0: 2e20 7820 5b30 2c20 315d 2e0d 0a20 2020  . x [0, 1]...   
-00010ce0: 2048 616d 7074 6f6e 2061 6e64 2044 6f6f   Hampton and Doo
-00010cf0: 7374 616e 2075 7365 6420 696e 2074 6865  stan used in the
-00010d00: 2066 7261 6d65 776f 726b 206f 6620 4241   framework of BA
-00010d10: 5345 2d50 4320 5b31 5d2e 0d0a 0d0a 2020  SE-PC [1].....  
-00010d20: 2020 2e2e 206d 6174 683a 3a20 7920 3d20    .. math:: y = 
-00010d30: 5c5c 6578 707b 5c5c 6c65 6674 2832 202d  \\exp{\\left(2 -
-00010d40: 205c 7375 6d5f 7b69 3d31 7d5e 7b4e 7d20   \sum_{i=1}^{N} 
-00010d50: 785f 6920 5c5c 6672 6163 7b5c 7369 6e28  x_i \\frac{\sin(
-00010d60: 692b 3129 7d7b 6920 2b20 317d 5c5c 7269  i+1)}{i + 1}\\ri
-00010d70: 6768 7429 7d0d 0a0d 0a20 2020 2050 6172  ght)}....    Par
-00010d80: 616d 6574 6572 730d 0a20 2020 202d 2d2d  ameters..    ---
-00010d90: 2d2d 2d2d 2d2d 2d0d 0a20 2020 2070 5b22  -------..    p["
-00010da0: 7831 225d 3a20 666c 6f61 7420 6f72 206e  x1"]: float or n
-00010db0: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-00010dc0: 5b6e 5f67 7269 645d 0d0a 2020 2020 2020  [n_grid]..      
-00010dd0: 2020 4669 7273 7420 7061 7261 6d65 7465    First paramete
-00010de0: 7220 6465 6669 6e65 6420 696e 205b 302c  r defined in [0,
-00010df0: 2031 5d0d 0a20 2020 2070 5b22 7869 225d   1]..    p["xi"]
-00010e00: 3a20 666c 6f61 7420 6f72 206e 6461 7272  : float or ndarr
-00010e10: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
-00010e20: 7269 645d 0d0a 2020 2020 2020 2020 692d  rid]..        i-
-00010e30: 7468 2070 6172 616d 6574 6572 2064 6566  th parameter def
-00010e40: 696e 6564 2069 6e20 5b30 2c20 315d 0d0a  ined in [0, 1]..
-00010e50: 2020 2020 705b 2278 4e22 5d3a 2066 6c6f      p["xN"]: flo
-00010e60: 6174 206f 7220 6e64 6172 7261 7920 6f66  at or ndarray of
-00010e70: 2066 6c6f 6174 205b 6e5f 6772 6964 5d0d   float [n_grid].
-00010e80: 0a20 2020 2020 2020 204e 7468 2070 6172  .        Nth par
-00010e90: 616d 6574 6572 2064 6566 696e 6564 2069  ameter defined i
-00010ea0: 6e20 5b30 2c20 315d 0d0a 0d0a 2020 2020  n [0, 1]....    
-00010eb0: 5265 7475 726e 730d 0a20 2020 202d 2d2d  Returns..    ---
-00010ec0: 2d2d 2d2d 0d0a 2020 2020 793a 206e 6461  ----..    y: nda
-00010ed0: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
-00010ee0: 5f67 7269 6420 7820 315d 0d0a 2020 2020  _grid x 1]..    
-00010ef0: 2020 2020 4f75 7470 7574 0d0a 0d0a 2020      Output....  
-00010f00: 2020 4e6f 7465 730d 0a20 2020 202d 2d2d    Notes..    ---
-00010f10: 2d2d 0d0a 2020 2020 2e2e 2070 6c6f 743a  --..    .. plot:
-00010f20: 3a0d 0a0d 0a20 2020 2020 2020 696d 706f  :....       impo
-00010f30: 7274 206e 756d 7079 2061 7320 6e70 0d0a  rt numpy as np..
-00010f40: 2020 2020 2020 2066 726f 6d20 7079 6770         from pygp
-00010f50: 632e 7465 7374 6675 6e63 7469 6f6e 7320  c.testfunctions 
-00010f60: 696d 706f 7274 2070 6c6f 745f 7465 7374  import plot_test
-00010f70: 6675 6e63 7469 6f6e 2061 7320 706c 6f74  function as plot
-00010f80: 0d0a 2020 2020 2020 2066 726f 6d20 636f  ..       from co
-00010f90: 6c6c 6563 7469 6f6e 7320 696d 706f 7274  llections import
-00010fa0: 204f 7264 6572 6564 4469 6374 0d0a 0d0a   OrderedDict....
-00010fb0: 2020 2020 2020 2070 6172 616d 6574 6572         parameter
-00010fc0: 7320 3d20 4f72 6465 7265 6444 6963 7428  s = OrderedDict(
-00010fd0: 290d 0a20 2020 2020 2020 7061 7261 6d65  )..       parame
-00010fe0: 7465 7273 5b22 7831 225d 203d 206e 702e  ters["x1"] = np.
-00010ff0: 6c69 6e73 7061 6365 2830 2c20 312c 2031  linspace(0, 1, 1
-00011000: 3030 290d 0a20 2020 2020 2020 7061 7261  00)..       para
-00011010: 6d65 7465 7273 5b22 7832 225d 203d 206e  meters["x2"] = n
-00011020: 702e 6c69 6e73 7061 6365 2830 2c20 312c  p.linspace(0, 1,
-00011030: 2031 3030 290d 0a0d 0a20 2020 2020 2020   100)....       
-00011040: 706c 6f74 2822 4d61 6e75 6661 6374 7572  plot("Manufactur
-00011050: 6544 6563 6179 222c 2070 6172 616d 6574  eDecay", paramet
-00011060: 6572 7329 0d0a 0d0a 2020 2020 2e2e 205b  ers)....    .. [
-00011070: 315d 2048 616d 7074 6f6e 2c20 4a2e 2c20  1] Hampton, J., 
-00011080: 446f 6f73 7461 6e2c 2041 2e2c 2028 3230  Doostan, A., (20
-00011090: 3138 292c 2042 6173 6973 2061 6461 7074  18), Basis adapt
-000110a0: 6976 6520 7361 6d70 6c65 2065 6666 6963  ive sample effic
-000110b0: 6965 6e74 2070 6f6c 796e 6f6d 6961 6c20  ient polynomial 
-000110c0: 6368 616f 7320 2842 4153 452d 5043 292c  chaos (BASE-PC),
-000110d0: 0d0a 2020 2020 2020 204a 6f75 726e 616c  ..       Journal
-000110e0: 206f 6620 436f 6d70 7574 6174 696f 6e61   of Computationa
-000110f0: 6c20 5068 7973 6963 732c 2033 3731 2c20  l Physics, 371, 
-00011100: 3230 2d34 392e 0d0a 2020 2020 2222 220d  20-49...    """.
-00011110: 0a0d 0a20 2020 2064 6566 205f 5f69 6e69  ...    def __ini
-00011120: 745f 5f28 7365 6c66 2c20 6d61 746c 6162  t__(self, matlab
-00011130: 5f6d 6f64 656c 3d46 616c 7365 293a 0d0a  _model=False):..
-00011140: 2020 2020 2020 2020 7375 7065 7228 7479          super(ty
-00011150: 7065 2873 656c 6629 2c20 7365 6c66 292e  pe(self), self).
-00011160: 5f5f 696e 6974 5f5f 286d 6174 6c61 625f  __init__(matlab_
-00011170: 6d6f 6465 6c3d 6d61 746c 6162 5f6d 6f64  model=matlab_mod
-00011180: 656c 290d 0a20 2020 2020 2020 2073 656c  el)..        sel
-00011190: 662e 666e 616d 6520 3d20 696e 7370 6563  f.fname = inspec
-000111a0: 742e 6765 7466 696c 6528 696e 7370 6563  t.getfile(inspec
-000111b0: 742e 6375 7272 656e 7466 7261 6d65 2829  t.currentframe()
-000111c0: 290d 0a0d 0a20 2020 2064 6566 2076 616c  )....    def val
-000111d0: 6964 6174 6528 7365 6c66 293a 0d0a 2020  idate(self):..  
-000111e0: 2020 2020 2020 7061 7373 0d0a 0d0a 2020        pass....  
-000111f0: 2020 6465 6620 7369 6d75 6c61 7465 2873    def simulate(s
-00011200: 656c 662c 2070 726f 6365 7373 5f69 643d  elf, process_id=
-00011210: 4e6f 6e65 2c20 6d61 746c 6162 5f65 6e67  None, matlab_eng
-00011220: 696e 653d 4e6f 6e65 293a 0d0a 2020 2020  ine=None):..    
-00011230: 2020 2020 2320 6465 7465 726d 696e 6520      # determine 
-00011240: 7375 6d20 696e 2065 7870 6f6e 656e 740d  sum in exponent.
-00011250: 0a20 2020 2020 2020 2073 203d 206e 702e  .        s = np.
-00011260: 7a65 726f 7328 6e70 2e61 7272 6179 2873  zeros(np.array(s
-00011270: 656c 662e 705b 6c69 7374 2873 656c 662e  elf.p[list(self.
-00011280: 702e 6b65 7973 2829 295b 305d 5d29 2e73  p.keys())[0]]).s
-00011290: 697a 6529 0d0a 0d0a 2020 2020 2020 2020  ize)....        
-000112a0: 666f 7220 692c 206b 6579 2069 6e20 656e  for i, key in en
-000112b0: 756d 6572 6174 6528 7365 6c66 2e70 2e6b  umerate(self.p.k
-000112c0: 6579 7328 2929 3a0d 0a20 2020 2020 2020  eys()):..       
-000112d0: 2020 2020 2073 202b 3d20 6e70 2e73 696e       s += np.sin
-000112e0: 2869 202b 2031 2920 2a20 7365 6c66 2e70  (i + 1) * self.p
-000112f0: 5b6b 6579 5d20 2f20 2869 202b 2031 2e29  [key] / (i + 1.)
-00011300: 0d0a 0d0a 2020 2020 2020 2020 2320 6465  ....        # de
-00011310: 7465 726d 696e 6520 6f75 7470 7574 0d0a  termine output..
-00011320: 2020 2020 2020 2020 7920 3d20 6e70 2e65          y = np.e
-00011330: 7870 2832 202d 2073 290d 0a0d 0a20 2020  xp(2 - s)....   
-00011340: 2020 2020 2079 5f6f 7574 203d 2079 5b3a       y_out = y[:
-00011350: 2c20 6e70 2e6e 6577 6178 6973 5d0d 0a0d  , np.newaxis]...
-00011360: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00011370: 795f 6f75 740d 0a0d 0a0d 0a63 6c61 7373  y_out......class
-00011380: 2047 656e 7a43 6f6e 7469 6e75 6f75 7328   GenzContinuous(
-00011390: 4162 7374 7261 6374 4d6f 6465 6c29 3a0d  AbstractModel):.
-000113a0: 0a20 2020 2022 2222 0d0a 2020 2020 4e2d  .    """..    N-
-000113b0: 6469 6d65 6e73 696f 6e61 6c20 2263 6f6e  dimensional "con
-000113c0: 7469 6e75 6f75 7322 2047 656e 7a20 6675  tinuous" Genz fu
-000113d0: 6e63 7469 6f6e 205b 315d 2e20 4974 2069  nction [1]. It i
-000113e0: 7320 6465 6669 6e65 6420 696e 2074 6865  s defined in the
-000113f0: 2069 6e74 6572 7661 6c20 5b30 2c20 315d   interval [0, 1]
-00011400: 2078 202e 2e2e 2078 205b 302c 2031 5d2e   x ... x [0, 1].
-00011410: 0d0a 0d0a 2020 2020 2e2e 206d 6174 683a  ....    .. math:
-00011420: 3a20 2079 203d 205c 5c65 7870 7b5c 5c6c  :  y = \\exp{\\l
-00011430: 6566 7428 2d20 5c73 756d 5f7b 693d 317d  eft(- \sum_{i=1}
-00011440: 5e7b 4e7d 2061 5f69 207c 2078 5f69 202d  ^{N} a_i | x_i -
-00011450: 2075 5f69 207c 205c 5c72 6967 6874 297d   u_i | \\right)}
-00011460: 0d0a 0d0a 2020 2020 5061 7261 6d65 7465  ....    Paramete
-00011470: 7273 0d0a 2020 2020 2d2d 2d2d 2d2d 2d2d  rs..    --------
-00011480: 2d2d 0d0a 2020 2020 705b 2278 3122 5d3a  --..    p["x1"]:
-00011490: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
-000114a0: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
-000114b0: 6964 5d0d 0a20 2020 2020 2020 2046 6972  id]..        Fir
-000114c0: 7374 2070 6172 616d 6574 6572 2064 6566  st parameter def
-000114d0: 696e 6564 2069 6e20 5b30 2c20 315d 0d0a  ined in [0, 1]..
-000114e0: 2020 2020 705b 2278 6922 5d3a 2066 6c6f      p["xi"]: flo
-000114f0: 6174 206f 7220 6e64 6172 7261 7920 6f66  at or ndarray of
-00011500: 2066 6c6f 6174 205b 6e5f 6772 6964 5d0d   float [n_grid].
-00011510: 0a20 2020 2020 2020 2069 2d74 6820 7061  .        i-th pa
-00011520: 7261 6d65 7465 7220 6465 6669 6e65 6420  rameter defined 
-00011530: 696e 205b 302c 2031 5d0d 0a20 2020 2070  in [0, 1]..    p
-00011540: 5b22 784e 225d 3a20 666c 6f61 7420 6f72  ["xN"]: float or
-00011550: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-00011560: 7420 5b6e 5f67 7269 645d 0d0a 2020 2020  t [n_grid]..    
-00011570: 2020 2020 4e74 6820 7061 7261 6d65 7465      Nth paramete
-00011580: 7220 6465 6669 6e65 6420 696e 205b 302c  r defined in [0,
-00011590: 2031 5d0d 0a0d 0a20 2020 2052 6574 7572   1]....    Retur
-000115a0: 6e73 0d0a 2020 2020 2d2d 2d2d 2d2d 2d0d  ns..    -------.
-000115b0: 0a20 2020 2079 3a20 6e64 6172 7261 7920  .    y: ndarray 
-000115c0: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
-000115d0: 2078 2031 5d0d 0a20 2020 2020 2020 204f   x 1]..        O
-000115e0: 7574 7075 740d 0a0d 0a20 2020 204e 6f74  utput....    Not
-000115f0: 6573 0d0a 2020 2020 2d2d 2d2d 2d0d 0a20  es..    -----.. 
-00011600: 2020 202e 2e20 706c 6f74 3a3a 0d0a 0d0a     .. plot::....
-00011610: 2020 2020 2020 2069 6d70 6f72 7420 6e75         import nu
-00011620: 6d70 7920 6173 206e 700d 0a20 2020 2020  mpy as np..     
-00011630: 2020 6672 6f6d 2070 7967 7063 2e74 6573    from pygpc.tes
-00011640: 7466 756e 6374 696f 6e73 2069 6d70 6f72  tfunctions impor
-00011650: 7420 706c 6f74 5f74 6573 7466 756e 6374  t plot_testfunct
-00011660: 696f 6e20 6173 2070 6c6f 740d 0a20 2020  ion as plot..   
-00011670: 2020 2020 6672 6f6d 2063 6f6c 6c65 6374      from collect
-00011680: 696f 6e73 2069 6d70 6f72 7420 4f72 6465  ions import Orde
-00011690: 7265 6444 6963 740d 0a0d 0a20 2020 2020  redDict....     
-000116a0: 2020 7061 7261 6d65 7465 7273 203d 204f    parameters = O
-000116b0: 7264 6572 6564 4469 6374 2829 0d0a 2020  rderedDict()..  
-000116c0: 2020 2020 2070 6172 616d 6574 6572 735b       parameters[
-000116d0: 2278 3122 5d20 3d20 6e70 2e6c 696e 7370  "x1"] = np.linsp
-000116e0: 6163 6528 302c 2031 2c20 3130 3029 0d0a  ace(0, 1, 100)..
-000116f0: 2020 2020 2020 2070 6172 616d 6574 6572         parameter
-00011700: 735b 2278 3222 5d20 3d20 6e70 2e6c 696e  s["x2"] = np.lin
-00011710: 7370 6163 6528 302c 2031 2c20 3130 3029  space(0, 1, 100)
-00011720: 0d0a 0d0a 2020 2020 2020 2070 6c6f 7428  ....       plot(
-00011730: 2247 656e 7a43 6f6e 7469 6e75 6f75 7322  "GenzContinuous"
-00011740: 2c20 7061 7261 6d65 7465 7273 290d 0a0d  , parameters)...
-00011750: 0a20 2020 202e 2e20 5b31 5d20 4765 6e7a  .    .. [1] Genz
-00011760: 2c20 412e 2028 3139 3834 292c 2054 6573  , A. (1984), Tes
-00011770: 7469 6e67 206d 756c 7469 6469 6d65 6e73  ting multidimens
-00011780: 696f 6e61 6c20 696e 7465 6772 6174 696f  ional integratio
-00011790: 6e20 726f 7574 696e 6573 2e0d 0a20 2020  n routines...   
-000117a0: 2020 2020 5072 6f63 2e20 6f66 2069 6e74      Proc. of int
-000117b0: 6572 6e61 7469 6f6e 616c 2063 6f6e 6665  ernational confe
-000117c0: 7265 6e63 6520 6f6e 2054 6f6f 6c73 2c20  rence on Tools, 
-000117d0: 6d65 7468 6f64 7320 616e 6420 6c61 6e67  methods and lang
-000117e0: 7561 6765 7320 666f 7220 7363 6965 6e74  uages for scient
-000117f0: 6966 6963 0d0a 2020 2020 2020 2061 6e64  ific..       and
-00011800: 2065 6e67 696e 6565 7269 6e67 2063 6f6d   engineering com
-00011810: 7075 7461 7469 6f6e 2c20 456c 7365 7669  putation, Elsevi
-00011820: 6572 204e 6f72 7468 2d48 6f6c 6c61 6e64  er North-Holland
-00011830: 2c20 496e 632e 2c20 4e65 7759 6f72 6b2c  , Inc., NewYork,
-00011840: 204e 592c 2055 5341 2c20 7070 2e20 3831   NY, USA, pp. 81
-00011850: 2d39 342e 0d0a 0d0a 2020 2020 2e2e 205b  -94.....    .. [
-00011860: 325d 2068 7474 7073 3a2f 2f77 7777 2e73  2] https://www.s
-00011870: 6675 2e63 612f 7e73 7375 726a 616e 6f2f  fu.ca/~ssurjano/
-00011880: 636f 6e74 2e68 746d 6c0d 0a20 2020 2022  cont.html..    "
-00011890: 2222 0d0a 0d0a 2020 2020 6465 6620 5f5f  ""....    def __
-000118a0: 696e 6974 5f5f 2873 656c 662c 206d 6174  init__(self, mat
-000118b0: 6c61 625f 6d6f 6465 6c3d 4661 6c73 6529  lab_model=False)
-000118c0: 3a0d 0a20 2020 2020 2020 2073 7570 6572  :..        super
-000118d0: 2874 7970 6528 7365 6c66 292c 2073 656c  (type(self), sel
-000118e0: 6629 2e5f 5f69 6e69 745f 5f28 6d61 746c  f).__init__(matl
-000118f0: 6162 5f6d 6f64 656c 3d6d 6174 6c61 625f  ab_model=matlab_
-00011900: 6d6f 6465 6c29 0d0a 2020 2020 2020 2020  model)..        
-00011910: 7365 6c66 2e66 6e61 6d65 203d 2069 6e73  self.fname = ins
-00011920: 7065 6374 2e67 6574 6669 6c65 2869 6e73  pect.getfile(ins
-00011930: 7065 6374 2e63 7572 7265 6e74 6672 616d  pect.currentfram
-00011940: 6528 2929 0d0a 0d0a 2020 2020 6465 6620  e())....    def 
-00011950: 7661 6c69 6461 7465 2873 656c 6629 3a0d  validate(self):.
-00011960: 0a20 2020 2020 2020 2070 6173 730d 0a0d  .        pass...
-00011970: 0a20 2020 2064 6566 2073 696d 756c 6174  .    def simulat
-00011980: 6528 7365 6c66 2c20 7072 6f63 6573 735f  e(self, process_
-00011990: 6964 3d4e 6f6e 652c 206d 6174 6c61 625f  id=None, matlab_
-000119a0: 656e 6769 6e65 3d4e 6f6e 6529 3a0d 0a20  engine=None):.. 
-000119b0: 2020 2020 2020 206e 203d 206c 656e 2873         n = len(s
-000119c0: 656c 662e 702e 6b65 7973 2829 290d 0a0d  elf.p.keys())...
-000119d0: 0a20 2020 2020 2020 2023 2073 6574 2063  .        # set c
-000119e0: 6f6e 7374 616e 7473 0d0a 2020 2020 2020  onstants..      
-000119f0: 2020 7520 3d20 302e 3520 2a20 6e70 2e6f    u = 0.5 * np.o
-00011a00: 6e65 7328 6e29 0d0a 2020 2020 2020 2020  nes(n)..        
-00011a10: 6120 3d20 3520 2a20 6e70 2e6f 6e65 7328  a = 5 * np.ones(
-00011a20: 6e29 0d0a 0d0a 2020 2020 2020 2020 2320  n)....        # 
-00011a30: 6465 7465 726d 696e 6520 7375 6d20 696e  determine sum in
-00011a40: 2065 7870 6f6e 656e 740d 0a20 2020 2020   exponent..     
-00011a50: 2020 2073 203d 206e 702e 7a65 726f 7328     s = np.zeros(
-00011a60: 6e70 2e61 7272 6179 2873 656c 662e 705b  np.array(self.p[
-00011a70: 6c69 7374 2873 656c 662e 702e 6b65 7973  list(self.p.keys
-00011a80: 2829 295b 305d 5d29 2e73 697a 6529 0d0a  ())[0]]).size)..
-00011a90: 0d0a 2020 2020 2020 2020 666f 7220 692c  ..        for i,
-00011aa0: 206b 6579 2069 6e20 656e 756d 6572 6174   key in enumerat
-00011ab0: 6528 7365 6c66 2e70 2e6b 6579 7328 2929  e(self.p.keys())
-00011ac0: 3a0d 0a20 2020 2020 2020 2020 2020 2073  :..            s
-00011ad0: 202b 3d20 615b 695d 202a 206e 702e 6162   += a[i] * np.ab
-00011ae0: 7328 7365 6c66 2e70 5b6b 6579 5d20 2d20  s(self.p[key] - 
-00011af0: 755b 695d 290d 0a0d 0a20 2020 2020 2020  u[i])....       
-00011b00: 2023 2064 6574 6572 6d69 6e65 206f 7574   # determine out
-00011b10: 7075 740d 0a20 2020 2020 2020 2079 203d  put..        y =
-00011b20: 206e 702e 6578 7028 2d73 290d 0a0d 0a20   np.exp(-s).... 
-00011b30: 2020 2020 2020 2079 5f6f 7574 203d 2079         y_out = y
-00011b40: 5b3a 2c20 6e70 2e6e 6577 6178 6973 5d0d  [:, np.newaxis].
-00011b50: 0a0d 0a20 2020 2020 2020 2072 6574 7572  ...        retur
-00011b60: 6e20 795f 6f75 740d 0a0d 0a0d 0a63 6c61  n y_out......cla
-00011b70: 7373 2047 656e 7a43 6f72 6e65 7250 6561  ss GenzCornerPea
-00011b80: 6b28 4162 7374 7261 6374 4d6f 6465 6c29  k(AbstractModel)
-00011b90: 3a0d 0a20 2020 2022 2222 0d0a 2020 2020  :..    """..    
-00011ba0: 4e2d 6469 6d65 6e73 696f 6e61 6c20 2243  N-dimensional "C
-00011bb0: 6f72 6e65 7250 6561 6b22 2047 656e 7a20  ornerPeak" Genz 
-00011bc0: 6675 6e63 7469 6f6e 205b 312c 325d 2e20  function [1,2]. 
-00011bd0: 4974 2069 7320 6465 6669 6e65 6420 696e  It is defined in
-00011be0: 2074 6865 2069 6e74 6572 7661 6c20 5b30   the interval [0
-00011bf0: 2c20 315d 2078 202e 2e2e 2078 205b 302c  , 1] x ... x [0,
-00011c00: 2031 5d2e 0d0a 2020 2020 5573 6564 2062   1]...    Used b
-00011c10: 7920 5b33 5d20 6173 2074 6573 7466 756e  y [3] as testfun
-00011c20: 6374 696f 6e2e 0d0a 0d0a 2020 2020 2e2e  ction.....    ..
-00011c30: 206d 6174 683a 3a20 7920 3d20 5c5c 6c65   math:: y = \\le
-00011c40: 6674 2820 3120 2b20 5c73 756d 5f7b 693d  ft( 1 + \sum_{i=
-00011c50: 317d 5e4e 2061 5f69 2078 5f69 5c5c 7269  1}^N a_i x_i\\ri
-00011c60: 6768 7429 5e7b 2d28 4e20 2b20 3129 7d0d  ght)^{-(N + 1)}.
-00011c70: 0a0d 0a20 2020 2050 6172 616d 6574 6572  ...    Parameter
-00011c80: 730d 0a20 2020 202d 2d2d 2d2d 2d2d 2d2d  s..    ---------
-00011c90: 2d0d 0a20 2020 2070 5b22 7831 225d 3a20  -..    p["x1"]: 
-00011ca0: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
-00011cb0: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
-00011cc0: 645d 0d0a 2020 2020 2020 2020 4669 7273  d]..        Firs
-00011cd0: 7420 7061 7261 6d65 7465 7220 6465 6669  t parameter defi
-00011ce0: 6e65 6420 696e 205b 302c 2031 5d0d 0a20  ned in [0, 1].. 
-00011cf0: 2020 2070 5b22 7869 225d 3a20 666c 6f61     p["xi"]: floa
-00011d00: 7420 6f72 206e 6461 7272 6179 206f 6620  t or ndarray of 
-00011d10: 666c 6f61 7420 5b6e 5f67 7269 645d 0d0a  float [n_grid]..
-00011d20: 2020 2020 2020 2020 692d 7468 2070 6172          i-th par
-00011d30: 616d 6574 6572 2064 6566 696e 6564 2069  ameter defined i
-00011d40: 6e20 5b30 2c20 315d 0d0a 2020 2020 705b  n [0, 1]..    p[
-00011d50: 2278 4e22 5d3a 2066 6c6f 6174 206f 7220  "xN"]: float or 
-00011d60: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-00011d70: 205b 6e5f 6772 6964 5d0d 0a20 2020 2020   [n_grid]..     
-00011d80: 2020 204e 7468 2070 6172 616d 6574 6572     Nth parameter
-00011d90: 2064 6566 696e 6564 2069 6e20 5b30 2c20   defined in [0, 
-00011da0: 315d 0d0a 0d0a 2020 2020 5265 7475 726e  1]....    Return
-00011db0: 730d 0a20 2020 202d 2d2d 2d2d 2d2d 0d0a  s..    -------..
-00011dc0: 2020 2020 793a 206e 6461 7272 6179 206f      y: ndarray o
-00011dd0: 6620 666c 6f61 7420 5b6e 5f67 7269 6420  f float [n_grid 
-00011de0: 7820 315d 0d0a 2020 2020 2020 2020 4f75  x 1]..        Ou
-00011df0: 7470 7574 0d0a 0d0a 2020 2020 4e6f 7465  tput....    Note
-00011e00: 730d 0a20 2020 202d 2d2d 2d2d 0d0a 2020  s..    -----..  
-00011e10: 2020 2e2e 2070 6c6f 743a 3a0d 0a0d 0a20    .. plot::.... 
-00011e20: 2020 2020 2020 696d 706f 7274 206e 756d        import num
-00011e30: 7079 2061 7320 6e70 0d0a 2020 2020 2020  py as np..      
-00011e40: 2066 726f 6d20 7079 6770 632e 7465 7374   from pygpc.test
-00011e50: 6675 6e63 7469 6f6e 7320 696d 706f 7274  functions import
-00011e60: 2070 6c6f 745f 7465 7374 6675 6e63 7469   plot_testfuncti
-00011e70: 6f6e 2061 7320 706c 6f74 0d0a 2020 2020  on as plot..    
-00011e80: 2020 2066 726f 6d20 636f 6c6c 6563 7469     from collecti
-00011e90: 6f6e 7320 696d 706f 7274 204f 7264 6572  ons import Order
-00011ea0: 6564 4469 6374 0d0a 0d0a 2020 2020 2020  edDict....      
-00011eb0: 2070 6172 616d 6574 6572 7320 3d20 4f72   parameters = Or
-00011ec0: 6465 7265 6444 6963 7428 290d 0a20 2020  deredDict()..   
-00011ed0: 2020 2020 7061 7261 6d65 7465 7273 5b22      parameters["
-00011ee0: 7831 225d 203d 206e 702e 6c69 6e73 7061  x1"] = np.linspa
-00011ef0: 6365 2830 2c20 312c 2031 3030 290d 0a20  ce(0, 1, 100).. 
-00011f00: 2020 2020 2020 7061 7261 6d65 7465 7273        parameters
-00011f10: 5b22 7832 225d 203d 206e 702e 6c69 6e73  ["x2"] = np.lins
-00011f20: 7061 6365 2830 2c20 312c 2031 3030 290d  pace(0, 1, 100).
-00011f30: 0a0d 0a20 2020 2020 2020 706c 6f74 2822  ...       plot("
-00011f40: 4765 6e7a 436f 726e 6572 5065 616b 222c  GenzCornerPeak",
-00011f50: 2070 6172 616d 6574 6572 7329 0d0a 0d0a   parameters)....
-00011f60: 2020 2020 2e2e 205b 315d 2047 656e 7a2c      .. [1] Genz,
-00011f70: 2041 2e20 2831 3938 3429 2c20 5465 7374   A. (1984), Test
-00011f80: 696e 6720 6d75 6c74 6964 696d 656e 7369  ing multidimensi
-00011f90: 6f6e 616c 2069 6e74 6567 7261 7469 6f6e  onal integration
-00011fa0: 2072 6f75 7469 6e65 732e 0d0a 2020 2020   routines...    
-00011fb0: 2020 2050 726f 632e 206f 6620 696e 7465     Proc. of inte
-00011fc0: 726e 6174 696f 6e61 6c20 636f 6e66 6572  rnational confer
-00011fd0: 656e 6365 206f 6e20 546f 6f6c 732c 206d  ence on Tools, m
-00011fe0: 6574 686f 6473 2061 6e64 206c 616e 6775  ethods and langu
-00011ff0: 6167 6573 2066 6f72 2073 6369 656e 7469  ages for scienti
-00012000: 6669 630d 0a20 2020 2020 2020 616e 6420  fic..       and 
-00012010: 656e 6769 6e65 6572 696e 6720 636f 6d70  engineering comp
-00012020: 7574 6174 696f 6e2c 2045 6c73 6576 6965  utation, Elsevie
-00012030: 7220 4e6f 7274 682d 486f 6c6c 616e 642c  r North-Holland,
-00012040: 2049 6e63 2e2c 204e 6577 596f 726b 2c20   Inc., NewYork, 
-00012050: 4e59 2c20 5553 412c 2070 702e 2038 312d  NY, USA, pp. 81-
-00012060: 3934 2e0d 0a0d 0a20 2020 202e 2e20 5b32  94.....    .. [2
-00012070: 5d20 6874 7470 733a 2f2f 7777 772e 7366  ] https://www.sf
-00012080: 752e 6361 2f7e 7373 7572 6a61 6e6f 2f63  u.ca/~ssurjano/c
-00012090: 6f70 6561 6b2e 6874 6d6c 0d0a 0d0a 2020  opeak.html....  
-000120a0: 2020 2e2e 205b 335d 204a 616b 656d 616e    .. [3] Jakeman
-000120b0: 2c20 4a2e 2044 2e2c 2045 6c64 7265 642c  , J. D., Eldred,
-000120c0: 204d 2e20 532e 2c20 2620 5361 7267 7379   M. S., & Sargsy
-000120d0: 616e 2c20 4b2e 2028 3230 3135 292e 0d0a  an, K. (2015)...
-000120e0: 2020 2020 2020 2045 6e68 616e 6369 6e67         Enhancing
-000120f0: 20e2 8493 312d 6d69 6e69 6d69 7a61 7469   ...1-minimizati
-00012100: 6f6e 2065 7374 696d 6174 6573 206f 6620  on estimates of 
-00012110: 706f 6c79 6e6f 6d69 616c 2063 6861 6f73  polynomial chaos
-00012120: 2065 7870 616e 7369 6f6e 7320 7573 696e   expansions usin
-00012130: 6720 6261 7369 7320 7365 6c65 6374 696f  g basis selectio
-00012140: 6e2e 0d0a 2020 2020 2020 204a 6f75 726e  n...       Journ
-00012150: 616c 206f 6620 436f 6d70 7574 6174 696f  al of Computatio
-00012160: 6e61 6c20 5068 7973 6963 732c 2032 3839  nal Physics, 289
-00012170: 2c20 3138 2d33 342e 0d0a 2020 2020 2222  , 18-34...    ""
-00012180: 220d 0a0d 0a20 2020 2064 6566 205f 5f69  "....    def __i
-00012190: 6e69 745f 5f28 7365 6c66 2c20 6d61 746c  nit__(self, matl
-000121a0: 6162 5f6d 6f64 656c 3d46 616c 7365 293a  ab_model=False):
-000121b0: 0d0a 2020 2020 2020 2020 7375 7065 7228  ..        super(
-000121c0: 7479 7065 2873 656c 6629 2c20 7365 6c66  type(self), self
-000121d0: 292e 5f5f 696e 6974 5f5f 286d 6174 6c61  ).__init__(matla
-000121e0: 625f 6d6f 6465 6c3d 6d61 746c 6162 5f6d  b_model=matlab_m
-000121f0: 6f64 656c 290d 0a20 2020 2020 2020 2073  odel)..        s
-00012200: 656c 662e 666e 616d 6520 3d20 696e 7370  elf.fname = insp
-00012210: 6563 742e 6765 7466 696c 6528 696e 7370  ect.getfile(insp
-00012220: 6563 742e 6375 7272 656e 7466 7261 6d65  ect.currentframe
-00012230: 2829 290d 0a0d 0a20 2020 2064 6566 2076  ())....    def v
-00012240: 616c 6964 6174 6528 7365 6c66 293a 0d0a  alidate(self):..
-00012250: 2020 2020 2020 2020 7061 7373 0d0a 0d0a          pass....
-00012260: 2020 2020 6465 6620 7369 6d75 6c61 7465      def simulate
-00012270: 2873 656c 662c 2070 726f 6365 7373 5f69  (self, process_i
-00012280: 643d 4e6f 6e65 2c20 6d61 746c 6162 5f65  d=None, matlab_e
-00012290: 6e67 696e 653d 4e6f 6e65 293a 0d0a 2020  ngine=None):..  
-000122a0: 2020 2020 2020 6e20 3d20 6c65 6e28 7365        n = len(se
-000122b0: 6c66 2e70 2e6b 6579 7328 2929 0d0a 0d0a  lf.p.keys())....
-000122c0: 2020 2020 2020 2020 2320 7365 7420 636f          # set co
-000122d0: 6e73 7461 6e74 730d 0a20 2020 2020 2020  nstants..       
-000122e0: 2061 203d 2035 202a 206e 702e 6f6e 6573   a = 5 * np.ones
-000122f0: 286e 290d 0a0d 0a20 2020 2020 2020 2023  (n)....        #
-00012300: 2064 6574 6572 6d69 6e65 2073 756d 0d0a   determine sum..
-00012310: 2020 2020 2020 2020 7320 3d20 6e70 2e7a          s = np.z
-00012320: 6572 6f73 286e 702e 6172 7261 7928 7365  eros(np.array(se
-00012330: 6c66 2e70 5b6c 6973 7428 7365 6c66 2e70  lf.p[list(self.p
-00012340: 2e6b 6579 7328 2929 5b30 5d5d 292e 7369  .keys())[0]]).si
-00012350: 7a65 290d 0a0d 0a20 2020 2020 2020 2066  ze)....        f
-00012360: 6f72 2069 2c20 6b65 7920 696e 2065 6e75  or i, key in enu
-00012370: 6d65 7261 7465 2873 656c 662e 702e 6b65  merate(self.p.ke
-00012380: 7973 2829 293a 0d0a 2020 2020 2020 2020  ys()):..        
-00012390: 2020 2020 7320 2b3d 2061 5b69 5d20 2a20      s += a[i] * 
-000123a0: 7365 6c66 2e70 5b6b 6579 5d0d 0a0d 0a20  self.p[key].... 
-000123b0: 2020 2020 2020 2023 2064 6574 6572 6d69         # determi
-000123c0: 6e65 206f 7574 7075 740d 0a20 2020 2020  ne output..     
-000123d0: 2020 2079 203d 2028 3120 2b20 7329 202a     y = (1 + s) *
-000123e0: 2a20 2d28 6e20 2b20 3129 0d0a 0d0a 2020  * -(n + 1)....  
-000123f0: 2020 2020 2020 795f 6f75 7420 3d20 795b        y_out = y[
-00012400: 3a2c 206e 702e 6e65 7761 7869 735d 0d0a  :, np.newaxis]..
-00012410: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-00012420: 2079 5f6f 7574 0d0a 0d0a 0d0a 636c 6173   y_out......clas
-00012430: 7320 4765 6e7a 4469 7363 6f6e 7469 6e75  s GenzDiscontinu
-00012440: 6f75 7328 4162 7374 7261 6374 4d6f 6465  ous(AbstractMode
-00012450: 6c29 3a0d 0a20 2020 2022 2222 0d0a 2020  l):..    """..  
-00012460: 2020 4e2d 6469 6d65 6e73 696f 6e61 6c20    N-dimensional 
-00012470: 2244 6973 636f 6e74 696e 756f 7573 2220  "Discontinuous" 
-00012480: 4765 6e7a 2066 756e 6374 696f 6e20 5b31  Genz function [1
-00012490: 5d2e 2049 7420 6973 2064 6566 696e 6564  ]. It is defined
-000124a0: 2069 6e20 7468 6520 696e 7465 7276 616c   in the interval
-000124b0: 205b 302c 2031 5d20 7820 2e2e 2e20 7820   [0, 1] x ... x 
-000124c0: 5b30 2c20 315d 2e0d 0a0d 0a20 2020 202e  [0, 1].....    .
-000124d0: 2e20 6d61 7468 3a3a 2079 203d 205c 6578  . math:: y = \ex
-000124e0: 705c 5c6c 6566 7428 205c 7375 6d5f 7b69  p\\left( \sum_{i
-000124f0: 3d31 7d5e 4e20 615f 6920 785f 695c 5c72  =1}^N a_i x_i\\r
-00012500: 6967 6874 2920 5c71 7561 6420 5c6d 6174  ight) \quad \mat
-00012510: 6872 6d7b 6966 7d20 5c71 7561 6420 785f  hrm{if} \quad x_
-00012520: 6920 3c20 755f 6920 5c71 7561 6420 5c6d  i < u_i \quad \m
-00012530: 6174 6872 6d7b 656c 7365 7d20 5c71 7561  athrm{else} \qua
-00012540: 6420 300d 0a0d 0a20 2020 2050 6172 616d  d 0....    Param
-00012550: 6574 6572 730d 0a20 2020 202d 2d2d 2d2d  eters..    -----
-00012560: 2d2d 2d2d 2d0d 0a20 2020 2070 5b22 7831  -----..    p["x1
-00012570: 225d 3a20 666c 6f61 7420 6f72 206e 6461  "]: float or nda
-00012580: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
-00012590: 5f67 7269 645d 0d0a 2020 2020 2020 2020  _grid]..        
-000125a0: 4669 7273 7420 7061 7261 6d65 7465 7220  First parameter 
-000125b0: 6465 6669 6e65 6420 696e 205b 302c 2031  defined in [0, 1
-000125c0: 5d0d 0a20 2020 2070 5b22 7869 225d 3a20  ]..    p["xi"]: 
-000125d0: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
-000125e0: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
-000125f0: 645d 0d0a 2020 2020 2020 2020 692d 7468  d]..        i-th
-00012600: 2070 6172 616d 6574 6572 2064 6566 696e   parameter defin
-00012610: 6564 2069 6e20 5b30 2c20 315d 0d0a 2020  ed in [0, 1]..  
-00012620: 2020 705b 2278 4e22 5d3a 2066 6c6f 6174    p["xN"]: float
-00012630: 206f 7220 6e64 6172 7261 7920 6f66 2066   or ndarray of f
-00012640: 6c6f 6174 205b 6e5f 6772 6964 5d0d 0a20  loat [n_grid].. 
-00012650: 2020 2020 2020 204e 7468 2070 6172 616d         Nth param
-00012660: 6574 6572 2064 6566 696e 6564 2069 6e20  eter defined in 
-00012670: 5b30 2c20 315d 0d0a 0d0a 2020 2020 5265  [0, 1]....    Re
-00012680: 7475 726e 730d 0a20 2020 202d 2d2d 2d2d  turns..    -----
-00012690: 2d2d 0d0a 2020 2020 793a 206e 6461 7272  --..    y: ndarr
-000126a0: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
-000126b0: 7269 6420 7820 315d 0d0a 2020 2020 2020  rid x 1]..      
-000126c0: 2020 4f75 7470 7574 0d0a 0d0a 2020 2020    Output....    
-000126d0: 4e6f 7465 730d 0a20 2020 202d 2d2d 2d2d  Notes..    -----
-000126e0: 0d0a 2020 2020 2e2e 2070 6c6f 743a 3a0d  ..    .. plot::.
-000126f0: 0a0d 0a20 2020 2020 2020 696d 706f 7274  ...       import
-00012700: 206e 756d 7079 2061 7320 6e70 0d0a 2020   numpy as np..  
-00012710: 2020 2020 2066 726f 6d20 7079 6770 632e       from pygpc.
-00012720: 7465 7374 6675 6e63 7469 6f6e 7320 696d  testfunctions im
-00012730: 706f 7274 2070 6c6f 745f 7465 7374 6675  port plot_testfu
-00012740: 6e63 7469 6f6e 2061 7320 706c 6f74 0d0a  nction as plot..
-00012750: 2020 2020 2020 2066 726f 6d20 636f 6c6c         from coll
-00012760: 6563 7469 6f6e 7320 696d 706f 7274 204f  ections import O
-00012770: 7264 6572 6564 4469 6374 0d0a 0d0a 2020  rderedDict....  
-00012780: 2020 2020 2070 6172 616d 6574 6572 7320       parameters 
-00012790: 3d20 4f72 6465 7265 6444 6963 7428 290d  = OrderedDict().
-000127a0: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
-000127b0: 7273 5b22 7831 225d 203d 206e 702e 6c69  rs["x1"] = np.li
-000127c0: 6e73 7061 6365 2830 2c20 312c 2031 3030  nspace(0, 1, 100
-000127d0: 290d 0a20 2020 2020 2020 7061 7261 6d65  )..       parame
-000127e0: 7465 7273 5b22 7832 225d 203d 206e 702e  ters["x2"] = np.
-000127f0: 6c69 6e73 7061 6365 2830 2c20 312c 2031  linspace(0, 1, 1
-00012800: 3030 290d 0a0d 0a20 2020 2020 2020 706c  00)....       pl
-00012810: 6f74 2822 4765 6e7a 4469 7363 6f6e 7469  ot("GenzDisconti
-00012820: 6e75 6f75 7322 2c20 7061 7261 6d65 7465  nuous", paramete
-00012830: 7273 290d 0a0d 0a20 2020 202e 2e20 5b31  rs)....    .. [1
-00012840: 5d20 4765 6e7a 2c20 412e 2028 3139 3834  ] Genz, A. (1984
-00012850: 292c 2054 6573 7469 6e67 206d 756c 7469  ), Testing multi
-00012860: 6469 6d65 6e73 696f 6e61 6c20 696e 7465  dimensional inte
-00012870: 6772 6174 696f 6e20 726f 7574 696e 6573  gration routines
-00012880: 2e0d 0a20 2020 2020 2020 5072 6f63 2e20  ...       Proc. 
-00012890: 6f66 2069 6e74 6572 6e61 7469 6f6e 616c  of international
-000128a0: 2063 6f6e 6665 7265 6e63 6520 6f6e 2054   conference on T
-000128b0: 6f6f 6c73 2c20 6d65 7468 6f64 7320 616e  ools, methods an
-000128c0: 6420 6c61 6e67 7561 6765 7320 666f 7220  d languages for 
-000128d0: 7363 6965 6e74 6966 6963 0d0a 2020 2020  scientific..    
-000128e0: 2020 2061 6e64 2065 6e67 696e 6565 7269     and engineeri
-000128f0: 6e67 2063 6f6d 7075 7461 7469 6f6e 2c20  ng computation, 
-00012900: 456c 7365 7669 6572 204e 6f72 7468 2d48  Elsevier North-H
-00012910: 6f6c 6c61 6e64 2c20 496e 632e 2c20 4e65  olland, Inc., Ne
-00012920: 7759 6f72 6b2c 204e 592c 2055 5341 2c20  wYork, NY, USA, 
-00012930: 7070 2e20 3831 2d39 342e 0d0a 0d0a 2020  pp. 81-94.....  
-00012940: 2020 2e2e 205b 325d 2068 7474 7073 3a2f    .. [2] https:/
-00012950: 2f77 7777 2e73 6675 2e63 612f 7e73 7375  /www.sfu.ca/~ssu
-00012960: 726a 616e 6f2f 6469 7363 2e68 746d 6c0d  rjano/disc.html.
-00012970: 0a20 2020 2022 2222 0d0a 0d0a 2020 2020  .    """....    
-00012980: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
-00012990: 662c 206d 6174 6c61 625f 6d6f 6465 6c3d  f, matlab_model=
-000129a0: 4661 6c73 6529 3a0d 0a20 2020 2020 2020  False):..       
-000129b0: 2073 7570 6572 2874 7970 6528 7365 6c66   super(type(self
-000129c0: 292c 2073 656c 6629 2e5f 5f69 6e69 745f  ), self).__init_
-000129d0: 5f28 6d61 746c 6162 5f6d 6f64 656c 3d6d  _(matlab_model=m
-000129e0: 6174 6c61 625f 6d6f 6465 6c29 0d0a 2020  atlab_model)..  
-000129f0: 2020 2020 2020 7365 6c66 2e66 6e61 6d65        self.fname
-00012a00: 203d 2069 6e73 7065 6374 2e67 6574 6669   = inspect.getfi
-00012a10: 6c65 2869 6e73 7065 6374 2e63 7572 7265  le(inspect.curre
-00012a20: 6e74 6672 616d 6528 2929 0d0a 0d0a 2020  ntframe())....  
-00012a30: 2020 6465 6620 7661 6c69 6461 7465 2873    def validate(s
-00012a40: 656c 6629 3a0d 0a20 2020 2020 2020 2070  elf):..        p
-00012a50: 6173 730d 0a0d 0a20 2020 2064 6566 2073  ass....    def s
-00012a60: 696d 756c 6174 6528 7365 6c66 2c20 7072  imulate(self, pr
-00012a70: 6f63 6573 735f 6964 3d4e 6f6e 652c 206d  ocess_id=None, m
-00012a80: 6174 6c61 625f 656e 6769 6e65 3d4e 6f6e  atlab_engine=Non
-00012a90: 6529 3a0d 0a0d 0a20 2020 2020 2020 206e  e):....        n
-00012aa0: 203d 206c 656e 2873 656c 662e 702e 6b65   = len(self.p.ke
-00012ab0: 7973 2829 290d 0a0d 0a20 2020 2020 2020  ys())....       
-00012ac0: 2023 2073 6574 2063 6f6e 7374 616e 7473   # set constants
-00012ad0: 0d0a 2020 2020 2020 2020 7520 3d20 302e  ..        u = 0.
-00012ae0: 3520 2a20 6e70 2e6f 6e65 7328 6e29 0d0a  5 * np.ones(n)..
-00012af0: 2020 2020 2020 2020 6120 3d20 3520 2a20          a = 5 * 
-00012b00: 6e70 2e6f 6e65 7328 6e29 0d0a 0d0a 2020  np.ones(n)....  
-00012b10: 2020 2020 2020 6d61 736b 203d 206e 702e        mask = np.
-00012b20: 7a65 726f 7328 286c 656e 2873 656c 662e  zeros((len(self.
-00012b30: 705b 6c69 7374 2873 656c 662e 702e 6b65  p[list(self.p.ke
-00012b40: 7973 2829 295b 305d 5d29 2c20 6e29 290d  ys())[0]]), n)).
-00012b50: 0a0d 0a20 2020 2020 2020 2066 6f72 2069  ...        for i
-00012b60: 2c20 6b65 7920 696e 2065 6e75 6d65 7261  , key in enumera
-00012b70: 7465 2873 656c 662e 702e 6b65 7973 2829  te(self.p.keys()
-00012b80: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
-00012b90: 6d61 736b 5b3a 2c20 695d 203d 2028 7365  mask[:, i] = (se
-00012ba0: 6c66 2e70 5b6b 6579 5d20 3e20 755b 695d  lf.p[key] > u[i]
-00012bb0: 292e 7371 7565 657a 6528 290d 0a20 2020  ).squeeze()..   
-00012bc0: 2020 2020 206d 6173 6b20 3d20 6d61 736b       mask = mask
-00012bd0: 2e61 6e79 2861 7869 733d 3129 0d0a 0d0a  .any(axis=1)....
-00012be0: 2020 2020 2020 2020 2320 6465 7465 726d          # determ
-00012bf0: 696e 6520 7375 6d0d 0a20 2020 2020 2020  ine sum..       
-00012c00: 2073 203d 206e 702e 7a65 726f 7328 286e   s = np.zeros((n
-00012c10: 702e 6172 7261 7928 7365 6c66 2e70 5b6c  p.array(self.p[l
-00012c20: 6973 7428 7365 6c66 2e70 2e6b 6579 7328  ist(self.p.keys(
-00012c30: 2929 5b30 5d5d 292e 7369 7a65 2c20 3129  ))[0]]).size, 1)
-00012c40: 290d 0a0d 0a20 2020 2020 2020 2066 6f72  )....        for
-00012c50: 2069 2c20 6b65 7920 696e 2065 6e75 6d65   i, key in enume
-00012c60: 7261 7465 2873 656c 662e 702e 6b65 7973  rate(self.p.keys
-00012c70: 2829 293a 0d0a 2020 2020 2020 2020 2020  ()):..          
-00012c80: 2020 6966 2073 656c 662e 705b 6b65 795d    if self.p[key]
-00012c90: 2e6e 6469 6d20 3d3d 2031 3a0d 0a20 2020  .ndim == 1:..   
-00012ca0: 2020 2020 2020 2020 2020 2020 2073 656c               sel
-00012cb0: 662e 705b 6b65 795d 203d 2073 656c 662e  f.p[key] = self.
-00012cc0: 705b 6b65 795d 5b3a 2c20 6e70 2e6e 6577  p[key][:, np.new
-00012cd0: 6178 6973 5d0d 0a20 2020 2020 2020 2020  axis]..         
-00012ce0: 2020 2073 202b 3d20 615b 695d 202a 2073     s += a[i] * s
-00012cf0: 656c 662e 705b 6b65 795d 0d0a 0d0a 2020  elf.p[key]....  
-00012d00: 2020 2020 2020 2320 6465 7465 726d 696e        # determin
-00012d10: 6520 6f75 7470 7574 0d0a 2020 2020 2020  e output..      
-00012d20: 2020 7920 3d20 6e70 2e65 7870 2873 290d    y = np.exp(s).
-00012d30: 0a20 2020 2020 2020 2079 5b6d 6173 6b5d  .        y[mask]
-00012d40: 203d 2030 2e0d 0a0d 0a20 2020 2020 2020   = 0.....       
-00012d50: 2072 6574 7572 6e20 790d 0a0d 0a0d 0a63   return y......c
-00012d60: 6c61 7373 2047 656e 7a47 6175 7373 6961  lass GenzGaussia
-00012d70: 6e50 6561 6b28 4162 7374 7261 6374 4d6f  nPeak(AbstractMo
-00012d80: 6465 6c29 3a0d 0a20 2020 2022 2222 0d0a  del):..    """..
-00012d90: 2020 2020 4e2d 6469 6d65 6e73 696f 6e61      N-dimensiona
-00012da0: 6c20 2247 6175 7373 6961 6e50 6561 6b22  l "GaussianPeak"
-00012db0: 2047 656e 7a20 6675 6e63 7469 6f6e 205b   Genz function [
-00012dc0: 315d 2e20 4974 2069 7320 6465 6669 6e65  1]. It is define
-00012dd0: 6420 696e 2074 6865 2069 6e74 6572 7661  d in the interva
-00012de0: 6c20 5b30 2c20 315d 2078 202e 2e2e 2078  l [0, 1] x ... x
-00012df0: 205b 302c 2031 5d2e 0d0a 0d0a 2020 2020   [0, 1].....    
-00012e00: 2e2e 206d 6174 683a 3a20 7920 3d20 5c65  .. math:: y = \e
-00012e10: 7870 5c5c 6c65 6674 2820 2d20 5c73 756d  xp\\left( - \sum
-00012e20: 5f7b 693d 317d 5e7b 4e7d 2061 5f69 205e  _{i=1}^{N} a_i ^
-00012e30: 3220 2878 5f69 202d 2075 5f69 295e 325c  2 (x_i - u_i)^2\
-00012e40: 5c72 6967 6874 290d 0a0d 0a20 2020 2042  \right)....    B
-00012e50: 7920 6465 6661 756c 7420 755f 6920 3d20  y default u_i = 
-00012e60: 302e 3520 616e 6420 615f 6920 3d20 352e  0.5 and a_i = 5.
-00012e70: 0d0a 0d0a 2020 2020 5061 7261 6d65 7465  ....    Paramete
-00012e80: 7273 0d0a 2020 2020 2d2d 2d2d 2d2d 2d2d  rs..    --------
-00012e90: 2d2d 0d0a 2020 2020 705b 2278 3122 5d3a  --..    p["x1"]:
-00012ea0: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
-00012eb0: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
-00012ec0: 6964 5d0d 0a20 2020 2020 2020 2046 6972  id]..        Fir
-00012ed0: 7374 2070 6172 616d 6574 6572 2064 6566  st parameter def
-00012ee0: 696e 6564 2069 6e20 5b30 2c20 315d 0d0a  ined in [0, 1]..
-00012ef0: 2020 2020 705b 2278 6922 5d3a 2066 6c6f      p["xi"]: flo
-00012f00: 6174 206f 7220 6e64 6172 7261 7920 6f66  at or ndarray of
-00012f10: 2066 6c6f 6174 205b 6e5f 6772 6964 5d0d   float [n_grid].
-00012f20: 0a20 2020 2020 2020 2069 2d74 6820 7061  .        i-th pa
-00012f30: 7261 6d65 7465 7220 6465 6669 6e65 6420  rameter defined 
-00012f40: 696e 205b 302c 2031 5d0d 0a20 2020 2070  in [0, 1]..    p
-00012f50: 5b22 784e 225d 3a20 666c 6f61 7420 6f72  ["xN"]: float or
-00012f60: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-00012f70: 7420 5b6e 5f67 7269 645d 0d0a 2020 2020  t [n_grid]..    
-00012f80: 2020 2020 4e74 6820 7061 7261 6d65 7465      Nth paramete
-00012f90: 7220 6465 6669 6e65 6420 696e 205b 302c  r defined in [0,
-00012fa0: 2031 5d0d 0a0d 0a20 2020 2052 6574 7572   1]....    Retur
-00012fb0: 6e73 0d0a 2020 2020 2d2d 2d2d 2d2d 2d0d  ns..    -------.
-00012fc0: 0a20 2020 2079 3a20 6e64 6172 7261 7920  .    y: ndarray 
-00012fd0: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
-00012fe0: 2078 2031 5d0d 0a20 2020 2020 2020 204f   x 1]..        O
-00012ff0: 7574 7075 740d 0a0d 0a20 2020 204e 6f74  utput....    Not
-00013000: 6573 0d0a 2020 2020 2d2d 2d2d 2d0d 0a20  es..    -----.. 
-00013010: 2020 202e 2e20 706c 6f74 3a3a 0d0a 0d0a     .. plot::....
-00013020: 2020 2020 2020 2069 6d70 6f72 7420 6e75         import nu
-00013030: 6d70 7920 6173 206e 700d 0a20 2020 2020  mpy as np..     
-00013040: 2020 6672 6f6d 2070 7967 7063 2e74 6573    from pygpc.tes
-00013050: 7466 756e 6374 696f 6e73 2069 6d70 6f72  tfunctions impor
-00013060: 7420 706c 6f74 5f74 6573 7466 756e 6374  t plot_testfunct
-00013070: 696f 6e20 6173 2070 6c6f 740d 0a20 2020  ion as plot..   
-00013080: 2020 2020 6672 6f6d 2063 6f6c 6c65 6374      from collect
-00013090: 696f 6e73 2069 6d70 6f72 7420 4f72 6465  ions import Orde
-000130a0: 7265 6444 6963 740d 0a0d 0a20 2020 2020  redDict....     
-000130b0: 2020 7061 7261 6d65 7465 7273 203d 204f    parameters = O
-000130c0: 7264 6572 6564 4469 6374 2829 0d0a 2020  rderedDict()..  
-000130d0: 2020 2020 2070 6172 616d 6574 6572 735b       parameters[
-000130e0: 2278 3122 5d20 3d20 6e70 2e6c 696e 7370  "x1"] = np.linsp
-000130f0: 6163 6528 302c 2031 2c20 3130 3029 0d0a  ace(0, 1, 100)..
-00013100: 2020 2020 2020 2070 6172 616d 6574 6572         parameter
-00013110: 735b 2278 3222 5d20 3d20 6e70 2e6c 696e  s["x2"] = np.lin
-00013120: 7370 6163 6528 302c 2031 2c20 3130 3029  space(0, 1, 100)
-00013130: 0d0a 0d0a 2020 2020 2020 2070 6c6f 7428  ....       plot(
-00013140: 2247 656e 7a47 6175 7373 6961 6e50 6561  "GenzGaussianPea
-00013150: 6b22 2c20 7061 7261 6d65 7465 7273 290d  k", parameters).
-00013160: 0a0d 0a20 2020 202e 2e20 5b31 5d20 4765  ...    .. [1] Ge
-00013170: 6e7a 2c20 412e 2028 3139 3834 292c 2054  nz, A. (1984), T
-00013180: 6573 7469 6e67 206d 756c 7469 6469 6d65  esting multidime
-00013190: 6e73 696f 6e61 6c20 696e 7465 6772 6174  nsional integrat
-000131a0: 696f 6e20 726f 7574 696e 6573 2e0d 0a20  ion routines... 
-000131b0: 2020 2020 2020 5072 6f63 2e20 6f66 2069        Proc. of i
-000131c0: 6e74 6572 6e61 7469 6f6e 616c 2063 6f6e  nternational con
-000131d0: 6665 7265 6e63 6520 6f6e 2054 6f6f 6c73  ference on Tools
-000131e0: 2c20 6d65 7468 6f64 7320 616e 6420 6c61  , methods and la
-000131f0: 6e67 7561 6765 7320 666f 7220 7363 6965  nguages for scie
-00013200: 6e74 6966 6963 0d0a 2020 2020 2020 2061  ntific..       a
-00013210: 6e64 2065 6e67 696e 6565 7269 6e67 2063  nd engineering c
-00013220: 6f6d 7075 7461 7469 6f6e 2c20 456c 7365  omputation, Else
-00013230: 7669 6572 204e 6f72 7468 2d48 6f6c 6c61  vier North-Holla
-00013240: 6e64 2c20 496e 632e 2c20 4e65 7759 6f72  nd, Inc., NewYor
-00013250: 6b2c 204e 592c 2055 5341 2c20 7070 2e20  k, NY, USA, pp. 
-00013260: 3831 2d39 342e 0d0a 0d0a 2020 2020 2e2e  81-94.....    ..
-00013270: 205b 325d 2068 7474 7073 3a2f 2f77 7777   [2] https://www
-00013280: 2e73 6675 2e63 612f 7e73 7375 726a 616e  .sfu.ca/~ssurjan
-00013290: 6f2f 6761 7573 7369 616e 2e68 746d 6c0d  o/gaussian.html.
-000132a0: 0a20 2020 2022 2222 0d0a 0d0a 2020 2020  .    """....    
-000132b0: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
-000132c0: 662c 206d 6174 6c61 625f 6d6f 6465 6c3d  f, matlab_model=
-000132d0: 4661 6c73 6529 3a0d 0a20 2020 2020 2020  False):..       
-000132e0: 2073 7570 6572 2874 7970 6528 7365 6c66   super(type(self
-000132f0: 292c 2073 656c 6629 2e5f 5f69 6e69 745f  ), self).__init_
-00013300: 5f28 6d61 746c 6162 5f6d 6f64 656c 3d6d  _(matlab_model=m
-00013310: 6174 6c61 625f 6d6f 6465 6c29 0d0a 2020  atlab_model)..  
-00013320: 2020 2020 2020 7365 6c66 2e66 6e61 6d65        self.fname
-00013330: 203d 2069 6e73 7065 6374 2e67 6574 6669   = inspect.getfi
-00013340: 6c65 2869 6e73 7065 6374 2e63 7572 7265  le(inspect.curre
-00013350: 6e74 6672 616d 6528 2929 0d0a 0d0a 2020  ntframe())....  
-00013360: 2020 6465 6620 7661 6c69 6461 7465 2873    def validate(s
-00013370: 656c 6629 3a0d 0a20 2020 2020 2020 2070  elf):..        p
-00013380: 6173 730d 0a0d 0a20 2020 2064 6566 2073  ass....    def s
-00013390: 696d 756c 6174 6528 7365 6c66 2c20 7072  imulate(self, pr
-000133a0: 6f63 6573 735f 6964 3d4e 6f6e 652c 206d  ocess_id=None, m
-000133b0: 6174 6c61 625f 656e 6769 6e65 3d4e 6f6e  atlab_engine=Non
-000133c0: 6529 3a0d 0a20 2020 2020 2020 206e 203d  e):..        n =
-000133d0: 206c 656e 2873 656c 662e 702e 6b65 7973   len(self.p.keys
-000133e0: 2829 290d 0a0d 0a20 2020 2020 2020 2023  ())....        #
-000133f0: 2073 6574 2063 6f6e 7374 616e 7473 0d0a   set constants..
-00013400: 2020 2020 2020 2020 7520 3d20 302e 3520          u = 0.5 
-00013410: 2a20 6e70 2e6f 6e65 7328 6e29 0d0a 2020  * np.ones(n)..  
-00013420: 2020 2020 2020 6120 3d20 3520 2a20 6e70        a = 5 * np
-00013430: 2e6f 6e65 7328 6e29 0d0a 0d0a 2020 2020  .ones(n)....    
-00013440: 2020 2020 2320 6465 7465 726d 696e 6520      # determine 
-00013450: 7375 6d0d 0a20 2020 2020 2020 2073 203d  sum..        s =
-00013460: 206e 702e 7a65 726f 7328 6e70 2e61 7272   np.zeros(np.arr
-00013470: 6179 2873 656c 662e 705b 6c69 7374 2873  ay(self.p[list(s
-00013480: 656c 662e 702e 6b65 7973 2829 295b 305d  elf.p.keys())[0]
-00013490: 5d29 2e73 697a 6529 0d0a 0d0a 2020 2020  ]).size)....    
-000134a0: 2020 2020 666f 7220 692c 206b 6579 2069      for i, key i
-000134b0: 6e20 656e 756d 6572 6174 6528 7365 6c66  n enumerate(self
-000134c0: 2e70 2e6b 6579 7328 2929 3a0d 0a20 2020  .p.keys()):..   
-000134d0: 2020 2020 2020 2020 2073 202b 3d20 615b           s += a[
-000134e0: 695d 202a 2a20 3220 2a20 2873 656c 662e  i] ** 2 * (self.
-000134f0: 705b 6b65 795d 202d 2075 5b69 5d29 202a  p[key] - u[i]) *
-00013500: 2a20 320d 0a0d 0a20 2020 2020 2020 2023  * 2....        #
-00013510: 2064 6574 6572 6d69 6e65 206f 7574 7075   determine outpu
-00013520: 740d 0a20 2020 2020 2020 2079 203d 206e  t..        y = n
-00013530: 702e 6578 7028 2d73 290d 0a0d 0a20 2020  p.exp(-s)....   
-00013540: 2020 2020 2079 5f6f 7574 203d 2079 5b3a       y_out = y[:
-00013550: 2c20 6e70 2e6e 6577 6178 6973 5d0d 0a0d  , np.newaxis]...
-00013560: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00013570: 795f 6f75 740d 0a0d 0a0d 0a63 6c61 7373  y_out......class
-00013580: 2047 656e 7a4f 7363 696c 6c61 746f 7279   GenzOscillatory
-00013590: 2841 6273 7472 6163 744d 6f64 656c 293a  (AbstractModel):
-000135a0: 0d0a 2020 2020 2222 220d 0a20 2020 204e  ..    """..    N
-000135b0: 2d64 696d 656e 7369 6f6e 616c 2022 4f73  -dimensional "Os
-000135c0: 6369 6c6c 6174 6f72 7922 2047 656e 7a20  cillatory" Genz 
-000135d0: 6675 6e63 7469 6f6e 205b 315d 2e20 4974  function [1]. It
-000135e0: 2069 7320 6465 6669 6e65 6420 696e 2074   is defined in t
-000135f0: 6865 2069 6e74 6572 7661 6c20 5b30 2c20  he interval [0, 
-00013600: 315d 2078 202e 2e2e 2078 205b 302c 2031  1] x ... x [0, 1
-00013610: 5d2e 0d0a 0d0a 2020 2020 2e2e 206d 6174  ].....    .. mat
-00013620: 683a 3a20 7920 3d20 5c5c 636f 7320 5c5c  h:: y = \\cos \\
-00013630: 6c65 6674 2820 3220 5c5c 7069 2075 5f31  left( 2 \\pi u_1
-00013640: 202b 205c 5c73 756d 5f7b 693d 317d 5e7b   + \\sum_{i=1}^{
-00013650: 4e7d 615f 6920 785f 6920 5c5c 7269 6768  N}a_i x_i \\righ
-00013660: 7429 0d0a 0d0a 2020 2020 5061 7261 6d65  t)....    Parame
-00013670: 7465 7273 0d0a 2020 2020 2d2d 2d2d 2d2d  ters..    ------
-00013680: 2d2d 2d2d 0d0a 2020 2020 705b 2278 3122  ----..    p["x1"
-00013690: 5d3a 2066 6c6f 6174 206f 7220 6e64 6172  ]: float or ndar
-000136a0: 7261 7920 6f66 2066 6c6f 6174 205b 6e5f  ray of float [n_
-000136b0: 6772 6964 5d0d 0a20 2020 2020 2020 2046  grid]..        F
-000136c0: 6972 7374 2070 6172 616d 6574 6572 2064  irst parameter d
-000136d0: 6566 696e 6564 2069 6e20 5b30 2c20 315d  efined in [0, 1]
-000136e0: 0d0a 2020 2020 705b 2278 6922 5d3a 2066  ..    p["xi"]: f
-000136f0: 6c6f 6174 206f 7220 6e64 6172 7261 7920  loat or ndarray 
-00013700: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
-00013710: 5d0d 0a20 2020 2020 2020 2069 2d74 6820  ]..        i-th 
-00013720: 7061 7261 6d65 7465 7220 6465 6669 6e65  parameter define
-00013730: 6420 696e 205b 302c 2031 5d0d 0a20 2020  d in [0, 1]..   
-00013740: 2070 5b22 784e 225d 3a20 666c 6f61 7420   p["xN"]: float 
-00013750: 6f72 206e 6461 7272 6179 206f 6620 666c  or ndarray of fl
-00013760: 6f61 7420 5b6e 5f67 7269 645d 0d0a 2020  oat [n_grid]..  
-00013770: 2020 2020 2020 4e74 6820 7061 7261 6d65        Nth parame
-00013780: 7465 7220 6465 6669 6e65 6420 696e 205b  ter defined in [
-00013790: 302c 2031 5d0d 0a0d 0a20 2020 2052 6574  0, 1]....    Ret
-000137a0: 7572 6e73 0d0a 2020 2020 2d2d 2d2d 2d2d  urns..    ------
-000137b0: 2d0d 0a20 2020 2079 3a20 6e64 6172 7261  -..    y: ndarra
-000137c0: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
-000137d0: 6964 2078 2031 5d0d 0a20 2020 2020 2020  id x 1]..       
-000137e0: 204f 7574 7075 740d 0a0d 0a20 2020 204e   Output....    N
-000137f0: 6f74 6573 0d0a 2020 2020 2d2d 2d2d 2d0d  otes..    -----.
-00013800: 0a20 2020 202e 2e20 706c 6f74 3a3a 0d0a  .    .. plot::..
-00013810: 0d0a 2020 2020 2020 2069 6d70 6f72 7420  ..       import 
-00013820: 6e75 6d70 7920 6173 206e 700d 0a20 2020  numpy as np..   
-00013830: 2020 2020 6672 6f6d 2070 7967 7063 2e74      from pygpc.t
-00013840: 6573 7466 756e 6374 696f 6e73 2069 6d70  estfunctions imp
-00013850: 6f72 7420 706c 6f74 5f74 6573 7466 756e  ort plot_testfun
-00013860: 6374 696f 6e20 6173 2070 6c6f 740d 0a20  ction as plot.. 
-00013870: 2020 2020 2020 6672 6f6d 2063 6f6c 6c65        from colle
-00013880: 6374 696f 6e73 2069 6d70 6f72 7420 4f72  ctions import Or
-00013890: 6465 7265 6444 6963 740d 0a0d 0a20 2020  deredDict....   
-000138a0: 2020 2020 7061 7261 6d65 7465 7273 203d      parameters =
-000138b0: 204f 7264 6572 6564 4469 6374 2829 0d0a   OrderedDict()..
-000138c0: 2020 2020 2020 2070 6172 616d 6574 6572         parameter
-000138d0: 735b 2278 3122 5d20 3d20 6e70 2e6c 696e  s["x1"] = np.lin
-000138e0: 7370 6163 6528 302c 2031 2c20 3130 3029  space(0, 1, 100)
-000138f0: 0d0a 2020 2020 2020 2070 6172 616d 6574  ..       paramet
-00013900: 6572 735b 2278 3222 5d20 3d20 6e70 2e6c  ers["x2"] = np.l
-00013910: 696e 7370 6163 6528 302c 2031 2c20 3130  inspace(0, 1, 10
-00013920: 3029 0d0a 0d0a 2020 2020 2020 2070 6c6f  0)....       plo
-00013930: 7428 2247 656e 7a4f 7363 696c 6c61 746f  t("GenzOscillato
-00013940: 7279 222c 2070 6172 616d 6574 6572 7329  ry", parameters)
-00013950: 0d0a 0d0a 2020 2020 2e2e 205b 315d 2047  ....    .. [1] G
-00013960: 656e 7a2c 2041 2e20 2831 3938 3429 2c20  enz, A. (1984), 
-00013970: 5465 7374 696e 6720 6d75 6c74 6964 696d  Testing multidim
-00013980: 656e 7369 6f6e 616c 2069 6e74 6567 7261  ensional integra
-00013990: 7469 6f6e 2072 6f75 7469 6e65 732e 0d0a  tion routines...
-000139a0: 2020 2020 2020 2050 726f 632e 206f 6620         Proc. of 
-000139b0: 696e 7465 726e 6174 696f 6e61 6c20 636f  international co
-000139c0: 6e66 6572 656e 6365 206f 6e20 546f 6f6c  nference on Tool
-000139d0: 732c 206d 6574 686f 6473 2061 6e64 206c  s, methods and l
-000139e0: 616e 6775 6167 6573 2066 6f72 2073 6369  anguages for sci
-000139f0: 656e 7469 6669 630d 0a20 2020 2020 2020  entific..       
-00013a00: 616e 6420 656e 6769 6e65 6572 696e 6720  and engineering 
-00013a10: 636f 6d70 7574 6174 696f 6e2c 2045 6c73  computation, Els
-00013a20: 6576 6965 7220 4e6f 7274 682d 486f 6c6c  evier North-Holl
-00013a30: 616e 642c 2049 6e63 2e2c 204e 6577 596f  and, Inc., NewYo
-00013a40: 726b 2c20 4e59 2c20 5553 412c 2070 702e  rk, NY, USA, pp.
-00013a50: 2038 312d 3934 2e0d 0a0d 0a20 2020 202e   81-94.....    .
-00013a60: 2e20 5b32 5d20 6874 7470 733a 2f2f 7777  . [2] https://ww
-00013a70: 772e 7366 752e 6361 2f7e 7373 7572 6a61  w.sfu.ca/~ssurja
-00013a80: 6e6f 2f6f 7363 696c 2e68 746d 6c0d 0a20  no/oscil.html.. 
-00013a90: 2020 2022 2222 0d0a 0d0a 2020 2020 6465     """....    de
-00013aa0: 6620 5f5f 696e 6974 5f5f 2873 656c 662c  f __init__(self,
-00013ab0: 206d 6174 6c61 625f 6d6f 6465 6c3d 4661   matlab_model=Fa
-00013ac0: 6c73 6529 3a0d 0a20 2020 2020 2020 2073  lse):..        s
-00013ad0: 7570 6572 2874 7970 6528 7365 6c66 292c  uper(type(self),
-00013ae0: 2073 656c 6629 2e5f 5f69 6e69 745f 5f28   self).__init__(
-00013af0: 6d61 746c 6162 5f6d 6f64 656c 3d6d 6174  matlab_model=mat
-00013b00: 6c61 625f 6d6f 6465 6c29 0d0a 2020 2020  lab_model)..    
-00013b10: 2020 2020 7365 6c66 2e66 6e61 6d65 203d      self.fname =
-00013b20: 2069 6e73 7065 6374 2e67 6574 6669 6c65   inspect.getfile
-00013b30: 2869 6e73 7065 6374 2e63 7572 7265 6e74  (inspect.current
-00013b40: 6672 616d 6528 2929 0d0a 0d0a 2020 2020  frame())....    
-00013b50: 6465 6620 7661 6c69 6461 7465 2873 656c  def validate(sel
-00013b60: 6629 3a0d 0a20 2020 2020 2020 2070 6173  f):..        pas
-00013b70: 730d 0a0d 0a20 2020 2064 6566 2073 696d  s....    def sim
-00013b80: 756c 6174 6528 7365 6c66 2c20 7072 6f63  ulate(self, proc
-00013b90: 6573 735f 6964 3d4e 6f6e 652c 206d 6174  ess_id=None, mat
-00013ba0: 6c61 625f 656e 6769 6e65 3d4e 6f6e 6529  lab_engine=None)
-00013bb0: 3a0d 0a20 2020 2020 2020 206e 203d 206c  :..        n = l
-00013bc0: 656e 2873 656c 662e 702e 6b65 7973 2829  en(self.p.keys()
-00013bd0: 290d 0a0d 0a20 2020 2020 2020 2023 2073  )....        # s
-00013be0: 6574 2063 6f6e 7374 616e 7473 0d0a 2020  et constants..  
-00013bf0: 2020 2020 2020 7520 3d20 302e 3520 2a20        u = 0.5 * 
-00013c00: 6e70 2e6f 6e65 7328 6e29 0d0a 2020 2020  np.ones(n)..    
-00013c10: 2020 2020 6120 3d20 3520 2a20 6e70 2e6f      a = 5 * np.o
-00013c20: 6e65 7328 6e29 0d0a 0d0a 2020 2020 2020  nes(n)....      
-00013c30: 2020 2320 6465 7465 726d 696e 6520 7375    # determine su
-00013c40: 6d0d 0a20 2020 2020 2020 2073 203d 206e  m..        s = n
-00013c50: 702e 7a65 726f 7328 6e70 2e61 7272 6179  p.zeros(np.array
-00013c60: 2873 656c 662e 705b 6c69 7374 2873 656c  (self.p[list(sel
-00013c70: 662e 702e 6b65 7973 2829 295b 305d 5d29  f.p.keys())[0]])
-00013c80: 2e73 697a 6529 0d0a 0d0a 2020 2020 2020  .size)....      
-00013c90: 2020 666f 7220 692c 206b 6579 2069 6e20    for i, key in 
-00013ca0: 656e 756d 6572 6174 6528 7365 6c66 2e70  enumerate(self.p
-00013cb0: 2e6b 6579 7328 2929 3a0d 0a20 2020 2020  .keys()):..     
-00013cc0: 2020 2020 2020 2073 202b 3d20 615b 695d         s += a[i]
-00013cd0: 202a 2073 656c 662e 705b 6b65 795d 0d0a   * self.p[key]..
-00013ce0: 0d0a 2020 2020 2020 2020 2320 6465 7465  ..        # dete
-00013cf0: 726d 696e 6520 6f75 7470 7574 0d0a 2020  rmine output..  
-00013d00: 2020 2020 2020 7920 3d20 6e70 2e63 6f73        y = np.cos
-00013d10: 2832 202a 206e 702e 7069 202a 2075 5b30  (2 * np.pi * u[0
-00013d20: 5d20 2b20 7329 0d0a 0d0a 2020 2020 2020  ] + s)....      
-00013d30: 2020 795f 6f75 7420 3d20 795b 3a2c 206e    y_out = y[:, n
-00013d40: 702e 6e65 7761 7869 735d 0d0a 0d0a 2020  p.newaxis]....  
-00013d50: 2020 2020 2020 2320 795f 6f75 7420 3d20        # y_out = 
-00013d60: 6e70 2e68 7374 6163 6b28 2879 5f6f 7574  np.hstack((y_out
-00013d70: 2c20 322a 795f 6f75 7429 290d 0a0d 0a20  , 2*y_out)).... 
-00013d80: 2020 2020 2020 2072 6574 7572 6e20 795f         return y_
-00013d90: 6f75 740d 0a0d 0a0d 0a63 6c61 7373 2047  out......class G
-00013da0: 656e 7a4f 7363 696c 6c61 746f 7279 5f4e  enzOscillatory_N
-00013db0: 614e 2841 6273 7472 6163 744d 6f64 656c  aN(AbstractModel
-00013dc0: 293a 0d0a 2020 2020 2222 220d 0a20 2020  ):..    """..   
-00013dd0: 204e 2d64 696d 656e 7369 6f6e 616c 2022   N-dimensional "
-00013de0: 4f73 6369 6c6c 6174 6f72 7922 2047 656e  Oscillatory" Gen
-00013df0: 7a20 6675 6e63 7469 6f6e 205b 315d 2e20  z function [1]. 
-00013e00: 4974 2069 7320 6465 6669 6e65 6420 696e  It is defined in
-00013e10: 2074 6865 2069 6e74 6572 7661 6c20 5b30   the interval [0
-00013e20: 2c20 315d 2078 202e 2e2e 2078 205b 302c  , 1] x ... x [0,
-00013e30: 2031 5d2e 0d0a 0d0a 2020 2020 2e2e 206d   1].....    .. m
-00013e40: 6174 683a 3a20 7920 3d20 5c5c 636f 7320  ath:: y = \\cos 
-00013e50: 5c5c 6c65 6674 2820 3220 5c5c 7069 2075  \\left( 2 \\pi u
-00013e60: 5f31 202b 205c 5c73 756d 5f7b 693d 317d  _1 + \\sum_{i=1}
-00013e70: 5e7b 4e7d 615f 6920 785f 6920 5c5c 7269  ^{N}a_i x_i \\ri
-00013e80: 6768 7429 0d0a 0d0a 2020 2020 5061 7261  ght)....    Para
-00013e90: 6d65 7465 7273 0d0a 2020 2020 2d2d 2d2d  meters..    ----
-00013ea0: 2d2d 2d2d 2d2d 0d0a 2020 2020 705b 2278  ------..    p["x
-00013eb0: 3122 5d3a 2066 6c6f 6174 206f 7220 6e64  1"]: float or nd
-00013ec0: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
-00013ed0: 6e5f 6772 6964 5d0d 0a20 2020 2020 2020  n_grid]..       
-00013ee0: 2046 6972 7374 2070 6172 616d 6574 6572   First parameter
-00013ef0: 2064 6566 696e 6564 2069 6e20 5b30 2c20   defined in [0, 
-00013f00: 315d 0d0a 2020 2020 705b 2278 6922 5d3a  1]..    p["xi"]:
-00013f10: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
-00013f20: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
-00013f30: 6964 5d0d 0a20 2020 2020 2020 2069 2d74  id]..        i-t
-00013f40: 6820 7061 7261 6d65 7465 7220 6465 6669  h parameter defi
-00013f50: 6e65 6420 696e 205b 302c 2031 5d0d 0a20  ned in [0, 1].. 
-00013f60: 2020 2070 5b22 784e 225d 3a20 666c 6f61     p["xN"]: floa
-00013f70: 7420 6f72 206e 6461 7272 6179 206f 6620  t or ndarray of 
-00013f80: 666c 6f61 7420 5b6e 5f67 7269 645d 0d0a  float [n_grid]..
-00013f90: 2020 2020 2020 2020 4e74 6820 7061 7261          Nth para
-00013fa0: 6d65 7465 7220 6465 6669 6e65 6420 696e  meter defined in
-00013fb0: 205b 302c 2031 5d0d 0a0d 0a20 2020 2052   [0, 1]....    R
-00013fc0: 6574 7572 6e73 0d0a 2020 2020 2d2d 2d2d  eturns..    ----
-00013fd0: 2d2d 2d0d 0a20 2020 2079 3a20 6e64 6172  ---..    y: ndar
-00013fe0: 7261 7920 6f66 2066 6c6f 6174 205b 6e5f  ray of float [n_
-00013ff0: 6772 6964 2078 2031 5d0d 0a20 2020 2020  grid x 1]..     
-00014000: 2020 204f 7574 7075 740d 0a0d 0a20 2020     Output....   
-00014010: 204e 6f74 6573 0d0a 2020 2020 2d2d 2d2d   Notes..    ----
-00014020: 2d0d 0a20 2020 202e 2e20 706c 6f74 3a3a  -..    .. plot::
-00014030: 0d0a 0d0a 2020 2020 2020 2069 6d70 6f72  ....       impor
-00014040: 7420 6e75 6d70 7920 6173 206e 700d 0a20  t numpy as np.. 
-00014050: 2020 2020 2020 6672 6f6d 2070 7967 7063        from pygpc
-00014060: 2e74 6573 7466 756e 6374 696f 6e73 2069  .testfunctions i
-00014070: 6d70 6f72 7420 706c 6f74 5f74 6573 7466  mport plot_testf
-00014080: 756e 6374 696f 6e20 6173 2070 6c6f 740d  unction as plot.
-00014090: 0a20 2020 2020 2020 6672 6f6d 2063 6f6c  .       from col
-000140a0: 6c65 6374 696f 6e73 2069 6d70 6f72 7420  lections import 
-000140b0: 4f72 6465 7265 6444 6963 740d 0a0d 0a20  OrderedDict.... 
-000140c0: 2020 2020 2020 7061 7261 6d65 7465 7273        parameters
-000140d0: 203d 204f 7264 6572 6564 4469 6374 2829   = OrderedDict()
-000140e0: 0d0a 2020 2020 2020 2070 6172 616d 6574  ..       paramet
-000140f0: 6572 735b 2278 3122 5d20 3d20 6e70 2e6c  ers["x1"] = np.l
-00014100: 696e 7370 6163 6528 302c 2031 2c20 3130  inspace(0, 1, 10
-00014110: 3029 0d0a 2020 2020 2020 2070 6172 616d  0)..       param
-00014120: 6574 6572 735b 2278 3222 5d20 3d20 6e70  eters["x2"] = np
-00014130: 2e6c 696e 7370 6163 6528 302c 2031 2c20  .linspace(0, 1, 
-00014140: 3130 3029 0d0a 0d0a 2020 2020 2020 2070  100)....       p
-00014150: 6c6f 7428 2247 656e 7a4f 7363 696c 6c61  lot("GenzOscilla
-00014160: 746f 7279 222c 2070 6172 616d 6574 6572  tory", parameter
-00014170: 7329 0d0a 0d0a 2020 2020 2e2e 205b 315d  s)....    .. [1]
-00014180: 2047 656e 7a2c 2041 2e20 2831 3938 3429   Genz, A. (1984)
-00014190: 2c20 5465 7374 696e 6720 6d75 6c74 6964  , Testing multid
-000141a0: 696d 656e 7369 6f6e 616c 2069 6e74 6567  imensional integ
-000141b0: 7261 7469 6f6e 2072 6f75 7469 6e65 732e  ration routines.
-000141c0: 0d0a 2020 2020 2020 2050 726f 632e 206f  ..       Proc. o
-000141d0: 6620 696e 7465 726e 6174 696f 6e61 6c20  f international 
-000141e0: 636f 6e66 6572 656e 6365 206f 6e20 546f  conference on To
-000141f0: 6f6c 732c 206d 6574 686f 6473 2061 6e64  ols, methods and
-00014200: 206c 616e 6775 6167 6573 2066 6f72 2073   languages for s
-00014210: 6369 656e 7469 6669 630d 0a20 2020 2020  cientific..     
-00014220: 2020 616e 6420 656e 6769 6e65 6572 696e    and engineerin
-00014230: 6720 636f 6d70 7574 6174 696f 6e2c 2045  g computation, E
-00014240: 6c73 6576 6965 7220 4e6f 7274 682d 486f  lsevier North-Ho
-00014250: 6c6c 616e 642c 2049 6e63 2e2c 204e 6577  lland, Inc., New
-00014260: 596f 726b 2c20 4e59 2c20 5553 412c 2070  York, NY, USA, p
-00014270: 702e 2038 312d 3934 2e0d 0a0d 0a20 2020  p. 81-94.....   
-00014280: 202e 2e20 5b32 5d20 6874 7470 733a 2f2f   .. [2] https://
-00014290: 7777 772e 7366 752e 6361 2f7e 7373 7572  www.sfu.ca/~ssur
-000142a0: 6a61 6e6f 2f6f 7363 696c 2e68 746d 6c0d  jano/oscil.html.
-000142b0: 0a20 2020 2022 2222 0d0a 0d0a 2020 2020  .    """....    
-000142c0: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
-000142d0: 662c 206d 6174 6c61 625f 6d6f 6465 6c3d  f, matlab_model=
-000142e0: 4661 6c73 6529 3a0d 0a20 2020 2020 2020  False):..       
-000142f0: 2073 7570 6572 2874 7970 6528 7365 6c66   super(type(self
-00014300: 292c 2073 656c 6629 2e5f 5f69 6e69 745f  ), self).__init_
-00014310: 5f28 6d61 746c 6162 5f6d 6f64 656c 3d6d  _(matlab_model=m
-00014320: 6174 6c61 625f 6d6f 6465 6c29 0d0a 2020  atlab_model)..  
-00014330: 2020 2020 2020 7365 6c66 2e66 6e61 6d65        self.fname
-00014340: 203d 2069 6e73 7065 6374 2e67 6574 6669   = inspect.getfi
-00014350: 6c65 2869 6e73 7065 6374 2e63 7572 7265  le(inspect.curre
-00014360: 6e74 6672 616d 6528 2929 0d0a 0d0a 2020  ntframe())....  
-00014370: 2020 6465 6620 7661 6c69 6461 7465 2873    def validate(s
-00014380: 656c 6629 3a0d 0a20 2020 2020 2020 2070  elf):..        p
-00014390: 6173 730d 0a0d 0a20 2020 2064 6566 2073  ass....    def s
-000143a0: 696d 756c 6174 6528 7365 6c66 2c20 7072  imulate(self, pr
-000143b0: 6f63 6573 735f 6964 3d4e 6f6e 652c 206d  ocess_id=None, m
-000143c0: 6174 6c61 625f 656e 6769 6e65 3d4e 6f6e  atlab_engine=Non
-000143d0: 6529 3a0d 0a20 2020 2020 2020 206e 203d  e):..        n =
-000143e0: 206c 656e 2873 656c 662e 702e 6b65 7973   len(self.p.keys
-000143f0: 2829 290d 0a0d 0a20 2020 2020 2020 2023  ())....        #
-00014400: 2073 6574 2063 6f6e 7374 616e 7473 0d0a   set constants..
-00014410: 2020 2020 2020 2020 7520 3d20 302e 3520          u = 0.5 
-00014420: 2a20 6e70 2e6f 6e65 7328 6e29 0d0a 2020  * np.ones(n)..  
-00014430: 2020 2020 2020 6120 3d20 3520 2a20 6e70        a = 5 * np
-00014440: 2e6f 6e65 7328 6e29 0d0a 0d0a 2020 2020  .ones(n)....    
-00014450: 2020 2020 2320 6465 7465 726d 696e 6520      # determine 
-00014460: 7375 6d0d 0a20 2020 2020 2020 2073 203d  sum..        s =
-00014470: 206e 702e 7a65 726f 7328 6e70 2e61 7272   np.zeros(np.arr
-00014480: 6179 2873 656c 662e 705b 6c69 7374 2873  ay(self.p[list(s
-00014490: 656c 662e 702e 6b65 7973 2829 295b 305d  elf.p.keys())[0]
-000144a0: 5d29 2e73 697a 6529 0d0a 0d0a 2020 2020  ]).size)....    
-000144b0: 2020 2020 666f 7220 692c 206b 6579 2069      for i, key i
-000144c0: 6e20 656e 756d 6572 6174 6528 7365 6c66  n enumerate(self
-000144d0: 2e70 2e6b 6579 7328 2929 3a0d 0a20 2020  .p.keys()):..   
-000144e0: 2020 2020 2020 2020 2073 202b 3d20 615b           s += a[
-000144f0: 695d 202a 2073 656c 662e 705b 6b65 795d  i] * self.p[key]
-00014500: 0d0a 0d0a 2020 2020 2020 2020 2320 6465  ....        # de
-00014510: 7465 726d 696e 6520 6f75 7470 7574 0d0a  termine output..
-00014520: 2020 2020 2020 2020 7920 3d20 6e70 2e63          y = np.c
-00014530: 6f73 2832 202a 206e 702e 7069 202a 2075  os(2 * np.pi * u
-00014540: 5b30 5d20 2b20 7329 0d0a 0d0a 2020 2020  [0] + s)....    
-00014550: 2020 2020 795f 6f75 7420 3d20 795b 3a2c      y_out = y[:,
-00014560: 206e 702e 6e65 7761 7869 735d 0d0a 0d0a   np.newaxis]....
-00014570: 2020 2020 2020 2020 2320 696e 7365 7274          # insert
-00014580: 2073 6f6d 6520 4e61 4e20 7661 6c75 6573   some NaN values
-00014590: 2066 6f72 2074 6573 7469 6e67 0d0a 2020   for testing..  
-000145a0: 2020 2020 2020 6d61 736b 203d 2073 656c        mask = sel
-000145b0: 662e 705b 6c69 7374 2873 656c 662e 702e  f.p[list(self.p.
-000145c0: 6b65 7973 2829 295b 305d 5d20 3e20 302e  keys())[0]] > 0.
-000145d0: 380d 0a20 2020 2020 2020 2079 5f6f 7574  8..        y_out
-000145e0: 5b6d 6173 6b2c 2030 5d20 3d20 6e70 2e4e  [mask, 0] = np.N
-000145f0: 614e 0d0a 0d0a 2020 2020 2020 2020 7265  aN....        re
-00014600: 7475 726e 2079 5f6f 7574 0d0a 0d0a 0d0a  turn y_out......
-00014610: 636c 6173 7320 4765 6e7a 5072 6f64 7563  class GenzProduc
-00014620: 7450 6561 6b28 4162 7374 7261 6374 4d6f  tPeak(AbstractMo
-00014630: 6465 6c29 3a0d 0a20 2020 2022 2222 0d0a  del):..    """..
-00014640: 2020 2020 4e2d 6469 6d65 6e73 696f 6e61      N-dimensiona
-00014650: 6c20 2250 726f 6475 6374 5065 616b 2220  l "ProductPeak" 
-00014660: 4765 6e7a 2066 756e 6374 696f 6e20 5b31  Genz function [1
-00014670: 5d2e 2049 7420 6973 2064 6566 696e 6564  ]. It is defined
-00014680: 2069 6e20 7468 6520 696e 7465 7276 616c   in the interval
-00014690: 205b 302c 2031 5d20 7820 2e2e 2e20 7820   [0, 1] x ... x 
-000146a0: 5b30 2c20 315d 2e0d 0a0d 0a20 2020 202e  [0, 1].....    .
-000146b0: 2e20 6d61 7468 3a3a 2079 203d 205c 7072  . math:: y = \pr
-000146c0: 6f64 5f7b 693d 317d 5e7b 4e7d 205c 5c6c  od_{i=1}^{N} \\l
-000146d0: 6566 7428 2061 5f69 5e7b 2d32 7d20 2b20  eft( a_i^{-2} + 
-000146e0: 2878 5f69 202d 2075 5f69 295e 3220 5c5c  (x_i - u_i)^2 \\
-000146f0: 7269 6768 7429 5e7b 2d31 7d0d 0a0d 0a20  right)^{-1}.... 
-00014700: 2020 2050 6172 616d 6574 6572 730d 0a20     Parameters.. 
-00014710: 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0d 0a20     ----------.. 
-00014720: 2020 2070 5b22 7831 225d 3a20 666c 6f61     p["x1"]: floa
-00014730: 7420 6f72 206e 6461 7272 6179 206f 6620  t or ndarray of 
-00014740: 666c 6f61 7420 5b6e 5f67 7269 645d 0d0a  float [n_grid]..
-00014750: 2020 2020 2020 2020 4669 7273 7420 7061          First pa
-00014760: 7261 6d65 7465 7220 6465 6669 6e65 6420  rameter defined 
-00014770: 696e 205b 302c 2031 5d0d 0a20 2020 2070  in [0, 1]..    p
-00014780: 5b22 7869 225d 3a20 666c 6f61 7420 6f72  ["xi"]: float or
-00014790: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-000147a0: 7420 5b6e 5f67 7269 645d 0d0a 2020 2020  t [n_grid]..    
-000147b0: 2020 2020 692d 7468 2070 6172 616d 6574      i-th paramet
-000147c0: 6572 2064 6566 696e 6564 2069 6e20 5b30  er defined in [0
-000147d0: 2c20 315d 0d0a 2020 2020 705b 2278 4e22  , 1]..    p["xN"
-000147e0: 5d3a 2066 6c6f 6174 206f 7220 6e64 6172  ]: float or ndar
-000147f0: 7261 7920 6f66 2066 6c6f 6174 205b 6e5f  ray of float [n_
-00014800: 6772 6964 5d0d 0a20 2020 2020 2020 204e  grid]..        N
-00014810: 7468 2070 6172 616d 6574 6572 2064 6566  th parameter def
-00014820: 696e 6564 2069 6e20 5b30 2c20 315d 0d0a  ined in [0, 1]..
-00014830: 0d0a 2020 2020 5265 7475 726e 730d 0a20  ..    Returns.. 
-00014840: 2020 202d 2d2d 2d2d 2d2d 0d0a 2020 2020     -------..    
-00014850: 793a 206e 6461 7272 6179 206f 6620 666c  y: ndarray of fl
-00014860: 6f61 7420 5b6e 5f67 7269 6420 7820 315d  oat [n_grid x 1]
-00014870: 0d0a 2020 2020 2020 2020 4f75 7470 7574  ..        Output
-00014880: 0d0a 0d0a 2020 2020 4e6f 7465 730d 0a20  ....    Notes.. 
-00014890: 2020 202d 2d2d 2d2d 0d0a 2020 2020 2e2e     -----..    ..
-000148a0: 2070 6c6f 743a 3a0d 0a0d 0a20 2020 2020   plot::....     
-000148b0: 2020 696d 706f 7274 206e 756d 7079 2061    import numpy a
-000148c0: 7320 6e70 0d0a 2020 2020 2020 2066 726f  s np..       fro
-000148d0: 6d20 7079 6770 632e 7465 7374 6675 6e63  m pygpc.testfunc
-000148e0: 7469 6f6e 7320 696d 706f 7274 2070 6c6f  tions import plo
-000148f0: 745f 7465 7374 6675 6e63 7469 6f6e 2061  t_testfunction a
-00014900: 7320 706c 6f74 0d0a 2020 2020 2020 2066  s plot..       f
-00014910: 726f 6d20 636f 6c6c 6563 7469 6f6e 7320  rom collections 
-00014920: 696d 706f 7274 204f 7264 6572 6564 4469  import OrderedDi
-00014930: 6374 0d0a 0d0a 2020 2020 2020 2070 6172  ct....       par
-00014940: 616d 6574 6572 7320 3d20 4f72 6465 7265  ameters = Ordere
-00014950: 6444 6963 7428 290d 0a20 2020 2020 2020  dDict()..       
-00014960: 7061 7261 6d65 7465 7273 5b22 7831 225d  parameters["x1"]
-00014970: 203d 206e 702e 6c69 6e73 7061 6365 2830   = np.linspace(0
-00014980: 2c20 312c 2031 3030 290d 0a20 2020 2020  , 1, 100)..     
-00014990: 2020 7061 7261 6d65 7465 7273 5b22 7832    parameters["x2
-000149a0: 225d 203d 206e 702e 6c69 6e73 7061 6365  "] = np.linspace
-000149b0: 2830 2c20 312c 2031 3030 290d 0a0d 0a20  (0, 1, 100).... 
-000149c0: 2020 2020 2020 706c 6f74 2822 4765 6e7a        plot("Genz
-000149d0: 5072 6f64 7563 7450 6561 6b22 2c20 7061  ProductPeak", pa
-000149e0: 7261 6d65 7465 7273 290d 0a0d 0a20 2020  rameters)....   
-000149f0: 202e 2e20 5b31 5d20 4765 6e7a 2c20 412e   .. [1] Genz, A.
-00014a00: 2028 3139 3834 292c 2054 6573 7469 6e67   (1984), Testing
-00014a10: 206d 756c 7469 6469 6d65 6e73 696f 6e61   multidimensiona
-00014a20: 6c20 696e 7465 6772 6174 696f 6e20 726f  l integration ro
-00014a30: 7574 696e 6573 2e0d 0a20 2020 2020 2020  utines...       
-00014a40: 5072 6f63 2e20 6f66 2069 6e74 6572 6e61  Proc. of interna
-00014a50: 7469 6f6e 616c 2063 6f6e 6665 7265 6e63  tional conferenc
-00014a60: 6520 6f6e 2054 6f6f 6c73 2c20 6d65 7468  e on Tools, meth
-00014a70: 6f64 7320 616e 6420 6c61 6e67 7561 6765  ods and language
-00014a80: 7320 666f 7220 7363 6965 6e74 6966 6963  s for scientific
-00014a90: 0d0a 2020 2020 2020 2061 6e64 2065 6e67  ..       and eng
-00014aa0: 696e 6565 7269 6e67 2063 6f6d 7075 7461  ineering computa
-00014ab0: 7469 6f6e 2c20 456c 7365 7669 6572 204e  tion, Elsevier N
-00014ac0: 6f72 7468 2d48 6f6c 6c61 6e64 2c20 496e  orth-Holland, In
-00014ad0: 632e 2c20 4e65 7759 6f72 6b2c 204e 592c  c., NewYork, NY,
-00014ae0: 2055 5341 2c20 7070 2e20 3831 2d39 342e   USA, pp. 81-94.
-00014af0: 0d0a 0d0a 2020 2020 2e2e 205b 325d 2068  ....    .. [2] h
-00014b00: 7474 7073 3a2f 2f77 7777 2e73 6675 2e63  ttps://www.sfu.c
-00014b10: 612f 7e73 7375 726a 616e 6f2f 7072 7065  a/~ssurjano/prpe
-00014b20: 616b 2e68 746d 6c0d 0a20 2020 2022 2222  ak.html..    """
-00014b30: 0d0a 0d0a 2020 2020 6465 6620 5f5f 696e  ....    def __in
-00014b40: 6974 5f5f 2873 656c 662c 206d 6174 6c61  it__(self, matla
-00014b50: 625f 6d6f 6465 6c3d 4661 6c73 6529 3a0d  b_model=False):.
-00014b60: 0a20 2020 2020 2020 2073 7570 6572 2874  .        super(t
-00014b70: 7970 6528 7365 6c66 292c 2073 656c 6629  ype(self), self)
-00014b80: 2e5f 5f69 6e69 745f 5f28 6d61 746c 6162  .__init__(matlab
-00014b90: 5f6d 6f64 656c 3d6d 6174 6c61 625f 6d6f  _model=matlab_mo
-00014ba0: 6465 6c29 0d0a 2020 2020 2020 2020 7365  del)..        se
-00014bb0: 6c66 2e66 6e61 6d65 203d 2069 6e73 7065  lf.fname = inspe
-00014bc0: 6374 2e67 6574 6669 6c65 2869 6e73 7065  ct.getfile(inspe
-00014bd0: 6374 2e63 7572 7265 6e74 6672 616d 6528  ct.currentframe(
-00014be0: 2929 0d0a 0d0a 2020 2020 6465 6620 7661  ))....    def va
-00014bf0: 6c69 6461 7465 2873 656c 6629 3a0d 0a20  lidate(self):.. 
-00014c00: 2020 2020 2020 2070 6173 730d 0a0d 0a20         pass.... 
-00014c10: 2020 2064 6566 2073 696d 756c 6174 6528     def simulate(
-00014c20: 7365 6c66 2c20 7072 6f63 6573 735f 6964  self, process_id
-00014c30: 3d4e 6f6e 652c 206d 6174 6c61 625f 656e  =None, matlab_en
-00014c40: 6769 6e65 3d4e 6f6e 6529 3a0d 0a20 2020  gine=None):..   
-00014c50: 2020 2020 206e 203d 206c 656e 2873 656c       n = len(sel
-00014c60: 662e 702e 6b65 7973 2829 290d 0a0d 0a20  f.p.keys()).... 
-00014c70: 2020 2020 2020 2023 2073 6574 2063 6f6e         # set con
-00014c80: 7374 616e 7473 0d0a 2020 2020 2020 2020  stants..        
-00014c90: 7520 3d20 302e 3520 2a20 6e70 2e6f 6e65  u = 0.5 * np.one
-00014ca0: 7328 6e29 0d0a 2020 2020 2020 2020 6120  s(n)..        a 
-00014cb0: 3d20 3520 2a20 6e70 2e6f 6e65 7328 6e29  = 5 * np.ones(n)
-00014cc0: 0d0a 0d0a 2020 2020 2020 2020 2320 6465  ....        # de
-00014cd0: 7465 726d 696e 6520 6f75 7470 7574 0d0a  termine output..
-00014ce0: 2020 2020 2020 2020 7920 3d20 6e70 2e6f          y = np.o
-00014cf0: 6e65 7328 6e70 2e61 7272 6179 2873 656c  nes(np.array(sel
-00014d00: 662e 705b 6c69 7374 2873 656c 662e 702e  f.p[list(self.p.
-00014d10: 6b65 7973 2829 295b 305d 5d29 2e73 697a  keys())[0]]).siz
-00014d20: 6529 0d0a 0d0a 2020 2020 2020 2020 666f  e)....        fo
-00014d30: 7220 692c 206b 6579 2069 6e20 656e 756d  r i, key in enum
-00014d40: 6572 6174 6528 7365 6c66 2e70 2e6b 6579  erate(self.p.key
-00014d50: 7328 2929 3a0d 0a20 2020 2020 2020 2020  s()):..         
-00014d60: 2020 2079 202a 3d20 3120 2f20 2861 5b69     y *= 1 / (a[i
-00014d70: 5d20 2a2a 2028 2d32 2920 2b20 2873 656c  ] ** (-2) + (sel
-00014d80: 662e 705b 6b65 795d 202d 2075 5b69 5d29  f.p[key] - u[i])
-00014d90: 202a 2a20 3229 0d0a 0d0a 2020 2020 2020   ** 2)....      
-00014da0: 2020 795f 6f75 7420 3d20 795b 3a2c 206e    y_out = y[:, n
-00014db0: 702e 6e65 7761 7869 735d 0d0a 0d0a 2020  p.newaxis]....  
-00014dc0: 2020 2020 2020 7265 7475 726e 2079 5f6f        return y_o
-00014dd0: 7574 0d0a 0d0a 0d0a 636c 6173 7320 5269  ut......class Ri
-00014de0: 6467 6528 4162 7374 7261 6374 4d6f 6465  dge(AbstractMode
-00014df0: 6c29 3a0d 0a20 2020 2022 2222 0d0a 2020  l):..    """..  
-00014e00: 2020 4e2d 6469 6d65 6e73 696f 6e61 6c20    N-dimensional 
-00014e10: 2252 6964 6765 2220 6675 6e63 7469 6f6e  "Ridge" function
-00014e20: 205b 315d 2028 616e 6420 616c 736f 2075   [1] (and also u
-00014e30: 7365 6420 6173 2074 6573 7466 756e 6374  sed as testfunct
-00014e40: 696f 6e20 7468 6572 6569 6e29 2e0d 0a20  ion therein)... 
-00014e50: 2020 2054 7970 6963 616c 6c79 2064 6566     Typically def
-00014e60: 696e 6564 2069 6e20 7468 6520 696e 7465  ined in the inte
-00014e70: 7276 616c 205b 2d34 2c20 345d 2078 202e  rval [-4, 4] x .
-00014e80: 2e2e 2078 205b 2d34 2c20 345d 2e0d 0a0d  .. x [-4, 4]....
-00014e90: 0a20 2020 202e 2e20 6d61 7468 3a3a 0d0a  .    .. math::..
-00014ea0: 2020 2020 2020 2079 203d 205c 7375 6d5f         y = \sum_
-00014eb0: 7b69 3d31 7d5e 7b4e 7d78 5f69 202b 2030  {i=1}^{N}x_i + 0
-00014ec0: 2e32 3520 5c5c 6c65 6674 2820 5c73 756d  .25 \\left( \sum
-00014ed0: 5f7b 693d 317d 5e7b 4e7d 785f 6920 5c5c  _{i=1}^{N}x_i \\
-00014ee0: 7269 6768 7429 5e32 202b 2030 2e30 3235  right)^2 + 0.025
-00014ef0: 205c 5c6c 6566 7428 205c 7375 6d5f 7b69   \\left( \sum_{i
-00014f00: 3d31 7d5e 7b4e 7d78 5f69 205c 5c72 6967  =1}^{N}x_i \\rig
-00014f10: 6874 295e 330d 0a0d 0a20 2020 2050 6172  ht)^3....    Par
-00014f20: 616d 6574 6572 730d 0a20 2020 202d 2d2d  ameters..    ---
-00014f30: 2d2d 2d2d 2d2d 2d0d 0a20 2020 2070 5b22  -------..    p["
-00014f40: 7831 225d 3a20 666c 6f61 7420 6f72 206e  x1"]: float or n
-00014f50: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-00014f60: 5b6e 5f67 7269 645d 0d0a 2020 2020 2020  [n_grid]..      
-00014f70: 2020 4669 7273 7420 7061 7261 6d65 7465    First paramete
-00014f80: 7220 6465 6669 6e65 6420 696e 2065 2e67  r defined in e.g
-00014f90: 2e20 5b2d 342c 2034 5d0d 0a20 2020 2070  . [-4, 4]..    p
-00014fa0: 5b22 7869 225d 3a20 666c 6f61 7420 6f72  ["xi"]: float or
-00014fb0: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-00014fc0: 7420 5b6e 5f67 7269 645d 0d0a 2020 2020  t [n_grid]..    
-00014fd0: 2020 2020 692d 7468 2070 6172 616d 6574      i-th paramet
-00014fe0: 6572 2064 6566 696e 6564 2069 6e20 652e  er defined in e.
-00014ff0: 672e 205b 2d34 2c20 345d 0d0a 2020 2020  g. [-4, 4]..    
-00015000: 705b 2278 4e22 5d3a 2066 6c6f 6174 206f  p["xN"]: float o
-00015010: 7220 6e64 6172 7261 7920 6f66 2066 6c6f  r ndarray of flo
-00015020: 6174 205b 6e5f 6772 6964 5d0d 0a20 2020  at [n_grid]..   
-00015030: 2020 2020 204e 7468 2070 6172 616d 6574       Nth paramet
-00015040: 6572 2064 6566 696e 6564 2069 6e20 652e  er defined in e.
-00015050: 672e 205b 2d34 2c20 345d 0d0a 0d0a 2020  g. [-4, 4]....  
-00015060: 2020 5265 7475 726e 730d 0a20 2020 202d    Returns..    -
-00015070: 2d2d 2d2d 2d2d 0d0a 2020 2020 793a 206e  ------..    y: n
-00015080: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-00015090: 5b6e 5f67 7269 6420 7820 315d 0d0a 2020  [n_grid x 1]..  
-000150a0: 2020 2020 2020 4f75 7470 7574 0d0a 0d0a        Output....
-000150b0: 2020 2020 4e6f 7465 730d 0a20 2020 202d      Notes..    -
-000150c0: 2d2d 2d2d 0d0a 2020 2020 2e2e 2070 6c6f  ----..    .. plo
-000150d0: 743a 3a0d 0a0d 0a20 2020 2020 2020 696d  t::....       im
-000150e0: 706f 7274 206e 756d 7079 2061 7320 6e70  port numpy as np
-000150f0: 0d0a 2020 2020 2020 2066 726f 6d20 7079  ..       from py
-00015100: 6770 632e 7465 7374 6675 6e63 7469 6f6e  gpc.testfunction
-00015110: 7320 696d 706f 7274 2070 6c6f 745f 7465  s import plot_te
-00015120: 7374 6675 6e63 7469 6f6e 2061 7320 706c  stfunction as pl
-00015130: 6f74 0d0a 2020 2020 2020 2066 726f 6d20  ot..       from 
-00015140: 636f 6c6c 6563 7469 6f6e 7320 696d 706f  collections impo
-00015150: 7274 204f 7264 6572 6564 4469 6374 0d0a  rt OrderedDict..
-00015160: 0d0a 2020 2020 2020 2070 6172 616d 6574  ..       paramet
-00015170: 6572 7320 3d20 4f72 6465 7265 6444 6963  ers = OrderedDic
-00015180: 7428 290d 0a20 2020 2020 2020 7061 7261  t()..       para
-00015190: 6d65 7465 7273 5b22 7831 225d 203d 206e  meters["x1"] = n
-000151a0: 702e 6c69 6e73 7061 6365 282d 342c 2034  p.linspace(-4, 4
-000151b0: 2c20 3130 3029 0d0a 2020 2020 2020 2070  , 100)..       p
-000151c0: 6172 616d 6574 6572 735b 2278 3222 5d20  arameters["x2"] 
-000151d0: 3d20 6e70 2e6c 696e 7370 6163 6528 2d34  = np.linspace(-4
-000151e0: 2c20 342c 2031 3030 290d 0a0d 0a20 2020  , 4, 100)....   
-000151f0: 2020 2020 706c 6f74 2822 5269 6467 6522      plot("Ridge"
-00015200: 2c20 7061 7261 6d65 7465 7273 290d 0a0d  , parameters)...
-00015210: 0a20 2020 202e 2e20 5b31 5d20 5473 696c  .    .. [1] Tsil
-00015220: 6966 6973 2c20 502e 2c20 4875 616e 2c20  ifis, P., Huan, 
-00015230: 582e 2c20 5361 6674 612c 2043 2e2c 2053  X., Safta, C., S
-00015240: 6172 6773 7961 6e2c 204b 2e2c 204c 6163  argsyan, K., Lac
-00015250: 617a 652c 2047 2e2c 204f 6566 656c 6569  aze, G., Oefelei
-00015260: 6e2c 204a 2e20 432e 2c20 4e61 6a6d 2c20  n, J. C., Najm, 
-00015270: 482e 204e 2e2c 2047 6861 6e65 6d2c 2052  H. N., Ghanem, R
-00015280: 2e20 472e 0d0a 2020 2020 2020 2028 3230  . G...       (20
-00015290: 3139 292e 2043 6f6d 7072 6573 7369 7665  19). Compressive
-000152a0: 2073 656e 7369 6e67 2061 6461 7074 6174   sensing adaptat
-000152b0: 696f 6e20 666f 7220 706f 6c79 6e6f 6d69  ion for polynomi
-000152c0: 616c 2063 6861 6f73 2065 7870 616e 7369  al chaos expansi
-000152d0: 6f6e 732e 0d0a 2020 2020 2020 204a 6f75  ons...       Jou
-000152e0: 726e 616c 206f 6620 436f 6d70 7574 6174  rnal of Computat
-000152f0: 696f 6e61 6c20 5068 7973 6963 732c 2033  ional Physics, 3
-00015300: 3830 2c20 3239 2d34 372e 0d0a 2020 2020  80, 29-47...    
-00015310: 2222 220d 0a0d 0a20 2020 2064 6566 205f  """....    def _
-00015320: 5f69 6e69 745f 5f28 7365 6c66 2c20 6d61  _init__(self, ma
-00015330: 746c 6162 5f6d 6f64 656c 3d46 616c 7365  tlab_model=False
-00015340: 293a 0d0a 2020 2020 2020 2020 7375 7065  ):..        supe
-00015350: 7228 7479 7065 2873 656c 6629 2c20 7365  r(type(self), se
-00015360: 6c66 292e 5f5f 696e 6974 5f5f 286d 6174  lf).__init__(mat
-00015370: 6c61 625f 6d6f 6465 6c3d 6d61 746c 6162  lab_model=matlab
-00015380: 5f6d 6f64 656c 290d 0a20 2020 2020 2020  _model)..       
-00015390: 2073 656c 662e 666e 616d 6520 3d20 696e   self.fname = in
-000153a0: 7370 6563 742e 6765 7466 696c 6528 696e  spect.getfile(in
-000153b0: 7370 6563 742e 6375 7272 656e 7466 7261  spect.currentfra
-000153c0: 6d65 2829 290d 0a0d 0a20 2020 2064 6566  me())....    def
-000153d0: 2076 616c 6964 6174 6528 7365 6c66 293a   validate(self):
-000153e0: 0d0a 2020 2020 2020 2020 7061 7373 0d0a  ..        pass..
-000153f0: 0d0a 2020 2020 6465 6620 7369 6d75 6c61  ..    def simula
-00015400: 7465 2873 656c 662c 2070 726f 6365 7373  te(self, process
-00015410: 5f69 643d 4e6f 6e65 2c20 6d61 746c 6162  _id=None, matlab
-00015420: 5f65 6e67 696e 653d 4e6f 6e65 293a 0d0a  _engine=None):..
-00015430: 2020 2020 2020 2020 6e20 3d20 6c65 6e28          n = len(
-00015440: 7365 6c66 2e70 2e6b 6579 7328 2929 0d0a  self.p.keys())..
-00015450: 0d0a 2020 2020 2020 2020 2320 6465 7465  ..        # dete
-00015460: 726d 696e 6520 7375 6d0d 0a20 2020 2020  rmine sum..     
-00015470: 2020 2073 203d 206e 702e 7a65 726f 7328     s = np.zeros(
-00015480: 6e70 2e61 7272 6179 2873 656c 662e 705b  np.array(self.p[
-00015490: 6c69 7374 2873 656c 662e 702e 6b65 7973  list(self.p.keys
-000154a0: 2829 295b 305d 5d29 2e73 697a 6529 0d0a  ())[0]]).size)..
-000154b0: 0d0a 2020 2020 2020 2020 666f 7220 692c  ..        for i,
-000154c0: 206b 6579 2069 6e20 656e 756d 6572 6174   key in enumerat
-000154d0: 6528 7365 6c66 2e70 2e6b 6579 7328 2929  e(self.p.keys())
-000154e0: 3a0d 0a20 2020 2020 2020 2020 2020 2073  :..            s
-000154f0: 202b 3d20 7365 6c66 2e70 5b6b 6579 5d0d   += self.p[key].
-00015500: 0a0d 0a20 2020 2020 2020 2023 2064 6574  ...        # det
-00015510: 6572 6d69 6e65 206f 7574 7075 740d 0a20  ermine output.. 
-00015520: 2020 2020 2020 2079 203d 2073 202b 2030         y = s + 0
-00015530: 2e32 3520 2a20 732a 2a32 202b 2030 2e30  .25 * s**2 + 0.0
-00015540: 3235 202a 2073 2a2a 330d 0a0d 0a20 2020  25 * s**3....   
-00015550: 2020 2020 2079 5f6f 7574 203d 2079 5b3a       y_out = y[:
-00015560: 2c20 6e70 2e6e 6577 6178 6973 5d0d 0a0d  , np.newaxis]...
-00015570: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00015580: 795f 6f75 740d 0a0d 0a0d 0a63 6c61 7373  y_out......class
-00015590: 204c 696d 3230 3032 2841 6273 7472 6163   Lim2002(Abstrac
-000155a0: 744d 6f64 656c 293a 0d0a 2020 2020 2222  tModel):..    ""
-000155b0: 220d 0a20 2020 2054 776f 2d64 696d 656e  "..    Two-dimen
-000155c0: 7369 6f6e 616c 2074 6573 7420 6675 6e63  sional test func
-000155d0: 7469 6f6e 206f 6620 4c69 6d20 6574 2061  tion of Lim et a
-000155e0: 6c2e 2028 3230 3032 2920 5b31 5d20 2865  l. (2002) [1] (e
-000155f0: 712e 2028 3237 2929 2e0d 0a0d 0a20 2020  q. (27)).....   
-00015600: 2054 6869 7320 6675 6e63 7469 6f6e 2069   This function i
-00015610: 7320 6120 706f 6c79 6e6f 6d69 616c 2069  s a polynomial i
-00015620: 6e20 7477 6f20 6469 6d65 6e73 696f 6e73  n two dimensions
-00015630: 2c20 7769 7468 2074 6572 6d73 2075 7020  , with terms up 
-00015640: 746f 2064 6567 7265 650d 0a20 2020 2035  to degree..    5
-00015650: 2e20 4974 2069 7320 6e6f 6e6c 696e 6561  . It is nonlinea
-00015660: 722c 2061 6e64 2069 7420 6973 2073 6d6f  r, and it is smo
-00015670: 6f74 6820 6465 7370 6974 6520 6265 696e  oth despite bein
-00015680: 6720 636f 6d70 6c65 782c 2077 6869 6368  g complex, which
-00015690: 2069 730d 0a20 2020 2063 6f6d 6d6f 6e20   is..    common 
-000156a0: 666f 7220 636f 6d70 7574 6572 2065 7870  for computer exp
-000156b0: 6572 696d 656e 7420 6675 6e63 7469 6f6e  eriment function
-000156c0: 732e 0d0a 0d0a 2020 2020 2e2e 206d 6174  s.....    .. mat
-000156d0: 683a 3a0d 0a20 2020 2020 2020 7920 3d20  h::..       y = 
-000156e0: 3920 2b20 5c5c 6672 6163 7b35 7d7b 327d  9 + \\frac{5}{2}
-000156f0: 2078 5f31 202d 205c 5c66 7261 637b 3335   x_1 - \\frac{35
-00015700: 7d7b 327d 2078 5f32 202b 205c 5c66 7261  }{2} x_2 + \\fra
-00015710: 637b 357d 7b32 7d20 785f 3120 785f 3220  c{5}{2} x_1 x_2 
-00015720: 2b20 3139 2078 5f32 5e32 202d 0d0a 2020  + 19 x_2^2 -..  
-00015730: 2020 2020 205c 5c66 7261 637b 3135 7d7b       \\frac{15}{
-00015740: 327d 2078 5f31 5e33 202d 205c 5c66 7261  2} x_1^3 - \\fra
-00015750: 637b 357d 7b32 7d20 785f 3120 785f 325e  c{5}{2} x_1 x_2^
-00015760: 3220 2d20 5c5c 6672 6163 7b31 317d 7b32  2 - \\frac{11}{2
-00015770: 7d20 785f 325e 3420 2b20 785f 315e 3320  } x_2^4 + x_1^3 
-00015780: 785f 325e 320d 0a0d 0a20 2020 2050 6172  x_2^2....    Par
-00015790: 616d 6574 6572 730d 0a20 2020 202d 2d2d  ameters..    ---
-000157a0: 2d2d 2d2d 2d2d 2d0d 0a20 2020 2070 5b22  -------..    p["
-000157b0: 7831 225d 3a20 666c 6f61 7420 6f72 206e  x1"]: float or n
-000157c0: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-000157d0: 5b6e 5f67 7269 645d 0d0a 2020 2020 2020  [n_grid]..      
-000157e0: 2020 4669 7273 7420 7061 7261 6d65 7465    First paramete
-000157f0: 7220 6465 6669 6e65 6420 696e 205b 302c  r defined in [0,
-00015800: 2031 5d0d 0a20 2020 2070 5b22 7832 225d   1]..    p["x2"]
-00015810: 3a20 666c 6f61 7420 6f72 206e 6461 7272  : float or ndarr
-00015820: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
-00015830: 7269 645d 0d0a 2020 2020 2020 2020 5365  rid]..        Se
-00015840: 636f 6e64 2070 6172 616d 6574 6572 2064  cond parameter d
-00015850: 6566 696e 6564 2069 6e20 5b30 2c20 315d  efined in [0, 1]
-00015860: 0d0a 0d0a 2020 2020 5265 7475 726e 730d  ....    Returns.
-00015870: 0a20 2020 202d 2d2d 2d2d 2d2d 0d0a 2020  .    -------..  
-00015880: 2020 793a 206e 6461 7272 6179 206f 6620    y: ndarray of 
-00015890: 666c 6f61 7420 5b6e 5f67 7269 6420 7820  float [n_grid x 
-000158a0: 315d 0d0a 2020 2020 2020 2020 4f75 7470  1]..        Outp
-000158b0: 7574 2064 6174 610d 0a0d 0a20 2020 204e  ut data....    N
-000158c0: 6f74 6573 0d0a 2020 2020 2d2d 2d2d 2d0d  otes..    -----.
-000158d0: 0a20 2020 202e 2e20 706c 6f74 3a3a 0d0a  .    .. plot::..
-000158e0: 0d0a 2020 2020 2020 2069 6d70 6f72 7420  ..       import 
-000158f0: 6e75 6d70 7920 6173 206e 700d 0a20 2020  numpy as np..   
-00015900: 2020 2020 6672 6f6d 2070 7967 7063 2e74      from pygpc.t
-00015910: 6573 7466 756e 6374 696f 6e73 2069 6d70  estfunctions imp
-00015920: 6f72 7420 706c 6f74 5f74 6573 7466 756e  ort plot_testfun
-00015930: 6374 696f 6e20 6173 2070 6c6f 740d 0a20  ction as plot.. 
-00015940: 2020 2020 2020 6672 6f6d 2063 6f6c 6c65        from colle
-00015950: 6374 696f 6e73 2069 6d70 6f72 7420 4f72  ctions import Or
-00015960: 6465 7265 6444 6963 740d 0a0d 0a20 2020  deredDict....   
-00015970: 2020 2020 7061 7261 6d65 7465 7273 203d      parameters =
-00015980: 204f 7264 6572 6564 4469 6374 2829 0d0a   OrderedDict()..
-00015990: 2020 2020 2020 2070 6172 616d 6574 6572         parameter
-000159a0: 735b 2278 3122 5d20 3d20 6e70 2e6c 696e  s["x1"] = np.lin
-000159b0: 7370 6163 6528 302c 2031 2c20 3130 3029  space(0, 1, 100)
-000159c0: 0d0a 2020 2020 2020 2070 6172 616d 6574  ..       paramet
-000159d0: 6572 735b 2278 3222 5d20 3d20 6e70 2e6c  ers["x2"] = np.l
-000159e0: 696e 7370 6163 6528 302c 2031 2c20 3130  inspace(0, 1, 10
-000159f0: 3029 0d0a 0d0a 2020 2020 2020 2070 6c6f  0)....       plo
-00015a00: 7428 224c 696d 3230 3032 222c 2070 6172  t("Lim2002", par
-00015a10: 616d 6574 6572 7329 0d0a 0d0a 2020 2020  ameters)....    
-00015a20: 2e2e 205b 315d 204c 696d 2c20 592e 2042  .. [1] Lim, Y. B
-00015a30: 2e2c 2053 6163 6b73 2c20 4a2e 2c20 5374  ., Sacks, J., St
-00015a40: 7564 6465 6e2c 2057 2e20 4a2e 2c20 2620  udden, W. J., & 
-00015a50: 5765 6c63 682c 2057 2e20 4a2e 2028 3230  Welch, W. J. (20
-00015a60: 3032 292e 2044 6573 6967 6e0d 0a20 2020  02). Design..   
-00015a70: 2020 2020 616e 6420 616e 616c 7973 6973      and analysis
-00015a80: 206f 6620 636f 6d70 7574 6572 2065 7870   of computer exp
-00015a90: 6572 696d 656e 7473 2077 6865 6e20 7468  eriments when th
-00015aa0: 6520 6f75 7470 7574 2069 7320 6869 6768  e output is high
-00015ab0: 6c79 2063 6f72 7265 6c61 7465 640d 0a20  ly correlated.. 
-00015ac0: 2020 2020 2020 6f76 6572 2074 6865 2069        over the i
-00015ad0: 6e70 7574 2073 7061 6365 2e20 4361 6e61  nput space. Cana
-00015ae0: 6469 616e 204a 6f75 726e 616c 206f 6620  dian Journal of 
-00015af0: 5374 6174 6973 7469 6373 2c20 3330 2831  Statistics, 30(1
-00015b00: 292c 2031 3039 2d31 3236 2e0d 0a20 2020  ), 109-126...   
-00015b10: 2022 2222 0d0a 0d0a 2020 2020 6465 6620   """....    def 
-00015b20: 5f5f 696e 6974 5f5f 2873 656c 662c 206d  __init__(self, m
-00015b30: 6174 6c61 625f 6d6f 6465 6c3d 4661 6c73  atlab_model=Fals
-00015b40: 6529 3a0d 0a20 2020 2020 2020 2073 7570  e):..        sup
-00015b50: 6572 2874 7970 6528 7365 6c66 292c 2073  er(type(self), s
-00015b60: 656c 6629 2e5f 5f69 6e69 745f 5f28 6d61  elf).__init__(ma
-00015b70: 746c 6162 5f6d 6f64 656c 3d6d 6174 6c61  tlab_model=matla
-00015b80: 625f 6d6f 6465 6c29 0d0a 2020 2020 2020  b_model)..      
-00015b90: 2020 7365 6c66 2e66 6e61 6d65 203d 2069    self.fname = i
-00015ba0: 6e73 7065 6374 2e67 6574 6669 6c65 2869  nspect.getfile(i
-00015bb0: 6e73 7065 6374 2e63 7572 7265 6e74 6672  nspect.currentfr
-00015bc0: 616d 6528 2929 0d0a 0d0a 2020 2020 6465  ame())....    de
-00015bd0: 6620 7661 6c69 6461 7465 2873 656c 6629  f validate(self)
-00015be0: 3a0d 0a20 2020 2020 2020 2070 6173 730d  :..        pass.
-00015bf0: 0a0d 0a20 2020 2064 6566 2073 696d 756c  ...    def simul
-00015c00: 6174 6528 7365 6c66 2c20 7072 6f63 6573  ate(self, proces
-00015c10: 735f 6964 3d4e 6f6e 652c 206d 6174 6c61  s_id=None, matla
-00015c20: 625f 656e 6769 6e65 3d4e 6f6e 6529 3a0d  b_engine=None):.
-00015c30: 0a20 2020 2020 2020 2079 203d 2039 202b  .        y = 9 +
-00015c40: 2032 2e35 202a 2073 656c 662e 705b 2278   2.5 * self.p["x
-00015c50: 3122 5d20 2d20 3137 2e35 202a 2073 656c  1"] - 17.5 * sel
-00015c60: 662e 705b 2278 3222 5d20 2b20 322e 3520  f.p["x2"] + 2.5 
-00015c70: 2a20 7365 6c66 2e70 5b22 7831 225d 202a  * self.p["x1"] *
-00015c80: 2073 656c 662e 705b 2278 3222 5d20 2b20   self.p["x2"] + 
-00015c90: 3139 202a 2073 656c 662e 705b 2278 3222  19 * self.p["x2"
-00015ca0: 5d20 2a2a 2032 202d 5c0d 0a20 2020 2020  ] ** 2 -\..     
-00015cb0: 2020 2020 2020 2037 2e35 202a 2073 656c         7.5 * sel
-00015cc0: 662e 705b 2278 3122 5d20 2a2a 2033 202d  f.p["x1"] ** 3 -
-00015cd0: 2032 2e35 202a 2073 656c 662e 705b 2278   2.5 * self.p["x
-00015ce0: 3122 5d20 2a20 7365 6c66 2e70 5b22 7832  1"] * self.p["x2
-00015cf0: 225d 202a 2a20 3220 2d20 352e 3520 2a20  "] ** 2 - 5.5 * 
-00015d00: 7365 6c66 2e70 5b22 7832 225d 202a 2a20  self.p["x2"] ** 
-00015d10: 3420 2b5c 0d0a 2020 2020 2020 2020 2020  4 +\..          
-00015d20: 2020 2873 656c 662e 705b 2278 3122 5d20    (self.p["x1"] 
-00015d30: 2a2a 2033 2920 2a20 2873 656c 662e 705b  ** 3) * (self.p[
-00015d40: 2278 3222 5d20 2a2a 2032 290d 0a0d 0a20  "x2"] ** 2).... 
-00015d50: 2020 2020 2020 2023 2079 203d 2028 3920         # y = (9 
-00015d60: 2b20 352e 3020 2f20 3220 2a20 7365 6c66  + 5.0 / 2 * self
-00015d70: 2e70 5b22 7831 225d 202d 2033 352e 3020  .p["x1"] - 35.0 
-00015d80: 2f20 3220 2a20 7365 6c66 2e70 5b22 7832  / 2 * self.p["x2
-00015d90: 225d 202b 2035 2e30 202f 2032 202a 2073  "] + 5.0 / 2 * s
-00015da0: 656c 662e 705b 2278 3122 5d20 2a20 7365  elf.p["x1"] * se
-00015db0: 6c66 2e70 5b22 7832 225d 202b 0d0a 2020  lf.p["x2"] +..  
-00015dc0: 2020 2020 2020 2320 2020 2020 2031 3920        #      19 
-00015dd0: 2a20 7365 6c66 2e70 5b22 7832 225d 202a  * self.p["x2"] *
-00015de0: 2a20 3220 2d20 3135 2e30 202f 2032 202a  * 2 - 15.0 / 2 *
-00015df0: 2073 656c 662e 705b 2278 3122 5d20 2a2a   self.p["x1"] **
-00015e00: 2033 202d 2035 2e30 202f 2032 202a 2073   3 - 5.0 / 2 * s
-00015e10: 656c 662e 705b 2278 3122 5d20 2a20 7365  elf.p["x1"] * se
-00015e20: 6c66 2e70 5b22 7832 225d 202a 2a20 3220  lf.p["x2"] ** 2 
-00015e30: 2d0d 0a20 2020 2020 2020 2023 2020 2020  -..        #    
-00015e40: 2020 3131 2e30 202f 2032 202a 2073 656c    11.0 / 2 * sel
-00015e50: 662e 705b 2278 3222 5d20 2a2a 2034 202b  f.p["x2"] ** 4 +
-00015e60: 2073 656c 662e 705b 2278 3122 5d20 2a2a   self.p["x1"] **
-00015e70: 2033 202a 2073 656c 662e 705b 2278 3222   3 * self.p["x2"
-00015e80: 5d20 2a2a 2032 290d 0a0d 0a20 2020 2020  ] ** 2)....     
-00015e90: 2020 2069 6620 7479 7065 2879 2920 6973     if type(y) is
-00015ea0: 206e 6f74 206e 702e 6e64 6172 7261 793a   not np.ndarray:
-00015eb0: 0d0a 2020 2020 2020 2020 2020 2020 7920  ..            y 
-00015ec0: 3d20 6e70 2e61 7272 6179 285b 795d 290d  = np.array([y]).
-00015ed0: 0a0d 0a20 2020 2020 2020 2079 5f6f 7574  ...        y_out
-00015ee0: 203d 2079 5b3a 2c20 6e70 2e6e 6577 6178   = y[:, np.newax
-00015ef0: 6973 5d0d 0a0d 0a20 2020 2020 2020 2072  is]....        r
-00015f00: 6574 7572 6e20 795f 6f75 740d 0a0d 0a0d  eturn y_out.....
-00015f10: 0a63 6c61 7373 2049 7368 6967 616d 6928  .class Ishigami(
-00015f20: 4162 7374 7261 6374 4d6f 6465 6c29 3a0d  AbstractModel):.
-00015f30: 0a20 2020 2022 2222 0d0a 2020 2020 5468  .    """..    Th
-00015f40: 7265 652d 6469 6d65 6e73 696f 6e61 6c20  ree-dimensional 
-00015f50: 7465 7374 2066 756e 6374 696f 6e20 6f66  test function of
-00015f60: 2049 7368 6967 616d 692e 0d0a 0d0a 2020   Ishigami.....  
-00015f70: 2020 5468 6520 4973 6869 6761 6d69 2066    The Ishigami f
-00015f80: 756e 6374 696f 6e20 6f66 2049 7368 6967  unction of Ishig
-00015f90: 616d 6920 2620 486f 6d6d 6120 2831 3939  ami & Homma (199
-00015fa0: 3029 205b 315d 2069 7320 7573 6564 2061  0) [1] is used a
-00015fb0: 7320 616e 2065 7861 6d70 6c65 0d0a 2020  s an example..  
-00015fc0: 2020 666f 7220 756e 6365 7274 6169 6e74    for uncertaint
-00015fd0: 7920 616e 6420 7365 6e73 6974 6976 6974  y and sensitivit
-00015fe0: 7920 616e 616c 7973 6973 206d 6574 686f  y analysis metho
-00015ff0: 6473 2c20 6265 6361 7573 6520 6974 2065  ds, because it e
-00016000: 7868 6962 6974 730d 0a20 2020 2073 7472  xhibits..    str
-00016010: 6f6e 6720 6e6f 6e6c 696e 6561 7269 7479  ong nonlinearity
-00016020: 2061 6e64 206e 6f6e 6d6f 6e6f 746f 6e69   and nonmonotoni
-00016030: 6369 7479 2e20 4974 2061 6c73 6f20 6861  city. It also ha
-00016040: 7320 6120 7065 6375 6c69 6172 0d0a 2020  s a peculiar..  
-00016050: 2020 6465 7065 6e64 656e 6365 206f 6e20    dependence on 
-00016060: 7833 2c20 6173 2064 6573 6372 6962 6564  x3, as described
-00016070: 2062 7920 536f 626f 6c27 2026 204c 6576   by Sobol' & Lev
-00016080: 6974 616e 2028 3139 3939 2920 5b32 5d2e  itan (1999) [2].
-00016090: 0d0a 2020 2020 5468 6520 7661 6c75 6573  ..    The values
-000160a0: 206f 6620 6120 616e 6420 6220 7573 6564   of a and b used
-000160b0: 2062 7920 4372 6573 7461 7578 2065 7420   by Crestaux et 
-000160c0: 616c 2e20 2832 3030 3729 205b 335d 2061  al. (2007) [3] a
-000160d0: 6e64 204d 6172 7265 6c20 6574 2061 6c2e  nd Marrel et al.
-000160e0: 2028 3230 3039 2920 5b34 5d20 6172 653a   (2009) [4] are:
-000160f0: 2061 203d 2037 2061 6e64 2062 203d 2030   a = 7 and b = 0
-00016100: 2e31 2e0d 0a0d 0a20 2020 202e 2e20 6d61  .1.....    .. ma
-00016110: 7468 3a3a 2079 203d 205c 7369 6e28 785f  th:: y = \sin(x_
-00016120: 3129 202b 2061 205c 7369 6e28 785f 3229  1) + a \sin(x_2)
-00016130: 5e32 202b 2062 2078 5f33 5e34 205c 7369  ^2 + b x_3^4 \si
-00016140: 6e28 785f 3129 0d0a 0d0a 2020 2020 5061  n(x_1)....    Pa
-00016150: 7261 6d65 7465 7273 0d0a 2020 2020 2d2d  rameters..    --
-00016160: 2d2d 2d2d 2d2d 2d2d 0d0a 2020 2020 705b  --------..    p[
-00016170: 2278 3122 5d3a 2066 6c6f 6174 206f 7220  "x1"]: float or 
-00016180: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-00016190: 205b 6e5f 6772 6964 5d0d 0a20 2020 2020   [n_grid]..     
-000161a0: 2020 2046 6972 7374 2070 6172 616d 6574     First paramet
-000161b0: 6572 2064 6566 696e 6564 2069 6e20 5b2d  er defined in [-
-000161c0: 7069 2c20 7069 5d0d 0a20 2020 2070 5b22  pi, pi]..    p["
-000161d0: 7832 225d 3a20 666c 6f61 7420 6f72 206e  x2"]: float or n
-000161e0: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-000161f0: 5b6e 5f67 7269 645d 0d0a 2020 2020 2020  [n_grid]..      
-00016200: 2020 5365 636f 6e64 2070 6172 616d 6574    Second paramet
-00016210: 6572 2064 6566 696e 6564 2069 6e20 5b2d  er defined in [-
-00016220: 7069 2c20 7069 5d0d 0a20 2020 2070 5b22  pi, pi]..    p["
-00016230: 7833 225d 3a20 666c 6f61 7420 6f72 206e  x3"]: float or n
-00016240: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-00016250: 5b6e 5f67 7269 645d 0d0a 2020 2020 2020  [n_grid]..      
-00016260: 2020 5468 6972 6420 7061 7261 6d65 7465    Third paramete
-00016270: 7220 6465 6669 6e65 6420 696e 205b 2d70  r defined in [-p
-00016280: 692c 2070 695d 0d0a 2020 2020 705b 2261  i, pi]..    p["a
-00016290: 225d 3a20 666c 6f61 740d 0a20 2020 2020  "]: float..     
-000162a0: 2020 2073 6861 7065 2070 6172 616d 6574     shape paramet
-000162b0: 6572 2028 613d 3729 0d0a 2020 2020 705b  er (a=7)..    p[
-000162c0: 2262 225d 3a20 666c 6f61 740d 0a20 2020  "b"]: float..   
-000162d0: 2020 2020 2073 6861 7065 2070 6172 616d       shape param
-000162e0: 6574 6572 2028 623d 302e 3129 0d0a 0d0a  eter (b=0.1)....
-000162f0: 2020 2020 5265 7475 726e 730d 0a20 2020      Returns..   
-00016300: 202d 2d2d 2d2d 2d2d 0d0a 2020 2020 793a   -------..    y:
-00016310: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-00016320: 7420 5b6e 5f67 7269 6420 7820 315d 0d0a  t [n_grid x 1]..
-00016330: 2020 2020 2020 2020 4f75 7470 7574 2064          Output d
-00016340: 6174 610d 0a0d 0a20 2020 204e 6f74 6573  ata....    Notes
-00016350: 0d0a 2020 2020 2d2d 2d2d 2d0d 0a20 2020  ..    -----..   
-00016360: 202e 2e20 706c 6f74 3a3a 0d0a 0d0a 2020   .. plot::....  
-00016370: 2020 2020 2069 6d70 6f72 7420 6e75 6d70       import nump
-00016380: 7920 6173 206e 700d 0a20 2020 2020 2020  y as np..       
-00016390: 6672 6f6d 2070 7967 7063 2e74 6573 7466  from pygpc.testf
-000163a0: 756e 6374 696f 6e73 2069 6d70 6f72 7420  unctions import 
-000163b0: 706c 6f74 5f74 6573 7466 756e 6374 696f  plot_testfunctio
-000163c0: 6e20 6173 2070 6c6f 740d 0a20 2020 2020  n as plot..     
-000163d0: 2020 6672 6f6d 2063 6f6c 6c65 6374 696f    from collectio
-000163e0: 6e73 2069 6d70 6f72 7420 4f72 6465 7265  ns import Ordere
-000163f0: 6444 6963 740d 0a0d 0a20 2020 2020 2020  dDict....       
-00016400: 7061 7261 6d65 7465 7273 203d 204f 7264  parameters = Ord
-00016410: 6572 6564 4469 6374 2829 0d0a 2020 2020  eredDict()..    
-00016420: 2020 2070 6172 616d 6574 6572 735b 2278     parameters["x
-00016430: 3122 5d20 3d20 6e70 2e6c 696e 7370 6163  1"] = np.linspac
-00016440: 6528 2d6e 702e 7069 2c20 6e70 2e70 692c  e(-np.pi, np.pi,
-00016450: 2031 3030 290d 0a20 2020 2020 2020 7061   100)..       pa
-00016460: 7261 6d65 7465 7273 5b22 7832 225d 203d  rameters["x2"] =
-00016470: 206e 702e 6c69 6e73 7061 6365 282d 6e70   np.linspace(-np
-00016480: 2e70 692c 206e 702e 7069 2c20 3130 3029  .pi, np.pi, 100)
-00016490: 0d0a 0d0a 2020 2020 2020 2063 6f6e 7374  ....       const
-000164a0: 616e 7473 203d 204f 7264 6572 6564 4469  ants = OrderedDi
-000164b0: 6374 2829 0d0a 2020 2020 2020 2063 6f6e  ct()..       con
-000164c0: 7374 616e 7473 5b22 6122 5d20 3d20 372e  stants["a"] = 7.
-000164d0: 0d0a 2020 2020 2020 2063 6f6e 7374 616e  ..       constan
-000164e0: 7473 5b22 6222 5d20 3d20 302e 310d 0a20  ts["b"] = 0.1.. 
-000164f0: 2020 2020 2020 636f 6e73 7461 6e74 735b        constants[
-00016500: 2278 3322 5d20 3d20 302e 0d0a 0d0a 2020  "x3"] = 0.....  
-00016510: 2020 2020 2070 6c6f 7428 2249 7368 6967       plot("Ishig
-00016520: 616d 6922 2c20 7061 7261 6d65 7465 7273  ami", parameters
-00016530: 2c20 636f 6e73 7461 6e74 732c 2070 6c6f  , constants, plo
-00016540: 745f 3364 3d46 616c 7365 290d 0a0d 0a20  t_3d=False).... 
-00016550: 2020 202e 2e20 5b31 5d20 4973 6869 6761     .. [1] Ishiga
-00016560: 6d69 2c20 542e 2c20 486f 6d6d 612c 2054  mi, T., Homma, T
-00016570: 2e20 2831 3939 302c 2044 6563 656d 6265  . (1990, Decembe
-00016580: 7229 2e20 416e 2069 6d70 6f72 7461 6e63  r). An importanc
-00016590: 6520 7175 616e 7469 6669 6361 7469 6f6e  e quantification
-000165a0: 0d0a 2020 2020 2020 2074 6563 686e 6971  ..       techniq
-000165b0: 7565 2069 6e20 756e 6365 7274 6169 6e74  ue in uncertaint
-000165c0: 7920 616e 616c 7973 6973 2066 6f72 2063  y analysis for c
-000165d0: 6f6d 7075 7465 7220 6d6f 6465 6c73 2e20  omputer models. 
-000165e0: 496e 2055 6e63 6572 7461 696e 7479 0d0a  In Uncertainty..
-000165f0: 2020 2020 2020 204d 6f64 656c 696e 6720         Modeling 
-00016600: 616e 6420 416e 616c 7973 6973 2c20 3139  and Analysis, 19
-00016610: 3930 2e20 5072 6f63 6565 6469 6e67 732e  90. Proceedings.
-00016620: 2c20 4669 7273 7420 496e 7465 726e 6174  , First Internat
-00016630: 696f 6e61 6c20 5379 6d70 6f73 6975 6d0d  ional Symposium.
-00016640: 0a20 2020 2020 2020 6f6e 2028 7070 2e20  .       on (pp. 
-00016650: 3339 382d 3430 3329 2e20 4945 4545 2e0d  398-403). IEEE..
-00016660: 0a0d 0a20 2020 202e 2e20 5b32 5d20 536f  ...    .. [2] So
-00016670: 626f 6c27 2c20 492e 4d2e 2c20 4c65 7669  bol', I.M., Levi
-00016680: 7461 6e2c 2059 2e4c 2e20 2831 3939 3929  tan, Y.L. (1999)
-00016690: 2e20 4f6e 2074 6865 2075 7365 206f 6620  . On the use of 
-000166a0: 7661 7269 616e 6365 2072 6564 7563 696e  variance reducin
-000166b0: 670d 0a20 2020 2020 2020 6d75 6c74 6970  g..       multip
-000166c0: 6c69 6572 7320 696e 204d 6f6e 7465 2043  liers in Monte C
-000166d0: 6172 6c6f 2063 6f6d 7075 7461 7469 6f6e  arlo computation
-000166e0: 7320 6f66 2061 2067 6c6f 6261 6c20 7365  s of a global se
-000166f0: 6e73 6974 6976 6974 7920 696e 6465 782e  nsitivity index.
-00016700: 0d0a 2020 2020 2020 2043 6f6d 7075 7465  ..       Compute
-00016710: 7220 5068 7973 6963 7320 436f 6d6d 756e  r Physics Commun
-00016720: 6963 6174 696f 6e73 2c20 3131 3728 3129  ications, 117(1)
-00016730: 2c20 3532 2d36 312e 0d0a 0d0a 2020 2020  , 52-61.....    
-00016740: 2e2e 205b 335d 2043 7265 7374 6175 782c  .. [3] Crestaux,
-00016750: 2054 2e2c 204d 6172 7469 6e65 7a2c 204a   T., Martinez, J
-00016760: 2e2d 4d2e 2c20 4c65 204d 6169 7472 652c  .-M., Le Maitre,
-00016770: 204f 2e2c 2026 204c 6166 6974 7465 2c20   O., & Lafitte, 
-00016780: 4f2e 2028 3230 3037 292e 0d0a 2020 2020  O. (2007)...    
-00016790: 2020 2050 6f6c 796e 6f6d 6961 6c20 6368     Polynomial ch
-000167a0: 616f 7320 6578 7061 6e73 696f 6e20 666f  aos expansion fo
-000167b0: 7220 756e 6365 7274 6169 6e74 6965 7320  r uncertainties 
-000167c0: 7175 616e 7469 6669 6361 7469 6f6e 2061  quantification a
-000167d0: 6e64 2073 656e 7369 7469 7669 7479 2061  nd sensitivity a
-000167e0: 6e61 6c79 7369 7320 5b50 6f77 6572 506f  nalysis [PowerPo
-000167f0: 696e 7420 736c 6964 6573 5d2e 0d0a 2020  int slides]...  
-00016800: 2020 2020 2052 6574 7269 6576 6564 2066       Retrieved f
-00016810: 726f 6d20 5341 4d4f 2032 3030 3720 7765  rom SAMO 2007 we
-00016820: 6273 6974 653a 2068 7474 703a 2f2f 7361  bsite: http://sa
-00016830: 6d6f 3230 3037 2e63 6865 6d2e 656c 7465  mo2007.chem.elte
-00016840: 2e68 752f 6c65 6374 7572 6573 2f43 7265  .hu/lectures/Cre
-00016850: 7374 6175 782e 7064 662e 0d0a 0d0a 2020  staux.pdf.....  
-00016860: 2020 2e2e 205b 345d 204d 6172 7265 6c2c    .. [4] Marrel,
-00016870: 2041 2e2c 2049 6f6f 7373 2c20 422e 2c20   A., Iooss, B., 
-00016880: 4c61 7572 656e 742c 2042 2e2c 2026 2052  Laurent, B., & R
-00016890: 6f75 7374 616e 742c 204f 2e20 2832 3030  oustant, O. (200
-000168a0: 3929 2e0d 0a20 2020 2020 2020 4361 6c63  9)...       Calc
-000168b0: 756c 6174 696f 6e73 206f 6620 736f 626f  ulations of sobo
-000168c0: 6c20 696e 6469 6365 7320 666f 7220 7468  l indices for th
-000168d0: 6520 6761 7573 7369 616e 2070 726f 6365  e gaussian proce
-000168e0: 7373 206d 6574 616d 6f64 656c 2e0d 0a20  ss metamodel... 
-000168f0: 2020 2020 2020 5265 6c69 6162 696c 6974        Reliabilit
-00016900: 7920 456e 6769 6e65 6572 696e 6720 2620  y Engineering & 
-00016910: 5379 7374 656d 2053 6166 6574 792c 2039  System Safety, 9
-00016920: 3428 3329 2c20 3734 322d 3735 312e 0d0a  4(3), 742-751...
-00016930: 2020 2020 2222 220d 0a0d 0a20 2020 2064      """....    d
-00016940: 6566 205f 5f69 6e69 745f 5f28 7365 6c66  ef __init__(self
-00016950: 2c20 6d61 746c 6162 5f6d 6f64 656c 3d46  , matlab_model=F
-00016960: 616c 7365 293a 0d0a 2020 2020 2020 2020  alse):..        
-00016970: 7375 7065 7228 7479 7065 2873 656c 6629  super(type(self)
-00016980: 2c20 7365 6c66 292e 5f5f 696e 6974 5f5f  , self).__init__
-00016990: 286d 6174 6c61 625f 6d6f 6465 6c3d 6d61  (matlab_model=ma
-000169a0: 746c 6162 5f6d 6f64 656c 290d 0a20 2020  tlab_model)..   
-000169b0: 2020 2020 2073 656c 662e 666e 616d 6520       self.fname 
-000169c0: 3d20 696e 7370 6563 742e 6765 7466 696c  = inspect.getfil
-000169d0: 6528 696e 7370 6563 742e 6375 7272 656e  e(inspect.curren
-000169e0: 7466 7261 6d65 2829 290d 0a0d 0a20 2020  tframe())....   
-000169f0: 2064 6566 2076 616c 6964 6174 6528 7365   def validate(se
-00016a00: 6c66 293a 0d0a 2020 2020 2020 2020 7061  lf):..        pa
-00016a10: 7373 0d0a 0d0a 2020 2020 6465 6620 7369  ss....    def si
-00016a20: 6d75 6c61 7465 2873 656c 662c 2070 726f  mulate(self, pro
-00016a30: 6365 7373 5f69 643d 4e6f 6e65 2c20 6d61  cess_id=None, ma
-00016a40: 746c 6162 5f65 6e67 696e 653d 4e6f 6e65  tlab_engine=None
-00016a50: 293a 0d0a 0d0a 2020 2020 2020 2020 6966  ):....        if
-00016a60: 2073 656c 662e 705b 2278 3122 5d20 6973   self.p["x1"] is
-00016a70: 206e 6f74 206e 702e 6e64 6172 7261 793a   not np.ndarray:
-00016a80: 0d0a 2020 2020 2020 2020 2020 2020 7365  ..            se
-00016a90: 6c66 2e70 5b22 7831 225d 203d 206e 702e  lf.p["x1"] = np.
-00016aa0: 6172 7261 7928 7365 6c66 2e70 5b22 7831  array(self.p["x1
-00016ab0: 225d 290d 0a0d 0a20 2020 2020 2020 2069  "])....        i
-00016ac0: 6620 7365 6c66 2e70 5b22 7832 225d 2069  f self.p["x2"] i
-00016ad0: 7320 6e6f 7420 6e70 2e6e 6461 7272 6179  s not np.ndarray
-00016ae0: 3a0d 0a20 2020 2020 2020 2020 2020 2073  :..            s
-00016af0: 656c 662e 705b 2278 3222 5d20 3d20 6e70  elf.p["x2"] = np
-00016b00: 2e61 7272 6179 2873 656c 662e 705b 2278  .array(self.p["x
-00016b10: 3222 5d29 0d0a 0d0a 2020 2020 2020 2020  2"])....        
-00016b20: 6966 2073 656c 662e 705b 2278 3322 5d20  if self.p["x3"] 
-00016b30: 6973 206e 6f74 206e 702e 6e64 6172 7261  is not np.ndarra
-00016b40: 793a 0d0a 2020 2020 2020 2020 2020 2020  y:..            
-00016b50: 7365 6c66 2e70 5b22 7833 225d 203d 206e  self.p["x3"] = n
-00016b60: 702e 6172 7261 7928 7365 6c66 2e70 5b22  p.array(self.p["
-00016b70: 7833 225d 290d 0a0d 0a20 2020 2020 2020  x3"])....       
-00016b80: 2069 6620 7365 6c66 2e70 5b22 6122 5d20   if self.p["a"] 
-00016b90: 6973 206e 6f74 206e 702e 6e64 6172 7261  is not np.ndarra
-00016ba0: 793a 0d0a 2020 2020 2020 2020 2020 2020  y:..            
-00016bb0: 7365 6c66 2e70 5b22 6122 5d20 3d20 6e70  self.p["a"] = np
-00016bc0: 2e61 7272 6179 2873 656c 662e 705b 2261  .array(self.p["a
-00016bd0: 225d 290d 0a0d 0a20 2020 2020 2020 2069  "])....        i
-00016be0: 6620 7365 6c66 2e70 5b22 6222 5d20 6973  f self.p["b"] is
-00016bf0: 206e 6f74 206e 702e 6e64 6172 7261 793a   not np.ndarray:
-00016c00: 0d0a 2020 2020 2020 2020 2020 2020 7365  ..            se
-00016c10: 6c66 2e70 5b22 6222 5d20 3d20 6e70 2e61  lf.p["b"] = np.a
-00016c20: 7272 6179 2873 656c 662e 705b 2262 225d  rray(self.p["b"]
-00016c30: 290d 0a0d 0a20 2020 2020 2020 2079 203d  )....        y =
-00016c40: 2028 6e70 2e73 696e 2873 656c 662e 705b   (np.sin(self.p[
-00016c50: 2278 3122 5d2e 666c 6174 7465 6e28 2929  "x1"].flatten())
-00016c60: 202b 2073 656c 662e 705b 2261 225d 2e66   + self.p["a"].f
-00016c70: 6c61 7474 656e 2829 202a 206e 702e 7369  latten() * np.si
-00016c80: 6e28 7365 6c66 2e70 5b22 7832 225d 2e66  n(self.p["x2"].f
-00016c90: 6c61 7474 656e 2829 2920 2a2a 2032 0d0a  latten()) ** 2..
-00016ca0: 2020 2020 2020 2020 2020 2020 202b 2073               + s
-00016cb0: 656c 662e 705b 2262 225d 2e66 6c61 7474  elf.p["b"].flatt
-00016cc0: 656e 2829 202a 2073 656c 662e 705b 2278  en() * self.p["x
-00016cd0: 3322 5d2e 666c 6174 7465 6e28 2920 2a2a  3"].flatten() **
-00016ce0: 2034 202a 206e 702e 7369 6e28 7365 6c66   4 * np.sin(self
-00016cf0: 2e70 5b22 7831 225d 2e66 6c61 7474 656e  .p["x1"].flatten
-00016d00: 2829 2929 0d0a 0d0a 2020 2020 2020 2020  ()))....        
-00016d10: 6966 2074 7970 6528 7929 2069 7320 6e6f  if type(y) is no
-00016d20: 7420 6e70 2e6e 6461 7272 6179 3a0d 0a20  t np.ndarray:.. 
-00016d30: 2020 2020 2020 2020 2020 2079 203d 206e             y = n
-00016d40: 702e 6172 7261 7928 5b79 5d29 0d0a 0d0a  p.array([y])....
-00016d50: 2020 2020 2020 2020 795f 6f75 7420 3d20          y_out = 
-00016d60: 795b 3a2c 206e 702e 6e65 7761 7869 735d  y[:, np.newaxis]
-00016d70: 0d0a 0d0a 2020 2020 2020 2020 7265 7475  ....        retu
-00016d80: 726e 2079 5f6f 7574 0d0a 0d0a 0d0a 636c  rn y_out......cl
-00016d90: 6173 7320 4973 6869 6761 6d69 5f4e 614e  ass Ishigami_NaN
-00016da0: 2841 6273 7472 6163 744d 6f64 656c 293a  (AbstractModel):
-00016db0: 0d0a 2020 2020 2222 220d 0a20 2020 2054  ..    """..    T
-00016dc0: 6872 6565 2d64 696d 656e 7369 6f6e 616c  hree-dimensional
-00016dd0: 2074 6573 7420 6675 6e63 7469 6f6e 206f   test function o
-00016de0: 6620 4973 6869 6761 6d69 2e0d 0a0d 0a20  f Ishigami..... 
-00016df0: 2020 2054 6865 2049 7368 6967 616d 6920     The Ishigami 
-00016e00: 6675 6e63 7469 6f6e 206f 6620 4973 6869  function of Ishi
-00016e10: 6761 6d69 2026 2048 6f6d 6d61 2028 3139  gami & Homma (19
-00016e20: 3930 2920 5b31 5d20 6973 2075 7365 6420  90) [1] is used 
-00016e30: 6173 2061 6e20 6578 616d 706c 650d 0a20  as an example.. 
-00016e40: 2020 2066 6f72 2075 6e63 6572 7461 696e     for uncertain
-00016e50: 7479 2061 6e64 2073 656e 7369 7469 7669  ty and sensitivi
-00016e60: 7479 2061 6e61 6c79 7369 7320 6d65 7468  ty analysis meth
-00016e70: 6f64 732c 2062 6563 6175 7365 2069 7420  ods, because it 
-00016e80: 6578 6869 6269 7473 0d0a 2020 2020 7374  exhibits..    st
-00016e90: 726f 6e67 206e 6f6e 6c69 6e65 6172 6974  rong nonlinearit
-00016ea0: 7920 616e 6420 6e6f 6e6d 6f6e 6f74 6f6e  y and nonmonoton
-00016eb0: 6963 6974 792e 2049 7420 616c 736f 2068  icity. It also h
-00016ec0: 6173 2061 2070 6563 756c 6961 720d 0a20  as a peculiar.. 
-00016ed0: 2020 2064 6570 656e 6465 6e63 6520 6f6e     dependence on
-00016ee0: 2078 332c 2061 7320 6465 7363 7269 6265   x3, as describe
-00016ef0: 6420 6279 2053 6f62 6f6c 2720 2620 4c65  d by Sobol' & Le
-00016f00: 7669 7461 6e20 2831 3939 3929 205b 325d  vitan (1999) [2]
-00016f10: 2e0d 0a20 2020 2054 6865 2076 616c 7565  ...    The value
-00016f20: 7320 6f66 2061 2061 6e64 2062 2075 7365  s of a and b use
-00016f30: 6420 6279 2043 7265 7374 6175 7820 6574  d by Crestaux et
-00016f40: 2061 6c2e 2028 3230 3037 2920 5b33 5d20   al. (2007) [3] 
-00016f50: 616e 6420 4d61 7272 656c 2065 7420 616c  and Marrel et al
-00016f60: 2e20 2832 3030 3929 205b 345d 2061 7265  . (2009) [4] are
-00016f70: 3a20 6120 3d20 3720 616e 6420 6220 3d20  : a = 7 and b = 
-00016f80: 302e 312e 0d0a 0d0a 2020 2020 2e2e 206d  0.1.....    .. m
-00016f90: 6174 683a 3a20 7920 3d20 5c73 696e 2878  ath:: y = \sin(x
-00016fa0: 5f31 2920 2b20 6120 5c73 696e 2878 5f32  _1) + a \sin(x_2
-00016fb0: 295e 3220 2b20 6220 785f 335e 3420 5c73  )^2 + b x_3^4 \s
-00016fc0: 696e 2878 5f31 290d 0a0d 0a20 2020 2050  in(x_1)....    P
-00016fd0: 6172 616d 6574 6572 730d 0a20 2020 202d  arameters..    -
-00016fe0: 2d2d 2d2d 2d2d 2d2d 2d0d 0a20 2020 2070  ---------..    p
-00016ff0: 5b22 7831 225d 3a20 666c 6f61 7420 6f72  ["x1"]: float or
-00017000: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-00017010: 7420 5b6e 5f67 7269 645d 0d0a 2020 2020  t [n_grid]..    
-00017020: 2020 2020 4669 7273 7420 7061 7261 6d65      First parame
-00017030: 7465 7220 6465 6669 6e65 6420 696e 205b  ter defined in [
-00017040: 2d70 692c 2070 695d 0d0a 2020 2020 705b  -pi, pi]..    p[
-00017050: 2278 3222 5d3a 2066 6c6f 6174 206f 7220  "x2"]: float or 
-00017060: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-00017070: 205b 6e5f 6772 6964 5d0d 0a20 2020 2020   [n_grid]..     
-00017080: 2020 2053 6563 6f6e 6420 7061 7261 6d65     Second parame
-00017090: 7465 7220 6465 6669 6e65 6420 696e 205b  ter defined in [
-000170a0: 2d70 692c 2070 695d 0d0a 2020 2020 705b  -pi, pi]..    p[
-000170b0: 2278 3322 5d3a 2066 6c6f 6174 206f 7220  "x3"]: float or 
-000170c0: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-000170d0: 205b 6e5f 6772 6964 5d0d 0a20 2020 2020   [n_grid]..     
-000170e0: 2020 2054 6869 7264 2070 6172 616d 6574     Third paramet
-000170f0: 6572 2064 6566 696e 6564 2069 6e20 5b2d  er defined in [-
-00017100: 7069 2c20 7069 5d0d 0a20 2020 2070 5b22  pi, pi]..    p["
-00017110: 6122 5d3a 2066 6c6f 6174 0d0a 2020 2020  a"]: float..    
-00017120: 2020 2020 7368 6170 6520 7061 7261 6d65      shape parame
-00017130: 7465 7220 2861 3d37 290d 0a20 2020 2070  ter (a=7)..    p
-00017140: 5b22 6222 5d3a 2066 6c6f 6174 0d0a 2020  ["b"]: float..  
-00017150: 2020 2020 2020 7368 6170 6520 7061 7261        shape para
-00017160: 6d65 7465 7220 2862 3d30 2e31 290d 0a0d  meter (b=0.1)...
-00017170: 0a20 2020 2052 6574 7572 6e73 0d0a 2020  .    Returns..  
-00017180: 2020 2d2d 2d2d 2d2d 2d0d 0a20 2020 2079    -------..    y
-00017190: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
-000171a0: 6174 205b 6e5f 6772 6964 2078 2031 5d0d  at [n_grid x 1].
-000171b0: 0a20 2020 2020 2020 204f 7574 7075 7420  .        Output 
-000171c0: 6461 7461 0d0a 0d0a 2020 2020 4e6f 7465  data....    Note
-000171d0: 730d 0a20 2020 202d 2d2d 2d2d 0d0a 2020  s..    -----..  
-000171e0: 2020 2e2e 2070 6c6f 743a 3a0d 0a0d 0a20    .. plot::.... 
-000171f0: 2020 2020 2020 696d 706f 7274 206e 756d        import num
-00017200: 7079 2061 7320 6e70 0d0a 2020 2020 2020  py as np..      
-00017210: 2066 726f 6d20 7079 6770 632e 7465 7374   from pygpc.test
-00017220: 6675 6e63 7469 6f6e 7320 696d 706f 7274  functions import
-00017230: 2070 6c6f 745f 7465 7374 6675 6e63 7469   plot_testfuncti
-00017240: 6f6e 2061 7320 706c 6f74 0d0a 2020 2020  on as plot..    
-00017250: 2020 2066 726f 6d20 636f 6c6c 6563 7469     from collecti
-00017260: 6f6e 7320 696d 706f 7274 204f 7264 6572  ons import Order
-00017270: 6564 4469 6374 0d0a 0d0a 2020 2020 2020  edDict....      
-00017280: 2070 6172 616d 6574 6572 7320 3d20 4f72   parameters = Or
-00017290: 6465 7265 6444 6963 7428 290d 0a20 2020  deredDict()..   
-000172a0: 2020 2020 7061 7261 6d65 7465 7273 5b22      parameters["
-000172b0: 7831 225d 203d 206e 702e 6c69 6e73 7061  x1"] = np.linspa
-000172c0: 6365 282d 6e70 2e70 692c 206e 702e 7069  ce(-np.pi, np.pi
-000172d0: 2c20 3130 3029 0d0a 2020 2020 2020 2070  , 100)..       p
-000172e0: 6172 616d 6574 6572 735b 2278 3222 5d20  arameters["x2"] 
-000172f0: 3d20 6e70 2e6c 696e 7370 6163 6528 2d6e  = np.linspace(-n
-00017300: 702e 7069 2c20 6e70 2e70 692c 2031 3030  p.pi, np.pi, 100
-00017310: 290d 0a0d 0a20 2020 2020 2020 636f 6e73  )....       cons
-00017320: 7461 6e74 7320 3d20 4f72 6465 7265 6444  tants = OrderedD
-00017330: 6963 7428 290d 0a20 2020 2020 2020 636f  ict()..       co
-00017340: 6e73 7461 6e74 735b 2261 225d 203d 2037  nstants["a"] = 7
-00017350: 2e0d 0a20 2020 2020 2020 636f 6e73 7461  ...       consta
-00017360: 6e74 735b 2262 225d 203d 2030 2e31 0d0a  nts["b"] = 0.1..
-00017370: 2020 2020 2020 2063 6f6e 7374 616e 7473         constants
-00017380: 5b22 7833 225d 203d 2030 2e0d 0a0d 0a20  ["x3"] = 0..... 
-00017390: 2020 2020 2020 706c 6f74 2822 4973 6869        plot("Ishi
-000173a0: 6761 6d69 222c 2070 6172 616d 6574 6572  gami", parameter
-000173b0: 732c 2063 6f6e 7374 616e 7473 2c20 706c  s, constants, pl
-000173c0: 6f74 5f33 643d 4661 6c73 6529 0d0a 0d0a  ot_3d=False)....
-000173d0: 2020 2020 2e2e 205b 315d 2049 7368 6967      .. [1] Ishig
-000173e0: 616d 692c 2054 2e2c 2048 6f6d 6d61 2c20  ami, T., Homma, 
-000173f0: 542e 2028 3139 3930 2c20 4465 6365 6d62  T. (1990, Decemb
-00017400: 6572 292e 2041 6e20 696d 706f 7274 616e  er). An importan
-00017410: 6365 2071 7561 6e74 6966 6963 6174 696f  ce quantificatio
-00017420: 6e0d 0a20 2020 2020 2020 7465 6368 6e69  n..       techni
-00017430: 7175 6520 696e 2075 6e63 6572 7461 696e  que in uncertain
-00017440: 7479 2061 6e61 6c79 7369 7320 666f 7220  ty analysis for 
-00017450: 636f 6d70 7574 6572 206d 6f64 656c 732e  computer models.
-00017460: 2049 6e20 556e 6365 7274 6169 6e74 790d   In Uncertainty.
-00017470: 0a20 2020 2020 2020 4d6f 6465 6c69 6e67  .       Modeling
-00017480: 2061 6e64 2041 6e61 6c79 7369 732c 2031   and Analysis, 1
-00017490: 3939 302e 2050 726f 6365 6564 696e 6773  990. Proceedings
-000174a0: 2e2c 2046 6972 7374 2049 6e74 6572 6e61  ., First Interna
-000174b0: 7469 6f6e 616c 2053 796d 706f 7369 756d  tional Symposium
-000174c0: 0d0a 2020 2020 2020 206f 6e20 2870 702e  ..       on (pp.
-000174d0: 2033 3938 2d34 3033 292e 2049 4545 452e   398-403). IEEE.
-000174e0: 0d0a 0d0a 2020 2020 2e2e 205b 325d 2053  ....    .. [2] S
-000174f0: 6f62 6f6c 272c 2049 2e4d 2e2c 204c 6576  obol', I.M., Lev
-00017500: 6974 616e 2c20 592e 4c2e 2028 3139 3939  itan, Y.L. (1999
-00017510: 292e 204f 6e20 7468 6520 7573 6520 6f66  ). On the use of
-00017520: 2076 6172 6961 6e63 6520 7265 6475 6369   variance reduci
-00017530: 6e67 0d0a 2020 2020 2020 206d 756c 7469  ng..       multi
-00017540: 706c 6965 7273 2069 6e20 4d6f 6e74 6520  pliers in Monte 
-00017550: 4361 726c 6f20 636f 6d70 7574 6174 696f  Carlo computatio
-00017560: 6e73 206f 6620 6120 676c 6f62 616c 2073  ns of a global s
-00017570: 656e 7369 7469 7669 7479 2069 6e64 6578  ensitivity index
-00017580: 2e0d 0a20 2020 2020 2020 436f 6d70 7574  ...       Comput
-00017590: 6572 2050 6879 7369 6373 2043 6f6d 6d75  er Physics Commu
-000175a0: 6e69 6361 7469 6f6e 732c 2031 3137 2831  nications, 117(1
-000175b0: 292c 2035 322d 3631 2e0d 0a0d 0a20 2020  ), 52-61.....   
-000175c0: 202e 2e20 5b33 5d20 4372 6573 7461 7578   .. [3] Crestaux
-000175d0: 2c20 542e 2c20 4d61 7274 696e 657a 2c20  , T., Martinez, 
-000175e0: 4a2e 2d4d 2e2c 204c 6520 4d61 6974 7265  J.-M., Le Maitre
-000175f0: 2c20 4f2e 2c20 2620 4c61 6669 7474 652c  , O., & Lafitte,
-00017600: 204f 2e20 2832 3030 3729 2e0d 0a20 2020   O. (2007)...   
-00017610: 2020 2020 506f 6c79 6e6f 6d69 616c 2063      Polynomial c
-00017620: 6861 6f73 2065 7870 616e 7369 6f6e 2066  haos expansion f
-00017630: 6f72 2075 6e63 6572 7461 696e 7469 6573  or uncertainties
-00017640: 2071 7561 6e74 6966 6963 6174 696f 6e20   quantification 
-00017650: 616e 6420 7365 6e73 6974 6976 6974 7920  and sensitivity 
-00017660: 616e 616c 7973 6973 205b 506f 7765 7250  analysis [PowerP
-00017670: 6f69 6e74 2073 6c69 6465 735d 2e0d 0a20  oint slides]... 
-00017680: 2020 2020 2020 5265 7472 6965 7665 6420        Retrieved 
-00017690: 6672 6f6d 2053 414d 4f20 3230 3037 2077  from SAMO 2007 w
-000176a0: 6562 7369 7465 3a20 6874 7470 3a2f 2f73  ebsite: http://s
-000176b0: 616d 6f32 3030 372e 6368 656d 2e65 6c74  amo2007.chem.elt
-000176c0: 652e 6875 2f6c 6563 7475 7265 732f 4372  e.hu/lectures/Cr
-000176d0: 6573 7461 7578 2e70 6466 2e0d 0a0d 0a20  estaux.pdf..... 
-000176e0: 2020 202e 2e20 5b34 5d20 4d61 7272 656c     .. [4] Marrel
-000176f0: 2c20 412e 2c20 496f 6f73 732c 2042 2e2c  , A., Iooss, B.,
-00017700: 204c 6175 7265 6e74 2c20 422e 2c20 2620   Laurent, B., & 
-00017710: 526f 7573 7461 6e74 2c20 4f2e 2028 3230  Roustant, O. (20
-00017720: 3039 292e 0d0a 2020 2020 2020 2043 616c  09)...       Cal
-00017730: 6375 6c61 7469 6f6e 7320 6f66 2073 6f62  culations of sob
-00017740: 6f6c 2069 6e64 6963 6573 2066 6f72 2074  ol indices for t
-00017750: 6865 2067 6175 7373 6961 6e20 7072 6f63  he gaussian proc
-00017760: 6573 7320 6d65 7461 6d6f 6465 6c2e 0d0a  ess metamodel...
-00017770: 2020 2020 2020 2052 656c 6961 6269 6c69         Reliabili
-00017780: 7479 2045 6e67 696e 6565 7269 6e67 2026  ty Engineering &
-00017790: 2053 7973 7465 6d20 5361 6665 7479 2c20   System Safety, 
-000177a0: 3934 2833 292c 2037 3432 2d37 3531 2e0d  94(3), 742-751..
-000177b0: 0a20 2020 2022 2222 0d0a 0d0a 2020 2020  .    """....    
-000177c0: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
-000177d0: 662c 206d 6174 6c61 625f 6d6f 6465 6c3d  f, matlab_model=
-000177e0: 4661 6c73 6529 3a0d 0a20 2020 2020 2020  False):..       
-000177f0: 2073 7570 6572 2874 7970 6528 7365 6c66   super(type(self
-00017800: 292c 2073 656c 6629 2e5f 5f69 6e69 745f  ), self).__init_
-00017810: 5f28 6d61 746c 6162 5f6d 6f64 656c 3d6d  _(matlab_model=m
-00017820: 6174 6c61 625f 6d6f 6465 6c29 0d0a 2020  atlab_model)..  
-00017830: 2020 2020 2020 7365 6c66 2e66 6e61 6d65        self.fname
-00017840: 203d 2069 6e73 7065 6374 2e67 6574 6669   = inspect.getfi
-00017850: 6c65 2869 6e73 7065 6374 2e63 7572 7265  le(inspect.curre
-00017860: 6e74 6672 616d 6528 2929 0d0a 0d0a 2020  ntframe())....  
-00017870: 2020 6465 6620 7661 6c69 6461 7465 2873    def validate(s
-00017880: 656c 6629 3a0d 0a20 2020 2020 2020 2070  elf):..        p
-00017890: 6173 730d 0a0d 0a20 2020 2064 6566 2073  ass....    def s
-000178a0: 696d 756c 6174 6528 7365 6c66 2c20 7072  imulate(self, pr
-000178b0: 6f63 6573 735f 6964 3d4e 6f6e 652c 206d  ocess_id=None, m
-000178c0: 6174 6c61 625f 656e 6769 6e65 3d4e 6f6e  atlab_engine=Non
-000178d0: 6529 3a0d 0a0d 0a20 2020 2020 2020 2069  e):....        i
-000178e0: 6620 7365 6c66 2e70 5b22 7831 225d 2069  f self.p["x1"] i
-000178f0: 7320 6e6f 7420 6e70 2e6e 6461 7272 6179  s not np.ndarray
-00017900: 3a0d 0a20 2020 2020 2020 2020 2020 2073  :..            s
-00017910: 656c 662e 705b 2278 3122 5d20 3d20 6e70  elf.p["x1"] = np
-00017920: 2e61 7272 6179 2873 656c 662e 705b 2278  .array(self.p["x
-00017930: 3122 5d29 0d0a 0d0a 2020 2020 2020 2020  1"])....        
-00017940: 6966 2073 656c 662e 705b 2278 3222 5d20  if self.p["x2"] 
-00017950: 6973 206e 6f74 206e 702e 6e64 6172 7261  is not np.ndarra
-00017960: 793a 0d0a 2020 2020 2020 2020 2020 2020  y:..            
-00017970: 7365 6c66 2e70 5b22 7832 225d 203d 206e  self.p["x2"] = n
-00017980: 702e 6172 7261 7928 7365 6c66 2e70 5b22  p.array(self.p["
-00017990: 7832 225d 290d 0a0d 0a20 2020 2020 2020  x2"])....       
-000179a0: 2069 6620 7365 6c66 2e70 5b22 7833 225d   if self.p["x3"]
-000179b0: 2069 7320 6e6f 7420 6e70 2e6e 6461 7272   is not np.ndarr
-000179c0: 6179 3a0d 0a20 2020 2020 2020 2020 2020  ay:..           
-000179d0: 2073 656c 662e 705b 2278 3322 5d20 3d20   self.p["x3"] = 
-000179e0: 6e70 2e61 7272 6179 2873 656c 662e 705b  np.array(self.p[
-000179f0: 2278 3322 5d29 0d0a 0d0a 2020 2020 2020  "x3"])....      
-00017a00: 2020 6966 2073 656c 662e 705b 2261 225d    if self.p["a"]
-00017a10: 2069 7320 6e6f 7420 6e70 2e6e 6461 7272   is not np.ndarr
-00017a20: 6179 3a0d 0a20 2020 2020 2020 2020 2020  ay:..           
-00017a30: 2073 656c 662e 705b 2261 225d 203d 206e   self.p["a"] = n
-00017a40: 702e 6172 7261 7928 7365 6c66 2e70 5b22  p.array(self.p["
-00017a50: 6122 5d29 0d0a 0d0a 2020 2020 2020 2020  a"])....        
-00017a60: 6966 2073 656c 662e 705b 2262 225d 2069  if self.p["b"] i
-00017a70: 7320 6e6f 7420 6e70 2e6e 6461 7272 6179  s not np.ndarray
-00017a80: 3a0d 0a20 2020 2020 2020 2020 2020 2073  :..            s
-00017a90: 656c 662e 705b 2262 225d 203d 206e 702e  elf.p["b"] = np.
-00017aa0: 6172 7261 7928 7365 6c66 2e70 5b22 6222  array(self.p["b"
-00017ab0: 5d29 0d0a 0d0a 2020 2020 2020 2020 7920  ])....        y 
-00017ac0: 3d20 286e 702e 7369 6e28 7365 6c66 2e70  = (np.sin(self.p
-00017ad0: 5b22 7831 225d 2e66 6c61 7474 656e 2829  ["x1"].flatten()
-00017ae0: 2920 2b20 7365 6c66 2e70 5b22 6122 5d2e  ) + self.p["a"].
-00017af0: 666c 6174 7465 6e28 2920 2a20 6e70 2e73  flatten() * np.s
-00017b00: 696e 2873 656c 662e 705b 2278 3222 5d2e  in(self.p["x2"].
-00017b10: 666c 6174 7465 6e28 2929 202a 2a20 320d  flatten()) ** 2.
-00017b20: 0a20 2020 2020 2020 2020 2020 2020 2b20  .             + 
-00017b30: 7365 6c66 2e70 5b22 6222 5d2e 666c 6174  self.p["b"].flat
-00017b40: 7465 6e28 2920 2a20 7365 6c66 2e70 5b22  ten() * self.p["
-00017b50: 7833 225d 2e66 6c61 7474 656e 2829 202a  x3"].flatten() *
-00017b60: 2a20 3420 2a20 6e70 2e73 696e 2873 656c  * 4 * np.sin(sel
-00017b70: 662e 705b 2278 3122 5d2e 666c 6174 7465  f.p["x1"].flatte
-00017b80: 6e28 2929 290d 0a0d 0a20 2020 2020 2020  n()))....       
-00017b90: 2069 6620 7479 7065 2879 2920 6973 206e   if type(y) is n
-00017ba0: 6f74 206e 702e 6e64 6172 7261 793a 0d0a  ot np.ndarray:..
-00017bb0: 2020 2020 2020 2020 2020 2020 7920 3d20              y = 
-00017bc0: 6e70 2e61 7272 6179 285b 795d 290d 0a0d  np.array([y])...
-00017bd0: 0a20 2020 2020 2020 2079 5f6f 7574 203d  .        y_out =
-00017be0: 2079 5b3a 2c20 6e70 2e6e 6577 6178 6973   y[:, np.newaxis
-00017bf0: 5d0d 0a0d 0a20 2020 2020 2020 2023 2069  ]....        # i
-00017c00: 6e73 6572 7420 736f 6d65 204e 614e 2076  nsert some NaN v
-00017c10: 616c 7565 7320 666f 7220 7465 7374 696e  alues for testin
-00017c20: 670d 0a20 2020 2020 2020 206d 6173 6b20  g..        mask 
-00017c30: 3d20 2873 656c 662e 705b 2278 3122 5d20  = (self.p["x1"] 
-00017c40: 3e20 3229 2e66 6c61 7474 656e 2829 0d0a  > 2).flatten()..
-00017c50: 2020 2020 2020 2020 795f 6f75 745b 6d61          y_out[ma
-00017c60: 736b 2c20 305d 203d 206e 702e 4e61 4e0d  sk, 0] = np.NaN.
-00017c70: 0a0d 0a20 2020 2020 2020 2072 6574 7572  ...        retur
-00017c80: 6e20 795f 6f75 740d 0a0d 0a0d 0a63 6c61  n y_out......cla
-00017c90: 7373 2047 4675 6e63 7469 6f6e 2841 6273  ss GFunction(Abs
-00017ca0: 7472 6163 744d 6f64 656c 293a 0d0a 2020  tractModel):..  
-00017cb0: 2020 2222 220d 0a20 2020 204e 2d64 696d    """..    N-dim
-00017cc0: 656e 7369 6f6e 616c 2067 2d66 756e 6374  ensional g-funct
-00017cd0: 696f 6e20 7573 6564 2062 7920 5361 6c74  ion used by Salt
-00017ce0: 656c 6c69 2061 6e64 2053 6f62 6f6c 2028  elli and Sobol (
-00017cf0: 3139 3935 2920 5b31 5d2e 0d0a 0d0a 2020  1995) [1].....  
-00017d00: 2020 5468 6973 2074 6573 7420 6675 6e63    This test func
-00017d10: 7469 6f6e 2069 7320 7573 6564 2061 7320  tion is used as 
-00017d20: 616e 2069 6e74 6567 7261 6e64 2066 6f72  an integrand for
-00017d30: 2076 6172 696f 7573 206e 756d 6572 6963   various numeric
-00017d40: 616c 0d0a 2020 2020 6573 7469 6d61 7469  al..    estimati
-00017d50: 6f6e 206d 6574 686f 6473 2c20 696e 636c  on methods, incl
-00017d60: 7564 696e 6720 7365 6e73 6974 6976 6974  uding sensitivit
-00017d70: 7920 616e 616c 7973 6973 206d 6574 686f  y analysis metho
-00017d80: 6473 2c20 6265 6361 7573 6520 6974 0d0a  ds, because it..
-00017d90: 2020 2020 6973 2066 6169 726c 7920 636f      is fairly co
-00017da0: 6d70 6c65 782c 2061 6e64 2069 7473 2073  mplex, and its s
-00017db0: 656e 7369 7469 7669 7479 2069 6e64 6963  ensitivity indic
-00017dc0: 6573 2063 616e 2062 6520 6578 7072 6573  es can be expres
-00017dd0: 7365 640d 0a20 2020 2061 6e61 6c79 7469  sed..    analyti
-00017de0: 6361 6c6c 792e 2054 6865 2065 7861 6374  cally. The exact
-00017df0: 2076 616c 7565 206f 6620 7468 6520 696e   value of the in
-00017e00: 7465 6772 616c 2077 6974 6820 7468 6973  tegral with this
-00017e10: 2066 756e 6374 696f 6e20 6173 2061 6e0d   function as an.
-00017e20: 0a20 2020 2069 6e74 6567 7261 6e64 2069  .    integrand i
-00017e30: 7320 312e 2046 6f72 2065 6163 6820 696e  s 1. For each in
-00017e40: 6465 7820 692c 2061 206c 6f77 6572 2076  dex i, a lower v
-00017e50: 616c 7565 206f 6620 615f 6920 696e 6469  alue of a_i indi
-00017e60: 6361 7465 7320 6120 6869 6768 6572 0d0a  cates a higher..
-00017e70: 2020 2020 696d 706f 7274 616e 6365 206f      importance o
-00017e80: 6620 7468 6520 696e 7075 7420 7661 7269  f the input vari
-00017e90: 6162 6c65 2078 692e 0d0a 0d0a 2020 2020  able xi.....    
-00017ea0: 2e2e 206d 6174 683a 3a20 5c70 726f 645f  .. math:: \prod_
-00017eb0: 7b69 3d31 7d5e 7b4e 7d5c 5c66 7261 637b  {i=1}^{N}\\frac{
-00017ec0: 7c34 2078 5f69 202d 2032 7c20 2b20 615f  |4 x_i - 2| + a_
-00017ed0: 697d 7b31 202b 2061 5f69 7d0d 0a0d 0a20  i}{1 + a_i}.... 
-00017ee0: 2020 2054 6865 2072 6563 6f6d 6d65 6e64     The recommend
-00017ef0: 6564 2076 616c 7565 7320 6f66 2061 5f69  ed values of a_i
-00017f00: 2062 7920 4372 6573 7461 7578 2065 7420   by Crestaux et 
-00017f10: 616c 2e20 2832 3030 3729 205b 325d 2061  al. (2007) [2] a
-00017f20: 7265 3a0d 0a0d 0a20 2020 202e 2e20 6d61  re:....    .. ma
-00017f30: 7468 3a3a 2061 5f69 203d 205c 5c66 7261  th:: a_i = \\fra
-00017f40: 637b 692d 327d 7b32 7d20 5c71 7561 6420  c{i-2}{2} \quad 
-00017f50: 5c6d 6174 6872 6d7b 666f 725c 3b61 6c6c  \mathrm{for\;all
-00017f60: 7d20 5c71 7561 6420 693d 312c 2e2e 2e2c  } \quad i=1,...,
-00017f70: 640d 0a0d 0a20 2020 2050 6172 616d 6574  d....    Paramet
-00017f80: 6572 730d 0a20 2020 202d 2d2d 2d2d 2d2d  ers..    -------
-00017f90: 2d2d 2d0d 0a20 2020 2070 5b22 7831 225d  ---..    p["x1"]
-00017fa0: 3a20 666c 6f61 7420 6f72 206e 6461 7272  : float or ndarr
-00017fb0: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
-00017fc0: 7269 645d 0d0a 2020 2020 2020 2020 4669  rid]..        Fi
-00017fd0: 7273 7420 7061 7261 6d65 7465 7220 5b30  rst parameter [0
-00017fe0: 2c20 315d 0d0a 2020 2020 705b 2278 6922  , 1]..    p["xi"
-00017ff0: 5d3a 2066 6c6f 6174 206f 7220 6e64 6172  ]: float or ndar
-00018000: 7261 7920 6f66 2066 6c6f 6174 205b 6e5f  ray of float [n_
-00018010: 6772 6964 5d0d 0a20 2020 2020 2020 2069  grid]..        i
-00018020: 2d74 6820 7061 7261 6d65 7465 7220 6465  -th parameter de
-00018030: 6669 6e65 6420 696e 205b 302c 2031 5d0d  fined in [0, 1].
-00018040: 0a20 2020 2070 5b22 784e 225d 3a20 666c  .    p["xN"]: fl
-00018050: 6f61 7420 6f72 206e 6461 7272 6179 206f  oat or ndarray o
-00018060: 6620 666c 6f61 7420 5b6e 5f67 7269 645d  f float [n_grid]
-00018070: 0d0a 2020 2020 2020 2020 4e74 6820 7061  ..        Nth pa
-00018080: 7261 6d65 7465 7220 5b30 2c20 315d 0d0a  rameter [0, 1]..
-00018090: 2020 2020 705b 2261 225d 3a20 6e64 6172      p["a"]: ndar
-000180a0: 7261 7920 6f66 2066 6c6f 6174 205b 4e5f  ray of float [N_
-000180b0: 6469 6d73 5d0d 0a20 2020 2020 2020 2049  dims]..        I
-000180c0: 6d70 6f72 7461 6e63 6520 6661 6374 6f72  mportance factor
-000180d0: 7320 6f66 2064 696d 656e 7369 6f6e 730d  s of dimensions.
-000180e0: 0a0d 0a20 2020 2052 6574 7572 6e73 0d0a  ...    Returns..
-000180f0: 2020 2020 2d2d 2d2d 2d2d 2d0d 0a20 2020      -------..   
-00018100: 2079 3a20 6e64 6172 7261 7920 6f66 2066   y: ndarray of f
-00018110: 6c6f 6174 205b 4e5f 696e 7075 7420 7820  loat [N_input x 
-00018120: 315d 0d0a 2020 2020 2020 2020 4f75 7470  1]..        Outp
-00018130: 7574 2064 6174 610d 0a0d 0a20 2020 204e  ut data....    N
-00018140: 6f74 6573 0d0a 2020 2020 2d2d 2d2d 2d0d  otes..    -----.
-00018150: 0a20 2020 202e 2e20 706c 6f74 3a3a 0d0a  .    .. plot::..
-00018160: 0d0a 2020 2020 2020 2069 6d70 6f72 7420  ..       import 
-00018170: 6e75 6d70 7920 6173 206e 700d 0a20 2020  numpy as np..   
-00018180: 2020 2020 6672 6f6d 2070 7967 7063 2e74      from pygpc.t
-00018190: 6573 7466 756e 6374 696f 6e73 2069 6d70  estfunctions imp
-000181a0: 6f72 7420 706c 6f74 5f74 6573 7466 756e  ort plot_testfun
-000181b0: 6374 696f 6e20 6173 2070 6c6f 740d 0a20  ction as plot.. 
-000181c0: 2020 2020 2020 6672 6f6d 2063 6f6c 6c65        from colle
-000181d0: 6374 696f 6e73 2069 6d70 6f72 7420 4f72  ctions import Or
-000181e0: 6465 7265 6444 6963 740d 0a0d 0a20 2020  deredDict....   
-000181f0: 2020 2020 7061 7261 6d65 7465 7273 203d      parameters =
-00018200: 204f 7264 6572 6564 4469 6374 2829 0d0a   OrderedDict()..
-00018210: 2020 2020 2020 2070 6172 616d 6574 6572         parameter
-00018220: 735b 2278 3122 5d20 3d20 6e70 2e6c 696e  s["x1"] = np.lin
-00018230: 7370 6163 6528 302c 2031 2c20 3130 3029  space(0, 1, 100)
-00018240: 0d0a 2020 2020 2020 2070 6172 616d 6574  ..       paramet
-00018250: 6572 735b 2278 3222 5d20 3d20 6e70 2e6c  ers["x2"] = np.l
-00018260: 696e 7370 6163 6528 302c 2031 2c20 3130  inspace(0, 1, 10
-00018270: 3029 0d0a 0d0a 2020 2020 2020 2063 6f6e  0)....       con
-00018280: 7374 616e 7473 203d 204f 7264 6572 6564  stants = Ordered
-00018290: 4469 6374 2829 0d0a 2020 2020 2020 2063  Dict()..       c
-000182a0: 6f6e 7374 616e 7473 5b22 6122 5d20 3d20  onstants["a"] = 
-000182b0: 2028 6e70 2e61 7261 6e67 6528 3229 2b31   (np.arange(2)+1
-000182c0: 2d32 2e29 2f32 2e0d 0a0d 0a20 2020 2020  -2.)/2.....     
-000182d0: 2020 706c 6f74 2822 4746 756e 6374 696f    plot("GFunctio
-000182e0: 6e22 2c20 7061 7261 6d65 7465 7273 2c20  n", parameters, 
-000182f0: 636f 6e73 7461 6e74 732c 2070 6c6f 745f  constants, plot_
-00018300: 3364 3d46 616c 7365 290d 0a0d 0a20 2020  3d=False)....   
-00018310: 202e 2e20 5b31 5d20 5361 6c74 656c 6c69   .. [1] Saltelli
-00018320: 2c20 416e 6472 6561 3b20 536f 626f 6c2c  , Andrea; Sobol,
-00018330: 2049 2e20 4d2e 2028 3139 3935 293a 2053   I. M. (1995): S
-00018340: 656e 7369 7469 7669 7479 2061 6e61 6c79  ensitivity analy
-00018350: 7369 7320 666f 7220 6e6f 6e6c 696e 6561  sis for nonlinea
-00018360: 720d 0a20 2020 2020 2020 6d61 7468 656d  r..       mathem
-00018370: 6174 6963 616c 206d 6f64 656c 733a 206e  atical models: n
-00018380: 756d 6572 6963 616c 2065 7870 6572 6965  umerical experie
-00018390: 6e63 652e 2049 6e3a 204d 6174 6865 6d61  nce. In: Mathema
-000183a0: 7469 6361 6c20 6d6f 6465 6c73 2061 6e64  tical models and
-000183b0: 0d0a 2020 2020 2020 2063 6f6d 7075 7465  ..       compute
-000183c0: 7220 6578 7065 7269 6d65 6e74 2037 2028  r experiment 7 (
-000183d0: 3131 292c 2070 702e 2031 362d 3238 2e0d  11), pp. 16-28..
-000183e0: 0a0d 0a20 2020 202e 2e20 5b32 5d20 4372  ...    .. [2] Cr
-000183f0: 6573 7461 7578 2c20 542e 2c20 4d61 7274  estaux, T., Mart
-00018400: 696e 657a 2c20 4a2e 2d4d 2e2c 204c 6520  inez, J.-M., Le 
-00018410: 4d61 6974 7265 2c20 4f2e 2c20 2620 4c61  Maitre, O., & La
-00018420: 6669 7474 652c 204f 2e20 2832 3030 3729  fitte, O. (2007)
-00018430: 2e0d 0a20 2020 2020 2020 506f 6c79 6e6f  ...       Polyno
-00018440: 6d69 616c 2063 6861 6f73 2065 7870 616e  mial chaos expan
-00018450: 7369 6f6e 2066 6f72 2075 6e63 6572 7461  sion for uncerta
-00018460: 696e 7469 6573 2071 7561 6e74 6966 6963  inties quantific
-00018470: 6174 696f 6e20 616e 6420 7365 6e73 6974  ation and sensit
-00018480: 6976 6974 7920 616e 616c 7973 6973 205b  ivity analysis [
-00018490: 506f 7765 7250 6f69 6e74 2073 6c69 6465  PowerPoint slide
-000184a0: 735d 2e0d 0a20 2020 2020 2020 5265 7472  s]...       Retr
-000184b0: 6965 7665 6420 6672 6f6d 2053 414d 4f20  ieved from SAMO 
-000184c0: 3230 3037 2077 6562 7369 7465 3a20 6874  2007 website: ht
-000184d0: 7470 3a2f 2f73 616d 6f32 3030 372e 6368  tp://samo2007.ch
-000184e0: 656d 2e65 6c74 652e 6875 2f6c 6563 7475  em.elte.hu/lectu
-000184f0: 7265 732f 4372 6573 7461 7578 2e70 6466  res/Crestaux.pdf
-00018500: 2e0d 0a20 2020 2022 2222 0d0a 0d0a 2020  ...    """....  
-00018510: 2020 6465 6620 5f5f 696e 6974 5f5f 2873    def __init__(s
-00018520: 656c 662c 206d 6174 6c61 625f 6d6f 6465  elf, matlab_mode
-00018530: 6c3d 4661 6c73 6529 3a0d 0a20 2020 2020  l=False):..     
-00018540: 2020 2073 7570 6572 2874 7970 6528 7365     super(type(se
-00018550: 6c66 292c 2073 656c 6629 2e5f 5f69 6e69  lf), self).__ini
-00018560: 745f 5f28 6d61 746c 6162 5f6d 6f64 656c  t__(matlab_model
-00018570: 3d6d 6174 6c61 625f 6d6f 6465 6c29 0d0a  =matlab_model)..
-00018580: 2020 2020 2020 2020 7365 6c66 2e66 6e61          self.fna
-00018590: 6d65 203d 2069 6e73 7065 6374 2e67 6574  me = inspect.get
-000185a0: 6669 6c65 2869 6e73 7065 6374 2e63 7572  file(inspect.cur
-000185b0: 7265 6e74 6672 616d 6528 2929 0d0a 0d0a  rentframe())....
-000185c0: 2020 2020 6465 6620 7661 6c69 6461 7465      def validate
-000185d0: 2873 656c 6629 3a0d 0a20 2020 2020 2020  (self):..       
-000185e0: 2070 6173 730d 0a0d 0a20 2020 2064 6566   pass....    def
-000185f0: 2073 696d 756c 6174 6528 7365 6c66 2c20   simulate(self, 
-00018600: 7072 6f63 6573 735f 6964 3d4e 6f6e 652c  process_id=None,
-00018610: 206d 6174 6c61 625f 656e 6769 6e65 3d4e   matlab_engine=N
-00018620: 6f6e 6529 3a0d 0a20 2020 2020 2020 2023  one):..        #
-00018630: 2064 6574 6572 6d69 6e65 206f 7574 7075   determine outpu
-00018640: 740d 0a20 2020 2020 2020 2079 203d 206e  t..        y = n
-00018650: 702e 6f6e 6573 286e 702e 6172 7261 7928  p.ones(np.array(
-00018660: 7365 6c66 2e70 5b6c 6973 7428 7365 6c66  self.p[list(self
-00018670: 2e70 2e6b 6579 7328 2929 5b30 5d5d 292e  .p.keys())[0]]).
-00018680: 7369 7a65 290d 0a0d 0a20 2020 2020 2020  size)....       
-00018690: 2066 6f72 2069 2c20 6b65 7920 696e 2065   for i, key in e
-000186a0: 6e75 6d65 7261 7465 2873 656c 662e 702e  numerate(self.p.
-000186b0: 6b65 7973 2829 293a 0d0a 2020 2020 2020  keys()):..      
-000186c0: 2020 2020 2020 6966 2022 7822 2069 6e20        if "x" in 
-000186d0: 6b65 793a 0d0a 2020 2020 2020 2020 2020  key:..          
-000186e0: 2020 2020 2020 7920 2a3d 2028 6e70 2e61        y *= (np.a
-000186f0: 6273 2834 2e30 202a 2073 656c 662e 705b  bs(4.0 * self.p[
-00018700: 6b65 795d 202d 2032 2920 2b20 7365 6c66  key] - 2) + self
-00018710: 2e70 5b22 6122 5d5b 3a2c 2069 5d29 202f  .p["a"][:, i]) /
-00018720: 2028 312e 3020 2b20 7365 6c66 2e70 5b22   (1.0 + self.p["
-00018730: 6122 5d5b 3a2c 2069 5d29 0d0a 0d0a 2020  a"][:, i])....  
-00018740: 2020 2020 2020 795f 6f75 7420 3d20 795b        y_out = y[
-00018750: 3a2c 206e 702e 6e65 7761 7869 735d 0d0a  :, np.newaxis]..
-00018760: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-00018770: 2079 5f6f 7574 0d0a 0d0a 0d0a 636c 6173   y_out......clas
-00018780: 7320 4269 6e61 7279 4469 7363 6f6e 7469  s BinaryDisconti
-00018790: 6e75 6f75 7353 7068 6572 6528 4162 7374  nuousSphere(Abst
-000187a0: 7261 6374 4d6f 6465 6c29 3a0d 0a20 2020  ractModel):..   
-000187b0: 2022 2222 0d0a 2020 2020 4e2d 6469 6d65   """..    N-dime
-000187c0: 6e73 696f 6e61 6c20 7465 7374 6675 6e63  nsional testfunc
-000187d0: 7469 6f6e 2063 6f6e 7461 696e 696e 6720  tion containing 
-000187e0: 6120 7370 6865 7269 6361 6c20 6469 7363  a spherical disc
-000187f0: 6f6e 7469 6e75 6974 792e 0d0a 2020 2020  ontinuity...    
-00018800: 496e 7369 6465 2074 6865 2073 7068 6572  Inside the spher
-00018810: 6520 7468 6520 6f75 7470 7574 2069 7320  e the output is 
-00018820: 3220 616e 6420 6f75 7473 6964 6520 6f66  2 and outside of
-00018830: 2074 6865 2073 7068 6572 6520 6974 2069   the sphere it i
-00018840: 7320 312e 0d0a 0d0a 2020 2020 2e2e 206d  s 1.....    .. m
-00018850: 6174 683a 3a0d 0a20 2020 2020 2020 7920  ath::..       y 
-00018860: 3d20 5c5c 6265 6769 6e7b 6361 7365 737d  = \\begin{cases}
-00018870: 0d0a 2020 2020 2020 2032 2c20 2620 5c5c  ..       2, & \\
-00018880: 7465 7874 7b69 6620 7d20 5c5c 7371 7274  text{if } \\sqrt
-00018890: 7b5c 5c73 756d 5f7b 693d 317d 5e7b 4e7d  {\\sum_{i=1}^{N}
-000188a0: 2878 5f69 2d30 2e35 295e 327d 205c 5c6c  (x_i-0.5)^2} \\l
-000188b0: 6571 2030 2e32 3520 5c5c 5c5c 0d0a 2020  eq 0.25 \\\\..  
-000188c0: 2020 2020 2031 2c20 2620 5c5c 7465 7874       1, & \\text
-000188d0: 7b6f 7468 6572 7769 7365 7d0d 0a20 2020  {otherwise}..   
-000188e0: 2020 2020 5c5c 656e 647b 6361 7365 737d      \\end{cases}
-000188f0: 0d0a 0d0a 2020 2020 5061 7261 6d65 7465  ....    Paramete
-00018900: 7273 0d0a 2020 2020 2d2d 2d2d 2d2d 2d2d  rs..    --------
-00018910: 2d2d 0d0a 2020 2020 705b 2278 3122 5d3a  --..    p["x1"]:
-00018920: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
-00018930: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
-00018940: 6964 5d0d 0a20 2020 2020 2020 2046 6972  id]..        Fir
-00018950: 7374 2070 6172 616d 6574 6572 205b 302c  st parameter [0,
-00018960: 2031 5d0d 0a20 2020 2070 5b22 7869 225d   1]..    p["xi"]
-00018970: 3a20 666c 6f61 7420 6f72 206e 6461 7272  : float or ndarr
-00018980: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
-00018990: 7269 645d 0d0a 2020 2020 2020 2020 692d  rid]..        i-
-000189a0: 7468 2070 6172 616d 6574 6572 2064 6566  th parameter def
-000189b0: 696e 6564 2069 6e20 5b30 2c20 315d 0d0a  ined in [0, 1]..
-000189c0: 2020 2020 705b 2278 4e22 5d3a 2066 6c6f      p["xN"]: flo
-000189d0: 6174 206f 7220 6e64 6172 7261 7920 6f66  at or ndarray of
-000189e0: 2066 6c6f 6174 205b 6e5f 6772 6964 5d0d   float [n_grid].
-000189f0: 0a20 2020 2020 2020 204e 7468 2070 6172  .        Nth par
-00018a00: 616d 6574 6572 205b 302c 2031 5d0d 0a0d  ameter [0, 1]...
-00018a10: 0a20 2020 2052 6574 7572 6e73 0d0a 2020  .    Returns..  
-00018a20: 2020 2d2d 2d2d 2d2d 2d0d 0a20 2020 2079    -------..    y
-00018a30: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
-00018a40: 6174 205b 6e5f 6772 6964 2078 2031 5d0d  at [n_grid x 1].
-00018a50: 0a20 2020 2020 2020 204f 7574 7075 7420  .        Output 
-00018a60: 6461 7461 0d0a 0d0a 2020 2020 4e6f 7465  data....    Note
-00018a70: 730d 0a20 2020 202d 2d2d 2d2d 0d0a 2020  s..    -----..  
-00018a80: 2020 2e2e 2070 6c6f 743a 3a0d 0a0d 0a20    .. plot::.... 
-00018a90: 2020 2020 2020 696d 706f 7274 206e 756d        import num
-00018aa0: 7079 2061 7320 6e70 0d0a 2020 2020 2020  py as np..      
-00018ab0: 2066 726f 6d20 7079 6770 632e 7465 7374   from pygpc.test
-00018ac0: 6675 6e63 7469 6f6e 7320 696d 706f 7274  functions import
-00018ad0: 2070 6c6f 745f 7465 7374 6675 6e63 7469   plot_testfuncti
-00018ae0: 6f6e 2061 7320 706c 6f74 0d0a 2020 2020  on as plot..    
-00018af0: 2020 2066 726f 6d20 636f 6c6c 6563 7469     from collecti
-00018b00: 6f6e 7320 696d 706f 7274 204f 7264 6572  ons import Order
-00018b10: 6564 4469 6374 0d0a 0d0a 2020 2020 2020  edDict....      
-00018b20: 2070 6172 616d 6574 6572 7320 3d20 4f72   parameters = Or
-00018b30: 6465 7265 6444 6963 7428 290d 0a20 2020  deredDict()..   
-00018b40: 2020 2020 7061 7261 6d65 7465 7273 5b22      parameters["
-00018b50: 7831 225d 203d 206e 702e 6c69 6e73 7061  x1"] = np.linspa
-00018b60: 6365 2830 2c20 312c 2035 3030 290d 0a20  ce(0, 1, 500).. 
-00018b70: 2020 2020 2020 7061 7261 6d65 7465 7273        parameters
-00018b80: 5b22 7832 225d 203d 206e 702e 6c69 6e73  ["x2"] = np.lins
-00018b90: 7061 6365 2830 2c20 312c 2035 3030 290d  pace(0, 1, 500).
-00018ba0: 0a0d 0a20 2020 2020 2020 706c 6f74 2822  ...       plot("
-00018bb0: 4269 6e61 7279 4469 7363 6f6e 7469 6e75  BinaryDiscontinu
-00018bc0: 6f75 7353 7068 6572 6522 2c20 7061 7261  ousSphere", para
-00018bd0: 6d65 7465 7273 290d 0a20 2020 2022 2222  meters)..    """
-00018be0: 0d0a 0d0a 2020 2020 6465 6620 5f5f 696e  ....    def __in
-00018bf0: 6974 5f5f 2873 656c 662c 206d 6174 6c61  it__(self, matla
-00018c00: 625f 6d6f 6465 6c3d 4661 6c73 6529 3a0d  b_model=False):.
-00018c10: 0a20 2020 2020 2020 2073 7570 6572 2874  .        super(t
-00018c20: 7970 6528 7365 6c66 292c 2073 656c 6629  ype(self), self)
-00018c30: 2e5f 5f69 6e69 745f 5f28 6d61 746c 6162  .__init__(matlab
-00018c40: 5f6d 6f64 656c 3d6d 6174 6c61 625f 6d6f  _model=matlab_mo
-00018c50: 6465 6c29 0d0a 2020 2020 2020 2020 7365  del)..        se
-00018c60: 6c66 2e66 6e61 6d65 203d 2069 6e73 7065  lf.fname = inspe
-00018c70: 6374 2e67 6574 6669 6c65 2869 6e73 7065  ct.getfile(inspe
-00018c80: 6374 2e63 7572 7265 6e74 6672 616d 6528  ct.currentframe(
-00018c90: 2929 0d0a 0d0a 2020 2020 6465 6620 7661  ))....    def va
-00018ca0: 6c69 6461 7465 2873 656c 6629 3a0d 0a20  lidate(self):.. 
-00018cb0: 2020 2020 2020 2070 6173 730d 0a0d 0a20         pass.... 
-00018cc0: 2020 2064 6566 2073 696d 756c 6174 6528     def simulate(
-00018cd0: 7365 6c66 2c20 7072 6f63 6573 735f 6964  self, process_id
-00018ce0: 3d4e 6f6e 652c 206d 6174 6c61 625f 656e  =None, matlab_en
-00018cf0: 6769 6e65 3d4e 6f6e 6529 3a0d 0a0d 0a20  gine=None):.... 
-00018d00: 2020 2020 2020 2078 203d 206e 702e 7673         x = np.vs
-00018d10: 7461 636b 285b 7365 6c66 2e70 5b6b 6579  tack([self.p[key
-00018d20: 5d2e 7371 7565 657a 6528 2920 666f 7220  ].squeeze() for 
-00018d30: 6b65 7920 696e 2073 656c 662e 702e 6b65  key in self.p.ke
-00018d40: 7973 2829 5d29 0d0a 0d0a 2020 2020 2020  ys()])....      
-00018d50: 2020 7920 3d20 6e70 2e6f 6e65 7328 782e    y = np.ones(x.
-00018d60: 7368 6170 655b 315d 290d 0a20 2020 2020  shape[1])..     
-00018d70: 2020 2079 5b6e 702e 6c69 6e61 6c67 2e6e     y[np.linalg.n
-00018d80: 6f72 6d28 782d 302e 352c 2061 7869 733d  orm(x-0.5, axis=
-00018d90: 3029 203c 3d20 302e 3235 5d20 3d20 322e  0) <= 0.25] = 2.
-00018da0: 0d0a 0d0a 2020 2020 2020 2020 795f 6f75  ....        y_ou
-00018db0: 7420 3d20 795b 3a2c 206e 702e 6e65 7761  t = y[:, np.newa
-00018dc0: 7869 735d 0d0a 0d0a 2020 2020 2020 2020  xis]....        
-00018dd0: 7265 7475 726e 2079 5f6f 7574 0d0a 0d0a  return y_out....
-00018de0: 0d0a 636c 6173 7320 436c 7573 7465 7233  ..class Cluster3
-00018df0: 5369 6d70 6c65 2841 6273 7472 6163 744d  Simple(AbstractM
-00018e00: 6f64 656c 293a 0d0a 2020 2020 2222 220d  odel):..    """.
-00018e10: 0a20 2020 2032 2d64 696d 656e 7369 6f6e  .    2-dimension
-00018e20: 616c 2074 6573 7466 756e 6374 696f 6e20  al testfunction 
-00018e30: 636f 6e74 6169 6e69 6e67 2061 2073 7068  containing a sph
-00018e40: 6572 6963 616c 2061 6e64 2061 206c 696e  erical and a lin
-00018e50: 6561 7220 6469 7363 6f6e 7469 6e75 6974  ear discontinuit
-00018e60: 792e 0d0a 0d0a 2020 2020 2e2e 206d 6174  y.....    .. mat
-00018e70: 683a 3a0d 0a20 2020 2020 2020 7920 3d20  h::..       y = 
-00018e80: 5c5c 6265 6769 6e7b 6361 7365 737d 0d0a  \\begin{cases}..
-00018e90: 2020 2020 2020 2032 2c20 2620 5c5c 7465         2, & \\te
-00018ea0: 7874 7b69 6620 7d20 5c5c 7371 7274 7b5c  xt{if } \\sqrt{\
-00018eb0: 5c73 756d 5f7b 693d 317d 5e7b 4e7d 2878  \sum_{i=1}^{N}(x
-00018ec0: 5f69 2d30 2e35 295e 327d 205c 5c6c 6571  _i-0.5)^2} \\leq
-00018ed0: 2030 2e32 3520 5c5c 5c5c 0d0a 2020 2020   0.25 \\\\..    
-00018ee0: 2020 2031 2c20 2620 5c5c 7465 7874 7b6f     1, & \\text{o
-00018ef0: 7468 6572 7769 7365 7d0d 0a20 2020 2020  therwise}..     
-00018f00: 2020 5c5c 656e 647b 6361 7365 737d 0d0a    \\end{cases}..
-00018f10: 0d0a 2020 2020 5061 7261 6d65 7465 7273  ..    Parameters
-00018f20: 0d0a 2020 2020 2d2d 2d2d 2d2d 2d2d 2d2d  ..    ----------
-00018f30: 0d0a 2020 2020 705b 2278 3122 5d3a 2066  ..    p["x1"]: f
-00018f40: 6c6f 6174 206f 7220 6e64 6172 7261 7920  loat or ndarray 
-00018f50: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
-00018f60: 5d0d 0a20 2020 2020 2020 2046 6972 7374  ]..        First
-00018f70: 2070 6172 616d 6574 6572 205b 302c 2031   parameter [0, 1
-00018f80: 5d0d 0a20 2020 2070 5b22 7832 225d 3a20  ]..    p["x2"]: 
-00018f90: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
-00018fa0: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
-00018fb0: 645d 0d0a 2020 2020 2020 2020 322d 6e64  d]..        2-nd
-00018fc0: 2070 6172 616d 6574 6572 2064 6566 696e   parameter defin
-00018fd0: 6564 2069 6e20 5b30 2c20 315d 0d0a 0d0a  ed in [0, 1]....
-00018fe0: 2020 2020 5265 7475 726e 730d 0a20 2020      Returns..   
-00018ff0: 202d 2d2d 2d2d 2d2d 0d0a 2020 2020 793a   -------..    y:
-00019000: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-00019010: 7420 5b6e 5f67 7269 6420 7820 315d 0d0a  t [n_grid x 1]..
-00019020: 2020 2020 2020 2020 4f75 7470 7574 2064          Output d
-00019030: 6174 610d 0a0d 0a20 2020 204e 6f74 6573  ata....    Notes
-00019040: 0d0a 2020 2020 2d2d 2d2d 2d0d 0a20 2020  ..    -----..   
-00019050: 202e 2e20 706c 6f74 3a3a 0d0a 0d0a 2020   .. plot::....  
-00019060: 2020 2020 2069 6d70 6f72 7420 6e75 6d70       import nump
-00019070: 7920 6173 206e 700d 0a20 2020 2020 2020  y as np..       
-00019080: 6672 6f6d 2070 7967 7063 2e74 6573 7466  from pygpc.testf
-00019090: 756e 6374 696f 6e73 2069 6d70 6f72 7420  unctions import 
-000190a0: 706c 6f74 5f74 6573 7466 756e 6374 696f  plot_testfunctio
-000190b0: 6e20 6173 2070 6c6f 740d 0a20 2020 2020  n as plot..     
-000190c0: 2020 6672 6f6d 2063 6f6c 6c65 6374 696f    from collectio
-000190d0: 6e73 2069 6d70 6f72 7420 4f72 6465 7265  ns import Ordere
-000190e0: 6444 6963 740d 0a0d 0a20 2020 2020 2020  dDict....       
-000190f0: 7061 7261 6d65 7465 7273 203d 204f 7264  parameters = Ord
-00019100: 6572 6564 4469 6374 2829 0d0a 2020 2020  eredDict()..    
-00019110: 2020 2070 6172 616d 6574 6572 735b 2278     parameters["x
-00019120: 3122 5d20 3d20 6e70 2e6c 696e 7370 6163  1"] = np.linspac
-00019130: 6528 302c 2031 2c20 3530 3029 0d0a 2020  e(0, 1, 500)..  
-00019140: 2020 2020 2070 6172 616d 6574 6572 735b       parameters[
-00019150: 2278 3222 5d20 3d20 6e70 2e6c 696e 7370  "x2"] = np.linsp
-00019160: 6163 6528 302c 2031 2c20 3530 3029 0d0a  ace(0, 1, 500)..
-00019170: 0d0a 2020 2020 2020 2070 6c6f 7428 2243  ..       plot("C
-00019180: 6c75 7374 6572 3353 696d 706c 6522 2c20  luster3Simple", 
-00019190: 7061 7261 6d65 7465 7273 290d 0a20 2020  parameters)..   
-000191a0: 2022 2222 0d0a 0d0a 2020 2020 6465 6620   """....    def 
-000191b0: 5f5f 696e 6974 5f5f 2873 656c 662c 206d  __init__(self, m
-000191c0: 6174 6c61 625f 6d6f 6465 6c3d 4661 6c73  atlab_model=Fals
-000191d0: 6529 3a0d 0a20 2020 2020 2020 2073 7570  e):..        sup
-000191e0: 6572 2874 7970 6528 7365 6c66 292c 2073  er(type(self), s
-000191f0: 656c 6629 2e5f 5f69 6e69 745f 5f28 6d61  elf).__init__(ma
-00019200: 746c 6162 5f6d 6f64 656c 3d6d 6174 6c61  tlab_model=matla
-00019210: 625f 6d6f 6465 6c29 0d0a 2020 2020 2020  b_model)..      
-00019220: 2020 7365 6c66 2e66 6e61 6d65 203d 2069    self.fname = i
-00019230: 6e73 7065 6374 2e67 6574 6669 6c65 2869  nspect.getfile(i
-00019240: 6e73 7065 6374 2e63 7572 7265 6e74 6672  nspect.currentfr
-00019250: 616d 6528 2929 0d0a 0d0a 2020 2020 6465  ame())....    de
-00019260: 6620 7661 6c69 6461 7465 2873 656c 6629  f validate(self)
-00019270: 3a0d 0a20 2020 2020 2020 2070 6173 730d  :..        pass.
-00019280: 0a0d 0a20 2020 2064 6566 2073 696d 756c  ...    def simul
-00019290: 6174 6528 7365 6c66 2c20 7072 6f63 6573  ate(self, proces
-000192a0: 735f 6964 3d4e 6f6e 652c 206d 6174 6c61  s_id=None, matla
-000192b0: 625f 656e 6769 6e65 3d4e 6f6e 6529 3a0d  b_engine=None):.
-000192c0: 0a0d 0a20 2020 2020 2020 2078 203d 206e  ...        x = n
-000192d0: 702e 7673 7461 636b 285b 7365 6c66 2e70  p.vstack([self.p
-000192e0: 5b6b 6579 5d2e 7371 7565 657a 6528 2920  [key].squeeze() 
-000192f0: 666f 7220 6b65 7920 696e 2073 656c 662e  for key in self.
-00019300: 702e 6b65 7973 2829 5d29 0d0a 0d0a 2020  p.keys()])....  
-00019310: 2020 2020 2020 7920 3d20 6e70 2e6f 6e65        y = np.one
-00019320: 7328 782e 7368 6170 655b 315d 290d 0a20  s(x.shape[1]).. 
-00019330: 2020 2020 2020 2079 5b6e 702e 6c69 6e61         y[np.lina
-00019340: 6c67 2e6e 6f72 6d28 782c 2061 7869 733d  lg.norm(x, axis=
-00019350: 3029 203c 3d20 302e 3235 5d20 3d20 322e  0) <= 0.25] = 2.
-00019360: 0d0a 2020 2020 2020 2020 795b 6e70 2e73  ..        y[np.s
-00019370: 756d 2878 2c20 6178 6973 3d30 2920 3e3d  um(x, axis=0) >=
-00019380: 2031 2e35 5d20 3d20 332e 0d0a 0d0a 2020   1.5] = 3.....  
-00019390: 2020 2020 2020 795f 6f75 7420 3d20 795b        y_out = y[
-000193a0: 3a2c 206e 702e 6e65 7761 7869 735d 0d0a  :, np.newaxis]..
-000193b0: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-000193c0: 2079 5f6f 7574 0d0a 0d0a 0d0a 636c 6173   y_out......clas
-000193d0: 7320 436f 6e74 696e 756f 7573 4469 7363  s ContinuousDisc
-000193e0: 6f6e 7469 6e75 6f75 7353 7068 6572 6528  ontinuousSphere(
-000193f0: 4162 7374 7261 6374 4d6f 6465 6c29 3a0d  AbstractModel):.
-00019400: 0a20 2020 2022 2222 0d0a 2020 2020 4e2d  .    """..    N-
-00019410: 6469 6d65 6e73 696f 6e61 6c20 7465 7374  dimensional test
-00019420: 6675 6e63 7469 6f6e 2063 6f6e 7461 696e  function contain
-00019430: 696e 6720 6120 7370 6865 7269 6361 6c20  ing a spherical 
-00019440: 6469 7363 6f6e 7469 6e75 6974 792e 0d0a  discontinuity...
-00019450: 2020 2020 496e 7369 6465 2074 6865 2073      Inside the s
-00019460: 7068 6572 6520 7468 6520 6f75 7470 7574  phere the output
-00019470: 2063 6f72 7265 7370 6f6e 6473 2074 6f20   corresponds to 
-00019480: 7468 6520 4d61 6e75 6661 6374 7572 6544  the ManufactureD
-00019490: 6563 6179 2066 756e 6374 696f 6e20 2873  ecay function (s
-000194a0: 6869 6674 6564 2062 7920 2d32 290d 0a20  hifted by -2).. 
-000194b0: 2020 2061 6e64 206f 7574 7369 6465 206f     and outside o
-000194c0: 6620 7468 6520 7370 6865 7265 2069 7420  f the sphere it 
-000194d0: 636f 7272 6573 706f 6e64 2074 6f20 7468  correspond to th
-000194e0: 6520 4765 6e7a 4f73 6369 6c6c 6174 6f72  e GenzOscillator
-000194f0: 7920 7465 7374 6675 6e63 7469 6f6e 2028  y testfunction (
-00019500: 7363 616c 6564 2062 7920 3229 2e0d 0a0d  scaled by 2)....
-00019510: 0a20 2020 202e 2e20 6d61 7468 3a3a 0d0a  .    .. math::..
-00019520: 2020 2020 2020 2079 203d 205c 5c62 6567         y = \\beg
-00019530: 696e 7b63 6173 6573 7d0d 0a20 2020 2020  in{cases}..     
-00019540: 2020 5c5c 7465 7874 7b4d 616e 7566 6163    \\text{Manufac
-00019550: 7475 7265 4465 6361 797d 2878 2920 2d20  tureDecay}(x) - 
-00019560: 322c 2026 205c 5c74 6578 747b 6966 207d  2, & \\text{if }
-00019570: 205c 5c73 7172 747b 5c5c 7375 6d5f 7b69   \\sqrt{\\sum_{i
-00019580: 3d31 7d5e 7b4e 7d78 5f69 5e32 7d20 5c5c  =1}^{N}x_i^2} \\
-00019590: 6c65 7120 302e 3235 205c 5c5c 5c0d 0a20  leq 0.25 \\\\.. 
-000195a0: 2020 2020 2020 5c5c 7465 7874 7b47 656e        \\text{Gen
-000195b0: 7a4f 7363 696c 6c61 746f 7279 7d28 7829  zOscillatory}(x)
-000195c0: 202a 2032 2c20 2620 5c5c 7465 7874 7b6f   * 2, & \\text{o
-000195d0: 7468 6572 7769 7365 7d0d 0a20 2020 2020  therwise}..     
-000195e0: 2020 5c5c 656e 647b 6361 7365 737d 0d0a    \\end{cases}..
-000195f0: 0d0a 2020 2020 5061 7261 6d65 7465 7273  ..    Parameters
-00019600: 0d0a 2020 2020 2d2d 2d2d 2d2d 2d2d 2d2d  ..    ----------
-00019610: 0d0a 2020 2020 705b 2278 3122 5d3a 2066  ..    p["x1"]: f
-00019620: 6c6f 6174 206f 7220 6e64 6172 7261 7920  loat or ndarray 
-00019630: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
-00019640: 5d0d 0a20 2020 2020 2020 2046 6972 7374  ]..        First
-00019650: 2070 6172 616d 6574 6572 205b 302c 2031   parameter [0, 1
-00019660: 5d0d 0a20 2020 2070 5b22 7869 225d 3a20  ]..    p["xi"]: 
-00019670: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
-00019680: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
-00019690: 645d 0d0a 2020 2020 2020 2020 692d 7468  d]..        i-th
-000196a0: 2070 6172 616d 6574 6572 2064 6566 696e   parameter defin
-000196b0: 6564 2069 6e20 5b30 2c20 315d 0d0a 2020  ed in [0, 1]..  
-000196c0: 2020 705b 2278 4e22 5d3a 2066 6c6f 6174    p["xN"]: float
-000196d0: 206f 7220 6e64 6172 7261 7920 6f66 2066   or ndarray of f
-000196e0: 6c6f 6174 205b 6e5f 6772 6964 5d0d 0a20  loat [n_grid].. 
-000196f0: 2020 2020 2020 204e 7468 2070 6172 616d         Nth param
-00019700: 6574 6572 205b 302c 2031 5d0d 0a0d 0a20  eter [0, 1].... 
-00019710: 2020 2052 6574 7572 6e73 0d0a 2020 2020     Returns..    
-00019720: 2d2d 2d2d 2d2d 2d0d 0a20 2020 2079 3a20  -------..    y: 
-00019730: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-00019740: 205b 6e5f 6772 6964 2078 2031 5d0d 0a20   [n_grid x 1].. 
-00019750: 2020 2020 2020 204f 7574 7075 7420 6461         Output da
-00019760: 7461 0d0a 0d0a 2020 2020 4e6f 7465 730d  ta....    Notes.
-00019770: 0a20 2020 202d 2d2d 2d2d 0d0a 2020 2020  .    -----..    
-00019780: 2e2e 2070 6c6f 743a 3a0d 0a0d 0a20 2020  .. plot::....   
-00019790: 2020 2020 696d 706f 7274 206e 756d 7079      import numpy
-000197a0: 2061 7320 6e70 0d0a 2020 2020 2020 2066   as np..       f
-000197b0: 726f 6d20 7079 6770 632e 7465 7374 6675  rom pygpc.testfu
-000197c0: 6e63 7469 6f6e 7320 696d 706f 7274 2070  nctions import p
-000197d0: 6c6f 745f 7465 7374 6675 6e63 7469 6f6e  lot_testfunction
-000197e0: 2061 7320 706c 6f74 0d0a 2020 2020 2020   as plot..      
-000197f0: 2066 726f 6d20 636f 6c6c 6563 7469 6f6e   from collection
-00019800: 7320 696d 706f 7274 204f 7264 6572 6564  s import Ordered
-00019810: 4469 6374 0d0a 0d0a 2020 2020 2020 2070  Dict....       p
-00019820: 6172 616d 6574 6572 7320 3d20 4f72 6465  arameters = Orde
-00019830: 7265 6444 6963 7428 290d 0a20 2020 2020  redDict()..     
-00019840: 2020 7061 7261 6d65 7465 7273 5b22 7831    parameters["x1
-00019850: 225d 203d 206e 702e 6c69 6e73 7061 6365  "] = np.linspace
-00019860: 2830 2c20 312c 2035 3030 290d 0a20 2020  (0, 1, 500)..   
-00019870: 2020 2020 7061 7261 6d65 7465 7273 5b22      parameters["
-00019880: 7832 225d 203d 206e 702e 6c69 6e73 7061  x2"] = np.linspa
-00019890: 6365 2830 2c20 312c 2035 3030 290d 0a0d  ce(0, 1, 500)...
-000198a0: 0a20 2020 2020 2020 706c 6f74 2822 436f  .       plot("Co
-000198b0: 6e74 696e 756f 7573 4469 7363 6f6e 7469  ntinuousDisconti
-000198c0: 6e75 6f75 7353 7068 6572 6522 2c20 7061  nuousSphere", pa
-000198d0: 7261 6d65 7465 7273 290d 0a20 2020 2022  rameters)..    "
-000198e0: 2222 0d0a 0d0a 2020 2020 6465 6620 5f5f  ""....    def __
-000198f0: 696e 6974 5f5f 2873 656c 662c 206d 6174  init__(self, mat
-00019900: 6c61 625f 6d6f 6465 6c3d 4661 6c73 6529  lab_model=False)
-00019910: 3a0d 0a20 2020 2020 2020 2073 7570 6572  :..        super
-00019920: 2874 7970 6528 7365 6c66 292c 2073 656c  (type(self), sel
-00019930: 6629 2e5f 5f69 6e69 745f 5f28 6d61 746c  f).__init__(matl
-00019940: 6162 5f6d 6f64 656c 3d6d 6174 6c61 625f  ab_model=matlab_
-00019950: 6d6f 6465 6c29 0d0a 2020 2020 2020 2020  model)..        
-00019960: 7365 6c66 2e66 6e61 6d65 203d 2069 6e73  self.fname = ins
-00019970: 7065 6374 2e67 6574 6669 6c65 2869 6e73  pect.getfile(ins
-00019980: 7065 6374 2e63 7572 7265 6e74 6672 616d  pect.currentfram
-00019990: 6528 2929 0d0a 0d0a 2020 2020 6465 6620  e())....    def 
-000199a0: 7661 6c69 6461 7465 2873 656c 6629 3a0d  validate(self):.
-000199b0: 0a20 2020 2020 2020 2070 6173 730d 0a0d  .        pass...
-000199c0: 0a20 2020 2064 6566 2073 696d 756c 6174  .    def simulat
-000199d0: 6528 7365 6c66 2c20 7072 6f63 6573 735f  e(self, process_
-000199e0: 6964 3d4e 6f6e 652c 206d 6174 6c61 625f  id=None, matlab_
-000199f0: 656e 6769 6e65 3d4e 6f6e 6529 3a0d 0a0d  engine=None):...
-00019a00: 0a20 2020 2020 2020 2066 6f72 206b 6579  .        for key
-00019a10: 2069 6e20 7365 6c66 2e70 2e6b 6579 7328   in self.p.keys(
-00019a20: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
-00019a30: 6966 2073 656c 662e 705b 6b65 795d 2e6e  if self.p[key].n
-00019a40: 6469 6d20 3d3d 2031 3a0d 0a20 2020 2020  dim == 1:..     
-00019a50: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00019a60: 705b 6b65 795d 203d 2073 656c 662e 705b  p[key] = self.p[
-00019a70: 6b65 795d 5b3a 2c20 6e70 2e6e 6577 6178  key][:, np.newax
-00019a80: 6973 5d0d 0a0d 0a20 2020 2020 2020 2078  is]....        x
-00019a90: 203d 206e 702e 6873 7461 636b 285b 7365   = np.hstack([se
-00019aa0: 6c66 2e70 5b6b 6579 5d20 666f 7220 6b65  lf.p[key] for ke
-00019ab0: 7920 696e 2073 656c 662e 702e 6b65 7973  y in self.p.keys
-00019ac0: 2829 5d29 0d0a 0d0a 2020 2020 2020 2020  ()])....        
-00019ad0: 7920 3d20 6e70 2e7a 6572 6f73 2878 2e73  y = np.zeros(x.s
-00019ae0: 6861 7065 5b30 5d29 0d0a 2020 2020 2020  hape[0])..      
-00019af0: 2020 6d61 736b 203d 2028 6e70 2e6c 696e    mask = (np.lin
-00019b00: 616c 672e 6e6f 726d 2878 2d30 2e35 2c20  alg.norm(x-0.5, 
-00019b10: 6178 6973 3d31 2920 3c3d 2030 2e32 3529  axis=1) <= 0.25)
-00019b20: 2e66 6c61 7474 656e 2829 0d0a 0d0a 2020  .flatten()....  
-00019b30: 2020 2020 2020 705f 3120 3d20 4f72 6465        p_1 = Orde
-00019b40: 7265 6444 6963 7428 290d 0a20 2020 2020  redDict()..     
-00019b50: 2020 2070 5f32 203d 204f 7264 6572 6564     p_2 = Ordered
-00019b60: 4469 6374 2829 0d0a 0d0a 2020 2020 2020  Dict()....      
-00019b70: 2020 666f 7220 692c 206b 6579 2069 6e20    for i, key in 
-00019b80: 656e 756d 6572 6174 6528 7365 6c66 2e70  enumerate(self.p
-00019b90: 2e6b 6579 7328 2929 3a0d 0a20 2020 2020  .keys()):..     
-00019ba0: 2020 2020 2020 2070 5f31 5b6b 6579 5d20         p_1[key] 
-00019bb0: 3d20 785b 6d61 736b 2c20 695d 0d0a 2020  = x[mask, i]..  
-00019bc0: 2020 2020 2020 2020 2020 705f 325b 6b65            p_2[ke
-00019bd0: 795d 203d 2078 5b6e 702e 6c6f 6769 6361  y] = x[np.logica
-00019be0: 6c5f 6e6f 7428 6d61 736b 292c 2069 5d0d  l_not(mask), i].
-00019bf0: 0a0d 0a20 2020 2020 2020 206d 6f64 656c  ...        model
-00019c00: 5f31 203d 204d 616e 7566 6163 7475 7265  _1 = Manufacture
-00019c10: 4465 6361 7928 292e 7365 745f 7061 7261  Decay().set_para
-00019c20: 6d65 7465 7273 2870 5f31 290d 0a20 2020  meters(p_1)..   
-00019c30: 2020 2020 206d 6f64 656c 5f32 203d 2047       model_2 = G
-00019c40: 656e 7a4f 7363 696c 6c61 746f 7279 2829  enzOscillatory()
-00019c50: 2e73 6574 5f70 6172 616d 6574 6572 7328  .set_parameters(
-00019c60: 705f 3229 0d0a 0d0a 2020 2020 2020 2020  p_2)....        
-00019c70: 795f 3120 3d20 6d6f 6465 6c5f 312e 7369  y_1 = model_1.si
-00019c80: 6d75 6c61 7465 2829 202d 2032 0d0a 2020  mulate() - 2..  
-00019c90: 2020 2020 2020 795f 3220 3d20 6d6f 6465        y_2 = mode
-00019ca0: 6c5f 322e 7369 6d75 6c61 7465 2829 202a  l_2.simulate() *
-00019cb0: 2032 0d0a 0d0a 2020 2020 2020 2020 795b   2....        y[
-00019cc0: 6d61 736b 5d20 3d20 795f 312e 666c 6174  mask] = y_1.flat
-00019cd0: 7465 6e28 290d 0a20 2020 2020 2020 2079  ten()..        y
-00019ce0: 5b6e 702e 6c6f 6769 6361 6c5f 6e6f 7428  [np.logical_not(
-00019cf0: 6d61 736b 295d 203d 2079 5f32 2e66 6c61  mask)] = y_2.fla
-00019d00: 7474 656e 2829 0d0a 0d0a 2020 2020 2020  tten()....      
-00019d10: 2020 795f 6f75 7420 3d20 795b 3a2c 206e    y_out = y[:, n
-00019d20: 702e 6e65 7761 7869 735d 0d0a 0d0a 2020  p.newaxis]....  
-00019d30: 2020 2020 2020 7265 7475 726e 2079 5f6f        return y_o
-00019d40: 7574 0d0a 0d0a 0d0a 636c 6173 7320 4469  ut......class Di
-00019d50: 7363 6f6e 7469 6e75 6f75 7352 6964 6765  scontinuousRidge
-00019d60: 4d61 6e75 6661 6374 7572 6544 6563 6179  ManufactureDecay
-00019d70: 2841 6273 7472 6163 744d 6f64 656c 293a  (AbstractModel):
-00019d80: 0d0a 2020 2020 2222 220d 0a20 2020 204e  ..    """..    N
-00019d90: 2d64 696d 656e 7369 6f6e 616c 2074 6573  -dimensional tes
-00019da0: 7466 756e 6374 696f 6e20 636f 6e74 6169  tfunction contai
-00019db0: 6e69 6e67 2061 206c 696e 6561 7220 6469  ning a linear di
-00019dc0: 7363 6f6e 7469 6e75 6974 792e 0d0a 2020  scontinuity...  
-00019dd0: 2020 4f6e 2074 6865 206f 6e65 2073 6964    On the one sid
-00019de0: 6520 7468 6520 6f75 7470 7574 2063 6f72  e the output cor
-00019df0: 7265 7370 6f6e 6473 2074 6f20 7468 6520  responds to the 
-00019e00: 5269 6467 6520 6675 6e63 7469 6f6e 0d0a  Ridge function..
-00019e10: 2020 2020 616e 6420 6f6e 2074 6865 206f      and on the o
-00019e20: 7468 6572 2073 6964 6520 6974 2063 6f72  ther side it cor
-00019e30: 7265 7370 6f6e 6420 746f 2074 6865 204d  respond to the M
-00019e40: 616e 7566 6163 7475 7265 4465 6361 7920  anufactureDecay 
-00019e50: 7465 7374 6675 6e63 7469 6f6e 2e0d 0a0d  testfunction....
-00019e60: 0a20 2020 202e 2e20 6d61 7468 3a3a 0d0a  .    .. math::..
-00019e70: 2020 2020 2020 2079 203d 205c 5c62 6567         y = \\beg
-00019e80: 696e 7b63 6173 6573 7d0d 0a20 2020 2020  in{cases}..     
-00019e90: 2020 5c5c 7465 7874 7b4d 616e 7566 6163    \\text{Manufac
-00019ea0: 7475 7265 4465 6361 797d 2878 292c 2026  tureDecay}(x), &
-00019eb0: 205c 5c74 6578 747b 6966 207d 205c 5c73   \\text{if } \\s
-00019ec0: 756d 5f7b 693d 317d 5e7b 4e7d 785f 6920  um_{i=1}^{N}x_i 
-00019ed0: 5c5c 6c65 7120 3120 5c5c 5c5c 0d0a 2020  \\leq 1 \\\\..  
-00019ee0: 2020 2020 205c 5c74 6578 747b 5269 6467       \\text{Ridg
-00019ef0: 657d 2878 292c 2026 205c 5c74 6578 747b  e}(x), & \\text{
-00019f00: 6f74 6865 7277 6973 657d 0d0a 2020 2020  otherwise}..    
-00019f10: 2020 205c 5c65 6e64 7b63 6173 6573 7d0d     \\end{cases}.
-00019f20: 0a0d 0a20 2020 2050 6172 616d 6574 6572  ...    Parameter
-00019f30: 730d 0a20 2020 202d 2d2d 2d2d 2d2d 2d2d  s..    ---------
-00019f40: 2d0d 0a20 2020 2070 5b22 7831 225d 3a20  -..    p["x1"]: 
-00019f50: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
-00019f60: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
-00019f70: 645d 0d0a 2020 2020 2020 2020 4669 7273  d]..        Firs
-00019f80: 7420 7061 7261 6d65 7465 7220 5b30 2c20  t parameter [0, 
-00019f90: 315d 0d0a 2020 2020 705b 2278 6922 5d3a  1]..    p["xi"]:
-00019fa0: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
-00019fb0: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
-00019fc0: 6964 5d0d 0a20 2020 2020 2020 2069 2d74  id]..        i-t
-00019fd0: 6820 7061 7261 6d65 7465 7220 6465 6669  h parameter defi
-00019fe0: 6e65 6420 696e 205b 302c 2031 5d0d 0a20  ned in [0, 1].. 
-00019ff0: 2020 2070 5b22 784e 225d 3a20 666c 6f61     p["xN"]: floa
-0001a000: 7420 6f72 206e 6461 7272 6179 206f 6620  t or ndarray of 
-0001a010: 666c 6f61 7420 5b6e 5f67 7269 645d 0d0a  float [n_grid]..
-0001a020: 2020 2020 2020 2020 4e74 6820 7061 7261          Nth para
-0001a030: 6d65 7465 7220 5b30 2c20 315d 0d0a 0d0a  meter [0, 1]....
-0001a040: 2020 2020 5265 7475 726e 730d 0a20 2020      Returns..   
-0001a050: 202d 2d2d 2d2d 2d2d 0d0a 2020 2020 793a   -------..    y:
-0001a060: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-0001a070: 7420 5b6e 5f67 7269 6420 7820 315d 0d0a  t [n_grid x 1]..
-0001a080: 2020 2020 2020 2020 4f75 7470 7574 2064          Output d
-0001a090: 6174 610d 0a0d 0a20 2020 204e 6f74 6573  ata....    Notes
-0001a0a0: 0d0a 2020 2020 2d2d 2d2d 2d0d 0a20 2020  ..    -----..   
-0001a0b0: 202e 2e20 706c 6f74 3a3a 0d0a 0d0a 2020   .. plot::....  
-0001a0c0: 2020 2020 2069 6d70 6f72 7420 6e75 6d70       import nump
-0001a0d0: 7920 6173 206e 700d 0a20 2020 2020 2020  y as np..       
-0001a0e0: 6672 6f6d 2070 7967 7063 2e74 6573 7466  from pygpc.testf
-0001a0f0: 756e 6374 696f 6e73 2069 6d70 6f72 7420  unctions import 
-0001a100: 706c 6f74 5f74 6573 7466 756e 6374 696f  plot_testfunctio
-0001a110: 6e20 6173 2070 6c6f 740d 0a20 2020 2020  n as plot..     
-0001a120: 2020 6672 6f6d 2063 6f6c 6c65 6374 696f    from collectio
-0001a130: 6e73 2069 6d70 6f72 7420 4f72 6465 7265  ns import Ordere
-0001a140: 6444 6963 740d 0a0d 0a20 2020 2020 2020  dDict....       
-0001a150: 7061 7261 6d65 7465 7273 203d 204f 7264  parameters = Ord
-0001a160: 6572 6564 4469 6374 2829 0d0a 2020 2020  eredDict()..    
-0001a170: 2020 2070 6172 616d 6574 6572 735b 2278     parameters["x
-0001a180: 3122 5d20 3d20 6e70 2e6c 696e 7370 6163  1"] = np.linspac
-0001a190: 6528 302c 2031 2c20 3235 3029 0d0a 2020  e(0, 1, 250)..  
-0001a1a0: 2020 2020 2070 6172 616d 6574 6572 735b       parameters[
-0001a1b0: 2278 3222 5d20 3d20 6e70 2e6c 696e 7370  "x2"] = np.linsp
-0001a1c0: 6163 6528 302c 2031 2c20 3235 3029 0d0a  ace(0, 1, 250)..
-0001a1d0: 0d0a 2020 2020 2020 2070 6c6f 7428 2244  ..       plot("D
-0001a1e0: 6973 636f 6e74 696e 756f 7573 5269 6467  iscontinuousRidg
-0001a1f0: 654d 616e 7566 6163 7475 7265 4465 6361  eManufactureDeca
-0001a200: 7922 2c20 7061 7261 6d65 7465 7273 290d  y", parameters).
-0001a210: 0a20 2020 2022 2222 0d0a 0d0a 2020 2020  .    """....    
-0001a220: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
-0001a230: 662c 206d 6174 6c61 625f 6d6f 6465 6c3d  f, matlab_model=
-0001a240: 4661 6c73 6529 3a0d 0a20 2020 2020 2020  False):..       
-0001a250: 2073 7570 6572 2874 7970 6528 7365 6c66   super(type(self
-0001a260: 292c 2073 656c 6629 2e5f 5f69 6e69 745f  ), self).__init_
-0001a270: 5f28 6d61 746c 6162 5f6d 6f64 656c 3d6d  _(matlab_model=m
-0001a280: 6174 6c61 625f 6d6f 6465 6c29 0d0a 2020  atlab_model)..  
-0001a290: 2020 2020 2020 7365 6c66 2e66 6e61 6d65        self.fname
-0001a2a0: 203d 2069 6e73 7065 6374 2e67 6574 6669   = inspect.getfi
-0001a2b0: 6c65 2869 6e73 7065 6374 2e63 7572 7265  le(inspect.curre
-0001a2c0: 6e74 6672 616d 6528 2929 0d0a 0d0a 2020  ntframe())....  
-0001a2d0: 2020 6465 6620 7661 6c69 6461 7465 2873    def validate(s
-0001a2e0: 656c 6629 3a0d 0a20 2020 2020 2020 2070  elf):..        p
-0001a2f0: 6173 730d 0a0d 0a20 2020 2064 6566 2073  ass....    def s
-0001a300: 696d 756c 6174 6528 7365 6c66 2c20 7072  imulate(self, pr
-0001a310: 6f63 6573 735f 6964 3d4e 6f6e 652c 206d  ocess_id=None, m
-0001a320: 6174 6c61 625f 656e 6769 6e65 3d4e 6f6e  atlab_engine=Non
-0001a330: 6529 3a0d 0a0d 0a20 2020 2020 2020 2066  e):....        f
-0001a340: 6f72 206b 6579 2069 6e20 7365 6c66 2e70  or key in self.p
-0001a350: 2e6b 6579 7328 293a 0d0a 2020 2020 2020  .keys():..      
-0001a360: 2020 2020 2020 6966 2073 656c 662e 705b        if self.p[
-0001a370: 6b65 795d 2e6e 6469 6d20 3d3d 2031 3a0d  key].ndim == 1:.
-0001a380: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001a390: 2073 656c 662e 705b 6b65 795d 203d 2073   self.p[key] = s
-0001a3a0: 656c 662e 705b 6b65 795d 5b3a 2c20 6e70  elf.p[key][:, np
-0001a3b0: 2e6e 6577 6178 6973 5d0d 0a0d 0a20 2020  .newaxis]....   
-0001a3c0: 2020 2020 2078 203d 206e 702e 6873 7461       x = np.hsta
-0001a3d0: 636b 285b 7365 6c66 2e70 5b6b 6579 5d20  ck([self.p[key] 
-0001a3e0: 666f 7220 6b65 7920 696e 2073 656c 662e  for key in self.
-0001a3f0: 702e 6b65 7973 2829 5d29 0d0a 0d0a 2020  p.keys()])....  
-0001a400: 2020 2020 2020 7920 3d20 6e70 2e7a 6572        y = np.zer
-0001a410: 6f73 2878 2e73 6861 7065 5b30 5d29 0d0a  os(x.shape[0])..
-0001a420: 2020 2020 2020 2020 6d61 736b 203d 2028          mask = (
-0001a430: 6e70 2e73 756d 2878 2c20 6178 6973 3d31  np.sum(x, axis=1
-0001a440: 2920 3c3d 2031 2e29 2e66 6c61 7474 656e  ) <= 1.).flatten
-0001a450: 2829 0d0a 2020 2020 2020 2020 2320 6d61  ()..        # ma
-0001a460: 736b 203d 206e 702e 6c6f 6769 6361 6c5f  sk = np.logical_
-0001a470: 616e 6428 6d61 736b 2c20 6e70 2e6c 696e  and(mask, np.lin
-0001a480: 616c 672e 6e6f 726d 2878 2d30 2e38 352c  alg.norm(x-0.85,
-0001a490: 2061 7869 733d 3129 203e 202e 3829 0d0a   axis=1) > .8)..
-0001a4a0: 0d0a 2020 2020 2020 2020 705f 3120 3d20  ..        p_1 = 
-0001a4b0: 4f72 6465 7265 6444 6963 7428 290d 0a20  OrderedDict().. 
-0001a4c0: 2020 2020 2020 2070 5f32 203d 204f 7264         p_2 = Ord
-0001a4d0: 6572 6564 4469 6374 2829 0d0a 0d0a 2020  eredDict()....  
-0001a4e0: 2020 2020 2020 666f 7220 692c 206b 6579        for i, key
-0001a4f0: 2069 6e20 656e 756d 6572 6174 6528 7365   in enumerate(se
-0001a500: 6c66 2e70 2e6b 6579 7328 2929 3a0d 0a20  lf.p.keys()):.. 
-0001a510: 2020 2020 2020 2020 2020 2070 5f31 5b6b             p_1[k
-0001a520: 6579 5d20 3d20 785b 6d61 736b 2c20 695d  ey] = x[mask, i]
-0001a530: 0d0a 2020 2020 2020 2020 2020 2020 705f  ..            p_
-0001a540: 325b 6b65 795d 203d 2078 5b6e 702e 6c6f  2[key] = x[np.lo
-0001a550: 6769 6361 6c5f 6e6f 7428 6d61 736b 292c  gical_not(mask),
-0001a560: 2069 5d0d 0a0d 0a20 2020 2020 2020 206d   i]....        m
-0001a570: 6f64 656c 5f31 203d 204d 616e 7566 6163  odel_1 = Manufac
-0001a580: 7475 7265 4465 6361 7928 292e 7365 745f  tureDecay().set_
-0001a590: 7061 7261 6d65 7465 7273 2870 5f31 290d  parameters(p_1).
-0001a5a0: 0a20 2020 2020 2020 206d 6f64 656c 5f32  .        model_2
-0001a5b0: 203d 2052 6964 6765 2829 2e73 6574 5f70   = Ridge().set_p
-0001a5c0: 6172 616d 6574 6572 7328 705f 3229 0d0a  arameters(p_2)..
-0001a5d0: 0d0a 2020 2020 2020 2020 795f 3120 3d20  ..        y_1 = 
-0001a5e0: 6d6f 6465 6c5f 312e 7369 6d75 6c61 7465  model_1.simulate
-0001a5f0: 2829 0d0a 2020 2020 2020 2020 795f 3220  ()..        y_2 
-0001a600: 3d20 6d6f 6465 6c5f 322e 7369 6d75 6c61  = model_2.simula
-0001a610: 7465 2829 0d0a 0d0a 2020 2020 2020 2020  te()....        
-0001a620: 795b 6d61 736b 5d20 3d20 795f 312e 666c  y[mask] = y_1.fl
-0001a630: 6174 7465 6e28 290d 0a20 2020 2020 2020  atten()..       
-0001a640: 2079 5b6e 702e 6c6f 6769 6361 6c5f 6e6f   y[np.logical_no
-0001a650: 7428 6d61 736b 295d 203d 2079 5f32 2e66  t(mask)] = y_2.f
-0001a660: 6c61 7474 656e 2829 0d0a 0d0a 2020 2020  latten()....    
-0001a670: 2020 2020 795f 6f75 7420 3d20 795b 3a2c      y_out = y[:,
-0001a680: 206e 702e 6e65 7761 7869 735d 0d0a 2020   np.newaxis]..  
-0001a690: 2020 2020 2020 795f 6f75 7420 3d20 6e70        y_out = np
-0001a6a0: 2e68 7374 6163 6b28 2879 5f6f 7574 2c20  .hstack((y_out, 
-0001a6b0: 795f 6f75 7429 290d 0a0d 0a20 2020 2020  y_out))....     
-0001a6c0: 2020 2072 6574 7572 6e20 795f 6f75 740d     return y_out.
-0001a6d0: 0a0d 0a0d 0a63 6c61 7373 2044 6973 636f  .....class Disco
-0001a6e0: 6e74 696e 756f 7573 5269 6467 654d 616e  ntinuousRidgeMan
-0001a6f0: 7566 6163 7475 7265 4465 6361 795f 4e61  ufactureDecay_Na
-0001a700: 4e28 4162 7374 7261 6374 4d6f 6465 6c29  N(AbstractModel)
-0001a710: 3a0d 0a20 2020 2022 2222 0d0a 2020 2020  :..    """..    
-0001a720: 4e2d 6469 6d65 6e73 696f 6e61 6c20 7465  N-dimensional te
-0001a730: 7374 6675 6e63 7469 6f6e 2063 6f6e 7461  stfunction conta
-0001a740: 696e 696e 6720 6120 6c69 6e65 6172 2064  ining a linear d
-0001a750: 6973 636f 6e74 696e 7569 7479 2e0d 0a20  iscontinuity... 
-0001a760: 2020 204f 6e20 7468 6520 6f6e 6520 7369     On the one si
-0001a770: 6465 2074 6865 206f 7574 7075 7420 636f  de the output co
-0001a780: 7272 6573 706f 6e64 7320 746f 2074 6865  rresponds to the
-0001a790: 2052 6964 6765 2066 756e 6374 696f 6e0d   Ridge function.
-0001a7a0: 0a20 2020 2061 6e64 206f 6e20 7468 6520  .    and on the 
-0001a7b0: 6f74 6865 7220 7369 6465 2069 7420 636f  other side it co
-0001a7c0: 7272 6573 706f 6e64 2074 6f20 7468 6520  rrespond to the 
-0001a7d0: 4d61 6e75 6661 6374 7572 6544 6563 6179  ManufactureDecay
-0001a7e0: 2074 6573 7466 756e 6374 696f 6e2e 0d0a   testfunction...
-0001a7f0: 0d0a 2020 2020 2e2e 206d 6174 683a 3a0d  ..    .. math::.
-0001a800: 0a20 2020 2020 2020 7920 3d20 5c5c 6265  .       y = \\be
-0001a810: 6769 6e7b 6361 7365 737d 0d0a 2020 2020  gin{cases}..    
-0001a820: 2020 205c 5c74 6578 747b 4d61 6e75 6661     \\text{Manufa
-0001a830: 6374 7572 6544 6563 6179 7d28 7829 2c20  ctureDecay}(x), 
-0001a840: 2620 5c5c 7465 7874 7b69 6620 7d20 5c5c  & \\text{if } \\
-0001a850: 7375 6d5f 7b69 3d31 7d5e 7b4e 7d78 5f69  sum_{i=1}^{N}x_i
-0001a860: 205c 5c6c 6571 2031 205c 5c5c 5c0d 0a20   \\leq 1 \\\\.. 
-0001a870: 2020 2020 2020 5c5c 7465 7874 7b52 6964        \\text{Rid
-0001a880: 6765 7d28 7829 2c20 2620 5c5c 7465 7874  ge}(x), & \\text
-0001a890: 7b6f 7468 6572 7769 7365 7d0d 0a20 2020  {otherwise}..   
-0001a8a0: 2020 2020 5c5c 656e 647b 6361 7365 737d      \\end{cases}
-0001a8b0: 0d0a 0d0a 2020 2020 5061 7261 6d65 7465  ....    Paramete
-0001a8c0: 7273 0d0a 2020 2020 2d2d 2d2d 2d2d 2d2d  rs..    --------
-0001a8d0: 2d2d 0d0a 2020 2020 705b 2278 3122 5d3a  --..    p["x1"]:
-0001a8e0: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
-0001a8f0: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
-0001a900: 6964 5d0d 0a20 2020 2020 2020 2046 6972  id]..        Fir
-0001a910: 7374 2070 6172 616d 6574 6572 205b 302c  st parameter [0,
-0001a920: 2031 5d0d 0a20 2020 2070 5b22 7869 225d   1]..    p["xi"]
-0001a930: 3a20 666c 6f61 7420 6f72 206e 6461 7272  : float or ndarr
-0001a940: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
-0001a950: 7269 645d 0d0a 2020 2020 2020 2020 692d  rid]..        i-
-0001a960: 7468 2070 6172 616d 6574 6572 2064 6566  th parameter def
-0001a970: 696e 6564 2069 6e20 5b30 2c20 315d 0d0a  ined in [0, 1]..
-0001a980: 2020 2020 705b 2278 4e22 5d3a 2066 6c6f      p["xN"]: flo
-0001a990: 6174 206f 7220 6e64 6172 7261 7920 6f66  at or ndarray of
-0001a9a0: 2066 6c6f 6174 205b 6e5f 6772 6964 5d0d   float [n_grid].
-0001a9b0: 0a20 2020 2020 2020 204e 7468 2070 6172  .        Nth par
-0001a9c0: 616d 6574 6572 205b 302c 2031 5d0d 0a0d  ameter [0, 1]...
-0001a9d0: 0a20 2020 2052 6574 7572 6e73 0d0a 2020  .    Returns..  
-0001a9e0: 2020 2d2d 2d2d 2d2d 2d0d 0a20 2020 2079    -------..    y
-0001a9f0: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
-0001aa00: 6174 205b 6e5f 6772 6964 2078 2031 5d0d  at [n_grid x 1].
-0001aa10: 0a20 2020 2020 2020 204f 7574 7075 7420  .        Output 
-0001aa20: 6461 7461 0d0a 0d0a 2020 2020 4e6f 7465  data....    Note
-0001aa30: 730d 0a20 2020 202d 2d2d 2d2d 0d0a 2020  s..    -----..  
-0001aa40: 2020 2e2e 2070 6c6f 743a 3a0d 0a0d 0a20    .. plot::.... 
-0001aa50: 2020 2020 2020 696d 706f 7274 206e 756d        import num
-0001aa60: 7079 2061 7320 6e70 0d0a 2020 2020 2020  py as np..      
-0001aa70: 2066 726f 6d20 7079 6770 632e 7465 7374   from pygpc.test
-0001aa80: 6675 6e63 7469 6f6e 7320 696d 706f 7274  functions import
-0001aa90: 2070 6c6f 745f 7465 7374 6675 6e63 7469   plot_testfuncti
-0001aaa0: 6f6e 2061 7320 706c 6f74 0d0a 2020 2020  on as plot..    
-0001aab0: 2020 2066 726f 6d20 636f 6c6c 6563 7469     from collecti
-0001aac0: 6f6e 7320 696d 706f 7274 204f 7264 6572  ons import Order
-0001aad0: 6564 4469 6374 0d0a 0d0a 2020 2020 2020  edDict....      
-0001aae0: 2070 6172 616d 6574 6572 7320 3d20 4f72   parameters = Or
-0001aaf0: 6465 7265 6444 6963 7428 290d 0a20 2020  deredDict()..   
-0001ab00: 2020 2020 7061 7261 6d65 7465 7273 5b22      parameters["
-0001ab10: 7831 225d 203d 206e 702e 6c69 6e73 7061  x1"] = np.linspa
-0001ab20: 6365 2830 2c20 312c 2032 3530 290d 0a20  ce(0, 1, 250).. 
-0001ab30: 2020 2020 2020 7061 7261 6d65 7465 7273        parameters
-0001ab40: 5b22 7832 225d 203d 206e 702e 6c69 6e73  ["x2"] = np.lins
-0001ab50: 7061 6365 2830 2c20 312c 2032 3530 290d  pace(0, 1, 250).
-0001ab60: 0a0d 0a20 2020 2020 2020 706c 6f74 2822  ...       plot("
-0001ab70: 4469 7363 6f6e 7469 6e75 6f75 7352 6964  DiscontinuousRid
-0001ab80: 6765 4d61 6e75 6661 6374 7572 6544 6563  geManufactureDec
-0001ab90: 6179 222c 2070 6172 616d 6574 6572 7329  ay", parameters)
-0001aba0: 0d0a 2020 2020 2222 220d 0a0d 0a20 2020  ..    """....   
-0001abb0: 2064 6566 205f 5f69 6e69 745f 5f28 7365   def __init__(se
-0001abc0: 6c66 2c20 6d61 746c 6162 5f6d 6f64 656c  lf, matlab_model
-0001abd0: 3d46 616c 7365 293a 0d0a 2020 2020 2020  =False):..      
-0001abe0: 2020 7375 7065 7228 7479 7065 2873 656c    super(type(sel
-0001abf0: 6629 2c20 7365 6c66 292e 5f5f 696e 6974  f), self).__init
-0001ac00: 5f5f 286d 6174 6c61 625f 6d6f 6465 6c3d  __(matlab_model=
-0001ac10: 6d61 746c 6162 5f6d 6f64 656c 290d 0a20  matlab_model).. 
-0001ac20: 2020 2020 2020 2073 656c 662e 666e 616d         self.fnam
-0001ac30: 6520 3d20 696e 7370 6563 742e 6765 7466  e = inspect.getf
-0001ac40: 696c 6528 696e 7370 6563 742e 6375 7272  ile(inspect.curr
-0001ac50: 656e 7466 7261 6d65 2829 290d 0a0d 0a20  entframe()).... 
-0001ac60: 2020 2064 6566 2076 616c 6964 6174 6528     def validate(
-0001ac70: 7365 6c66 293a 0d0a 2020 2020 2020 2020  self):..        
-0001ac80: 7061 7373 0d0a 0d0a 2020 2020 6465 6620  pass....    def 
-0001ac90: 7369 6d75 6c61 7465 2873 656c 662c 2070  simulate(self, p
-0001aca0: 726f 6365 7373 5f69 643d 4e6f 6e65 2c20  rocess_id=None, 
-0001acb0: 6d61 746c 6162 5f65 6e67 696e 653d 4e6f  matlab_engine=No
-0001acc0: 6e65 293a 0d0a 0d0a 2020 2020 2020 2020  ne):....        
-0001acd0: 666f 7220 6b65 7920 696e 2073 656c 662e  for key in self.
-0001ace0: 702e 6b65 7973 2829 3a0d 0a20 2020 2020  p.keys():..     
-0001acf0: 2020 2020 2020 2069 6620 7365 6c66 2e70         if self.p
-0001ad00: 5b6b 6579 5d2e 6e64 696d 203d 3d20 313a  [key].ndim == 1:
-0001ad10: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0001ad20: 2020 7365 6c66 2e70 5b6b 6579 5d20 3d20    self.p[key] = 
-0001ad30: 7365 6c66 2e70 5b6b 6579 5d5b 3a2c 206e  self.p[key][:, n
-0001ad40: 702e 6e65 7761 7869 735d 0d0a 0d0a 2020  p.newaxis]....  
-0001ad50: 2020 2020 2020 7820 3d20 6e70 2e68 7374        x = np.hst
-0001ad60: 6163 6b28 5b73 656c 662e 705b 6b65 795d  ack([self.p[key]
-0001ad70: 2066 6f72 206b 6579 2069 6e20 7365 6c66   for key in self
-0001ad80: 2e70 2e6b 6579 7328 295d 290d 0a0d 0a20  .p.keys()]).... 
-0001ad90: 2020 2020 2020 2079 203d 206e 702e 7a65         y = np.ze
-0001ada0: 726f 7328 782e 7368 6170 655b 305d 290d  ros(x.shape[0]).
-0001adb0: 0a20 2020 2020 2020 206d 6173 6b20 3d20  .        mask = 
-0001adc0: 286e 702e 7375 6d28 782c 2061 7869 733d  (np.sum(x, axis=
-0001add0: 3129 203c 3d20 312e 292e 666c 6174 7465  1) <= 1.).flatte
-0001ade0: 6e28 290d 0a20 2020 2020 2020 2023 206d  n()..        # m
-0001adf0: 6173 6b20 3d20 6e70 2e6c 6f67 6963 616c  ask = np.logical
-0001ae00: 5f61 6e64 286d 6173 6b2c 206e 702e 6c69  _and(mask, np.li
-0001ae10: 6e61 6c67 2e6e 6f72 6d28 782d 302e 3835  nalg.norm(x-0.85
-0001ae20: 2c20 6178 6973 3d31 2920 3e20 2e38 290d  , axis=1) > .8).
-0001ae30: 0a0d 0a20 2020 2020 2020 2070 5f31 203d  ...        p_1 =
-0001ae40: 204f 7264 6572 6564 4469 6374 2829 0d0a   OrderedDict()..
-0001ae50: 2020 2020 2020 2020 705f 3220 3d20 4f72          p_2 = Or
-0001ae60: 6465 7265 6444 6963 7428 290d 0a0d 0a20  deredDict().... 
-0001ae70: 2020 2020 2020 2066 6f72 2069 2c20 6b65         for i, ke
-0001ae80: 7920 696e 2065 6e75 6d65 7261 7465 2873  y in enumerate(s
-0001ae90: 656c 662e 702e 6b65 7973 2829 293a 0d0a  elf.p.keys()):..
-0001aea0: 2020 2020 2020 2020 2020 2020 705f 315b              p_1[
-0001aeb0: 6b65 795d 203d 2078 5b6d 6173 6b2c 2069  key] = x[mask, i
-0001aec0: 5d0d 0a20 2020 2020 2020 2020 2020 2070  ]..            p
-0001aed0: 5f32 5b6b 6579 5d20 3d20 785b 6e70 2e6c  _2[key] = x[np.l
-0001aee0: 6f67 6963 616c 5f6e 6f74 286d 6173 6b29  ogical_not(mask)
-0001aef0: 2c20 695d 0d0a 0d0a 2020 2020 2020 2020  , i]....        
-0001af00: 6d6f 6465 6c5f 3120 3d20 4d61 6e75 6661  model_1 = Manufa
-0001af10: 6374 7572 6544 6563 6179 2829 2e73 6574  ctureDecay().set
-0001af20: 5f70 6172 616d 6574 6572 7328 705f 3129  _parameters(p_1)
-0001af30: 0d0a 2020 2020 2020 2020 6d6f 6465 6c5f  ..        model_
-0001af40: 3220 3d20 5269 6467 6528 292e 7365 745f  2 = Ridge().set_
-0001af50: 7061 7261 6d65 7465 7273 2870 5f32 290d  parameters(p_2).
-0001af60: 0a0d 0a20 2020 2020 2020 2079 5f31 203d  ...        y_1 =
-0001af70: 206d 6f64 656c 5f31 2e73 696d 756c 6174   model_1.simulat
-0001af80: 6528 290d 0a20 2020 2020 2020 2079 5f32  e()..        y_2
-0001af90: 203d 206d 6f64 656c 5f32 2e73 696d 756c   = model_2.simul
-0001afa0: 6174 6528 290d 0a0d 0a20 2020 2020 2020  ate()....       
-0001afb0: 2079 5b6d 6173 6b5d 203d 2079 5f31 2e66   y[mask] = y_1.f
-0001afc0: 6c61 7474 656e 2829 0d0a 2020 2020 2020  latten()..      
-0001afd0: 2020 795b 6e70 2e6c 6f67 6963 616c 5f6e    y[np.logical_n
-0001afe0: 6f74 286d 6173 6b29 5d20 3d20 795f 322e  ot(mask)] = y_2.
-0001aff0: 666c 6174 7465 6e28 290d 0a0d 0a20 2020  flatten()....   
-0001b000: 2020 2020 2079 5f6f 7574 203d 2079 5b3a       y_out = y[:
-0001b010: 2c20 6e70 2e6e 6577 6178 6973 5d0d 0a20  , np.newaxis].. 
-0001b020: 2020 2020 2020 2079 5f6f 7574 203d 206e         y_out = n
-0001b030: 702e 6873 7461 636b 2828 795f 6f75 742c  p.hstack((y_out,
-0001b040: 2079 5f6f 7574 2929 0d0a 0d0a 2020 2020   y_out))....    
-0001b050: 2020 2020 2320 696e 7365 7274 2073 6f6d      # insert som
-0001b060: 6520 4e61 4e20 7661 6c75 6573 2066 6f72  e NaN values for
-0001b070: 2074 6573 7469 6e67 0d0a 2020 2020 2020   testing..      
-0001b080: 2020 6d61 736b 203d 2028 7365 6c66 2e70    mask = (self.p
-0001b090: 5b6c 6973 7428 7365 6c66 2e70 2e6b 6579  [list(self.p.key
-0001b0a0: 7328 2929 5b30 5d5d 203e 2030 2e38 292e  s())[0]] > 0.8).
-0001b0b0: 666c 6174 7465 6e28 290d 0a20 2020 2020  flatten()..     
-0001b0c0: 2020 2079 5f6f 7574 5b6d 6173 6b2c 2030     y_out[mask, 0
-0001b0d0: 5d20 3d20 6e70 2e4e 614e 0d0a 0d0a 2020  ] = np.NaN....  
-0001b0e0: 2020 2020 2020 7265 7475 726e 2079 5f6f        return y_o
-0001b0f0: 7574 0d0a 0d0a 0d0a 636c 6173 7320 4f61  ut......class Oa
-0001b100: 6b6c 6579 4f68 6167 616e 3230 3034 2841  kleyOhagan2004(A
-0001b110: 6273 7472 6163 744d 6f64 656c 293a 0d0a  bstractModel):..
-0001b120: 2020 2020 2320 546f 646f 3a20 404c 7563      # Todo: @Luc
-0001b130: 6173 3a20 7265 6d6f 7665 2074 6578 7420  as: remove text 
-0001b140: 6669 6c65 730d 0a20 2020 2022 2222 0d0a  files..    """..
-0001b150: 2020 2020 3135 2d64 696d 656e 7369 6f6e      15-dimension
-0001b160: 616c 2074 6573 7420 6675 6e63 7469 6f6e  al test function
-0001b170: 206f 6620 4f61 6b6c 6579 2061 6e64 204f   of Oakley and O
-0001b180: 2748 6167 616e 2028 3230 3034 2920 5b31  'Hagan (2004) [1
-0001b190: 5d2e 0d0a 0d0a 2020 2020 5468 6973 2066  ].....    This f
-0001b1a0: 756e 6374 696f 6e27 7320 612d 636f 6566  unction's a-coef
-0001b1b0: 6669 6369 656e 7473 2061 7265 2063 686f  ficients are cho
-0001b1c0: 7365 6e20 736f 2074 6861 7420 3520 6f66  sen so that 5 of
-0001b1d0: 2074 6865 2069 6e70 7574 0d0a 2020 2020   the input..    
-0001b1e0: 7661 7269 6162 6c65 7320 636f 6e74 7269  variables contri
-0001b1f0: 6275 7465 2073 6967 6e69 6669 6361 6e74  bute significant
-0001b200: 6c79 2074 6f20 7468 6520 6f75 7470 7574  ly to the output
-0001b210: 2076 6172 6961 6e63 652c 2035 2068 6176   variance, 5 hav
-0001b220: 6520 610d 0a20 2020 206d 7563 6820 736d  e a..    much sm
-0001b230: 616c 6c65 7220 6566 6665 6374 2c20 616e  aller effect, an
-0001b240: 6420 7468 6520 7265 6d61 696e 696e 6720  d the remaining 
-0001b250: 3520 6861 7665 2061 6c6d 6f73 7420 6e6f  5 have almost no
-0001b260: 2065 6666 6563 7420 6f6e 2074 6865 0d0a   effect on the..
-0001b270: 2020 2020 6f75 7470 7574 2076 6172 6961      output varia
-0001b280: 6e63 652e 0d0a 0d0a 2020 2020 2e2e 206d  nce.....    .. m
-0001b290: 6174 683a 3a0d 0a20 2020 2020 2020 7920  ath::..       y 
-0001b2a0: 3d20 5c6d 6174 6862 667b 617d 5f31 5e54  = \mathbf{a}_1^T
-0001b2b0: 5c6d 6174 6862 667b 787d 202b 205c 6d61  \mathbf{x} + \ma
-0001b2c0: 7468 6266 7b61 7d5f 325e 5420 5c73 696e  thbf{a}_2^T \sin
-0001b2d0: 285c 6d61 7468 6266 7b78 7d29 202b 205c  (\mathbf{x}) + \
-0001b2e0: 6d61 7468 6266 7b61 7d5f 335e 5420 5c63  mathbf{a}_3^T \c
-0001b2f0: 6f73 285c 6d61 7468 6266 7b78 7d29 202b  os(\mathbf{x}) +
-0001b300: 0d0a 2020 2020 2020 205c 6d61 7468 6266  ..       \mathbf
-0001b310: 7b78 7d5e 545c 6d61 7468 6266 7b4d 7d5c  {x}^T\mathbf{M}\
-0001b320: 6d61 7468 6266 7b78 7d0d 0a0d 0a20 2020  mathbf{x}....   
-0001b330: 2054 6865 2070 6172 616d 6574 6572 2076   The parameter v
-0001b340: 6563 746f 7273 2061 2061 6e64 206d 6174  ectors a and mat
-0001b350: 7269 7820 4d20 6172 6520 696e 202f 7079  rix M are in /py
-0001b360: 6770 632f 7063 6b2f 6461 7461 2f6f 616b  gpc/pck/data/oak
-0001b370: 6c65 795f 6f68 6167 616e 5f32 3030 342e  ley_ohagan_2004.
-0001b380: 0d0a 0d0a 2020 2020 5061 7261 6d65 7465  ....    Paramete
-0001b390: 7273 0d0a 2020 2020 2d2d 2d2d 2d2d 2d2d  rs..    --------
-0001b3a0: 2d2d 0d0a 2020 2020 705b 2278 312e 2e2e  --..    p["x1...
-0001b3b0: 3135 225d 3a20 6e64 6172 7261 7920 6f66  15"]: ndarray of
-0001b3c0: 2066 6c6f 6174 205b 6e5f 6772 6964 5d0d   float [n_grid].
-0001b3d0: 0a20 2020 2020 2020 2049 6e70 7574 2064  .        Input d
-0001b3e0: 6174 612c 2078 6920 7e20 4e28 6d75 3d30  ata, xi ~ N(mu=0
-0001b3f0: 2c20 7369 676d 613d 3129 2c20 666f 7220  , sigma=1), for 
-0001b400: 616c 6c20 6920 3d20 312c 2032 2c2e 2e2e  all i = 1, 2,...
-0001b410: 2c20 3135 2e0d 0a0d 0a20 2020 2052 6574  , 15.....    Ret
-0001b420: 7572 6e73 0d0a 2020 2020 2d2d 2d2d 2d2d  urns..    ------
-0001b430: 2d0d 0a20 2020 2079 3a20 6e64 6172 7261  -..    y: ndarra
-0001b440: 7920 6f66 2066 6c6f 6174 205b 4e5f 696e  y of float [N_in
-0001b450: 7075 7420 7820 315d 0d0a 2020 2020 2020  put x 1]..      
-0001b460: 2020 4f75 7470 7574 2064 6174 610d 0a0d    Output data...
-0001b470: 0a20 2020 204e 6f74 6573 0d0a 2020 2020  .    Notes..    
-0001b480: 2d2d 2d2d 2d0d 0a20 2020 202e 2e20 5b31  -----..    .. [1
-0001b490: 5d20 4f61 6b6c 6579 2c20 4a2e 2045 2e2c  ] Oakley, J. E.,
-0001b4a0: 2026 204f 2748 6167 616e 2c20 412e 2028   & O'Hagan, A. (
-0001b4b0: 3230 3034 292e 2050 726f 6261 6269 6c69  2004). Probabili
-0001b4c0: 7374 6963 2073 656e 7369 7469 7669 7479  stic sensitivity
-0001b4d0: 2061 6e61 6c79 7369 730d 0a20 2020 2020   analysis..     
-0001b4e0: 2020 6f66 2063 6f6d 706c 6578 206d 6f64    of complex mod
-0001b4f0: 656c 733a 2061 2042 6179 6573 6961 6e20  els: a Bayesian 
-0001b500: 6170 7072 6f61 6368 2e20 4a6f 7572 6e61  approach. Journa
-0001b510: 6c20 6f66 2074 6865 2052 6f79 616c 2053  l of the Royal S
-0001b520: 7461 7469 7374 6963 616c 0d0a 2020 2020  tatistical..    
-0001b530: 2020 2053 6f63 6965 7479 3a20 5365 7269     Society: Seri
-0001b540: 6573 2042 2028 5374 6174 6973 7469 6361  es B (Statistica
-0001b550: 6c20 4d65 7468 6f64 6f6c 6f67 7929 2c20  l Methodology), 
-0001b560: 3636 2833 292c 2037 3531 2d37 3639 2e0d  66(3), 751-769..
-0001b570: 0a20 2020 2022 2222 0d0a 0d0a 2020 2020  .    """....    
-0001b580: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
-0001b590: 662c 206d 6174 6c61 625f 6d6f 6465 6c3d  f, matlab_model=
-0001b5a0: 4661 6c73 6529 3a0d 0a20 2020 2020 2020  False):..       
-0001b5b0: 2073 7570 6572 2874 7970 6528 7365 6c66   super(type(self
-0001b5c0: 292c 2073 656c 6629 2e5f 5f69 6e69 745f  ), self).__init_
-0001b5d0: 5f28 6d61 746c 6162 5f6d 6f64 656c 3d6d  _(matlab_model=m
-0001b5e0: 6174 6c61 625f 6d6f 6465 6c29 0d0a 2020  atlab_model)..  
-0001b5f0: 2020 2020 2020 7365 6c66 2e66 6e61 6d65        self.fname
-0001b600: 203d 2069 6e73 7065 6374 2e67 6574 6669   = inspect.getfi
-0001b610: 6c65 2869 6e73 7065 6374 2e63 7572 7265  le(inspect.curre
-0001b620: 6e74 6672 616d 6528 2929 0d0a 0d0a 2020  ntframe())....  
-0001b630: 2020 6465 6620 7661 6c69 6461 7465 2873    def validate(s
-0001b640: 656c 6629 3a0d 0a20 2020 2020 2020 2070  elf):..        p
-0001b650: 6173 730d 0a0d 0a20 2020 2064 6566 2073  ass....    def s
-0001b660: 696d 756c 6174 6528 7365 6c66 2c20 7072  imulate(self, pr
-0001b670: 6f63 6573 735f 6964 3d4e 6f6e 652c 206d  ocess_id=None, m
-0001b680: 6174 6c61 625f 656e 6769 6e65 3d4e 6f6e  atlab_engine=Non
-0001b690: 6529 3a0d 0a20 2020 2020 2020 2023 206c  e):..        # l
-0001b6a0: 6f61 6420 636f 6566 6669 6369 656e 7473  oad coefficients
-0001b6b0: 0d0a 2020 2020 2020 2020 666f 6c64 6572  ..        folder
-0001b6c0: 203d 206f 732e 7061 7468 2e73 706c 6974   = os.path.split
-0001b6d0: 286f 732e 7061 7468 2e64 6972 6e61 6d65  (os.path.dirname
-0001b6e0: 285f 5f66 696c 655f 5f29 295b 305d 0d0a  (__file__))[0]..
-0001b6f0: 2020 2020 2020 2020 6d20 3d20 6e70 2e6c          m = np.l
-0001b700: 6f61 6474 7874 286f 732e 7061 7468 2e6a  oadtxt(os.path.j
-0001b710: 6f69 6e28 666f 6c64 6572 2c20 226f 616b  oin(folder, "oak
-0001b720: 6c65 795f 6f68 6167 616e 5f32 3030 345f  ley_ohagan_2004_
-0001b730: 4d2e 7478 7422 2929 0d0a 2020 2020 2020  M.txt"))..      
-0001b740: 2020 6131 203d 206e 702e 6c6f 6164 7478    a1 = np.loadtx
-0001b750: 7428 6f73 2e70 6174 682e 6a6f 696e 2866  t(os.path.join(f
-0001b760: 6f6c 6465 722c 2022 6f61 6b6c 6579 5f6f  older, "oakley_o
-0001b770: 6861 6761 6e5f 3230 3034 5f61 312e 7478  hagan_2004_a1.tx
-0001b780: 7422 2929 0d0a 2020 2020 2020 2020 6132  t"))..        a2
-0001b790: 203d 206e 702e 6c6f 6164 7478 7428 6f73   = np.loadtxt(os
-0001b7a0: 2e70 6174 682e 6a6f 696e 2866 6f6c 6465  .path.join(folde
-0001b7b0: 722c 2022 6f61 6b6c 6579 5f6f 6861 6761  r, "oakley_ohaga
-0001b7c0: 6e5f 3230 3034 5f61 322e 7478 7422 2929  n_2004_a2.txt"))
-0001b7d0: 0d0a 2020 2020 2020 2020 6133 203d 206e  ..        a3 = n
-0001b7e0: 702e 6c6f 6164 7478 7428 6f73 2e70 6174  p.loadtxt(os.pat
-0001b7f0: 682e 6a6f 696e 2866 6f6c 6465 722c 2022  h.join(folder, "
-0001b800: 6f61 6b6c 6579 5f6f 6861 6761 6e5f 3230  oakley_ohagan_20
-0001b810: 3034 5f61 332e 7478 7422 2929 0d0a 0d0a  04_a3.txt"))....
-0001b820: 2020 2020 2020 2020 7820 3d20 6e70 2e7a          x = np.z
-0001b830: 6572 6f73 2828 7365 6c66 2e70 5b6c 6973  eros((self.p[lis
-0001b840: 7428 7365 6c66 2e70 2e6b 6579 7328 2929  t(self.p.keys())
-0001b850: 5b30 5d5d 2e73 697a 652c 2031 3529 290d  [0]].size, 15)).
-0001b860: 0a0d 0a20 2020 2020 2020 2066 6f72 2069  ...        for i
-0001b870: 2c20 6b65 7920 696e 2065 6e75 6d65 7261  , key in enumera
-0001b880: 7465 2873 656c 662e 702e 6b65 7973 2829  te(self.p.keys()
-0001b890: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
-0001b8a0: 785b 3a2c 2069 5d20 3d20 7365 6c66 2e70  x[:, i] = self.p
-0001b8b0: 5b6b 6579 5d0d 0a0d 0a20 2020 2020 2020  [key]....       
-0001b8c0: 2023 2066 756e 6374 696f 6e0d 0a20 2020   # function..   
-0001b8d0: 2020 2020 2079 203d 2028 6e70 2e64 6f74       y = (np.dot
-0001b8e0: 2878 2c20 6131 2920 2b20 6e70 2e64 6f74  (x, a1) + np.dot
-0001b8f0: 286e 702e 7369 6e28 7829 2c20 6132 290d  (np.sin(x), a2).
-0001b900: 0a20 2020 2020 2020 2020 2020 2020 2b20  .             + 
-0001b910: 6e70 2e64 6f74 286e 702e 636f 7328 7829  np.dot(np.cos(x)
-0001b920: 2c20 6133 2920 2b20 6e70 2e73 756d 286e  , a3) + np.sum(n
-0001b930: 702e 6d75 6c74 6970 6c79 286e 702e 646f  p.multiply(np.do
-0001b940: 7428 782c 206d 292c 2078 292c 2061 7869  t(x, m), x), axi
-0001b950: 733d 3129 290d 0a0d 0a20 2020 2020 2020  s=1))....       
-0001b960: 2079 5f6f 7574 203d 2079 5b3a 2c20 6e70   y_out = y[:, np
-0001b970: 2e6e 6577 6178 6973 5d0d 0a0d 0a20 2020  .newaxis]....   
-0001b980: 2020 2020 2072 6574 7572 6e20 795f 6f75       return y_ou
-0001b990: 740d 0a0d 0a0d 0a63 6c61 7373 2057 656c  t......class Wel
-0001b9a0: 6368 3139 3932 2841 6273 7472 6163 744d  ch1992(AbstractM
-0001b9b0: 6f64 656c 293a 0d0a 2020 2020 2222 220d  odel):..    """.
-0001b9c0: 0a20 2020 2032 302d 6469 6d65 6e73 696f  .    20-dimensio
-0001b9d0: 6e61 6c20 7465 7374 2066 756e 6374 696f  nal test functio
-0001b9e0: 6e20 6f66 2057 656c 6368 2065 7420 616c  n of Welch et al
-0001b9f0: 2e20 2831 3939 3229 205b 315d 2e0d 0a0d  . (1992) [1]....
-0001ba00: 0a20 2020 2046 6f72 2069 6e70 7574 2076  .    For input v
-0001ba10: 6172 6961 626c 6520 7363 7265 656e 696e  ariable screenin
-0001ba20: 6720 7075 7270 6f73 6573 2c20 6974 2063  g purposes, it c
-0001ba30: 616e 2062 6520 666f 756e 6420 7468 6174  an be found that
-0001ba40: 2073 6f6d 6520 696e 7075 740d 0a20 2020   some input..   
-0001ba50: 2076 6172 6961 626c 6573 206f 6620 7468   variables of th
-0001ba60: 6973 2066 756e 6374 696f 6e20 6861 7665  is function have
-0001ba70: 2061 2076 6572 7920 6869 6768 2065 6666   a very high eff
-0001ba80: 6563 7420 6f6e 2074 6865 206f 7574 7075  ect on the outpu
-0001ba90: 742c 0d0a 2020 2020 636f 6d70 6172 6564  t,..    compared
-0001baa0: 2074 6f20 6f74 6865 7220 696e 7075 7420   to other input 
-0001bab0: 7661 7269 6162 6c65 732e 2041 7320 5765  variables. As We
-0001bac0: 6c63 6820 6574 2061 6c2e 2028 3139 3932  lch et al. (1992
-0001bad0: 2920 5b31 5d20 706f 696e 7420 6f75 742c  ) [1] point out,
-0001bae0: 0d0a 2020 2020 696e 7465 7261 6374 696f  ..    interactio
-0001baf0: 6e73 2061 6e64 206e 6f6e 6c69 6e65 6172  ns and nonlinear
-0001bb00: 2065 6666 6563 7473 206d 616b 6520 7468   effects make th
-0001bb10: 6973 2066 756e 6374 696f 6e20 6368 616c  is function chal
-0001bb20: 6c65 6e67 696e 672e 0d0a 0d0a 2020 2020  lenging.....    
-0001bb30: 2e2e 206d 6174 683a 3a0d 0a20 2020 2020  .. math::..     
-0001bb40: 2020 7920 3d20 5c5c 6672 6163 7b35 2078    y = \\frac{5 x
-0001bb50: 5f7b 3132 7d7d 7b31 202b 2078 5f31 7d20  _{12}}{1 + x_1} 
-0001bb60: 2b20 3520 2878 5f34 202d 2078 5f7b 3230  + 5 (x_4 - x_{20
-0001bb70: 7d29 5e32 202b 2078 5f35 202b 2034 3020  })^2 + x_5 + 40 
-0001bb80: 785f 7b31 397d 5e33 202b 2035 2078 5f7b  x_{19}^3 + 5 x_{
-0001bb90: 3139 7d20 2b20 302e 3035 2078 5f32 0d0a  19} + 0.05 x_2..
-0001bba0: 2020 2020 2020 202b 2030 2e30 3820 785f         + 0.08 x_
-0001bbb0: 3320 2d20 302e 3033 2078 5f36 202b 2030  3 - 0.03 x_6 + 0
-0001bbc0: 2e30 3320 785f 3720 2d20 302e 3039 2078  .03 x_7 - 0.09 x
-0001bbd0: 5f39 202d 2030 2e30 3120 785f 7b31 307d  _9 - 0.01 x_{10}
-0001bbe0: 202d 0d0a 0d0a 2020 2020 2020 2030 2e30   -....       0.0
-0001bbf0: 3720 785f 7b31 317d 202b 2030 2e32 3520  7 x_{11} + 0.25 
-0001bc00: 785f 7b31 337d 5e32 202d 2030 2e30 3420  x_{13}^2 - 0.04 
-0001bc10: 785f 7b31 347d 202b 2030 2e30 3620 785f  x_{14} + 0.06 x_
-0001bc20: 7b31 357d 202d 2030 2e30 3120 785f 7b31  {15} - 0.01 x_{1
-0001bc30: 377d 202d 2030 2e30 3320 785f 7b31 387d  7} - 0.03 x_{18}
-0001bc40: 0d0a 0d0a 2020 2020 5061 7261 6d65 7465  ....    Paramete
-0001bc50: 7273 0d0a 2020 2020 2d2d 2d2d 2d2d 2d2d  rs..    --------
-0001bc60: 2d2d 0d0a 2020 2020 705b 2278 312e 2e2e  --..    p["x1...
-0001bc70: 7832 3022 5d3a 2066 6c6f 6174 0d0a 2020  x20"]: float..  
-0001bc80: 2020 2020 2020 496e 7075 7420 6461 7461        Input data
-0001bc90: 2c20 7869 207e 2055 282d 302e 352c 2030  , xi ~ U(-0.5, 0
-0001bca0: 2e35 292c 2066 6f72 2061 6c6c 2069 203d  .5), for all i =
-0001bcb0: 2031 2c2e 2e2e 2c20 3230 2e0d 0a0d 0a20   1,..., 20..... 
-0001bcc0: 2020 2052 6574 7572 6e73 0d0a 2020 2020     Returns..    
-0001bcd0: 2d2d 2d2d 2d2d 2d0d 0a20 2020 2079 3a20  -------..    y: 
-0001bce0: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-0001bcf0: 205b 6e5f 6772 6964 2078 2031 5d0d 0a20   [n_grid x 1].. 
-0001bd00: 2020 2020 2020 204f 7574 7075 7420 6461         Output da
-0001bd10: 7461 0d0a 0d0a 2020 2020 4e6f 7465 730d  ta....    Notes.
-0001bd20: 0a20 2020 202d 2d2d 2d2d 0d0a 2020 2020  .    -----..    
-0001bd30: 2e2e 205b 315d 2057 656c 6368 2c20 572e  .. [1] Welch, W.
-0001bd40: 204a 2e2c 2042 7563 6b2c 2052 2e20 4a2e   J., Buck, R. J.
-0001bd50: 2c20 5361 636b 732c 204a 2e2c 2057 796e  , Sacks, J., Wyn
-0001bd60: 6e2c 2048 2e20 502e 2c20 4d69 7463 6865  n, H. P., Mitche
-0001bd70: 6c6c 2c20 542e 204a 2e2c 204d 6f72 7269  ll, T. J., Morri
-0001bd80: 732c 204d 2e20 442e 2028 3139 3932 292e  s, M. D. (1992).
-0001bd90: 0d0a 2020 2020 2020 2053 6372 6565 6e69  ..       Screeni
-0001bda0: 6e67 2c20 7072 6564 6963 7469 6e67 2c20  ng, predicting, 
-0001bdb0: 616e 6420 636f 6d70 7574 6572 2065 7870  and computer exp
-0001bdc0: 6572 696d 656e 7473 2e20 5465 6368 6e6f  eriments. Techno
-0001bdd0: 6d65 7472 6963 732c 2033 3428 3129 2c20  metrics, 34(1), 
-0001bde0: 3135 2d32 352e 0d0a 2020 2020 2222 220d  15-25...    """.
-0001bdf0: 0a0d 0a20 2020 2064 6566 205f 5f69 6e69  ...    def __ini
-0001be00: 745f 5f28 7365 6c66 2c20 6d61 746c 6162  t__(self, matlab
-0001be10: 5f6d 6f64 656c 3d46 616c 7365 293a 0d0a  _model=False):..
-0001be20: 2020 2020 2020 2020 7375 7065 7228 7479          super(ty
-0001be30: 7065 2873 656c 6629 2c20 7365 6c66 292e  pe(self), self).
-0001be40: 5f5f 696e 6974 5f5f 286d 6174 6c61 625f  __init__(matlab_
-0001be50: 6d6f 6465 6c3d 6d61 746c 6162 5f6d 6f64  model=matlab_mod
-0001be60: 656c 290d 0a20 2020 2020 2020 2073 656c  el)..        sel
-0001be70: 662e 666e 616d 6520 3d20 696e 7370 6563  f.fname = inspec
-0001be80: 742e 6765 7466 696c 6528 696e 7370 6563  t.getfile(inspec
-0001be90: 742e 6375 7272 656e 7466 7261 6d65 2829  t.currentframe()
-0001bea0: 290d 0a0d 0a20 2020 2064 6566 2076 616c  )....    def val
-0001beb0: 6964 6174 6528 7365 6c66 293a 0d0a 2020  idate(self):..  
-0001bec0: 2020 2020 2020 7061 7373 0d0a 0d0a 2020        pass....  
-0001bed0: 2020 6465 6620 7369 6d75 6c61 7465 2873    def simulate(s
-0001bee0: 656c 662c 2070 726f 6365 7373 5f69 643d  elf, process_id=
-0001bef0: 4e6f 6e65 2c20 6d61 746c 6162 5f65 6e67  None, matlab_eng
-0001bf00: 696e 653d 4e6f 6e65 293a 0d0a 2020 2020  ine=None):..    
-0001bf10: 2020 2020 7920 3d20 2835 2e30 202a 2073      y = (5.0 * s
-0001bf20: 656c 662e 705b 2278 3132 225d 202f 2028  elf.p["x12"] / (
-0001bf30: 3120 2b20 7365 6c66 2e70 5b22 7831 225d  1 + self.p["x1"]
-0001bf40: 2920 2b20 3520 2a20 2873 656c 662e 705b  ) + 5 * (self.p[
-0001bf50: 2278 3422 5d20 2d20 7365 6c66 2e70 5b22  "x4"] - self.p["
-0001bf60: 7832 3022 5d29 202a 2a20 320d 0a20 2020  x20"]) ** 2..   
-0001bf70: 2020 2020 2020 2020 2020 2b20 7365 6c66            + self
-0001bf80: 2e70 5b22 7835 225d 202b 2034 3020 2a20  .p["x5"] + 40 * 
-0001bf90: 7365 6c66 2e70 5b22 7831 3922 5d20 2a2a  self.p["x19"] **
-0001bfa0: 2033 202b 2035 202a 2073 656c 662e 705b   3 + 5 * self.p[
-0001bfb0: 2278 3139 225d 202b 2030 2e30 3520 2a20  "x19"] + 0.05 * 
-0001bfc0: 7365 6c66 2e70 5b22 7832 225d 0d0a 2020  self.p["x2"]..  
-0001bfd0: 2020 2020 2020 2020 2020 202b 2030 2e30             + 0.0
-0001bfe0: 3820 2a20 7365 6c66 2e70 5b22 7833 225d  8 * self.p["x3"]
-0001bff0: 202d 2030 2e30 3320 2a20 7365 6c66 2e70   - 0.03 * self.p
-0001c000: 5b22 7836 225d 202b 2030 2e30 3320 2a20  ["x6"] + 0.03 * 
-0001c010: 7365 6c66 2e70 5b22 7837 225d 0d0a 2020  self.p["x7"]..  
-0001c020: 2020 2020 2020 2020 2020 202d 2030 2e30             - 0.0
-0001c030: 3920 2a20 7365 6c66 2e70 5b22 7839 225d  9 * self.p["x9"]
-0001c040: 202d 2030 2e30 3120 2a20 7365 6c66 2e70   - 0.01 * self.p
-0001c050: 5b22 7831 3022 5d20 2d20 302e 3037 202a  ["x10"] - 0.07 *
-0001c060: 2073 656c 662e 705b 2278 3131 225d 0d0a   self.p["x11"]..
-0001c070: 2020 2020 2020 2020 2020 2020 202b 2030               + 0
-0001c080: 2e32 3520 2a20 7365 6c66 2e70 5b22 7831  .25 * self.p["x1
-0001c090: 3322 5d20 2a2a 2032 202d 2030 2e30 3420  3"] ** 2 - 0.04 
-0001c0a0: 2a20 7365 6c66 2e70 5b22 7831 3422 5d0d  * self.p["x14"].
-0001c0b0: 0a20 2020 2020 2020 2020 2020 2020 2b20  .             + 
-0001c0c0: 302e 3036 202a 2073 656c 662e 705b 2278  0.06 * self.p["x
-0001c0d0: 3135 225d 202d 2030 2e30 3120 2a20 7365  15"] - 0.01 * se
-0001c0e0: 6c66 2e70 5b22 7831 3722 5d20 2d20 302e  lf.p["x17"] - 0.
-0001c0f0: 3033 202a 2073 656c 662e 705b 2278 3138  03 * self.p["x18
-0001c100: 225d 290d 0a0d 0a20 2020 2020 2020 2079  "])....        y
-0001c110: 5f6f 7574 203d 2079 5b3a 2c20 6e70 2e6e  _out = y[:, np.n
-0001c120: 6577 6178 6973 5d0d 0a0d 0a20 2020 2020  ewaxis]....     
-0001c130: 2020 2072 6574 7572 6e20 795f 6f75 740d     return y_out.
-0001c140: 0a0d 0a0d 0a63 6c61 7373 2057 696e 6757  .....class WingW
-0001c150: 6569 6768 7428 4162 7374 7261 6374 4d6f  eight(AbstractMo
-0001c160: 6465 6c29 3a0d 0a20 2020 2022 2222 0d0a  del):..    """..
-0001c170: 2020 2020 3130 2d64 696d 656e 7369 6f6e      10-dimension
-0001c180: 616c 2074 6573 7420 6675 6e63 7469 6f6e  al test function
-0001c190: 2077 6869 6368 206d 6f64 656c 7320 6120   which models a 
-0001c1a0: 6c69 6768 7420 6169 7263 7261 6674 2077  light aircraft w
-0001c1b0: 696e 6720 6672 6f6d 2046 6f72 7265 7374  ing from Forrest
-0001c1c0: 6572 2065 7420 616c 2e20 2832 3030 3829  er et al. (2008)
-0001c1d0: 205b 315d 0d0a 0d0a 2020 2020 2e2e 206d   [1]....    .. m
-0001c1e0: 6174 683a 3a0d 0a20 2020 2020 2020 7920  ath::..       y 
-0001c1f0: 3d20 5c5c 6672 6163 7b30 2e30 3336 2078  = \\frac{0.036 x
-0001c200: 5f31 5e7b 302e 3735 387d 2078 5f32 5e7b  _1^{0.758} x_2^{
-0001c210: 302e 3030 3335 7d20 785f 337d 7b5c 636f  0.0035} x_3}{\co
-0001c220: 7328 785f 3429 5e32 295e 7b30 2e36 7d7d  s(x_4)^2)^{0.6}}
-0001c230: 2078 5f35 5e7b 302e 3030 367d 2078 5f36   x_5^{0.006} x_6
-0001c240: 5e7b 302e 3034 7d0d 0a20 2020 2020 2020  ^{0.04}..       
-0001c250: 5c5c 6c65 6674 2820 5c5c 6672 6163 7b31  \\left( \\frac{1
-0001c260: 3030 2078 5f37 7d7b 5c63 6f73 2878 5f34  00 x_7}{\cos(x_4
-0001c270: 297d 5c5c 7269 6768 7429 5e7b 2d30 2e33  )}\\right)^{-0.3
-0001c280: 7d20 2878 5f38 2078 5f39 295e 7b30 2e34  } (x_8 x_9)^{0.4
-0001c290: 397d 202b 2078 5f31 2078 5f7b 3130 7d0d  9} + x_1 x_{10}.
-0001c2a0: 0a0d 0a20 2020 2050 6172 616d 6574 6572  ...    Parameter
-0001c2b0: 730d 0a20 2020 202d 2d2d 2d2d 2d2d 2d2d  s..    ---------
-0001c2c0: 2d0d 0a20 2020 2070 5b22 7831 225d 3a20  -..    p["x1"]: 
-0001c2d0: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
-0001c2e0: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
-0001c2f0: 645d 0d0a 2020 2020 2020 2020 7831 2853  d]..        x1(S
-0001c300: 7729 205b 3135 302c 2032 3030 5d0d 0a20  w) [150, 200].. 
-0001c310: 2020 2070 5b22 7832 225d 3a20 666c 6f61     p["x2"]: floa
-0001c320: 7420 6f72 206e 6461 7272 6179 206f 6620  t or ndarray of 
-0001c330: 666c 6f61 7420 5b6e 5f67 7269 645d 0d0a  float [n_grid]..
-0001c340: 2020 2020 2020 2020 7832 2857 6677 2920          x2(Wfw) 
-0001c350: 5b32 3230 2c20 3330 305d 0d0a 2020 2020  [220, 300]..    
-0001c360: 705b 2278 3322 5d3a 2066 6c6f 6174 206f  p["x3"]: float o
-0001c370: 7220 6e64 6172 7261 7920 6f66 2066 6c6f  r ndarray of flo
-0001c380: 6174 205b 6e5f 6772 6964 5d0d 0a20 2020  at [n_grid]..   
-0001c390: 2020 2020 2078 3328 4129 205b 362c 2031       x3(A) [6, 1
-0001c3a0: 305d 0d0a 2020 2020 705b 2278 3422 5d3a  0]..    p["x4"]:
-0001c3b0: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
-0001c3c0: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
-0001c3d0: 6964 5d0d 0a20 2020 2020 2020 2078 3428  id]..        x4(
-0001c3e0: 4c61 6d62 6461 2920 5b2d 3130 2c20 3130  Lambda) [-10, 10
-0001c3f0: 5d0d 0a20 2020 2070 5b22 7835 225d 3a20  ]..    p["x5"]: 
-0001c400: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
-0001c410: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
-0001c420: 645d 0d0a 2020 2020 2020 2020 7835 2871  d]..        x5(q
-0001c430: 2920 5b31 362c 2034 355d 0d0a 2020 2020  ) [16, 45]..    
-0001c440: 705b 2278 3622 5d3a 2066 6c6f 6174 206f  p["x6"]: float o
-0001c450: 7220 6e64 6172 7261 7920 6f66 2066 6c6f  r ndarray of flo
-0001c460: 6174 205b 6e5f 6772 6964 5d0d 0a20 2020  at [n_grid]..   
-0001c470: 2020 2020 2078 3628 6c61 6d62 6461 2920       x6(lambda) 
-0001c480: 5b30 2e35 2c20 315d 0d0a 2020 2020 705b  [0.5, 1]..    p[
-0001c490: 2278 3722 5d3a 2066 6c6f 6174 206f 7220  "x7"]: float or 
-0001c4a0: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-0001c4b0: 205b 6e5f 6772 6964 5d0d 0a20 2020 2020   [n_grid]..     
-0001c4c0: 2020 2078 3728 7463 2920 5b30 2e30 382c     x7(tc) [0.08,
-0001c4d0: 2030 2e31 385d 0d0a 2020 2020 705b 2278   0.18]..    p["x
-0001c4e0: 3822 5d3a 2066 6c6f 6174 206f 7220 6e64  8"]: float or nd
-0001c4f0: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
-0001c500: 6e5f 6772 6964 5d0d 0a20 2020 2020 2020  n_grid]..       
-0001c510: 2078 3828 4e7a 2920 5b32 2e35 2c20 365d   x8(Nz) [2.5, 6]
-0001c520: 0d0a 2020 2020 705b 2278 3922 5d3a 2066  ..    p["x9"]: f
-0001c530: 6c6f 6174 206f 7220 6e64 6172 7261 7920  loat or ndarray 
-0001c540: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
-0001c550: 5d0d 0a20 2020 2020 2020 2078 3928 5764  ]..        x9(Wd
-0001c560: 6729 205b 3137 3030 2c20 3235 3030 5d0d  g) [1700, 2500].
-0001c570: 0a20 2020 2070 5b22 7831 3022 5d3a 2066  .    p["x10"]: f
-0001c580: 6c6f 6174 206f 7220 6e64 6172 7261 7920  loat or ndarray 
-0001c590: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
-0001c5a0: 5d0d 0a20 2020 2020 2020 2078 3130 2857  ]..        x10(W
-0001c5b0: 7029 205b 302e 3032 352c 2030 2e30 385d  p) [0.025, 0.08]
-0001c5c0: 0d0a 0d0a 2020 2020 5265 7475 726e 730d  ....    Returns.
-0001c5d0: 0a20 2020 202d 2d2d 2d2d 2d2d 0d0a 2020  .    -------..  
-0001c5e0: 2020 793a 2066 6c6f 6174 206f 7220 6e64    y: float or nd
-0001c5f0: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
-0001c600: 6e5f 6772 6964 2078 2031 5d0d 0a20 2020  n_grid x 1]..   
-0001c610: 2020 2020 204f 7574 7075 7420 6461 7461       Output data
-0001c620: 0d0a 0d0a 2020 2020 4e6f 7465 730d 0a20  ....    Notes.. 
-0001c630: 2020 202d 2d2d 2d2d 0d0a 2020 2020 2e2e     -----..    ..
-0001c640: 205b 315d 2046 6f72 7265 7374 6572 2c20   [1] Forrester, 
-0001c650: 412e 2c20 536f 6265 7374 6572 2c20 412e  A., Sobester, A.
-0001c660: 2c20 2620 4b65 616e 652c 2041 2e20 2832  , & Keane, A. (2
-0001c670: 3030 3829 2e0d 0a20 2020 2020 2020 456e  008)...       En
-0001c680: 6769 6e65 6572 696e 6720 6465 7369 676e  gineering design
-0001c690: 2076 6961 2073 7572 726f 6761 7465 206d   via surrogate m
-0001c6a0: 6f64 656c 6c69 6e67 3a20 6120 7072 6163  odelling: a prac
-0001c6b0: 7469 6361 6c20 6775 6964 652e 204a 6f68  tical guide. Joh
-0001c6c0: 6e20 5769 6c65 7920 2620 536f 6e73 2e0d  n Wiley & Sons..
-0001c6d0: 0a20 2020 2022 2222 0d0a 0d0a 2020 2020  .    """....    
-0001c6e0: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
-0001c6f0: 662c 206d 6174 6c61 625f 6d6f 6465 6c3d  f, matlab_model=
-0001c700: 4661 6c73 6529 3a0d 0a20 2020 2020 2020  False):..       
-0001c710: 2073 7570 6572 2874 7970 6528 7365 6c66   super(type(self
-0001c720: 292c 2073 656c 6629 2e5f 5f69 6e69 745f  ), self).__init_
-0001c730: 5f28 6d61 746c 6162 5f6d 6f64 656c 3d6d  _(matlab_model=m
-0001c740: 6174 6c61 625f 6d6f 6465 6c29 0d0a 2020  atlab_model)..  
-0001c750: 2020 2020 2020 7365 6c66 2e66 6e61 6d65        self.fname
-0001c760: 203d 2069 6e73 7065 6374 2e67 6574 6669   = inspect.getfi
-0001c770: 6c65 2869 6e73 7065 6374 2e63 7572 7265  le(inspect.curre
-0001c780: 6e74 6672 616d 6528 2929 0d0a 0d0a 2020  ntframe())....  
-0001c790: 2020 6465 6620 7661 6c69 6461 7465 2873    def validate(s
-0001c7a0: 656c 6629 3a0d 0a20 2020 2020 2020 2070  elf):..        p
-0001c7b0: 6173 730d 0a0d 0a20 2020 2064 6566 2073  ass....    def s
-0001c7c0: 696d 756c 6174 6528 7365 6c66 2c20 7072  imulate(self, pr
-0001c7d0: 6f63 6573 735f 6964 3d4e 6f6e 652c 206d  ocess_id=None, m
-0001c7e0: 6174 6c61 625f 656e 6769 6e65 3d4e 6f6e  atlab_engine=Non
-0001c7f0: 6529 3a0d 0a20 2020 2020 2020 2079 203d  e):..        y =
-0001c800: 2030 2e30 3336 202a 2073 656c 662e 705b   0.036 * self.p[
-0001c810: 2278 3122 5d20 2a2a 2030 2e37 3538 202a  "x1"] ** 0.758 *
-0001c820: 2073 656c 662e 705b 2278 3222 5d20 2a2a   self.p["x2"] **
-0001c830: 2030 2e30 3033 3520 2a20 5c0d 0a20 2020   0.0035 * \..   
-0001c840: 2020 2020 2020 2020 2020 2873 656c 662e            (self.
-0001c850: 705b 2278 3322 5d20 2f20 6e70 2e63 6f73  p["x3"] / np.cos
-0001c860: 2873 656c 662e 705b 2278 3422 5d29 202a  (self.p["x4"]) *
-0001c870: 2a20 3229 202a 2a20 302e 3620 2a20 5c0d  * 2) ** 0.6 * \.
-0001c880: 0a20 2020 2020 2020 2020 2020 2020 7365  .             se
-0001c890: 6c66 2e70 5b22 7835 225d 202a 2a20 302e  lf.p["x5"] ** 0.
-0001c8a0: 3030 3620 2a20 7365 6c66 2e70 5b22 7836  006 * self.p["x6
-0001c8b0: 225d 202a 2a20 302e 3034 202a 205c 0d0a  "] ** 0.04 * \..
-0001c8c0: 2020 2020 2020 2020 2020 2020 2028 3130               (10
-0001c8d0: 3020 2a20 7365 6c66 2e70 5b22 7837 225d  0 * self.p["x7"]
-0001c8e0: 202f 206e 702e 636f 7328 7365 6c66 2e70   / np.cos(self.p
-0001c8f0: 5b22 7834 225d 2929 2a2a 282d 302e 3329  ["x4"]))**(-0.3)
-0001c900: 202a 205c 0d0a 2020 2020 2020 2020 2020   * \..          
-0001c910: 2020 2028 7365 6c66 2e70 5b22 7838 225d     (self.p["x8"]
-0001c920: 202a 2073 656c 662e 705b 2278 3922 5d29   * self.p["x9"])
-0001c930: 2a2a 302e 3439 202b 2073 656c 662e 705b  **0.49 + self.p[
-0001c940: 2278 3122 5d20 2a20 7365 6c66 2e70 5b22  "x1"] * self.p["
-0001c950: 7831 3022 5d0d 0a0d 0a20 2020 2020 2020  x10"]....       
-0001c960: 2079 5f6f 7574 203d 2079 5b3a 2c20 6e70   y_out = y[:, np
-0001c970: 2e6e 6577 6178 6973 5d0d 0a0d 0a20 2020  .newaxis]....   
-0001c980: 2020 2020 2072 6574 7572 6e20 795f 6f75       return y_ou
-0001c990: 740d 0a0d 0a0d 0a63 6c61 7373 2053 7068  t......class Sph
-0001c9a0: 6572 654d 6f64 656c 2841 6273 7472 6163  ereModel(Abstrac
-0001c9b0: 744d 6f64 656c 293a 0d0a 2020 2020 2222  tModel):..    ""
-0001c9c0: 220d 0a20 2020 2043 616c 6375 6c61 7465  "..    Calculate
-0001c9d0: 7320 7468 6520 656c 6563 7472 6963 2070  s the electric p
-0001c9e0: 6f74 656e 7469 616c 2069 6e20 6120 332d  otential in a 3-
-0001c9f0: 6c61 7965 7265 6420 7370 6865 7265 2063  layered sphere c
-0001ca00: 6175 7365 6420 6279 2070 6f69 6e74 2d6c  aused by point-l
-0001ca10: 696b 6520 656c 6563 7472 6f64 6573 0d0a  ike electrodes..
-0001ca20: 2020 2020 6166 7465 7220 5275 7368 2061      after Rush a
-0001ca30: 6e64 2044 7269 7363 6f6c 6c20 2831 3936  nd Driscoll (196
-0001ca40: 3929 205b 315d 2e0d 0a0d 0a20 2020 2050  9) [1].....    P
-0001ca50: 6172 616d 6574 6572 730d 0a20 2020 202d  arameters..    -
-0001ca60: 2d2d 2d2d 2d2d 2d2d 2d0d 0a20 2020 2070  ---------..    p
-0001ca70: 5b22 7369 676d 615f 3122 5d3a 2066 6c6f  ["sigma_1"]: flo
-0001ca80: 6174 0d0a 2020 2020 2020 2020 436f 6e64  at..        Cond
-0001ca90: 7563 7469 7669 7479 206f 6620 7468 6520  uctivity of the 
-0001caa0: 696e 6e65 726d 6f73 7420 6c61 7965 722c  innermost layer,
-0001cab0: 2069 6e20 2853 2f6d 290d 0a20 2020 2070   in (S/m)..    p
-0001cac0: 5b22 7369 676d 615f 3222 5d3a 2066 6c6f  ["sigma_2"]: flo
-0001cad0: 6174 0d0a 2020 2020 2020 2020 436f 6e64  at..        Cond
-0001cae0: 7563 7469 7669 7479 206f 6620 7468 6520  uctivity of the 
-0001caf0: 696e 7465 726d 6564 6961 7465 206c 6179  intermediate lay
-0001cb00: 6572 2c20 696e 2028 532f 6d29 0d0a 2020  er, in (S/m)..  
-0001cb10: 2020 705b 2273 6967 6d61 5f33 225d 3a20    p["sigma_3"]: 
-0001cb20: 666c 6f61 740d 0a20 2020 2020 2020 2043  float..        C
-0001cb30: 6f6e 6475 6374 6976 6974 7920 6f66 2074  onductivity of t
-0001cb40: 6865 206f 7574 6572 6d6f 7374 206c 6179  he outermost lay
-0001cb50: 6572 2c20 696e 2028 532f 6d29 0d0a 2020  er, in (S/m)..  
-0001cb60: 2020 705b 2272 6164 6969 225d 3a20 6c69    p["radii"]: li
-0001cb70: 7374 205b 335d 0d0a 2020 2020 2020 2020  st [3]..        
-0001cb80: 5261 6469 7573 206f 6620 6561 6368 206f  Radius of each o
-0001cb90: 6620 7468 6520 3320 6c61 7965 7273 2028  f the 3 layers (
-0001cba0: 696e 6e65 726d 6f73 7420 746f 206f 7574  innermost to out
-0001cbb0: 6572 6d6f 7374 292c 2069 6e20 286d 6d29  ermost), in (mm)
-0001cbc0: 0d0a 2020 2020 705b 2261 6e6f 6465 5f70  ..    p["anode_p
-0001cbd0: 6f73 225d 3a20 6e64 6172 7261 7920 6f66  os"]: ndarray of
-0001cbe0: 2066 6c6f 6174 205b 3320 7820 315d 0d0a   float [3 x 1]..
-0001cbf0: 2020 2020 2020 2020 506f 7369 7469 6f6e          Position
-0001cc00: 206f 6620 7468 6520 616e 6f64 655f 706f   of the anode_po
-0001cc10: 732c 2069 6e20 286d 6d29 0d0a 2020 2020  s, in (mm)..    
-0001cc20: 705b 2263 6174 686f 6465 5f70 6f73 225d  p["cathode_pos"]
-0001cc30: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
-0001cc40: 6174 205b 3320 7820 315d 0d0a 2020 2020  at [3 x 1]..    
-0001cc50: 2020 2020 506f 7369 7469 6f6e 206f 6620      Position of 
-0001cc60: 6361 7468 6f64 655f 706f 732c 2069 6e20  cathode_pos, in 
-0001cc70: 286d 6d29 0d0a 2020 2020 705b 2270 225d  (mm)..    p["p"]
-0001cc80: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
-0001cc90: 6174 205b 4e20 7820 335d 0d0a 2020 2020  at [N x 3]..    
-0001cca0: 2020 2020 506f 7369 7469 6f6e 7320 7768      Positions wh
-0001ccb0: 6572 6520 7468 6520 706f 7465 6e74 6961  ere the potentia
-0001ccc0: 6c20 7368 6f75 6c64 2062 6520 6361 6c63  l should be calc
-0001ccd0: 756c 6174 6564 2c20 696e 2028 6d6d 290d  ulated, in (mm).
-0001cce0: 0a0d 0a20 2020 2052 6574 7572 6e73 0d0a  ...    Returns..
-0001ccf0: 2020 2020 2d2d 2d2d 2d2d 2d0d 0a20 2020      -------..   
-0001cd00: 2070 6f74 656e 7469 616c 3a20 6e64 6172   potential: ndar
-0001cd10: 7261 7920 6f66 2066 6c6f 6174 205b 3120  ray of float [1 
-0001cd20: 7820 6e5f 6f75 745d 0d0a 2020 2020 2020  x n_out]..      
-0001cd30: 2020 5661 6c75 6573 206f 6620 7468 6520    Values of the 
-0001cd40: 656c 6563 7472 6963 2070 6f74 656e 7469  electric potenti
-0001cd50: 616c 2c20 696e 2028 5629 0d0a 0d0a 2020  al, in (V)....  
-0001cd60: 2020 4e6f 7465 730d 0a20 2020 202d 2d2d    Notes..    ---
-0001cd70: 2d2d 0d0a 2020 2020 2e2e 205b 315d 2052  --..    .. [1] R
-0001cd80: 7573 682c 2053 2e2c 2026 2044 7269 7363  ush, S., & Drisc
-0001cd90: 6f6c 6c2c 2044 2e20 412e 2028 3139 3639  oll, D. A. (1969
-0001cda0: 292e 2045 4547 2065 6c65 6374 726f 6465  ). EEG electrode
-0001cdb0: 2073 656e 7369 7469 7669 7479 2d61 6e20   sensitivity-an 
-0001cdc0: 6170 706c 6963 6174 696f 6e20 6f66 2072  application of r
-0001cdd0: 6563 6970 726f 6369 7479 2e0d 0a20 2020  eciprocity...   
-0001cde0: 2020 2020 4945 4545 2074 7261 6e73 6163      IEEE transac
-0001cdf0: 7469 6f6e 7320 6f6e 2062 696f 6d65 6469  tions on biomedi
-0001ce00: 6361 6c20 656e 6769 6e65 6572 696e 672c  cal engineering,
-0001ce10: 2028 3129 2c20 3135 2d32 322e 0d0a 2020   (1), 15-22...  
-0001ce20: 2020 2222 220d 0a20 2020 2064 6566 205f    """..    def _
-0001ce30: 5f69 6e69 745f 5f28 7365 6c66 2c20 6d61  _init__(self, ma
-0001ce40: 746c 6162 5f6d 6f64 656c 3d46 616c 7365  tlab_model=False
-0001ce50: 293a 0d0a 2020 2020 2020 2020 7375 7065  ):..        supe
-0001ce60: 7228 7479 7065 2873 656c 6629 2c20 7365  r(type(self), se
-0001ce70: 6c66 292e 5f5f 696e 6974 5f5f 286d 6174  lf).__init__(mat
-0001ce80: 6c61 625f 6d6f 6465 6c3d 6d61 746c 6162  lab_model=matlab
-0001ce90: 5f6d 6f64 656c 290d 0a20 2020 2020 2020  _model)..       
-0001cea0: 2073 656c 662e 666e 616d 6520 3d20 696e   self.fname = in
-0001ceb0: 7370 6563 742e 6765 7466 696c 6528 696e  spect.getfile(in
-0001cec0: 7370 6563 742e 6375 7272 656e 7466 7261  spect.currentfra
-0001ced0: 6d65 2829 290d 0a20 2020 2020 2020 2073  me())..        s
-0001cee0: 656c 662e 6e62 725f 706f 6c79 6e6f 6d69  elf.nbr_polynomi
-0001cef0: 616c 7320 3d20 3530 0d0a 0d0a 2020 2020  als = 50....    
-0001cf00: 6465 6620 7661 6c69 6461 7465 2873 656c  def validate(sel
-0001cf10: 6629 3a0d 0a20 2020 2020 2020 2070 6173  f):..        pas
-0001cf20: 730d 0a0d 0a20 2020 2064 6566 2073 696d  s....    def sim
-0001cf30: 756c 6174 6528 7365 6c66 2c20 7072 6f63  ulate(self, proc
-0001cf40: 6573 735f 6964 3d4e 6f6e 652c 206d 6174  ess_id=None, mat
-0001cf50: 6c61 625f 656e 6769 6e65 3d4e 6f6e 6529  lab_engine=None)
-0001cf60: 3a0d 0a0d 0a20 2020 2020 2020 2061 7373  :....        ass
-0001cf70: 6572 7420 6c65 6e28 7365 6c66 2e70 5b22  ert len(self.p["
-0001cf80: 5222 5d29 203d 3d20 330d 0a20 2020 2020  R"]) == 3..     
-0001cf90: 2020 2061 7373 6572 7420 7365 6c66 2e70     assert self.p
-0001cfa0: 5b22 5222 5d5b 305d 203c 2073 656c 662e  ["R"][0] < self.
-0001cfb0: 705b 2252 225d 5b31 5d20 3c20 7365 6c66  p["R"][1] < self
-0001cfc0: 2e70 5b22 5222 5d5b 325d 0d0a 2020 2020  .p["R"][2]..    
-0001cfd0: 2020 2020 6173 7365 7274 206c 656e 2873      assert len(s
-0001cfe0: 656c 662e 705b 2261 6e6f 6465 5f70 6f73  elf.p["anode_pos
-0001cff0: 225d 2920 3d3d 2033 0d0a 2020 2020 2020  "]) == 3..      
-0001d000: 2020 6173 7365 7274 206c 656e 2873 656c    assert len(sel
-0001d010: 662e 705b 2263 6174 686f 6465 5f70 6f73  f.p["cathode_pos
-0001d020: 225d 2920 3d3d 2033 0d0a 2020 2020 2020  "]) == 3..      
-0001d030: 2020 6173 7365 7274 2073 656c 662e 705b    assert self.p[
-0001d040: 2270 6f69 6e74 7322 5d2e 7368 6170 655b  "points"].shape[
-0001d050: 315d 203d 3d20 330d 0a0d 0a20 2020 2020  1] == 3....     
-0001d060: 2020 2062 5f6f 7665 725f 7320 3d20 666c     b_over_s = fl
-0001d070: 6f61 7428 7365 6c66 2e70 5b22 7369 676d  oat(self.p["sigm
-0001d080: 615f 3122 5d29 202f 2066 6c6f 6174 2873  a_1"]) / float(s
-0001d090: 656c 662e 705b 2273 6967 6d61 5f32 225d  elf.p["sigma_2"]
-0001d0a0: 290d 0a20 2020 2020 2020 2073 5f6f 7665  )..        s_ove
-0001d0b0: 725f 7420 3d20 666c 6f61 7428 7365 6c66  r_t = float(self
-0001d0c0: 2e70 5b22 7369 676d 615f 3222 5d29 202f  .p["sigma_2"]) /
-0001d0d0: 2066 6c6f 6174 2873 656c 662e 705b 2273   float(self.p["s
-0001d0e0: 6967 6d61 5f33 225d 290d 0a20 2020 2020  igma_3"])..     
-0001d0f0: 2020 2072 6164 6975 735f 6272 6169 6e20     radius_brain 
-0001d100: 3d20 7365 6c66 2e70 5b22 5222 5d5b 305d  = self.p["R"][0]
-0001d110: 202a 2031 652d 330d 0a20 2020 2020 2020   * 1e-3..       
-0001d120: 2072 6164 6975 735f 736b 756c 6c20 3d20   radius_skull = 
-0001d130: 7365 6c66 2e70 5b22 5222 5d5b 315d 202a  self.p["R"][1] *
-0001d140: 2031 652d 330d 0a20 2020 2020 2020 2072   1e-3..        r
-0001d150: 6164 6975 735f 736b 696e 203d 2073 656c  adius_skin = sel
-0001d160: 662e 705b 2252 225d 5b32 5d20 2a20 3165  f.p["R"][2] * 1e
-0001d170: 2d33 0d0a 0d0a 2020 2020 2020 2020 7220  -3....        r 
-0001d180: 3d20 6e70 2e6c 696e 616c 672e 6e6f 726d  = np.linalg.norm
-0001d190: 2873 656c 662e 705b 2270 6f69 6e74 7322  (self.p["points"
-0001d1a0: 5d2c 2061 7869 733d 3129 202a 2031 652d  ], axis=1) * 1e-
-0001d1b0: 330d 0a20 2020 2020 2020 2074 6865 7461  3..        theta
-0001d1c0: 203d 206e 702e 6172 6363 6f73 2873 656c   = np.arccos(sel
-0001d1d0: 662e 705b 2270 6f69 6e74 7322 5d5b 3a2c  f.p["points"][:,
-0001d1e0: 2032 5d20 2a20 3165 2d33 202f 2072 290d   2] * 1e-3 / r).
-0001d1f0: 0a20 2020 2020 2020 2070 6869 203d 206e  .        phi = n
-0001d200: 702e 6172 6374 616e 3228 7365 6c66 2e70  p.arctan2(self.p
-0001d210: 5b22 706f 696e 7473 225d 5b3a 2c20 315d  ["points"][:, 1]
-0001d220: 2c20 7365 6c66 2e70 5b22 706f 696e 7473  , self.p["points
-0001d230: 225d 5b3a 2c20 305d 290d 0a0d 0a20 2020  "][:, 0])....   
-0001d240: 2020 2020 2070 5f72 203d 206e 702e 7673       p_r = np.vs
-0001d250: 7461 636b 2828 722c 2074 6865 7461 2c20  tack((r, theta, 
-0001d260: 7068 6929 292e 540d 0a0d 0a20 2020 2020  phi)).T....     
-0001d270: 2020 2063 6174 686f 6465 5f70 6f73 203d     cathode_pos =
-0001d280: 2028 6e70 2e73 7172 7428 7365 6c66 2e70   (np.sqrt(self.p
-0001d290: 5b22 6361 7468 6f64 655f 706f 7322 5d5b  ["cathode_pos"][
-0001d2a0: 305d 202a 2a20 3220 2b0d 0a20 2020 2020  0] ** 2 +..     
-0001d2b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d2c0: 2020 2020 2020 2020 2020 7365 6c66 2e70            self.p
-0001d2d0: 5b22 6361 7468 6f64 655f 706f 7322 5d5b  ["cathode_pos"][
-0001d2e0: 315d 202a 2a20 3220 2b0d 0a20 2020 2020  1] ** 2 +..     
-0001d2f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d300: 2020 2020 2020 2020 2020 7365 6c66 2e70            self.p
-0001d310: 5b22 6361 7468 6f64 655f 706f 7322 5d5b  ["cathode_pos"][
-0001d320: 325d 202a 2a20 3229 202a 2031 652d 332c  2] ** 2) * 1e-3,
-0001d330: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0001d340: 2020 2020 2020 2020 206e 702e 6172 6363           np.arcc
-0001d350: 6f73 2873 656c 662e 705b 2263 6174 686f  os(self.p["catho
-0001d360: 6465 5f70 6f73 225d 5b32 5d20 2f0d 0a20  de_pos"][2] /.. 
-0001d370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d380: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d390: 6e70 2e73 7172 7428 7365 6c66 2e70 5b22  np.sqrt(self.p["
-0001d3a0: 6361 7468 6f64 655f 706f 7322 5d5b 305d  cathode_pos"][0]
-0001d3b0: 202a 2a20 3220 2b0d 0a20 2020 2020 2020   ** 2 +..       
+000106b0: 700a 2020 2020 2020 2066 726f 6d20 7079  p.       from py
+000106c0: 6770 632e 7465 7374 6675 6e63 7469 6f6e  gpc.testfunction
+000106d0: 7320 696d 706f 7274 2070 6c6f 745f 7465  s import plot_te
+000106e0: 7374 6675 6e63 7469 6f6e 2061 7320 706c  stfunction as pl
+000106f0: 6f74 0a20 2020 2020 2020 6672 6f6d 2063  ot.       from c
+00010700: 6f6c 6c65 6374 696f 6e73 2069 6d70 6f72  ollections impor
+00010710: 7420 4f72 6465 7265 6444 6963 740a 0a20  t OrderedDict.. 
+00010720: 2020 2020 2020 7061 7261 6d65 7465 7273        parameters
+00010730: 203d 204f 7264 6572 6564 4469 6374 2829   = OrderedDict()
+00010740: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
+00010750: 7273 5b22 7831 225d 203d 206e 702e 6c69  rs["x1"] = np.li
+00010760: 6e73 7061 6365 2830 2c20 312c 2031 3030  nspace(0, 1, 100
+00010770: 290a 2020 2020 2020 2070 6172 616d 6574  ).       paramet
+00010780: 6572 735b 2278 3222 5d20 3d20 6e70 2e6c  ers["x2"] = np.l
+00010790: 696e 7370 6163 6528 302c 2031 2c20 3130  inspace(0, 1, 10
+000107a0: 3029 0a0a 2020 2020 2020 2070 6c6f 7428  0)..       plot(
+000107b0: 224d 616e 7566 6163 7475 7265 4465 6361  "ManufactureDeca
+000107c0: 7922 2c20 7061 7261 6d65 7465 7273 290a  y", parameters).
+000107d0: 0a20 2020 202e 2e20 5b31 5d20 4861 6d70  .    .. [1] Hamp
+000107e0: 746f 6e2c 204a 2e2c 2044 6f6f 7374 616e  ton, J., Doostan
+000107f0: 2c20 412e 2c20 2832 3031 3829 2c20 4261  , A., (2018), Ba
+00010800: 7369 7320 6164 6170 7469 7665 2073 616d  sis adaptive sam
+00010810: 706c 6520 6566 6669 6369 656e 7420 706f  ple efficient po
+00010820: 6c79 6e6f 6d69 616c 2063 6861 6f73 2028  lynomial chaos (
+00010830: 4241 5345 2d50 4329 2c0a 2020 2020 2020  BASE-PC),.      
+00010840: 204a 6f75 726e 616c 206f 6620 436f 6d70   Journal of Comp
+00010850: 7574 6174 696f 6e61 6c20 5068 7973 6963  utational Physic
+00010860: 732c 2033 3731 2c20 3230 2d34 392e 0a20  s, 371, 20-49.. 
+00010870: 2020 2022 2222 0a0a 2020 2020 6465 6620     """..    def 
+00010880: 5f5f 696e 6974 5f5f 2873 656c 662c 206d  __init__(self, m
+00010890: 6174 6c61 625f 6d6f 6465 6c3d 4661 6c73  atlab_model=Fals
+000108a0: 6529 3a0a 2020 2020 2020 2020 7375 7065  e):.        supe
+000108b0: 7228 7479 7065 2873 656c 6629 2c20 7365  r(type(self), se
+000108c0: 6c66 292e 5f5f 696e 6974 5f5f 286d 6174  lf).__init__(mat
+000108d0: 6c61 625f 6d6f 6465 6c3d 6d61 746c 6162  lab_model=matlab
+000108e0: 5f6d 6f64 656c 290a 2020 2020 2020 2020  _model).        
+000108f0: 7365 6c66 2e66 6e61 6d65 203d 2069 6e73  self.fname = ins
+00010900: 7065 6374 2e67 6574 6669 6c65 2869 6e73  pect.getfile(ins
+00010910: 7065 6374 2e63 7572 7265 6e74 6672 616d  pect.currentfram
+00010920: 6528 2929 0a0a 2020 2020 6465 6620 7661  e())..    def va
+00010930: 6c69 6461 7465 2873 656c 6629 3a0a 2020  lidate(self):.  
+00010940: 2020 2020 2020 7061 7373 0a0a 2020 2020        pass..    
+00010950: 6465 6620 7369 6d75 6c61 7465 2873 656c  def simulate(sel
+00010960: 662c 2070 726f 6365 7373 5f69 643d 4e6f  f, process_id=No
+00010970: 6e65 2c20 6d61 746c 6162 5f65 6e67 696e  ne, matlab_engin
+00010980: 653d 4e6f 6e65 293a 0a20 2020 2020 2020  e=None):.       
+00010990: 2023 2064 6574 6572 6d69 6e65 2073 756d   # determine sum
+000109a0: 2069 6e20 6578 706f 6e65 6e74 0a20 2020   in exponent.   
+000109b0: 2020 2020 2073 203d 206e 702e 7a65 726f       s = np.zero
+000109c0: 7328 6e70 2e61 7272 6179 2873 656c 662e  s(np.array(self.
+000109d0: 705b 6c69 7374 2873 656c 662e 702e 6b65  p[list(self.p.ke
+000109e0: 7973 2829 295b 305d 5d29 2e73 697a 6529  ys())[0]]).size)
+000109f0: 0a0a 2020 2020 2020 2020 666f 7220 692c  ..        for i,
+00010a00: 206b 6579 2069 6e20 656e 756d 6572 6174   key in enumerat
+00010a10: 6528 7365 6c66 2e70 2e6b 6579 7328 2929  e(self.p.keys())
+00010a20: 3a0a 2020 2020 2020 2020 2020 2020 7320  :.            s 
+00010a30: 2b3d 206e 702e 7369 6e28 6920 2b20 3129  += np.sin(i + 1)
+00010a40: 202a 2073 656c 662e 705b 6b65 795d 202f   * self.p[key] /
+00010a50: 2028 6920 2b20 312e 290a 0a20 2020 2020   (i + 1.)..     
+00010a60: 2020 2023 2064 6574 6572 6d69 6e65 206f     # determine o
+00010a70: 7574 7075 740a 2020 2020 2020 2020 7920  utput.        y 
+00010a80: 3d20 6e70 2e65 7870 2832 202d 2073 290a  = np.exp(2 - s).
+00010a90: 0a20 2020 2020 2020 2079 5f6f 7574 203d  .        y_out =
+00010aa0: 2079 5b3a 2c20 6e70 2e6e 6577 6178 6973   y[:, np.newaxis
+00010ab0: 5d0a 0a20 2020 2020 2020 2072 6574 7572  ]..        retur
+00010ac0: 6e20 795f 6f75 740a 0a0a 636c 6173 7320  n y_out...class 
+00010ad0: 4765 6e7a 436f 6e74 696e 756f 7573 2841  GenzContinuous(A
+00010ae0: 6273 7472 6163 744d 6f64 656c 293a 0a20  bstractModel):. 
+00010af0: 2020 2022 2222 0a20 2020 204e 2d64 696d     """.    N-dim
+00010b00: 656e 7369 6f6e 616c 2022 636f 6e74 696e  ensional "contin
+00010b10: 756f 7573 2220 4765 6e7a 2066 756e 6374  uous" Genz funct
+00010b20: 696f 6e20 5b31 5d2e 2049 7420 6973 2064  ion [1]. It is d
+00010b30: 6566 696e 6564 2069 6e20 7468 6520 696e  efined in the in
+00010b40: 7465 7276 616c 205b 302c 2031 5d20 7820  terval [0, 1] x 
+00010b50: 2e2e 2e20 7820 5b30 2c20 315d 2e0a 0a20  ... x [0, 1]... 
+00010b60: 2020 202e 2e20 6d61 7468 3a3a 2020 7920     .. math::  y 
+00010b70: 3d20 5c5c 6578 707b 5c5c 6c65 6674 282d  = \\exp{\\left(-
+00010b80: 205c 7375 6d5f 7b69 3d31 7d5e 7b4e 7d20   \sum_{i=1}^{N} 
+00010b90: 615f 6920 7c20 785f 6920 2d20 755f 6920  a_i | x_i - u_i 
+00010ba0: 7c20 5c5c 7269 6768 7429 7d0a 0a20 2020  | \\right)}..   
+00010bb0: 2050 6172 616d 6574 6572 730a 2020 2020   Parameters.    
+00010bc0: 2d2d 2d2d 2d2d 2d2d 2d2d 0a20 2020 2070  ----------.    p
+00010bd0: 5b22 7831 225d 3a20 666c 6f61 7420 6f72  ["x1"]: float or
+00010be0: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
+00010bf0: 7420 5b6e 5f67 7269 645d 0a20 2020 2020  t [n_grid].     
+00010c00: 2020 2046 6972 7374 2070 6172 616d 6574     First paramet
+00010c10: 6572 2064 6566 696e 6564 2069 6e20 5b30  er defined in [0
+00010c20: 2c20 315d 0a20 2020 2070 5b22 7869 225d  , 1].    p["xi"]
+00010c30: 3a20 666c 6f61 7420 6f72 206e 6461 7272  : float or ndarr
+00010c40: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
+00010c50: 7269 645d 0a20 2020 2020 2020 2069 2d74  rid].        i-t
+00010c60: 6820 7061 7261 6d65 7465 7220 6465 6669  h parameter defi
+00010c70: 6e65 6420 696e 205b 302c 2031 5d0a 2020  ned in [0, 1].  
+00010c80: 2020 705b 2278 4e22 5d3a 2066 6c6f 6174    p["xN"]: float
+00010c90: 206f 7220 6e64 6172 7261 7920 6f66 2066   or ndarray of f
+00010ca0: 6c6f 6174 205b 6e5f 6772 6964 5d0a 2020  loat [n_grid].  
+00010cb0: 2020 2020 2020 4e74 6820 7061 7261 6d65        Nth parame
+00010cc0: 7465 7220 6465 6669 6e65 6420 696e 205b  ter defined in [
+00010cd0: 302c 2031 5d0a 0a20 2020 2052 6574 7572  0, 1]..    Retur
+00010ce0: 6e73 0a20 2020 202d 2d2d 2d2d 2d2d 0a20  ns.    -------. 
+00010cf0: 2020 2079 3a20 6e64 6172 7261 7920 6f66     y: ndarray of
+00010d00: 2066 6c6f 6174 205b 6e5f 6772 6964 2078   float [n_grid x
+00010d10: 2031 5d0a 2020 2020 2020 2020 4f75 7470   1].        Outp
+00010d20: 7574 0a0a 2020 2020 4e6f 7465 730a 2020  ut..    Notes.  
+00010d30: 2020 2d2d 2d2d 2d0a 2020 2020 2e2e 2070    -----.    .. p
+00010d40: 6c6f 743a 3a0a 0a20 2020 2020 2020 696d  lot::..       im
+00010d50: 706f 7274 206e 756d 7079 2061 7320 6e70  port numpy as np
+00010d60: 0a20 2020 2020 2020 6672 6f6d 2070 7967  .       from pyg
+00010d70: 7063 2e74 6573 7466 756e 6374 696f 6e73  pc.testfunctions
+00010d80: 2069 6d70 6f72 7420 706c 6f74 5f74 6573   import plot_tes
+00010d90: 7466 756e 6374 696f 6e20 6173 2070 6c6f  tfunction as plo
+00010da0: 740a 2020 2020 2020 2066 726f 6d20 636f  t.       from co
+00010db0: 6c6c 6563 7469 6f6e 7320 696d 706f 7274  llections import
+00010dc0: 204f 7264 6572 6564 4469 6374 0a0a 2020   OrderedDict..  
+00010dd0: 2020 2020 2070 6172 616d 6574 6572 7320       parameters 
+00010de0: 3d20 4f72 6465 7265 6444 6963 7428 290a  = OrderedDict().
+00010df0: 2020 2020 2020 2070 6172 616d 6574 6572         parameter
+00010e00: 735b 2278 3122 5d20 3d20 6e70 2e6c 696e  s["x1"] = np.lin
+00010e10: 7370 6163 6528 302c 2031 2c20 3130 3029  space(0, 1, 100)
+00010e20: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
+00010e30: 7273 5b22 7832 225d 203d 206e 702e 6c69  rs["x2"] = np.li
+00010e40: 6e73 7061 6365 2830 2c20 312c 2031 3030  nspace(0, 1, 100
+00010e50: 290a 0a20 2020 2020 2020 706c 6f74 2822  )..       plot("
+00010e60: 4765 6e7a 436f 6e74 696e 756f 7573 222c  GenzContinuous",
+00010e70: 2070 6172 616d 6574 6572 7329 0a0a 2020   parameters)..  
+00010e80: 2020 2e2e 205b 315d 2047 656e 7a2c 2041    .. [1] Genz, A
+00010e90: 2e20 2831 3938 3429 2c20 5465 7374 696e  . (1984), Testin
+00010ea0: 6720 6d75 6c74 6964 696d 656e 7369 6f6e  g multidimension
+00010eb0: 616c 2069 6e74 6567 7261 7469 6f6e 2072  al integration r
+00010ec0: 6f75 7469 6e65 732e 0a20 2020 2020 2020  outines..       
+00010ed0: 5072 6f63 2e20 6f66 2069 6e74 6572 6e61  Proc. of interna
+00010ee0: 7469 6f6e 616c 2063 6f6e 6665 7265 6e63  tional conferenc
+00010ef0: 6520 6f6e 2054 6f6f 6c73 2c20 6d65 7468  e on Tools, meth
+00010f00: 6f64 7320 616e 6420 6c61 6e67 7561 6765  ods and language
+00010f10: 7320 666f 7220 7363 6965 6e74 6966 6963  s for scientific
+00010f20: 0a20 2020 2020 2020 616e 6420 656e 6769  .       and engi
+00010f30: 6e65 6572 696e 6720 636f 6d70 7574 6174  neering computat
+00010f40: 696f 6e2c 2045 6c73 6576 6965 7220 4e6f  ion, Elsevier No
+00010f50: 7274 682d 486f 6c6c 616e 642c 2049 6e63  rth-Holland, Inc
+00010f60: 2e2c 204e 6577 596f 726b 2c20 4e59 2c20  ., NewYork, NY, 
+00010f70: 5553 412c 2070 702e 2038 312d 3934 2e0a  USA, pp. 81-94..
+00010f80: 0a20 2020 202e 2e20 5b32 5d20 6874 7470  .    .. [2] http
+00010f90: 733a 2f2f 7777 772e 7366 752e 6361 2f7e  s://www.sfu.ca/~
+00010fa0: 7373 7572 6a61 6e6f 2f63 6f6e 742e 6874  ssurjano/cont.ht
+00010fb0: 6d6c 0a20 2020 2022 2222 0a0a 2020 2020  ml.    """..    
+00010fc0: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
+00010fd0: 662c 206d 6174 6c61 625f 6d6f 6465 6c3d  f, matlab_model=
+00010fe0: 4661 6c73 6529 3a0a 2020 2020 2020 2020  False):.        
+00010ff0: 7375 7065 7228 7479 7065 2873 656c 6629  super(type(self)
+00011000: 2c20 7365 6c66 292e 5f5f 696e 6974 5f5f  , self).__init__
+00011010: 286d 6174 6c61 625f 6d6f 6465 6c3d 6d61  (matlab_model=ma
+00011020: 746c 6162 5f6d 6f64 656c 290a 2020 2020  tlab_model).    
+00011030: 2020 2020 7365 6c66 2e66 6e61 6d65 203d      self.fname =
+00011040: 2069 6e73 7065 6374 2e67 6574 6669 6c65   inspect.getfile
+00011050: 2869 6e73 7065 6374 2e63 7572 7265 6e74  (inspect.current
+00011060: 6672 616d 6528 2929 0a0a 2020 2020 6465  frame())..    de
+00011070: 6620 7661 6c69 6461 7465 2873 656c 6629  f validate(self)
+00011080: 3a0a 2020 2020 2020 2020 7061 7373 0a0a  :.        pass..
+00011090: 2020 2020 6465 6620 7369 6d75 6c61 7465      def simulate
+000110a0: 2873 656c 662c 2070 726f 6365 7373 5f69  (self, process_i
+000110b0: 643d 4e6f 6e65 2c20 6d61 746c 6162 5f65  d=None, matlab_e
+000110c0: 6e67 696e 653d 4e6f 6e65 293a 0a20 2020  ngine=None):.   
+000110d0: 2020 2020 206e 203d 206c 656e 2873 656c       n = len(sel
+000110e0: 662e 702e 6b65 7973 2829 290a 0a20 2020  f.p.keys())..   
+000110f0: 2020 2020 2023 2073 6574 2063 6f6e 7374       # set const
+00011100: 616e 7473 0a20 2020 2020 2020 2075 203d  ants.        u =
+00011110: 2030 2e35 202a 206e 702e 6f6e 6573 286e   0.5 * np.ones(n
+00011120: 290a 2020 2020 2020 2020 6120 3d20 3520  ).        a = 5 
+00011130: 2a20 6e70 2e6f 6e65 7328 6e29 0a0a 2020  * np.ones(n)..  
+00011140: 2020 2020 2020 2320 6465 7465 726d 696e        # determin
+00011150: 6520 7375 6d20 696e 2065 7870 6f6e 656e  e sum in exponen
+00011160: 740a 2020 2020 2020 2020 7320 3d20 6e70  t.        s = np
+00011170: 2e7a 6572 6f73 286e 702e 6172 7261 7928  .zeros(np.array(
+00011180: 7365 6c66 2e70 5b6c 6973 7428 7365 6c66  self.p[list(self
+00011190: 2e70 2e6b 6579 7328 2929 5b30 5d5d 292e  .p.keys())[0]]).
+000111a0: 7369 7a65 290a 0a20 2020 2020 2020 2066  size)..        f
+000111b0: 6f72 2069 2c20 6b65 7920 696e 2065 6e75  or i, key in enu
+000111c0: 6d65 7261 7465 2873 656c 662e 702e 6b65  merate(self.p.ke
+000111d0: 7973 2829 293a 0a20 2020 2020 2020 2020  ys()):.         
+000111e0: 2020 2073 202b 3d20 615b 695d 202a 206e     s += a[i] * n
+000111f0: 702e 6162 7328 7365 6c66 2e70 5b6b 6579  p.abs(self.p[key
+00011200: 5d20 2d20 755b 695d 290a 0a20 2020 2020  ] - u[i])..     
+00011210: 2020 2023 2064 6574 6572 6d69 6e65 206f     # determine o
+00011220: 7574 7075 740a 2020 2020 2020 2020 7920  utput.        y 
+00011230: 3d20 6e70 2e65 7870 282d 7329 0a0a 2020  = np.exp(-s)..  
+00011240: 2020 2020 2020 795f 6f75 7420 3d20 795b        y_out = y[
+00011250: 3a2c 206e 702e 6e65 7761 7869 735d 0a0a  :, np.newaxis]..
+00011260: 2020 2020 2020 2020 7265 7475 726e 2079          return y
+00011270: 5f6f 7574 0a0a 0a63 6c61 7373 2047 656e  _out...class Gen
+00011280: 7a43 6f72 6e65 7250 6561 6b28 4162 7374  zCornerPeak(Abst
+00011290: 7261 6374 4d6f 6465 6c29 3a0a 2020 2020  ractModel):.    
+000112a0: 2222 220a 2020 2020 4e2d 6469 6d65 6e73  """.    N-dimens
+000112b0: 696f 6e61 6c20 2243 6f72 6e65 7250 6561  ional "CornerPea
+000112c0: 6b22 2047 656e 7a20 6675 6e63 7469 6f6e  k" Genz function
+000112d0: 205b 312c 325d 2e20 4974 2069 7320 6465   [1,2]. It is de
+000112e0: 6669 6e65 6420 696e 2074 6865 2069 6e74  fined in the int
+000112f0: 6572 7661 6c20 5b30 2c20 315d 2078 202e  erval [0, 1] x .
+00011300: 2e2e 2078 205b 302c 2031 5d2e 0a20 2020  .. x [0, 1]..   
+00011310: 2055 7365 6420 6279 205b 335d 2061 7320   Used by [3] as 
+00011320: 7465 7374 6675 6e63 7469 6f6e 2e0a 0a20  testfunction... 
+00011330: 2020 202e 2e20 6d61 7468 3a3a 2079 203d     .. math:: y =
+00011340: 205c 5c6c 6566 7428 2031 202b 205c 7375   \\left( 1 + \su
+00011350: 6d5f 7b69 3d31 7d5e 4e20 615f 6920 785f  m_{i=1}^N a_i x_
+00011360: 695c 5c72 6967 6874 295e 7b2d 284e 202b  i\\right)^{-(N +
+00011370: 2031 297d 0a0a 2020 2020 5061 7261 6d65   1)}..    Parame
+00011380: 7465 7273 0a20 2020 202d 2d2d 2d2d 2d2d  ters.    -------
+00011390: 2d2d 2d0a 2020 2020 705b 2278 3122 5d3a  ---.    p["x1"]:
+000113a0: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
+000113b0: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
+000113c0: 6964 5d0a 2020 2020 2020 2020 4669 7273  id].        Firs
+000113d0: 7420 7061 7261 6d65 7465 7220 6465 6669  t parameter defi
+000113e0: 6e65 6420 696e 205b 302c 2031 5d0a 2020  ned in [0, 1].  
+000113f0: 2020 705b 2278 6922 5d3a 2066 6c6f 6174    p["xi"]: float
+00011400: 206f 7220 6e64 6172 7261 7920 6f66 2066   or ndarray of f
+00011410: 6c6f 6174 205b 6e5f 6772 6964 5d0a 2020  loat [n_grid].  
+00011420: 2020 2020 2020 692d 7468 2070 6172 616d        i-th param
+00011430: 6574 6572 2064 6566 696e 6564 2069 6e20  eter defined in 
+00011440: 5b30 2c20 315d 0a20 2020 2070 5b22 784e  [0, 1].    p["xN
+00011450: 225d 3a20 666c 6f61 7420 6f72 206e 6461  "]: float or nda
+00011460: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
+00011470: 5f67 7269 645d 0a20 2020 2020 2020 204e  _grid].        N
+00011480: 7468 2070 6172 616d 6574 6572 2064 6566  th parameter def
+00011490: 696e 6564 2069 6e20 5b30 2c20 315d 0a0a  ined in [0, 1]..
+000114a0: 2020 2020 5265 7475 726e 730a 2020 2020      Returns.    
+000114b0: 2d2d 2d2d 2d2d 2d0a 2020 2020 793a 206e  -------.    y: n
+000114c0: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+000114d0: 5b6e 5f67 7269 6420 7820 315d 0a20 2020  [n_grid x 1].   
+000114e0: 2020 2020 204f 7574 7075 740a 0a20 2020       Output..   
+000114f0: 204e 6f74 6573 0a20 2020 202d 2d2d 2d2d   Notes.    -----
+00011500: 0a20 2020 202e 2e20 706c 6f74 3a3a 0a0a  .    .. plot::..
+00011510: 2020 2020 2020 2069 6d70 6f72 7420 6e75         import nu
+00011520: 6d70 7920 6173 206e 700a 2020 2020 2020  mpy as np.      
+00011530: 2066 726f 6d20 7079 6770 632e 7465 7374   from pygpc.test
+00011540: 6675 6e63 7469 6f6e 7320 696d 706f 7274  functions import
+00011550: 2070 6c6f 745f 7465 7374 6675 6e63 7469   plot_testfuncti
+00011560: 6f6e 2061 7320 706c 6f74 0a20 2020 2020  on as plot.     
+00011570: 2020 6672 6f6d 2063 6f6c 6c65 6374 696f    from collectio
+00011580: 6e73 2069 6d70 6f72 7420 4f72 6465 7265  ns import Ordere
+00011590: 6444 6963 740a 0a20 2020 2020 2020 7061  dDict..       pa
+000115a0: 7261 6d65 7465 7273 203d 204f 7264 6572  rameters = Order
+000115b0: 6564 4469 6374 2829 0a20 2020 2020 2020  edDict().       
+000115c0: 7061 7261 6d65 7465 7273 5b22 7831 225d  parameters["x1"]
+000115d0: 203d 206e 702e 6c69 6e73 7061 6365 2830   = np.linspace(0
+000115e0: 2c20 312c 2031 3030 290a 2020 2020 2020  , 1, 100).      
+000115f0: 2070 6172 616d 6574 6572 735b 2278 3222   parameters["x2"
+00011600: 5d20 3d20 6e70 2e6c 696e 7370 6163 6528  ] = np.linspace(
+00011610: 302c 2031 2c20 3130 3029 0a0a 2020 2020  0, 1, 100)..    
+00011620: 2020 2070 6c6f 7428 2247 656e 7a43 6f72     plot("GenzCor
+00011630: 6e65 7250 6561 6b22 2c20 7061 7261 6d65  nerPeak", parame
+00011640: 7465 7273 290a 0a20 2020 202e 2e20 5b31  ters)..    .. [1
+00011650: 5d20 4765 6e7a 2c20 412e 2028 3139 3834  ] Genz, A. (1984
+00011660: 292c 2054 6573 7469 6e67 206d 756c 7469  ), Testing multi
+00011670: 6469 6d65 6e73 696f 6e61 6c20 696e 7465  dimensional inte
+00011680: 6772 6174 696f 6e20 726f 7574 696e 6573  gration routines
+00011690: 2e0a 2020 2020 2020 2050 726f 632e 206f  ..       Proc. o
+000116a0: 6620 696e 7465 726e 6174 696f 6e61 6c20  f international 
+000116b0: 636f 6e66 6572 656e 6365 206f 6e20 546f  conference on To
+000116c0: 6f6c 732c 206d 6574 686f 6473 2061 6e64  ols, methods and
+000116d0: 206c 616e 6775 6167 6573 2066 6f72 2073   languages for s
+000116e0: 6369 656e 7469 6669 630a 2020 2020 2020  cientific.      
+000116f0: 2061 6e64 2065 6e67 696e 6565 7269 6e67   and engineering
+00011700: 2063 6f6d 7075 7461 7469 6f6e 2c20 456c   computation, El
+00011710: 7365 7669 6572 204e 6f72 7468 2d48 6f6c  sevier North-Hol
+00011720: 6c61 6e64 2c20 496e 632e 2c20 4e65 7759  land, Inc., NewY
+00011730: 6f72 6b2c 204e 592c 2055 5341 2c20 7070  ork, NY, USA, pp
+00011740: 2e20 3831 2d39 342e 0a0a 2020 2020 2e2e  . 81-94...    ..
+00011750: 205b 325d 2068 7474 7073 3a2f 2f77 7777   [2] https://www
+00011760: 2e73 6675 2e63 612f 7e73 7375 726a 616e  .sfu.ca/~ssurjan
+00011770: 6f2f 636f 7065 616b 2e68 746d 6c0a 0a20  o/copeak.html.. 
+00011780: 2020 202e 2e20 5b33 5d20 4a61 6b65 6d61     .. [3] Jakema
+00011790: 6e2c 204a 2e20 442e 2c20 456c 6472 6564  n, J. D., Eldred
+000117a0: 2c20 4d2e 2053 2e2c 2026 2053 6172 6773  , M. S., & Sargs
+000117b0: 7961 6e2c 204b 2e20 2832 3031 3529 2e0a  yan, K. (2015)..
+000117c0: 2020 2020 2020 2045 6e68 616e 6369 6e67         Enhancing
+000117d0: 20e2 8493 312d 6d69 6e69 6d69 7a61 7469   ...1-minimizati
+000117e0: 6f6e 2065 7374 696d 6174 6573 206f 6620  on estimates of 
+000117f0: 706f 6c79 6e6f 6d69 616c 2063 6861 6f73  polynomial chaos
+00011800: 2065 7870 616e 7369 6f6e 7320 7573 696e   expansions usin
+00011810: 6720 6261 7369 7320 7365 6c65 6374 696f  g basis selectio
+00011820: 6e2e 0a20 2020 2020 2020 4a6f 7572 6e61  n..       Journa
+00011830: 6c20 6f66 2043 6f6d 7075 7461 7469 6f6e  l of Computation
+00011840: 616c 2050 6879 7369 6373 2c20 3238 392c  al Physics, 289,
+00011850: 2031 382d 3334 2e0a 2020 2020 2222 220a   18-34..    """.
+00011860: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
+00011870: 5f28 7365 6c66 2c20 6d61 746c 6162 5f6d  _(self, matlab_m
+00011880: 6f64 656c 3d46 616c 7365 293a 0a20 2020  odel=False):.   
+00011890: 2020 2020 2073 7570 6572 2874 7970 6528       super(type(
+000118a0: 7365 6c66 292c 2073 656c 6629 2e5f 5f69  self), self).__i
+000118b0: 6e69 745f 5f28 6d61 746c 6162 5f6d 6f64  nit__(matlab_mod
+000118c0: 656c 3d6d 6174 6c61 625f 6d6f 6465 6c29  el=matlab_model)
+000118d0: 0a20 2020 2020 2020 2073 656c 662e 666e  .        self.fn
+000118e0: 616d 6520 3d20 696e 7370 6563 742e 6765  ame = inspect.ge
+000118f0: 7466 696c 6528 696e 7370 6563 742e 6375  tfile(inspect.cu
+00011900: 7272 656e 7466 7261 6d65 2829 290a 0a20  rrentframe()).. 
+00011910: 2020 2064 6566 2076 616c 6964 6174 6528     def validate(
+00011920: 7365 6c66 293a 0a20 2020 2020 2020 2070  self):.        p
+00011930: 6173 730a 0a20 2020 2064 6566 2073 696d  ass..    def sim
+00011940: 756c 6174 6528 7365 6c66 2c20 7072 6f63  ulate(self, proc
+00011950: 6573 735f 6964 3d4e 6f6e 652c 206d 6174  ess_id=None, mat
+00011960: 6c61 625f 656e 6769 6e65 3d4e 6f6e 6529  lab_engine=None)
+00011970: 3a0a 2020 2020 2020 2020 6e20 3d20 6c65  :.        n = le
+00011980: 6e28 7365 6c66 2e70 2e6b 6579 7328 2929  n(self.p.keys())
+00011990: 0a0a 2020 2020 2020 2020 2320 7365 7420  ..        # set 
+000119a0: 636f 6e73 7461 6e74 730a 2020 2020 2020  constants.      
+000119b0: 2020 6120 3d20 3520 2a20 6e70 2e6f 6e65    a = 5 * np.one
+000119c0: 7328 6e29 0a0a 2020 2020 2020 2020 2320  s(n)..        # 
+000119d0: 6465 7465 726d 696e 6520 7375 6d0a 2020  determine sum.  
+000119e0: 2020 2020 2020 7320 3d20 6e70 2e7a 6572        s = np.zer
+000119f0: 6f73 286e 702e 6172 7261 7928 7365 6c66  os(np.array(self
+00011a00: 2e70 5b6c 6973 7428 7365 6c66 2e70 2e6b  .p[list(self.p.k
+00011a10: 6579 7328 2929 5b30 5d5d 292e 7369 7a65  eys())[0]]).size
+00011a20: 290a 0a20 2020 2020 2020 2066 6f72 2069  )..        for i
+00011a30: 2c20 6b65 7920 696e 2065 6e75 6d65 7261  , key in enumera
+00011a40: 7465 2873 656c 662e 702e 6b65 7973 2829  te(self.p.keys()
+00011a50: 293a 0a20 2020 2020 2020 2020 2020 2073  ):.            s
+00011a60: 202b 3d20 615b 695d 202a 2073 656c 662e   += a[i] * self.
+00011a70: 705b 6b65 795d 0a0a 2020 2020 2020 2020  p[key]..        
+00011a80: 2320 6465 7465 726d 696e 6520 6f75 7470  # determine outp
+00011a90: 7574 0a20 2020 2020 2020 2079 203d 2028  ut.        y = (
+00011aa0: 3120 2b20 7329 202a 2a20 2d28 6e20 2b20  1 + s) ** -(n + 
+00011ab0: 3129 0a0a 2020 2020 2020 2020 795f 6f75  1)..        y_ou
+00011ac0: 7420 3d20 795b 3a2c 206e 702e 6e65 7761  t = y[:, np.newa
+00011ad0: 7869 735d 0a0a 2020 2020 2020 2020 7265  xis]..        re
+00011ae0: 7475 726e 2079 5f6f 7574 0a0a 0a63 6c61  turn y_out...cla
+00011af0: 7373 2047 656e 7a44 6973 636f 6e74 696e  ss GenzDiscontin
+00011b00: 756f 7573 2841 6273 7472 6163 744d 6f64  uous(AbstractMod
+00011b10: 656c 293a 0a20 2020 2022 2222 0a20 2020  el):.    """.   
+00011b20: 204e 2d64 696d 656e 7369 6f6e 616c 2022   N-dimensional "
+00011b30: 4469 7363 6f6e 7469 6e75 6f75 7322 2047  Discontinuous" G
+00011b40: 656e 7a20 6675 6e63 7469 6f6e 205b 315d  enz function [1]
+00011b50: 2e20 4974 2069 7320 6465 6669 6e65 6420  . It is defined 
+00011b60: 696e 2074 6865 2069 6e74 6572 7661 6c20  in the interval 
+00011b70: 5b30 2c20 315d 2078 202e 2e2e 2078 205b  [0, 1] x ... x [
+00011b80: 302c 2031 5d2e 0a0a 2020 2020 2e2e 206d  0, 1]...    .. m
+00011b90: 6174 683a 3a20 7920 3d20 5c65 7870 5c5c  ath:: y = \exp\\
+00011ba0: 6c65 6674 2820 5c73 756d 5f7b 693d 317d  left( \sum_{i=1}
+00011bb0: 5e4e 2061 5f69 2078 5f69 5c5c 7269 6768  ^N a_i x_i\\righ
+00011bc0: 7429 205c 7175 6164 205c 6d61 7468 726d  t) \quad \mathrm
+00011bd0: 7b69 667d 205c 7175 6164 2078 5f69 203c  {if} \quad x_i <
+00011be0: 2075 5f69 205c 7175 6164 205c 6d61 7468   u_i \quad \math
+00011bf0: 726d 7b65 6c73 657d 205c 7175 6164 2030  rm{else} \quad 0
+00011c00: 0a0a 2020 2020 5061 7261 6d65 7465 7273  ..    Parameters
+00011c10: 0a20 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0a  .    ----------.
+00011c20: 2020 2020 705b 2278 3122 5d3a 2066 6c6f      p["x1"]: flo
+00011c30: 6174 206f 7220 6e64 6172 7261 7920 6f66  at or ndarray of
+00011c40: 2066 6c6f 6174 205b 6e5f 6772 6964 5d0a   float [n_grid].
+00011c50: 2020 2020 2020 2020 4669 7273 7420 7061          First pa
+00011c60: 7261 6d65 7465 7220 6465 6669 6e65 6420  rameter defined 
+00011c70: 696e 205b 302c 2031 5d0a 2020 2020 705b  in [0, 1].    p[
+00011c80: 2278 6922 5d3a 2066 6c6f 6174 206f 7220  "xi"]: float or 
+00011c90: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
+00011ca0: 205b 6e5f 6772 6964 5d0a 2020 2020 2020   [n_grid].      
+00011cb0: 2020 692d 7468 2070 6172 616d 6574 6572    i-th parameter
+00011cc0: 2064 6566 696e 6564 2069 6e20 5b30 2c20   defined in [0, 
+00011cd0: 315d 0a20 2020 2070 5b22 784e 225d 3a20  1].    p["xN"]: 
+00011ce0: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
+00011cf0: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
+00011d00: 645d 0a20 2020 2020 2020 204e 7468 2070  d].        Nth p
+00011d10: 6172 616d 6574 6572 2064 6566 696e 6564  arameter defined
+00011d20: 2069 6e20 5b30 2c20 315d 0a0a 2020 2020   in [0, 1]..    
+00011d30: 5265 7475 726e 730a 2020 2020 2d2d 2d2d  Returns.    ----
+00011d40: 2d2d 2d0a 2020 2020 793a 206e 6461 7272  ---.    y: ndarr
+00011d50: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
+00011d60: 7269 6420 7820 315d 0a20 2020 2020 2020  rid x 1].       
+00011d70: 204f 7574 7075 740a 0a20 2020 204e 6f74   Output..    Not
+00011d80: 6573 0a20 2020 202d 2d2d 2d2d 0a20 2020  es.    -----.   
+00011d90: 202e 2e20 706c 6f74 3a3a 0a0a 2020 2020   .. plot::..    
+00011da0: 2020 2069 6d70 6f72 7420 6e75 6d70 7920     import numpy 
+00011db0: 6173 206e 700a 2020 2020 2020 2066 726f  as np.       fro
+00011dc0: 6d20 7079 6770 632e 7465 7374 6675 6e63  m pygpc.testfunc
+00011dd0: 7469 6f6e 7320 696d 706f 7274 2070 6c6f  tions import plo
+00011de0: 745f 7465 7374 6675 6e63 7469 6f6e 2061  t_testfunction a
+00011df0: 7320 706c 6f74 0a20 2020 2020 2020 6672  s plot.       fr
+00011e00: 6f6d 2063 6f6c 6c65 6374 696f 6e73 2069  om collections i
+00011e10: 6d70 6f72 7420 4f72 6465 7265 6444 6963  mport OrderedDic
+00011e20: 740a 0a20 2020 2020 2020 7061 7261 6d65  t..       parame
+00011e30: 7465 7273 203d 204f 7264 6572 6564 4469  ters = OrderedDi
+00011e40: 6374 2829 0a20 2020 2020 2020 7061 7261  ct().       para
+00011e50: 6d65 7465 7273 5b22 7831 225d 203d 206e  meters["x1"] = n
+00011e60: 702e 6c69 6e73 7061 6365 2830 2c20 312c  p.linspace(0, 1,
+00011e70: 2031 3030 290a 2020 2020 2020 2070 6172   100).       par
+00011e80: 616d 6574 6572 735b 2278 3222 5d20 3d20  ameters["x2"] = 
+00011e90: 6e70 2e6c 696e 7370 6163 6528 302c 2031  np.linspace(0, 1
+00011ea0: 2c20 3130 3029 0a0a 2020 2020 2020 2070  , 100)..       p
+00011eb0: 6c6f 7428 2247 656e 7a44 6973 636f 6e74  lot("GenzDiscont
+00011ec0: 696e 756f 7573 222c 2070 6172 616d 6574  inuous", paramet
+00011ed0: 6572 7329 0a0a 2020 2020 2e2e 205b 315d  ers)..    .. [1]
+00011ee0: 2047 656e 7a2c 2041 2e20 2831 3938 3429   Genz, A. (1984)
+00011ef0: 2c20 5465 7374 696e 6720 6d75 6c74 6964  , Testing multid
+00011f00: 696d 656e 7369 6f6e 616c 2069 6e74 6567  imensional integ
+00011f10: 7261 7469 6f6e 2072 6f75 7469 6e65 732e  ration routines.
+00011f20: 0a20 2020 2020 2020 5072 6f63 2e20 6f66  .       Proc. of
+00011f30: 2069 6e74 6572 6e61 7469 6f6e 616c 2063   international c
+00011f40: 6f6e 6665 7265 6e63 6520 6f6e 2054 6f6f  onference on Too
+00011f50: 6c73 2c20 6d65 7468 6f64 7320 616e 6420  ls, methods and 
+00011f60: 6c61 6e67 7561 6765 7320 666f 7220 7363  languages for sc
+00011f70: 6965 6e74 6966 6963 0a20 2020 2020 2020  ientific.       
+00011f80: 616e 6420 656e 6769 6e65 6572 696e 6720  and engineering 
+00011f90: 636f 6d70 7574 6174 696f 6e2c 2045 6c73  computation, Els
+00011fa0: 6576 6965 7220 4e6f 7274 682d 486f 6c6c  evier North-Holl
+00011fb0: 616e 642c 2049 6e63 2e2c 204e 6577 596f  and, Inc., NewYo
+00011fc0: 726b 2c20 4e59 2c20 5553 412c 2070 702e  rk, NY, USA, pp.
+00011fd0: 2038 312d 3934 2e0a 0a20 2020 202e 2e20   81-94...    .. 
+00011fe0: 5b32 5d20 6874 7470 733a 2f2f 7777 772e  [2] https://www.
+00011ff0: 7366 752e 6361 2f7e 7373 7572 6a61 6e6f  sfu.ca/~ssurjano
+00012000: 2f64 6973 632e 6874 6d6c 0a20 2020 2022  /disc.html.    "
+00012010: 2222 0a0a 2020 2020 6465 6620 5f5f 696e  ""..    def __in
+00012020: 6974 5f5f 2873 656c 662c 206d 6174 6c61  it__(self, matla
+00012030: 625f 6d6f 6465 6c3d 4661 6c73 6529 3a0a  b_model=False):.
+00012040: 2020 2020 2020 2020 7375 7065 7228 7479          super(ty
+00012050: 7065 2873 656c 6629 2c20 7365 6c66 292e  pe(self), self).
+00012060: 5f5f 696e 6974 5f5f 286d 6174 6c61 625f  __init__(matlab_
+00012070: 6d6f 6465 6c3d 6d61 746c 6162 5f6d 6f64  model=matlab_mod
+00012080: 656c 290a 2020 2020 2020 2020 7365 6c66  el).        self
+00012090: 2e66 6e61 6d65 203d 2069 6e73 7065 6374  .fname = inspect
+000120a0: 2e67 6574 6669 6c65 2869 6e73 7065 6374  .getfile(inspect
+000120b0: 2e63 7572 7265 6e74 6672 616d 6528 2929  .currentframe())
+000120c0: 0a0a 2020 2020 6465 6620 7661 6c69 6461  ..    def valida
+000120d0: 7465 2873 656c 6629 3a0a 2020 2020 2020  te(self):.      
+000120e0: 2020 7061 7373 0a0a 2020 2020 6465 6620    pass..    def 
+000120f0: 7369 6d75 6c61 7465 2873 656c 662c 2070  simulate(self, p
+00012100: 726f 6365 7373 5f69 643d 4e6f 6e65 2c20  rocess_id=None, 
+00012110: 6d61 746c 6162 5f65 6e67 696e 653d 4e6f  matlab_engine=No
+00012120: 6e65 293a 0a0a 2020 2020 2020 2020 6e20  ne):..        n 
+00012130: 3d20 6c65 6e28 7365 6c66 2e70 2e6b 6579  = len(self.p.key
+00012140: 7328 2929 0a0a 2020 2020 2020 2020 2320  s())..        # 
+00012150: 7365 7420 636f 6e73 7461 6e74 730a 2020  set constants.  
+00012160: 2020 2020 2020 7520 3d20 302e 3520 2a20        u = 0.5 * 
+00012170: 6e70 2e6f 6e65 7328 6e29 0a20 2020 2020  np.ones(n).     
+00012180: 2020 2061 203d 2035 202a 206e 702e 6f6e     a = 5 * np.on
+00012190: 6573 286e 290a 0a20 2020 2020 2020 206d  es(n)..        m
+000121a0: 6173 6b20 3d20 6e70 2e7a 6572 6f73 2828  ask = np.zeros((
+000121b0: 6c65 6e28 7365 6c66 2e70 5b6c 6973 7428  len(self.p[list(
+000121c0: 7365 6c66 2e70 2e6b 6579 7328 2929 5b30  self.p.keys())[0
+000121d0: 5d5d 292c 206e 2929 0a0a 2020 2020 2020  ]]), n))..      
+000121e0: 2020 666f 7220 692c 206b 6579 2069 6e20    for i, key in 
+000121f0: 656e 756d 6572 6174 6528 7365 6c66 2e70  enumerate(self.p
+00012200: 2e6b 6579 7328 2929 3a0a 2020 2020 2020  .keys()):.      
+00012210: 2020 2020 2020 6d61 736b 5b3a 2c20 695d        mask[:, i]
+00012220: 203d 2028 7365 6c66 2e70 5b6b 6579 5d20   = (self.p[key] 
+00012230: 3e20 755b 695d 292e 7371 7565 657a 6528  > u[i]).squeeze(
+00012240: 290a 2020 2020 2020 2020 6d61 736b 203d  ).        mask =
+00012250: 206d 6173 6b2e 616e 7928 6178 6973 3d31   mask.any(axis=1
+00012260: 290a 0a20 2020 2020 2020 2023 2064 6574  )..        # det
+00012270: 6572 6d69 6e65 2073 756d 0a20 2020 2020  ermine sum.     
+00012280: 2020 2073 203d 206e 702e 7a65 726f 7328     s = np.zeros(
+00012290: 286e 702e 6172 7261 7928 7365 6c66 2e70  (np.array(self.p
+000122a0: 5b6c 6973 7428 7365 6c66 2e70 2e6b 6579  [list(self.p.key
+000122b0: 7328 2929 5b30 5d5d 292e 7369 7a65 2c20  s())[0]]).size, 
+000122c0: 3129 290a 0a20 2020 2020 2020 2066 6f72  1))..        for
+000122d0: 2069 2c20 6b65 7920 696e 2065 6e75 6d65   i, key in enume
+000122e0: 7261 7465 2873 656c 662e 702e 6b65 7973  rate(self.p.keys
+000122f0: 2829 293a 0a20 2020 2020 2020 2020 2020  ()):.           
+00012300: 2069 6620 7365 6c66 2e70 5b6b 6579 5d2e   if self.p[key].
+00012310: 6e64 696d 203d 3d20 313a 0a20 2020 2020  ndim == 1:.     
+00012320: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+00012330: 705b 6b65 795d 203d 2073 656c 662e 705b  p[key] = self.p[
+00012340: 6b65 795d 5b3a 2c20 6e70 2e6e 6577 6178  key][:, np.newax
+00012350: 6973 5d0a 2020 2020 2020 2020 2020 2020  is].            
+00012360: 7320 2b3d 2061 5b69 5d20 2a20 7365 6c66  s += a[i] * self
+00012370: 2e70 5b6b 6579 5d0a 0a20 2020 2020 2020  .p[key]..       
+00012380: 2023 2064 6574 6572 6d69 6e65 206f 7574   # determine out
+00012390: 7075 740a 2020 2020 2020 2020 7920 3d20  put.        y = 
+000123a0: 6e70 2e65 7870 2873 290a 2020 2020 2020  np.exp(s).      
+000123b0: 2020 795b 6d61 736b 5d20 3d20 302e 0a0a    y[mask] = 0...
+000123c0: 2020 2020 2020 2020 7265 7475 726e 2079          return y
+000123d0: 0a0a 0a63 6c61 7373 2047 656e 7a47 6175  ...class GenzGau
+000123e0: 7373 6961 6e50 6561 6b28 4162 7374 7261  ssianPeak(Abstra
+000123f0: 6374 4d6f 6465 6c29 3a0a 2020 2020 2222  ctModel):.    ""
+00012400: 220a 2020 2020 4e2d 6469 6d65 6e73 696f  ".    N-dimensio
+00012410: 6e61 6c20 2247 6175 7373 6961 6e50 6561  nal "GaussianPea
+00012420: 6b22 2047 656e 7a20 6675 6e63 7469 6f6e  k" Genz function
+00012430: 205b 315d 2e20 4974 2069 7320 6465 6669   [1]. It is defi
+00012440: 6e65 6420 696e 2074 6865 2069 6e74 6572  ned in the inter
+00012450: 7661 6c20 5b30 2c20 315d 2078 202e 2e2e  val [0, 1] x ...
+00012460: 2078 205b 302c 2031 5d2e 0a0a 2020 2020   x [0, 1]...    
+00012470: 2e2e 206d 6174 683a 3a20 7920 3d20 5c65  .. math:: y = \e
+00012480: 7870 5c5c 6c65 6674 2820 2d20 5c73 756d  xp\\left( - \sum
+00012490: 5f7b 693d 317d 5e7b 4e7d 2061 5f69 205e  _{i=1}^{N} a_i ^
+000124a0: 3220 2878 5f69 202d 2075 5f69 295e 325c  2 (x_i - u_i)^2\
+000124b0: 5c72 6967 6874 290a 0a20 2020 2042 7920  \right)..    By 
+000124c0: 6465 6661 756c 7420 755f 6920 3d20 302e  default u_i = 0.
+000124d0: 3520 616e 6420 615f 6920 3d20 352e 0a0a  5 and a_i = 5...
+000124e0: 2020 2020 5061 7261 6d65 7465 7273 0a20      Parameters. 
+000124f0: 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020     ----------.  
+00012500: 2020 705b 2278 3122 5d3a 2066 6c6f 6174    p["x1"]: float
+00012510: 206f 7220 6e64 6172 7261 7920 6f66 2066   or ndarray of f
+00012520: 6c6f 6174 205b 6e5f 6772 6964 5d0a 2020  loat [n_grid].  
+00012530: 2020 2020 2020 4669 7273 7420 7061 7261        First para
+00012540: 6d65 7465 7220 6465 6669 6e65 6420 696e  meter defined in
+00012550: 205b 302c 2031 5d0a 2020 2020 705b 2278   [0, 1].    p["x
+00012560: 6922 5d3a 2066 6c6f 6174 206f 7220 6e64  i"]: float or nd
+00012570: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
+00012580: 6e5f 6772 6964 5d0a 2020 2020 2020 2020  n_grid].        
+00012590: 692d 7468 2070 6172 616d 6574 6572 2064  i-th parameter d
+000125a0: 6566 696e 6564 2069 6e20 5b30 2c20 315d  efined in [0, 1]
+000125b0: 0a20 2020 2070 5b22 784e 225d 3a20 666c  .    p["xN"]: fl
+000125c0: 6f61 7420 6f72 206e 6461 7272 6179 206f  oat or ndarray o
+000125d0: 6620 666c 6f61 7420 5b6e 5f67 7269 645d  f float [n_grid]
+000125e0: 0a20 2020 2020 2020 204e 7468 2070 6172  .        Nth par
+000125f0: 616d 6574 6572 2064 6566 696e 6564 2069  ameter defined i
+00012600: 6e20 5b30 2c20 315d 0a0a 2020 2020 5265  n [0, 1]..    Re
+00012610: 7475 726e 730a 2020 2020 2d2d 2d2d 2d2d  turns.    ------
+00012620: 2d0a 2020 2020 793a 206e 6461 7272 6179  -.    y: ndarray
+00012630: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
+00012640: 6420 7820 315d 0a20 2020 2020 2020 204f  d x 1].        O
+00012650: 7574 7075 740a 0a20 2020 204e 6f74 6573  utput..    Notes
+00012660: 0a20 2020 202d 2d2d 2d2d 0a20 2020 202e  .    -----.    .
+00012670: 2e20 706c 6f74 3a3a 0a0a 2020 2020 2020  . plot::..      
+00012680: 2069 6d70 6f72 7420 6e75 6d70 7920 6173   import numpy as
+00012690: 206e 700a 2020 2020 2020 2066 726f 6d20   np.       from 
+000126a0: 7079 6770 632e 7465 7374 6675 6e63 7469  pygpc.testfuncti
+000126b0: 6f6e 7320 696d 706f 7274 2070 6c6f 745f  ons import plot_
+000126c0: 7465 7374 6675 6e63 7469 6f6e 2061 7320  testfunction as 
+000126d0: 706c 6f74 0a20 2020 2020 2020 6672 6f6d  plot.       from
+000126e0: 2063 6f6c 6c65 6374 696f 6e73 2069 6d70   collections imp
+000126f0: 6f72 7420 4f72 6465 7265 6444 6963 740a  ort OrderedDict.
+00012700: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
+00012710: 7273 203d 204f 7264 6572 6564 4469 6374  rs = OrderedDict
+00012720: 2829 0a20 2020 2020 2020 7061 7261 6d65  ().       parame
+00012730: 7465 7273 5b22 7831 225d 203d 206e 702e  ters["x1"] = np.
+00012740: 6c69 6e73 7061 6365 2830 2c20 312c 2031  linspace(0, 1, 1
+00012750: 3030 290a 2020 2020 2020 2070 6172 616d  00).       param
+00012760: 6574 6572 735b 2278 3222 5d20 3d20 6e70  eters["x2"] = np
+00012770: 2e6c 696e 7370 6163 6528 302c 2031 2c20  .linspace(0, 1, 
+00012780: 3130 3029 0a0a 2020 2020 2020 2070 6c6f  100)..       plo
+00012790: 7428 2247 656e 7a47 6175 7373 6961 6e50  t("GenzGaussianP
+000127a0: 6561 6b22 2c20 7061 7261 6d65 7465 7273  eak", parameters
+000127b0: 290a 0a20 2020 202e 2e20 5b31 5d20 4765  )..    .. [1] Ge
+000127c0: 6e7a 2c20 412e 2028 3139 3834 292c 2054  nz, A. (1984), T
+000127d0: 6573 7469 6e67 206d 756c 7469 6469 6d65  esting multidime
+000127e0: 6e73 696f 6e61 6c20 696e 7465 6772 6174  nsional integrat
+000127f0: 696f 6e20 726f 7574 696e 6573 2e0a 2020  ion routines..  
+00012800: 2020 2020 2050 726f 632e 206f 6620 696e       Proc. of in
+00012810: 7465 726e 6174 696f 6e61 6c20 636f 6e66  ternational conf
+00012820: 6572 656e 6365 206f 6e20 546f 6f6c 732c  erence on Tools,
+00012830: 206d 6574 686f 6473 2061 6e64 206c 616e   methods and lan
+00012840: 6775 6167 6573 2066 6f72 2073 6369 656e  guages for scien
+00012850: 7469 6669 630a 2020 2020 2020 2061 6e64  tific.       and
+00012860: 2065 6e67 696e 6565 7269 6e67 2063 6f6d   engineering com
+00012870: 7075 7461 7469 6f6e 2c20 456c 7365 7669  putation, Elsevi
+00012880: 6572 204e 6f72 7468 2d48 6f6c 6c61 6e64  er North-Holland
+00012890: 2c20 496e 632e 2c20 4e65 7759 6f72 6b2c  , Inc., NewYork,
+000128a0: 204e 592c 2055 5341 2c20 7070 2e20 3831   NY, USA, pp. 81
+000128b0: 2d39 342e 0a0a 2020 2020 2e2e 205b 325d  -94...    .. [2]
+000128c0: 2068 7474 7073 3a2f 2f77 7777 2e73 6675   https://www.sfu
+000128d0: 2e63 612f 7e73 7375 726a 616e 6f2f 6761  .ca/~ssurjano/ga
+000128e0: 7573 7369 616e 2e68 746d 6c0a 2020 2020  ussian.html.    
+000128f0: 2222 220a 0a20 2020 2064 6566 205f 5f69  """..    def __i
+00012900: 6e69 745f 5f28 7365 6c66 2c20 6d61 746c  nit__(self, matl
+00012910: 6162 5f6d 6f64 656c 3d46 616c 7365 293a  ab_model=False):
+00012920: 0a20 2020 2020 2020 2073 7570 6572 2874  .        super(t
+00012930: 7970 6528 7365 6c66 292c 2073 656c 6629  ype(self), self)
+00012940: 2e5f 5f69 6e69 745f 5f28 6d61 746c 6162  .__init__(matlab
+00012950: 5f6d 6f64 656c 3d6d 6174 6c61 625f 6d6f  _model=matlab_mo
+00012960: 6465 6c29 0a20 2020 2020 2020 2073 656c  del).        sel
+00012970: 662e 666e 616d 6520 3d20 696e 7370 6563  f.fname = inspec
+00012980: 742e 6765 7466 696c 6528 696e 7370 6563  t.getfile(inspec
+00012990: 742e 6375 7272 656e 7466 7261 6d65 2829  t.currentframe()
+000129a0: 290a 0a20 2020 2064 6566 2076 616c 6964  )..    def valid
+000129b0: 6174 6528 7365 6c66 293a 0a20 2020 2020  ate(self):.     
+000129c0: 2020 2070 6173 730a 0a20 2020 2064 6566     pass..    def
+000129d0: 2073 696d 756c 6174 6528 7365 6c66 2c20   simulate(self, 
+000129e0: 7072 6f63 6573 735f 6964 3d4e 6f6e 652c  process_id=None,
+000129f0: 206d 6174 6c61 625f 656e 6769 6e65 3d4e   matlab_engine=N
+00012a00: 6f6e 6529 3a0a 2020 2020 2020 2020 6e20  one):.        n 
+00012a10: 3d20 6c65 6e28 7365 6c66 2e70 2e6b 6579  = len(self.p.key
+00012a20: 7328 2929 0a0a 2020 2020 2020 2020 2320  s())..        # 
+00012a30: 7365 7420 636f 6e73 7461 6e74 730a 2020  set constants.  
+00012a40: 2020 2020 2020 7520 3d20 302e 3520 2a20        u = 0.5 * 
+00012a50: 6e70 2e6f 6e65 7328 6e29 0a20 2020 2020  np.ones(n).     
+00012a60: 2020 2061 203d 2035 202a 206e 702e 6f6e     a = 5 * np.on
+00012a70: 6573 286e 290a 0a20 2020 2020 2020 2023  es(n)..        #
+00012a80: 2064 6574 6572 6d69 6e65 2073 756d 0a20   determine sum. 
+00012a90: 2020 2020 2020 2073 203d 206e 702e 7a65         s = np.ze
+00012aa0: 726f 7328 6e70 2e61 7272 6179 2873 656c  ros(np.array(sel
+00012ab0: 662e 705b 6c69 7374 2873 656c 662e 702e  f.p[list(self.p.
+00012ac0: 6b65 7973 2829 295b 305d 5d29 2e73 697a  keys())[0]]).siz
+00012ad0: 6529 0a0a 2020 2020 2020 2020 666f 7220  e)..        for 
+00012ae0: 692c 206b 6579 2069 6e20 656e 756d 6572  i, key in enumer
+00012af0: 6174 6528 7365 6c66 2e70 2e6b 6579 7328  ate(self.p.keys(
+00012b00: 2929 3a0a 2020 2020 2020 2020 2020 2020  )):.            
+00012b10: 7320 2b3d 2061 5b69 5d20 2a2a 2032 202a  s += a[i] ** 2 *
+00012b20: 2028 7365 6c66 2e70 5b6b 6579 5d20 2d20   (self.p[key] - 
+00012b30: 755b 695d 2920 2a2a 2032 0a0a 2020 2020  u[i]) ** 2..    
+00012b40: 2020 2020 2320 6465 7465 726d 696e 6520      # determine 
+00012b50: 6f75 7470 7574 0a20 2020 2020 2020 2079  output.        y
+00012b60: 203d 206e 702e 6578 7028 2d73 290a 0a20   = np.exp(-s).. 
+00012b70: 2020 2020 2020 2079 5f6f 7574 203d 2079         y_out = y
+00012b80: 5b3a 2c20 6e70 2e6e 6577 6178 6973 5d0a  [:, np.newaxis].
+00012b90: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00012ba0: 795f 6f75 740a 0a0a 636c 6173 7320 4765  y_out...class Ge
+00012bb0: 6e7a 4f73 6369 6c6c 6174 6f72 7928 4162  nzOscillatory(Ab
+00012bc0: 7374 7261 6374 4d6f 6465 6c29 3a0a 2020  stractModel):.  
+00012bd0: 2020 2222 220a 2020 2020 4e2d 6469 6d65    """.    N-dime
+00012be0: 6e73 696f 6e61 6c20 224f 7363 696c 6c61  nsional "Oscilla
+00012bf0: 746f 7279 2220 4765 6e7a 2066 756e 6374  tory" Genz funct
+00012c00: 696f 6e20 5b31 5d2e 2049 7420 6973 2064  ion [1]. It is d
+00012c10: 6566 696e 6564 2069 6e20 7468 6520 696e  efined in the in
+00012c20: 7465 7276 616c 205b 302c 2031 5d20 7820  terval [0, 1] x 
+00012c30: 2e2e 2e20 7820 5b30 2c20 315d 2e0a 0a20  ... x [0, 1]... 
+00012c40: 2020 202e 2e20 6d61 7468 3a3a 2079 203d     .. math:: y =
+00012c50: 205c 5c63 6f73 205c 5c6c 6566 7428 2032   \\cos \\left( 2
+00012c60: 205c 5c70 6920 755f 3120 2b20 5c5c 7375   \\pi u_1 + \\su
+00012c70: 6d5f 7b69 3d31 7d5e 7b4e 7d61 5f69 2078  m_{i=1}^{N}a_i x
+00012c80: 5f69 205c 5c72 6967 6874 290a 0a20 2020  _i \\right)..   
+00012c90: 2050 6172 616d 6574 6572 730a 2020 2020   Parameters.    
+00012ca0: 2d2d 2d2d 2d2d 2d2d 2d2d 0a20 2020 2070  ----------.    p
+00012cb0: 5b22 7831 225d 3a20 666c 6f61 7420 6f72  ["x1"]: float or
+00012cc0: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
+00012cd0: 7420 5b6e 5f67 7269 645d 0a20 2020 2020  t [n_grid].     
+00012ce0: 2020 2046 6972 7374 2070 6172 616d 6574     First paramet
+00012cf0: 6572 2064 6566 696e 6564 2069 6e20 5b30  er defined in [0
+00012d00: 2c20 315d 0a20 2020 2070 5b22 7869 225d  , 1].    p["xi"]
+00012d10: 3a20 666c 6f61 7420 6f72 206e 6461 7272  : float or ndarr
+00012d20: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
+00012d30: 7269 645d 0a20 2020 2020 2020 2069 2d74  rid].        i-t
+00012d40: 6820 7061 7261 6d65 7465 7220 6465 6669  h parameter defi
+00012d50: 6e65 6420 696e 205b 302c 2031 5d0a 2020  ned in [0, 1].  
+00012d60: 2020 705b 2278 4e22 5d3a 2066 6c6f 6174    p["xN"]: float
+00012d70: 206f 7220 6e64 6172 7261 7920 6f66 2066   or ndarray of f
+00012d80: 6c6f 6174 205b 6e5f 6772 6964 5d0a 2020  loat [n_grid].  
+00012d90: 2020 2020 2020 4e74 6820 7061 7261 6d65        Nth parame
+00012da0: 7465 7220 6465 6669 6e65 6420 696e 205b  ter defined in [
+00012db0: 302c 2031 5d0a 0a20 2020 2052 6574 7572  0, 1]..    Retur
+00012dc0: 6e73 0a20 2020 202d 2d2d 2d2d 2d2d 0a20  ns.    -------. 
+00012dd0: 2020 2079 3a20 6e64 6172 7261 7920 6f66     y: ndarray of
+00012de0: 2066 6c6f 6174 205b 6e5f 6772 6964 2078   float [n_grid x
+00012df0: 2031 5d0a 2020 2020 2020 2020 4f75 7470   1].        Outp
+00012e00: 7574 0a0a 2020 2020 4e6f 7465 730a 2020  ut..    Notes.  
+00012e10: 2020 2d2d 2d2d 2d0a 2020 2020 2e2e 2070    -----.    .. p
+00012e20: 6c6f 743a 3a0a 0a20 2020 2020 2020 696d  lot::..       im
+00012e30: 706f 7274 206e 756d 7079 2061 7320 6e70  port numpy as np
+00012e40: 0a20 2020 2020 2020 6672 6f6d 2070 7967  .       from pyg
+00012e50: 7063 2e74 6573 7466 756e 6374 696f 6e73  pc.testfunctions
+00012e60: 2069 6d70 6f72 7420 706c 6f74 5f74 6573   import plot_tes
+00012e70: 7466 756e 6374 696f 6e20 6173 2070 6c6f  tfunction as plo
+00012e80: 740a 2020 2020 2020 2066 726f 6d20 636f  t.       from co
+00012e90: 6c6c 6563 7469 6f6e 7320 696d 706f 7274  llections import
+00012ea0: 204f 7264 6572 6564 4469 6374 0a0a 2020   OrderedDict..  
+00012eb0: 2020 2020 2070 6172 616d 6574 6572 7320       parameters 
+00012ec0: 3d20 4f72 6465 7265 6444 6963 7428 290a  = OrderedDict().
+00012ed0: 2020 2020 2020 2070 6172 616d 6574 6572         parameter
+00012ee0: 735b 2278 3122 5d20 3d20 6e70 2e6c 696e  s["x1"] = np.lin
+00012ef0: 7370 6163 6528 302c 2031 2c20 3130 3029  space(0, 1, 100)
+00012f00: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
+00012f10: 7273 5b22 7832 225d 203d 206e 702e 6c69  rs["x2"] = np.li
+00012f20: 6e73 7061 6365 2830 2c20 312c 2031 3030  nspace(0, 1, 100
+00012f30: 290a 0a20 2020 2020 2020 706c 6f74 2822  )..       plot("
+00012f40: 4765 6e7a 4f73 6369 6c6c 6174 6f72 7922  GenzOscillatory"
+00012f50: 2c20 7061 7261 6d65 7465 7273 290a 0a20  , parameters).. 
+00012f60: 2020 202e 2e20 5b31 5d20 4765 6e7a 2c20     .. [1] Genz, 
+00012f70: 412e 2028 3139 3834 292c 2054 6573 7469  A. (1984), Testi
+00012f80: 6e67 206d 756c 7469 6469 6d65 6e73 696f  ng multidimensio
+00012f90: 6e61 6c20 696e 7465 6772 6174 696f 6e20  nal integration 
+00012fa0: 726f 7574 696e 6573 2e0a 2020 2020 2020  routines..      
+00012fb0: 2050 726f 632e 206f 6620 696e 7465 726e   Proc. of intern
+00012fc0: 6174 696f 6e61 6c20 636f 6e66 6572 656e  ational conferen
+00012fd0: 6365 206f 6e20 546f 6f6c 732c 206d 6574  ce on Tools, met
+00012fe0: 686f 6473 2061 6e64 206c 616e 6775 6167  hods and languag
+00012ff0: 6573 2066 6f72 2073 6369 656e 7469 6669  es for scientifi
+00013000: 630a 2020 2020 2020 2061 6e64 2065 6e67  c.       and eng
+00013010: 696e 6565 7269 6e67 2063 6f6d 7075 7461  ineering computa
+00013020: 7469 6f6e 2c20 456c 7365 7669 6572 204e  tion, Elsevier N
+00013030: 6f72 7468 2d48 6f6c 6c61 6e64 2c20 496e  orth-Holland, In
+00013040: 632e 2c20 4e65 7759 6f72 6b2c 204e 592c  c., NewYork, NY,
+00013050: 2055 5341 2c20 7070 2e20 3831 2d39 342e   USA, pp. 81-94.
+00013060: 0a0a 2020 2020 2e2e 205b 325d 2068 7474  ..    .. [2] htt
+00013070: 7073 3a2f 2f77 7777 2e73 6675 2e63 612f  ps://www.sfu.ca/
+00013080: 7e73 7375 726a 616e 6f2f 6f73 6369 6c2e  ~ssurjano/oscil.
+00013090: 6874 6d6c 0a20 2020 2022 2222 0a0a 2020  html.    """..  
+000130a0: 2020 6465 6620 5f5f 696e 6974 5f5f 2873    def __init__(s
+000130b0: 656c 662c 206d 6174 6c61 625f 6d6f 6465  elf, matlab_mode
+000130c0: 6c3d 4661 6c73 6529 3a0a 2020 2020 2020  l=False):.      
+000130d0: 2020 7375 7065 7228 7479 7065 2873 656c    super(type(sel
+000130e0: 6629 2c20 7365 6c66 292e 5f5f 696e 6974  f), self).__init
+000130f0: 5f5f 286d 6174 6c61 625f 6d6f 6465 6c3d  __(matlab_model=
+00013100: 6d61 746c 6162 5f6d 6f64 656c 290a 2020  matlab_model).  
+00013110: 2020 2020 2020 7365 6c66 2e66 6e61 6d65        self.fname
+00013120: 203d 2069 6e73 7065 6374 2e67 6574 6669   = inspect.getfi
+00013130: 6c65 2869 6e73 7065 6374 2e63 7572 7265  le(inspect.curre
+00013140: 6e74 6672 616d 6528 2929 0a0a 2020 2020  ntframe())..    
+00013150: 6465 6620 7661 6c69 6461 7465 2873 656c  def validate(sel
+00013160: 6629 3a0a 2020 2020 2020 2020 7061 7373  f):.        pass
+00013170: 0a0a 2020 2020 6465 6620 7369 6d75 6c61  ..    def simula
+00013180: 7465 2873 656c 662c 2070 726f 6365 7373  te(self, process
+00013190: 5f69 643d 4e6f 6e65 2c20 6d61 746c 6162  _id=None, matlab
+000131a0: 5f65 6e67 696e 653d 4e6f 6e65 293a 0a20  _engine=None):. 
+000131b0: 2020 2020 2020 206e 203d 206c 656e 2873         n = len(s
+000131c0: 656c 662e 702e 6b65 7973 2829 290a 0a20  elf.p.keys()).. 
+000131d0: 2020 2020 2020 2023 2073 6574 2063 6f6e         # set con
+000131e0: 7374 616e 7473 0a20 2020 2020 2020 2075  stants.        u
+000131f0: 203d 2030 2e35 202a 206e 702e 6f6e 6573   = 0.5 * np.ones
+00013200: 286e 290a 2020 2020 2020 2020 6120 3d20  (n).        a = 
+00013210: 3520 2a20 6e70 2e6f 6e65 7328 6e29 0a0a  5 * np.ones(n)..
+00013220: 2020 2020 2020 2020 2320 6465 7465 726d          # determ
+00013230: 696e 6520 7375 6d0a 2020 2020 2020 2020  ine sum.        
+00013240: 7320 3d20 6e70 2e7a 6572 6f73 286e 702e  s = np.zeros(np.
+00013250: 6172 7261 7928 7365 6c66 2e70 5b6c 6973  array(self.p[lis
+00013260: 7428 7365 6c66 2e70 2e6b 6579 7328 2929  t(self.p.keys())
+00013270: 5b30 5d5d 292e 7369 7a65 290a 0a20 2020  [0]]).size)..   
+00013280: 2020 2020 2066 6f72 2069 2c20 6b65 7920       for i, key 
+00013290: 696e 2065 6e75 6d65 7261 7465 2873 656c  in enumerate(sel
+000132a0: 662e 702e 6b65 7973 2829 293a 0a20 2020  f.p.keys()):.   
+000132b0: 2020 2020 2020 2020 2073 202b 3d20 615b           s += a[
+000132c0: 695d 202a 2073 656c 662e 705b 6b65 795d  i] * self.p[key]
+000132d0: 0a0a 2020 2020 2020 2020 2320 6465 7465  ..        # dete
+000132e0: 726d 696e 6520 6f75 7470 7574 0a20 2020  rmine output.   
+000132f0: 2020 2020 2079 203d 206e 702e 636f 7328       y = np.cos(
+00013300: 3220 2a20 6e70 2e70 6920 2a20 755b 305d  2 * np.pi * u[0]
+00013310: 202b 2073 290a 0a20 2020 2020 2020 2079   + s)..        y
+00013320: 5f6f 7574 203d 2079 5b3a 2c20 6e70 2e6e  _out = y[:, np.n
+00013330: 6577 6178 6973 5d0a 0a20 2020 2020 2020  ewaxis]..       
+00013340: 2023 2079 5f6f 7574 203d 206e 702e 6873   # y_out = np.hs
+00013350: 7461 636b 2828 795f 6f75 742c 2032 2a79  tack((y_out, 2*y
+00013360: 5f6f 7574 2929 0a0a 2020 2020 2020 2020  _out))..        
+00013370: 7265 7475 726e 2079 5f6f 7574 0a0a 0a63  return y_out...c
+00013380: 6c61 7373 2047 656e 7a4f 7363 696c 6c61  lass GenzOscilla
+00013390: 746f 7279 5f4e 614e 2841 6273 7472 6163  tory_NaN(Abstrac
+000133a0: 744d 6f64 656c 293a 0a20 2020 2022 2222  tModel):.    """
+000133b0: 0a20 2020 204e 2d64 696d 656e 7369 6f6e  .    N-dimension
+000133c0: 616c 2022 4f73 6369 6c6c 6174 6f72 7922  al "Oscillatory"
+000133d0: 2047 656e 7a20 6675 6e63 7469 6f6e 205b   Genz function [
+000133e0: 315d 2e20 4974 2069 7320 6465 6669 6e65  1]. It is define
+000133f0: 6420 696e 2074 6865 2069 6e74 6572 7661  d in the interva
+00013400: 6c20 5b30 2c20 315d 2078 202e 2e2e 2078  l [0, 1] x ... x
+00013410: 205b 302c 2031 5d2e 0a0a 2020 2020 2e2e   [0, 1]...    ..
+00013420: 206d 6174 683a 3a20 7920 3d20 5c5c 636f   math:: y = \\co
+00013430: 7320 5c5c 6c65 6674 2820 3220 5c5c 7069  s \\left( 2 \\pi
+00013440: 2075 5f31 202b 205c 5c73 756d 5f7b 693d   u_1 + \\sum_{i=
+00013450: 317d 5e7b 4e7d 615f 6920 785f 6920 5c5c  1}^{N}a_i x_i \\
+00013460: 7269 6768 7429 0a0a 2020 2020 5061 7261  right)..    Para
+00013470: 6d65 7465 7273 0a20 2020 202d 2d2d 2d2d  meters.    -----
+00013480: 2d2d 2d2d 2d0a 2020 2020 705b 2278 3122  -----.    p["x1"
+00013490: 5d3a 2066 6c6f 6174 206f 7220 6e64 6172  ]: float or ndar
+000134a0: 7261 7920 6f66 2066 6c6f 6174 205b 6e5f  ray of float [n_
+000134b0: 6772 6964 5d0a 2020 2020 2020 2020 4669  grid].        Fi
+000134c0: 7273 7420 7061 7261 6d65 7465 7220 6465  rst parameter de
+000134d0: 6669 6e65 6420 696e 205b 302c 2031 5d0a  fined in [0, 1].
+000134e0: 2020 2020 705b 2278 6922 5d3a 2066 6c6f      p["xi"]: flo
+000134f0: 6174 206f 7220 6e64 6172 7261 7920 6f66  at or ndarray of
+00013500: 2066 6c6f 6174 205b 6e5f 6772 6964 5d0a   float [n_grid].
+00013510: 2020 2020 2020 2020 692d 7468 2070 6172          i-th par
+00013520: 616d 6574 6572 2064 6566 696e 6564 2069  ameter defined i
+00013530: 6e20 5b30 2c20 315d 0a20 2020 2070 5b22  n [0, 1].    p["
+00013540: 784e 225d 3a20 666c 6f61 7420 6f72 206e  xN"]: float or n
+00013550: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+00013560: 5b6e 5f67 7269 645d 0a20 2020 2020 2020  [n_grid].       
+00013570: 204e 7468 2070 6172 616d 6574 6572 2064   Nth parameter d
+00013580: 6566 696e 6564 2069 6e20 5b30 2c20 315d  efined in [0, 1]
+00013590: 0a0a 2020 2020 5265 7475 726e 730a 2020  ..    Returns.  
+000135a0: 2020 2d2d 2d2d 2d2d 2d0a 2020 2020 793a    -------.    y:
+000135b0: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
+000135c0: 7420 5b6e 5f67 7269 6420 7820 315d 0a20  t [n_grid x 1]. 
+000135d0: 2020 2020 2020 204f 7574 7075 740a 0a20         Output.. 
+000135e0: 2020 204e 6f74 6573 0a20 2020 202d 2d2d     Notes.    ---
+000135f0: 2d2d 0a20 2020 202e 2e20 706c 6f74 3a3a  --.    .. plot::
+00013600: 0a0a 2020 2020 2020 2069 6d70 6f72 7420  ..       import 
+00013610: 6e75 6d70 7920 6173 206e 700a 2020 2020  numpy as np.    
+00013620: 2020 2066 726f 6d20 7079 6770 632e 7465     from pygpc.te
+00013630: 7374 6675 6e63 7469 6f6e 7320 696d 706f  stfunctions impo
+00013640: 7274 2070 6c6f 745f 7465 7374 6675 6e63  rt plot_testfunc
+00013650: 7469 6f6e 2061 7320 706c 6f74 0a20 2020  tion as plot.   
+00013660: 2020 2020 6672 6f6d 2063 6f6c 6c65 6374      from collect
+00013670: 696f 6e73 2069 6d70 6f72 7420 4f72 6465  ions import Orde
+00013680: 7265 6444 6963 740a 0a20 2020 2020 2020  redDict..       
+00013690: 7061 7261 6d65 7465 7273 203d 204f 7264  parameters = Ord
+000136a0: 6572 6564 4469 6374 2829 0a20 2020 2020  eredDict().     
+000136b0: 2020 7061 7261 6d65 7465 7273 5b22 7831    parameters["x1
+000136c0: 225d 203d 206e 702e 6c69 6e73 7061 6365  "] = np.linspace
+000136d0: 2830 2c20 312c 2031 3030 290a 2020 2020  (0, 1, 100).    
+000136e0: 2020 2070 6172 616d 6574 6572 735b 2278     parameters["x
+000136f0: 3222 5d20 3d20 6e70 2e6c 696e 7370 6163  2"] = np.linspac
+00013700: 6528 302c 2031 2c20 3130 3029 0a0a 2020  e(0, 1, 100)..  
+00013710: 2020 2020 2070 6c6f 7428 2247 656e 7a4f       plot("GenzO
+00013720: 7363 696c 6c61 746f 7279 222c 2070 6172  scillatory", par
+00013730: 616d 6574 6572 7329 0a0a 2020 2020 2e2e  ameters)..    ..
+00013740: 205b 315d 2047 656e 7a2c 2041 2e20 2831   [1] Genz, A. (1
+00013750: 3938 3429 2c20 5465 7374 696e 6720 6d75  984), Testing mu
+00013760: 6c74 6964 696d 656e 7369 6f6e 616c 2069  ltidimensional i
+00013770: 6e74 6567 7261 7469 6f6e 2072 6f75 7469  ntegration routi
+00013780: 6e65 732e 0a20 2020 2020 2020 5072 6f63  nes..       Proc
+00013790: 2e20 6f66 2069 6e74 6572 6e61 7469 6f6e  . of internation
+000137a0: 616c 2063 6f6e 6665 7265 6e63 6520 6f6e  al conference on
+000137b0: 2054 6f6f 6c73 2c20 6d65 7468 6f64 7320   Tools, methods 
+000137c0: 616e 6420 6c61 6e67 7561 6765 7320 666f  and languages fo
+000137d0: 7220 7363 6965 6e74 6966 6963 0a20 2020  r scientific.   
+000137e0: 2020 2020 616e 6420 656e 6769 6e65 6572      and engineer
+000137f0: 696e 6720 636f 6d70 7574 6174 696f 6e2c  ing computation,
+00013800: 2045 6c73 6576 6965 7220 4e6f 7274 682d   Elsevier North-
+00013810: 486f 6c6c 616e 642c 2049 6e63 2e2c 204e  Holland, Inc., N
+00013820: 6577 596f 726b 2c20 4e59 2c20 5553 412c  ewYork, NY, USA,
+00013830: 2070 702e 2038 312d 3934 2e0a 0a20 2020   pp. 81-94...   
+00013840: 202e 2e20 5b32 5d20 6874 7470 733a 2f2f   .. [2] https://
+00013850: 7777 772e 7366 752e 6361 2f7e 7373 7572  www.sfu.ca/~ssur
+00013860: 6a61 6e6f 2f6f 7363 696c 2e68 746d 6c0a  jano/oscil.html.
+00013870: 2020 2020 2222 220a 0a20 2020 2064 6566      """..    def
+00013880: 205f 5f69 6e69 745f 5f28 7365 6c66 2c20   __init__(self, 
+00013890: 6d61 746c 6162 5f6d 6f64 656c 3d46 616c  matlab_model=Fal
+000138a0: 7365 293a 0a20 2020 2020 2020 2073 7570  se):.        sup
+000138b0: 6572 2874 7970 6528 7365 6c66 292c 2073  er(type(self), s
+000138c0: 656c 6629 2e5f 5f69 6e69 745f 5f28 6d61  elf).__init__(ma
+000138d0: 746c 6162 5f6d 6f64 656c 3d6d 6174 6c61  tlab_model=matla
+000138e0: 625f 6d6f 6465 6c29 0a20 2020 2020 2020  b_model).       
+000138f0: 2073 656c 662e 666e 616d 6520 3d20 696e   self.fname = in
+00013900: 7370 6563 742e 6765 7466 696c 6528 696e  spect.getfile(in
+00013910: 7370 6563 742e 6375 7272 656e 7466 7261  spect.currentfra
+00013920: 6d65 2829 290a 0a20 2020 2064 6566 2076  me())..    def v
+00013930: 616c 6964 6174 6528 7365 6c66 293a 0a20  alidate(self):. 
+00013940: 2020 2020 2020 2070 6173 730a 0a20 2020         pass..   
+00013950: 2064 6566 2073 696d 756c 6174 6528 7365   def simulate(se
+00013960: 6c66 2c20 7072 6f63 6573 735f 6964 3d4e  lf, process_id=N
+00013970: 6f6e 652c 206d 6174 6c61 625f 656e 6769  one, matlab_engi
+00013980: 6e65 3d4e 6f6e 6529 3a0a 2020 2020 2020  ne=None):.      
+00013990: 2020 6e20 3d20 6c65 6e28 7365 6c66 2e70    n = len(self.p
+000139a0: 2e6b 6579 7328 2929 0a0a 2020 2020 2020  .keys())..      
+000139b0: 2020 2320 7365 7420 636f 6e73 7461 6e74    # set constant
+000139c0: 730a 2020 2020 2020 2020 7520 3d20 302e  s.        u = 0.
+000139d0: 3520 2a20 6e70 2e6f 6e65 7328 6e29 0a20  5 * np.ones(n). 
+000139e0: 2020 2020 2020 2061 203d 2035 202a 206e         a = 5 * n
+000139f0: 702e 6f6e 6573 286e 290a 0a20 2020 2020  p.ones(n)..     
+00013a00: 2020 2023 2064 6574 6572 6d69 6e65 2073     # determine s
+00013a10: 756d 0a20 2020 2020 2020 2073 203d 206e  um.        s = n
+00013a20: 702e 7a65 726f 7328 6e70 2e61 7272 6179  p.zeros(np.array
+00013a30: 2873 656c 662e 705b 6c69 7374 2873 656c  (self.p[list(sel
+00013a40: 662e 702e 6b65 7973 2829 295b 305d 5d29  f.p.keys())[0]])
+00013a50: 2e73 697a 6529 0a0a 2020 2020 2020 2020  .size)..        
+00013a60: 666f 7220 692c 206b 6579 2069 6e20 656e  for i, key in en
+00013a70: 756d 6572 6174 6528 7365 6c66 2e70 2e6b  umerate(self.p.k
+00013a80: 6579 7328 2929 3a0a 2020 2020 2020 2020  eys()):.        
+00013a90: 2020 2020 7320 2b3d 2061 5b69 5d20 2a20      s += a[i] * 
+00013aa0: 7365 6c66 2e70 5b6b 6579 5d0a 0a20 2020  self.p[key]..   
+00013ab0: 2020 2020 2023 2064 6574 6572 6d69 6e65       # determine
+00013ac0: 206f 7574 7075 740a 2020 2020 2020 2020   output.        
+00013ad0: 7920 3d20 6e70 2e63 6f73 2832 202a 206e  y = np.cos(2 * n
+00013ae0: 702e 7069 202a 2075 5b30 5d20 2b20 7329  p.pi * u[0] + s)
+00013af0: 0a0a 2020 2020 2020 2020 795f 6f75 7420  ..        y_out 
+00013b00: 3d20 795b 3a2c 206e 702e 6e65 7761 7869  = y[:, np.newaxi
+00013b10: 735d 0a0a 2020 2020 2020 2020 2320 696e  s]..        # in
+00013b20: 7365 7274 2073 6f6d 6520 4e61 4e20 7661  sert some NaN va
+00013b30: 6c75 6573 2066 6f72 2074 6573 7469 6e67  lues for testing
+00013b40: 0a20 2020 2020 2020 206d 6173 6b20 3d20  .        mask = 
+00013b50: 7365 6c66 2e70 5b6c 6973 7428 7365 6c66  self.p[list(self
+00013b60: 2e70 2e6b 6579 7328 2929 5b30 5d5d 203e  .p.keys())[0]] >
+00013b70: 2030 2e38 0a20 2020 2020 2020 2079 5f6f   0.8.        y_o
+00013b80: 7574 5b6d 6173 6b2c 2030 5d20 3d20 6e70  ut[mask, 0] = np
+00013b90: 2e4e 614e 0a0a 2020 2020 2020 2020 7265  .NaN..        re
+00013ba0: 7475 726e 2079 5f6f 7574 0a0a 0a63 6c61  turn y_out...cla
+00013bb0: 7373 2047 656e 7a50 726f 6475 6374 5065  ss GenzProductPe
+00013bc0: 616b 2841 6273 7472 6163 744d 6f64 656c  ak(AbstractModel
+00013bd0: 293a 0a20 2020 2022 2222 0a20 2020 204e  ):.    """.    N
+00013be0: 2d64 696d 656e 7369 6f6e 616c 2022 5072  -dimensional "Pr
+00013bf0: 6f64 7563 7450 6561 6b22 2047 656e 7a20  oductPeak" Genz 
+00013c00: 6675 6e63 7469 6f6e 205b 315d 2e20 4974  function [1]. It
+00013c10: 2069 7320 6465 6669 6e65 6420 696e 2074   is defined in t
+00013c20: 6865 2069 6e74 6572 7661 6c20 5b30 2c20  he interval [0, 
+00013c30: 315d 2078 202e 2e2e 2078 205b 302c 2031  1] x ... x [0, 1
+00013c40: 5d2e 0a0a 2020 2020 2e2e 206d 6174 683a  ]...    .. math:
+00013c50: 3a20 7920 3d20 5c70 726f 645f 7b69 3d31  : y = \prod_{i=1
+00013c60: 7d5e 7b4e 7d20 5c5c 6c65 6674 2820 615f  }^{N} \\left( a_
+00013c70: 695e 7b2d 327d 202b 2028 785f 6920 2d20  i^{-2} + (x_i - 
+00013c80: 755f 6929 5e32 205c 5c72 6967 6874 295e  u_i)^2 \\right)^
+00013c90: 7b2d 317d 0a0a 2020 2020 5061 7261 6d65  {-1}..    Parame
+00013ca0: 7465 7273 0a20 2020 202d 2d2d 2d2d 2d2d  ters.    -------
+00013cb0: 2d2d 2d0a 2020 2020 705b 2278 3122 5d3a  ---.    p["x1"]:
+00013cc0: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
+00013cd0: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
+00013ce0: 6964 5d0a 2020 2020 2020 2020 4669 7273  id].        Firs
+00013cf0: 7420 7061 7261 6d65 7465 7220 6465 6669  t parameter defi
+00013d00: 6e65 6420 696e 205b 302c 2031 5d0a 2020  ned in [0, 1].  
+00013d10: 2020 705b 2278 6922 5d3a 2066 6c6f 6174    p["xi"]: float
+00013d20: 206f 7220 6e64 6172 7261 7920 6f66 2066   or ndarray of f
+00013d30: 6c6f 6174 205b 6e5f 6772 6964 5d0a 2020  loat [n_grid].  
+00013d40: 2020 2020 2020 692d 7468 2070 6172 616d        i-th param
+00013d50: 6574 6572 2064 6566 696e 6564 2069 6e20  eter defined in 
+00013d60: 5b30 2c20 315d 0a20 2020 2070 5b22 784e  [0, 1].    p["xN
+00013d70: 225d 3a20 666c 6f61 7420 6f72 206e 6461  "]: float or nda
+00013d80: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
+00013d90: 5f67 7269 645d 0a20 2020 2020 2020 204e  _grid].        N
+00013da0: 7468 2070 6172 616d 6574 6572 2064 6566  th parameter def
+00013db0: 696e 6564 2069 6e20 5b30 2c20 315d 0a0a  ined in [0, 1]..
+00013dc0: 2020 2020 5265 7475 726e 730a 2020 2020      Returns.    
+00013dd0: 2d2d 2d2d 2d2d 2d0a 2020 2020 793a 206e  -------.    y: n
+00013de0: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+00013df0: 5b6e 5f67 7269 6420 7820 315d 0a20 2020  [n_grid x 1].   
+00013e00: 2020 2020 204f 7574 7075 740a 0a20 2020       Output..   
+00013e10: 204e 6f74 6573 0a20 2020 202d 2d2d 2d2d   Notes.    -----
+00013e20: 0a20 2020 202e 2e20 706c 6f74 3a3a 0a0a  .    .. plot::..
+00013e30: 2020 2020 2020 2069 6d70 6f72 7420 6e75         import nu
+00013e40: 6d70 7920 6173 206e 700a 2020 2020 2020  mpy as np.      
+00013e50: 2066 726f 6d20 7079 6770 632e 7465 7374   from pygpc.test
+00013e60: 6675 6e63 7469 6f6e 7320 696d 706f 7274  functions import
+00013e70: 2070 6c6f 745f 7465 7374 6675 6e63 7469   plot_testfuncti
+00013e80: 6f6e 2061 7320 706c 6f74 0a20 2020 2020  on as plot.     
+00013e90: 2020 6672 6f6d 2063 6f6c 6c65 6374 696f    from collectio
+00013ea0: 6e73 2069 6d70 6f72 7420 4f72 6465 7265  ns import Ordere
+00013eb0: 6444 6963 740a 0a20 2020 2020 2020 7061  dDict..       pa
+00013ec0: 7261 6d65 7465 7273 203d 204f 7264 6572  rameters = Order
+00013ed0: 6564 4469 6374 2829 0a20 2020 2020 2020  edDict().       
+00013ee0: 7061 7261 6d65 7465 7273 5b22 7831 225d  parameters["x1"]
+00013ef0: 203d 206e 702e 6c69 6e73 7061 6365 2830   = np.linspace(0
+00013f00: 2c20 312c 2031 3030 290a 2020 2020 2020  , 1, 100).      
+00013f10: 2070 6172 616d 6574 6572 735b 2278 3222   parameters["x2"
+00013f20: 5d20 3d20 6e70 2e6c 696e 7370 6163 6528  ] = np.linspace(
+00013f30: 302c 2031 2c20 3130 3029 0a0a 2020 2020  0, 1, 100)..    
+00013f40: 2020 2070 6c6f 7428 2247 656e 7a50 726f     plot("GenzPro
+00013f50: 6475 6374 5065 616b 222c 2070 6172 616d  ductPeak", param
+00013f60: 6574 6572 7329 0a0a 2020 2020 2e2e 205b  eters)..    .. [
+00013f70: 315d 2047 656e 7a2c 2041 2e20 2831 3938  1] Genz, A. (198
+00013f80: 3429 2c20 5465 7374 696e 6720 6d75 6c74  4), Testing mult
+00013f90: 6964 696d 656e 7369 6f6e 616c 2069 6e74  idimensional int
+00013fa0: 6567 7261 7469 6f6e 2072 6f75 7469 6e65  egration routine
+00013fb0: 732e 0a20 2020 2020 2020 5072 6f63 2e20  s..       Proc. 
+00013fc0: 6f66 2069 6e74 6572 6e61 7469 6f6e 616c  of international
+00013fd0: 2063 6f6e 6665 7265 6e63 6520 6f6e 2054   conference on T
+00013fe0: 6f6f 6c73 2c20 6d65 7468 6f64 7320 616e  ools, methods an
+00013ff0: 6420 6c61 6e67 7561 6765 7320 666f 7220  d languages for 
+00014000: 7363 6965 6e74 6966 6963 0a20 2020 2020  scientific.     
+00014010: 2020 616e 6420 656e 6769 6e65 6572 696e    and engineerin
+00014020: 6720 636f 6d70 7574 6174 696f 6e2c 2045  g computation, E
+00014030: 6c73 6576 6965 7220 4e6f 7274 682d 486f  lsevier North-Ho
+00014040: 6c6c 616e 642c 2049 6e63 2e2c 204e 6577  lland, Inc., New
+00014050: 596f 726b 2c20 4e59 2c20 5553 412c 2070  York, NY, USA, p
+00014060: 702e 2038 312d 3934 2e0a 0a20 2020 202e  p. 81-94...    .
+00014070: 2e20 5b32 5d20 6874 7470 733a 2f2f 7777  . [2] https://ww
+00014080: 772e 7366 752e 6361 2f7e 7373 7572 6a61  w.sfu.ca/~ssurja
+00014090: 6e6f 2f70 7270 6561 6b2e 6874 6d6c 0a20  no/prpeak.html. 
+000140a0: 2020 2022 2222 0a0a 2020 2020 6465 6620     """..    def 
+000140b0: 5f5f 696e 6974 5f5f 2873 656c 662c 206d  __init__(self, m
+000140c0: 6174 6c61 625f 6d6f 6465 6c3d 4661 6c73  atlab_model=Fals
+000140d0: 6529 3a0a 2020 2020 2020 2020 7375 7065  e):.        supe
+000140e0: 7228 7479 7065 2873 656c 6629 2c20 7365  r(type(self), se
+000140f0: 6c66 292e 5f5f 696e 6974 5f5f 286d 6174  lf).__init__(mat
+00014100: 6c61 625f 6d6f 6465 6c3d 6d61 746c 6162  lab_model=matlab
+00014110: 5f6d 6f64 656c 290a 2020 2020 2020 2020  _model).        
+00014120: 7365 6c66 2e66 6e61 6d65 203d 2069 6e73  self.fname = ins
+00014130: 7065 6374 2e67 6574 6669 6c65 2869 6e73  pect.getfile(ins
+00014140: 7065 6374 2e63 7572 7265 6e74 6672 616d  pect.currentfram
+00014150: 6528 2929 0a0a 2020 2020 6465 6620 7661  e())..    def va
+00014160: 6c69 6461 7465 2873 656c 6629 3a0a 2020  lidate(self):.  
+00014170: 2020 2020 2020 7061 7373 0a0a 2020 2020        pass..    
+00014180: 6465 6620 7369 6d75 6c61 7465 2873 656c  def simulate(sel
+00014190: 662c 2070 726f 6365 7373 5f69 643d 4e6f  f, process_id=No
+000141a0: 6e65 2c20 6d61 746c 6162 5f65 6e67 696e  ne, matlab_engin
+000141b0: 653d 4e6f 6e65 293a 0a20 2020 2020 2020  e=None):.       
+000141c0: 206e 203d 206c 656e 2873 656c 662e 702e   n = len(self.p.
+000141d0: 6b65 7973 2829 290a 0a20 2020 2020 2020  keys())..       
+000141e0: 2023 2073 6574 2063 6f6e 7374 616e 7473   # set constants
+000141f0: 0a20 2020 2020 2020 2075 203d 2030 2e35  .        u = 0.5
+00014200: 202a 206e 702e 6f6e 6573 286e 290a 2020   * np.ones(n).  
+00014210: 2020 2020 2020 6120 3d20 3520 2a20 6e70        a = 5 * np
+00014220: 2e6f 6e65 7328 6e29 0a0a 2020 2020 2020  .ones(n)..      
+00014230: 2020 2320 6465 7465 726d 696e 6520 6f75    # determine ou
+00014240: 7470 7574 0a20 2020 2020 2020 2079 203d  tput.        y =
+00014250: 206e 702e 6f6e 6573 286e 702e 6172 7261   np.ones(np.arra
+00014260: 7928 7365 6c66 2e70 5b6c 6973 7428 7365  y(self.p[list(se
+00014270: 6c66 2e70 2e6b 6579 7328 2929 5b30 5d5d  lf.p.keys())[0]]
+00014280: 292e 7369 7a65 290a 0a20 2020 2020 2020  ).size)..       
+00014290: 2066 6f72 2069 2c20 6b65 7920 696e 2065   for i, key in e
+000142a0: 6e75 6d65 7261 7465 2873 656c 662e 702e  numerate(self.p.
+000142b0: 6b65 7973 2829 293a 0a20 2020 2020 2020  keys()):.       
+000142c0: 2020 2020 2079 202a 3d20 3120 2f20 2861       y *= 1 / (a
+000142d0: 5b69 5d20 2a2a 2028 2d32 2920 2b20 2873  [i] ** (-2) + (s
+000142e0: 656c 662e 705b 6b65 795d 202d 2075 5b69  elf.p[key] - u[i
+000142f0: 5d29 202a 2a20 3229 0a0a 2020 2020 2020  ]) ** 2)..      
+00014300: 2020 795f 6f75 7420 3d20 795b 3a2c 206e    y_out = y[:, n
+00014310: 702e 6e65 7761 7869 735d 0a0a 2020 2020  p.newaxis]..    
+00014320: 2020 2020 7265 7475 726e 2079 5f6f 7574      return y_out
+00014330: 0a0a 0a63 6c61 7373 2052 6964 6765 2841  ...class Ridge(A
+00014340: 6273 7472 6163 744d 6f64 656c 293a 0a20  bstractModel):. 
+00014350: 2020 2022 2222 0a20 2020 204e 2d64 696d     """.    N-dim
+00014360: 656e 7369 6f6e 616c 2022 5269 6467 6522  ensional "Ridge"
+00014370: 2066 756e 6374 696f 6e20 5b31 5d20 2861   function [1] (a
+00014380: 6e64 2061 6c73 6f20 7573 6564 2061 7320  nd also used as 
+00014390: 7465 7374 6675 6e63 7469 6f6e 2074 6865  testfunction the
+000143a0: 7265 696e 292e 0a20 2020 2054 7970 6963  rein)..    Typic
+000143b0: 616c 6c79 2064 6566 696e 6564 2069 6e20  ally defined in 
+000143c0: 7468 6520 696e 7465 7276 616c 205b 2d34  the interval [-4
+000143d0: 2c20 345d 2078 202e 2e2e 2078 205b 2d34  , 4] x ... x [-4
+000143e0: 2c20 345d 2e0a 0a20 2020 202e 2e20 6d61  , 4]...    .. ma
+000143f0: 7468 3a3a 0a20 2020 2020 2020 7920 3d20  th::.       y = 
+00014400: 5c73 756d 5f7b 693d 317d 5e7b 4e7d 785f  \sum_{i=1}^{N}x_
+00014410: 6920 2b20 302e 3235 205c 5c6c 6566 7428  i + 0.25 \\left(
+00014420: 205c 7375 6d5f 7b69 3d31 7d5e 7b4e 7d78   \sum_{i=1}^{N}x
+00014430: 5f69 205c 5c72 6967 6874 295e 3220 2b20  _i \\right)^2 + 
+00014440: 302e 3032 3520 5c5c 6c65 6674 2820 5c73  0.025 \\left( \s
+00014450: 756d 5f7b 693d 317d 5e7b 4e7d 785f 6920  um_{i=1}^{N}x_i 
+00014460: 5c5c 7269 6768 7429 5e33 0a0a 2020 2020  \\right)^3..    
+00014470: 5061 7261 6d65 7465 7273 0a20 2020 202d  Parameters.    -
+00014480: 2d2d 2d2d 2d2d 2d2d 2d0a 2020 2020 705b  ---------.    p[
+00014490: 2278 3122 5d3a 2066 6c6f 6174 206f 7220  "x1"]: float or 
+000144a0: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
+000144b0: 205b 6e5f 6772 6964 5d0a 2020 2020 2020   [n_grid].      
+000144c0: 2020 4669 7273 7420 7061 7261 6d65 7465    First paramete
+000144d0: 7220 6465 6669 6e65 6420 696e 2065 2e67  r defined in e.g
+000144e0: 2e20 5b2d 342c 2034 5d0a 2020 2020 705b  . [-4, 4].    p[
+000144f0: 2278 6922 5d3a 2066 6c6f 6174 206f 7220  "xi"]: float or 
+00014500: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
+00014510: 205b 6e5f 6772 6964 5d0a 2020 2020 2020   [n_grid].      
+00014520: 2020 692d 7468 2070 6172 616d 6574 6572    i-th parameter
+00014530: 2064 6566 696e 6564 2069 6e20 652e 672e   defined in e.g.
+00014540: 205b 2d34 2c20 345d 0a20 2020 2070 5b22   [-4, 4].    p["
+00014550: 784e 225d 3a20 666c 6f61 7420 6f72 206e  xN"]: float or n
+00014560: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+00014570: 5b6e 5f67 7269 645d 0a20 2020 2020 2020  [n_grid].       
+00014580: 204e 7468 2070 6172 616d 6574 6572 2064   Nth parameter d
+00014590: 6566 696e 6564 2069 6e20 652e 672e 205b  efined in e.g. [
+000145a0: 2d34 2c20 345d 0a0a 2020 2020 5265 7475  -4, 4]..    Retu
+000145b0: 726e 730a 2020 2020 2d2d 2d2d 2d2d 2d0a  rns.    -------.
+000145c0: 2020 2020 793a 206e 6461 7272 6179 206f      y: ndarray o
+000145d0: 6620 666c 6f61 7420 5b6e 5f67 7269 6420  f float [n_grid 
+000145e0: 7820 315d 0a20 2020 2020 2020 204f 7574  x 1].        Out
+000145f0: 7075 740a 0a20 2020 204e 6f74 6573 0a20  put..    Notes. 
+00014600: 2020 202d 2d2d 2d2d 0a20 2020 202e 2e20     -----.    .. 
+00014610: 706c 6f74 3a3a 0a0a 2020 2020 2020 2069  plot::..       i
+00014620: 6d70 6f72 7420 6e75 6d70 7920 6173 206e  mport numpy as n
+00014630: 700a 2020 2020 2020 2066 726f 6d20 7079  p.       from py
+00014640: 6770 632e 7465 7374 6675 6e63 7469 6f6e  gpc.testfunction
+00014650: 7320 696d 706f 7274 2070 6c6f 745f 7465  s import plot_te
+00014660: 7374 6675 6e63 7469 6f6e 2061 7320 706c  stfunction as pl
+00014670: 6f74 0a20 2020 2020 2020 6672 6f6d 2063  ot.       from c
+00014680: 6f6c 6c65 6374 696f 6e73 2069 6d70 6f72  ollections impor
+00014690: 7420 4f72 6465 7265 6444 6963 740a 0a20  t OrderedDict.. 
+000146a0: 2020 2020 2020 7061 7261 6d65 7465 7273        parameters
+000146b0: 203d 204f 7264 6572 6564 4469 6374 2829   = OrderedDict()
+000146c0: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
+000146d0: 7273 5b22 7831 225d 203d 206e 702e 6c69  rs["x1"] = np.li
+000146e0: 6e73 7061 6365 282d 342c 2034 2c20 3130  nspace(-4, 4, 10
+000146f0: 3029 0a20 2020 2020 2020 7061 7261 6d65  0).       parame
+00014700: 7465 7273 5b22 7832 225d 203d 206e 702e  ters["x2"] = np.
+00014710: 6c69 6e73 7061 6365 282d 342c 2034 2c20  linspace(-4, 4, 
+00014720: 3130 3029 0a0a 2020 2020 2020 2070 6c6f  100)..       plo
+00014730: 7428 2252 6964 6765 222c 2070 6172 616d  t("Ridge", param
+00014740: 6574 6572 7329 0a0a 2020 2020 2e2e 205b  eters)..    .. [
+00014750: 315d 2054 7369 6c69 6669 732c 2050 2e2c  1] Tsilifis, P.,
+00014760: 2048 7561 6e2c 2058 2e2c 2053 6166 7461   Huan, X., Safta
+00014770: 2c20 432e 2c20 5361 7267 7379 616e 2c20  , C., Sargsyan, 
+00014780: 4b2e 2c20 4c61 6361 7a65 2c20 472e 2c20  K., Lacaze, G., 
+00014790: 4f65 6665 6c65 696e 2c20 4a2e 2043 2e2c  Oefelein, J. C.,
+000147a0: 204e 616a 6d2c 2048 2e20 4e2e 2c20 4768   Najm, H. N., Gh
+000147b0: 616e 656d 2c20 522e 2047 2e0a 2020 2020  anem, R. G..    
+000147c0: 2020 2028 3230 3139 292e 2043 6f6d 7072     (2019). Compr
+000147d0: 6573 7369 7665 2073 656e 7369 6e67 2061  essive sensing a
+000147e0: 6461 7074 6174 696f 6e20 666f 7220 706f  daptation for po
+000147f0: 6c79 6e6f 6d69 616c 2063 6861 6f73 2065  lynomial chaos e
+00014800: 7870 616e 7369 6f6e 732e 0a20 2020 2020  xpansions..     
+00014810: 2020 4a6f 7572 6e61 6c20 6f66 2043 6f6d    Journal of Com
+00014820: 7075 7461 7469 6f6e 616c 2050 6879 7369  putational Physi
+00014830: 6373 2c20 3338 302c 2032 392d 3437 2e0a  cs, 380, 29-47..
+00014840: 2020 2020 2222 220a 0a20 2020 2064 6566      """..    def
+00014850: 205f 5f69 6e69 745f 5f28 7365 6c66 2c20   __init__(self, 
+00014860: 6d61 746c 6162 5f6d 6f64 656c 3d46 616c  matlab_model=Fal
+00014870: 7365 293a 0a20 2020 2020 2020 2073 7570  se):.        sup
+00014880: 6572 2874 7970 6528 7365 6c66 292c 2073  er(type(self), s
+00014890: 656c 6629 2e5f 5f69 6e69 745f 5f28 6d61  elf).__init__(ma
+000148a0: 746c 6162 5f6d 6f64 656c 3d6d 6174 6c61  tlab_model=matla
+000148b0: 625f 6d6f 6465 6c29 0a20 2020 2020 2020  b_model).       
+000148c0: 2073 656c 662e 666e 616d 6520 3d20 696e   self.fname = in
+000148d0: 7370 6563 742e 6765 7466 696c 6528 696e  spect.getfile(in
+000148e0: 7370 6563 742e 6375 7272 656e 7466 7261  spect.currentfra
+000148f0: 6d65 2829 290a 0a20 2020 2064 6566 2076  me())..    def v
+00014900: 616c 6964 6174 6528 7365 6c66 293a 0a20  alidate(self):. 
+00014910: 2020 2020 2020 2070 6173 730a 0a20 2020         pass..   
+00014920: 2064 6566 2073 696d 756c 6174 6528 7365   def simulate(se
+00014930: 6c66 2c20 7072 6f63 6573 735f 6964 3d4e  lf, process_id=N
+00014940: 6f6e 652c 206d 6174 6c61 625f 656e 6769  one, matlab_engi
+00014950: 6e65 3d4e 6f6e 6529 3a0a 2020 2020 2020  ne=None):.      
+00014960: 2020 6e20 3d20 6c65 6e28 7365 6c66 2e70    n = len(self.p
+00014970: 2e6b 6579 7328 2929 0a0a 2020 2020 2020  .keys())..      
+00014980: 2020 2320 6465 7465 726d 696e 6520 7375    # determine su
+00014990: 6d0a 2020 2020 2020 2020 7320 3d20 6e70  m.        s = np
+000149a0: 2e7a 6572 6f73 286e 702e 6172 7261 7928  .zeros(np.array(
+000149b0: 7365 6c66 2e70 5b6c 6973 7428 7365 6c66  self.p[list(self
+000149c0: 2e70 2e6b 6579 7328 2929 5b30 5d5d 292e  .p.keys())[0]]).
+000149d0: 7369 7a65 290a 0a20 2020 2020 2020 2066  size)..        f
+000149e0: 6f72 2069 2c20 6b65 7920 696e 2065 6e75  or i, key in enu
+000149f0: 6d65 7261 7465 2873 656c 662e 702e 6b65  merate(self.p.ke
+00014a00: 7973 2829 293a 0a20 2020 2020 2020 2020  ys()):.         
+00014a10: 2020 2073 202b 3d20 7365 6c66 2e70 5b6b     s += self.p[k
+00014a20: 6579 5d0a 0a20 2020 2020 2020 2023 2064  ey]..        # d
+00014a30: 6574 6572 6d69 6e65 206f 7574 7075 740a  etermine output.
+00014a40: 2020 2020 2020 2020 7920 3d20 7320 2b20          y = s + 
+00014a50: 302e 3235 202a 2073 2a2a 3220 2b20 302e  0.25 * s**2 + 0.
+00014a60: 3032 3520 2a20 732a 2a33 0a0a 2020 2020  025 * s**3..    
+00014a70: 2020 2020 795f 6f75 7420 3d20 795b 3a2c      y_out = y[:,
+00014a80: 206e 702e 6e65 7761 7869 735d 0a0a 2020   np.newaxis]..  
+00014a90: 2020 2020 2020 7265 7475 726e 2079 5f6f        return y_o
+00014aa0: 7574 0a0a 0a63 6c61 7373 204c 696d 3230  ut...class Lim20
+00014ab0: 3032 2841 6273 7472 6163 744d 6f64 656c  02(AbstractModel
+00014ac0: 293a 0a20 2020 2022 2222 0a20 2020 2054  ):.    """.    T
+00014ad0: 776f 2d64 696d 656e 7369 6f6e 616c 2074  wo-dimensional t
+00014ae0: 6573 7420 6675 6e63 7469 6f6e 206f 6620  est function of 
+00014af0: 4c69 6d20 6574 2061 6c2e 2028 3230 3032  Lim et al. (2002
+00014b00: 2920 5b31 5d20 2865 712e 2028 3237 2929  ) [1] (eq. (27))
+00014b10: 2e0a 0a20 2020 2054 6869 7320 6675 6e63  ...    This func
+00014b20: 7469 6f6e 2069 7320 6120 706f 6c79 6e6f  tion is a polyno
+00014b30: 6d69 616c 2069 6e20 7477 6f20 6469 6d65  mial in two dime
+00014b40: 6e73 696f 6e73 2c20 7769 7468 2074 6572  nsions, with ter
+00014b50: 6d73 2075 7020 746f 2064 6567 7265 650a  ms up to degree.
+00014b60: 2020 2020 352e 2049 7420 6973 206e 6f6e      5. It is non
+00014b70: 6c69 6e65 6172 2c20 616e 6420 6974 2069  linear, and it i
+00014b80: 7320 736d 6f6f 7468 2064 6573 7069 7465  s smooth despite
+00014b90: 2062 6569 6e67 2063 6f6d 706c 6578 2c20   being complex, 
+00014ba0: 7768 6963 6820 6973 0a20 2020 2063 6f6d  which is.    com
+00014bb0: 6d6f 6e20 666f 7220 636f 6d70 7574 6572  mon for computer
+00014bc0: 2065 7870 6572 696d 656e 7420 6675 6e63   experiment func
+00014bd0: 7469 6f6e 732e 0a0a 2020 2020 2e2e 206d  tions...    .. m
+00014be0: 6174 683a 3a0a 2020 2020 2020 2079 203d  ath::.       y =
+00014bf0: 2039 202b 205c 5c66 7261 637b 357d 7b32   9 + \\frac{5}{2
+00014c00: 7d20 785f 3120 2d20 5c5c 6672 6163 7b33  } x_1 - \\frac{3
+00014c10: 357d 7b32 7d20 785f 3220 2b20 5c5c 6672  5}{2} x_2 + \\fr
+00014c20: 6163 7b35 7d7b 327d 2078 5f31 2078 5f32  ac{5}{2} x_1 x_2
+00014c30: 202b 2031 3920 785f 325e 3220 2d0a 2020   + 19 x_2^2 -.  
+00014c40: 2020 2020 205c 5c66 7261 637b 3135 7d7b       \\frac{15}{
+00014c50: 327d 2078 5f31 5e33 202d 205c 5c66 7261  2} x_1^3 - \\fra
+00014c60: 637b 357d 7b32 7d20 785f 3120 785f 325e  c{5}{2} x_1 x_2^
+00014c70: 3220 2d20 5c5c 6672 6163 7b31 317d 7b32  2 - \\frac{11}{2
+00014c80: 7d20 785f 325e 3420 2b20 785f 315e 3320  } x_2^4 + x_1^3 
+00014c90: 785f 325e 320a 0a20 2020 2050 6172 616d  x_2^2..    Param
+00014ca0: 6574 6572 730a 2020 2020 2d2d 2d2d 2d2d  eters.    ------
+00014cb0: 2d2d 2d2d 0a20 2020 2070 5b22 7831 225d  ----.    p["x1"]
+00014cc0: 3a20 666c 6f61 7420 6f72 206e 6461 7272  : float or ndarr
+00014cd0: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
+00014ce0: 7269 645d 0a20 2020 2020 2020 2046 6972  rid].        Fir
+00014cf0: 7374 2070 6172 616d 6574 6572 2064 6566  st parameter def
+00014d00: 696e 6564 2069 6e20 5b30 2c20 315d 0a20  ined in [0, 1]. 
+00014d10: 2020 2070 5b22 7832 225d 3a20 666c 6f61     p["x2"]: floa
+00014d20: 7420 6f72 206e 6461 7272 6179 206f 6620  t or ndarray of 
+00014d30: 666c 6f61 7420 5b6e 5f67 7269 645d 0a20  float [n_grid]. 
+00014d40: 2020 2020 2020 2053 6563 6f6e 6420 7061         Second pa
+00014d50: 7261 6d65 7465 7220 6465 6669 6e65 6420  rameter defined 
+00014d60: 696e 205b 302c 2031 5d0a 0a20 2020 2052  in [0, 1]..    R
+00014d70: 6574 7572 6e73 0a20 2020 202d 2d2d 2d2d  eturns.    -----
+00014d80: 2d2d 0a20 2020 2079 3a20 6e64 6172 7261  --.    y: ndarra
+00014d90: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
+00014da0: 6964 2078 2031 5d0a 2020 2020 2020 2020  id x 1].        
+00014db0: 4f75 7470 7574 2064 6174 610a 0a20 2020  Output data..   
+00014dc0: 204e 6f74 6573 0a20 2020 202d 2d2d 2d2d   Notes.    -----
+00014dd0: 0a20 2020 202e 2e20 706c 6f74 3a3a 0a0a  .    .. plot::..
+00014de0: 2020 2020 2020 2069 6d70 6f72 7420 6e75         import nu
+00014df0: 6d70 7920 6173 206e 700a 2020 2020 2020  mpy as np.      
+00014e00: 2066 726f 6d20 7079 6770 632e 7465 7374   from pygpc.test
+00014e10: 6675 6e63 7469 6f6e 7320 696d 706f 7274  functions import
+00014e20: 2070 6c6f 745f 7465 7374 6675 6e63 7469   plot_testfuncti
+00014e30: 6f6e 2061 7320 706c 6f74 0a20 2020 2020  on as plot.     
+00014e40: 2020 6672 6f6d 2063 6f6c 6c65 6374 696f    from collectio
+00014e50: 6e73 2069 6d70 6f72 7420 4f72 6465 7265  ns import Ordere
+00014e60: 6444 6963 740a 0a20 2020 2020 2020 7061  dDict..       pa
+00014e70: 7261 6d65 7465 7273 203d 204f 7264 6572  rameters = Order
+00014e80: 6564 4469 6374 2829 0a20 2020 2020 2020  edDict().       
+00014e90: 7061 7261 6d65 7465 7273 5b22 7831 225d  parameters["x1"]
+00014ea0: 203d 206e 702e 6c69 6e73 7061 6365 2830   = np.linspace(0
+00014eb0: 2c20 312c 2031 3030 290a 2020 2020 2020  , 1, 100).      
+00014ec0: 2070 6172 616d 6574 6572 735b 2278 3222   parameters["x2"
+00014ed0: 5d20 3d20 6e70 2e6c 696e 7370 6163 6528  ] = np.linspace(
+00014ee0: 302c 2031 2c20 3130 3029 0a0a 2020 2020  0, 1, 100)..    
+00014ef0: 2020 2070 6c6f 7428 224c 696d 3230 3032     plot("Lim2002
+00014f00: 222c 2070 6172 616d 6574 6572 7329 0a0a  ", parameters)..
+00014f10: 2020 2020 2e2e 205b 315d 204c 696d 2c20      .. [1] Lim, 
+00014f20: 592e 2042 2e2c 2053 6163 6b73 2c20 4a2e  Y. B., Sacks, J.
+00014f30: 2c20 5374 7564 6465 6e2c 2057 2e20 4a2e  , Studden, W. J.
+00014f40: 2c20 2620 5765 6c63 682c 2057 2e20 4a2e  , & Welch, W. J.
+00014f50: 2028 3230 3032 292e 2044 6573 6967 6e0a   (2002). Design.
+00014f60: 2020 2020 2020 2061 6e64 2061 6e61 6c79         and analy
+00014f70: 7369 7320 6f66 2063 6f6d 7075 7465 7220  sis of computer 
+00014f80: 6578 7065 7269 6d65 6e74 7320 7768 656e  experiments when
+00014f90: 2074 6865 206f 7574 7075 7420 6973 2068   the output is h
+00014fa0: 6967 686c 7920 636f 7272 656c 6174 6564  ighly correlated
+00014fb0: 0a20 2020 2020 2020 6f76 6572 2074 6865  .       over the
+00014fc0: 2069 6e70 7574 2073 7061 6365 2e20 4361   input space. Ca
+00014fd0: 6e61 6469 616e 204a 6f75 726e 616c 206f  nadian Journal o
+00014fe0: 6620 5374 6174 6973 7469 6373 2c20 3330  f Statistics, 30
+00014ff0: 2831 292c 2031 3039 2d31 3236 2e0a 2020  (1), 109-126..  
+00015000: 2020 2222 220a 0a20 2020 2064 6566 205f    """..    def _
+00015010: 5f69 6e69 745f 5f28 7365 6c66 2c20 6d61  _init__(self, ma
+00015020: 746c 6162 5f6d 6f64 656c 3d46 616c 7365  tlab_model=False
+00015030: 293a 0a20 2020 2020 2020 2073 7570 6572  ):.        super
+00015040: 2874 7970 6528 7365 6c66 292c 2073 656c  (type(self), sel
+00015050: 6629 2e5f 5f69 6e69 745f 5f28 6d61 746c  f).__init__(matl
+00015060: 6162 5f6d 6f64 656c 3d6d 6174 6c61 625f  ab_model=matlab_
+00015070: 6d6f 6465 6c29 0a20 2020 2020 2020 2073  model).        s
+00015080: 656c 662e 666e 616d 6520 3d20 696e 7370  elf.fname = insp
+00015090: 6563 742e 6765 7466 696c 6528 696e 7370  ect.getfile(insp
+000150a0: 6563 742e 6375 7272 656e 7466 7261 6d65  ect.currentframe
+000150b0: 2829 290a 0a20 2020 2064 6566 2076 616c  ())..    def val
+000150c0: 6964 6174 6528 7365 6c66 293a 0a20 2020  idate(self):.   
+000150d0: 2020 2020 2070 6173 730a 0a20 2020 2064       pass..    d
+000150e0: 6566 2073 696d 756c 6174 6528 7365 6c66  ef simulate(self
+000150f0: 2c20 7072 6f63 6573 735f 6964 3d4e 6f6e  , process_id=Non
+00015100: 652c 206d 6174 6c61 625f 656e 6769 6e65  e, matlab_engine
+00015110: 3d4e 6f6e 6529 3a0a 2020 2020 2020 2020  =None):.        
+00015120: 7920 3d20 3920 2b20 322e 3520 2a20 7365  y = 9 + 2.5 * se
+00015130: 6c66 2e70 5b22 7831 225d 202d 2031 372e  lf.p["x1"] - 17.
+00015140: 3520 2a20 7365 6c66 2e70 5b22 7832 225d  5 * self.p["x2"]
+00015150: 202b 2032 2e35 202a 2073 656c 662e 705b   + 2.5 * self.p[
+00015160: 2278 3122 5d20 2a20 7365 6c66 2e70 5b22  "x1"] * self.p["
+00015170: 7832 225d 202b 2031 3920 2a20 7365 6c66  x2"] + 19 * self
+00015180: 2e70 5b22 7832 225d 202a 2a20 3220 2d5c  .p["x2"] ** 2 -\
+00015190: 0a20 2020 2020 2020 2020 2020 2037 2e35  .            7.5
+000151a0: 202a 2073 656c 662e 705b 2278 3122 5d20   * self.p["x1"] 
+000151b0: 2a2a 2033 202d 2032 2e35 202a 2073 656c  ** 3 - 2.5 * sel
+000151c0: 662e 705b 2278 3122 5d20 2a20 7365 6c66  f.p["x1"] * self
+000151d0: 2e70 5b22 7832 225d 202a 2a20 3220 2d20  .p["x2"] ** 2 - 
+000151e0: 352e 3520 2a20 7365 6c66 2e70 5b22 7832  5.5 * self.p["x2
+000151f0: 225d 202a 2a20 3420 2b5c 0a20 2020 2020  "] ** 4 +\.     
+00015200: 2020 2020 2020 2028 7365 6c66 2e70 5b22         (self.p["
+00015210: 7831 225d 202a 2a20 3329 202a 2028 7365  x1"] ** 3) * (se
+00015220: 6c66 2e70 5b22 7832 225d 202a 2a20 3229  lf.p["x2"] ** 2)
+00015230: 0a0a 2020 2020 2020 2020 2320 7920 3d20  ..        # y = 
+00015240: 2839 202b 2035 2e30 202f 2032 202a 2073  (9 + 5.0 / 2 * s
+00015250: 656c 662e 705b 2278 3122 5d20 2d20 3335  elf.p["x1"] - 35
+00015260: 2e30 202f 2032 202a 2073 656c 662e 705b  .0 / 2 * self.p[
+00015270: 2278 3222 5d20 2b20 352e 3020 2f20 3220  "x2"] + 5.0 / 2 
+00015280: 2a20 7365 6c66 2e70 5b22 7831 225d 202a  * self.p["x1"] *
+00015290: 2073 656c 662e 705b 2278 3222 5d20 2b0a   self.p["x2"] +.
+000152a0: 2020 2020 2020 2020 2320 2020 2020 2031          #      1
+000152b0: 3920 2a20 7365 6c66 2e70 5b22 7832 225d  9 * self.p["x2"]
+000152c0: 202a 2a20 3220 2d20 3135 2e30 202f 2032   ** 2 - 15.0 / 2
+000152d0: 202a 2073 656c 662e 705b 2278 3122 5d20   * self.p["x1"] 
+000152e0: 2a2a 2033 202d 2035 2e30 202f 2032 202a  ** 3 - 5.0 / 2 *
+000152f0: 2073 656c 662e 705b 2278 3122 5d20 2a20   self.p["x1"] * 
+00015300: 7365 6c66 2e70 5b22 7832 225d 202a 2a20  self.p["x2"] ** 
+00015310: 3220 2d0a 2020 2020 2020 2020 2320 2020  2 -.        #   
+00015320: 2020 2031 312e 3020 2f20 3220 2a20 7365     11.0 / 2 * se
+00015330: 6c66 2e70 5b22 7832 225d 202a 2a20 3420  lf.p["x2"] ** 4 
+00015340: 2b20 7365 6c66 2e70 5b22 7831 225d 202a  + self.p["x1"] *
+00015350: 2a20 3320 2a20 7365 6c66 2e70 5b22 7832  * 3 * self.p["x2
+00015360: 225d 202a 2a20 3229 0a0a 2020 2020 2020  "] ** 2)..      
+00015370: 2020 6966 2074 7970 6528 7929 2069 7320    if type(y) is 
+00015380: 6e6f 7420 6e70 2e6e 6461 7272 6179 3a0a  not np.ndarray:.
+00015390: 2020 2020 2020 2020 2020 2020 7920 3d20              y = 
+000153a0: 6e70 2e61 7272 6179 285b 795d 290a 0a20  np.array([y]).. 
+000153b0: 2020 2020 2020 2079 5f6f 7574 203d 2079         y_out = y
+000153c0: 5b3a 2c20 6e70 2e6e 6577 6178 6973 5d0a  [:, np.newaxis].
+000153d0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+000153e0: 795f 6f75 740a 0a0a 636c 6173 7320 4973  y_out...class Is
+000153f0: 6869 6761 6d69 2841 6273 7472 6163 744d  higami(AbstractM
+00015400: 6f64 656c 293a 0a20 2020 2022 2222 0a20  odel):.    """. 
+00015410: 2020 2054 6872 6565 2d64 696d 656e 7369     Three-dimensi
+00015420: 6f6e 616c 2074 6573 7420 6675 6e63 7469  onal test functi
+00015430: 6f6e 206f 6620 4973 6869 6761 6d69 2e0a  on of Ishigami..
+00015440: 0a20 2020 2054 6865 2049 7368 6967 616d  .    The Ishigam
+00015450: 6920 6675 6e63 7469 6f6e 206f 6620 4973  i function of Is
+00015460: 6869 6761 6d69 2026 2048 6f6d 6d61 2028  higami & Homma (
+00015470: 3139 3930 2920 5b31 5d20 6973 2075 7365  1990) [1] is use
+00015480: 6420 6173 2061 6e20 6578 616d 706c 650a  d as an example.
+00015490: 2020 2020 666f 7220 756e 6365 7274 6169      for uncertai
+000154a0: 6e74 7920 616e 6420 7365 6e73 6974 6976  nty and sensitiv
+000154b0: 6974 7920 616e 616c 7973 6973 206d 6574  ity analysis met
+000154c0: 686f 6473 2c20 6265 6361 7573 6520 6974  hods, because it
+000154d0: 2065 7868 6962 6974 730a 2020 2020 7374   exhibits.    st
+000154e0: 726f 6e67 206e 6f6e 6c69 6e65 6172 6974  rong nonlinearit
+000154f0: 7920 616e 6420 6e6f 6e6d 6f6e 6f74 6f6e  y and nonmonoton
+00015500: 6963 6974 792e 2049 7420 616c 736f 2068  icity. It also h
+00015510: 6173 2061 2070 6563 756c 6961 720a 2020  as a peculiar.  
+00015520: 2020 6465 7065 6e64 656e 6365 206f 6e20    dependence on 
+00015530: 7833 2c20 6173 2064 6573 6372 6962 6564  x3, as described
+00015540: 2062 7920 536f 626f 6c27 2026 204c 6576   by Sobol' & Lev
+00015550: 6974 616e 2028 3139 3939 2920 5b32 5d2e  itan (1999) [2].
+00015560: 0a20 2020 2054 6865 2076 616c 7565 7320  .    The values 
+00015570: 6f66 2061 2061 6e64 2062 2075 7365 6420  of a and b used 
+00015580: 6279 2043 7265 7374 6175 7820 6574 2061  by Crestaux et a
+00015590: 6c2e 2028 3230 3037 2920 5b33 5d20 616e  l. (2007) [3] an
+000155a0: 6420 4d61 7272 656c 2065 7420 616c 2e20  d Marrel et al. 
+000155b0: 2832 3030 3929 205b 345d 2061 7265 3a20  (2009) [4] are: 
+000155c0: 6120 3d20 3720 616e 6420 6220 3d20 302e  a = 7 and b = 0.
+000155d0: 312e 0a0a 2020 2020 2e2e 206d 6174 683a  1...    .. math:
+000155e0: 3a20 7920 3d20 5c73 696e 2878 5f31 2920  : y = \sin(x_1) 
+000155f0: 2b20 6120 5c73 696e 2878 5f32 295e 3220  + a \sin(x_2)^2 
+00015600: 2b20 6220 785f 335e 3420 5c73 696e 2878  + b x_3^4 \sin(x
+00015610: 5f31 290a 0a20 2020 2050 6172 616d 6574  _1)..    Paramet
+00015620: 6572 730a 2020 2020 2d2d 2d2d 2d2d 2d2d  ers.    --------
+00015630: 2d2d 0a20 2020 2070 5b22 7831 225d 3a20  --.    p["x1"]: 
+00015640: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
+00015650: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
+00015660: 645d 0a20 2020 2020 2020 2046 6972 7374  d].        First
+00015670: 2070 6172 616d 6574 6572 2064 6566 696e   parameter defin
+00015680: 6564 2069 6e20 5b2d 7069 2c20 7069 5d0a  ed in [-pi, pi].
+00015690: 2020 2020 705b 2278 3222 5d3a 2066 6c6f      p["x2"]: flo
+000156a0: 6174 206f 7220 6e64 6172 7261 7920 6f66  at or ndarray of
+000156b0: 2066 6c6f 6174 205b 6e5f 6772 6964 5d0a   float [n_grid].
+000156c0: 2020 2020 2020 2020 5365 636f 6e64 2070          Second p
+000156d0: 6172 616d 6574 6572 2064 6566 696e 6564  arameter defined
+000156e0: 2069 6e20 5b2d 7069 2c20 7069 5d0a 2020   in [-pi, pi].  
+000156f0: 2020 705b 2278 3322 5d3a 2066 6c6f 6174    p["x3"]: float
+00015700: 206f 7220 6e64 6172 7261 7920 6f66 2066   or ndarray of f
+00015710: 6c6f 6174 205b 6e5f 6772 6964 5d0a 2020  loat [n_grid].  
+00015720: 2020 2020 2020 5468 6972 6420 7061 7261        Third para
+00015730: 6d65 7465 7220 6465 6669 6e65 6420 696e  meter defined in
+00015740: 205b 2d70 692c 2070 695d 0a20 2020 2070   [-pi, pi].    p
+00015750: 5b22 6122 5d3a 2066 6c6f 6174 0a20 2020  ["a"]: float.   
+00015760: 2020 2020 2073 6861 7065 2070 6172 616d       shape param
+00015770: 6574 6572 2028 613d 3729 0a20 2020 2070  eter (a=7).    p
+00015780: 5b22 6222 5d3a 2066 6c6f 6174 0a20 2020  ["b"]: float.   
+00015790: 2020 2020 2073 6861 7065 2070 6172 616d       shape param
+000157a0: 6574 6572 2028 623d 302e 3129 0a0a 2020  eter (b=0.1)..  
+000157b0: 2020 5265 7475 726e 730a 2020 2020 2d2d    Returns.    --
+000157c0: 2d2d 2d2d 2d0a 2020 2020 793a 206e 6461  -----.    y: nda
+000157d0: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
+000157e0: 5f67 7269 6420 7820 315d 0a20 2020 2020  _grid x 1].     
+000157f0: 2020 204f 7574 7075 7420 6461 7461 0a0a     Output data..
+00015800: 2020 2020 4e6f 7465 730a 2020 2020 2d2d      Notes.    --
+00015810: 2d2d 2d0a 2020 2020 2e2e 2070 6c6f 743a  ---.    .. plot:
+00015820: 3a0a 0a20 2020 2020 2020 696d 706f 7274  :..       import
+00015830: 206e 756d 7079 2061 7320 6e70 0a20 2020   numpy as np.   
+00015840: 2020 2020 6672 6f6d 2070 7967 7063 2e74      from pygpc.t
+00015850: 6573 7466 756e 6374 696f 6e73 2069 6d70  estfunctions imp
+00015860: 6f72 7420 706c 6f74 5f74 6573 7466 756e  ort plot_testfun
+00015870: 6374 696f 6e20 6173 2070 6c6f 740a 2020  ction as plot.  
+00015880: 2020 2020 2066 726f 6d20 636f 6c6c 6563       from collec
+00015890: 7469 6f6e 7320 696d 706f 7274 204f 7264  tions import Ord
+000158a0: 6572 6564 4469 6374 0a0a 2020 2020 2020  eredDict..      
+000158b0: 2070 6172 616d 6574 6572 7320 3d20 4f72   parameters = Or
+000158c0: 6465 7265 6444 6963 7428 290a 2020 2020  deredDict().    
+000158d0: 2020 2070 6172 616d 6574 6572 735b 2278     parameters["x
+000158e0: 3122 5d20 3d20 6e70 2e6c 696e 7370 6163  1"] = np.linspac
+000158f0: 6528 2d6e 702e 7069 2c20 6e70 2e70 692c  e(-np.pi, np.pi,
+00015900: 2031 3030 290a 2020 2020 2020 2070 6172   100).       par
+00015910: 616d 6574 6572 735b 2278 3222 5d20 3d20  ameters["x2"] = 
+00015920: 6e70 2e6c 696e 7370 6163 6528 2d6e 702e  np.linspace(-np.
+00015930: 7069 2c20 6e70 2e70 692c 2031 3030 290a  pi, np.pi, 100).
+00015940: 0a20 2020 2020 2020 636f 6e73 7461 6e74  .       constant
+00015950: 7320 3d20 4f72 6465 7265 6444 6963 7428  s = OrderedDict(
+00015960: 290a 2020 2020 2020 2063 6f6e 7374 616e  ).       constan
+00015970: 7473 5b22 6122 5d20 3d20 372e 0a20 2020  ts["a"] = 7..   
+00015980: 2020 2020 636f 6e73 7461 6e74 735b 2262      constants["b
+00015990: 225d 203d 2030 2e31 0a20 2020 2020 2020  "] = 0.1.       
+000159a0: 636f 6e73 7461 6e74 735b 2278 3322 5d20  constants["x3"] 
+000159b0: 3d20 302e 0a0a 2020 2020 2020 2070 6c6f  = 0...       plo
+000159c0: 7428 2249 7368 6967 616d 6922 2c20 7061  t("Ishigami", pa
+000159d0: 7261 6d65 7465 7273 2c20 636f 6e73 7461  rameters, consta
+000159e0: 6e74 732c 2070 6c6f 745f 3364 3d46 616c  nts, plot_3d=Fal
+000159f0: 7365 290a 0a20 2020 202e 2e20 5b31 5d20  se)..    .. [1] 
+00015a00: 4973 6869 6761 6d69 2c20 542e 2c20 486f  Ishigami, T., Ho
+00015a10: 6d6d 612c 2054 2e20 2831 3939 302c 2044  mma, T. (1990, D
+00015a20: 6563 656d 6265 7229 2e20 416e 2069 6d70  ecember). An imp
+00015a30: 6f72 7461 6e63 6520 7175 616e 7469 6669  ortance quantifi
+00015a40: 6361 7469 6f6e 0a20 2020 2020 2020 7465  cation.       te
+00015a50: 6368 6e69 7175 6520 696e 2075 6e63 6572  chnique in uncer
+00015a60: 7461 696e 7479 2061 6e61 6c79 7369 7320  tainty analysis 
+00015a70: 666f 7220 636f 6d70 7574 6572 206d 6f64  for computer mod
+00015a80: 656c 732e 2049 6e20 556e 6365 7274 6169  els. In Uncertai
+00015a90: 6e74 790a 2020 2020 2020 204d 6f64 656c  nty.       Model
+00015aa0: 696e 6720 616e 6420 416e 616c 7973 6973  ing and Analysis
+00015ab0: 2c20 3139 3930 2e20 5072 6f63 6565 6469  , 1990. Proceedi
+00015ac0: 6e67 732e 2c20 4669 7273 7420 496e 7465  ngs., First Inte
+00015ad0: 726e 6174 696f 6e61 6c20 5379 6d70 6f73  rnational Sympos
+00015ae0: 6975 6d0a 2020 2020 2020 206f 6e20 2870  ium.       on (p
+00015af0: 702e 2033 3938 2d34 3033 292e 2049 4545  p. 398-403). IEE
+00015b00: 452e 0a0a 2020 2020 2e2e 205b 325d 2053  E...    .. [2] S
+00015b10: 6f62 6f6c 272c 2049 2e4d 2e2c 204c 6576  obol', I.M., Lev
+00015b20: 6974 616e 2c20 592e 4c2e 2028 3139 3939  itan, Y.L. (1999
+00015b30: 292e 204f 6e20 7468 6520 7573 6520 6f66  ). On the use of
+00015b40: 2076 6172 6961 6e63 6520 7265 6475 6369   variance reduci
+00015b50: 6e67 0a20 2020 2020 2020 6d75 6c74 6970  ng.       multip
+00015b60: 6c69 6572 7320 696e 204d 6f6e 7465 2043  liers in Monte C
+00015b70: 6172 6c6f 2063 6f6d 7075 7461 7469 6f6e  arlo computation
+00015b80: 7320 6f66 2061 2067 6c6f 6261 6c20 7365  s of a global se
+00015b90: 6e73 6974 6976 6974 7920 696e 6465 782e  nsitivity index.
+00015ba0: 0a20 2020 2020 2020 436f 6d70 7574 6572  .       Computer
+00015bb0: 2050 6879 7369 6373 2043 6f6d 6d75 6e69   Physics Communi
+00015bc0: 6361 7469 6f6e 732c 2031 3137 2831 292c  cations, 117(1),
+00015bd0: 2035 322d 3631 2e0a 0a20 2020 202e 2e20   52-61...    .. 
+00015be0: 5b33 5d20 4372 6573 7461 7578 2c20 542e  [3] Crestaux, T.
+00015bf0: 2c20 4d61 7274 696e 657a 2c20 4a2e 2d4d  , Martinez, J.-M
+00015c00: 2e2c 204c 6520 4d61 6974 7265 2c20 4f2e  ., Le Maitre, O.
+00015c10: 2c20 2620 4c61 6669 7474 652c 204f 2e20  , & Lafitte, O. 
+00015c20: 2832 3030 3729 2e0a 2020 2020 2020 2050  (2007)..       P
+00015c30: 6f6c 796e 6f6d 6961 6c20 6368 616f 7320  olynomial chaos 
+00015c40: 6578 7061 6e73 696f 6e20 666f 7220 756e  expansion for un
+00015c50: 6365 7274 6169 6e74 6965 7320 7175 616e  certainties quan
+00015c60: 7469 6669 6361 7469 6f6e 2061 6e64 2073  tification and s
+00015c70: 656e 7369 7469 7669 7479 2061 6e61 6c79  ensitivity analy
+00015c80: 7369 7320 5b50 6f77 6572 506f 696e 7420  sis [PowerPoint 
+00015c90: 736c 6964 6573 5d2e 0a20 2020 2020 2020  slides]..       
+00015ca0: 5265 7472 6965 7665 6420 6672 6f6d 2053  Retrieved from S
+00015cb0: 414d 4f20 3230 3037 2077 6562 7369 7465  AMO 2007 website
+00015cc0: 3a20 6874 7470 3a2f 2f73 616d 6f32 3030  : http://samo200
+00015cd0: 372e 6368 656d 2e65 6c74 652e 6875 2f6c  7.chem.elte.hu/l
+00015ce0: 6563 7475 7265 732f 4372 6573 7461 7578  ectures/Crestaux
+00015cf0: 2e70 6466 2e0a 0a20 2020 202e 2e20 5b34  .pdf...    .. [4
+00015d00: 5d20 4d61 7272 656c 2c20 412e 2c20 496f  ] Marrel, A., Io
+00015d10: 6f73 732c 2042 2e2c 204c 6175 7265 6e74  oss, B., Laurent
+00015d20: 2c20 422e 2c20 2620 526f 7573 7461 6e74  , B., & Roustant
+00015d30: 2c20 4f2e 2028 3230 3039 292e 0a20 2020  , O. (2009)..   
+00015d40: 2020 2020 4361 6c63 756c 6174 696f 6e73      Calculations
+00015d50: 206f 6620 736f 626f 6c20 696e 6469 6365   of sobol indice
+00015d60: 7320 666f 7220 7468 6520 6761 7573 7369  s for the gaussi
+00015d70: 616e 2070 726f 6365 7373 206d 6574 616d  an process metam
+00015d80: 6f64 656c 2e0a 2020 2020 2020 2052 656c  odel..       Rel
+00015d90: 6961 6269 6c69 7479 2045 6e67 696e 6565  iability Enginee
+00015da0: 7269 6e67 2026 2053 7973 7465 6d20 5361  ring & System Sa
+00015db0: 6665 7479 2c20 3934 2833 292c 2037 3432  fety, 94(3), 742
+00015dc0: 2d37 3531 2e0a 2020 2020 2222 220a 0a20  -751..    """.. 
+00015dd0: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
+00015de0: 7365 6c66 2c20 6d61 746c 6162 5f6d 6f64  self, matlab_mod
+00015df0: 656c 3d46 616c 7365 293a 0a20 2020 2020  el=False):.     
+00015e00: 2020 2073 7570 6572 2874 7970 6528 7365     super(type(se
+00015e10: 6c66 292c 2073 656c 6629 2e5f 5f69 6e69  lf), self).__ini
+00015e20: 745f 5f28 6d61 746c 6162 5f6d 6f64 656c  t__(matlab_model
+00015e30: 3d6d 6174 6c61 625f 6d6f 6465 6c29 0a20  =matlab_model). 
+00015e40: 2020 2020 2020 2073 656c 662e 666e 616d         self.fnam
+00015e50: 6520 3d20 696e 7370 6563 742e 6765 7466  e = inspect.getf
+00015e60: 696c 6528 696e 7370 6563 742e 6375 7272  ile(inspect.curr
+00015e70: 656e 7466 7261 6d65 2829 290a 0a20 2020  entframe())..   
+00015e80: 2064 6566 2076 616c 6964 6174 6528 7365   def validate(se
+00015e90: 6c66 293a 0a20 2020 2020 2020 2070 6173  lf):.        pas
+00015ea0: 730a 0a20 2020 2064 6566 2073 696d 756c  s..    def simul
+00015eb0: 6174 6528 7365 6c66 2c20 7072 6f63 6573  ate(self, proces
+00015ec0: 735f 6964 3d4e 6f6e 652c 206d 6174 6c61  s_id=None, matla
+00015ed0: 625f 656e 6769 6e65 3d4e 6f6e 6529 3a0a  b_engine=None):.
+00015ee0: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
+00015ef0: 2e70 5b22 7831 225d 2069 7320 6e6f 7420  .p["x1"] is not 
+00015f00: 6e70 2e6e 6461 7272 6179 3a0a 2020 2020  np.ndarray:.    
+00015f10: 2020 2020 2020 2020 7365 6c66 2e70 5b22          self.p["
+00015f20: 7831 225d 203d 206e 702e 6172 7261 7928  x1"] = np.array(
+00015f30: 7365 6c66 2e70 5b22 7831 225d 290a 0a20  self.p["x1"]).. 
+00015f40: 2020 2020 2020 2069 6620 7365 6c66 2e70         if self.p
+00015f50: 5b22 7832 225d 2069 7320 6e6f 7420 6e70  ["x2"] is not np
+00015f60: 2e6e 6461 7272 6179 3a0a 2020 2020 2020  .ndarray:.      
+00015f70: 2020 2020 2020 7365 6c66 2e70 5b22 7832        self.p["x2
+00015f80: 225d 203d 206e 702e 6172 7261 7928 7365  "] = np.array(se
+00015f90: 6c66 2e70 5b22 7832 225d 290a 0a20 2020  lf.p["x2"])..   
+00015fa0: 2020 2020 2069 6620 7365 6c66 2e70 5b22       if self.p["
+00015fb0: 7833 225d 2069 7320 6e6f 7420 6e70 2e6e  x3"] is not np.n
+00015fc0: 6461 7272 6179 3a0a 2020 2020 2020 2020  darray:.        
+00015fd0: 2020 2020 7365 6c66 2e70 5b22 7833 225d      self.p["x3"]
+00015fe0: 203d 206e 702e 6172 7261 7928 7365 6c66   = np.array(self
+00015ff0: 2e70 5b22 7833 225d 290a 0a20 2020 2020  .p["x3"])..     
+00016000: 2020 2069 6620 7365 6c66 2e70 5b22 6122     if self.p["a"
+00016010: 5d20 6973 206e 6f74 206e 702e 6e64 6172  ] is not np.ndar
+00016020: 7261 793a 0a20 2020 2020 2020 2020 2020  ray:.           
+00016030: 2073 656c 662e 705b 2261 225d 203d 206e   self.p["a"] = n
+00016040: 702e 6172 7261 7928 7365 6c66 2e70 5b22  p.array(self.p["
+00016050: 6122 5d29 0a0a 2020 2020 2020 2020 6966  a"])..        if
+00016060: 2073 656c 662e 705b 2262 225d 2069 7320   self.p["b"] is 
+00016070: 6e6f 7420 6e70 2e6e 6461 7272 6179 3a0a  not np.ndarray:.
+00016080: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00016090: 2e70 5b22 6222 5d20 3d20 6e70 2e61 7272  .p["b"] = np.arr
+000160a0: 6179 2873 656c 662e 705b 2262 225d 290a  ay(self.p["b"]).
+000160b0: 0a20 2020 2020 2020 2079 203d 2028 6e70  .        y = (np
+000160c0: 2e73 696e 2873 656c 662e 705b 2278 3122  .sin(self.p["x1"
+000160d0: 5d2e 666c 6174 7465 6e28 2929 202b 2073  ].flatten()) + s
+000160e0: 656c 662e 705b 2261 225d 2e66 6c61 7474  elf.p["a"].flatt
+000160f0: 656e 2829 202a 206e 702e 7369 6e28 7365  en() * np.sin(se
+00016100: 6c66 2e70 5b22 7832 225d 2e66 6c61 7474  lf.p["x2"].flatt
+00016110: 656e 2829 2920 2a2a 2032 0a20 2020 2020  en()) ** 2.     
+00016120: 2020 2020 2020 2020 2b20 7365 6c66 2e70          + self.p
+00016130: 5b22 6222 5d2e 666c 6174 7465 6e28 2920  ["b"].flatten() 
+00016140: 2a20 7365 6c66 2e70 5b22 7833 225d 2e66  * self.p["x3"].f
+00016150: 6c61 7474 656e 2829 202a 2a20 3420 2a20  latten() ** 4 * 
+00016160: 6e70 2e73 696e 2873 656c 662e 705b 2278  np.sin(self.p["x
+00016170: 3122 5d2e 666c 6174 7465 6e28 2929 290a  1"].flatten())).
+00016180: 0a20 2020 2020 2020 2069 6620 7479 7065  .        if type
+00016190: 2879 2920 6973 206e 6f74 206e 702e 6e64  (y) is not np.nd
+000161a0: 6172 7261 793a 0a20 2020 2020 2020 2020  array:.         
+000161b0: 2020 2079 203d 206e 702e 6172 7261 7928     y = np.array(
+000161c0: 5b79 5d29 0a0a 2020 2020 2020 2020 795f  [y])..        y_
+000161d0: 6f75 7420 3d20 795b 3a2c 206e 702e 6e65  out = y[:, np.ne
+000161e0: 7761 7869 735d 0a0a 2020 2020 2020 2020  waxis]..        
+000161f0: 7265 7475 726e 2079 5f6f 7574 0a0a 0a63  return y_out...c
+00016200: 6c61 7373 2049 7368 6967 616d 695f 4e61  lass Ishigami_Na
+00016210: 4e28 4162 7374 7261 6374 4d6f 6465 6c29  N(AbstractModel)
+00016220: 3a0a 2020 2020 2222 220a 2020 2020 5468  :.    """.    Th
+00016230: 7265 652d 6469 6d65 6e73 696f 6e61 6c20  ree-dimensional 
+00016240: 7465 7374 2066 756e 6374 696f 6e20 6f66  test function of
+00016250: 2049 7368 6967 616d 692e 0a0a 2020 2020   Ishigami...    
+00016260: 5468 6520 4973 6869 6761 6d69 2066 756e  The Ishigami fun
+00016270: 6374 696f 6e20 6f66 2049 7368 6967 616d  ction of Ishigam
+00016280: 6920 2620 486f 6d6d 6120 2831 3939 3029  i & Homma (1990)
+00016290: 205b 315d 2069 7320 7573 6564 2061 7320   [1] is used as 
+000162a0: 616e 2065 7861 6d70 6c65 0a20 2020 2066  an example.    f
+000162b0: 6f72 2075 6e63 6572 7461 696e 7479 2061  or uncertainty a
+000162c0: 6e64 2073 656e 7369 7469 7669 7479 2061  nd sensitivity a
+000162d0: 6e61 6c79 7369 7320 6d65 7468 6f64 732c  nalysis methods,
+000162e0: 2062 6563 6175 7365 2069 7420 6578 6869   because it exhi
+000162f0: 6269 7473 0a20 2020 2073 7472 6f6e 6720  bits.    strong 
+00016300: 6e6f 6e6c 696e 6561 7269 7479 2061 6e64  nonlinearity and
+00016310: 206e 6f6e 6d6f 6e6f 746f 6e69 6369 7479   nonmonotonicity
+00016320: 2e20 4974 2061 6c73 6f20 6861 7320 6120  . It also has a 
+00016330: 7065 6375 6c69 6172 0a20 2020 2064 6570  peculiar.    dep
+00016340: 656e 6465 6e63 6520 6f6e 2078 332c 2061  endence on x3, a
+00016350: 7320 6465 7363 7269 6265 6420 6279 2053  s described by S
+00016360: 6f62 6f6c 2720 2620 4c65 7669 7461 6e20  obol' & Levitan 
+00016370: 2831 3939 3929 205b 325d 2e0a 2020 2020  (1999) [2]..    
+00016380: 5468 6520 7661 6c75 6573 206f 6620 6120  The values of a 
+00016390: 616e 6420 6220 7573 6564 2062 7920 4372  and b used by Cr
+000163a0: 6573 7461 7578 2065 7420 616c 2e20 2832  estaux et al. (2
+000163b0: 3030 3729 205b 335d 2061 6e64 204d 6172  007) [3] and Mar
+000163c0: 7265 6c20 6574 2061 6c2e 2028 3230 3039  rel et al. (2009
+000163d0: 2920 5b34 5d20 6172 653a 2061 203d 2037  ) [4] are: a = 7
+000163e0: 2061 6e64 2062 203d 2030 2e31 2e0a 0a20   and b = 0.1... 
+000163f0: 2020 202e 2e20 6d61 7468 3a3a 2079 203d     .. math:: y =
+00016400: 205c 7369 6e28 785f 3129 202b 2061 205c   \sin(x_1) + a \
+00016410: 7369 6e28 785f 3229 5e32 202b 2062 2078  sin(x_2)^2 + b x
+00016420: 5f33 5e34 205c 7369 6e28 785f 3129 0a0a  _3^4 \sin(x_1)..
+00016430: 2020 2020 5061 7261 6d65 7465 7273 0a20      Parameters. 
+00016440: 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020     ----------.  
+00016450: 2020 705b 2278 3122 5d3a 2066 6c6f 6174    p["x1"]: float
+00016460: 206f 7220 6e64 6172 7261 7920 6f66 2066   or ndarray of f
+00016470: 6c6f 6174 205b 6e5f 6772 6964 5d0a 2020  loat [n_grid].  
+00016480: 2020 2020 2020 4669 7273 7420 7061 7261        First para
+00016490: 6d65 7465 7220 6465 6669 6e65 6420 696e  meter defined in
+000164a0: 205b 2d70 692c 2070 695d 0a20 2020 2070   [-pi, pi].    p
+000164b0: 5b22 7832 225d 3a20 666c 6f61 7420 6f72  ["x2"]: float or
+000164c0: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
+000164d0: 7420 5b6e 5f67 7269 645d 0a20 2020 2020  t [n_grid].     
+000164e0: 2020 2053 6563 6f6e 6420 7061 7261 6d65     Second parame
+000164f0: 7465 7220 6465 6669 6e65 6420 696e 205b  ter defined in [
+00016500: 2d70 692c 2070 695d 0a20 2020 2070 5b22  -pi, pi].    p["
+00016510: 7833 225d 3a20 666c 6f61 7420 6f72 206e  x3"]: float or n
+00016520: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+00016530: 5b6e 5f67 7269 645d 0a20 2020 2020 2020  [n_grid].       
+00016540: 2054 6869 7264 2070 6172 616d 6574 6572   Third parameter
+00016550: 2064 6566 696e 6564 2069 6e20 5b2d 7069   defined in [-pi
+00016560: 2c20 7069 5d0a 2020 2020 705b 2261 225d  , pi].    p["a"]
+00016570: 3a20 666c 6f61 740a 2020 2020 2020 2020  : float.        
+00016580: 7368 6170 6520 7061 7261 6d65 7465 7220  shape parameter 
+00016590: 2861 3d37 290a 2020 2020 705b 2262 225d  (a=7).    p["b"]
+000165a0: 3a20 666c 6f61 740a 2020 2020 2020 2020  : float.        
+000165b0: 7368 6170 6520 7061 7261 6d65 7465 7220  shape parameter 
+000165c0: 2862 3d30 2e31 290a 0a20 2020 2052 6574  (b=0.1)..    Ret
+000165d0: 7572 6e73 0a20 2020 202d 2d2d 2d2d 2d2d  urns.    -------
+000165e0: 0a20 2020 2079 3a20 6e64 6172 7261 7920  .    y: ndarray 
+000165f0: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
+00016600: 2078 2031 5d0a 2020 2020 2020 2020 4f75   x 1].        Ou
+00016610: 7470 7574 2064 6174 610a 0a20 2020 204e  tput data..    N
+00016620: 6f74 6573 0a20 2020 202d 2d2d 2d2d 0a20  otes.    -----. 
+00016630: 2020 202e 2e20 706c 6f74 3a3a 0a0a 2020     .. plot::..  
+00016640: 2020 2020 2069 6d70 6f72 7420 6e75 6d70       import nump
+00016650: 7920 6173 206e 700a 2020 2020 2020 2066  y as np.       f
+00016660: 726f 6d20 7079 6770 632e 7465 7374 6675  rom pygpc.testfu
+00016670: 6e63 7469 6f6e 7320 696d 706f 7274 2070  nctions import p
+00016680: 6c6f 745f 7465 7374 6675 6e63 7469 6f6e  lot_testfunction
+00016690: 2061 7320 706c 6f74 0a20 2020 2020 2020   as plot.       
+000166a0: 6672 6f6d 2063 6f6c 6c65 6374 696f 6e73  from collections
+000166b0: 2069 6d70 6f72 7420 4f72 6465 7265 6444   import OrderedD
+000166c0: 6963 740a 0a20 2020 2020 2020 7061 7261  ict..       para
+000166d0: 6d65 7465 7273 203d 204f 7264 6572 6564  meters = Ordered
+000166e0: 4469 6374 2829 0a20 2020 2020 2020 7061  Dict().       pa
+000166f0: 7261 6d65 7465 7273 5b22 7831 225d 203d  rameters["x1"] =
+00016700: 206e 702e 6c69 6e73 7061 6365 282d 6e70   np.linspace(-np
+00016710: 2e70 692c 206e 702e 7069 2c20 3130 3029  .pi, np.pi, 100)
+00016720: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
+00016730: 7273 5b22 7832 225d 203d 206e 702e 6c69  rs["x2"] = np.li
+00016740: 6e73 7061 6365 282d 6e70 2e70 692c 206e  nspace(-np.pi, n
+00016750: 702e 7069 2c20 3130 3029 0a0a 2020 2020  p.pi, 100)..    
+00016760: 2020 2063 6f6e 7374 616e 7473 203d 204f     constants = O
+00016770: 7264 6572 6564 4469 6374 2829 0a20 2020  rderedDict().   
+00016780: 2020 2020 636f 6e73 7461 6e74 735b 2261      constants["a
+00016790: 225d 203d 2037 2e0a 2020 2020 2020 2063  "] = 7..       c
+000167a0: 6f6e 7374 616e 7473 5b22 6222 5d20 3d20  onstants["b"] = 
+000167b0: 302e 310a 2020 2020 2020 2063 6f6e 7374  0.1.       const
+000167c0: 616e 7473 5b22 7833 225d 203d 2030 2e0a  ants["x3"] = 0..
+000167d0: 0a20 2020 2020 2020 706c 6f74 2822 4973  .       plot("Is
+000167e0: 6869 6761 6d69 222c 2070 6172 616d 6574  higami", paramet
+000167f0: 6572 732c 2063 6f6e 7374 616e 7473 2c20  ers, constants, 
+00016800: 706c 6f74 5f33 643d 4661 6c73 6529 0a0a  plot_3d=False)..
+00016810: 2020 2020 2e2e 205b 315d 2049 7368 6967      .. [1] Ishig
+00016820: 616d 692c 2054 2e2c 2048 6f6d 6d61 2c20  ami, T., Homma, 
+00016830: 542e 2028 3139 3930 2c20 4465 6365 6d62  T. (1990, Decemb
+00016840: 6572 292e 2041 6e20 696d 706f 7274 616e  er). An importan
+00016850: 6365 2071 7561 6e74 6966 6963 6174 696f  ce quantificatio
+00016860: 6e0a 2020 2020 2020 2074 6563 686e 6971  n.       techniq
+00016870: 7565 2069 6e20 756e 6365 7274 6169 6e74  ue in uncertaint
+00016880: 7920 616e 616c 7973 6973 2066 6f72 2063  y analysis for c
+00016890: 6f6d 7075 7465 7220 6d6f 6465 6c73 2e20  omputer models. 
+000168a0: 496e 2055 6e63 6572 7461 696e 7479 0a20  In Uncertainty. 
+000168b0: 2020 2020 2020 4d6f 6465 6c69 6e67 2061        Modeling a
+000168c0: 6e64 2041 6e61 6c79 7369 732c 2031 3939  nd Analysis, 199
+000168d0: 302e 2050 726f 6365 6564 696e 6773 2e2c  0. Proceedings.,
+000168e0: 2046 6972 7374 2049 6e74 6572 6e61 7469   First Internati
+000168f0: 6f6e 616c 2053 796d 706f 7369 756d 0a20  onal Symposium. 
+00016900: 2020 2020 2020 6f6e 2028 7070 2e20 3339        on (pp. 39
+00016910: 382d 3430 3329 2e20 4945 4545 2e0a 0a20  8-403). IEEE... 
+00016920: 2020 202e 2e20 5b32 5d20 536f 626f 6c27     .. [2] Sobol'
+00016930: 2c20 492e 4d2e 2c20 4c65 7669 7461 6e2c  , I.M., Levitan,
+00016940: 2059 2e4c 2e20 2831 3939 3929 2e20 4f6e   Y.L. (1999). On
+00016950: 2074 6865 2075 7365 206f 6620 7661 7269   the use of vari
+00016960: 616e 6365 2072 6564 7563 696e 670a 2020  ance reducing.  
+00016970: 2020 2020 206d 756c 7469 706c 6965 7273       multipliers
+00016980: 2069 6e20 4d6f 6e74 6520 4361 726c 6f20   in Monte Carlo 
+00016990: 636f 6d70 7574 6174 696f 6e73 206f 6620  computations of 
+000169a0: 6120 676c 6f62 616c 2073 656e 7369 7469  a global sensiti
+000169b0: 7669 7479 2069 6e64 6578 2e0a 2020 2020  vity index..    
+000169c0: 2020 2043 6f6d 7075 7465 7220 5068 7973     Computer Phys
+000169d0: 6963 7320 436f 6d6d 756e 6963 6174 696f  ics Communicatio
+000169e0: 6e73 2c20 3131 3728 3129 2c20 3532 2d36  ns, 117(1), 52-6
+000169f0: 312e 0a0a 2020 2020 2e2e 205b 335d 2043  1...    .. [3] C
+00016a00: 7265 7374 6175 782c 2054 2e2c 204d 6172  restaux, T., Mar
+00016a10: 7469 6e65 7a2c 204a 2e2d 4d2e 2c20 4c65  tinez, J.-M., Le
+00016a20: 204d 6169 7472 652c 204f 2e2c 2026 204c   Maitre, O., & L
+00016a30: 6166 6974 7465 2c20 4f2e 2028 3230 3037  afitte, O. (2007
+00016a40: 292e 0a20 2020 2020 2020 506f 6c79 6e6f  )..       Polyno
+00016a50: 6d69 616c 2063 6861 6f73 2065 7870 616e  mial chaos expan
+00016a60: 7369 6f6e 2066 6f72 2075 6e63 6572 7461  sion for uncerta
+00016a70: 696e 7469 6573 2071 7561 6e74 6966 6963  inties quantific
+00016a80: 6174 696f 6e20 616e 6420 7365 6e73 6974  ation and sensit
+00016a90: 6976 6974 7920 616e 616c 7973 6973 205b  ivity analysis [
+00016aa0: 506f 7765 7250 6f69 6e74 2073 6c69 6465  PowerPoint slide
+00016ab0: 735d 2e0a 2020 2020 2020 2052 6574 7269  s]..       Retri
+00016ac0: 6576 6564 2066 726f 6d20 5341 4d4f 2032  eved from SAMO 2
+00016ad0: 3030 3720 7765 6273 6974 653a 2068 7474  007 website: htt
+00016ae0: 703a 2f2f 7361 6d6f 3230 3037 2e63 6865  p://samo2007.che
+00016af0: 6d2e 656c 7465 2e68 752f 6c65 6374 7572  m.elte.hu/lectur
+00016b00: 6573 2f43 7265 7374 6175 782e 7064 662e  es/Crestaux.pdf.
+00016b10: 0a0a 2020 2020 2e2e 205b 345d 204d 6172  ..    .. [4] Mar
+00016b20: 7265 6c2c 2041 2e2c 2049 6f6f 7373 2c20  rel, A., Iooss, 
+00016b30: 422e 2c20 4c61 7572 656e 742c 2042 2e2c  B., Laurent, B.,
+00016b40: 2026 2052 6f75 7374 616e 742c 204f 2e20   & Roustant, O. 
+00016b50: 2832 3030 3929 2e0a 2020 2020 2020 2043  (2009)..       C
+00016b60: 616c 6375 6c61 7469 6f6e 7320 6f66 2073  alculations of s
+00016b70: 6f62 6f6c 2069 6e64 6963 6573 2066 6f72  obol indices for
+00016b80: 2074 6865 2067 6175 7373 6961 6e20 7072   the gaussian pr
+00016b90: 6f63 6573 7320 6d65 7461 6d6f 6465 6c2e  ocess metamodel.
+00016ba0: 0a20 2020 2020 2020 5265 6c69 6162 696c  .       Reliabil
+00016bb0: 6974 7920 456e 6769 6e65 6572 696e 6720  ity Engineering 
+00016bc0: 2620 5379 7374 656d 2053 6166 6574 792c  & System Safety,
+00016bd0: 2039 3428 3329 2c20 3734 322d 3735 312e   94(3), 742-751.
+00016be0: 0a20 2020 2022 2222 0a0a 2020 2020 6465  .    """..    de
+00016bf0: 6620 5f5f 696e 6974 5f5f 2873 656c 662c  f __init__(self,
+00016c00: 206d 6174 6c61 625f 6d6f 6465 6c3d 4661   matlab_model=Fa
+00016c10: 6c73 6529 3a0a 2020 2020 2020 2020 7375  lse):.        su
+00016c20: 7065 7228 7479 7065 2873 656c 6629 2c20  per(type(self), 
+00016c30: 7365 6c66 292e 5f5f 696e 6974 5f5f 286d  self).__init__(m
+00016c40: 6174 6c61 625f 6d6f 6465 6c3d 6d61 746c  atlab_model=matl
+00016c50: 6162 5f6d 6f64 656c 290a 2020 2020 2020  ab_model).      
+00016c60: 2020 7365 6c66 2e66 6e61 6d65 203d 2069    self.fname = i
+00016c70: 6e73 7065 6374 2e67 6574 6669 6c65 2869  nspect.getfile(i
+00016c80: 6e73 7065 6374 2e63 7572 7265 6e74 6672  nspect.currentfr
+00016c90: 616d 6528 2929 0a0a 2020 2020 6465 6620  ame())..    def 
+00016ca0: 7661 6c69 6461 7465 2873 656c 6629 3a0a  validate(self):.
+00016cb0: 2020 2020 2020 2020 7061 7373 0a0a 2020          pass..  
+00016cc0: 2020 6465 6620 7369 6d75 6c61 7465 2873    def simulate(s
+00016cd0: 656c 662c 2070 726f 6365 7373 5f69 643d  elf, process_id=
+00016ce0: 4e6f 6e65 2c20 6d61 746c 6162 5f65 6e67  None, matlab_eng
+00016cf0: 696e 653d 4e6f 6e65 293a 0a0a 2020 2020  ine=None):..    
+00016d00: 2020 2020 6966 2073 656c 662e 705b 2278      if self.p["x
+00016d10: 3122 5d20 6973 206e 6f74 206e 702e 6e64  1"] is not np.nd
+00016d20: 6172 7261 793a 0a20 2020 2020 2020 2020  array:.         
+00016d30: 2020 2073 656c 662e 705b 2278 3122 5d20     self.p["x1"] 
+00016d40: 3d20 6e70 2e61 7272 6179 2873 656c 662e  = np.array(self.
+00016d50: 705b 2278 3122 5d29 0a0a 2020 2020 2020  p["x1"])..      
+00016d60: 2020 6966 2073 656c 662e 705b 2278 3222    if self.p["x2"
+00016d70: 5d20 6973 206e 6f74 206e 702e 6e64 6172  ] is not np.ndar
+00016d80: 7261 793a 0a20 2020 2020 2020 2020 2020  ray:.           
+00016d90: 2073 656c 662e 705b 2278 3222 5d20 3d20   self.p["x2"] = 
+00016da0: 6e70 2e61 7272 6179 2873 656c 662e 705b  np.array(self.p[
+00016db0: 2278 3222 5d29 0a0a 2020 2020 2020 2020  "x2"])..        
+00016dc0: 6966 2073 656c 662e 705b 2278 3322 5d20  if self.p["x3"] 
+00016dd0: 6973 206e 6f74 206e 702e 6e64 6172 7261  is not np.ndarra
+00016de0: 793a 0a20 2020 2020 2020 2020 2020 2073  y:.            s
+00016df0: 656c 662e 705b 2278 3322 5d20 3d20 6e70  elf.p["x3"] = np
+00016e00: 2e61 7272 6179 2873 656c 662e 705b 2278  .array(self.p["x
+00016e10: 3322 5d29 0a0a 2020 2020 2020 2020 6966  3"])..        if
+00016e20: 2073 656c 662e 705b 2261 225d 2069 7320   self.p["a"] is 
+00016e30: 6e6f 7420 6e70 2e6e 6461 7272 6179 3a0a  not np.ndarray:.
+00016e40: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00016e50: 2e70 5b22 6122 5d20 3d20 6e70 2e61 7272  .p["a"] = np.arr
+00016e60: 6179 2873 656c 662e 705b 2261 225d 290a  ay(self.p["a"]).
+00016e70: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
+00016e80: 2e70 5b22 6222 5d20 6973 206e 6f74 206e  .p["b"] is not n
+00016e90: 702e 6e64 6172 7261 793a 0a20 2020 2020  p.ndarray:.     
+00016ea0: 2020 2020 2020 2073 656c 662e 705b 2262         self.p["b
+00016eb0: 225d 203d 206e 702e 6172 7261 7928 7365  "] = np.array(se
+00016ec0: 6c66 2e70 5b22 6222 5d29 0a0a 2020 2020  lf.p["b"])..    
+00016ed0: 2020 2020 7920 3d20 286e 702e 7369 6e28      y = (np.sin(
+00016ee0: 7365 6c66 2e70 5b22 7831 225d 2e66 6c61  self.p["x1"].fla
+00016ef0: 7474 656e 2829 2920 2b20 7365 6c66 2e70  tten()) + self.p
+00016f00: 5b22 6122 5d2e 666c 6174 7465 6e28 2920  ["a"].flatten() 
+00016f10: 2a20 6e70 2e73 696e 2873 656c 662e 705b  * np.sin(self.p[
+00016f20: 2278 3222 5d2e 666c 6174 7465 6e28 2929  "x2"].flatten())
+00016f30: 202a 2a20 320a 2020 2020 2020 2020 2020   ** 2.          
+00016f40: 2020 202b 2073 656c 662e 705b 2262 225d     + self.p["b"]
+00016f50: 2e66 6c61 7474 656e 2829 202a 2073 656c  .flatten() * sel
+00016f60: 662e 705b 2278 3322 5d2e 666c 6174 7465  f.p["x3"].flatte
+00016f70: 6e28 2920 2a2a 2034 202a 206e 702e 7369  n() ** 4 * np.si
+00016f80: 6e28 7365 6c66 2e70 5b22 7831 225d 2e66  n(self.p["x1"].f
+00016f90: 6c61 7474 656e 2829 2929 0a0a 2020 2020  latten()))..    
+00016fa0: 2020 2020 6966 2074 7970 6528 7929 2069      if type(y) i
+00016fb0: 7320 6e6f 7420 6e70 2e6e 6461 7272 6179  s not np.ndarray
+00016fc0: 3a0a 2020 2020 2020 2020 2020 2020 7920  :.            y 
+00016fd0: 3d20 6e70 2e61 7272 6179 285b 795d 290a  = np.array([y]).
+00016fe0: 0a20 2020 2020 2020 2079 5f6f 7574 203d  .        y_out =
+00016ff0: 2079 5b3a 2c20 6e70 2e6e 6577 6178 6973   y[:, np.newaxis
+00017000: 5d0a 0a20 2020 2020 2020 2023 2069 6e73  ]..        # ins
+00017010: 6572 7420 736f 6d65 204e 614e 2076 616c  ert some NaN val
+00017020: 7565 7320 666f 7220 7465 7374 696e 670a  ues for testing.
+00017030: 2020 2020 2020 2020 6d61 736b 203d 2028          mask = (
+00017040: 7365 6c66 2e70 5b22 7831 225d 203e 2032  self.p["x1"] > 2
+00017050: 292e 666c 6174 7465 6e28 290a 2020 2020  ).flatten().    
+00017060: 2020 2020 795f 6f75 745b 6d61 736b 2c20      y_out[mask, 
+00017070: 305d 203d 206e 702e 4e61 4e0a 0a20 2020  0] = np.NaN..   
+00017080: 2020 2020 2072 6574 7572 6e20 795f 6f75       return y_ou
+00017090: 740a 0a0a 636c 6173 7320 4746 756e 6374  t...class GFunct
+000170a0: 696f 6e28 4162 7374 7261 6374 4d6f 6465  ion(AbstractMode
+000170b0: 6c29 3a0a 2020 2020 2222 220a 2020 2020  l):.    """.    
+000170c0: 4e2d 6469 6d65 6e73 696f 6e61 6c20 672d  N-dimensional g-
+000170d0: 6675 6e63 7469 6f6e 2075 7365 6420 6279  function used by
+000170e0: 2053 616c 7465 6c6c 6920 616e 6420 536f   Saltelli and So
+000170f0: 626f 6c20 2831 3939 3529 205b 315d 2e0a  bol (1995) [1]..
+00017100: 0a20 2020 2054 6869 7320 7465 7374 2066  .    This test f
+00017110: 756e 6374 696f 6e20 6973 2075 7365 6420  unction is used 
+00017120: 6173 2061 6e20 696e 7465 6772 616e 6420  as an integrand 
+00017130: 666f 7220 7661 7269 6f75 7320 6e75 6d65  for various nume
+00017140: 7269 6361 6c0a 2020 2020 6573 7469 6d61  rical.    estima
+00017150: 7469 6f6e 206d 6574 686f 6473 2c20 696e  tion methods, in
+00017160: 636c 7564 696e 6720 7365 6e73 6974 6976  cluding sensitiv
+00017170: 6974 7920 616e 616c 7973 6973 206d 6574  ity analysis met
+00017180: 686f 6473 2c20 6265 6361 7573 6520 6974  hods, because it
+00017190: 0a20 2020 2069 7320 6661 6972 6c79 2063  .    is fairly c
+000171a0: 6f6d 706c 6578 2c20 616e 6420 6974 7320  omplex, and its 
+000171b0: 7365 6e73 6974 6976 6974 7920 696e 6469  sensitivity indi
+000171c0: 6365 7320 6361 6e20 6265 2065 7870 7265  ces can be expre
+000171d0: 7373 6564 0a20 2020 2061 6e61 6c79 7469  ssed.    analyti
+000171e0: 6361 6c6c 792e 2054 6865 2065 7861 6374  cally. The exact
+000171f0: 2076 616c 7565 206f 6620 7468 6520 696e   value of the in
+00017200: 7465 6772 616c 2077 6974 6820 7468 6973  tegral with this
+00017210: 2066 756e 6374 696f 6e20 6173 2061 6e0a   function as an.
+00017220: 2020 2020 696e 7465 6772 616e 6420 6973      integrand is
+00017230: 2031 2e20 466f 7220 6561 6368 2069 6e64   1. For each ind
+00017240: 6578 2069 2c20 6120 6c6f 7765 7220 7661  ex i, a lower va
+00017250: 6c75 6520 6f66 2061 5f69 2069 6e64 6963  lue of a_i indic
+00017260: 6174 6573 2061 2068 6967 6865 720a 2020  ates a higher.  
+00017270: 2020 696d 706f 7274 616e 6365 206f 6620    importance of 
+00017280: 7468 6520 696e 7075 7420 7661 7269 6162  the input variab
+00017290: 6c65 2078 692e 0a0a 2020 2020 2e2e 206d  le xi...    .. m
+000172a0: 6174 683a 3a20 5c70 726f 645f 7b69 3d31  ath:: \prod_{i=1
+000172b0: 7d5e 7b4e 7d5c 5c66 7261 637b 7c34 2078  }^{N}\\frac{|4 x
+000172c0: 5f69 202d 2032 7c20 2b20 615f 697d 7b31  _i - 2| + a_i}{1
+000172d0: 202b 2061 5f69 7d0a 0a20 2020 2054 6865   + a_i}..    The
+000172e0: 2072 6563 6f6d 6d65 6e64 6564 2076 616c   recommended val
+000172f0: 7565 7320 6f66 2061 5f69 2062 7920 4372  ues of a_i by Cr
+00017300: 6573 7461 7578 2065 7420 616c 2e20 2832  estaux et al. (2
+00017310: 3030 3729 205b 325d 2061 7265 3a0a 0a20  007) [2] are:.. 
+00017320: 2020 202e 2e20 6d61 7468 3a3a 2061 5f69     .. math:: a_i
+00017330: 203d 205c 5c66 7261 637b 692d 327d 7b32   = \\frac{i-2}{2
+00017340: 7d20 5c71 7561 6420 5c6d 6174 6872 6d7b  } \quad \mathrm{
+00017350: 666f 725c 3b61 6c6c 7d20 5c71 7561 6420  for\;all} \quad 
+00017360: 693d 312c 2e2e 2e2c 640a 0a20 2020 2050  i=1,...,d..    P
+00017370: 6172 616d 6574 6572 730a 2020 2020 2d2d  arameters.    --
+00017380: 2d2d 2d2d 2d2d 2d2d 0a20 2020 2070 5b22  --------.    p["
+00017390: 7831 225d 3a20 666c 6f61 7420 6f72 206e  x1"]: float or n
+000173a0: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+000173b0: 5b6e 5f67 7269 645d 0a20 2020 2020 2020  [n_grid].       
+000173c0: 2046 6972 7374 2070 6172 616d 6574 6572   First parameter
+000173d0: 205b 302c 2031 5d0a 2020 2020 705b 2278   [0, 1].    p["x
+000173e0: 6922 5d3a 2066 6c6f 6174 206f 7220 6e64  i"]: float or nd
+000173f0: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
+00017400: 6e5f 6772 6964 5d0a 2020 2020 2020 2020  n_grid].        
+00017410: 692d 7468 2070 6172 616d 6574 6572 2064  i-th parameter d
+00017420: 6566 696e 6564 2069 6e20 5b30 2c20 315d  efined in [0, 1]
+00017430: 0a20 2020 2070 5b22 784e 225d 3a20 666c  .    p["xN"]: fl
+00017440: 6f61 7420 6f72 206e 6461 7272 6179 206f  oat or ndarray o
+00017450: 6620 666c 6f61 7420 5b6e 5f67 7269 645d  f float [n_grid]
+00017460: 0a20 2020 2020 2020 204e 7468 2070 6172  .        Nth par
+00017470: 616d 6574 6572 205b 302c 2031 5d0a 2020  ameter [0, 1].  
+00017480: 2020 705b 2261 225d 3a20 6e64 6172 7261    p["a"]: ndarra
+00017490: 7920 6f66 2066 6c6f 6174 205b 4e5f 6469  y of float [N_di
+000174a0: 6d73 5d0a 2020 2020 2020 2020 496d 706f  ms].        Impo
+000174b0: 7274 616e 6365 2066 6163 746f 7273 206f  rtance factors o
+000174c0: 6620 6469 6d65 6e73 696f 6e73 0a0a 2020  f dimensions..  
+000174d0: 2020 5265 7475 726e 730a 2020 2020 2d2d    Returns.    --
+000174e0: 2d2d 2d2d 2d0a 2020 2020 793a 206e 6461  -----.    y: nda
+000174f0: 7272 6179 206f 6620 666c 6f61 7420 5b4e  rray of float [N
+00017500: 5f69 6e70 7574 2078 2031 5d0a 2020 2020  _input x 1].    
+00017510: 2020 2020 4f75 7470 7574 2064 6174 610a      Output data.
+00017520: 0a20 2020 204e 6f74 6573 0a20 2020 202d  .    Notes.    -
+00017530: 2d2d 2d2d 0a20 2020 202e 2e20 706c 6f74  ----.    .. plot
+00017540: 3a3a 0a0a 2020 2020 2020 2069 6d70 6f72  ::..       impor
+00017550: 7420 6e75 6d70 7920 6173 206e 700a 2020  t numpy as np.  
+00017560: 2020 2020 2066 726f 6d20 7079 6770 632e       from pygpc.
+00017570: 7465 7374 6675 6e63 7469 6f6e 7320 696d  testfunctions im
+00017580: 706f 7274 2070 6c6f 745f 7465 7374 6675  port plot_testfu
+00017590: 6e63 7469 6f6e 2061 7320 706c 6f74 0a20  nction as plot. 
+000175a0: 2020 2020 2020 6672 6f6d 2063 6f6c 6c65        from colle
+000175b0: 6374 696f 6e73 2069 6d70 6f72 7420 4f72  ctions import Or
+000175c0: 6465 7265 6444 6963 740a 0a20 2020 2020  deredDict..     
+000175d0: 2020 7061 7261 6d65 7465 7273 203d 204f    parameters = O
+000175e0: 7264 6572 6564 4469 6374 2829 0a20 2020  rderedDict().   
+000175f0: 2020 2020 7061 7261 6d65 7465 7273 5b22      parameters["
+00017600: 7831 225d 203d 206e 702e 6c69 6e73 7061  x1"] = np.linspa
+00017610: 6365 2830 2c20 312c 2031 3030 290a 2020  ce(0, 1, 100).  
+00017620: 2020 2020 2070 6172 616d 6574 6572 735b       parameters[
+00017630: 2278 3222 5d20 3d20 6e70 2e6c 696e 7370  "x2"] = np.linsp
+00017640: 6163 6528 302c 2031 2c20 3130 3029 0a0a  ace(0, 1, 100)..
+00017650: 2020 2020 2020 2063 6f6e 7374 616e 7473         constants
+00017660: 203d 204f 7264 6572 6564 4469 6374 2829   = OrderedDict()
+00017670: 0a20 2020 2020 2020 636f 6e73 7461 6e74  .       constant
+00017680: 735b 2261 225d 203d 2020 286e 702e 6172  s["a"] =  (np.ar
+00017690: 616e 6765 2832 292b 312d 322e 292f 322e  ange(2)+1-2.)/2.
+000176a0: 0a0a 2020 2020 2020 2070 6c6f 7428 2247  ..       plot("G
+000176b0: 4675 6e63 7469 6f6e 222c 2070 6172 616d  Function", param
+000176c0: 6574 6572 732c 2063 6f6e 7374 616e 7473  eters, constants
+000176d0: 2c20 706c 6f74 5f33 643d 4661 6c73 6529  , plot_3d=False)
+000176e0: 0a0a 2020 2020 2e2e 205b 315d 2053 616c  ..    .. [1] Sal
+000176f0: 7465 6c6c 692c 2041 6e64 7265 613b 2053  telli, Andrea; S
+00017700: 6f62 6f6c 2c20 492e 204d 2e20 2831 3939  obol, I. M. (199
+00017710: 3529 3a20 5365 6e73 6974 6976 6974 7920  5): Sensitivity 
+00017720: 616e 616c 7973 6973 2066 6f72 206e 6f6e  analysis for non
+00017730: 6c69 6e65 6172 0a20 2020 2020 2020 6d61  linear.       ma
+00017740: 7468 656d 6174 6963 616c 206d 6f64 656c  thematical model
+00017750: 733a 206e 756d 6572 6963 616c 2065 7870  s: numerical exp
+00017760: 6572 6965 6e63 652e 2049 6e3a 204d 6174  erience. In: Mat
+00017770: 6865 6d61 7469 6361 6c20 6d6f 6465 6c73  hematical models
+00017780: 2061 6e64 0a20 2020 2020 2020 636f 6d70   and.       comp
+00017790: 7574 6572 2065 7870 6572 696d 656e 7420  uter experiment 
+000177a0: 3720 2831 3129 2c20 7070 2e20 3136 2d32  7 (11), pp. 16-2
+000177b0: 382e 0a0a 2020 2020 2e2e 205b 325d 2043  8...    .. [2] C
+000177c0: 7265 7374 6175 782c 2054 2e2c 204d 6172  restaux, T., Mar
+000177d0: 7469 6e65 7a2c 204a 2e2d 4d2e 2c20 4c65  tinez, J.-M., Le
+000177e0: 204d 6169 7472 652c 204f 2e2c 2026 204c   Maitre, O., & L
+000177f0: 6166 6974 7465 2c20 4f2e 2028 3230 3037  afitte, O. (2007
+00017800: 292e 0a20 2020 2020 2020 506f 6c79 6e6f  )..       Polyno
+00017810: 6d69 616c 2063 6861 6f73 2065 7870 616e  mial chaos expan
+00017820: 7369 6f6e 2066 6f72 2075 6e63 6572 7461  sion for uncerta
+00017830: 696e 7469 6573 2071 7561 6e74 6966 6963  inties quantific
+00017840: 6174 696f 6e20 616e 6420 7365 6e73 6974  ation and sensit
+00017850: 6976 6974 7920 616e 616c 7973 6973 205b  ivity analysis [
+00017860: 506f 7765 7250 6f69 6e74 2073 6c69 6465  PowerPoint slide
+00017870: 735d 2e0a 2020 2020 2020 2052 6574 7269  s]..       Retri
+00017880: 6576 6564 2066 726f 6d20 5341 4d4f 2032  eved from SAMO 2
+00017890: 3030 3720 7765 6273 6974 653a 2068 7474  007 website: htt
+000178a0: 703a 2f2f 7361 6d6f 3230 3037 2e63 6865  p://samo2007.che
+000178b0: 6d2e 656c 7465 2e68 752f 6c65 6374 7572  m.elte.hu/lectur
+000178c0: 6573 2f43 7265 7374 6175 782e 7064 662e  es/Crestaux.pdf.
+000178d0: 0a20 2020 2022 2222 0a0a 2020 2020 6465  .    """..    de
+000178e0: 6620 5f5f 696e 6974 5f5f 2873 656c 662c  f __init__(self,
+000178f0: 206d 6174 6c61 625f 6d6f 6465 6c3d 4661   matlab_model=Fa
+00017900: 6c73 6529 3a0a 2020 2020 2020 2020 7375  lse):.        su
+00017910: 7065 7228 7479 7065 2873 656c 6629 2c20  per(type(self), 
+00017920: 7365 6c66 292e 5f5f 696e 6974 5f5f 286d  self).__init__(m
+00017930: 6174 6c61 625f 6d6f 6465 6c3d 6d61 746c  atlab_model=matl
+00017940: 6162 5f6d 6f64 656c 290a 2020 2020 2020  ab_model).      
+00017950: 2020 7365 6c66 2e66 6e61 6d65 203d 2069    self.fname = i
+00017960: 6e73 7065 6374 2e67 6574 6669 6c65 2869  nspect.getfile(i
+00017970: 6e73 7065 6374 2e63 7572 7265 6e74 6672  nspect.currentfr
+00017980: 616d 6528 2929 0a0a 2020 2020 6465 6620  ame())..    def 
+00017990: 7661 6c69 6461 7465 2873 656c 6629 3a0a  validate(self):.
+000179a0: 2020 2020 2020 2020 7061 7373 0a0a 2020          pass..  
+000179b0: 2020 6465 6620 7369 6d75 6c61 7465 2873    def simulate(s
+000179c0: 656c 662c 2070 726f 6365 7373 5f69 643d  elf, process_id=
+000179d0: 4e6f 6e65 2c20 6d61 746c 6162 5f65 6e67  None, matlab_eng
+000179e0: 696e 653d 4e6f 6e65 293a 0a20 2020 2020  ine=None):.     
+000179f0: 2020 2023 2064 6574 6572 6d69 6e65 206f     # determine o
+00017a00: 7574 7075 740a 2020 2020 2020 2020 7920  utput.        y 
+00017a10: 3d20 6e70 2e6f 6e65 7328 6e70 2e61 7272  = np.ones(np.arr
+00017a20: 6179 2873 656c 662e 705b 6c69 7374 2873  ay(self.p[list(s
+00017a30: 656c 662e 702e 6b65 7973 2829 295b 305d  elf.p.keys())[0]
+00017a40: 5d29 2e73 697a 6529 0a0a 2020 2020 2020  ]).size)..      
+00017a50: 2020 666f 7220 692c 206b 6579 2069 6e20    for i, key in 
+00017a60: 656e 756d 6572 6174 6528 7365 6c66 2e70  enumerate(self.p
+00017a70: 2e6b 6579 7328 2929 3a0a 2020 2020 2020  .keys()):.      
+00017a80: 2020 2020 2020 6966 2022 7822 2069 6e20        if "x" in 
+00017a90: 6b65 793a 0a20 2020 2020 2020 2020 2020  key:.           
+00017aa0: 2020 2020 2079 202a 3d20 286e 702e 6162       y *= (np.ab
+00017ab0: 7328 342e 3020 2a20 7365 6c66 2e70 5b6b  s(4.0 * self.p[k
+00017ac0: 6579 5d20 2d20 3229 202b 2073 656c 662e  ey] - 2) + self.
+00017ad0: 705b 2261 225d 5b3a 2c20 695d 2920 2f20  p["a"][:, i]) / 
+00017ae0: 2831 2e30 202b 2073 656c 662e 705b 2261  (1.0 + self.p["a
+00017af0: 225d 5b3a 2c20 695d 290a 0a20 2020 2020  "][:, i])..     
+00017b00: 2020 2079 5f6f 7574 203d 2079 5b3a 2c20     y_out = y[:, 
+00017b10: 6e70 2e6e 6577 6178 6973 5d0a 0a20 2020  np.newaxis]..   
+00017b20: 2020 2020 2072 6574 7572 6e20 795f 6f75       return y_ou
+00017b30: 740a 0a0a 636c 6173 7320 4269 6e61 7279  t...class Binary
+00017b40: 4469 7363 6f6e 7469 6e75 6f75 7353 7068  DiscontinuousSph
+00017b50: 6572 6528 4162 7374 7261 6374 4d6f 6465  ere(AbstractMode
+00017b60: 6c29 3a0a 2020 2020 2222 220a 2020 2020  l):.    """.    
+00017b70: 4e2d 6469 6d65 6e73 696f 6e61 6c20 7465  N-dimensional te
+00017b80: 7374 6675 6e63 7469 6f6e 2063 6f6e 7461  stfunction conta
+00017b90: 696e 696e 6720 6120 7370 6865 7269 6361  ining a spherica
+00017ba0: 6c20 6469 7363 6f6e 7469 6e75 6974 792e  l discontinuity.
+00017bb0: 0a20 2020 2049 6e73 6964 6520 7468 6520  .    Inside the 
+00017bc0: 7370 6865 7265 2074 6865 206f 7574 7075  sphere the outpu
+00017bd0: 7420 6973 2032 2061 6e64 206f 7574 7369  t is 2 and outsi
+00017be0: 6465 206f 6620 7468 6520 7370 6865 7265  de of the sphere
+00017bf0: 2069 7420 6973 2031 2e0a 0a20 2020 202e   it is 1...    .
+00017c00: 2e20 6d61 7468 3a3a 0a20 2020 2020 2020  . math::.       
+00017c10: 7920 3d20 5c5c 6265 6769 6e7b 6361 7365  y = \\begin{case
+00017c20: 737d 0a20 2020 2020 2020 322c 2026 205c  s}.       2, & \
+00017c30: 5c74 6578 747b 6966 207d 205c 5c73 7172  \text{if } \\sqr
+00017c40: 747b 5c5c 7375 6d5f 7b69 3d31 7d5e 7b4e  t{\\sum_{i=1}^{N
+00017c50: 7d28 785f 692d 302e 3529 5e32 7d20 5c5c  }(x_i-0.5)^2} \\
+00017c60: 6c65 7120 302e 3235 205c 5c5c 5c0a 2020  leq 0.25 \\\\.  
+00017c70: 2020 2020 2031 2c20 2620 5c5c 7465 7874       1, & \\text
+00017c80: 7b6f 7468 6572 7769 7365 7d0a 2020 2020  {otherwise}.    
+00017c90: 2020 205c 5c65 6e64 7b63 6173 6573 7d0a     \\end{cases}.
+00017ca0: 0a20 2020 2050 6172 616d 6574 6572 730a  .    Parameters.
+00017cb0: 2020 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0a20      ----------. 
+00017cc0: 2020 2070 5b22 7831 225d 3a20 666c 6f61     p["x1"]: floa
+00017cd0: 7420 6f72 206e 6461 7272 6179 206f 6620  t or ndarray of 
+00017ce0: 666c 6f61 7420 5b6e 5f67 7269 645d 0a20  float [n_grid]. 
+00017cf0: 2020 2020 2020 2046 6972 7374 2070 6172         First par
+00017d00: 616d 6574 6572 205b 302c 2031 5d0a 2020  ameter [0, 1].  
+00017d10: 2020 705b 2278 6922 5d3a 2066 6c6f 6174    p["xi"]: float
+00017d20: 206f 7220 6e64 6172 7261 7920 6f66 2066   or ndarray of f
+00017d30: 6c6f 6174 205b 6e5f 6772 6964 5d0a 2020  loat [n_grid].  
+00017d40: 2020 2020 2020 692d 7468 2070 6172 616d        i-th param
+00017d50: 6574 6572 2064 6566 696e 6564 2069 6e20  eter defined in 
+00017d60: 5b30 2c20 315d 0a20 2020 2070 5b22 784e  [0, 1].    p["xN
+00017d70: 225d 3a20 666c 6f61 7420 6f72 206e 6461  "]: float or nda
+00017d80: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
+00017d90: 5f67 7269 645d 0a20 2020 2020 2020 204e  _grid].        N
+00017da0: 7468 2070 6172 616d 6574 6572 205b 302c  th parameter [0,
+00017db0: 2031 5d0a 0a20 2020 2052 6574 7572 6e73   1]..    Returns
+00017dc0: 0a20 2020 202d 2d2d 2d2d 2d2d 0a20 2020  .    -------.   
+00017dd0: 2079 3a20 6e64 6172 7261 7920 6f66 2066   y: ndarray of f
+00017de0: 6c6f 6174 205b 6e5f 6772 6964 2078 2031  loat [n_grid x 1
+00017df0: 5d0a 2020 2020 2020 2020 4f75 7470 7574  ].        Output
+00017e00: 2064 6174 610a 0a20 2020 204e 6f74 6573   data..    Notes
+00017e10: 0a20 2020 202d 2d2d 2d2d 0a20 2020 202e  .    -----.    .
+00017e20: 2e20 706c 6f74 3a3a 0a0a 2020 2020 2020  . plot::..      
+00017e30: 2069 6d70 6f72 7420 6e75 6d70 7920 6173   import numpy as
+00017e40: 206e 700a 2020 2020 2020 2066 726f 6d20   np.       from 
+00017e50: 7079 6770 632e 7465 7374 6675 6e63 7469  pygpc.testfuncti
+00017e60: 6f6e 7320 696d 706f 7274 2070 6c6f 745f  ons import plot_
+00017e70: 7465 7374 6675 6e63 7469 6f6e 2061 7320  testfunction as 
+00017e80: 706c 6f74 0a20 2020 2020 2020 6672 6f6d  plot.       from
+00017e90: 2063 6f6c 6c65 6374 696f 6e73 2069 6d70   collections imp
+00017ea0: 6f72 7420 4f72 6465 7265 6444 6963 740a  ort OrderedDict.
+00017eb0: 0a20 2020 2020 2020 7061 7261 6d65 7465  .       paramete
+00017ec0: 7273 203d 204f 7264 6572 6564 4469 6374  rs = OrderedDict
+00017ed0: 2829 0a20 2020 2020 2020 7061 7261 6d65  ().       parame
+00017ee0: 7465 7273 5b22 7831 225d 203d 206e 702e  ters["x1"] = np.
+00017ef0: 6c69 6e73 7061 6365 2830 2c20 312c 2035  linspace(0, 1, 5
+00017f00: 3030 290a 2020 2020 2020 2070 6172 616d  00).       param
+00017f10: 6574 6572 735b 2278 3222 5d20 3d20 6e70  eters["x2"] = np
+00017f20: 2e6c 696e 7370 6163 6528 302c 2031 2c20  .linspace(0, 1, 
+00017f30: 3530 3029 0a0a 2020 2020 2020 2070 6c6f  500)..       plo
+00017f40: 7428 2242 696e 6172 7944 6973 636f 6e74  t("BinaryDiscont
+00017f50: 696e 756f 7573 5370 6865 7265 222c 2070  inuousSphere", p
+00017f60: 6172 616d 6574 6572 7329 0a20 2020 2022  arameters).    "
+00017f70: 2222 0a0a 2020 2020 6465 6620 5f5f 696e  ""..    def __in
+00017f80: 6974 5f5f 2873 656c 662c 206d 6174 6c61  it__(self, matla
+00017f90: 625f 6d6f 6465 6c3d 4661 6c73 6529 3a0a  b_model=False):.
+00017fa0: 2020 2020 2020 2020 7375 7065 7228 7479          super(ty
+00017fb0: 7065 2873 656c 6629 2c20 7365 6c66 292e  pe(self), self).
+00017fc0: 5f5f 696e 6974 5f5f 286d 6174 6c61 625f  __init__(matlab_
+00017fd0: 6d6f 6465 6c3d 6d61 746c 6162 5f6d 6f64  model=matlab_mod
+00017fe0: 656c 290a 2020 2020 2020 2020 7365 6c66  el).        self
+00017ff0: 2e66 6e61 6d65 203d 2069 6e73 7065 6374  .fname = inspect
+00018000: 2e67 6574 6669 6c65 2869 6e73 7065 6374  .getfile(inspect
+00018010: 2e63 7572 7265 6e74 6672 616d 6528 2929  .currentframe())
+00018020: 0a0a 2020 2020 6465 6620 7661 6c69 6461  ..    def valida
+00018030: 7465 2873 656c 6629 3a0a 2020 2020 2020  te(self):.      
+00018040: 2020 7061 7373 0a0a 2020 2020 6465 6620    pass..    def 
+00018050: 7369 6d75 6c61 7465 2873 656c 662c 2070  simulate(self, p
+00018060: 726f 6365 7373 5f69 643d 4e6f 6e65 2c20  rocess_id=None, 
+00018070: 6d61 746c 6162 5f65 6e67 696e 653d 4e6f  matlab_engine=No
+00018080: 6e65 293a 0a0a 2020 2020 2020 2020 7820  ne):..        x 
+00018090: 3d20 6e70 2e76 7374 6163 6b28 5b73 656c  = np.vstack([sel
+000180a0: 662e 705b 6b65 795d 2e73 7175 6565 7a65  f.p[key].squeeze
+000180b0: 2829 2066 6f72 206b 6579 2069 6e20 7365  () for key in se
+000180c0: 6c66 2e70 2e6b 6579 7328 295d 290a 0a20  lf.p.keys()]).. 
+000180d0: 2020 2020 2020 2079 203d 206e 702e 6f6e         y = np.on
+000180e0: 6573 2878 2e73 6861 7065 5b31 5d29 0a20  es(x.shape[1]). 
+000180f0: 2020 2020 2020 2079 5b6e 702e 6c69 6e61         y[np.lina
+00018100: 6c67 2e6e 6f72 6d28 782d 302e 352c 2061  lg.norm(x-0.5, a
+00018110: 7869 733d 3029 203c 3d20 302e 3235 5d20  xis=0) <= 0.25] 
+00018120: 3d20 322e 0a0a 2020 2020 2020 2020 795f  = 2...        y_
+00018130: 6f75 7420 3d20 795b 3a2c 206e 702e 6e65  out = y[:, np.ne
+00018140: 7761 7869 735d 0a0a 2020 2020 2020 2020  waxis]..        
+00018150: 7265 7475 726e 2079 5f6f 7574 0a0a 0a63  return y_out...c
+00018160: 6c61 7373 2043 6c75 7374 6572 3353 696d  lass Cluster3Sim
+00018170: 706c 6528 4162 7374 7261 6374 4d6f 6465  ple(AbstractMode
+00018180: 6c29 3a0a 2020 2020 2222 220a 2020 2020  l):.    """.    
+00018190: 322d 6469 6d65 6e73 696f 6e61 6c20 7465  2-dimensional te
+000181a0: 7374 6675 6e63 7469 6f6e 2063 6f6e 7461  stfunction conta
+000181b0: 696e 696e 6720 6120 7370 6865 7269 6361  ining a spherica
+000181c0: 6c20 616e 6420 6120 6c69 6e65 6172 2064  l and a linear d
+000181d0: 6973 636f 6e74 696e 7569 7479 2e0a 0a20  iscontinuity... 
+000181e0: 2020 202e 2e20 6d61 7468 3a3a 0a20 2020     .. math::.   
+000181f0: 2020 2020 7920 3d20 5c5c 6265 6769 6e7b      y = \\begin{
+00018200: 6361 7365 737d 0a20 2020 2020 2020 322c  cases}.       2,
+00018210: 2026 205c 5c74 6578 747b 6966 207d 205c   & \\text{if } \
+00018220: 5c73 7172 747b 5c5c 7375 6d5f 7b69 3d31  \sqrt{\\sum_{i=1
+00018230: 7d5e 7b4e 7d28 785f 692d 302e 3529 5e32  }^{N}(x_i-0.5)^2
+00018240: 7d20 5c5c 6c65 7120 302e 3235 205c 5c5c  } \\leq 0.25 \\\
+00018250: 5c0a 2020 2020 2020 2031 2c20 2620 5c5c  \.       1, & \\
+00018260: 7465 7874 7b6f 7468 6572 7769 7365 7d0a  text{otherwise}.
+00018270: 2020 2020 2020 205c 5c65 6e64 7b63 6173         \\end{cas
+00018280: 6573 7d0a 0a20 2020 2050 6172 616d 6574  es}..    Paramet
+00018290: 6572 730a 2020 2020 2d2d 2d2d 2d2d 2d2d  ers.    --------
+000182a0: 2d2d 0a20 2020 2070 5b22 7831 225d 3a20  --.    p["x1"]: 
+000182b0: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
+000182c0: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
+000182d0: 645d 0a20 2020 2020 2020 2046 6972 7374  d].        First
+000182e0: 2070 6172 616d 6574 6572 205b 302c 2031   parameter [0, 1
+000182f0: 5d0a 2020 2020 705b 2278 3222 5d3a 2066  ].    p["x2"]: f
+00018300: 6c6f 6174 206f 7220 6e64 6172 7261 7920  loat or ndarray 
+00018310: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
+00018320: 5d0a 2020 2020 2020 2020 322d 6e64 2070  ].        2-nd p
+00018330: 6172 616d 6574 6572 2064 6566 696e 6564  arameter defined
+00018340: 2069 6e20 5b30 2c20 315d 0a0a 2020 2020   in [0, 1]..    
+00018350: 5265 7475 726e 730a 2020 2020 2d2d 2d2d  Returns.    ----
+00018360: 2d2d 2d0a 2020 2020 793a 206e 6461 7272  ---.    y: ndarr
+00018370: 6179 206f 6620 666c 6f61 7420 5b6e 5f67  ay of float [n_g
+00018380: 7269 6420 7820 315d 0a20 2020 2020 2020  rid x 1].       
+00018390: 204f 7574 7075 7420 6461 7461 0a0a 2020   Output data..  
+000183a0: 2020 4e6f 7465 730a 2020 2020 2d2d 2d2d    Notes.    ----
+000183b0: 2d0a 2020 2020 2e2e 2070 6c6f 743a 3a0a  -.    .. plot::.
+000183c0: 0a20 2020 2020 2020 696d 706f 7274 206e  .       import n
+000183d0: 756d 7079 2061 7320 6e70 0a20 2020 2020  umpy as np.     
+000183e0: 2020 6672 6f6d 2070 7967 7063 2e74 6573    from pygpc.tes
+000183f0: 7466 756e 6374 696f 6e73 2069 6d70 6f72  tfunctions impor
+00018400: 7420 706c 6f74 5f74 6573 7466 756e 6374  t plot_testfunct
+00018410: 696f 6e20 6173 2070 6c6f 740a 2020 2020  ion as plot.    
+00018420: 2020 2066 726f 6d20 636f 6c6c 6563 7469     from collecti
+00018430: 6f6e 7320 696d 706f 7274 204f 7264 6572  ons import Order
+00018440: 6564 4469 6374 0a0a 2020 2020 2020 2070  edDict..       p
+00018450: 6172 616d 6574 6572 7320 3d20 4f72 6465  arameters = Orde
+00018460: 7265 6444 6963 7428 290a 2020 2020 2020  redDict().      
+00018470: 2070 6172 616d 6574 6572 735b 2278 3122   parameters["x1"
+00018480: 5d20 3d20 6e70 2e6c 696e 7370 6163 6528  ] = np.linspace(
+00018490: 302c 2031 2c20 3530 3029 0a20 2020 2020  0, 1, 500).     
+000184a0: 2020 7061 7261 6d65 7465 7273 5b22 7832    parameters["x2
+000184b0: 225d 203d 206e 702e 6c69 6e73 7061 6365  "] = np.linspace
+000184c0: 2830 2c20 312c 2035 3030 290a 0a20 2020  (0, 1, 500)..   
+000184d0: 2020 2020 706c 6f74 2822 436c 7573 7465      plot("Cluste
+000184e0: 7233 5369 6d70 6c65 222c 2070 6172 616d  r3Simple", param
+000184f0: 6574 6572 7329 0a20 2020 2022 2222 0a0a  eters).    """..
+00018500: 2020 2020 6465 6620 5f5f 696e 6974 5f5f      def __init__
+00018510: 2873 656c 662c 206d 6174 6c61 625f 6d6f  (self, matlab_mo
+00018520: 6465 6c3d 4661 6c73 6529 3a0a 2020 2020  del=False):.    
+00018530: 2020 2020 7375 7065 7228 7479 7065 2873      super(type(s
+00018540: 656c 6629 2c20 7365 6c66 292e 5f5f 696e  elf), self).__in
+00018550: 6974 5f5f 286d 6174 6c61 625f 6d6f 6465  it__(matlab_mode
+00018560: 6c3d 6d61 746c 6162 5f6d 6f64 656c 290a  l=matlab_model).
+00018570: 2020 2020 2020 2020 7365 6c66 2e66 6e61          self.fna
+00018580: 6d65 203d 2069 6e73 7065 6374 2e67 6574  me = inspect.get
+00018590: 6669 6c65 2869 6e73 7065 6374 2e63 7572  file(inspect.cur
+000185a0: 7265 6e74 6672 616d 6528 2929 0a0a 2020  rentframe())..  
+000185b0: 2020 6465 6620 7661 6c69 6461 7465 2873    def validate(s
+000185c0: 656c 6629 3a0a 2020 2020 2020 2020 7061  elf):.        pa
+000185d0: 7373 0a0a 2020 2020 6465 6620 7369 6d75  ss..    def simu
+000185e0: 6c61 7465 2873 656c 662c 2070 726f 6365  late(self, proce
+000185f0: 7373 5f69 643d 4e6f 6e65 2c20 6d61 746c  ss_id=None, matl
+00018600: 6162 5f65 6e67 696e 653d 4e6f 6e65 293a  ab_engine=None):
+00018610: 0a0a 2020 2020 2020 2020 7820 3d20 6e70  ..        x = np
+00018620: 2e76 7374 6163 6b28 5b73 656c 662e 705b  .vstack([self.p[
+00018630: 6b65 795d 2e73 7175 6565 7a65 2829 2066  key].squeeze() f
+00018640: 6f72 206b 6579 2069 6e20 7365 6c66 2e70  or key in self.p
+00018650: 2e6b 6579 7328 295d 290a 0a20 2020 2020  .keys()])..     
+00018660: 2020 2079 203d 206e 702e 6f6e 6573 2878     y = np.ones(x
+00018670: 2e73 6861 7065 5b31 5d29 0a20 2020 2020  .shape[1]).     
+00018680: 2020 2079 5b6e 702e 6c69 6e61 6c67 2e6e     y[np.linalg.n
+00018690: 6f72 6d28 782c 2061 7869 733d 3029 203c  orm(x, axis=0) <
+000186a0: 3d20 302e 3235 5d20 3d20 322e 0a20 2020  = 0.25] = 2..   
+000186b0: 2020 2020 2079 5b6e 702e 7375 6d28 782c       y[np.sum(x,
+000186c0: 2061 7869 733d 3029 203e 3d20 312e 355d   axis=0) >= 1.5]
+000186d0: 203d 2033 2e0a 0a20 2020 2020 2020 2079   = 3...        y
+000186e0: 5f6f 7574 203d 2079 5b3a 2c20 6e70 2e6e  _out = y[:, np.n
+000186f0: 6577 6178 6973 5d0a 0a20 2020 2020 2020  ewaxis]..       
+00018700: 2072 6574 7572 6e20 795f 6f75 740a 0a0a   return y_out...
+00018710: 636c 6173 7320 436f 6e74 696e 756f 7573  class Continuous
+00018720: 4469 7363 6f6e 7469 6e75 6f75 7353 7068  DiscontinuousSph
+00018730: 6572 6528 4162 7374 7261 6374 4d6f 6465  ere(AbstractMode
+00018740: 6c29 3a0a 2020 2020 2222 220a 2020 2020  l):.    """.    
+00018750: 4e2d 6469 6d65 6e73 696f 6e61 6c20 7465  N-dimensional te
+00018760: 7374 6675 6e63 7469 6f6e 2063 6f6e 7461  stfunction conta
+00018770: 696e 696e 6720 6120 7370 6865 7269 6361  ining a spherica
+00018780: 6c20 6469 7363 6f6e 7469 6e75 6974 792e  l discontinuity.
+00018790: 0a20 2020 2049 6e73 6964 6520 7468 6520  .    Inside the 
+000187a0: 7370 6865 7265 2074 6865 206f 7574 7075  sphere the outpu
+000187b0: 7420 636f 7272 6573 706f 6e64 7320 746f  t corresponds to
+000187c0: 2074 6865 204d 616e 7566 6163 7475 7265   the Manufacture
+000187d0: 4465 6361 7920 6675 6e63 7469 6f6e 2028  Decay function (
+000187e0: 7368 6966 7465 6420 6279 202d 3229 0a20  shifted by -2). 
+000187f0: 2020 2061 6e64 206f 7574 7369 6465 206f     and outside o
+00018800: 6620 7468 6520 7370 6865 7265 2069 7420  f the sphere it 
+00018810: 636f 7272 6573 706f 6e64 2074 6f20 7468  correspond to th
+00018820: 6520 4765 6e7a 4f73 6369 6c6c 6174 6f72  e GenzOscillator
+00018830: 7920 7465 7374 6675 6e63 7469 6f6e 2028  y testfunction (
+00018840: 7363 616c 6564 2062 7920 3229 2e0a 0a20  scaled by 2)... 
+00018850: 2020 202e 2e20 6d61 7468 3a3a 0a20 2020     .. math::.   
+00018860: 2020 2020 7920 3d20 5c5c 6265 6769 6e7b      y = \\begin{
+00018870: 6361 7365 737d 0a20 2020 2020 2020 5c5c  cases}.       \\
+00018880: 7465 7874 7b4d 616e 7566 6163 7475 7265  text{Manufacture
+00018890: 4465 6361 797d 2878 2920 2d20 322c 2026  Decay}(x) - 2, &
+000188a0: 205c 5c74 6578 747b 6966 207d 205c 5c73   \\text{if } \\s
+000188b0: 7172 747b 5c5c 7375 6d5f 7b69 3d31 7d5e  qrt{\\sum_{i=1}^
+000188c0: 7b4e 7d78 5f69 5e32 7d20 5c5c 6c65 7120  {N}x_i^2} \\leq 
+000188d0: 302e 3235 205c 5c5c 5c0a 2020 2020 2020  0.25 \\\\.      
+000188e0: 205c 5c74 6578 747b 4765 6e7a 4f73 6369   \\text{GenzOsci
+000188f0: 6c6c 6174 6f72 797d 2878 2920 2a20 322c  llatory}(x) * 2,
+00018900: 2026 205c 5c74 6578 747b 6f74 6865 7277   & \\text{otherw
+00018910: 6973 657d 0a20 2020 2020 2020 5c5c 656e  ise}.       \\en
+00018920: 647b 6361 7365 737d 0a0a 2020 2020 5061  d{cases}..    Pa
+00018930: 7261 6d65 7465 7273 0a20 2020 202d 2d2d  rameters.    ---
+00018940: 2d2d 2d2d 2d2d 2d0a 2020 2020 705b 2278  -------.    p["x
+00018950: 3122 5d3a 2066 6c6f 6174 206f 7220 6e64  1"]: float or nd
+00018960: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
+00018970: 6e5f 6772 6964 5d0a 2020 2020 2020 2020  n_grid].        
+00018980: 4669 7273 7420 7061 7261 6d65 7465 7220  First parameter 
+00018990: 5b30 2c20 315d 0a20 2020 2070 5b22 7869  [0, 1].    p["xi
+000189a0: 225d 3a20 666c 6f61 7420 6f72 206e 6461  "]: float or nda
+000189b0: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
+000189c0: 5f67 7269 645d 0a20 2020 2020 2020 2069  _grid].        i
+000189d0: 2d74 6820 7061 7261 6d65 7465 7220 6465  -th parameter de
+000189e0: 6669 6e65 6420 696e 205b 302c 2031 5d0a  fined in [0, 1].
+000189f0: 2020 2020 705b 2278 4e22 5d3a 2066 6c6f      p["xN"]: flo
+00018a00: 6174 206f 7220 6e64 6172 7261 7920 6f66  at or ndarray of
+00018a10: 2066 6c6f 6174 205b 6e5f 6772 6964 5d0a   float [n_grid].
+00018a20: 2020 2020 2020 2020 4e74 6820 7061 7261          Nth para
+00018a30: 6d65 7465 7220 5b30 2c20 315d 0a0a 2020  meter [0, 1]..  
+00018a40: 2020 5265 7475 726e 730a 2020 2020 2d2d    Returns.    --
+00018a50: 2d2d 2d2d 2d0a 2020 2020 793a 206e 6461  -----.    y: nda
+00018a60: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
+00018a70: 5f67 7269 6420 7820 315d 0a20 2020 2020  _grid x 1].     
+00018a80: 2020 204f 7574 7075 7420 6461 7461 0a0a     Output data..
+00018a90: 2020 2020 4e6f 7465 730a 2020 2020 2d2d      Notes.    --
+00018aa0: 2d2d 2d0a 2020 2020 2e2e 2070 6c6f 743a  ---.    .. plot:
+00018ab0: 3a0a 0a20 2020 2020 2020 696d 706f 7274  :..       import
+00018ac0: 206e 756d 7079 2061 7320 6e70 0a20 2020   numpy as np.   
+00018ad0: 2020 2020 6672 6f6d 2070 7967 7063 2e74      from pygpc.t
+00018ae0: 6573 7466 756e 6374 696f 6e73 2069 6d70  estfunctions imp
+00018af0: 6f72 7420 706c 6f74 5f74 6573 7466 756e  ort plot_testfun
+00018b00: 6374 696f 6e20 6173 2070 6c6f 740a 2020  ction as plot.  
+00018b10: 2020 2020 2066 726f 6d20 636f 6c6c 6563       from collec
+00018b20: 7469 6f6e 7320 696d 706f 7274 204f 7264  tions import Ord
+00018b30: 6572 6564 4469 6374 0a0a 2020 2020 2020  eredDict..      
+00018b40: 2070 6172 616d 6574 6572 7320 3d20 4f72   parameters = Or
+00018b50: 6465 7265 6444 6963 7428 290a 2020 2020  deredDict().    
+00018b60: 2020 2070 6172 616d 6574 6572 735b 2278     parameters["x
+00018b70: 3122 5d20 3d20 6e70 2e6c 696e 7370 6163  1"] = np.linspac
+00018b80: 6528 302c 2031 2c20 3530 3029 0a20 2020  e(0, 1, 500).   
+00018b90: 2020 2020 7061 7261 6d65 7465 7273 5b22      parameters["
+00018ba0: 7832 225d 203d 206e 702e 6c69 6e73 7061  x2"] = np.linspa
+00018bb0: 6365 2830 2c20 312c 2035 3030 290a 0a20  ce(0, 1, 500).. 
+00018bc0: 2020 2020 2020 706c 6f74 2822 436f 6e74        plot("Cont
+00018bd0: 696e 756f 7573 4469 7363 6f6e 7469 6e75  inuousDiscontinu
+00018be0: 6f75 7353 7068 6572 6522 2c20 7061 7261  ousSphere", para
+00018bf0: 6d65 7465 7273 290a 2020 2020 2222 220a  meters).    """.
+00018c00: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
+00018c10: 5f28 7365 6c66 2c20 6d61 746c 6162 5f6d  _(self, matlab_m
+00018c20: 6f64 656c 3d46 616c 7365 293a 0a20 2020  odel=False):.   
+00018c30: 2020 2020 2073 7570 6572 2874 7970 6528       super(type(
+00018c40: 7365 6c66 292c 2073 656c 6629 2e5f 5f69  self), self).__i
+00018c50: 6e69 745f 5f28 6d61 746c 6162 5f6d 6f64  nit__(matlab_mod
+00018c60: 656c 3d6d 6174 6c61 625f 6d6f 6465 6c29  el=matlab_model)
+00018c70: 0a20 2020 2020 2020 2073 656c 662e 666e  .        self.fn
+00018c80: 616d 6520 3d20 696e 7370 6563 742e 6765  ame = inspect.ge
+00018c90: 7466 696c 6528 696e 7370 6563 742e 6375  tfile(inspect.cu
+00018ca0: 7272 656e 7466 7261 6d65 2829 290a 0a20  rrentframe()).. 
+00018cb0: 2020 2064 6566 2076 616c 6964 6174 6528     def validate(
+00018cc0: 7365 6c66 293a 0a20 2020 2020 2020 2070  self):.        p
+00018cd0: 6173 730a 0a20 2020 2064 6566 2073 696d  ass..    def sim
+00018ce0: 756c 6174 6528 7365 6c66 2c20 7072 6f63  ulate(self, proc
+00018cf0: 6573 735f 6964 3d4e 6f6e 652c 206d 6174  ess_id=None, mat
+00018d00: 6c61 625f 656e 6769 6e65 3d4e 6f6e 6529  lab_engine=None)
+00018d10: 3a0a 0a20 2020 2020 2020 2066 6f72 206b  :..        for k
+00018d20: 6579 2069 6e20 7365 6c66 2e70 2e6b 6579  ey in self.p.key
+00018d30: 7328 293a 0a20 2020 2020 2020 2020 2020  s():.           
+00018d40: 2069 6620 7365 6c66 2e70 5b6b 6579 5d2e   if self.p[key].
+00018d50: 6e64 696d 203d 3d20 313a 0a20 2020 2020  ndim == 1:.     
+00018d60: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+00018d70: 705b 6b65 795d 203d 2073 656c 662e 705b  p[key] = self.p[
+00018d80: 6b65 795d 5b3a 2c20 6e70 2e6e 6577 6178  key][:, np.newax
+00018d90: 6973 5d0a 0a20 2020 2020 2020 2078 203d  is]..        x =
+00018da0: 206e 702e 6873 7461 636b 285b 7365 6c66   np.hstack([self
+00018db0: 2e70 5b6b 6579 5d20 666f 7220 6b65 7920  .p[key] for key 
+00018dc0: 696e 2073 656c 662e 702e 6b65 7973 2829  in self.p.keys()
+00018dd0: 5d29 0a0a 2020 2020 2020 2020 7920 3d20  ])..        y = 
+00018de0: 6e70 2e7a 6572 6f73 2878 2e73 6861 7065  np.zeros(x.shape
+00018df0: 5b30 5d29 0a20 2020 2020 2020 206d 6173  [0]).        mas
+00018e00: 6b20 3d20 286e 702e 6c69 6e61 6c67 2e6e  k = (np.linalg.n
+00018e10: 6f72 6d28 782d 302e 352c 2061 7869 733d  orm(x-0.5, axis=
+00018e20: 3129 203c 3d20 302e 3235 292e 666c 6174  1) <= 0.25).flat
+00018e30: 7465 6e28 290a 0a20 2020 2020 2020 2070  ten()..        p
+00018e40: 5f31 203d 204f 7264 6572 6564 4469 6374  _1 = OrderedDict
+00018e50: 2829 0a20 2020 2020 2020 2070 5f32 203d  ().        p_2 =
+00018e60: 204f 7264 6572 6564 4469 6374 2829 0a0a   OrderedDict()..
+00018e70: 2020 2020 2020 2020 666f 7220 692c 206b          for i, k
+00018e80: 6579 2069 6e20 656e 756d 6572 6174 6528  ey in enumerate(
+00018e90: 7365 6c66 2e70 2e6b 6579 7328 2929 3a0a  self.p.keys()):.
+00018ea0: 2020 2020 2020 2020 2020 2020 705f 315b              p_1[
+00018eb0: 6b65 795d 203d 2078 5b6d 6173 6b2c 2069  key] = x[mask, i
+00018ec0: 5d0a 2020 2020 2020 2020 2020 2020 705f  ].            p_
+00018ed0: 325b 6b65 795d 203d 2078 5b6e 702e 6c6f  2[key] = x[np.lo
+00018ee0: 6769 6361 6c5f 6e6f 7428 6d61 736b 292c  gical_not(mask),
+00018ef0: 2069 5d0a 0a20 2020 2020 2020 206d 6f64   i]..        mod
+00018f00: 656c 5f31 203d 204d 616e 7566 6163 7475  el_1 = Manufactu
+00018f10: 7265 4465 6361 7928 292e 7365 745f 7061  reDecay().set_pa
+00018f20: 7261 6d65 7465 7273 2870 5f31 290a 2020  rameters(p_1).  
+00018f30: 2020 2020 2020 6d6f 6465 6c5f 3220 3d20        model_2 = 
+00018f40: 4765 6e7a 4f73 6369 6c6c 6174 6f72 7928  GenzOscillatory(
+00018f50: 292e 7365 745f 7061 7261 6d65 7465 7273  ).set_parameters
+00018f60: 2870 5f32 290a 0a20 2020 2020 2020 2079  (p_2)..        y
+00018f70: 5f31 203d 206d 6f64 656c 5f31 2e73 696d  _1 = model_1.sim
+00018f80: 756c 6174 6528 2920 2d20 320a 2020 2020  ulate() - 2.    
+00018f90: 2020 2020 795f 3220 3d20 6d6f 6465 6c5f      y_2 = model_
+00018fa0: 322e 7369 6d75 6c61 7465 2829 202a 2032  2.simulate() * 2
+00018fb0: 0a0a 2020 2020 2020 2020 795b 6d61 736b  ..        y[mask
+00018fc0: 5d20 3d20 795f 312e 666c 6174 7465 6e28  ] = y_1.flatten(
+00018fd0: 290a 2020 2020 2020 2020 795b 6e70 2e6c  ).        y[np.l
+00018fe0: 6f67 6963 616c 5f6e 6f74 286d 6173 6b29  ogical_not(mask)
+00018ff0: 5d20 3d20 795f 322e 666c 6174 7465 6e28  ] = y_2.flatten(
+00019000: 290a 0a20 2020 2020 2020 2079 5f6f 7574  )..        y_out
+00019010: 203d 2079 5b3a 2c20 6e70 2e6e 6577 6178   = y[:, np.newax
+00019020: 6973 5d0a 0a20 2020 2020 2020 2072 6574  is]..        ret
+00019030: 7572 6e20 795f 6f75 740a 0a0a 636c 6173  urn y_out...clas
+00019040: 7320 4469 7363 6f6e 7469 6e75 6f75 7352  s DiscontinuousR
+00019050: 6964 6765 4d61 6e75 6661 6374 7572 6544  idgeManufactureD
+00019060: 6563 6179 2841 6273 7472 6163 744d 6f64  ecay(AbstractMod
+00019070: 656c 293a 0a20 2020 2022 2222 0a20 2020  el):.    """.   
+00019080: 204e 2d64 696d 656e 7369 6f6e 616c 2074   N-dimensional t
+00019090: 6573 7466 756e 6374 696f 6e20 636f 6e74  estfunction cont
+000190a0: 6169 6e69 6e67 2061 206c 696e 6561 7220  aining a linear 
+000190b0: 6469 7363 6f6e 7469 6e75 6974 792e 0a20  discontinuity.. 
+000190c0: 2020 204f 6e20 7468 6520 6f6e 6520 7369     On the one si
+000190d0: 6465 2074 6865 206f 7574 7075 7420 636f  de the output co
+000190e0: 7272 6573 706f 6e64 7320 746f 2074 6865  rresponds to the
+000190f0: 2052 6964 6765 2066 756e 6374 696f 6e0a   Ridge function.
+00019100: 2020 2020 616e 6420 6f6e 2074 6865 206f      and on the o
+00019110: 7468 6572 2073 6964 6520 6974 2063 6f72  ther side it cor
+00019120: 7265 7370 6f6e 6420 746f 2074 6865 204d  respond to the M
+00019130: 616e 7566 6163 7475 7265 4465 6361 7920  anufactureDecay 
+00019140: 7465 7374 6675 6e63 7469 6f6e 2e0a 0a20  testfunction... 
+00019150: 2020 202e 2e20 6d61 7468 3a3a 0a20 2020     .. math::.   
+00019160: 2020 2020 7920 3d20 5c5c 6265 6769 6e7b      y = \\begin{
+00019170: 6361 7365 737d 0a20 2020 2020 2020 5c5c  cases}.       \\
+00019180: 7465 7874 7b4d 616e 7566 6163 7475 7265  text{Manufacture
+00019190: 4465 6361 797d 2878 292c 2026 205c 5c74  Decay}(x), & \\t
+000191a0: 6578 747b 6966 207d 205c 5c73 756d 5f7b  ext{if } \\sum_{
+000191b0: 693d 317d 5e7b 4e7d 785f 6920 5c5c 6c65  i=1}^{N}x_i \\le
+000191c0: 7120 3120 5c5c 5c5c 0a20 2020 2020 2020  q 1 \\\\.       
+000191d0: 5c5c 7465 7874 7b52 6964 6765 7d28 7829  \\text{Ridge}(x)
+000191e0: 2c20 2620 5c5c 7465 7874 7b6f 7468 6572  , & \\text{other
+000191f0: 7769 7365 7d0a 2020 2020 2020 205c 5c65  wise}.       \\e
+00019200: 6e64 7b63 6173 6573 7d0a 0a20 2020 2050  nd{cases}..    P
+00019210: 6172 616d 6574 6572 730a 2020 2020 2d2d  arameters.    --
+00019220: 2d2d 2d2d 2d2d 2d2d 0a20 2020 2070 5b22  --------.    p["
+00019230: 7831 225d 3a20 666c 6f61 7420 6f72 206e  x1"]: float or n
+00019240: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+00019250: 5b6e 5f67 7269 645d 0a20 2020 2020 2020  [n_grid].       
+00019260: 2046 6972 7374 2070 6172 616d 6574 6572   First parameter
+00019270: 205b 302c 2031 5d0a 2020 2020 705b 2278   [0, 1].    p["x
+00019280: 6922 5d3a 2066 6c6f 6174 206f 7220 6e64  i"]: float or nd
+00019290: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
+000192a0: 6e5f 6772 6964 5d0a 2020 2020 2020 2020  n_grid].        
+000192b0: 692d 7468 2070 6172 616d 6574 6572 2064  i-th parameter d
+000192c0: 6566 696e 6564 2069 6e20 5b30 2c20 315d  efined in [0, 1]
+000192d0: 0a20 2020 2070 5b22 784e 225d 3a20 666c  .    p["xN"]: fl
+000192e0: 6f61 7420 6f72 206e 6461 7272 6179 206f  oat or ndarray o
+000192f0: 6620 666c 6f61 7420 5b6e 5f67 7269 645d  f float [n_grid]
+00019300: 0a20 2020 2020 2020 204e 7468 2070 6172  .        Nth par
+00019310: 616d 6574 6572 205b 302c 2031 5d0a 0a20  ameter [0, 1].. 
+00019320: 2020 2052 6574 7572 6e73 0a20 2020 202d     Returns.    -
+00019330: 2d2d 2d2d 2d2d 0a20 2020 2079 3a20 6e64  ------.    y: nd
+00019340: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
+00019350: 6e5f 6772 6964 2078 2031 5d0a 2020 2020  n_grid x 1].    
+00019360: 2020 2020 4f75 7470 7574 2064 6174 610a      Output data.
+00019370: 0a20 2020 204e 6f74 6573 0a20 2020 202d  .    Notes.    -
+00019380: 2d2d 2d2d 0a20 2020 202e 2e20 706c 6f74  ----.    .. plot
+00019390: 3a3a 0a0a 2020 2020 2020 2069 6d70 6f72  ::..       impor
+000193a0: 7420 6e75 6d70 7920 6173 206e 700a 2020  t numpy as np.  
+000193b0: 2020 2020 2066 726f 6d20 7079 6770 632e       from pygpc.
+000193c0: 7465 7374 6675 6e63 7469 6f6e 7320 696d  testfunctions im
+000193d0: 706f 7274 2070 6c6f 745f 7465 7374 6675  port plot_testfu
+000193e0: 6e63 7469 6f6e 2061 7320 706c 6f74 0a20  nction as plot. 
+000193f0: 2020 2020 2020 6672 6f6d 2063 6f6c 6c65        from colle
+00019400: 6374 696f 6e73 2069 6d70 6f72 7420 4f72  ctions import Or
+00019410: 6465 7265 6444 6963 740a 0a20 2020 2020  deredDict..     
+00019420: 2020 7061 7261 6d65 7465 7273 203d 204f    parameters = O
+00019430: 7264 6572 6564 4469 6374 2829 0a20 2020  rderedDict().   
+00019440: 2020 2020 7061 7261 6d65 7465 7273 5b22      parameters["
+00019450: 7831 225d 203d 206e 702e 6c69 6e73 7061  x1"] = np.linspa
+00019460: 6365 2830 2c20 312c 2032 3530 290a 2020  ce(0, 1, 250).  
+00019470: 2020 2020 2070 6172 616d 6574 6572 735b       parameters[
+00019480: 2278 3222 5d20 3d20 6e70 2e6c 696e 7370  "x2"] = np.linsp
+00019490: 6163 6528 302c 2031 2c20 3235 3029 0a0a  ace(0, 1, 250)..
+000194a0: 2020 2020 2020 2070 6c6f 7428 2244 6973         plot("Dis
+000194b0: 636f 6e74 696e 756f 7573 5269 6467 654d  continuousRidgeM
+000194c0: 616e 7566 6163 7475 7265 4465 6361 7922  anufactureDecay"
+000194d0: 2c20 7061 7261 6d65 7465 7273 290a 2020  , parameters).  
+000194e0: 2020 2222 220a 0a20 2020 2064 6566 205f    """..    def _
+000194f0: 5f69 6e69 745f 5f28 7365 6c66 2c20 6d61  _init__(self, ma
+00019500: 746c 6162 5f6d 6f64 656c 3d46 616c 7365  tlab_model=False
+00019510: 293a 0a20 2020 2020 2020 2073 7570 6572  ):.        super
+00019520: 2874 7970 6528 7365 6c66 292c 2073 656c  (type(self), sel
+00019530: 6629 2e5f 5f69 6e69 745f 5f28 6d61 746c  f).__init__(matl
+00019540: 6162 5f6d 6f64 656c 3d6d 6174 6c61 625f  ab_model=matlab_
+00019550: 6d6f 6465 6c29 0a20 2020 2020 2020 2073  model).        s
+00019560: 656c 662e 666e 616d 6520 3d20 696e 7370  elf.fname = insp
+00019570: 6563 742e 6765 7466 696c 6528 696e 7370  ect.getfile(insp
+00019580: 6563 742e 6375 7272 656e 7466 7261 6d65  ect.currentframe
+00019590: 2829 290a 0a20 2020 2064 6566 2076 616c  ())..    def val
+000195a0: 6964 6174 6528 7365 6c66 293a 0a20 2020  idate(self):.   
+000195b0: 2020 2020 2070 6173 730a 0a20 2020 2064       pass..    d
+000195c0: 6566 2073 696d 756c 6174 6528 7365 6c66  ef simulate(self
+000195d0: 2c20 7072 6f63 6573 735f 6964 3d4e 6f6e  , process_id=Non
+000195e0: 652c 206d 6174 6c61 625f 656e 6769 6e65  e, matlab_engine
+000195f0: 3d4e 6f6e 6529 3a0a 0a20 2020 2020 2020  =None):..       
+00019600: 2066 6f72 206b 6579 2069 6e20 7365 6c66   for key in self
+00019610: 2e70 2e6b 6579 7328 293a 0a20 2020 2020  .p.keys():.     
+00019620: 2020 2020 2020 2069 6620 7365 6c66 2e70         if self.p
+00019630: 5b6b 6579 5d2e 6e64 696d 203d 3d20 313a  [key].ndim == 1:
+00019640: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00019650: 2073 656c 662e 705b 6b65 795d 203d 2073   self.p[key] = s
+00019660: 656c 662e 705b 6b65 795d 5b3a 2c20 6e70  elf.p[key][:, np
+00019670: 2e6e 6577 6178 6973 5d0a 0a20 2020 2020  .newaxis]..     
+00019680: 2020 2078 203d 206e 702e 6873 7461 636b     x = np.hstack
+00019690: 285b 7365 6c66 2e70 5b6b 6579 5d20 666f  ([self.p[key] fo
+000196a0: 7220 6b65 7920 696e 2073 656c 662e 702e  r key in self.p.
+000196b0: 6b65 7973 2829 5d29 0a0a 2020 2020 2020  keys()])..      
+000196c0: 2020 7920 3d20 6e70 2e7a 6572 6f73 2878    y = np.zeros(x
+000196d0: 2e73 6861 7065 5b30 5d29 0a20 2020 2020  .shape[0]).     
+000196e0: 2020 206d 6173 6b20 3d20 286e 702e 7375     mask = (np.su
+000196f0: 6d28 782c 2061 7869 733d 3129 203c 3d20  m(x, axis=1) <= 
+00019700: 312e 292e 666c 6174 7465 6e28 290a 2020  1.).flatten().  
+00019710: 2020 2020 2020 2320 6d61 736b 203d 206e        # mask = n
+00019720: 702e 6c6f 6769 6361 6c5f 616e 6428 6d61  p.logical_and(ma
+00019730: 736b 2c20 6e70 2e6c 696e 616c 672e 6e6f  sk, np.linalg.no
+00019740: 726d 2878 2d30 2e38 352c 2061 7869 733d  rm(x-0.85, axis=
+00019750: 3129 203e 202e 3829 0a0a 2020 2020 2020  1) > .8)..      
+00019760: 2020 705f 3120 3d20 4f72 6465 7265 6444    p_1 = OrderedD
+00019770: 6963 7428 290a 2020 2020 2020 2020 705f  ict().        p_
+00019780: 3220 3d20 4f72 6465 7265 6444 6963 7428  2 = OrderedDict(
+00019790: 290a 0a20 2020 2020 2020 2066 6f72 2069  )..        for i
+000197a0: 2c20 6b65 7920 696e 2065 6e75 6d65 7261  , key in enumera
+000197b0: 7465 2873 656c 662e 702e 6b65 7973 2829  te(self.p.keys()
+000197c0: 293a 0a20 2020 2020 2020 2020 2020 2070  ):.            p
+000197d0: 5f31 5b6b 6579 5d20 3d20 785b 6d61 736b  _1[key] = x[mask
+000197e0: 2c20 695d 0a20 2020 2020 2020 2020 2020  , i].           
+000197f0: 2070 5f32 5b6b 6579 5d20 3d20 785b 6e70   p_2[key] = x[np
+00019800: 2e6c 6f67 6963 616c 5f6e 6f74 286d 6173  .logical_not(mas
+00019810: 6b29 2c20 695d 0a0a 2020 2020 2020 2020  k), i]..        
+00019820: 6d6f 6465 6c5f 3120 3d20 4d61 6e75 6661  model_1 = Manufa
+00019830: 6374 7572 6544 6563 6179 2829 2e73 6574  ctureDecay().set
+00019840: 5f70 6172 616d 6574 6572 7328 705f 3129  _parameters(p_1)
+00019850: 0a20 2020 2020 2020 206d 6f64 656c 5f32  .        model_2
+00019860: 203d 2052 6964 6765 2829 2e73 6574 5f70   = Ridge().set_p
+00019870: 6172 616d 6574 6572 7328 705f 3229 0a0a  arameters(p_2)..
+00019880: 2020 2020 2020 2020 795f 3120 3d20 6d6f          y_1 = mo
+00019890: 6465 6c5f 312e 7369 6d75 6c61 7465 2829  del_1.simulate()
+000198a0: 0a20 2020 2020 2020 2079 5f32 203d 206d  .        y_2 = m
+000198b0: 6f64 656c 5f32 2e73 696d 756c 6174 6528  odel_2.simulate(
+000198c0: 290a 0a20 2020 2020 2020 2079 5b6d 6173  )..        y[mas
+000198d0: 6b5d 203d 2079 5f31 2e66 6c61 7474 656e  k] = y_1.flatten
+000198e0: 2829 0a20 2020 2020 2020 2079 5b6e 702e  ().        y[np.
+000198f0: 6c6f 6769 6361 6c5f 6e6f 7428 6d61 736b  logical_not(mask
+00019900: 295d 203d 2079 5f32 2e66 6c61 7474 656e  )] = y_2.flatten
+00019910: 2829 0a0a 2020 2020 2020 2020 795f 6f75  ()..        y_ou
+00019920: 7420 3d20 795b 3a2c 206e 702e 6e65 7761  t = y[:, np.newa
+00019930: 7869 735d 0a20 2020 2020 2020 2079 5f6f  xis].        y_o
+00019940: 7574 203d 206e 702e 6873 7461 636b 2828  ut = np.hstack((
+00019950: 795f 6f75 742c 2079 5f6f 7574 2929 0a0a  y_out, y_out))..
+00019960: 2020 2020 2020 2020 7265 7475 726e 2079          return y
+00019970: 5f6f 7574 0a0a 0a63 6c61 7373 2044 6973  _out...class Dis
+00019980: 636f 6e74 696e 756f 7573 5269 6467 654d  continuousRidgeM
+00019990: 616e 7566 6163 7475 7265 4465 6361 795f  anufactureDecay_
+000199a0: 4e61 4e28 4162 7374 7261 6374 4d6f 6465  NaN(AbstractMode
+000199b0: 6c29 3a0a 2020 2020 2222 220a 2020 2020  l):.    """.    
+000199c0: 4e2d 6469 6d65 6e73 696f 6e61 6c20 7465  N-dimensional te
+000199d0: 7374 6675 6e63 7469 6f6e 2063 6f6e 7461  stfunction conta
+000199e0: 696e 696e 6720 6120 6c69 6e65 6172 2064  ining a linear d
+000199f0: 6973 636f 6e74 696e 7569 7479 2e0a 2020  iscontinuity..  
+00019a00: 2020 4f6e 2074 6865 206f 6e65 2073 6964    On the one sid
+00019a10: 6520 7468 6520 6f75 7470 7574 2063 6f72  e the output cor
+00019a20: 7265 7370 6f6e 6473 2074 6f20 7468 6520  responds to the 
+00019a30: 5269 6467 6520 6675 6e63 7469 6f6e 0a20  Ridge function. 
+00019a40: 2020 2061 6e64 206f 6e20 7468 6520 6f74     and on the ot
+00019a50: 6865 7220 7369 6465 2069 7420 636f 7272  her side it corr
+00019a60: 6573 706f 6e64 2074 6f20 7468 6520 4d61  espond to the Ma
+00019a70: 6e75 6661 6374 7572 6544 6563 6179 2074  nufactureDecay t
+00019a80: 6573 7466 756e 6374 696f 6e2e 0a0a 2020  estfunction...  
+00019a90: 2020 2e2e 206d 6174 683a 3a0a 2020 2020    .. math::.    
+00019aa0: 2020 2079 203d 205c 5c62 6567 696e 7b63     y = \\begin{c
+00019ab0: 6173 6573 7d0a 2020 2020 2020 205c 5c74  ases}.       \\t
+00019ac0: 6578 747b 4d61 6e75 6661 6374 7572 6544  ext{ManufactureD
+00019ad0: 6563 6179 7d28 7829 2c20 2620 5c5c 7465  ecay}(x), & \\te
+00019ae0: 7874 7b69 6620 7d20 5c5c 7375 6d5f 7b69  xt{if } \\sum_{i
+00019af0: 3d31 7d5e 7b4e 7d78 5f69 205c 5c6c 6571  =1}^{N}x_i \\leq
+00019b00: 2031 205c 5c5c 5c0a 2020 2020 2020 205c   1 \\\\.       \
+00019b10: 5c74 6578 747b 5269 6467 657d 2878 292c  \text{Ridge}(x),
+00019b20: 2026 205c 5c74 6578 747b 6f74 6865 7277   & \\text{otherw
+00019b30: 6973 657d 0a20 2020 2020 2020 5c5c 656e  ise}.       \\en
+00019b40: 647b 6361 7365 737d 0a0a 2020 2020 5061  d{cases}..    Pa
+00019b50: 7261 6d65 7465 7273 0a20 2020 202d 2d2d  rameters.    ---
+00019b60: 2d2d 2d2d 2d2d 2d0a 2020 2020 705b 2278  -------.    p["x
+00019b70: 3122 5d3a 2066 6c6f 6174 206f 7220 6e64  1"]: float or nd
+00019b80: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
+00019b90: 6e5f 6772 6964 5d0a 2020 2020 2020 2020  n_grid].        
+00019ba0: 4669 7273 7420 7061 7261 6d65 7465 7220  First parameter 
+00019bb0: 5b30 2c20 315d 0a20 2020 2070 5b22 7869  [0, 1].    p["xi
+00019bc0: 225d 3a20 666c 6f61 7420 6f72 206e 6461  "]: float or nda
+00019bd0: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
+00019be0: 5f67 7269 645d 0a20 2020 2020 2020 2069  _grid].        i
+00019bf0: 2d74 6820 7061 7261 6d65 7465 7220 6465  -th parameter de
+00019c00: 6669 6e65 6420 696e 205b 302c 2031 5d0a  fined in [0, 1].
+00019c10: 2020 2020 705b 2278 4e22 5d3a 2066 6c6f      p["xN"]: flo
+00019c20: 6174 206f 7220 6e64 6172 7261 7920 6f66  at or ndarray of
+00019c30: 2066 6c6f 6174 205b 6e5f 6772 6964 5d0a   float [n_grid].
+00019c40: 2020 2020 2020 2020 4e74 6820 7061 7261          Nth para
+00019c50: 6d65 7465 7220 5b30 2c20 315d 0a0a 2020  meter [0, 1]..  
+00019c60: 2020 5265 7475 726e 730a 2020 2020 2d2d    Returns.    --
+00019c70: 2d2d 2d2d 2d0a 2020 2020 793a 206e 6461  -----.    y: nda
+00019c80: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
+00019c90: 5f67 7269 6420 7820 315d 0a20 2020 2020  _grid x 1].     
+00019ca0: 2020 204f 7574 7075 7420 6461 7461 0a0a     Output data..
+00019cb0: 2020 2020 4e6f 7465 730a 2020 2020 2d2d      Notes.    --
+00019cc0: 2d2d 2d0a 2020 2020 2e2e 2070 6c6f 743a  ---.    .. plot:
+00019cd0: 3a0a 0a20 2020 2020 2020 696d 706f 7274  :..       import
+00019ce0: 206e 756d 7079 2061 7320 6e70 0a20 2020   numpy as np.   
+00019cf0: 2020 2020 6672 6f6d 2070 7967 7063 2e74      from pygpc.t
+00019d00: 6573 7466 756e 6374 696f 6e73 2069 6d70  estfunctions imp
+00019d10: 6f72 7420 706c 6f74 5f74 6573 7466 756e  ort plot_testfun
+00019d20: 6374 696f 6e20 6173 2070 6c6f 740a 2020  ction as plot.  
+00019d30: 2020 2020 2066 726f 6d20 636f 6c6c 6563       from collec
+00019d40: 7469 6f6e 7320 696d 706f 7274 204f 7264  tions import Ord
+00019d50: 6572 6564 4469 6374 0a0a 2020 2020 2020  eredDict..      
+00019d60: 2070 6172 616d 6574 6572 7320 3d20 4f72   parameters = Or
+00019d70: 6465 7265 6444 6963 7428 290a 2020 2020  deredDict().    
+00019d80: 2020 2070 6172 616d 6574 6572 735b 2278     parameters["x
+00019d90: 3122 5d20 3d20 6e70 2e6c 696e 7370 6163  1"] = np.linspac
+00019da0: 6528 302c 2031 2c20 3235 3029 0a20 2020  e(0, 1, 250).   
+00019db0: 2020 2020 7061 7261 6d65 7465 7273 5b22      parameters["
+00019dc0: 7832 225d 203d 206e 702e 6c69 6e73 7061  x2"] = np.linspa
+00019dd0: 6365 2830 2c20 312c 2032 3530 290a 0a20  ce(0, 1, 250).. 
+00019de0: 2020 2020 2020 706c 6f74 2822 4469 7363        plot("Disc
+00019df0: 6f6e 7469 6e75 6f75 7352 6964 6765 4d61  ontinuousRidgeMa
+00019e00: 6e75 6661 6374 7572 6544 6563 6179 222c  nufactureDecay",
+00019e10: 2070 6172 616d 6574 6572 7329 0a20 2020   parameters).   
+00019e20: 2022 2222 0a0a 2020 2020 6465 6620 5f5f   """..    def __
+00019e30: 696e 6974 5f5f 2873 656c 662c 206d 6174  init__(self, mat
+00019e40: 6c61 625f 6d6f 6465 6c3d 4661 6c73 6529  lab_model=False)
+00019e50: 3a0a 2020 2020 2020 2020 7375 7065 7228  :.        super(
+00019e60: 7479 7065 2873 656c 6629 2c20 7365 6c66  type(self), self
+00019e70: 292e 5f5f 696e 6974 5f5f 286d 6174 6c61  ).__init__(matla
+00019e80: 625f 6d6f 6465 6c3d 6d61 746c 6162 5f6d  b_model=matlab_m
+00019e90: 6f64 656c 290a 2020 2020 2020 2020 7365  odel).        se
+00019ea0: 6c66 2e66 6e61 6d65 203d 2069 6e73 7065  lf.fname = inspe
+00019eb0: 6374 2e67 6574 6669 6c65 2869 6e73 7065  ct.getfile(inspe
+00019ec0: 6374 2e63 7572 7265 6e74 6672 616d 6528  ct.currentframe(
+00019ed0: 2929 0a0a 2020 2020 6465 6620 7661 6c69  ))..    def vali
+00019ee0: 6461 7465 2873 656c 6629 3a0a 2020 2020  date(self):.    
+00019ef0: 2020 2020 7061 7373 0a0a 2020 2020 6465      pass..    de
+00019f00: 6620 7369 6d75 6c61 7465 2873 656c 662c  f simulate(self,
+00019f10: 2070 726f 6365 7373 5f69 643d 4e6f 6e65   process_id=None
+00019f20: 2c20 6d61 746c 6162 5f65 6e67 696e 653d  , matlab_engine=
+00019f30: 4e6f 6e65 293a 0a0a 2020 2020 2020 2020  None):..        
+00019f40: 666f 7220 6b65 7920 696e 2073 656c 662e  for key in self.
+00019f50: 702e 6b65 7973 2829 3a0a 2020 2020 2020  p.keys():.      
+00019f60: 2020 2020 2020 6966 2073 656c 662e 705b        if self.p[
+00019f70: 6b65 795d 2e6e 6469 6d20 3d3d 2031 3a0a  key].ndim == 1:.
+00019f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019f90: 7365 6c66 2e70 5b6b 6579 5d20 3d20 7365  self.p[key] = se
+00019fa0: 6c66 2e70 5b6b 6579 5d5b 3a2c 206e 702e  lf.p[key][:, np.
+00019fb0: 6e65 7761 7869 735d 0a0a 2020 2020 2020  newaxis]..      
+00019fc0: 2020 7820 3d20 6e70 2e68 7374 6163 6b28    x = np.hstack(
+00019fd0: 5b73 656c 662e 705b 6b65 795d 2066 6f72  [self.p[key] for
+00019fe0: 206b 6579 2069 6e20 7365 6c66 2e70 2e6b   key in self.p.k
+00019ff0: 6579 7328 295d 290a 0a20 2020 2020 2020  eys()])..       
+0001a000: 2079 203d 206e 702e 7a65 726f 7328 782e   y = np.zeros(x.
+0001a010: 7368 6170 655b 305d 290a 2020 2020 2020  shape[0]).      
+0001a020: 2020 6d61 736b 203d 2028 6e70 2e73 756d    mask = (np.sum
+0001a030: 2878 2c20 6178 6973 3d31 2920 3c3d 2031  (x, axis=1) <= 1
+0001a040: 2e29 2e66 6c61 7474 656e 2829 0a20 2020  .).flatten().   
+0001a050: 2020 2020 2023 206d 6173 6b20 3d20 6e70       # mask = np
+0001a060: 2e6c 6f67 6963 616c 5f61 6e64 286d 6173  .logical_and(mas
+0001a070: 6b2c 206e 702e 6c69 6e61 6c67 2e6e 6f72  k, np.linalg.nor
+0001a080: 6d28 782d 302e 3835 2c20 6178 6973 3d31  m(x-0.85, axis=1
+0001a090: 2920 3e20 2e38 290a 0a20 2020 2020 2020  ) > .8)..       
+0001a0a0: 2070 5f31 203d 204f 7264 6572 6564 4469   p_1 = OrderedDi
+0001a0b0: 6374 2829 0a20 2020 2020 2020 2070 5f32  ct().        p_2
+0001a0c0: 203d 204f 7264 6572 6564 4469 6374 2829   = OrderedDict()
+0001a0d0: 0a0a 2020 2020 2020 2020 666f 7220 692c  ..        for i,
+0001a0e0: 206b 6579 2069 6e20 656e 756d 6572 6174   key in enumerat
+0001a0f0: 6528 7365 6c66 2e70 2e6b 6579 7328 2929  e(self.p.keys())
+0001a100: 3a0a 2020 2020 2020 2020 2020 2020 705f  :.            p_
+0001a110: 315b 6b65 795d 203d 2078 5b6d 6173 6b2c  1[key] = x[mask,
+0001a120: 2069 5d0a 2020 2020 2020 2020 2020 2020   i].            
+0001a130: 705f 325b 6b65 795d 203d 2078 5b6e 702e  p_2[key] = x[np.
+0001a140: 6c6f 6769 6361 6c5f 6e6f 7428 6d61 736b  logical_not(mask
+0001a150: 292c 2069 5d0a 0a20 2020 2020 2020 206d  ), i]..        m
+0001a160: 6f64 656c 5f31 203d 204d 616e 7566 6163  odel_1 = Manufac
+0001a170: 7475 7265 4465 6361 7928 292e 7365 745f  tureDecay().set_
+0001a180: 7061 7261 6d65 7465 7273 2870 5f31 290a  parameters(p_1).
+0001a190: 2020 2020 2020 2020 6d6f 6465 6c5f 3220          model_2 
+0001a1a0: 3d20 5269 6467 6528 292e 7365 745f 7061  = Ridge().set_pa
+0001a1b0: 7261 6d65 7465 7273 2870 5f32 290a 0a20  rameters(p_2).. 
+0001a1c0: 2020 2020 2020 2079 5f31 203d 206d 6f64         y_1 = mod
+0001a1d0: 656c 5f31 2e73 696d 756c 6174 6528 290a  el_1.simulate().
+0001a1e0: 2020 2020 2020 2020 795f 3220 3d20 6d6f          y_2 = mo
+0001a1f0: 6465 6c5f 322e 7369 6d75 6c61 7465 2829  del_2.simulate()
+0001a200: 0a0a 2020 2020 2020 2020 795b 6d61 736b  ..        y[mask
+0001a210: 5d20 3d20 795f 312e 666c 6174 7465 6e28  ] = y_1.flatten(
+0001a220: 290a 2020 2020 2020 2020 795b 6e70 2e6c  ).        y[np.l
+0001a230: 6f67 6963 616c 5f6e 6f74 286d 6173 6b29  ogical_not(mask)
+0001a240: 5d20 3d20 795f 322e 666c 6174 7465 6e28  ] = y_2.flatten(
+0001a250: 290a 0a20 2020 2020 2020 2079 5f6f 7574  )..        y_out
+0001a260: 203d 2079 5b3a 2c20 6e70 2e6e 6577 6178   = y[:, np.newax
+0001a270: 6973 5d0a 2020 2020 2020 2020 795f 6f75  is].        y_ou
+0001a280: 7420 3d20 6e70 2e68 7374 6163 6b28 2879  t = np.hstack((y
+0001a290: 5f6f 7574 2c20 795f 6f75 7429 290a 0a20  _out, y_out)).. 
+0001a2a0: 2020 2020 2020 2023 2069 6e73 6572 7420         # insert 
+0001a2b0: 736f 6d65 204e 614e 2076 616c 7565 7320  some NaN values 
+0001a2c0: 666f 7220 7465 7374 696e 670a 2020 2020  for testing.    
+0001a2d0: 2020 2020 6d61 736b 203d 2028 7365 6c66      mask = (self
+0001a2e0: 2e70 5b6c 6973 7428 7365 6c66 2e70 2e6b  .p[list(self.p.k
+0001a2f0: 6579 7328 2929 5b30 5d5d 203e 2030 2e38  eys())[0]] > 0.8
+0001a300: 292e 666c 6174 7465 6e28 290a 2020 2020  ).flatten().    
+0001a310: 2020 2020 795f 6f75 745b 6d61 736b 2c20      y_out[mask, 
+0001a320: 305d 203d 206e 702e 4e61 4e0a 0a20 2020  0] = np.NaN..   
+0001a330: 2020 2020 2072 6574 7572 6e20 795f 6f75       return y_ou
+0001a340: 740a 0a0a 636c 6173 7320 4f61 6b6c 6579  t...class Oakley
+0001a350: 4f68 6167 616e 3230 3034 2841 6273 7472  Ohagan2004(Abstr
+0001a360: 6163 744d 6f64 656c 293a 0a20 2020 2023  actModel):.    #
+0001a370: 2054 6f64 6f3a 2040 4c75 6361 733a 2072   Todo: @Lucas: r
+0001a380: 656d 6f76 6520 7465 7874 2066 696c 6573  emove text files
+0001a390: 0a20 2020 2022 2222 0a20 2020 2031 352d  .    """.    15-
+0001a3a0: 6469 6d65 6e73 696f 6e61 6c20 7465 7374  dimensional test
+0001a3b0: 2066 756e 6374 696f 6e20 6f66 204f 616b   function of Oak
+0001a3c0: 6c65 7920 616e 6420 4f27 4861 6761 6e20  ley and O'Hagan 
+0001a3d0: 2832 3030 3429 205b 315d 2e0a 0a20 2020  (2004) [1]...   
+0001a3e0: 2054 6869 7320 6675 6e63 7469 6f6e 2773   This function's
+0001a3f0: 2061 2d63 6f65 6666 6963 6965 6e74 7320   a-coefficients 
+0001a400: 6172 6520 6368 6f73 656e 2073 6f20 7468  are chosen so th
+0001a410: 6174 2035 206f 6620 7468 6520 696e 7075  at 5 of the inpu
+0001a420: 740a 2020 2020 7661 7269 6162 6c65 7320  t.    variables 
+0001a430: 636f 6e74 7269 6275 7465 2073 6967 6e69  contribute signi
+0001a440: 6669 6361 6e74 6c79 2074 6f20 7468 6520  ficantly to the 
+0001a450: 6f75 7470 7574 2076 6172 6961 6e63 652c  output variance,
+0001a460: 2035 2068 6176 6520 610a 2020 2020 6d75   5 have a.    mu
+0001a470: 6368 2073 6d61 6c6c 6572 2065 6666 6563  ch smaller effec
+0001a480: 742c 2061 6e64 2074 6865 2072 656d 6169  t, and the remai
+0001a490: 6e69 6e67 2035 2068 6176 6520 616c 6d6f  ning 5 have almo
+0001a4a0: 7374 206e 6f20 6566 6665 6374 206f 6e20  st no effect on 
+0001a4b0: 7468 650a 2020 2020 6f75 7470 7574 2076  the.    output v
+0001a4c0: 6172 6961 6e63 652e 0a0a 2020 2020 2e2e  ariance...    ..
+0001a4d0: 206d 6174 683a 3a0a 2020 2020 2020 2079   math::.       y
+0001a4e0: 203d 205c 6d61 7468 6266 7b61 7d5f 315e   = \mathbf{a}_1^
+0001a4f0: 545c 6d61 7468 6266 7b78 7d20 2b20 5c6d  T\mathbf{x} + \m
+0001a500: 6174 6862 667b 617d 5f32 5e54 205c 7369  athbf{a}_2^T \si
+0001a510: 6e28 5c6d 6174 6862 667b 787d 2920 2b20  n(\mathbf{x}) + 
+0001a520: 5c6d 6174 6862 667b 617d 5f33 5e54 205c  \mathbf{a}_3^T \
+0001a530: 636f 7328 5c6d 6174 6862 667b 787d 2920  cos(\mathbf{x}) 
+0001a540: 2b0a 2020 2020 2020 205c 6d61 7468 6266  +.       \mathbf
+0001a550: 7b78 7d5e 545c 6d61 7468 6266 7b4d 7d5c  {x}^T\mathbf{M}\
+0001a560: 6d61 7468 6266 7b78 7d0a 0a20 2020 2054  mathbf{x}..    T
+0001a570: 6865 2070 6172 616d 6574 6572 2076 6563  he parameter vec
+0001a580: 746f 7273 2061 2061 6e64 206d 6174 7269  tors a and matri
+0001a590: 7820 4d20 6172 6520 696e 202f 7079 6770  x M are in /pygp
+0001a5a0: 632f 7063 6b2f 6461 7461 2f6f 616b 6c65  c/pck/data/oakle
+0001a5b0: 795f 6f68 6167 616e 5f32 3030 342e 0a0a  y_ohagan_2004...
+0001a5c0: 2020 2020 5061 7261 6d65 7465 7273 0a20      Parameters. 
+0001a5d0: 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020     ----------.  
+0001a5e0: 2020 705b 2278 312e 2e2e 3135 225d 3a20    p["x1...15"]: 
+0001a5f0: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
+0001a600: 205b 6e5f 6772 6964 5d0a 2020 2020 2020   [n_grid].      
+0001a610: 2020 496e 7075 7420 6461 7461 2c20 7869    Input data, xi
+0001a620: 207e 204e 286d 753d 302c 2073 6967 6d61   ~ N(mu=0, sigma
+0001a630: 3d31 292c 2066 6f72 2061 6c6c 2069 203d  =1), for all i =
+0001a640: 2031 2c20 322c 2e2e 2e2c 2031 352e 0a0a   1, 2,..., 15...
+0001a650: 2020 2020 5265 7475 726e 730a 2020 2020      Returns.    
+0001a660: 2d2d 2d2d 2d2d 2d0a 2020 2020 793a 206e  -------.    y: n
+0001a670: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+0001a680: 5b4e 5f69 6e70 7574 2078 2031 5d0a 2020  [N_input x 1].  
+0001a690: 2020 2020 2020 4f75 7470 7574 2064 6174        Output dat
+0001a6a0: 610a 0a20 2020 204e 6f74 6573 0a20 2020  a..    Notes.   
+0001a6b0: 202d 2d2d 2d2d 0a20 2020 202e 2e20 5b31   -----.    .. [1
+0001a6c0: 5d20 4f61 6b6c 6579 2c20 4a2e 2045 2e2c  ] Oakley, J. E.,
+0001a6d0: 2026 204f 2748 6167 616e 2c20 412e 2028   & O'Hagan, A. (
+0001a6e0: 3230 3034 292e 2050 726f 6261 6269 6c69  2004). Probabili
+0001a6f0: 7374 6963 2073 656e 7369 7469 7669 7479  stic sensitivity
+0001a700: 2061 6e61 6c79 7369 730a 2020 2020 2020   analysis.      
+0001a710: 206f 6620 636f 6d70 6c65 7820 6d6f 6465   of complex mode
+0001a720: 6c73 3a20 6120 4261 7965 7369 616e 2061  ls: a Bayesian a
+0001a730: 7070 726f 6163 682e 204a 6f75 726e 616c  pproach. Journal
+0001a740: 206f 6620 7468 6520 526f 7961 6c20 5374   of the Royal St
+0001a750: 6174 6973 7469 6361 6c0a 2020 2020 2020  atistical.      
+0001a760: 2053 6f63 6965 7479 3a20 5365 7269 6573   Society: Series
+0001a770: 2042 2028 5374 6174 6973 7469 6361 6c20   B (Statistical 
+0001a780: 4d65 7468 6f64 6f6c 6f67 7929 2c20 3636  Methodology), 66
+0001a790: 2833 292c 2037 3531 2d37 3639 2e0a 2020  (3), 751-769..  
+0001a7a0: 2020 2222 220a 0a20 2020 2064 6566 205f    """..    def _
+0001a7b0: 5f69 6e69 745f 5f28 7365 6c66 2c20 6d61  _init__(self, ma
+0001a7c0: 746c 6162 5f6d 6f64 656c 3d46 616c 7365  tlab_model=False
+0001a7d0: 293a 0a20 2020 2020 2020 2073 7570 6572  ):.        super
+0001a7e0: 2874 7970 6528 7365 6c66 292c 2073 656c  (type(self), sel
+0001a7f0: 6629 2e5f 5f69 6e69 745f 5f28 6d61 746c  f).__init__(matl
+0001a800: 6162 5f6d 6f64 656c 3d6d 6174 6c61 625f  ab_model=matlab_
+0001a810: 6d6f 6465 6c29 0a20 2020 2020 2020 2073  model).        s
+0001a820: 656c 662e 666e 616d 6520 3d20 696e 7370  elf.fname = insp
+0001a830: 6563 742e 6765 7466 696c 6528 696e 7370  ect.getfile(insp
+0001a840: 6563 742e 6375 7272 656e 7466 7261 6d65  ect.currentframe
+0001a850: 2829 290a 0a20 2020 2064 6566 2076 616c  ())..    def val
+0001a860: 6964 6174 6528 7365 6c66 293a 0a20 2020  idate(self):.   
+0001a870: 2020 2020 2070 6173 730a 0a20 2020 2064       pass..    d
+0001a880: 6566 2073 696d 756c 6174 6528 7365 6c66  ef simulate(self
+0001a890: 2c20 7072 6f63 6573 735f 6964 3d4e 6f6e  , process_id=Non
+0001a8a0: 652c 206d 6174 6c61 625f 656e 6769 6e65  e, matlab_engine
+0001a8b0: 3d4e 6f6e 6529 3a0a 2020 2020 2020 2020  =None):.        
+0001a8c0: 2320 6c6f 6164 2063 6f65 6666 6963 6965  # load coefficie
+0001a8d0: 6e74 730a 2020 2020 2020 2020 666f 6c64  nts.        fold
+0001a8e0: 6572 203d 206f 732e 7061 7468 2e73 706c  er = os.path.spl
+0001a8f0: 6974 286f 732e 7061 7468 2e64 6972 6e61  it(os.path.dirna
+0001a900: 6d65 285f 5f66 696c 655f 5f29 295b 305d  me(__file__))[0]
+0001a910: 0a20 2020 2020 2020 206d 203d 206e 702e  .        m = np.
+0001a920: 6c6f 6164 7478 7428 6f73 2e70 6174 682e  loadtxt(os.path.
+0001a930: 6a6f 696e 2866 6f6c 6465 722c 2022 6f61  join(folder, "oa
+0001a940: 6b6c 6579 5f6f 6861 6761 6e5f 3230 3034  kley_ohagan_2004
+0001a950: 5f4d 2e74 7874 2229 290a 2020 2020 2020  _M.txt")).      
+0001a960: 2020 6131 203d 206e 702e 6c6f 6164 7478    a1 = np.loadtx
+0001a970: 7428 6f73 2e70 6174 682e 6a6f 696e 2866  t(os.path.join(f
+0001a980: 6f6c 6465 722c 2022 6f61 6b6c 6579 5f6f  older, "oakley_o
+0001a990: 6861 6761 6e5f 3230 3034 5f61 312e 7478  hagan_2004_a1.tx
+0001a9a0: 7422 2929 0a20 2020 2020 2020 2061 3220  t")).        a2 
+0001a9b0: 3d20 6e70 2e6c 6f61 6474 7874 286f 732e  = np.loadtxt(os.
+0001a9c0: 7061 7468 2e6a 6f69 6e28 666f 6c64 6572  path.join(folder
+0001a9d0: 2c20 226f 616b 6c65 795f 6f68 6167 616e  , "oakley_ohagan
+0001a9e0: 5f32 3030 345f 6132 2e74 7874 2229 290a  _2004_a2.txt")).
+0001a9f0: 2020 2020 2020 2020 6133 203d 206e 702e          a3 = np.
+0001aa00: 6c6f 6164 7478 7428 6f73 2e70 6174 682e  loadtxt(os.path.
+0001aa10: 6a6f 696e 2866 6f6c 6465 722c 2022 6f61  join(folder, "oa
+0001aa20: 6b6c 6579 5f6f 6861 6761 6e5f 3230 3034  kley_ohagan_2004
+0001aa30: 5f61 332e 7478 7422 2929 0a0a 2020 2020  _a3.txt"))..    
+0001aa40: 2020 2020 7820 3d20 6e70 2e7a 6572 6f73      x = np.zeros
+0001aa50: 2828 7365 6c66 2e70 5b6c 6973 7428 7365  ((self.p[list(se
+0001aa60: 6c66 2e70 2e6b 6579 7328 2929 5b30 5d5d  lf.p.keys())[0]]
+0001aa70: 2e73 697a 652c 2031 3529 290a 0a20 2020  .size, 15))..   
+0001aa80: 2020 2020 2066 6f72 2069 2c20 6b65 7920       for i, key 
+0001aa90: 696e 2065 6e75 6d65 7261 7465 2873 656c  in enumerate(sel
+0001aaa0: 662e 702e 6b65 7973 2829 293a 0a20 2020  f.p.keys()):.   
+0001aab0: 2020 2020 2020 2020 2078 5b3a 2c20 695d           x[:, i]
+0001aac0: 203d 2073 656c 662e 705b 6b65 795d 0a0a   = self.p[key]..
+0001aad0: 2020 2020 2020 2020 2320 6675 6e63 7469          # functi
+0001aae0: 6f6e 0a20 2020 2020 2020 2079 203d 2028  on.        y = (
+0001aaf0: 6e70 2e64 6f74 2878 2c20 6131 2920 2b20  np.dot(x, a1) + 
+0001ab00: 6e70 2e64 6f74 286e 702e 7369 6e28 7829  np.dot(np.sin(x)
+0001ab10: 2c20 6132 290a 2020 2020 2020 2020 2020  , a2).          
+0001ab20: 2020 202b 206e 702e 646f 7428 6e70 2e63     + np.dot(np.c
+0001ab30: 6f73 2878 292c 2061 3329 202b 206e 702e  os(x), a3) + np.
+0001ab40: 7375 6d28 6e70 2e6d 756c 7469 706c 7928  sum(np.multiply(
+0001ab50: 6e70 2e64 6f74 2878 2c20 6d29 2c20 7829  np.dot(x, m), x)
+0001ab60: 2c20 6178 6973 3d31 2929 0a0a 2020 2020  , axis=1))..    
+0001ab70: 2020 2020 795f 6f75 7420 3d20 795b 3a2c      y_out = y[:,
+0001ab80: 206e 702e 6e65 7761 7869 735d 0a0a 2020   np.newaxis]..  
+0001ab90: 2020 2020 2020 7265 7475 726e 2079 5f6f        return y_o
+0001aba0: 7574 0a0a 0a63 6c61 7373 2057 656c 6368  ut...class Welch
+0001abb0: 3139 3932 2841 6273 7472 6163 744d 6f64  1992(AbstractMod
+0001abc0: 656c 293a 0a20 2020 2022 2222 0a20 2020  el):.    """.   
+0001abd0: 2032 302d 6469 6d65 6e73 696f 6e61 6c20   20-dimensional 
+0001abe0: 7465 7374 2066 756e 6374 696f 6e20 6f66  test function of
+0001abf0: 2057 656c 6368 2065 7420 616c 2e20 2831   Welch et al. (1
+0001ac00: 3939 3229 205b 315d 2e0a 0a20 2020 2046  992) [1]...    F
+0001ac10: 6f72 2069 6e70 7574 2076 6172 6961 626c  or input variabl
+0001ac20: 6520 7363 7265 656e 696e 6720 7075 7270  e screening purp
+0001ac30: 6f73 6573 2c20 6974 2063 616e 2062 6520  oses, it can be 
+0001ac40: 666f 756e 6420 7468 6174 2073 6f6d 6520  found that some 
+0001ac50: 696e 7075 740a 2020 2020 7661 7269 6162  input.    variab
+0001ac60: 6c65 7320 6f66 2074 6869 7320 6675 6e63  les of this func
+0001ac70: 7469 6f6e 2068 6176 6520 6120 7665 7279  tion have a very
+0001ac80: 2068 6967 6820 6566 6665 6374 206f 6e20   high effect on 
+0001ac90: 7468 6520 6f75 7470 7574 2c0a 2020 2020  the output,.    
+0001aca0: 636f 6d70 6172 6564 2074 6f20 6f74 6865  compared to othe
+0001acb0: 7220 696e 7075 7420 7661 7269 6162 6c65  r input variable
+0001acc0: 732e 2041 7320 5765 6c63 6820 6574 2061  s. As Welch et a
+0001acd0: 6c2e 2028 3139 3932 2920 5b31 5d20 706f  l. (1992) [1] po
+0001ace0: 696e 7420 6f75 742c 0a20 2020 2069 6e74  int out,.    int
+0001acf0: 6572 6163 7469 6f6e 7320 616e 6420 6e6f  eractions and no
+0001ad00: 6e6c 696e 6561 7220 6566 6665 6374 7320  nlinear effects 
+0001ad10: 6d61 6b65 2074 6869 7320 6675 6e63 7469  make this functi
+0001ad20: 6f6e 2063 6861 6c6c 656e 6769 6e67 2e0a  on challenging..
+0001ad30: 0a20 2020 202e 2e20 6d61 7468 3a3a 0a20  .    .. math::. 
+0001ad40: 2020 2020 2020 7920 3d20 5c5c 6672 6163        y = \\frac
+0001ad50: 7b35 2078 5f7b 3132 7d7d 7b31 202b 2078  {5 x_{12}}{1 + x
+0001ad60: 5f31 7d20 2b20 3520 2878 5f34 202d 2078  _1} + 5 (x_4 - x
+0001ad70: 5f7b 3230 7d29 5e32 202b 2078 5f35 202b  _{20})^2 + x_5 +
+0001ad80: 2034 3020 785f 7b31 397d 5e33 202b 2035   40 x_{19}^3 + 5
+0001ad90: 2078 5f7b 3139 7d20 2b20 302e 3035 2078   x_{19} + 0.05 x
+0001ada0: 5f32 0a20 2020 2020 2020 2b20 302e 3038  _2.       + 0.08
+0001adb0: 2078 5f33 202d 2030 2e30 3320 785f 3620   x_3 - 0.03 x_6 
+0001adc0: 2b20 302e 3033 2078 5f37 202d 2030 2e30  + 0.03 x_7 - 0.0
+0001add0: 3920 785f 3920 2d20 302e 3031 2078 5f7b  9 x_9 - 0.01 x_{
+0001ade0: 3130 7d20 2d0a 0a20 2020 2020 2020 302e  10} -..       0.
+0001adf0: 3037 2078 5f7b 3131 7d20 2b20 302e 3235  07 x_{11} + 0.25
+0001ae00: 2078 5f7b 3133 7d5e 3220 2d20 302e 3034   x_{13}^2 - 0.04
+0001ae10: 2078 5f7b 3134 7d20 2b20 302e 3036 2078   x_{14} + 0.06 x
+0001ae20: 5f7b 3135 7d20 2d20 302e 3031 2078 5f7b  _{15} - 0.01 x_{
+0001ae30: 3137 7d20 2d20 302e 3033 2078 5f7b 3138  17} - 0.03 x_{18
+0001ae40: 7d0a 0a20 2020 2050 6172 616d 6574 6572  }..    Parameter
+0001ae50: 730a 2020 2020 2d2d 2d2d 2d2d 2d2d 2d2d  s.    ----------
+0001ae60: 0a20 2020 2070 5b22 7831 2e2e 2e78 3230  .    p["x1...x20
+0001ae70: 225d 3a20 666c 6f61 740a 2020 2020 2020  "]: float.      
+0001ae80: 2020 496e 7075 7420 6461 7461 2c20 7869    Input data, xi
+0001ae90: 207e 2055 282d 302e 352c 2030 2e35 292c   ~ U(-0.5, 0.5),
+0001aea0: 2066 6f72 2061 6c6c 2069 203d 2031 2c2e   for all i = 1,.
+0001aeb0: 2e2e 2c20 3230 2e0a 0a20 2020 2052 6574  .., 20...    Ret
+0001aec0: 7572 6e73 0a20 2020 202d 2d2d 2d2d 2d2d  urns.    -------
+0001aed0: 0a20 2020 2079 3a20 6e64 6172 7261 7920  .    y: ndarray 
+0001aee0: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
+0001aef0: 2078 2031 5d0a 2020 2020 2020 2020 4f75   x 1].        Ou
+0001af00: 7470 7574 2064 6174 610a 0a20 2020 204e  tput data..    N
+0001af10: 6f74 6573 0a20 2020 202d 2d2d 2d2d 0a20  otes.    -----. 
+0001af20: 2020 202e 2e20 5b31 5d20 5765 6c63 682c     .. [1] Welch,
+0001af30: 2057 2e20 4a2e 2c20 4275 636b 2c20 522e   W. J., Buck, R.
+0001af40: 204a 2e2c 2053 6163 6b73 2c20 4a2e 2c20   J., Sacks, J., 
+0001af50: 5779 6e6e 2c20 482e 2050 2e2c 204d 6974  Wynn, H. P., Mit
+0001af60: 6368 656c 6c2c 2054 2e20 4a2e 2c20 4d6f  chell, T. J., Mo
+0001af70: 7272 6973 2c20 4d2e 2044 2e20 2831 3939  rris, M. D. (199
+0001af80: 3229 2e0a 2020 2020 2020 2053 6372 6565  2)..       Scree
+0001af90: 6e69 6e67 2c20 7072 6564 6963 7469 6e67  ning, predicting
+0001afa0: 2c20 616e 6420 636f 6d70 7574 6572 2065  , and computer e
+0001afb0: 7870 6572 696d 656e 7473 2e20 5465 6368  xperiments. Tech
+0001afc0: 6e6f 6d65 7472 6963 732c 2033 3428 3129  nometrics, 34(1)
+0001afd0: 2c20 3135 2d32 352e 0a20 2020 2022 2222  , 15-25..    """
+0001afe0: 0a0a 2020 2020 6465 6620 5f5f 696e 6974  ..    def __init
+0001aff0: 5f5f 2873 656c 662c 206d 6174 6c61 625f  __(self, matlab_
+0001b000: 6d6f 6465 6c3d 4661 6c73 6529 3a0a 2020  model=False):.  
+0001b010: 2020 2020 2020 7375 7065 7228 7479 7065        super(type
+0001b020: 2873 656c 6629 2c20 7365 6c66 292e 5f5f  (self), self).__
+0001b030: 696e 6974 5f5f 286d 6174 6c61 625f 6d6f  init__(matlab_mo
+0001b040: 6465 6c3d 6d61 746c 6162 5f6d 6f64 656c  del=matlab_model
+0001b050: 290a 2020 2020 2020 2020 7365 6c66 2e66  ).        self.f
+0001b060: 6e61 6d65 203d 2069 6e73 7065 6374 2e67  name = inspect.g
+0001b070: 6574 6669 6c65 2869 6e73 7065 6374 2e63  etfile(inspect.c
+0001b080: 7572 7265 6e74 6672 616d 6528 2929 0a0a  urrentframe())..
+0001b090: 2020 2020 6465 6620 7661 6c69 6461 7465      def validate
+0001b0a0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+0001b0b0: 7061 7373 0a0a 2020 2020 6465 6620 7369  pass..    def si
+0001b0c0: 6d75 6c61 7465 2873 656c 662c 2070 726f  mulate(self, pro
+0001b0d0: 6365 7373 5f69 643d 4e6f 6e65 2c20 6d61  cess_id=None, ma
+0001b0e0: 746c 6162 5f65 6e67 696e 653d 4e6f 6e65  tlab_engine=None
+0001b0f0: 293a 0a20 2020 2020 2020 2079 203d 2028  ):.        y = (
+0001b100: 352e 3020 2a20 7365 6c66 2e70 5b22 7831  5.0 * self.p["x1
+0001b110: 3222 5d20 2f20 2831 202b 2073 656c 662e  2"] / (1 + self.
+0001b120: 705b 2278 3122 5d29 202b 2035 202a 2028  p["x1"]) + 5 * (
+0001b130: 7365 6c66 2e70 5b22 7834 225d 202d 2073  self.p["x4"] - s
+0001b140: 656c 662e 705b 2278 3230 225d 2920 2a2a  elf.p["x20"]) **
+0001b150: 2032 0a20 2020 2020 2020 2020 2020 2020   2.             
+0001b160: 2b20 7365 6c66 2e70 5b22 7835 225d 202b  + self.p["x5"] +
+0001b170: 2034 3020 2a20 7365 6c66 2e70 5b22 7831   40 * self.p["x1
+0001b180: 3922 5d20 2a2a 2033 202b 2035 202a 2073  9"] ** 3 + 5 * s
+0001b190: 656c 662e 705b 2278 3139 225d 202b 2030  elf.p["x19"] + 0
+0001b1a0: 2e30 3520 2a20 7365 6c66 2e70 5b22 7832  .05 * self.p["x2
+0001b1b0: 225d 0a20 2020 2020 2020 2020 2020 2020  "].             
+0001b1c0: 2b20 302e 3038 202a 2073 656c 662e 705b  + 0.08 * self.p[
+0001b1d0: 2278 3322 5d20 2d20 302e 3033 202a 2073  "x3"] - 0.03 * s
+0001b1e0: 656c 662e 705b 2278 3622 5d20 2b20 302e  elf.p["x6"] + 0.
+0001b1f0: 3033 202a 2073 656c 662e 705b 2278 3722  03 * self.p["x7"
+0001b200: 5d0a 2020 2020 2020 2020 2020 2020 202d  ].             -
+0001b210: 2030 2e30 3920 2a20 7365 6c66 2e70 5b22   0.09 * self.p["
+0001b220: 7839 225d 202d 2030 2e30 3120 2a20 7365  x9"] - 0.01 * se
+0001b230: 6c66 2e70 5b22 7831 3022 5d20 2d20 302e  lf.p["x10"] - 0.
+0001b240: 3037 202a 2073 656c 662e 705b 2278 3131  07 * self.p["x11
+0001b250: 225d 0a20 2020 2020 2020 2020 2020 2020  "].             
+0001b260: 2b20 302e 3235 202a 2073 656c 662e 705b  + 0.25 * self.p[
+0001b270: 2278 3133 225d 202a 2a20 3220 2d20 302e  "x13"] ** 2 - 0.
+0001b280: 3034 202a 2073 656c 662e 705b 2278 3134  04 * self.p["x14
+0001b290: 225d 0a20 2020 2020 2020 2020 2020 2020  "].             
+0001b2a0: 2b20 302e 3036 202a 2073 656c 662e 705b  + 0.06 * self.p[
+0001b2b0: 2278 3135 225d 202d 2030 2e30 3120 2a20  "x15"] - 0.01 * 
+0001b2c0: 7365 6c66 2e70 5b22 7831 3722 5d20 2d20  self.p["x17"] - 
+0001b2d0: 302e 3033 202a 2073 656c 662e 705b 2278  0.03 * self.p["x
+0001b2e0: 3138 225d 290a 0a20 2020 2020 2020 2079  18"])..        y
+0001b2f0: 5f6f 7574 203d 2079 5b3a 2c20 6e70 2e6e  _out = y[:, np.n
+0001b300: 6577 6178 6973 5d0a 0a20 2020 2020 2020  ewaxis]..       
+0001b310: 2072 6574 7572 6e20 795f 6f75 740a 0a0a   return y_out...
+0001b320: 636c 6173 7320 5769 6e67 5765 6967 6874  class WingWeight
+0001b330: 2841 6273 7472 6163 744d 6f64 656c 293a  (AbstractModel):
+0001b340: 0a20 2020 2022 2222 0a20 2020 2031 302d  .    """.    10-
+0001b350: 6469 6d65 6e73 696f 6e61 6c20 7465 7374  dimensional test
+0001b360: 2066 756e 6374 696f 6e20 7768 6963 6820   function which 
+0001b370: 6d6f 6465 6c73 2061 206c 6967 6874 2061  models a light a
+0001b380: 6972 6372 6166 7420 7769 6e67 2066 726f  ircraft wing fro
+0001b390: 6d20 466f 7272 6573 7465 7220 6574 2061  m Forrester et a
+0001b3a0: 6c2e 2028 3230 3038 2920 5b31 5d0a 0a20  l. (2008) [1].. 
+0001b3b0: 2020 202e 2e20 6d61 7468 3a3a 0a20 2020     .. math::.   
+0001b3c0: 2020 2020 7920 3d20 5c5c 6672 6163 7b30      y = \\frac{0
+0001b3d0: 2e30 3336 2078 5f31 5e7b 302e 3735 387d  .036 x_1^{0.758}
+0001b3e0: 2078 5f32 5e7b 302e 3030 3335 7d20 785f   x_2^{0.0035} x_
+0001b3f0: 337d 7b5c 636f 7328 785f 3429 5e32 295e  3}{\cos(x_4)^2)^
+0001b400: 7b30 2e36 7d7d 2078 5f35 5e7b 302e 3030  {0.6}} x_5^{0.00
+0001b410: 367d 2078 5f36 5e7b 302e 3034 7d0a 2020  6} x_6^{0.04}.  
+0001b420: 2020 2020 205c 5c6c 6566 7428 205c 5c66       \\left( \\f
+0001b430: 7261 637b 3130 3020 785f 377d 7b5c 636f  rac{100 x_7}{\co
+0001b440: 7328 785f 3429 7d5c 5c72 6967 6874 295e  s(x_4)}\\right)^
+0001b450: 7b2d 302e 337d 2028 785f 3820 785f 3929  {-0.3} (x_8 x_9)
+0001b460: 5e7b 302e 3439 7d20 2b20 785f 3120 785f  ^{0.49} + x_1 x_
+0001b470: 7b31 307d 0a0a 2020 2020 5061 7261 6d65  {10}..    Parame
+0001b480: 7465 7273 0a20 2020 202d 2d2d 2d2d 2d2d  ters.    -------
+0001b490: 2d2d 2d0a 2020 2020 705b 2278 3122 5d3a  ---.    p["x1"]:
+0001b4a0: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
+0001b4b0: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
+0001b4c0: 6964 5d0a 2020 2020 2020 2020 7831 2853  id].        x1(S
+0001b4d0: 7729 205b 3135 302c 2032 3030 5d0a 2020  w) [150, 200].  
+0001b4e0: 2020 705b 2278 3222 5d3a 2066 6c6f 6174    p["x2"]: float
+0001b4f0: 206f 7220 6e64 6172 7261 7920 6f66 2066   or ndarray of f
+0001b500: 6c6f 6174 205b 6e5f 6772 6964 5d0a 2020  loat [n_grid].  
+0001b510: 2020 2020 2020 7832 2857 6677 2920 5b32        x2(Wfw) [2
+0001b520: 3230 2c20 3330 305d 0a20 2020 2070 5b22  20, 300].    p["
+0001b530: 7833 225d 3a20 666c 6f61 7420 6f72 206e  x3"]: float or n
+0001b540: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+0001b550: 5b6e 5f67 7269 645d 0a20 2020 2020 2020  [n_grid].       
+0001b560: 2078 3328 4129 205b 362c 2031 305d 0a20   x3(A) [6, 10]. 
+0001b570: 2020 2070 5b22 7834 225d 3a20 666c 6f61     p["x4"]: floa
+0001b580: 7420 6f72 206e 6461 7272 6179 206f 6620  t or ndarray of 
+0001b590: 666c 6f61 7420 5b6e 5f67 7269 645d 0a20  float [n_grid]. 
+0001b5a0: 2020 2020 2020 2078 3428 4c61 6d62 6461         x4(Lambda
+0001b5b0: 2920 5b2d 3130 2c20 3130 5d0a 2020 2020  ) [-10, 10].    
+0001b5c0: 705b 2278 3522 5d3a 2066 6c6f 6174 206f  p["x5"]: float o
+0001b5d0: 7220 6e64 6172 7261 7920 6f66 2066 6c6f  r ndarray of flo
+0001b5e0: 6174 205b 6e5f 6772 6964 5d0a 2020 2020  at [n_grid].    
+0001b5f0: 2020 2020 7835 2871 2920 5b31 362c 2034      x5(q) [16, 4
+0001b600: 355d 0a20 2020 2070 5b22 7836 225d 3a20  5].    p["x6"]: 
+0001b610: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
+0001b620: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
+0001b630: 645d 0a20 2020 2020 2020 2078 3628 6c61  d].        x6(la
+0001b640: 6d62 6461 2920 5b30 2e35 2c20 315d 0a20  mbda) [0.5, 1]. 
+0001b650: 2020 2070 5b22 7837 225d 3a20 666c 6f61     p["x7"]: floa
+0001b660: 7420 6f72 206e 6461 7272 6179 206f 6620  t or ndarray of 
+0001b670: 666c 6f61 7420 5b6e 5f67 7269 645d 0a20  float [n_grid]. 
+0001b680: 2020 2020 2020 2078 3728 7463 2920 5b30         x7(tc) [0
+0001b690: 2e30 382c 2030 2e31 385d 0a20 2020 2070  .08, 0.18].    p
+0001b6a0: 5b22 7838 225d 3a20 666c 6f61 7420 6f72  ["x8"]: float or
+0001b6b0: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
+0001b6c0: 7420 5b6e 5f67 7269 645d 0a20 2020 2020  t [n_grid].     
+0001b6d0: 2020 2078 3828 4e7a 2920 5b32 2e35 2c20     x8(Nz) [2.5, 
+0001b6e0: 365d 0a20 2020 2070 5b22 7839 225d 3a20  6].    p["x9"]: 
+0001b6f0: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
+0001b700: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
+0001b710: 645d 0a20 2020 2020 2020 2078 3928 5764  d].        x9(Wd
+0001b720: 6729 205b 3137 3030 2c20 3235 3030 5d0a  g) [1700, 2500].
+0001b730: 2020 2020 705b 2278 3130 225d 3a20 666c      p["x10"]: fl
+0001b740: 6f61 7420 6f72 206e 6461 7272 6179 206f  oat or ndarray o
+0001b750: 6620 666c 6f61 7420 5b6e 5f67 7269 645d  f float [n_grid]
+0001b760: 0a20 2020 2020 2020 2078 3130 2857 7029  .        x10(Wp)
+0001b770: 205b 302e 3032 352c 2030 2e30 385d 0a0a   [0.025, 0.08]..
+0001b780: 2020 2020 5265 7475 726e 730a 2020 2020      Returns.    
+0001b790: 2d2d 2d2d 2d2d 2d0a 2020 2020 793a 2066  -------.    y: f
+0001b7a0: 6c6f 6174 206f 7220 6e64 6172 7261 7920  loat or ndarray 
+0001b7b0: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
+0001b7c0: 2078 2031 5d0a 2020 2020 2020 2020 4f75   x 1].        Ou
+0001b7d0: 7470 7574 2064 6174 610a 0a20 2020 204e  tput data..    N
+0001b7e0: 6f74 6573 0a20 2020 202d 2d2d 2d2d 0a20  otes.    -----. 
+0001b7f0: 2020 202e 2e20 5b31 5d20 466f 7272 6573     .. [1] Forres
+0001b800: 7465 722c 2041 2e2c 2053 6f62 6573 7465  ter, A., Sobeste
+0001b810: 722c 2041 2e2c 2026 204b 6561 6e65 2c20  r, A., & Keane, 
+0001b820: 412e 2028 3230 3038 292e 0a20 2020 2020  A. (2008)..     
+0001b830: 2020 456e 6769 6e65 6572 696e 6720 6465    Engineering de
+0001b840: 7369 676e 2076 6961 2073 7572 726f 6761  sign via surroga
+0001b850: 7465 206d 6f64 656c 6c69 6e67 3a20 6120  te modelling: a 
+0001b860: 7072 6163 7469 6361 6c20 6775 6964 652e  practical guide.
+0001b870: 204a 6f68 6e20 5769 6c65 7920 2620 536f   John Wiley & So
+0001b880: 6e73 2e0a 2020 2020 2222 220a 0a20 2020  ns..    """..   
+0001b890: 2064 6566 205f 5f69 6e69 745f 5f28 7365   def __init__(se
+0001b8a0: 6c66 2c20 6d61 746c 6162 5f6d 6f64 656c  lf, matlab_model
+0001b8b0: 3d46 616c 7365 293a 0a20 2020 2020 2020  =False):.       
+0001b8c0: 2073 7570 6572 2874 7970 6528 7365 6c66   super(type(self
+0001b8d0: 292c 2073 656c 6629 2e5f 5f69 6e69 745f  ), self).__init_
+0001b8e0: 5f28 6d61 746c 6162 5f6d 6f64 656c 3d6d  _(matlab_model=m
+0001b8f0: 6174 6c61 625f 6d6f 6465 6c29 0a20 2020  atlab_model).   
+0001b900: 2020 2020 2073 656c 662e 666e 616d 6520       self.fname 
+0001b910: 3d20 696e 7370 6563 742e 6765 7466 696c  = inspect.getfil
+0001b920: 6528 696e 7370 6563 742e 6375 7272 656e  e(inspect.curren
+0001b930: 7466 7261 6d65 2829 290a 0a20 2020 2064  tframe())..    d
+0001b940: 6566 2076 616c 6964 6174 6528 7365 6c66  ef validate(self
+0001b950: 293a 0a20 2020 2020 2020 2070 6173 730a  ):.        pass.
+0001b960: 0a20 2020 2064 6566 2073 696d 756c 6174  .    def simulat
+0001b970: 6528 7365 6c66 2c20 7072 6f63 6573 735f  e(self, process_
+0001b980: 6964 3d4e 6f6e 652c 206d 6174 6c61 625f  id=None, matlab_
+0001b990: 656e 6769 6e65 3d4e 6f6e 6529 3a0a 2020  engine=None):.  
+0001b9a0: 2020 2020 2020 7920 3d20 302e 3033 3620        y = 0.036 
+0001b9b0: 2a20 7365 6c66 2e70 5b22 7831 225d 202a  * self.p["x1"] *
+0001b9c0: 2a20 302e 3735 3820 2a20 7365 6c66 2e70  * 0.758 * self.p
+0001b9d0: 5b22 7832 225d 202a 2a20 302e 3030 3335  ["x2"] ** 0.0035
+0001b9e0: 202a 205c 0a20 2020 2020 2020 2020 2020   * \.           
+0001b9f0: 2020 2873 656c 662e 705b 2278 3322 5d20    (self.p["x3"] 
+0001ba00: 2f20 6e70 2e63 6f73 2873 656c 662e 705b  / np.cos(self.p[
+0001ba10: 2278 3422 5d29 202a 2a20 3229 202a 2a20  "x4"]) ** 2) ** 
+0001ba20: 302e 3620 2a20 5c0a 2020 2020 2020 2020  0.6 * \.        
+0001ba30: 2020 2020 2073 656c 662e 705b 2278 3522       self.p["x5"
+0001ba40: 5d20 2a2a 2030 2e30 3036 202a 2073 656c  ] ** 0.006 * sel
+0001ba50: 662e 705b 2278 3622 5d20 2a2a 2030 2e30  f.p["x6"] ** 0.0
+0001ba60: 3420 2a20 5c0a 2020 2020 2020 2020 2020  4 * \.          
+0001ba70: 2020 2028 3130 3020 2a20 7365 6c66 2e70     (100 * self.p
+0001ba80: 5b22 7837 225d 202f 206e 702e 636f 7328  ["x7"] / np.cos(
+0001ba90: 7365 6c66 2e70 5b22 7834 225d 2929 2a2a  self.p["x4"]))**
+0001baa0: 282d 302e 3329 202a 205c 0a20 2020 2020  (-0.3) * \.     
+0001bab0: 2020 2020 2020 2020 2873 656c 662e 705b          (self.p[
+0001bac0: 2278 3822 5d20 2a20 7365 6c66 2e70 5b22  "x8"] * self.p["
+0001bad0: 7839 225d 292a 2a30 2e34 3920 2b20 7365  x9"])**0.49 + se
+0001bae0: 6c66 2e70 5b22 7831 225d 202a 2073 656c  lf.p["x1"] * sel
+0001baf0: 662e 705b 2278 3130 225d 0a0a 2020 2020  f.p["x10"]..    
+0001bb00: 2020 2020 795f 6f75 7420 3d20 795b 3a2c      y_out = y[:,
+0001bb10: 206e 702e 6e65 7761 7869 735d 0a0a 2020   np.newaxis]..  
+0001bb20: 2020 2020 2020 7265 7475 726e 2079 5f6f        return y_o
+0001bb30: 7574 0a0a 0a63 6c61 7373 2053 7068 6572  ut...class Spher
+0001bb40: 654d 6f64 656c 2841 6273 7472 6163 744d  eModel(AbstractM
+0001bb50: 6f64 656c 293a 0a20 2020 2022 2222 0a20  odel):.    """. 
+0001bb60: 2020 2043 616c 6375 6c61 7465 7320 7468     Calculates th
+0001bb70: 6520 656c 6563 7472 6963 2070 6f74 656e  e electric poten
+0001bb80: 7469 616c 2069 6e20 6120 332d 6c61 7965  tial in a 3-laye
+0001bb90: 7265 6420 7370 6865 7265 2063 6175 7365  red sphere cause
+0001bba0: 6420 6279 2070 6f69 6e74 2d6c 696b 6520  d by point-like 
+0001bbb0: 656c 6563 7472 6f64 6573 0a20 2020 2061  electrodes.    a
+0001bbc0: 6674 6572 2052 7573 6820 616e 6420 4472  fter Rush and Dr
+0001bbd0: 6973 636f 6c6c 2028 3139 3639 2920 5b31  iscoll (1969) [1
+0001bbe0: 5d2e 0a0a 2020 2020 5061 7261 6d65 7465  ]...    Paramete
+0001bbf0: 7273 0a20 2020 202d 2d2d 2d2d 2d2d 2d2d  rs.    ---------
+0001bc00: 2d0a 2020 2020 705b 2273 6967 6d61 5f31  -.    p["sigma_1
+0001bc10: 225d 3a20 666c 6f61 740a 2020 2020 2020  "]: float.      
+0001bc20: 2020 436f 6e64 7563 7469 7669 7479 206f    Conductivity o
+0001bc30: 6620 7468 6520 696e 6e65 726d 6f73 7420  f the innermost 
+0001bc40: 6c61 7965 722c 2069 6e20 2853 2f6d 290a  layer, in (S/m).
+0001bc50: 2020 2020 705b 2273 6967 6d61 5f32 225d      p["sigma_2"]
+0001bc60: 3a20 666c 6f61 740a 2020 2020 2020 2020  : float.        
+0001bc70: 436f 6e64 7563 7469 7669 7479 206f 6620  Conductivity of 
+0001bc80: 7468 6520 696e 7465 726d 6564 6961 7465  the intermediate
+0001bc90: 206c 6179 6572 2c20 696e 2028 532f 6d29   layer, in (S/m)
+0001bca0: 0a20 2020 2070 5b22 7369 676d 615f 3322  .    p["sigma_3"
+0001bcb0: 5d3a 2066 6c6f 6174 0a20 2020 2020 2020  ]: float.       
+0001bcc0: 2043 6f6e 6475 6374 6976 6974 7920 6f66   Conductivity of
+0001bcd0: 2074 6865 206f 7574 6572 6d6f 7374 206c   the outermost l
+0001bce0: 6179 6572 2c20 696e 2028 532f 6d29 0a20  ayer, in (S/m). 
+0001bcf0: 2020 2070 5b22 7261 6469 6922 5d3a 206c     p["radii"]: l
+0001bd00: 6973 7420 5b33 5d0a 2020 2020 2020 2020  ist [3].        
+0001bd10: 5261 6469 7573 206f 6620 6561 6368 206f  Radius of each o
+0001bd20: 6620 7468 6520 3320 6c61 7965 7273 2028  f the 3 layers (
+0001bd30: 696e 6e65 726d 6f73 7420 746f 206f 7574  innermost to out
+0001bd40: 6572 6d6f 7374 292c 2069 6e20 286d 6d29  ermost), in (mm)
+0001bd50: 0a20 2020 2070 5b22 616e 6f64 655f 706f  .    p["anode_po
+0001bd60: 7322 5d3a 206e 6461 7272 6179 206f 6620  s"]: ndarray of 
+0001bd70: 666c 6f61 7420 5b33 2078 2031 5d0a 2020  float [3 x 1].  
+0001bd80: 2020 2020 2020 506f 7369 7469 6f6e 206f        Position o
+0001bd90: 6620 7468 6520 616e 6f64 655f 706f 732c  f the anode_pos,
+0001bda0: 2069 6e20 286d 6d29 0a20 2020 2070 5b22   in (mm).    p["
+0001bdb0: 6361 7468 6f64 655f 706f 7322 5d3a 206e  cathode_pos"]: n
+0001bdc0: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+0001bdd0: 5b33 2078 2031 5d0a 2020 2020 2020 2020  [3 x 1].        
+0001bde0: 506f 7369 7469 6f6e 206f 6620 6361 7468  Position of cath
+0001bdf0: 6f64 655f 706f 732c 2069 6e20 286d 6d29  ode_pos, in (mm)
+0001be00: 0a20 2020 2070 5b22 7022 5d3a 206e 6461  .    p["p"]: nda
+0001be10: 7272 6179 206f 6620 666c 6f61 7420 5b4e  rray of float [N
+0001be20: 2078 2033 5d0a 2020 2020 2020 2020 506f   x 3].        Po
+0001be30: 7369 7469 6f6e 7320 7768 6572 6520 7468  sitions where th
+0001be40: 6520 706f 7465 6e74 6961 6c20 7368 6f75  e potential shou
+0001be50: 6c64 2062 6520 6361 6c63 756c 6174 6564  ld be calculated
+0001be60: 2c20 696e 2028 6d6d 290a 0a20 2020 2052  , in (mm)..    R
+0001be70: 6574 7572 6e73 0a20 2020 202d 2d2d 2d2d  eturns.    -----
+0001be80: 2d2d 0a20 2020 2070 6f74 656e 7469 616c  --.    potential
+0001be90: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
+0001bea0: 6174 205b 3120 7820 6e5f 6f75 745d 0a20  at [1 x n_out]. 
+0001beb0: 2020 2020 2020 2056 616c 7565 7320 6f66         Values of
+0001bec0: 2074 6865 2065 6c65 6374 7269 6320 706f   the electric po
+0001bed0: 7465 6e74 6961 6c2c 2069 6e20 2856 290a  tential, in (V).
+0001bee0: 0a20 2020 204e 6f74 6573 0a20 2020 202d  .    Notes.    -
+0001bef0: 2d2d 2d2d 0a20 2020 202e 2e20 5b31 5d20  ----.    .. [1] 
+0001bf00: 5275 7368 2c20 532e 2c20 2620 4472 6973  Rush, S., & Dris
+0001bf10: 636f 6c6c 2c20 442e 2041 2e20 2831 3936  coll, D. A. (196
+0001bf20: 3929 2e20 4545 4720 656c 6563 7472 6f64  9). EEG electrod
+0001bf30: 6520 7365 6e73 6974 6976 6974 792d 616e  e sensitivity-an
+0001bf40: 2061 7070 6c69 6361 7469 6f6e 206f 6620   application of 
+0001bf50: 7265 6369 7072 6f63 6974 792e 0a20 2020  reciprocity..   
+0001bf60: 2020 2020 4945 4545 2074 7261 6e73 6163      IEEE transac
+0001bf70: 7469 6f6e 7320 6f6e 2062 696f 6d65 6469  tions on biomedi
+0001bf80: 6361 6c20 656e 6769 6e65 6572 696e 672c  cal engineering,
+0001bf90: 2028 3129 2c20 3135 2d32 322e 0a20 2020   (1), 15-22..   
+0001bfa0: 2022 2222 0a20 2020 2064 6566 205f 5f69   """.    def __i
+0001bfb0: 6e69 745f 5f28 7365 6c66 2c20 6d61 746c  nit__(self, matl
+0001bfc0: 6162 5f6d 6f64 656c 3d46 616c 7365 293a  ab_model=False):
+0001bfd0: 0a20 2020 2020 2020 2073 7570 6572 2874  .        super(t
+0001bfe0: 7970 6528 7365 6c66 292c 2073 656c 6629  ype(self), self)
+0001bff0: 2e5f 5f69 6e69 745f 5f28 6d61 746c 6162  .__init__(matlab
+0001c000: 5f6d 6f64 656c 3d6d 6174 6c61 625f 6d6f  _model=matlab_mo
+0001c010: 6465 6c29 0a20 2020 2020 2020 2073 656c  del).        sel
+0001c020: 662e 666e 616d 6520 3d20 696e 7370 6563  f.fname = inspec
+0001c030: 742e 6765 7466 696c 6528 696e 7370 6563  t.getfile(inspec
+0001c040: 742e 6375 7272 656e 7466 7261 6d65 2829  t.currentframe()
+0001c050: 290a 2020 2020 2020 2020 7365 6c66 2e6e  ).        self.n
+0001c060: 6272 5f70 6f6c 796e 6f6d 6961 6c73 203d  br_polynomials =
+0001c070: 2035 300a 0a20 2020 2064 6566 2076 616c   50..    def val
+0001c080: 6964 6174 6528 7365 6c66 293a 0a20 2020  idate(self):.   
+0001c090: 2020 2020 2070 6173 730a 0a20 2020 2064       pass..    d
+0001c0a0: 6566 2073 696d 756c 6174 6528 7365 6c66  ef simulate(self
+0001c0b0: 2c20 7072 6f63 6573 735f 6964 3d4e 6f6e  , process_id=Non
+0001c0c0: 652c 206d 6174 6c61 625f 656e 6769 6e65  e, matlab_engine
+0001c0d0: 3d4e 6f6e 6529 3a0a 0a20 2020 2020 2020  =None):..       
+0001c0e0: 2061 7373 6572 7420 6c65 6e28 7365 6c66   assert len(self
+0001c0f0: 2e70 5b22 5222 5d29 203d 3d20 330a 2020  .p["R"]) == 3.  
+0001c100: 2020 2020 2020 6173 7365 7274 2073 656c        assert sel
+0001c110: 662e 705b 2252 225d 5b30 5d20 3c20 7365  f.p["R"][0] < se
+0001c120: 6c66 2e70 5b22 5222 5d5b 315d 203c 2073  lf.p["R"][1] < s
+0001c130: 656c 662e 705b 2252 225d 5b32 5d0a 2020  elf.p["R"][2].  
+0001c140: 2020 2020 2020 6173 7365 7274 206c 656e        assert len
+0001c150: 2873 656c 662e 705b 2261 6e6f 6465 5f70  (self.p["anode_p
+0001c160: 6f73 225d 2920 3d3d 2033 0a20 2020 2020  os"]) == 3.     
+0001c170: 2020 2061 7373 6572 7420 6c65 6e28 7365     assert len(se
+0001c180: 6c66 2e70 5b22 6361 7468 6f64 655f 706f  lf.p["cathode_po
+0001c190: 7322 5d29 203d 3d20 330a 2020 2020 2020  s"]) == 3.      
+0001c1a0: 2020 6173 7365 7274 2073 656c 662e 705b    assert self.p[
+0001c1b0: 2270 6f69 6e74 7322 5d2e 7368 6170 655b  "points"].shape[
+0001c1c0: 315d 203d 3d20 330a 0a20 2020 2020 2020  1] == 3..       
+0001c1d0: 2062 5f6f 7665 725f 7320 3d20 666c 6f61   b_over_s = floa
+0001c1e0: 7428 7365 6c66 2e70 5b22 7369 676d 615f  t(self.p["sigma_
+0001c1f0: 3122 5d29 202f 2066 6c6f 6174 2873 656c  1"]) / float(sel
+0001c200: 662e 705b 2273 6967 6d61 5f32 225d 290a  f.p["sigma_2"]).
+0001c210: 2020 2020 2020 2020 735f 6f76 6572 5f74          s_over_t
+0001c220: 203d 2066 6c6f 6174 2873 656c 662e 705b   = float(self.p[
+0001c230: 2273 6967 6d61 5f32 225d 2920 2f20 666c  "sigma_2"]) / fl
+0001c240: 6f61 7428 7365 6c66 2e70 5b22 7369 676d  oat(self.p["sigm
+0001c250: 615f 3322 5d29 0a20 2020 2020 2020 2072  a_3"]).        r
+0001c260: 6164 6975 735f 6272 6169 6e20 3d20 7365  adius_brain = se
+0001c270: 6c66 2e70 5b22 5222 5d5b 305d 202a 2031  lf.p["R"][0] * 1
+0001c280: 652d 330a 2020 2020 2020 2020 7261 6469  e-3.        radi
+0001c290: 7573 5f73 6b75 6c6c 203d 2073 656c 662e  us_skull = self.
+0001c2a0: 705b 2252 225d 5b31 5d20 2a20 3165 2d33  p["R"][1] * 1e-3
+0001c2b0: 0a20 2020 2020 2020 2072 6164 6975 735f  .        radius_
+0001c2c0: 736b 696e 203d 2073 656c 662e 705b 2252  skin = self.p["R
+0001c2d0: 225d 5b32 5d20 2a20 3165 2d33 0a0a 2020  "][2] * 1e-3..  
+0001c2e0: 2020 2020 2020 7220 3d20 6e70 2e6c 696e        r = np.lin
+0001c2f0: 616c 672e 6e6f 726d 2873 656c 662e 705b  alg.norm(self.p[
+0001c300: 2270 6f69 6e74 7322 5d2c 2061 7869 733d  "points"], axis=
+0001c310: 3129 202a 2031 652d 330a 2020 2020 2020  1) * 1e-3.      
+0001c320: 2020 7468 6574 6120 3d20 6e70 2e61 7263    theta = np.arc
+0001c330: 636f 7328 7365 6c66 2e70 5b22 706f 696e  cos(self.p["poin
+0001c340: 7473 225d 5b3a 2c20 325d 202a 2031 652d  ts"][:, 2] * 1e-
+0001c350: 3320 2f20 7229 0a20 2020 2020 2020 2070  3 / r).        p
+0001c360: 6869 203d 206e 702e 6172 6374 616e 3228  hi = np.arctan2(
+0001c370: 7365 6c66 2e70 5b22 706f 696e 7473 225d  self.p["points"]
+0001c380: 5b3a 2c20 315d 2c20 7365 6c66 2e70 5b22  [:, 1], self.p["
+0001c390: 706f 696e 7473 225d 5b3a 2c20 305d 290a  points"][:, 0]).
+0001c3a0: 0a20 2020 2020 2020 2070 5f72 203d 206e  .        p_r = n
+0001c3b0: 702e 7673 7461 636b 2828 722c 2074 6865  p.vstack((r, the
+0001c3c0: 7461 2c20 7068 6929 292e 540a 0a20 2020  ta, phi)).T..   
+0001c3d0: 2020 2020 2063 6174 686f 6465 5f70 6f73       cathode_pos
+0001c3e0: 203d 2028 6e70 2e73 7172 7428 7365 6c66   = (np.sqrt(self
+0001c3f0: 2e70 5b22 6361 7468 6f64 655f 706f 7322  .p["cathode_pos"
+0001c400: 5d5b 305d 202a 2a20 3220 2b0a 2020 2020  ][0] ** 2 +.    
+0001c410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c420: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+0001c430: 705b 2263 6174 686f 6465 5f70 6f73 225d  p["cathode_pos"]
+0001c440: 5b31 5d20 2a2a 2032 202b 0a20 2020 2020  [1] ** 2 +.     
+0001c450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c460: 2020 2020 2020 2020 2020 7365 6c66 2e70            self.p
+0001c470: 5b22 6361 7468 6f64 655f 706f 7322 5d5b  ["cathode_pos"][
+0001c480: 325d 202a 2a20 3229 202a 2031 652d 332c  2] ** 2) * 1e-3,
+0001c490: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001c4a0: 2020 2020 2020 2020 6e70 2e61 7263 636f          np.arcco
+0001c4b0: 7328 7365 6c66 2e70 5b22 6361 7468 6f64  s(self.p["cathod
+0001c4c0: 655f 706f 7322 5d5b 325d 202f 0a20 2020  e_pos"][2] /.   
+0001c4d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c4e0: 2020 2020 2020 2020 2020 2020 2020 6e70                np
+0001c4f0: 2e73 7172 7428 7365 6c66 2e70 5b22 6361  .sqrt(self.p["ca
+0001c500: 7468 6f64 655f 706f 7322 5d5b 305d 202a  thode_pos"][0] *
+0001c510: 2a20 3220 2b0a 2020 2020 2020 2020 2020  * 2 +.          
+0001c520: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c530: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+0001c540: 656c 662e 705b 2263 6174 686f 6465 5f70  elf.p["cathode_p
+0001c550: 6f73 225d 5b31 5d20 2a2a 2032 202b 0a20  os"][1] ** 2 +. 
+0001c560: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c570: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c580: 2020 2020 2020 2020 7365 6c66 2e70 5b22          self.p["
+0001c590: 6361 7468 6f64 655f 706f 7322 5d5b 325d  cathode_pos"][2]
+0001c5a0: 202a 2a20 3229 292c 0a20 2020 2020 2020   ** 2)),.       
+0001c5b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c5c0: 6e70 2e61 7263 7461 6e32 2873 656c 662e  np.arctan2(self.
+0001c5d0: 705b 2263 6174 686f 6465 5f70 6f73 225d  p["cathode_pos"]
+0001c5e0: 5b31 5d2c 2073 656c 662e 705b 2263 6174  [1], self.p["cat
+0001c5f0: 686f 6465 5f70 6f73 225d 5b30 5d29 290a  hode_pos"][0])).
+0001c600: 0a20 2020 2020 2020 2061 6e6f 6465 5f70  .        anode_p
+0001c610: 6f73 203d 2028 0a20 2020 2020 2020 2020  os = (.         
+0001c620: 2020 206e 702e 7371 7274 2873 656c 662e     np.sqrt(self.
+0001c630: 705b 2261 6e6f 6465 5f70 6f73 225d 5b30  p["anode_pos"][0
+0001c640: 5d20 2a2a 2032 202b 2073 656c 662e 705b  ] ** 2 + self.p[
+0001c650: 2261 6e6f 6465 5f70 6f73 225d 5b31 5d20  "anode_pos"][1] 
+0001c660: 2a2a 2032 202b 2073 656c 662e 705b 2261  ** 2 + self.p["a
+0001c670: 6e6f 6465 5f70 6f73 225d 5b32 5d20 2a2a  node_pos"][2] **
+0001c680: 2032 2920 2a20 3165 2d33 2c0a 2020 2020   2) * 1e-3,.    
+0001c690: 2020 2020 2020 2020 6e70 2e61 7263 636f          np.arcco
+0001c6a0: 7328 7365 6c66 2e70 5b22 616e 6f64 655f  s(self.p["anode_
+0001c6b0: 706f 7322 5d5b 325d 202f 0a20 2020 2020  pos"][2] /.     
+0001c6c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c6d0: 206e 702e 7371 7274 2873 656c 662e 705b   np.sqrt(self.p[
+0001c6e0: 2261 6e6f 6465 5f70 6f73 225d 5b30 5d20  "anode_pos"][0] 
+0001c6f0: 2a2a 2032 202b 0a20 2020 2020 2020 2020  ** 2 +.         
+0001c700: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c710: 2020 2020 2073 656c 662e 705b 2261 6e6f       self.p["ano
+0001c720: 6465 5f70 6f73 225d 5b31 5d20 2a2a 2032  de_pos"][1] ** 2
+0001c730: 202b 0a20 2020 2020 2020 2020 2020 2020   +.             
+0001c740: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c750: 2073 656c 662e 705b 2261 6e6f 6465 5f70   self.p["anode_p
+0001c760: 6f73 225d 5b32 5d20 2a2a 2032 2929 2c0a  os"][2] ** 2)),.
+0001c770: 2020 2020 2020 2020 2020 2020 6e70 2e61              np.a
+0001c780: 7263 7461 6e32 2873 656c 662e 705b 2261  rctan2(self.p["a
+0001c790: 6e6f 6465 5f70 6f73 225d 5b31 5d2c 2073  node_pos"][1], s
+0001c7a0: 656c 662e 705b 2261 6e6f 6465 5f70 6f73  elf.p["anode_pos
+0001c7b0: 225d 5b30 5d29 290a 0a20 2020 2020 2020  "][0]))..       
+0001c7c0: 2064 6566 2061 286e 293a 0a20 2020 2020   def a(n):.     
+0001c7d0: 2020 2020 2020 2072 6574 7572 6e20 2828         return ((
+0001c7e0: 3220 2a20 6e20 2b20 3129 202a 2a20 3320  2 * n + 1) ** 3 
+0001c7f0: 2f20 2832 202a 206e 2929 202f 2028 2828  / (2 * n)) / (((
+0001c800: 625f 6f76 6572 5f73 202b 2031 2920 2a20  b_over_s + 1) * 
+0001c810: 6e20 2b20 3129 202a 2028 2873 5f6f 7665  n + 1) * ((s_ove
+0001c820: 725f 7420 2b20 3129 202a 206e 202b 2031  r_t + 1) * n + 1
+0001c830: 2920 2b0a 2020 2020 2020 2020 2020 2020  ) +.            
+0001c840: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c850: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c860: 2020 2020 2020 2028 625f 6f76 6572 5f73         (b_over_s
+0001c870: 202d 2031 2920 2a20 2873 5f6f 7665 725f   - 1) * (s_over_
+0001c880: 7420 2d20 3129 202a 206e 202a 2028 6e20  t - 1) * n * (n 
+0001c890: 2b20 3129 202a 0a20 2020 2020 2020 2020  + 1) *.         
+0001c8a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c8b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c8c0: 2020 2020 2020 2020 2020 2872 6164 6975            (radiu
+0001c8d0: 735f 6272 6169 6e20 2f20 7261 6469 7573  s_brain / radius
+0001c8e0: 5f73 6b75 6c6c 2920 2a2a 2028 3220 2a20  _skull) ** (2 * 
+0001c8f0: 6e20 2b20 3129 202b 0a20 2020 2020 2020  n + 1) +.       
+0001c900: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c910: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c920: 2020 2020 2020 2020 2020 2020 2873 5f6f              (s_o
+0001c930: 7665 725f 7420 2d20 3129 202a 2028 6e20  ver_t - 1) * (n 
+0001c940: 2b20 3129 202a 2028 2862 5f6f 7665 725f  + 1) * ((b_over_
+0001c950: 7320 2b20 3129 202a 206e 202b 2031 2920  s + 1) * n + 1) 
+0001c960: 2a0a 2020 2020 2020 2020 2020 2020 2020  *.              
+0001c970: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c980: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c990: 2020 2020 2028 7261 6469 7573 5f73 6b75       (radius_sku
+0001c9a0: 6c6c 202f 2072 6164 6975 735f 736b 696e  ll / radius_skin
+0001c9b0: 2920 2a2a 2028 3220 2a20 6e20 2b20 3129  ) ** (2 * n + 1)
+0001c9c0: 202b 0a20 2020 2020 2020 2020 2020 2020   +.             
+0001c9d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c9e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c9f0: 2020 2020 2020 2862 5f6f 7665 725f 7320        (b_over_s 
+0001ca00: 2d20 3129 202a 2028 6e20 2b20 3129 202a  - 1) * (n + 1) *
+0001ca10: 2028 2873 5f6f 7665 725f 7420 2b20 3129   ((s_over_t + 1)
+0001ca20: 202a 2028 6e20 2b20 3129 202d 2031 2920   * (n + 1) - 1) 
+0001ca30: 2a0a 2020 2020 2020 2020 2020 2020 2020  *.              
+0001ca40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ca50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ca60: 2020 2020 2028 7261 6469 7573 5f62 7261       (radius_bra
+0001ca70: 696e 202f 2072 6164 6975 735f 736b 696e  in / radius_skin
+0001ca80: 2920 2a2a 2028 3220 2a20 6e20 2b20 3129  ) ** (2 * n + 1)
+0001ca90: 290a 0a20 2020 2020 2020 2023 2041 6c6c  )..        # All
+0001caa0: 206f 6620 7468 6520 6265 6c6c 6f77 2069   of the bellow i
+0001cab0: 7320 6d6f 6469 6669 6564 3a20 6469 7669  s modified: divi
+0001cac0: 7369 6f6e 2062 7920 7261 6469 7573 5f73  sion by radius_s
+0001cad0: 6b69 6e20 6d6f 7665 6420 746f 2074 6865  kin moved to the
+0001cae0: 0a20 2020 2020 2020 2023 2063 6f65 6666  .        # coeff
+0001caf0: 6963 6965 6e74 7320 6361 6c63 756c 6174  icients calculat
+0001cb00: 696f 6e73 2064 7565 2074 6f20 6e75 6d65  ions due to nume
+0001cb10: 7269 6361 6c20 636f 6e73 7472 6169 6e74  rical constraint
+0001cb20: 730a 2020 2020 2020 2020 2320 5448 4953  s.        # THIS
+0001cb30: 2049 5320 4449 4646 4552 454e 5420 4652   IS DIFFERENT FR
+0001cb40: 4f4d 2054 4845 2050 4150 4552 2028 7468  OM THE PAPER (th
+0001cb50: 6572 6527 7320 6120 7375 6d20 696e 7374  ere's a sum inst
+0001cb60: 6561 6420 6f66 2064 6966 6665 7265 6e63  ead of differenc
+0001cb70: 6529 0a20 2020 2020 2020 2064 6566 2073  e).        def s
+0001cb80: 286e 293a 0a20 2020 2020 2020 2020 2020  (n):.           
+0001cb90: 2072 6574 7572 6e20 2861 286e 2929 202a   return (a(n)) *
+0001cba0: 2028 2831 202b 2062 5f6f 7665 725f 7329   ((1 + b_over_s)
+0001cbb0: 202a 206e 202b 2031 2920 2f20 2832 202a   * n + 1) / (2 *
+0001cbc0: 206e 202b 2031 290a 0a20 2020 2020 2020   n + 1)..       
+0001cbd0: 2064 6566 2075 286e 293a 0a20 2020 2020   def u(n):.     
+0001cbe0: 2020 2020 2020 2072 6574 7572 6e20 2861         return (a
+0001cbf0: 286e 2920 2a20 7261 6469 7573 5f73 6b69  (n) * radius_ski
+0001cc00: 6e29 202a 206e 202a 2028 3120 2d20 625f  n) * n * (1 - b_
+0001cc10: 6f76 6572 5f73 2920 2a20 5c0a 2020 2020  over_s) * \.    
+0001cc20: 2020 2020 2020 2020 2020 2020 2020 2072                 r
+0001cc30: 6164 6975 735f 6272 6169 6e20 2a2a 2028  adius_brain ** (
+0001cc40: 3220 2a20 6e20 2b20 3129 202f 2028 3220  2 * n + 1) / (2 
+0001cc50: 2a20 6e20 2b20 3129 0a0a 2020 2020 2020  * n + 1)..      
+0001cc60: 2020 6465 6620 7428 6e29 3a0a 2020 2020    def t(n):.    
+0001cc70: 2020 2020 2020 2020 7265 7475 726e 2028          return (
+0001cc80: 6128 6e29 202f 2028 2832 202a 206e 202b  a(n) / ((2 * n +
+0001cc90: 2031 2920 2a2a 2032 2929 202a 205c 0a20   1) ** 2)) * \. 
+0001cca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ccb0: 2020 2828 2831 202b 2062 5f6f 7665 725f    (((1 + b_over_
+0001ccc0: 7329 202a 206e 202b 2031 2920 2a20 2828  s) * n + 1) * ((
+0001ccd0: 3120 2b20 735f 6f76 6572 5f74 2920 2a20  1 + s_over_t) * 
+0001cce0: 6e20 2b20 3129 202b 0a20 2020 2020 2020  n + 1) +.       
+0001ccf0: 2020 2020 2020 2020 2020 2020 206e 202a               n *
+0001cd00: 2028 6e20 2b20 3129 202a 2028 3120 2d20   (n + 1) * (1 - 
+0001cd10: 625f 6f76 6572 5f73 2920 2a20 2831 202d  b_over_s) * (1 -
+0001cd20: 2073 5f6f 7665 725f 7429 202a 2028 7261   s_over_t) * (ra
+0001cd30: 6469 7573 5f62 7261 696e 202f 2072 6164  dius_brain / rad
+0001cd40: 6975 735f 736b 756c 6c29 202a 2a20 2832  ius_skull) ** (2
+0001cd50: 202a 206e 202b 2031 2929 0a0a 2020 2020   * n + 1))..    
+0001cd60: 2020 2020 6465 6620 7728 6e29 3a0a 2020      def w(n):.  
+0001cd70: 2020 2020 2020 2020 2020 7265 7475 726e            return
+0001cd80: 2028 286e 202a 2061 286e 2920 2a20 7261   ((n * a(n) * ra
+0001cd90: 6469 7573 5f73 6b69 6e29 202f 2028 2832  dius_skin) / ((2
+0001cda0: 202a 206e 202b 2031 2920 2a2a 2032 2929   * n + 1) ** 2))
+0001cdb0: 202a 205c 0a20 2020 2020 2020 2020 2020   * \.           
+0001cdc0: 2020 2020 2020 2020 2828 3120 2d20 735f          ((1 - s_
+0001cdd0: 6f76 6572 5f74 2920 2a20 2828 3120 2b20  over_t) * ((1 + 
+0001cde0: 625f 6f76 6572 5f73 2920 2a20 6e20 2b20  b_over_s) * n + 
+0001cdf0: 3129 202a 2072 6164 6975 735f 736b 756c  1) * radius_skul
+0001ce00: 6c20 2a2a 2028 3220 2a20 6e20 2b20 3129  l ** (2 * n + 1)
+0001ce10: 202b 0a20 2020 2020 2020 2020 2020 2020   +.             
+0001ce20: 2020 2020 2020 2028 3120 2d20 625f 6f76         (1 - b_ov
+0001ce30: 6572 5f73 2920 2a20 2828 3120 2b20 735f  er_s) * ((1 + s_
+0001ce40: 6f76 6572 5f74 2920 2a20 6e20 2b20 735f  over_t) * n + s_
+0001ce50: 6f76 6572 5f74 2920 2a20 7261 6469 7573  over_t) * radius
+0001ce60: 5f62 7261 696e 202a 2a20 2832 202a 206e  _brain ** (2 * n
+0001ce70: 202b 2031 2929 0a0a 2020 2020 2020 2020   + 1))..        
+0001ce80: 6272 6169 6e5f 7265 6769 6f6e 203d 206e  brain_region = n
+0001ce90: 702e 7768 6572 6528 705f 725b 3a2c 2030  p.where(p_r[:, 0
+0001cea0: 5d20 3c3d 2072 6164 6975 735f 6272 6169  ] <= radius_brai
+0001ceb0: 6e29 5b30 5d0a 2020 2020 2020 2020 736b  n)[0].        sk
+0001cec0: 756c 6c5f 7265 6769 6f6e 203d 206e 702e  ull_region = np.
+0001ced0: 7768 6572 6528 0a20 2020 2020 2020 2020  where(.         
+0001cee0: 2020 2028 705f 725b 3a2c 2030 5d20 3e20     (p_r[:, 0] > 
+0001cef0: 7261 6469 7573 5f62 7261 696e 2920 2a20  radius_brain) * 
+0001cf00: 2870 5f72 5b3a 2c20 305d 203c 3d20 7261  (p_r[:, 0] <= ra
+0001cf10: 6469 7573 5f73 6b75 6c6c 2929 5b30 5d0a  dius_skull))[0].
+0001cf20: 2020 2020 2020 2020 736b 696e 5f72 6567          skin_reg
+0001cf30: 696f 6e20 3d20 6e70 2e77 6865 7265 2828  ion = np.where((
+0001cf40: 705f 725b 3a2c 2030 5d20 3e20 7261 6469  p_r[:, 0] > radi
+0001cf50: 7573 5f73 6b75 6c6c 290a 2020 2020 2020  us_skull).      
+0001cf60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cf70: 2020 2020 2020 2020 202a 2028 705f 725b           * (p_r[
+0001cf80: 3a2c 2030 5d20 3c3d 2072 6164 6975 735f  :, 0] <= radius_
+0001cf90: 736b 696e 2929 5b30 5d0a 2020 2020 2020  skin))[0].      
+0001cfa0: 2020 696e 7369 6465 5f73 7068 6572 6520    inside_sphere 
+0001cfb0: 3d20 6e70 2e77 6865 7265 2828 705f 725b  = np.where((p_r[
+0001cfc0: 3a2c 2030 5d20 3c3d 2072 6164 6975 735f  :, 0] <= radius_
+0001cfd0: 736b 696e 2929 5b30 5d0a 2020 2020 2020  skin))[0].      
+0001cfe0: 2020 6f75 7473 6964 655f 7370 6865 7265    outside_sphere
+0001cff0: 203d 206e 702e 7768 6572 6528 2870 5f72   = np.where((p_r
+0001d000: 5b3a 2c20 305d 203e 2072 6164 6975 735f  [:, 0] > radius_
+0001d010: 736b 696e 2929 5b30 5d0a 0a20 2020 2020  skin))[0]..     
+0001d020: 2020 2063 6f73 5f74 6865 7461 5f61 203d     cos_theta_a =
+0001d030: 206e 702e 636f 7328 6361 7468 6f64 655f   np.cos(cathode_
+0001d040: 706f 735b 315d 2920 2a20 6e70 2e63 6f73  pos[1]) * np.cos
+0001d050: 2870 5f72 5b3a 2c20 315d 2920 2b20 5c0a  (p_r[:, 1]) + \.
+0001d060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d070: 2020 2020 2020 6e70 2e73 696e 2863 6174        np.sin(cat
+0001d080: 686f 6465 5f70 6f73 5b31 5d29 202a 206e  hode_pos[1]) * n
+0001d090: 702e 7369 6e28 705f 725b 3a2c 2031 5d29  p.sin(p_r[:, 1])
+0001d0a0: 202a 205c 0a20 2020 2020 2020 2020 2020   * \.           
+0001d0b0: 2020 2020 2020 2020 2020 206e 702e 636f             np.co
+0001d0c0: 7328 705f 725b 3a2c 2032 5d20 2d20 6361  s(p_r[:, 2] - ca
+0001d0d0: 7468 6f64 655f 706f 735b 325d 290a 2020  thode_pos[2]).  
+0001d0e0: 2020 2020 2020 636f 735f 7468 6574 615f        cos_theta_
+0001d0f0: 6220 3d20 6e70 2e63 6f73 2861 6e6f 6465  b = np.cos(anode
+0001d100: 5f70 6f73 5b31 5d29 202a 206e 702e 636f  _pos[1]) * np.co
+0001d110: 7328 705f 725b 3a2c 2031 5d29 202b 205c  s(p_r[:, 1]) + \
+0001d120: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001d130: 2020 2020 2020 206e 702e 7369 6e28 616e         np.sin(an
+0001d140: 6f64 655f 706f 735b 315d 2920 2a20 6e70  ode_pos[1]) * np
+0001d150: 2e73 696e 2870 5f72 5b3a 2c20 315d 2920  .sin(p_r[:, 1]) 
+0001d160: 2a20 5c0a 2020 2020 2020 2020 2020 2020  * \.            
+0001d170: 2020 2020 2020 2020 2020 6e70 2e63 6f73            np.cos
+0001d180: 2870 5f72 5b3a 2c20 325d 202d 2061 6e6f  (p_r[:, 2] - ano
+0001d190: 6465 5f70 6f73 5b32 5d29 0a0a 2020 2020  de_pos[2])..    
+0001d1a0: 2020 2020 706f 7465 6e74 6961 6c73 203d      potentials =
+0001d1b0: 206e 702e 7a65 726f 7328 2873 656c 662e   np.zeros((self.
+0001d1c0: 705b 2270 6f69 6e74 7322 5d2e 7368 6170  p["points"].shap
+0001d1d0: 655b 305d 292c 2064 7479 7065 3d27 666c  e[0]), dtype='fl
+0001d1e0: 6f61 7436 3427 290a 0a20 2020 2020 2020  oat64')..       
+0001d1f0: 2063 6f65 6666 6963 6965 6e74 7320 3d20   coefficients = 
+0001d200: 6e70 2e7a 6572 6f73 2828 7365 6c66 2e6e  np.zeros((self.n
+0001d210: 6272 5f70 6f6c 796e 6f6d 6961 6c73 2c20  br_polynomials, 
+0001d220: 7365 6c66 2e70 5b22 706f 696e 7473 225d  self.p["points"]
+0001d230: 2e73 6861 7065 5b30 5d29 2c20 6474 7970  .shape[0]), dtyp
+0001d240: 653d 2766 6c6f 6174 3634 2729 0a0a 2020  e='float64')..  
+0001d250: 2020 2020 2020 2320 6163 6365 6c65 7261        # accelera
+0001d260: 7465 0a20 2020 2020 2020 2066 6f72 2069  te.        for i
+0001d270: 6920 696e 2072 616e 6765 2831 2c20 7365  i in range(1, se
+0001d280: 6c66 2e6e 6272 5f70 6f6c 796e 6f6d 6961  lf.nbr_polynomia
+0001d290: 6c73 293a 0a20 2020 2020 2020 2020 2020  ls):.           
+0001d2a0: 206e 6920 3d20 666c 6f61 7428 6969 290a   ni = float(ii).
+0001d2b0: 2020 2020 2020 2020 2020 2020 636f 6566              coef
+0001d2c0: 6669 6369 656e 7473 5b69 692c 2062 7261  ficients[ii, bra
+0001d2d0: 696e 5f72 6567 696f 6e5d 203d 206e 702e  in_region] = np.
+0001d2e0: 6e61 6e5f 746f 5f6e 756d 280a 2020 2020  nan_to_num(.    
+0001d2f0: 2020 2020 2020 2020 2020 2020 6128 6e69              a(ni
+0001d300: 2920 2a20 2828 705f 725b 6272 6169 6e5f  ) * ((p_r[brain_
+0001d310: 7265 6769 6f6e 2c20 305d 202f 2072 6164  region, 0] / rad
+0001d320: 6975 735f 736b 696e 2920 2a2a 206e 6929  ius_skin) ** ni)
+0001d330: 290a 0a20 2020 2020 2020 2020 2020 2063  )..            c
+0001d340: 6f65 6666 6963 6965 6e74 735b 6969 2c20  oefficients[ii, 
+0001d350: 736b 756c 6c5f 7265 6769 6f6e 5d20 3d20  skull_region] = 
+0001d360: 6e70 2e6e 616e 5f74 6f5f 6e75 6d28 7328  np.nan_to_num(s(
+0001d370: 6e69 2920 2a20 2870 5f72 5b73 6b75 6c6c  ni) * (p_r[skull
+0001d380: 5f72 6567 696f 6e2c 2030 5d20 2f20 7261  _region, 0] / ra
+0001d390: 6469 7573 5f73 6b69 6e29 202a 2a20 6e69  dius_skin) ** ni
+0001d3a0: 202b 0a20 2020 2020 2020 2020 2020 2020   +.             
+0001d3b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 0001d3c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d3d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d3e0: 2020 7365 6c66 2e70 5b22 6361 7468 6f64    self.p["cathod
-0001d3f0: 655f 706f 7322 5d5b 315d 202a 2a20 3220  e_pos"][1] ** 2 
-0001d400: 2b0d 0a20 2020 2020 2020 2020 2020 2020  +..             
-0001d410: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d420: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-0001d430: 2e70 5b22 6361 7468 6f64 655f 706f 7322  .p["cathode_pos"
-0001d440: 5d5b 325d 202a 2a20 3229 292c 0d0a 2020  ][2] ** 2)),..  
-0001d450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d460: 2020 2020 206e 702e 6172 6374 616e 3228       np.arctan2(
-0001d470: 7365 6c66 2e70 5b22 6361 7468 6f64 655f  self.p["cathode_
-0001d480: 706f 7322 5d5b 315d 2c20 7365 6c66 2e70  pos"][1], self.p
-0001d490: 5b22 6361 7468 6f64 655f 706f 7322 5d5b  ["cathode_pos"][
-0001d4a0: 305d 2929 0d0a 0d0a 2020 2020 2020 2020  0]))....        
-0001d4b0: 616e 6f64 655f 706f 7320 3d20 280d 0a20  anode_pos = (.. 
-0001d4c0: 2020 2020 2020 2020 2020 206e 702e 7371             np.sq
-0001d4d0: 7274 2873 656c 662e 705b 2261 6e6f 6465  rt(self.p["anode
-0001d4e0: 5f70 6f73 225d 5b30 5d20 2a2a 2032 202b  _pos"][0] ** 2 +
-0001d4f0: 2073 656c 662e 705b 2261 6e6f 6465 5f70   self.p["anode_p
-0001d500: 6f73 225d 5b31 5d20 2a2a 2032 202b 2073  os"][1] ** 2 + s
-0001d510: 656c 662e 705b 2261 6e6f 6465 5f70 6f73  elf.p["anode_pos
-0001d520: 225d 5b32 5d20 2a2a 2032 2920 2a20 3165  "][2] ** 2) * 1e
-0001d530: 2d33 2c0d 0a20 2020 2020 2020 2020 2020  -3,..           
-0001d540: 206e 702e 6172 6363 6f73 2873 656c 662e   np.arccos(self.
-0001d550: 705b 2261 6e6f 6465 5f70 6f73 225d 5b32  p["anode_pos"][2
-0001d560: 5d20 2f0d 0a20 2020 2020 2020 2020 2020  ] /..           
-0001d570: 2020 2020 2020 2020 2020 206e 702e 7371             np.sq
-0001d580: 7274 2873 656c 662e 705b 2261 6e6f 6465  rt(self.p["anode
-0001d590: 5f70 6f73 225d 5b30 5d20 2a2a 2032 202b  _pos"][0] ** 2 +
-0001d5a0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0001d5b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d5c0: 7365 6c66 2e70 5b22 616e 6f64 655f 706f  self.p["anode_po
-0001d5d0: 7322 5d5b 315d 202a 2a20 3220 2b0d 0a20  s"][1] ** 2 +.. 
-0001d5e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d5f0: 2020 2020 2020 2020 2020 2020 2073 656c               sel
-0001d600: 662e 705b 2261 6e6f 6465 5f70 6f73 225d  f.p["anode_pos"]
-0001d610: 5b32 5d20 2a2a 2032 2929 2c0d 0a20 2020  [2] ** 2)),..   
-0001d620: 2020 2020 2020 2020 206e 702e 6172 6374           np.arct
-0001d630: 616e 3228 7365 6c66 2e70 5b22 616e 6f64  an2(self.p["anod
-0001d640: 655f 706f 7322 5d5b 315d 2c20 7365 6c66  e_pos"][1], self
-0001d650: 2e70 5b22 616e 6f64 655f 706f 7322 5d5b  .p["anode_pos"][
-0001d660: 305d 2929 0d0a 0d0a 2020 2020 2020 2020  0]))....        
-0001d670: 6465 6620 6128 6e29 3a0d 0a20 2020 2020  def a(n):..     
-0001d680: 2020 2020 2020 2072 6574 7572 6e20 2828         return ((
-0001d690: 3220 2a20 6e20 2b20 3129 202a 2a20 3320  2 * n + 1) ** 3 
-0001d6a0: 2f20 2832 202a 206e 2929 202f 2028 2828  / (2 * n)) / (((
-0001d6b0: 625f 6f76 6572 5f73 202b 2031 2920 2a20  b_over_s + 1) * 
-0001d6c0: 6e20 2b20 3129 202a 2028 2873 5f6f 7665  n + 1) * ((s_ove
-0001d6d0: 725f 7420 2b20 3129 202a 206e 202b 2031  r_t + 1) * n + 1
-0001d6e0: 2920 2b0d 0a20 2020 2020 2020 2020 2020  ) +..           
-0001d6f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d700: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d710: 2020 2020 2020 2020 2862 5f6f 7665 725f          (b_over_
-0001d720: 7320 2d20 3129 202a 2028 735f 6f76 6572  s - 1) * (s_over
-0001d730: 5f74 202d 2031 2920 2a20 6e20 2a20 286e  _t - 1) * n * (n
-0001d740: 202b 2031 2920 2a0d 0a20 2020 2020 2020   + 1) *..       
-0001d750: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d760: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d770: 2020 2020 2020 2020 2020 2020 2872 6164              (rad
-0001d780: 6975 735f 6272 6169 6e20 2f20 7261 6469  ius_brain / radi
-0001d790: 7573 5f73 6b75 6c6c 2920 2a2a 2028 3220  us_skull) ** (2 
-0001d7a0: 2a20 6e20 2b20 3129 202b 0d0a 2020 2020  * n + 1) +..    
-0001d7b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d7c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d7d0: 2020 2020 2020 2020 2020 2020 2020 2028                 (
-0001d7e0: 735f 6f76 6572 5f74 202d 2031 2920 2a20  s_over_t - 1) * 
-0001d7f0: 286e 202b 2031 2920 2a20 2828 625f 6f76  (n + 1) * ((b_ov
-0001d800: 6572 5f73 202b 2031 2920 2a20 6e20 2b20  er_s + 1) * n + 
-0001d810: 3129 202a 0d0a 2020 2020 2020 2020 2020  1) *..          
-0001d820: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d830: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d840: 2020 2020 2020 2020 2028 7261 6469 7573           (radius
-0001d850: 5f73 6b75 6c6c 202f 2072 6164 6975 735f  _skull / radius_
-0001d860: 736b 696e 2920 2a2a 2028 3220 2a20 6e20  skin) ** (2 * n 
-0001d870: 2b20 3129 202b 0d0a 2020 2020 2020 2020  + 1) +..        
-0001d880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d890: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d8a0: 2020 2020 2020 2020 2020 2028 625f 6f76             (b_ov
-0001d8b0: 6572 5f73 202d 2031 2920 2a20 286e 202b  er_s - 1) * (n +
-0001d8c0: 2031 2920 2a20 2828 735f 6f76 6572 5f74   1) * ((s_over_t
-0001d8d0: 202b 2031 2920 2a20 286e 202b 2031 2920   + 1) * (n + 1) 
-0001d8e0: 2d20 3129 202a 0d0a 2020 2020 2020 2020  - 1) *..        
-0001d8f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d900: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d910: 2020 2020 2020 2020 2020 2028 7261 6469             (radi
-0001d920: 7573 5f62 7261 696e 202f 2072 6164 6975  us_brain / radiu
-0001d930: 735f 736b 696e 2920 2a2a 2028 3220 2a20  s_skin) ** (2 * 
-0001d940: 6e20 2b20 3129 290d 0a0d 0a20 2020 2020  n + 1))....     
-0001d950: 2020 2023 2041 6c6c 206f 6620 7468 6520     # All of the 
-0001d960: 6265 6c6c 6f77 2069 7320 6d6f 6469 6669  bellow is modifi
-0001d970: 6564 3a20 6469 7669 7369 6f6e 2062 7920  ed: division by 
-0001d980: 7261 6469 7573 5f73 6b69 6e20 6d6f 7665  radius_skin move
-0001d990: 6420 746f 2074 6865 0d0a 2020 2020 2020  d to the..      
-0001d9a0: 2020 2320 636f 6566 6669 6369 656e 7473    # coefficients
-0001d9b0: 2063 616c 6375 6c61 7469 6f6e 7320 6475   calculations du
-0001d9c0: 6520 746f 206e 756d 6572 6963 616c 2063  e to numerical c
-0001d9d0: 6f6e 7374 7261 696e 7473 0d0a 2020 2020  onstraints..    
-0001d9e0: 2020 2020 2320 5448 4953 2049 5320 4449      # THIS IS DI
-0001d9f0: 4646 4552 454e 5420 4652 4f4d 2054 4845  FFERENT FROM THE
-0001da00: 2050 4150 4552 2028 7468 6572 6527 7320   PAPER (there's 
-0001da10: 6120 7375 6d20 696e 7374 6561 6420 6f66  a sum instead of
-0001da20: 2064 6966 6665 7265 6e63 6529 0d0a 2020   difference)..  
-0001da30: 2020 2020 2020 6465 6620 7328 6e29 3a0d        def s(n):.
-0001da40: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-0001da50: 7572 6e20 2861 286e 2929 202a 2028 2831  urn (a(n)) * ((1
-0001da60: 202b 2062 5f6f 7665 725f 7329 202a 206e   + b_over_s) * n
-0001da70: 202b 2031 2920 2f20 2832 202a 206e 202b   + 1) / (2 * n +
-0001da80: 2031 290d 0a0d 0a20 2020 2020 2020 2064   1)....        d
-0001da90: 6566 2075 286e 293a 0d0a 2020 2020 2020  ef u(n):..      
-0001daa0: 2020 2020 2020 7265 7475 726e 2028 6128        return (a(
-0001dab0: 6e29 202a 2072 6164 6975 735f 736b 696e  n) * radius_skin
-0001dac0: 2920 2a20 6e20 2a20 2831 202d 2062 5f6f  ) * n * (1 - b_o
-0001dad0: 7665 725f 7329 202a 205c 0d0a 2020 2020  ver_s) * \..    
-0001dae0: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-0001daf0: 6164 6975 735f 6272 6169 6e20 2a2a 2028  adius_brain ** (
-0001db00: 3220 2a20 6e20 2b20 3129 202f 2028 3220  2 * n + 1) / (2 
-0001db10: 2a20 6e20 2b20 3129 0d0a 0d0a 2020 2020  * n + 1)....    
-0001db20: 2020 2020 6465 6620 7428 6e29 3a0d 0a20      def t(n):.. 
-0001db30: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-0001db40: 6e20 2861 286e 2920 2f20 2828 3220 2a20  n (a(n) / ((2 * 
-0001db50: 6e20 2b20 3129 202a 2a20 3229 2920 2a20  n + 1) ** 2)) * 
-0001db60: 5c0d 0a20 2020 2020 2020 2020 2020 2020  \..             
-0001db70: 2020 2020 2020 2828 2831 202b 2062 5f6f        (((1 + b_o
-0001db80: 7665 725f 7329 202a 206e 202b 2031 2920  ver_s) * n + 1) 
-0001db90: 2a20 2828 3120 2b20 735f 6f76 6572 5f74  * ((1 + s_over_t
-0001dba0: 2920 2a20 6e20 2b20 3129 202b 0d0a 2020  ) * n + 1) +..  
-0001dbb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001dbc0: 2020 6e20 2a20 286e 202b 2031 2920 2a20    n * (n + 1) * 
-0001dbd0: 2831 202d 2062 5f6f 7665 725f 7329 202a  (1 - b_over_s) *
-0001dbe0: 2028 3120 2d20 735f 6f76 6572 5f74 2920   (1 - s_over_t) 
-0001dbf0: 2a20 2872 6164 6975 735f 6272 6169 6e20  * (radius_brain 
-0001dc00: 2f20 7261 6469 7573 5f73 6b75 6c6c 2920  / radius_skull) 
-0001dc10: 2a2a 2028 3220 2a20 6e20 2b20 3129 290d  ** (2 * n + 1)).
-0001dc20: 0a0d 0a20 2020 2020 2020 2064 6566 2077  ...        def w
-0001dc30: 286e 293a 0d0a 2020 2020 2020 2020 2020  (n):..          
-0001dc40: 2020 7265 7475 726e 2028 286e 202a 2061    return ((n * a
-0001dc50: 286e 2920 2a20 7261 6469 7573 5f73 6b69  (n) * radius_ski
-0001dc60: 6e29 202f 2028 2832 202a 206e 202b 2031  n) / ((2 * n + 1
-0001dc70: 2920 2a2a 2032 2929 202a 205c 0d0a 2020  ) ** 2)) * \..  
-0001dc80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001dc90: 2028 2831 202d 2073 5f6f 7665 725f 7429   ((1 - s_over_t)
-0001dca0: 202a 2028 2831 202b 2062 5f6f 7665 725f   * ((1 + b_over_
-0001dcb0: 7329 202a 206e 202b 2031 2920 2a20 7261  s) * n + 1) * ra
-0001dcc0: 6469 7573 5f73 6b75 6c6c 202a 2a20 2832  dius_skull ** (2
-0001dcd0: 202a 206e 202b 2031 2920 2b0d 0a20 2020   * n + 1) +..   
-0001dce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001dcf0: 2028 3120 2d20 625f 6f76 6572 5f73 2920   (1 - b_over_s) 
-0001dd00: 2a20 2828 3120 2b20 735f 6f76 6572 5f74  * ((1 + s_over_t
-0001dd10: 2920 2a20 6e20 2b20 735f 6f76 6572 5f74  ) * n + s_over_t
-0001dd20: 2920 2a20 7261 6469 7573 5f62 7261 696e  ) * radius_brain
-0001dd30: 202a 2a20 2832 202a 206e 202b 2031 2929   ** (2 * n + 1))
-0001dd40: 0d0a 0d0a 2020 2020 2020 2020 6272 6169  ....        brai
-0001dd50: 6e5f 7265 6769 6f6e 203d 206e 702e 7768  n_region = np.wh
-0001dd60: 6572 6528 705f 725b 3a2c 2030 5d20 3c3d  ere(p_r[:, 0] <=
-0001dd70: 2072 6164 6975 735f 6272 6169 6e29 5b30   radius_brain)[0
-0001dd80: 5d0d 0a20 2020 2020 2020 2073 6b75 6c6c  ]..        skull
-0001dd90: 5f72 6567 696f 6e20 3d20 6e70 2e77 6865  _region = np.whe
-0001dda0: 7265 280d 0a20 2020 2020 2020 2020 2020  re(..           
-0001ddb0: 2028 705f 725b 3a2c 2030 5d20 3e20 7261   (p_r[:, 0] > ra
-0001ddc0: 6469 7573 5f62 7261 696e 2920 2a20 2870  dius_brain) * (p
-0001ddd0: 5f72 5b3a 2c20 305d 203c 3d20 7261 6469  _r[:, 0] <= radi
-0001dde0: 7573 5f73 6b75 6c6c 2929 5b30 5d0d 0a20  us_skull))[0].. 
-0001ddf0: 2020 2020 2020 2073 6b69 6e5f 7265 6769         skin_regi
-0001de00: 6f6e 203d 206e 702e 7768 6572 6528 2870  on = np.where((p
-0001de10: 5f72 5b3a 2c20 305d 203e 2072 6164 6975  _r[:, 0] > radiu
-0001de20: 735f 736b 756c 6c29 0d0a 2020 2020 2020  s_skull)..      
-0001de30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001de40: 2020 2020 2020 2020 202a 2028 705f 725b           * (p_r[
-0001de50: 3a2c 2030 5d20 3c3d 2072 6164 6975 735f  :, 0] <= radius_
-0001de60: 736b 696e 2929 5b30 5d0d 0a20 2020 2020  skin))[0]..     
-0001de70: 2020 2069 6e73 6964 655f 7370 6865 7265     inside_sphere
-0001de80: 203d 206e 702e 7768 6572 6528 2870 5f72   = np.where((p_r
-0001de90: 5b3a 2c20 305d 203c 3d20 7261 6469 7573  [:, 0] <= radius
-0001dea0: 5f73 6b69 6e29 295b 305d 0d0a 2020 2020  _skin))[0]..    
-0001deb0: 2020 2020 6f75 7473 6964 655f 7370 6865      outside_sphe
-0001dec0: 7265 203d 206e 702e 7768 6572 6528 2870  re = np.where((p
-0001ded0: 5f72 5b3a 2c20 305d 203e 2072 6164 6975  _r[:, 0] > radiu
-0001dee0: 735f 736b 696e 2929 5b30 5d0d 0a0d 0a20  s_skin))[0].... 
-0001def0: 2020 2020 2020 2063 6f73 5f74 6865 7461         cos_theta
-0001df00: 5f61 203d 206e 702e 636f 7328 6361 7468  _a = np.cos(cath
-0001df10: 6f64 655f 706f 735b 315d 2920 2a20 6e70  ode_pos[1]) * np
-0001df20: 2e63 6f73 2870 5f72 5b3a 2c20 315d 2920  .cos(p_r[:, 1]) 
-0001df30: 2b20 5c0d 0a20 2020 2020 2020 2020 2020  + \..           
-0001df40: 2020 2020 2020 2020 2020 206e 702e 7369             np.si
-0001df50: 6e28 6361 7468 6f64 655f 706f 735b 315d  n(cathode_pos[1]
-0001df60: 2920 2a20 6e70 2e73 696e 2870 5f72 5b3a  ) * np.sin(p_r[:
-0001df70: 2c20 315d 2920 2a20 5c0d 0a20 2020 2020  , 1]) * \..     
-0001df80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001df90: 206e 702e 636f 7328 705f 725b 3a2c 2032   np.cos(p_r[:, 2
-0001dfa0: 5d20 2d20 6361 7468 6f64 655f 706f 735b  ] - cathode_pos[
-0001dfb0: 325d 290d 0a20 2020 2020 2020 2063 6f73  2])..        cos
-0001dfc0: 5f74 6865 7461 5f62 203d 206e 702e 636f  _theta_b = np.co
-0001dfd0: 7328 616e 6f64 655f 706f 735b 315d 2920  s(anode_pos[1]) 
-0001dfe0: 2a20 6e70 2e63 6f73 2870 5f72 5b3a 2c20  * np.cos(p_r[:, 
-0001dff0: 315d 2920 2b20 5c0d 0a20 2020 2020 2020  1]) + \..       
-0001e000: 2020 2020 2020 2020 2020 2020 2020 206e                 n
-0001e010: 702e 7369 6e28 616e 6f64 655f 706f 735b  p.sin(anode_pos[
-0001e020: 315d 2920 2a20 6e70 2e73 696e 2870 5f72  1]) * np.sin(p_r
-0001e030: 5b3a 2c20 315d 2920 2a20 5c0d 0a20 2020  [:, 1]) * \..   
-0001e040: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e050: 2020 206e 702e 636f 7328 705f 725b 3a2c     np.cos(p_r[:,
-0001e060: 2032 5d20 2d20 616e 6f64 655f 706f 735b   2] - anode_pos[
-0001e070: 325d 290d 0a0d 0a20 2020 2020 2020 2070  2])....        p
-0001e080: 6f74 656e 7469 616c 7320 3d20 6e70 2e7a  otentials = np.z
-0001e090: 6572 6f73 2828 7365 6c66 2e70 5b22 706f  eros((self.p["po
-0001e0a0: 696e 7473 225d 2e73 6861 7065 5b30 5d29  ints"].shape[0])
-0001e0b0: 2c20 6474 7970 653d 2766 6c6f 6174 3634  , dtype='float64
-0001e0c0: 2729 0d0a 0d0a 2020 2020 2020 2020 636f  ')....        co
-0001e0d0: 6566 6669 6369 656e 7473 203d 206e 702e  efficients = np.
-0001e0e0: 7a65 726f 7328 2873 656c 662e 6e62 725f  zeros((self.nbr_
-0001e0f0: 706f 6c79 6e6f 6d69 616c 732c 2073 656c  polynomials, sel
-0001e100: 662e 705b 2270 6f69 6e74 7322 5d2e 7368  f.p["points"].sh
-0001e110: 6170 655b 305d 292c 2064 7479 7065 3d27  ape[0]), dtype='
-0001e120: 666c 6f61 7436 3427 290d 0a0d 0a20 2020  float64')....   
-0001e130: 2020 2020 2023 2061 6363 656c 6572 6174       # accelerat
-0001e140: 650d 0a20 2020 2020 2020 2066 6f72 2069  e..        for i
-0001e150: 6920 696e 2072 616e 6765 2831 2c20 7365  i in range(1, se
-0001e160: 6c66 2e6e 6272 5f70 6f6c 796e 6f6d 6961  lf.nbr_polynomia
-0001e170: 6c73 293a 0d0a 2020 2020 2020 2020 2020  ls):..          
-0001e180: 2020 6e69 203d 2066 6c6f 6174 2869 6929    ni = float(ii)
-0001e190: 0d0a 2020 2020 2020 2020 2020 2020 636f  ..            co
-0001e1a0: 6566 6669 6369 656e 7473 5b69 692c 2062  efficients[ii, b
-0001e1b0: 7261 696e 5f72 6567 696f 6e5d 203d 206e  rain_region] = n
-0001e1c0: 702e 6e61 6e5f 746f 5f6e 756d 280d 0a20  p.nan_to_num(.. 
-0001e1d0: 2020 2020 2020 2020 2020 2020 2020 2061                 a
-0001e1e0: 286e 6929 202a 2028 2870 5f72 5b62 7261  (ni) * ((p_r[bra
-0001e1f0: 696e 5f72 6567 696f 6e2c 2030 5d20 2f20  in_region, 0] / 
-0001e200: 7261 6469 7573 5f73 6b69 6e29 202a 2a20  radius_skin) ** 
-0001e210: 6e69 2929 0d0a 0d0a 2020 2020 2020 2020  ni))....        
-0001e220: 2020 2020 636f 6566 6669 6369 656e 7473      coefficients
-0001e230: 5b69 692c 2073 6b75 6c6c 5f72 6567 696f  [ii, skull_regio
-0001e240: 6e5d 203d 206e 702e 6e61 6e5f 746f 5f6e  n] = np.nan_to_n
-0001e250: 756d 2873 286e 6929 202a 2028 705f 725b  um(s(ni) * (p_r[
-0001e260: 736b 756c 6c5f 7265 6769 6f6e 2c20 305d  skull_region, 0]
-0001e270: 202f 2072 6164 6975 735f 736b 696e 2920   / radius_skin) 
-0001e280: 2a2a 206e 6920 2b0d 0a20 2020 2020 2020  ** ni +..       
-0001e290: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e2a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e2b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e2c0: 2020 2020 7528 6e69 2920 2a20 2870 5f72      u(ni) * (p_r
-0001e2d0: 5b73 6b75 6c6c 5f72 6567 696f 6e2c 2030  [skull_region, 0
-0001e2e0: 5d20 2a20 7261 6469 7573 5f73 6b69 6e29  ] * radius_skin)
-0001e2f0: 202a 2a20 282d 6e69 202d 2031 2929 0d0a   ** (-ni - 1))..
-0001e300: 0d0a 2020 2020 2020 2020 2020 2020 636f  ..            co
-0001e310: 6566 6669 6369 656e 7473 5b69 692c 2073  efficients[ii, s
-0001e320: 6b69 6e5f 7265 6769 6f6e 5d20 3d20 6e70  kin_region] = np
-0001e330: 2e6e 616e 5f74 6f5f 6e75 6d28 7428 6e69  .nan_to_num(t(ni
-0001e340: 2920 2a20 2870 5f72 5b73 6b69 6e5f 7265  ) * (p_r[skin_re
-0001e350: 6769 6f6e 2c20 305d 202f 2072 6164 6975  gion, 0] / radiu
-0001e360: 735f 736b 696e 2920 2a2a 206e 690d 0a20  s_skin) ** ni.. 
-0001e370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e380: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e390: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e3a0: 2020 2020 2020 2020 202b 2077 286e 6929           + w(ni)
-0001e3b0: 202a 2028 705f 725b 736b 696e 5f72 6567   * (p_r[skin_reg
-0001e3c0: 696f 6e2c 2030 5d20 2a20 7261 6469 7573  ion, 0] * radius
-0001e3d0: 5f73 6b69 6e29 202a 2a20 282d 6e69 202d  _skin) ** (-ni -
-0001e3e0: 2031 2929 0d0a 0d0a 2020 2020 2020 2020   1))....        
-0001e3f0: 706f 7465 6e74 6961 6c73 5b69 6e73 6964  potentials[insid
-0001e400: 655f 7370 6865 7265 5d20 3d20 6e70 2e6e  e_sphere] = np.n
-0001e410: 616e 5f74 6f5f 6e75 6d28 0d0a 2020 2020  an_to_num(..    
-0001e420: 2020 2020 2020 2020 6e70 2e70 6f6c 796e          np.polyn
-0001e430: 6f6d 6961 6c2e 6c65 6765 6e64 7265 2e6c  omial.legendre.l
-0001e440: 6567 7661 6c28 636f 735f 7468 6574 615f  egval(cos_theta_
-0001e450: 615b 696e 7369 6465 5f73 7068 6572 655d  a[inside_sphere]
-0001e460: 2c20 636f 6566 6669 6369 656e 7473 5b3a  , coefficients[:
-0001e470: 2c20 696e 7369 6465 5f73 7068 6572 655d  , inside_sphere]
-0001e480: 2c20 7465 6e73 6f72 3d46 616c 7365 2920  , tensor=False) 
-0001e490: 2d0d 0a20 2020 2020 2020 2020 2020 206e  -..            n
-0001e4a0: 702e 706f 6c79 6e6f 6d69 616c 2e6c 6567  p.polynomial.leg
-0001e4b0: 656e 6472 652e 6c65 6776 616c 2863 6f73  endre.legval(cos
-0001e4c0: 5f74 6865 7461 5f62 5b69 6e73 6964 655f  _theta_b[inside_
-0001e4d0: 7370 6865 7265 5d2c 2063 6f65 6666 6963  sphere], coeffic
-0001e4e0: 6965 6e74 735b 3a2c 2069 6e73 6964 655f  ients[:, inside_
-0001e4f0: 7370 6865 7265 5d2c 2074 656e 736f 723d  sphere], tensor=
-0001e500: 4661 6c73 6529 290d 0a0d 0a20 2020 2020  False))....     
-0001e510: 2020 2070 6f74 656e 7469 616c 7320 2a3d     potentials *=
-0001e520: 2031 2e30 202f 2028 3220 2a20 6e70 2e70   1.0 / (2 * np.p
-0001e530: 6920 2a20 7365 6c66 2e70 5b22 7369 676d  i * self.p["sigm
-0001e540: 615f 3322 5d20 2a20 7261 6469 7573 5f73  a_3"] * radius_s
-0001e550: 6b69 6e29 0d0a 0d0a 2020 2020 2020 2020  kin)....        
-0001e560: 706f 7465 6e74 6961 6c73 5b6f 7574 7369  potentials[outsi
-0001e570: 6465 5f73 7068 6572 655d 203d 2030 2e30  de_sphere] = 0.0
-0001e580: 0d0a 0d0a 2020 2020 2020 2020 706f 7465  ....        pote
-0001e590: 6e74 6961 6c73 203d 2070 6f74 656e 7469  ntials = potenti
-0001e5a0: 616c 735b 6e70 2e6e 6577 6178 6973 2c20  als[np.newaxis, 
-0001e5b0: 3a5d 0d0a 0d0a 2020 2020 2020 2020 7265  :]....        re
-0001e5c0: 7475 726e 2070 6f74 656e 7469 616c 730d  turn potentials.
-0001e5d0: 0a0d 0a0d 0a63 6c61 7373 2050 6f74 656e  .....class Poten
-0001e5e0: 7469 616c 486f 6d6f 6765 6e65 6f75 7344  tialHomogeneousD
-0001e5f0: 6970 6f6c 6528 4162 7374 7261 6374 4d6f  ipole(AbstractMo
-0001e600: 6465 6c29 3a0d 0a20 2020 2022 2222 0d0a  del):..    """..
-0001e610: 2020 2020 4361 6c63 756c 6174 6573 2074      Calculates t
-0001e620: 6865 2073 7572 6661 6365 2070 6f74 656e  he surface poten
-0001e630: 7469 616c 2067 656e 6572 6174 6564 2062  tial generated b
-0001e640: 7920 6120 6469 706f 6c65 2069 6e73 6964  y a dipole insid
-0001e650: 6520 6120 686f 6d6f 6765 6e65 6f75 7320  e a homogeneous 
-0001e660: 636f 6e64 7563 7469 6e67 2073 7068 6572  conducting spher
-0001e670: 6520 6166 7465 7220 5961 6f20 2832 3030  e after Yao (200
-0001e680: 3029 2e0d 0a0d 0a20 2020 2050 6172 616d  0).....    Param
-0001e690: 6574 6572 730d 0a20 2020 202d 2d2d 2d2d  eters..    -----
-0001e6a0: 2d2d 2d2d 2d0d 0a20 2020 2070 5b22 7370  -----..    p["sp
-0001e6b0: 6865 7265 5f72 6164 6975 7322 5d3a 2066  here_radius"]: f
-0001e6c0: 6c6f 6174 0d0a 2020 2020 2020 2020 5261  loat..        Ra
-0001e6d0: 6469 7573 206f 6620 7370 6865 7265 2069  dius of sphere i
-0001e6e0: 6e20 286d 6d29 0d0a 2020 2020 705b 2263  n (mm)..    p["c
-0001e6f0: 6f6e 6475 6374 6976 6974 7922 5d3a 2066  onductivity"]: f
-0001e700: 6c6f 6174 0d0a 2020 2020 2020 2020 436f  loat..        Co
-0001e710: 6e64 7563 7469 7669 7479 206f 6620 6d65  nductivity of me
-0001e720: 6469 756d 2069 6e20 2853 2f6d 290d 0a20  dium in (S/m).. 
-0001e730: 2020 2070 5b22 6469 706f 6c65 5f70 6f73     p["dipole_pos
-0001e740: 225d 3a20 6e64 6172 7261 7920 6f66 2066  "]: ndarray of f
-0001e750: 6c6f 6174 205b 3320 7820 315d 0d0a 2020  loat [3 x 1]..  
-0001e760: 2020 2020 2020 506f 7369 7469 6f6e 206f        Position o
-0001e770: 6620 6469 706f 6c65 2069 6e20 286d 6d29  f dipole in (mm)
-0001e780: 0d0a 2020 2020 705b 2264 6970 6f6c 655f  ..    p["dipole_
-0001e790: 6d6f 6d65 6e74 225d 3a20 6e64 6172 7261  moment"]: ndarra
-0001e7a0: 7920 6f66 2066 6c6f 6174 205b 3320 7820  y of float [3 x 
-0001e7b0: 315d 0d0a 2020 2020 2020 2020 4d6f 6d65  1]..        Mome
-0001e7c0: 6e74 206f 6620 6469 706f 6c65 2069 6e20  nt of dipole in 
-0001e7d0: 2843 6d29 0d0a 2020 2020 705b 2264 6574  (Cm)..    p["det
-0001e7e0: 6563 746f 725f 706f 7369 7469 6f6e 7322  ector_positions"
-0001e7f0: 5d3a 206e 6461 7272 6179 206f 6620 666c  ]: ndarray of fl
-0001e800: 6f61 7420 5b6e 2078 2033 5d0d 0a20 2020  oat [n x 3]..   
-0001e810: 2020 2020 2050 6f73 6974 696f 6e20 6f66       Position of
-0001e820: 2064 6574 6563 746f 7273 2c20 7769 6c6c   detectors, will
-0001e830: 2062 6520 7072 6f6a 6563 7465 6420 696e   be projected in
-0001e840: 746f 2074 6865 2073 7068 6572 6520 7375  to the sphere su
-0001e850: 7266 6163 6520 696e 2028 6d6d 290d 0a0d  rface in (mm)...
-0001e860: 0a20 2020 2052 6574 7572 6e73 0d0a 2020  .    Returns..  
-0001e870: 2020 2d2d 2d2d 2d2d 2d0d 0a20 2020 2070    -------..    p
-0001e880: 6f74 656e 7469 616c 3a20 6e64 6172 7261  otential: ndarra
-0001e890: 7920 6f66 2066 6c6f 6174 205b 3120 7820  y of float [1 x 
-0001e8a0: 6e5f 6f75 745d 0d0a 2020 2020 2020 2050  n_out]..       P
-0001e8b0: 6f74 656e 7469 616c 2061 7420 7468 6520  otential at the 
-0001e8c0: 706f 696e 7473 0d0a 0d0a 2020 2020 4e6f  points....    No
-0001e8d0: 7465 730d 0a20 2020 202d 2d2d 2d2d 0d0a  tes..    -----..
-0001e8e0: 2020 2020 2e2e 205b 315d 2059 616f 2c20      .. [1] Yao, 
-0001e8f0: 442e 2028 3230 3030 292e 2045 6c65 6374  D. (2000). Elect
-0001e900: 7269 6320 706f 7465 6e74 6961 6c20 7072  ric potential pr
-0001e910: 6f64 7563 6564 2062 7920 6120 6469 706f  oduced by a dipo
-0001e920: 6c65 2069 6e20 6120 686f 6d6f 6765 6e65  le in a homogene
-0001e930: 6f75 7320 636f 6e64 7563 7469 6e67 2073  ous conducting s
-0001e940: 7068 6572 652e 0d0a 2020 2020 2020 2049  phere...       I
-0001e950: 4545 4520 5472 616e 7361 6374 696f 6e73  EEE Transactions
-0001e960: 206f 6e20 4269 6f6d 6564 6963 616c 2045   on Biomedical E
-0001e970: 6e67 696e 6565 7269 6e67 2c20 3437 2837  ngineering, 47(7
-0001e980: 292c 2039 3634 2d39 3636 2e0d 0a20 2020  ), 964-966...   
-0001e990: 2022 2222 0d0a 0d0a 2020 2020 6465 6620   """....    def 
-0001e9a0: 5f5f 696e 6974 5f5f 2873 656c 662c 206d  __init__(self, m
-0001e9b0: 6174 6c61 625f 6d6f 6465 6c3d 4661 6c73  atlab_model=Fals
-0001e9c0: 6529 3a0d 0a20 2020 2020 2020 2073 7570  e):..        sup
-0001e9d0: 6572 2874 7970 6528 7365 6c66 292c 2073  er(type(self), s
-0001e9e0: 656c 6629 2e5f 5f69 6e69 745f 5f28 6d61  elf).__init__(ma
-0001e9f0: 746c 6162 5f6d 6f64 656c 3d6d 6174 6c61  tlab_model=matla
-0001ea00: 625f 6d6f 6465 6c29 0d0a 2020 2020 2020  b_model)..      
-0001ea10: 2020 7365 6c66 2e66 6e61 6d65 203d 2069    self.fname = i
-0001ea20: 6e73 7065 6374 2e67 6574 6669 6c65 2869  nspect.getfile(i
-0001ea30: 6e73 7065 6374 2e63 7572 7265 6e74 6672  nspect.currentfr
-0001ea40: 616d 6528 2929 0d0a 0d0a 2020 2020 6465  ame())....    de
-0001ea50: 6620 7661 6c69 6461 7465 2873 656c 6629  f validate(self)
-0001ea60: 3a0d 0a20 2020 2020 2020 2070 6173 730d  :..        pass.
-0001ea70: 0a0d 0a20 2020 2064 6566 2073 696d 756c  ...    def simul
-0001ea80: 6174 6528 7365 6c66 2c20 7072 6f63 6573  ate(self, proces
-0001ea90: 735f 6964 3d4e 6f6e 652c 206d 6174 6c61  s_id=None, matla
-0001eaa0: 625f 656e 6769 6e65 3d4e 6f6e 6529 3a0d  b_engine=None):.
-0001eab0: 0a0d 0a20 2020 2020 2020 2073 656c 662e  ...        self.
-0001eac0: 705b 2264 6574 6563 746f 725f 706f 7369  p["detector_posi
-0001ead0: 7469 6f6e 7322 5d20 3d20 6e70 2e61 746c  tions"] = np.atl
-0001eae0: 6561 7374 5f32 6428 7365 6c66 2e70 5b22  east_2d(self.p["
-0001eaf0: 6465 7465 6374 6f72 5f70 6f73 6974 696f  detector_positio
-0001eb00: 6e73 225d 290d 0a20 2020 2020 2020 2061  ns"])..        a
-0001eb10: 7373 6572 7420 7365 6c66 2e70 5b22 6465  ssert self.p["de
-0001eb20: 7465 6374 6f72 5f70 6f73 6974 696f 6e73  tector_positions
-0001eb30: 225d 2e73 6861 7065 5b31 5d20 3d3d 2033  "].shape[1] == 3
-0001eb40: 0d0a 2020 2020 2020 2020 6173 7365 7274  ..        assert
-0001eb50: 206e 702e 6c69 6e61 6c67 2e6e 6f72 6d28   np.linalg.norm(
-0001eb60: 7365 6c66 2e70 5b22 6469 706f 6c65 5f70  self.p["dipole_p
-0001eb70: 6f73 225d 2920 3c20 7365 6c66 2e70 5b22  os"]) < self.p["
-0001eb80: 7370 6865 7265 5f72 6164 6975 7322 5d0d  sphere_radius"].
-0001eb90: 0a0d 0a20 2020 2020 2020 2073 656c 662e  ...        self.
-0001eba0: 705b 2273 7068 6572 655f 7261 6469 7573  p["sphere_radius
-0001ebb0: 225d 203d 206e 702e 666c 6f61 7431 3238  "] = np.float128
-0001ebc0: 2873 656c 662e 705b 2273 7068 6572 655f  (self.p["sphere_
-0001ebd0: 7261 6469 7573 225d 202a 2031 652d 3329  radius"] * 1e-3)
-0001ebe0: 0d0a 2020 2020 2020 2020 7365 6c66 2e70  ..        self.p
-0001ebf0: 5b22 6469 706f 6c65 5f70 6f73 225d 203d  ["dipole_pos"] =
-0001ec00: 206e 702e 6172 7261 7928 7365 6c66 2e70   np.array(self.p
-0001ec10: 5b22 6469 706f 6c65 5f70 6f73 225d 2c20  ["dipole_pos"], 
-0001ec20: 6474 7970 653d 6e70 2e66 6c6f 6174 3132  dtype=np.float12
-0001ec30: 3829 202a 2031 652d 330d 0a20 2020 2020  8) * 1e-3..     
-0001ec40: 2020 2073 656c 662e 705b 2264 6970 6f6c     self.p["dipol
-0001ec50: 655f 6d6f 6d65 6e74 225d 203d 206e 702e  e_moment"] = np.
-0001ec60: 6172 7261 7928 7365 6c66 2e70 5b22 6469  array(self.p["di
-0001ec70: 706f 6c65 5f6d 6f6d 656e 7422 5d2c 2064  pole_moment"], d
-0001ec80: 7479 7065 3d6e 702e 666c 6f61 7431 3238  type=np.float128
-0001ec90: 290d 0a20 2020 2020 2020 2073 656c 662e  )..        self.
-0001eca0: 705b 2264 6574 6563 746f 725f 706f 7369  p["detector_posi
-0001ecb0: 7469 6f6e 7322 5d20 3d20 6e70 2e61 7272  tions"] = np.arr
-0001ecc0: 6179 2873 656c 662e 705b 2264 6574 6563  ay(self.p["detec
-0001ecd0: 746f 725f 706f 7369 7469 6f6e 7322 5d2c  tor_positions"],
-0001ece0: 2064 7479 7065 3d6e 702e 666c 6f61 7431   dtype=np.float1
-0001ecf0: 3238 2920 2a20 3165 2d33 0d0a 0d0a 2020  28) * 1e-3....  
-0001ed00: 2020 2020 2020 7273 203d 2073 656c 662e        rs = self.
-0001ed10: 705b 2273 7068 6572 655f 7261 6469 7573  p["sphere_radius
-0001ed20: 225d 0d0a 2020 2020 2020 2020 7230 203d  "]..        r0 =
-0001ed30: 206e 702e 6c69 6e61 6c67 2e6e 6f72 6d28   np.linalg.norm(
-0001ed40: 7365 6c66 2e70 5b22 6469 706f 6c65 5f70  self.p["dipole_p
-0001ed50: 6f73 225d 290d 0a20 2020 2020 2020 2072  os"])..        r
-0001ed60: 203d 206e 702e 6c69 6e61 6c67 2e6e 6f72   = np.linalg.nor
-0001ed70: 6d28 7365 6c66 2e70 5b22 6465 7465 6374  m(self.p["detect
-0001ed80: 6f72 5f70 6f73 6974 696f 6e73 225d 2c20  or_positions"], 
-0001ed90: 6178 6973 3d31 290d 0a20 2020 2020 2020  axis=1)..       
-0001eda0: 2072 7020 3d20 6e70 2e6c 696e 616c 672e   rp = np.linalg.
-0001edb0: 6e6f 726d 2873 656c 662e 705b 2264 6970  norm(self.p["dip
-0001edc0: 6f6c 655f 706f 7322 5d20 2d20 7365 6c66  ole_pos"] - self
-0001edd0: 2e70 5b22 6465 7465 6374 6f72 5f70 6f73  .p["detector_pos
-0001ede0: 6974 696f 6e73 225d 2c20 6178 6973 3d31  itions"], axis=1
-0001edf0: 290d 0a0d 0a20 2020 2020 2020 2069 6620  )....        if 
-0001ee00: 6e6f 7420 6e70 2e61 6c6c 636c 6f73 6528  not np.allclose(
-0001ee10: 722c 2072 7329 3a0d 0a20 2020 2020 2020  r, rs):..       
-0001ee20: 2020 2020 2077 6172 6e69 6e67 732e 7761       warnings.wa
-0001ee30: 726e 2827 536f 6d65 2070 6f69 6e74 7320  rn('Some points 
-0001ee40: 6172 6520 6e6f 7420 696e 2074 6865 2073  are not in the s
-0001ee50: 7572 6661 6365 2121 2729 0d0a 0d0a 2020  urface!!')....  
-0001ee60: 2020 2020 2020 6966 206e 702e 6973 636c        if np.iscl
-0001ee70: 6f73 6528 7230 2c20 3029 3a0d 0a20 2020  ose(r0, 0):..   
-0001ee80: 2020 2020 2020 2020 2063 6f73 5f70 6869           cos_phi
-0001ee90: 203d 206e 702e 7a65 726f 7328 6c65 6e28   = np.zeros(len(
-0001eea0: 7365 6c66 2e70 5b22 6465 7465 6374 6f72  self.p["detector
-0001eeb0: 5f70 6f73 6974 696f 6e73 225d 292c 2064  _positions"]), d
-0001eec0: 7479 7065 3d6e 702e 666c 6f61 7431 3238  type=np.float128
-0001eed0: 290d 0a20 2020 2020 2020 2065 6c73 653a  )..        else:
-0001eee0: 0d0a 2020 2020 2020 2020 2020 2020 636f  ..            co
-0001eef0: 735f 7068 6920 3d20 7365 6c66 2e70 5b22  s_phi = self.p["
-0001ef00: 6469 706f 6c65 5f70 6f73 225d 2e64 6f74  dipole_pos"].dot
-0001ef10: 2873 656c 662e 705b 2264 6574 6563 746f  (self.p["detecto
-0001ef20: 725f 706f 7369 7469 6f6e 7322 5d2e 5429  r_positions"].T)
-0001ef30: 202f 205c 0d0a 2020 2020 2020 2020 2020   / \..          
-0001ef40: 2020 2020 2020 2020 2020 2020 286e 702e              (np.
-0001ef50: 6c69 6e61 6c67 2e6e 6f72 6d28 7365 6c66  linalg.norm(self
-0001ef60: 2e70 5b22 6469 706f 6c65 5f70 6f73 225d  .p["dipole_pos"]
-0001ef70: 2920 2a20 6e70 2e6c 696e 616c 672e 6e6f  ) * np.linalg.no
-0001ef80: 726d 2873 656c 662e 705b 2264 6574 6563  rm(self.p["detec
-0001ef90: 746f 725f 706f 7369 7469 6f6e 7322 5d2c  tor_positions"],
-0001efa0: 2061 7869 733d 3129 290d 0a0d 0a20 2020   axis=1))....   
-0001efb0: 2020 2020 2073 6563 6f6e 645f 7465 726d       second_term
-0001efc0: 203d 2031 2e20 2f20 2872 705b 3a2c 204e   = 1. / (rp[:, N
-0001efd0: 6f6e 655d 202a 2072 7320 2a2a 2032 2920  one] * rs ** 2) 
-0001efe0: 2a20 280d 0a20 2020 2020 2020 2020 2020  * (..           
-0001eff0: 2020 2020 2073 656c 662e 705b 2264 6574       self.p["det
-0001f000: 6563 746f 725f 706f 7369 7469 6f6e 7322  ector_positions"
-0001f010: 5d20 2b20 2873 656c 662e 705b 2264 6574  ] + (self.p["det
-0001f020: 6563 746f 725f 706f 7369 7469 6f6e 7322  ector_positions"
-0001f030: 5d20 2a20 7230 202a 2063 6f73 5f70 6869  ] * r0 * cos_phi
-0001f040: 5b3a 2c20 4e6f 6e65 5d20 2d0d 0a20 2020  [:, None] -..   
-0001f050: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001f060: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001f070: 2020 2020 2020 2020 2020 2020 2072 7320               rs 
-0001f080: 2a20 7365 6c66 2e70 5b22 6469 706f 6c65  * self.p["dipole
-0001f090: 5f70 6f73 225d 2920 2f0d 0a20 2020 2020  _pos"]) /..     
-0001f0a0: 2020 2020 2020 2020 2020 2028 7273 202b             (rs +
-0001f0b0: 2072 7020 2d20 7230 202a 2063 6f73 5f70   rp - r0 * cos_p
-0001f0c0: 6869 295b 3a2c 204e 6f6e 655d 290d 0a0d  hi)[:, None])...
-0001f0d0: 0a20 2020 2020 2020 2070 6f74 656e 7469  .        potenti
-0001f0e0: 616c 203d 2073 656c 662e 705b 2264 6970  al = self.p["dip
-0001f0f0: 6f6c 655f 6d6f 6d65 6e74 225d 2e64 6f74  ole_moment"].dot
-0001f100: 2828 3220 2a20 2873 656c 662e 705b 2264  ((2 * (self.p["d
-0001f110: 6574 6563 746f 725f 706f 7369 7469 6f6e  etector_position
-0001f120: 7322 5d20 2d20 7365 6c66 2e70 5b22 6469  s"] - self.p["di
-0001f130: 706f 6c65 5f70 6f73 225d 2920 2f0d 0a20  pole_pos"]) /.. 
-0001f140: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001f150: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001f160: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001f170: 2872 7020 2a2a 2033 295b 3a2c 204e 6f6e  (rp ** 3)[:, Non
-0001f180: 655d 202b 2073 6563 6f6e 645f 7465 726d  e] + second_term
-0001f190: 292e 5429 2e54 0d0a 0d0a 2020 2020 2020  ).T).T....      
-0001f1a0: 2020 706f 7465 6e74 6961 6c20 2f3d 2034    potential /= 4
-0001f1b0: 202a 206e 702e 7069 202a 2073 656c 662e   * np.pi * self.
-0001f1c0: 705b 2263 6f6e 6475 6374 6976 6974 7922  p["conductivity"
-0001f1d0: 5d0d 0a0d 0a20 2020 2020 2020 2070 6f74  ]....        pot
-0001f1e0: 656e 7469 616c 203d 2070 6f74 656e 7469  ential = potenti
-0001f1f0: 616c 5b6e 702e 6e65 7761 7869 732c 203a  al[np.newaxis, :
-0001f200: 5d0d 0a0d 0a20 2020 2020 2020 2072 6574  ]....        ret
-0001f210: 7572 6e20 706f 7465 6e74 6961 6c0d 0a0d  urn potential...
-0001f220: 0a0d 0a63 6c61 7373 2042 6669 656c 644f  ...class BfieldO
-0001f230: 7574 7369 6465 5370 6865 7265 2841 6273  utsideSphere(Abs
-0001f240: 7472 6163 744d 6f64 656c 293a 0d0a 2020  tractModel):..  
-0001f250: 2020 2222 220d 0a20 2020 2043 616c 6375    """..    Calcu
-0001f260: 6c61 7465 7320 7468 6520 422d 6669 656c  lates the B-fiel
-0001f270: 6420 6f75 7473 6964 6520 6120 7370 6865  d outside a sphe
-0001f280: 7265 2c20 646f 6573 206e 6f74 2064 6570  re, does not dep
-0001f290: 656e 6420 6f6e 2063 6f6e 6475 6374 6976  end on conductiv
-0001f2a0: 6974 7920 6166 7465 7220 4a61 7276 6173  ity after Jarvas
-0001f2b0: 2028 3139 3837 292e 0d0a 2020 2020 4469   (1987)...    Di
-0001f2c0: 706f 6c65 2069 6e20 5349 2075 6e69 7473  pole in SI units
-0001f2d0: 2c20 706f 7369 7469 6f6e 7320 696e 2028  , positions in (
-0001f2e0: 6d6d 290d 0a0d 0a20 2020 2050 6172 616d  mm)....    Param
-0001f2f0: 6574 6572 730d 0a20 2020 202d 2d2d 2d2d  eters..    -----
-0001f300: 2d2d 2d2d 2d0d 0a20 2020 2070 5b22 7370  -----..    p["sp
-0001f310: 6865 7265 5f72 6164 6975 7322 5d3a 2066  here_radius"]: f
-0001f320: 6c6f 6174 0d0a 2020 2020 2020 2020 5261  loat..        Ra
-0001f330: 6469 7573 206f 6620 7370 6865 7265 2069  dius of sphere i
-0001f340: 6e20 286d 6d29 0d0a 2020 2020 705b 2264  n (mm)..    p["d
-0001f350: 6970 6f6c 655f 706f 7322 5d3a 206e 6461  ipole_pos"]: nda
-0001f360: 7272 6179 206f 6620 666c 6f61 7420 5b33  rray of float [3
-0001f370: 2078 2031 5d0d 0a20 2020 2020 2020 2050   x 1]..        P
-0001f380: 6f73 6974 696f 6e20 6f66 2064 6970 6f6c  osition of dipol
-0001f390: 6520 696e 2028 6d6d 290d 0a20 2020 2070  e in (mm)..    p
-0001f3a0: 5b22 6469 706f 6c65 5f6d 6f6d 656e 7422  ["dipole_moment"
-0001f3b0: 5d3a 206e 6461 7272 6179 206f 6620 666c  ]: ndarray of fl
-0001f3c0: 6f61 7420 5b33 2078 2031 5d0d 0a20 2020  oat [3 x 1]..   
-0001f3d0: 2020 2020 204d 6f6d 656e 7420 6f66 2064       Moment of d
-0001f3e0: 6970 6f6c 6520 696e 2028 416d 7329 0d0a  ipole in (Ams)..
-0001f3f0: 2020 2020 705b 2264 6574 6563 746f 725f      p["detector_
-0001f400: 706f 7369 7469 6f6e 7322 5d3a 206e 6461  positions"]: nda
-0001f410: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
-0001f420: 2078 2033 5d0d 0a20 2020 2020 2020 2050   x 3]..        P
-0001f430: 6f73 6974 696f 6e20 6f66 2064 6574 6563  osition of detec
-0001f440: 746f 7273 2c20 6d75 7374 206c 6965 206f  tors, must lie o
-0001f450: 7574 7369 6465 2073 7068 6572 650d 0a0d  utside sphere...
-0001f460: 0a20 2020 2052 6574 7572 6e73 0d0a 2020  .    Returns..  
-0001f470: 2020 2d2d 2d2d 2d2d 2d0d 0a20 2020 2042    -------..    B
-0001f480: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
-0001f490: 6174 205b 3120 7820 332a 4e5d 0d0a 2020  at [1 x 3*N]..  
-0001f4a0: 2020 2020 2020 422d 6669 656c 6473 2069        B-fields i
-0001f4b0: 6e20 6465 7465 6374 6f72 2070 6f73 6974  n detector posit
-0001f4c0: 696f 6e73 0d0a 0d0a 2020 2020 4e6f 7465  ions....    Note
-0001f4d0: 730d 0a20 2020 202d 2d2d 2d2d 0d0a 2020  s..    -----..  
-0001f4e0: 2020 2e2e 205b 315d 2053 6172 7661 732c    .. [1] Sarvas,
-0001f4f0: 204a 2e20 2831 3938 3729 2e20 4261 7369   J. (1987). Basi
-0001f500: 6320 6d61 7468 656d 6174 6963 616c 2061  c mathematical a
-0001f510: 6e64 2065 6c65 6374 726f 6d61 676e 6574  nd electromagnet
-0001f520: 6963 2063 6f6e 6365 7074 7320 6f66 2074  ic concepts of t
-0001f530: 6865 2062 696f 6d61 676e 6574 6963 2069  he biomagnetic i
-0001f540: 6e76 6572 7365 2070 726f 626c 656d 2e0d  nverse problem..
-0001f550: 0a20 2020 2020 2020 5068 7973 6963 7320  .       Physics 
-0001f560: 696e 204d 6564 6963 696e 6520 2620 4269  in Medicine & Bi
-0001f570: 6f6c 6f67 792c 2033 3228 3129 2c20 3131  ology, 32(1), 11
-0001f580: 2e0d 0a20 2020 2022 2222 0d0a 0d0a 2020  ...    """....  
-0001f590: 2020 6465 6620 5f5f 696e 6974 5f5f 2873    def __init__(s
-0001f5a0: 656c 662c 206d 6174 6c61 625f 6d6f 6465  elf, matlab_mode
-0001f5b0: 6c3d 4661 6c73 6529 3a0d 0a20 2020 2020  l=False):..     
-0001f5c0: 2020 2073 7570 6572 2874 7970 6528 7365     super(type(se
-0001f5d0: 6c66 292c 2073 656c 6629 2e5f 5f69 6e69  lf), self).__ini
-0001f5e0: 745f 5f28 6d61 746c 6162 5f6d 6f64 656c  t__(matlab_model
-0001f5f0: 3d6d 6174 6c61 625f 6d6f 6465 6c29 0d0a  =matlab_model)..
-0001f600: 2020 2020 2020 2020 7365 6c66 2e66 6e61          self.fna
-0001f610: 6d65 203d 2069 6e73 7065 6374 2e67 6574  me = inspect.get
-0001f620: 6669 6c65 2869 6e73 7065 6374 2e63 7572  file(inspect.cur
-0001f630: 7265 6e74 6672 616d 6528 2929 0d0a 0d0a  rentframe())....
-0001f640: 2020 2020 6465 6620 7661 6c69 6461 7465      def validate
-0001f650: 2873 656c 6629 3a0d 0a20 2020 2020 2020  (self):..       
-0001f660: 2070 6173 730d 0a0d 0a20 2020 2064 6566   pass....    def
-0001f670: 2073 696d 756c 6174 6528 7365 6c66 2c20   simulate(self, 
-0001f680: 7072 6f63 6573 735f 6964 3d4e 6f6e 652c  process_id=None,
-0001f690: 206d 6174 6c61 625f 656e 6769 6e65 3d4e   matlab_engine=N
-0001f6a0: 6f6e 6529 3a0d 0a20 2020 2020 2020 2070  one):..        p
-0001f6b0: 6f73 203d 206e 702e 6172 7261 7928 7365  os = np.array(se
-0001f6c0: 6c66 2e70 5b22 6469 706f 6c65 5f70 6f73  lf.p["dipole_pos
-0001f6d0: 225d 2c20 6474 7970 653d 666c 6f61 7429  "], dtype=float)
-0001f6e0: 202a 2031 652d 330d 0a20 2020 2020 2020   * 1e-3..       
-0001f6f0: 206d 6f6d 656e 7420 3d20 6e70 2e61 7272   moment = np.arr
-0001f700: 6179 2873 656c 662e 705b 2264 6970 6f6c  ay(self.p["dipol
-0001f710: 655f 6d6f 6d65 6e74 225d 2c20 6474 7970  e_moment"], dtyp
-0001f720: 653d 666c 6f61 7429 0d0a 2020 2020 2020  e=float)..      
-0001f730: 2020 6465 7465 6374 6f72 203d 206e 702e    detector = np.
-0001f740: 6172 7261 7928 7365 6c66 2e70 5b22 6465  array(self.p["de
-0001f750: 7465 6374 6f72 5f70 6f73 6974 696f 6e73  tector_positions
-0001f760: 225d 2c20 6474 7970 653d 666c 6f61 7429  "], dtype=float)
-0001f770: 202a 2031 652d 330d 0a0d 0a20 2020 2020   * 1e-3....     
-0001f780: 2020 2061 7373 6572 7420 6e70 2e61 6c6c     assert np.all
-0001f790: 286e 702e 6c69 6e61 6c67 2e6e 6f72 6d28  (np.linalg.norm(
-0001f7a0: 7365 6c66 2e70 5b22 6465 7465 6374 6f72  self.p["detector
-0001f7b0: 5f70 6f73 6974 696f 6e73 225d 2c20 6178  _positions"], ax
-0001f7c0: 6973 3d31 2920 3e20 7365 6c66 2e70 5b22  is=1) > self.p["
-0001f7d0: 7370 6865 7265 5f72 6164 6975 7322 5d29  sphere_radius"])
-0001f7e0: 2c20 5c0d 0a20 2020 2020 2020 2020 2020  , \..           
-0001f7f0: 2022 416c 6c20 706f 696e 7473 206d 7573   "All points mus
-0001f800: 7420 6265 206f 7574 7369 6465 2074 6865  t be outside the
-0001f810: 2073 7068 6572 6522 0d0a 0d0a 2020 2020   sphere"....    
-0001f820: 2020 2020 6173 7365 7274 206e 702e 616c      assert np.al
-0001f830: 6c28 6e70 2e6c 696e 616c 672e 6e6f 726d  l(np.linalg.norm
-0001f840: 2873 656c 662e 705b 2264 6970 6f6c 655f  (self.p["dipole_
-0001f850: 706f 7322 5d29 203c 2073 656c 662e 705b  pos"]) < self.p[
-0001f860: 2273 7068 6572 655f 7261 6469 7573 225d  "sphere_radius"]
-0001f870: 292c 205c 0d0a 2020 2020 2020 2020 2020  ), \..          
-0001f880: 2020 2244 6970 6f6c 6520 6d75 7374 2062    "Dipole must b
-0001f890: 6520 6f75 7473 6964 6520 7370 6865 7265  e outside sphere
-0001f8a0: 220d 0a0d 0a20 2020 2020 2020 2062 203d  "....        b =
-0001f8b0: 206e 702e 7a65 726f 7328 7365 6c66 2e70   np.zeros(self.p
-0001f8c0: 5b22 6465 7465 6374 6f72 5f70 6f73 6974  ["detector_posit
-0001f8d0: 696f 6e73 225d 2e73 6861 7065 2c20 6474  ions"].shape, dt
-0001f8e0: 7970 653d 666c 6f61 7429 0d0a 0d0a 2020  ype=float)....  
-0001f8f0: 2020 2020 2020 666f 7220 6969 2c20 7220        for ii, r 
-0001f900: 696e 2065 6e75 6d65 7261 7465 2864 6574  in enumerate(det
-0001f910: 6563 746f 7229 3a0d 0a20 2020 2020 2020  ector):..       
-0001f920: 2020 2020 206e 6f72 6d5f 7220 3d20 6e70       norm_r = np
-0001f930: 2e6c 696e 616c 672e 6e6f 726d 2872 290d  .linalg.norm(r).
-0001f940: 0a0d 0a20 2020 2020 2020 2020 2020 2072  ...            r
-0001f950: 5f30 203d 2070 6f73 0d0a 2020 2020 2020  _0 = pos..      
-0001f960: 2020 2020 2020 2320 6e6f 726d 5f72 3020        # norm_r0 
-0001f970: 3d20 6e70 2e6c 696e 616c 672e 6e6f 726d  = np.linalg.norm
-0001f980: 2870 6f73 290d 0a0d 0a20 2020 2020 2020  (pos)....       
-0001f990: 2020 2020 2061 203d 2072 202d 2072 5f30       a = r - r_0
-0001f9a0: 0d0a 2020 2020 2020 2020 2020 2020 6e6f  ..            no
-0001f9b0: 726d 5f61 203d 206e 702e 6c69 6e61 6c67  rm_a = np.linalg
-0001f9c0: 2e6e 6f72 6d28 6129 0d0a 0d0a 2020 2020  .norm(a)....    
-0001f9d0: 2020 2020 2020 2020 6620 3d20 6e6f 726d          f = norm
-0001f9e0: 5f61 202a 2028 6e6f 726d 5f72 202a 206e  _a * (norm_r * n
-0001f9f0: 6f72 6d5f 6120 2b20 6e6f 726d 5f72 202a  orm_a + norm_r *
-0001fa00: 2a20 3220 2d20 725f 302e 646f 7428 7229  * 2 - r_0.dot(r)
-0001fa10: 290d 0a0d 0a20 2020 2020 2020 2020 2020  )....           
-0001fa20: 2067 7261 645f 6620 3d20 286e 6f72 6d5f   grad_f = (norm_
-0001fa30: 7220 2a2a 2028 2d31 2920 2a20 6e6f 726d  r ** (-1) * norm
-0001fa40: 5f61 202a 2a20 3220 2b20 6e6f 726d 5f61  _a ** 2 + norm_a
-0001fa50: 202a 2a20 282d 3129 202a 2061 2e64 6f74   ** (-1) * a.dot
-0001fa60: 2872 2920 2b20 3220 2a20 6e6f 726d 5f61  (r) + 2 * norm_a
-0001fa70: 202b 2032 202a 206e 6f72 6d5f 7229 202a   + 2 * norm_r) *
-0001fa80: 2072 202d 205c 0d0a 2020 2020 2020 2020   r - \..        
-0001fa90: 2020 2020 2020 2020 2020 2020 2028 6e6f               (no
-0001faa0: 726d 5f61 202b 2032 202a 206e 6f72 6d5f  rm_a + 2 * norm_
-0001fab0: 7220 2b20 6e6f 726d 5f61 202a 2a20 282d  r + norm_a ** (-
-0001fac0: 3129 202a 2061 2e64 6f74 2872 2929 202a  1) * a.dot(r)) *
-0001fad0: 2072 5f30 0d0a 0d0a 2020 2020 2020 2020   r_0....        
-0001fae0: 2020 2020 625b 6969 2c20 3a5d 203d 2028      b[ii, :] = (
-0001faf0: 3420 2a20 6e70 2e70 6920 2a20 3165 2d37  4 * np.pi * 1e-7
-0001fb00: 2920 2f20 5c0d 0a20 2020 2020 2020 2020  ) / \..         
-0001fb10: 2020 2020 2020 2020 2020 2020 2020 2834                (4
-0001fb20: 202a 206e 702e 7069 202a 2066 202a 2a20   * np.pi * f ** 
-0001fb30: 3229 202a 2028 6620 2a20 6e70 2e63 726f  2) * (f * np.cro
-0001fb40: 7373 286d 6f6d 656e 742c 2072 5f30 2920  ss(moment, r_0) 
-0001fb50: 2d20 6e70 2e64 6f74 286e 702e 6372 6f73  - np.dot(np.cros
-0001fb60: 7328 6d6f 6d65 6e74 2c20 725f 3029 2c20  s(moment, r_0), 
-0001fb70: 7229 202a 2067 7261 645f 6629 0d0a 0d0a  r) * grad_f)....
-0001fb80: 2020 2020 2020 2020 6220 3d20 622e 666c          b = b.fl
-0001fb90: 6174 7465 6e28 295b 6e70 2e6e 6577 6178  atten()[np.newax
-0001fba0: 6973 2c20 3a5d 0d0a 0d0a 2020 2020 2020  is, :]....      
-0001fbb0: 2020 7265 7475 726e 2062 0d0a 0d0a 0d0a    return b......
-0001fbc0: 636c 6173 7320 544d 5345 6669 656c 6453  class TMSEfieldS
-0001fbd0: 7068 6572 6528 4162 7374 7261 6374 4d6f  phere(AbstractMo
-0001fbe0: 6465 6c29 3a0d 0a20 2020 2022 2222 0d0a  del):..    """..
-0001fbf0: 2020 2020 4361 6c63 756c 6174 6520 7468      Calculate th
-0001fc00: 6520 452d 6669 656c 6420 696e 2061 2073  e E-field in a s
-0001fc10: 7068 6572 6520 6361 7573 6564 2062 7920  phere caused by 
-0001fc20: 6578 7465 726e 616c 206d 6167 6e65 7469  external magneti
-0001fc30: 6320 6469 706f 6c65 7320 6166 7465 7220  c dipoles after 
-0001fc40: 4865 6c6c 6572 2061 6e64 2076 616e 2048  Heller and van H
-0001fc50: 756c 7374 6579 6e20 2831 3939 3229 2e0d  ulsteyn (1992)..
-0001fc60: 0a20 2020 2054 6865 2072 6573 756c 7473  .    The results
-0001fc70: 2061 7265 2069 6e64 6570 656e 6465 6e74   are independent
-0001fc80: 206f 6620 636f 6e64 7563 7469 7669 7479   of conductivity
-0001fc90: 2e0d 0a0d 0a20 2020 2050 6172 616d 6574  .....    Paramet
-0001fca0: 6572 730d 0a20 2020 202d 2d2d 2d2d 2d2d  ers..    -------
-0001fcb0: 2d2d 2d0d 0a20 2020 2070 5b22 6469 706f  ---..    p["dipo
-0001fcc0: 6c65 5f70 6f73 225d 3a20 6e64 6172 7261  le_pos"]: ndarra
-0001fcd0: 7920 6f66 2066 6c6f 6174 205b 4d20 7820  y of float [M x 
-0001fce0: 335d 0d0a 2020 2020 2020 2020 506f 7369  3]..        Posi
-0001fcf0: 7469 6f6e 206f 6620 6469 706f 6c65 732c  tion of dipoles,
-0001fd00: 206d 7573 7420 6265 206f 7574 7369 6465   must be outside
-0001fd10: 2073 7068 6572 650d 0a20 2020 2070 5b22   sphere..    p["
-0001fd20: 6469 706f 6c65 5f6d 6f6d 656e 7422 5d3a  dipole_moment"]:
-0001fd30: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-0001fd40: 7420 5b6d 2078 2033 5d0d 0a20 2020 2020  t [m x 3]..     
-0001fd50: 2020 204d 6f6d 656e 7420 6f66 2064 6970     Moment of dip
-0001fd60: 6f6c 6573 0d0a 2020 2020 705b 2264 6964  oles..    p["did
-0001fd70: 7422 5d3a 2066 6c6f 6174 0d0a 2020 2020  t"]: float..    
-0001fd80: 2020 2020 5661 7269 6174 696f 6e20 7261      Variation ra
-0001fd90: 7465 206f 6620 6375 7272 656e 7420 696e  te of current in
-0001fda0: 2074 6865 2063 6f69 6c0d 0a20 2020 2070   the coil..    p
-0001fdb0: 5b22 706f 7369 7469 6f6e 7322 5d3a 206e  ["positions"]: n
-0001fdc0: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-0001fdd0: 5b4e 2078 2033 5d0d 0a20 2020 2020 2020  [N x 3]..       
-0001fde0: 2050 6f73 6974 696f 6e20 7768 6572 6520   Position where 
-0001fdf0: 6669 656c 6473 2073 686f 756c 6420 6265  fields should be
-0001fe00: 2063 616c 6375 6c61 7465 642c 206d 7573   calculated, mus
-0001fe10: 7420 6c69 6520 696e 7369 6465 2073 7068  t lie inside sph
-0001fe20: 6572 6520 696e 2028 6d6d 290d 0a0d 0a20  ere in (mm).... 
-0001fe30: 2020 2052 6574 7572 6e73 0d0a 2020 2020     Returns..    
-0001fe40: 2d2d 2d2d 2d2d 2d0d 0a20 2020 2045 3a20  -------..    E: 
-0001fe50: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-0001fe60: 205b 3120 7820 332a 4e5d 0d0a 2020 2020   [1 x 3*N]..    
-0001fe70: 2020 2020 452d 6669 656c 6473 2061 7420      E-fields at 
-0001fe80: 6465 7465 6374 6f72 2070 6f73 6974 696f  detector positio
-0001fe90: 6e73 0d0a 0d0a 2020 2020 4e6f 7465 730d  ns....    Notes.
-0001fea0: 0a20 2020 202d 2d2d 2d2d 0d0a 2020 2020  .    -----..    
-0001feb0: 2e2e 205b 315d 2048 656c 6c65 722c 204c  .. [1] Heller, L
-0001fec0: 2e2c 2026 2076 616e 2048 756c 7374 6579  ., & van Hulstey
-0001fed0: 6e2c 2044 2e20 422e 2028 3139 3932 292e  n, D. B. (1992).
-0001fee0: 2042 7261 696e 2073 7469 6d75 6c61 7469   Brain stimulati
-0001fef0: 6f6e 2075 7369 6e67 2065 6c65 6374 726f  on using electro
-0001ff00: 6d61 676e 6574 6963 2073 6f75 7263 6573  magnetic sources
-0001ff10: 3a0d 0a20 2020 2020 2020 7468 656f 7265  :..       theore
-0001ff20: 7469 6361 6c20 6173 7065 6374 732e 2042  tical aspects. B
-0001ff30: 696f 7068 7973 6963 616c 204a 6f75 726e  iophysical Journ
-0001ff40: 616c 2c20 3633 2831 292c 2031 3239 2d31  al, 63(1), 129-1
-0001ff50: 3338 2e0d 0a20 2020 2022 2222 0d0a 0d0a  38...    """....
-0001ff60: 2020 2020 6465 6620 5f5f 696e 6974 5f5f      def __init__
-0001ff70: 2873 656c 662c 206d 6174 6c61 625f 6d6f  (self, matlab_mo
-0001ff80: 6465 6c3d 4661 6c73 6529 3a0d 0a20 2020  del=False):..   
-0001ff90: 2020 2020 2073 7570 6572 2874 7970 6528       super(type(
-0001ffa0: 7365 6c66 292c 2073 656c 6629 2e5f 5f69  self), self).__i
-0001ffb0: 6e69 745f 5f28 6d61 746c 6162 5f6d 6f64  nit__(matlab_mod
-0001ffc0: 656c 3d6d 6174 6c61 625f 6d6f 6465 6c29  el=matlab_model)
-0001ffd0: 0d0a 2020 2020 2020 2020 7365 6c66 2e66  ..        self.f
-0001ffe0: 6e61 6d65 203d 2069 6e73 7065 6374 2e67  name = inspect.g
-0001fff0: 6574 6669 6c65 2869 6e73 7065 6374 2e63  etfile(inspect.c
-00020000: 7572 7265 6e74 6672 616d 6528 2929 0d0a  urrentframe())..
-00020010: 0d0a 2020 2020 6465 6620 7661 6c69 6461  ..    def valida
-00020020: 7465 2873 656c 6629 3a0d 0a20 2020 2020  te(self):..     
-00020030: 2020 2070 6173 730d 0a0d 0a20 2020 2064     pass....    d
-00020040: 6566 2073 696d 756c 6174 6528 7365 6c66  ef simulate(self
-00020050: 2c20 7072 6f63 6573 735f 6964 3d4e 6f6e  , process_id=Non
-00020060: 652c 206d 6174 6c61 625f 656e 6769 6e65  e, matlab_engine
-00020070: 3d4e 6f6e 6529 3a0d 0a0d 0a20 2020 2020  =None):....     
-00020080: 2020 2069 6620 7365 6c66 2e70 5b22 6469     if self.p["di
-00020090: 706f 6c65 5f70 6f73 225d 2e73 6861 7065  pole_pos"].shape
-000200a0: 2021 3d20 7365 6c66 2e70 5b22 6469 706f   != self.p["dipo
-000200b0: 6c65 5f6d 6f6d 656e 7422 5d2e 7368 6170  le_moment"].shap
-000200c0: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-000200d0: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
-000200e0: 2827 4c69 7374 206f 6620 6469 706f 6c65  ('List of dipole
-000200f0: 2070 6f73 6974 696f 6e20 616e 6420 6d6f   position and mo
-00020100: 6d65 6e74 7320 7368 6f75 6c64 2068 6176  ments should hav
-00020110: 6520 7468 6520 7361 6d65 270d 0a20 2020  e the same'..   
-00020120: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020130: 2020 2020 2020 2020 2020 276c 656e 6774            'lengt
-00020140: 6873 2729 0d0a 2020 2020 2020 2020 6d75  hs')..        mu
-00020150: 305f 3470 6920 3d20 3165 2d37 0d0a 0d0a  0_4pi = 1e-7....
-00020160: 2020 2020 2020 2020 6520 3d20 6e70 2e7a          e = np.z
-00020170: 6572 6f73 2873 656c 662e 705b 2270 6f73  eros(self.p["pos
-00020180: 6974 696f 6e73 225d 2e73 6861 7065 2c20  itions"].shape, 
-00020190: 6474 7970 653d 666c 6f61 7429 0d0a 2020  dtype=float)..  
-000201a0: 2020 2020 2020 6470 203d 206e 702e 6174        dp = np.at
-000201b0: 6c65 6173 745f 3264 2873 656c 662e 705b  least_2d(self.p[
-000201c0: 2264 6970 6f6c 655f 706f 7322 5d29 0d0a  "dipole_pos"])..
-000201d0: 2020 2020 2020 2020 646d 203d 206e 702e          dm = np.
-000201e0: 6174 6c65 6173 745f 3264 2873 656c 662e  atleast_2d(self.
-000201f0: 705b 2264 6970 6f6c 655f 6d6f 6d65 6e74  p["dipole_moment
-00020200: 225d 290d 0a0d 0a20 2020 2020 2020 2072  "])....        r
-00020210: 3120 3d20 7365 6c66 2e70 5b22 706f 7369  1 = self.p["posi
-00020220: 7469 6f6e 7322 5d0d 0a0d 0a20 2020 2020  tions"]....     
-00020230: 2020 2066 6f72 206d 2c20 7232 2069 6e20     for m, r2 in 
-00020240: 7a69 7028 646d 2c20 6470 293a 0d0a 2020  zip(dm, dp):..  
-00020250: 2020 2020 2020 2020 2020 6120 3d20 7232            a = r2
-00020260: 202d 2072 310d 0a20 2020 2020 2020 2020   - r1..         
-00020270: 2020 206e 6f72 6d5f 6120 3d20 6e70 2e6c     norm_a = np.l
-00020280: 696e 616c 672e 6e6f 726d 2861 2c20 6178  inalg.norm(a, ax
-00020290: 6973 3d31 295b 3a2c 204e 6f6e 655d 0d0a  is=1)[:, None]..
-000202a0: 0d0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
-000202b0: 6e6f 726d 5f72 3120 3d20 6e70 2e6c 696e  norm_r1 = np.lin
-000202c0: 616c 672e 6e6f 726d 2872 312c 2061 7869  alg.norm(r1, axi
-000202d0: 733d 3129 5b3a 2c20 4e6f 6e65 5d0d 0a20  s=1)[:, None].. 
-000202e0: 2020 2020 2020 2020 2020 206e 6f72 6d5f             norm_
-000202f0: 7232 203d 206e 702e 6c69 6e61 6c67 2e6e  r2 = np.linalg.n
-00020300: 6f72 6d28 7232 290d 0a0d 0a20 2020 2020  orm(r2)....     
-00020310: 2020 2020 2020 2072 325f 646f 745f 6120         r2_dot_a 
-00020320: 3d20 6e70 2e73 756d 2872 3220 2a20 612c  = np.sum(r2 * a,
-00020330: 2061 7869 733d 3129 5b3a 2c20 4e6f 6e65   axis=1)[:, None
-00020340: 5d0d 0a20 2020 2020 2020 2020 2020 2066  ]..            f
-00020350: 203d 206e 6f72 6d5f 6120 2a20 286e 6f72   = norm_a * (nor
-00020360: 6d5f 7232 202a 206e 6f72 6d5f 6120 2b20  m_r2 * norm_a + 
-00020370: 7232 5f64 6f74 5f61 290d 0a20 2020 2020  r2_dot_a)..     
-00020380: 2020 2020 2020 2067 7261 645f 6620 3d20         grad_f = 
-00020390: 286e 6f72 6d5f 6120 2a2a 2032 202f 206e  (norm_a ** 2 / n
-000203a0: 6f72 6d5f 7232 202b 2032 202a 206e 6f72  orm_r2 + 2 * nor
-000203b0: 6d5f 6120 2b20 3220 2a20 6e6f 726d 5f72  m_a + 2 * norm_r
-000203c0: 3220 2b20 7232 5f64 6f74 5f61 202f 206e  2 + r2_dot_a / n
-000203d0: 6f72 6d5f 6129 202a 2072 3220 2d20 5c0d  orm_a) * r2 - \.
-000203e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000203f0: 2020 2020 2020 286e 6f72 6d5f 6120 2b20        (norm_a + 
-00020400: 3220 2a20 6e6f 726d 5f72 3220 2b20 7232  2 * norm_r2 + r2
-00020410: 5f64 6f74 5f61 202f 206e 6f72 6d5f 6129  _dot_a / norm_a)
-00020420: 202a 2072 310d 0a20 2020 2020 2020 2020   * r1..         
-00020430: 2020 2065 202b 3d20 2d73 656c 662e 705b     e += -self.p[
-00020440: 2264 6964 7422 5d20 2a20 6d75 305f 3470  "didt"] * mu0_4p
-00020450: 6920 2f20 6620 2a2a 2032 202a 2028 0d0a  i / f ** 2 * (..
-00020460: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00020470: 2020 2020 6620 2a20 6e70 2e63 726f 7373      f * np.cross
-00020480: 2872 312c 206d 2920 2d20 6e70 2e63 726f  (r1, m) - np.cro
-00020490: 7373 286e 702e 7375 6d28 6d20 2a20 6772  ss(np.sum(m * gr
-000204a0: 6164 5f66 2c20 6178 6973 3d31 295b 3a2c  ad_f, axis=1)[:,
-000204b0: 204e 6f6e 655d 202a 2072 312c 2072 3229   None] * r1, r2)
-000204c0: 290d 0a0d 0a20 2020 2020 2020 2065 203d  )....        e =
-000204d0: 2065 2e66 6c61 7474 656e 2829 5b6e 702e   e.flatten()[np.
-000204e0: 6e65 7761 7869 732c 203a 5d0d 0a0d 0a20  newaxis, :].... 
-000204f0: 2020 2020 2020 2072 6574 7572 6e20 650d         return e.
-00020500: 0a0d 0a0d 0a63 6c61 7373 2050 6f74 656e  .....class Poten
-00020510: 7469 616c 4469 706f 6c65 334c 6179 6572  tialDipole3Layer
-00020520: 7328 4162 7374 7261 6374 4d6f 6465 6c29  s(AbstractModel)
-00020530: 3a0d 0a20 2020 2022 2222 0d0a 2020 2020  :..    """..    
-00020540: 4361 6c63 756c 6174 6573 2074 6865 2065  Calculates the e
-00020550: 6c65 6374 7269 6320 706f 7465 6e74 6961  lectric potentia
-00020560: 6c20 696e 2061 2033 2d6c 6179 6572 6564  l in a 3-layered
-00020570: 2073 7068 6572 6520 6361 7573 6564 2062   sphere caused b
-00020580: 7920 6120 6469 706f 6c65 2061 6674 6572  y a dipole after
-00020590: 2041 7279 2065 7420 616c 2e20 2831 3938   Ary et al. (198
-000205a0: 3129 2e0d 0a0d 0a20 2020 2050 6172 616d  1).....    Param
-000205b0: 6574 6572 730d 0a20 2020 202d 2d2d 2d2d  eters..    -----
-000205c0: 2d2d 2d2d 2d0d 0a20 2020 2070 5b22 7261  -----..    p["ra
-000205d0: 6469 6922 5d3a 206c 6973 7420 5b33 5d0d  dii"]: list [3].
-000205e0: 0a20 2020 2020 2020 2052 6164 6975 7320  .        Radius 
-000205f0: 6f66 2065 6163 6820 6f66 2074 6865 2033  of each of the 3
-00020600: 206c 6179 6572 7320 2869 6e6e 6572 6d6f   layers (innermo
-00020610: 7374 2074 6f20 6f75 7465 726d 6f73 7429  st to outermost)
-00020620: 2069 6e20 286d 6d29 0d0a 2020 2020 705b   in (mm)..    p[
-00020630: 2263 6f6e 645f 6272 6169 6e5f 7363 616c  "cond_brain_scal
-00020640: 7022 5d3a 2066 6c6f 6174 0d0a 2020 2020  p"]: float..    
-00020650: 2020 2020 436f 6e64 7563 7469 7669 7479      Conductivity
-00020660: 206f 6620 7468 6520 6272 6169 6e20 616e   of the brain an
-00020670: 6420 7363 616c 7020 6c61 7965 7273 2069  d scalp layers i
-00020680: 6e20 2853 2f6d 290d 0a20 2020 2070 5b22  n (S/m)..    p["
-00020690: 636f 6e64 5f73 6b75 6c6c 225d 3a20 666c  cond_skull"]: fl
-000206a0: 6f61 740d 0a20 2020 2020 2020 2043 6f6e  oat..        Con
-000206b0: 6475 6374 6976 6974 7920 6f66 2074 6865  ductivity of the
-000206c0: 2073 6b75 6c6c 206c 6179 6572 2069 6e20   skull layer in 
-000206d0: 2853 2f6d 290d 0a20 2020 2070 5b22 6469  (S/m)..    p["di
-000206e0: 706f 6c65 5f70 6f73 225d 3a20 6e64 6172  pole_pos"]: ndar
-000206f0: 7261 7920 6f66 2066 6c6f 6174 205b 3320  ray of float [3 
-00020700: 7820 315d 0d0a 2020 2020 2020 2020 506f  x 1]..        Po
-00020710: 7369 7469 6f6e 206f 6620 7468 6520 6469  sition of the di
-00020720: 706f 6c65 2c20 696e 2028 6d6d 290d 0a20  pole, in (mm).. 
-00020730: 2020 2070 5b22 6469 706f 6c65 5f6d 6f6d     p["dipole_mom
-00020740: 656e 7422 5d3a 206e 6461 7272 6179 206f  ent"]: ndarray o
-00020750: 6620 666c 6f61 7420 5b33 2078 2031 5d0d  f float [3 x 1].
-00020760: 0a20 2020 2020 2020 204d 6f6d 656e 7420  .        Moment 
-00020770: 6f66 2064 6970 6f6c 652c 2069 6e20 2843  of dipole, in (C
-00020780: 6d29 0d0a 2020 2020 705b 2273 7572 6661  m)..    p["surfa
-00020790: 6365 5f70 6f69 6e74 7322 5d3a 206e 6461  ce_points"]: nda
-000207a0: 7272 6179 206f 6620 666c 6f61 7420 5b4e  rray of float [N
-000207b0: 2078 2033 5d0d 0a20 2020 2020 2020 204c   x 3]..        L
-000207c0: 6973 7420 6f66 2070 6f73 6974 696f 6e73  ist of positions
-000207d0: 2077 6865 7265 2074 6865 2070 6f74 656e   where the poten
-000207e0: 7469 616c 2073 686f 756c 6420 6265 2063  tial should be c
-000207f0: 616c 6375 6c61 7465 6420 696e 2028 6d6d  alculated in (mm
-00020800: 290d 0a0d 0a20 2020 2052 6574 7572 6e73  )....    Returns
-00020810: 0d0a 2020 2020 2d2d 2d2d 2d2d 2d0d 0a20  ..    -------.. 
-00020820: 2020 2070 6f74 656e 7469 616c 3a20 6e64     potential: nd
-00020830: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
-00020840: 3120 7820 6e5f 6f75 745d 0d0a 2020 2020  1 x n_out]..    
-00020850: 2020 2020 5661 6c75 6573 206f 6620 7468      Values of th
-00020860: 6520 656c 6563 7472 6963 2070 6f74 656e  e electric poten
-00020870: 7469 616c 2c20 696e 2028 5629 0d0a 0d0a  tial, in (V)....
-00020880: 2020 2020 4e6f 7465 730d 0a20 2020 202d      Notes..    -
-00020890: 2d2d 2d2d 0d0a 2020 2020 2e2e 205b 315d  ----..    .. [1]
-000208a0: 2041 7279 2c20 4a2e 2050 2e2c 204b 6c65   Ary, J. P., Kle
-000208b0: 696e 2c20 532e 2041 2e2c 2026 2046 656e  in, S. A., & Fen
-000208c0: 6465 722c 2044 2e20 482e 2028 3139 3831  der, D. H. (1981
-000208d0: 292e 204c 6f63 6174 696f 6e20 6f66 2073  ). Location of s
-000208e0: 6f75 7263 6573 206f 6620 6576 6f6b 6564  ources of evoked
-000208f0: 2073 6361 6c70 2070 6f74 656e 7469 616c   scalp potential
-00020900: 733a 0d0a 2020 2020 2020 2063 6f72 7265  s:..       corre
-00020910: 6374 696f 6e73 2066 6f72 2073 6b75 6c6c  ctions for skull
-00020920: 2061 6e64 2073 6361 6c70 2074 6869 636b   and scalp thick
-00020930: 6e65 7373 6573 2e20 4945 4545 2054 7261  nesses. IEEE Tra
-00020940: 6e73 6163 7469 6f6e 7320 6f6e 2042 696f  nsactions on Bio
-00020950: 6d65 6469 6361 6c20 456e 6769 6e65 6572  medical Engineer
-00020960: 696e 672c 2028 3629 2c20 3434 372d 3435  ing, (6), 447-45
-00020970: 322e 0d0a 2020 2020 2020 2065 712e 2032  2...       eq. 2
-00020980: 2061 6e64 2032 610d 0a20 2020 2022 2222   and 2a..    """
-00020990: 0d0a 0d0a 2020 2020 6465 6620 5f5f 696e  ....    def __in
-000209a0: 6974 5f5f 2873 656c 662c 206d 6174 6c61  it__(self, matla
-000209b0: 625f 6d6f 6465 6c3d 4661 6c73 6529 3a0d  b_model=False):.
-000209c0: 0a20 2020 2020 2020 2073 7570 6572 2874  .        super(t
-000209d0: 7970 6528 7365 6c66 292c 2073 656c 6629  ype(self), self)
-000209e0: 2e5f 5f69 6e69 745f 5f28 6d61 746c 6162  .__init__(matlab
-000209f0: 5f6d 6f64 656c 3d6d 6174 6c61 625f 6d6f  _model=matlab_mo
-00020a00: 6465 6c29 0d0a 2020 2020 2020 2020 7365  del)..        se
-00020a10: 6c66 2e66 6e61 6d65 203d 2069 6e73 7065  lf.fname = inspe
-00020a20: 6374 2e67 6574 6669 6c65 2869 6e73 7065  ct.getfile(inspe
-00020a30: 6374 2e63 7572 7265 6e74 6672 616d 6528  ct.currentframe(
-00020a40: 2929 0d0a 0d0a 2020 2020 6465 6620 7661  ))....    def va
-00020a50: 6c69 6461 7465 2873 656c 6629 3a0d 0a20  lidate(self):.. 
-00020a60: 2020 2020 2020 2070 6173 730d 0a0d 0a20         pass.... 
-00020a70: 2020 2064 6566 2073 696d 756c 6174 6528     def simulate(
-00020a80: 7365 6c66 2c20 7072 6f63 6573 735f 6964  self, process_id
-00020a90: 3d4e 6f6e 652c 206d 6174 6c61 625f 656e  =None, matlab_en
-00020aa0: 6769 6e65 3d4e 6f6e 6529 3a0d 0a0d 0a20  gine=None):.... 
-00020ab0: 2020 2020 2020 2061 7373 6572 7420 6c65         assert le
-00020ac0: 6e28 7365 6c66 2e70 5b22 7261 6469 6922  n(self.p["radii"
-00020ad0: 5d29 203d 3d20 330d 0a20 2020 2020 2020  ]) == 3..       
-00020ae0: 2061 7373 6572 7420 7365 6c66 2e70 5b22   assert self.p["
-00020af0: 7261 6469 6922 5d5b 305d 203c 2073 656c  radii"][0] < sel
-00020b00: 662e 705b 2272 6164 6969 225d 5b31 5d20  f.p["radii"][1] 
-00020b10: 3c20 7365 6c66 2e70 5b22 7261 6469 6922  < self.p["radii"
-00020b20: 5d5b 325d 0d0a 2020 2020 2020 2020 6173  ][2]..        as
-00020b30: 7365 7274 206c 656e 2873 656c 662e 705b  sert len(self.p[
-00020b40: 2264 6970 6f6c 655f 6d6f 6d65 6e74 225d  "dipole_moment"]
-00020b50: 2920 3d3d 2033 0d0a 2020 2020 2020 2020  ) == 3..        
-00020b60: 6173 7365 7274 206c 656e 2873 656c 662e  assert len(self.
-00020b70: 705b 2264 6970 6f6c 655f 706f 7322 5d29  p["dipole_pos"])
-00020b80: 203d 3d20 330d 0a20 2020 2020 2020 2061   == 3..        a
-00020b90: 7373 6572 7420 7365 6c66 2e70 5b22 7375  ssert self.p["su
-00020ba0: 7266 6163 655f 706f 696e 7473 225d 2e73  rface_points"].s
-00020bb0: 6861 7065 5b31 5d20 3d3d 2033 0d0a 2020  hape[1] == 3..  
-00020bc0: 2020 2020 2020 6173 7365 7274 206e 702e        assert np.
-00020bd0: 6c69 6e61 6c67 2e6e 6f72 6d28 7365 6c66  linalg.norm(self
-00020be0: 2e70 5b22 6469 706f 6c65 5f70 6f73 225d  .p["dipole_pos"]
-00020bf0: 2920 3c20 7365 6c66 2e70 5b22 7261 6469  ) < self.p["radi
-00020c00: 6922 5d5b 305d 2c20 2244 6970 6f6c 6520  i"][0], "Dipole 
-00020c10: 6d75 7374 2062 6520 696e 7369 6465 2069  must be inside i
-00020c20: 6e6e 6572 2073 7068 6572 6522 0d0a 0d0a  nner sphere"....
-00020c30: 2020 2020 2020 2020 7869 203d 2066 6c6f          xi = flo
-00020c40: 6174 2873 656c 662e 705b 2263 6f6e 645f  at(self.p["cond_
-00020c50: 736b 756c 6c22 5d29 202f 2066 6c6f 6174  skull"]) / float
-00020c60: 2873 656c 662e 705b 2263 6f6e 645f 6272  (self.p["cond_br
-00020c70: 6169 6e5f 7363 616c 7022 5d29 0d0a 2020  ain_scalp"])..  
-00020c80: 2020 2020 2020 7220 3d20 666c 6f61 7428        r = float(
-00020c90: 7365 6c66 2e70 5b22 7261 6469 6922 5d5b  self.p["radii"][
-00020ca0: 325d 202a 2031 652d 3329 0d0a 2020 2020  2] * 1e-3)..    
-00020cb0: 2020 2020 6631 203d 2066 6c6f 6174 2873      f1 = float(s
-00020cc0: 656c 662e 705b 2272 6164 6969 225d 5b30  elf.p["radii"][0
-00020cd0: 5d20 2a20 3165 2d33 2920 2f20 720d 0a20  ] * 1e-3) / r.. 
-00020ce0: 2020 2020 2020 2066 3220 3d20 666c 6f61         f2 = floa
-00020cf0: 7428 7365 6c66 2e70 5b22 7261 6469 6922  t(self.p["radii"
-00020d00: 5d5b 315d 202a 2031 652d 3329 202f 2072  ][1] * 1e-3) / r
-00020d10: 0d0a 2020 2020 2020 2020 6220 3d20 6e70  ..        b = np
-00020d20: 2e6c 696e 616c 672e 6e6f 726d 2873 656c  .linalg.norm(sel
-00020d30: 662e 705b 2264 6970 6f6c 655f 706f 7322  f.p["dipole_pos"
-00020d40: 5d29 202a 2031 652d 3320 2f20 720d 0a0d  ]) * 1e-3 / r...
-00020d50: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
-00020d60: 6e70 2e61 6c6c 636c 6f73 6528 6e70 2e6c  np.allclose(np.l
-00020d70: 696e 616c 672e 6e6f 726d 2873 656c 662e  inalg.norm(self.
-00020d80: 705b 2273 7572 6661 6365 5f70 6f69 6e74  p["surface_point
-00020d90: 7322 5d2c 2061 7869 733d 3129 2c20 7220  s"], axis=1), r 
-00020da0: 2a20 3165 3329 3a0d 0a20 2020 2020 2020  * 1e3):..       
-00020db0: 2020 2020 2077 6172 6e69 6e67 732e 7761       warnings.wa
-00020dc0: 726e 2827 536f 6d65 2070 6f69 6e74 7320  rn('Some points 
-00020dd0: 6172 6520 6e6f 7420 696e 2074 6865 2073  are not in the s
-00020de0: 7572 6661 6365 2121 2729 0d0a 0d0a 2020  urface!!')....  
-00020df0: 2020 2020 2020 6966 206e 702e 6973 636c        if np.iscl
-00020e00: 6f73 6528 622c 2030 293a 0d0a 2020 2020  ose(b, 0):..    
-00020e10: 2020 2020 2020 2020 725f 6469 7220 3d20          r_dir = 
-00020e20: 6e70 2e61 7272 6179 2873 656c 662e 705b  np.array(self.p[
-00020e30: 2264 6970 6f6c 655f 6d6f 6d65 6e74 225d  "dipole_moment"]
-00020e40: 2c20 6474 7970 653d 666c 6f61 7429 0d0a  , dtype=float)..
-00020e50: 2020 2020 2020 2020 2020 2020 725f 6469              r_di
-00020e60: 7220 2f3d 206e 702e 6c69 6e61 6c67 2e6e  r /= np.linalg.n
-00020e70: 6f72 6d28 725f 6469 7229 0d0a 2020 2020  orm(r_dir)..    
-00020e80: 2020 2020 656c 7365 3a0d 0a20 2020 2020      else:..     
-00020e90: 2020 2020 2020 2072 5f64 6972 203d 2073         r_dir = s
-00020ea0: 656c 662e 705b 2264 6970 6f6c 655f 706f  elf.p["dipole_po
-00020eb0: 7322 5d20 2f20 6e70 2e6c 696e 616c 672e  s"] / np.linalg.
-00020ec0: 6e6f 726d 2873 656c 662e 705b 2264 6970  norm(self.p["dip
-00020ed0: 6f6c 655f 706f 7322 5d29 0d0a 0d0a 2020  ole_pos"])....  
-00020ee0: 2020 2020 2020 6d5f 7220 3d20 6e70 2e64        m_r = np.d
-00020ef0: 6f74 2873 656c 662e 705b 2264 6970 6f6c  ot(self.p["dipol
-00020f00: 655f 6d6f 6d65 6e74 225d 2c20 725f 6469  e_moment"], r_di
-00020f10: 7229 0d0a 2020 2020 2020 2020 636f 735f  r)..        cos_
-00020f20: 616c 7068 6120 3d20 7365 6c66 2e70 5b22  alpha = self.p["
-00020f30: 7375 7266 6163 655f 706f 696e 7473 225d  surface_points"]
-00020f40: 2e64 6f74 2872 5f64 6972 2920 2f20 7220  .dot(r_dir) / r 
-00020f50: 2a20 3165 2d33 0d0a 0d0a 2020 2020 2020  * 1e-3....      
-00020f60: 2020 745f 6469 7220 3d20 7365 6c66 2e70    t_dir = self.p
-00020f70: 5b22 6469 706f 6c65 5f6d 6f6d 656e 7422  ["dipole_moment"
-00020f80: 5d20 2d20 6d5f 7220 2a20 725f 6469 720d  ] - m_r * r_dir.
-00020f90: 0a0d 0a20 2020 2020 2020 2023 2069 6620  ...        # if 
-00020fa0: 7468 6520 6469 706f 6c65 2069 7320 7261  the dipole is ra
-00020fb0: 6469 616c 206f 6e6c 790d 0a20 2020 2020  dial only..     
-00020fc0: 2020 2069 6620 6e70 2e69 7363 6c6f 7365     if np.isclose
-00020fd0: 286e 702e 6c69 6e61 6c67 2e6e 6f72 6d28  (np.linalg.norm(
-00020fe0: 7365 6c66 2e70 5b22 6469 706f 6c65 5f6d  self.p["dipole_m
-00020ff0: 6f6d 656e 7422 5d29 2c20 6e70 2e61 6273  oment"]), np.abs
-00021000: 286e 702e 646f 7428 725f 6469 722c 2073  (np.dot(r_dir, s
-00021010: 656c 662e 705b 2264 6970 6f6c 655f 6d6f  elf.p["dipole_mo
-00021020: 6d65 6e74 225d 2929 293a 0d0a 2020 2020  ment"]))):..    
-00021030: 2020 2020 2020 2020 2320 7472 7920 746f          # try to
-00021040: 2073 6574 2061 6e20 6178 6973 2069 6e20   set an axis in 
-00021050: 782c 2069 6620 7468 6520 6469 706f 6c65  x, if the dipole
-00021060: 2069 7320 6e6f 7420 696e 2078 0d0a 2020   is not in x..  
-00021070: 2020 2020 2020 2020 2020 6966 206e 6f74            if not
-00021080: 206e 702e 616c 6c63 6c6f 7365 286e 702e   np.allclose(np.
-00021090: 6162 7328 725f 6469 722e 646f 7428 5b31  abs(r_dir.dot([1
-000210a0: 2c20 302c 2030 5d29 292c 2031 293a 0d0a  , 0, 0])), 1):..
-000210b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000210c0: 745f 6469 7220 3d20 6e70 2e61 7272 6179  t_dir = np.array
-000210d0: 285b 312e 2c20 302e 2c20 302e 5d2c 2064  ([1., 0., 0.], d
-000210e0: 7479 7065 3d66 6c6f 6174 290d 0a20 2020  type=float)..   
-000210f0: 2020 2020 2020 2020 2023 206f 7468 6572           # other
-00021100: 7769 7365 2c20 7365 7420 6974 2069 6e20  wise, set it in 
-00021110: 790d 0a20 2020 2020 2020 2020 2020 2065  y..            e
-00021120: 6c73 653a 0d0a 2020 2020 2020 2020 2020  lse:..          
-00021130: 2020 2020 2020 745f 6469 7220 3d20 6e70        t_dir = np
-00021140: 2e61 7272 6179 285b 302e 2c20 312e 2c20  .array([0., 1., 
-00021150: 302e 5d2c 2064 7479 7065 3d66 6c6f 6174  0.], dtype=float
-00021160: 290d 0a20 2020 2020 2020 2020 2020 2074  )..            t
-00021170: 5f64 6972 203d 2074 5f64 6972 202d 2072  _dir = t_dir - r
-00021180: 5f64 6972 2e64 6f74 2874 5f64 6972 290d  _dir.dot(t_dir).
-00021190: 0a0d 0a20 2020 2020 2020 2074 5f64 6972  ...        t_dir
-000211a0: 202f 3d20 6e70 2e6c 696e 616c 672e 6e6f   /= np.linalg.no
-000211b0: 726d 2874 5f64 6972 290d 0a20 2020 2020  rm(t_dir)..     
-000211c0: 2020 2074 325f 6469 7220 3d20 6e70 2e63     t2_dir = np.c
-000211d0: 726f 7373 2872 5f64 6972 2c20 745f 6469  ross(r_dir, t_di
-000211e0: 7229 0d0a 2020 2020 2020 2020 6d5f 7420  r)..        m_t 
-000211f0: 3d20 6e70 2e64 6f74 2873 656c 662e 705b  = np.dot(self.p[
-00021200: 2264 6970 6f6c 655f 6d6f 6d65 6e74 225d  "dipole_moment"]
-00021210: 2c20 745f 6469 7229 0d0a 2020 2020 2020  , t_dir)..      
-00021220: 2020 6265 7461 203d 206e 702e 6172 6374    beta = np.arct
-00021230: 616e 3228 7365 6c66 2e70 5b22 7375 7266  an2(self.p["surf
-00021240: 6163 655f 706f 696e 7473 225d 2e64 6f74  ace_points"].dot
-00021250: 2874 325f 6469 7229 2c20 7365 6c66 2e70  (t2_dir), self.p
-00021260: 5b22 7375 7266 6163 655f 706f 696e 7473  ["surface_points
-00021270: 225d 2e64 6f74 2874 5f64 6972 2929 0d0a  "].dot(t_dir))..
-00021280: 2020 2020 2020 2020 636f 735f 6265 7461          cos_beta
-00021290: 203d 206e 702e 636f 7328 6265 7461 290d   = np.cos(beta).
-000212a0: 0a0d 0a20 2020 2020 2020 2064 6566 2064  ...        def d
-000212b0: 286e 293a 0d0a 2020 2020 2020 2020 2020  (n):..          
-000212c0: 2020 645f 6e20 3d20 2828 6e20 2b20 3129    d_n = ((n + 1)
-000212d0: 202a 2078 6920 2b20 6e29 202a 2028 286e   * xi + n) * ((n
-000212e0: 202a 2078 6929 202f 2028 6e20 2b20 3129   * xi) / (n + 1)
-000212f0: 202b 2031 2920 2b20 5c0d 0a20 2020 2020   + 1) + \..     
-00021300: 2020 2020 2020 2020 2020 2020 2028 3120               (1 
-00021310: 2d20 7869 2920 2a20 2828 6e20 2b20 3129  - xi) * ((n + 1)
-00021320: 202a 2078 6920 2b20 6e29 202a 2028 6631   * xi + n) * (f1
-00021330: 202a 2a20 2832 202a 206e 202b 2031 2920   ** (2 * n + 1) 
-00021340: 2d20 6632 202a 2a20 2832 202a 206e 202b  - f2 ** (2 * n +
-00021350: 2031 2929 202d 205c 0d0a 2020 2020 2020   1)) - \..      
-00021360: 2020 2020 2020 2020 2020 2020 6e20 2a20              n * 
-00021370: 2831 202d 2078 6929 202a 2a20 3220 2a20  (1 - xi) ** 2 * 
-00021380: 2866 3120 2f20 6632 2920 2a2a 2028 3220  (f1 / f2) ** (2 
-00021390: 2a20 6e20 2b20 3129 0d0a 2020 2020 2020  * n + 1)..      
-000213a0: 2020 2020 2020 7265 7475 726e 2064 5f6e        return d_n
-000213b0: 0d0a 0d0a 2020 2020 2020 2020 706f 7465  ....        pote
-000213c0: 6e74 6961 6c20 3d20 6e70 2e7a 6572 6f73  ntial = np.zeros
-000213d0: 2873 656c 662e 705b 2273 7572 6661 6365  (self.p["surface
-000213e0: 5f70 6f69 6e74 7322 5d2e 7368 6170 655b  _points"].shape[
-000213f0: 305d 2c20 6474 7970 653d 2766 6c6f 6174  0], dtype='float
-00021400: 3634 2729 0d0a 0d0a 2020 2020 2020 2020  64')....        
-00021410: 7020 3d20 6e70 2e7a 6572 6f73 2828 322c  p = np.zeros((2,
-00021420: 2073 656c 662e 6e62 725f 706f 6c79 6e6f   self.nbr_polyno
-00021430: 6d69 616c 7320 2b20 312c 2073 656c 662e  mials + 1, self.
-00021440: 705b 2273 7572 6661 6365 5f70 6f69 6e74  p["surface_point
-00021450: 7322 5d2e 7368 6170 655b 305d 292c 2064  s"].shape[0]), d
-00021460: 7479 7065 3d27 666c 6f61 7436 3427 290d  type='float64').
-00021470: 0a0d 0a20 2020 2020 2020 2066 6f72 2069  ...        for i
-00021480: 692c 2063 6120 696e 2065 6e75 6d65 7261  i, ca in enumera
-00021490: 7465 2863 6f73 5f61 6c70 6861 293a 0d0a  te(cos_alpha):..
-000214a0: 2020 2020 2020 2020 2020 2020 705b 3a2c              p[:,
-000214b0: 203a 2c20 6969 5d2c 205f 203d 2073 6369   :, ii], _ = sci
-000214c0: 7079 2e73 7065 6369 616c 2e6c 706d 6e28  py.special.lpmn(
-000214d0: 312c 2073 656c 662e 6e62 725f 706f 6c79  1, self.nbr_poly
-000214e0: 6e6f 6d69 616c 732c 2063 6129 0d0a 0d0a  nomials, ca)....
-000214f0: 2020 2020 2020 2020 666f 7220 6969 2069          for ii i
-00021500: 6e20 7261 6e67 6528 312c 2073 656c 662e  n range(1, self.
-00021510: 6e62 725f 706f 6c79 6e6f 6d69 616c 7320  nbr_polynomials 
-00021520: 2b20 3129 3a0d 0a20 2020 2020 2020 2020  + 1):..         
-00021530: 2020 206e 6920 3d20 666c 6f61 7428 6969     ni = float(ii
-00021540: 290d 0a20 2020 2020 2020 2020 2020 2070  )..            p
-00021550: 6f74 656e 7469 616c 202b 3d20 6e70 2e6e  otential += np.n
-00021560: 616e 5f74 6f5f 6e75 6d28 0d0a 2020 2020  an_to_num(..    
-00021570: 2020 2020 2020 2020 2020 2020 2832 202a              (2 *
-00021580: 206e 6920 2b20 3129 202f 206e 6920 2a20   ni + 1) / ni * 
-00021590: 6220 2a2a 2028 6e69 202d 2031 2920 2a20  b ** (ni - 1) * 
-000215a0: 2828 7869 202a 2028 3220 2a20 6e69 202b  ((xi * (2 * ni +
-000215b0: 2031 2920 2a2a 2032 2920 2f20 2864 286e   1) ** 2) / (d(n
-000215c0: 6929 202a 2028 6e69 202b 2031 2929 2920  i) * (ni + 1))) 
-000215d0: 2a0d 0a20 2020 2020 2020 2020 2020 2020  *..             
-000215e0: 2020 2028 6e69 202a 206d 5f72 202a 2070     (ni * m_r * p
-000215f0: 5b30 2c20 6969 2c20 3a5d 202d 206d 5f74  [0, ii, :] - m_t
-00021600: 202a 2070 5b31 2c20 6969 2c20 3a5d 202a   * p[1, ii, :] *
-00021610: 2063 6f73 5f62 6574 6129 290d 0a0d 0a20   cos_beta)).... 
-00021620: 2020 2020 2020 2070 6f74 656e 7469 616c         potential
-00021630: 202f 3d20 3420 2a20 6e70 2e70 6920 2a20   /= 4 * np.pi * 
-00021640: 7365 6c66 2e70 5b22 636f 6e64 5f62 7261  self.p["cond_bra
-00021650: 696e 5f73 6361 6c70 225d 202a 2072 202a  in_scalp"] * r *
-00021660: 2a20 320d 0a0d 0a20 2020 2020 2020 2070  * 2....        p
-00021670: 6f74 656e 7469 616c 203d 2070 6f74 656e  otential = poten
-00021680: 7469 616c 5b6e 702e 6e65 7761 7869 732c  tial[np.newaxis,
-00021690: 203a 5d0d 0a0d 0a20 2020 2020 2020 2072   :]....        r
-000216a0: 6574 7572 6e20 706f 7465 6e74 6961 6c0d  eturn potential.
-000216b0: 0a0d 0a0d 0a63 6c61 7373 2045 6c65 6374  .....class Elect
-000216c0: 726f 6465 4d6f 6465 6c28 4162 7374 7261  rodeModel(Abstra
-000216d0: 6374 4d6f 6465 6c29 3a0d 0a20 2020 2022  ctModel):..    "
-000216e0: 2222 0d0a 2020 2020 4d6f 6469 6669 6564  ""..    Modified
-000216f0: 2076 6572 7369 6f6e 206f 6620 5261 6e64   version of Rand
-00021700: 6c65 7320 6369 7263 7569 742e 0d0a 2020  les circuit...  
-00021710: 2020 5468 6973 2063 6972 6375 6974 2069    This circuit i
-00021720: 7320 7573 6564 2074 6f20 6d6f 6465 6c20  s used to model 
-00021730: 7468 6520 696d 7065 6461 6e63 6520 6f66  the impedance of
-00021740: 2061 6e20 696e 6572 7420 656c 6563 7472   an inert electr
-00021750: 6f64 6520 696e 2061 6e20 656c 6563 7472  ode in an electr
-00021760: 6f6c 7974 6520 7769 7468 2061 2066 696e  olyte with a fin
-00021770: 6974 6520 5761 7262 7572 6720 6c61 7965  ite Warburg laye
-00021780: 722e 0d0a 2020 2020 4369 7263 7569 743a  r...    Circuit:
-00021790: 202d 5273 2d28 5128 5263 742d 2857 5277   -Rs-(Q(Rct-(WRw
-000217a0: 2929 292d 0d0a 0d0a 2020 2020 5061 7261  )))-....    Para
-000217b0: 6d65 7465 7273 0d0a 2020 2020 2d2d 2d2d  meters..    ----
-000217c0: 2d2d 2d2d 2d2d 0d0a 2020 2020 705b 226e  ------..    p["n
-000217d0: 5f51 646c 225d 3a20 666c 6f61 7420 6f72  _Qdl"]: float or
-000217e0: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-000217f0: 7420 5b6e 5f67 7269 645d 0d0a 2020 2020  t [n_grid]..    
-00021800: 2020 2020 4669 7273 7420 7061 7261 6d65      First parame
-00021810: 7465 7220 6465 6669 6e65 6420 696e 205b  ter defined in [
-00021820: 302c 2049 6e66 5d0d 0a20 2020 2070 5b22  0, Inf]..    p["
-00021830: 5164 6c22 5d3a 2066 6c6f 6174 206f 7220  Qdl"]: float or 
-00021840: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-00021850: 205b 6e5f 6772 6964 5d0d 0a20 2020 2020   [n_grid]..     
-00021860: 2020 2053 6563 6f6e 6420 7061 7261 6d65     Second parame
-00021870: 7465 7220 6465 6669 6e65 6420 696e 205b  ter defined in [
-00021880: 302c 2031 5d0d 0a20 2020 2070 5b22 6e5f  0, 1]..    p["n_
-00021890: 5164 225d 3a20 666c 6f61 7420 6f72 206e  Qd"]: float or n
-000218a0: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
-000218b0: 5b6e 5f67 7269 645d 0d0a 2020 2020 2020  [n_grid]..      
-000218c0: 2020 5468 6972 6420 7061 7261 6d65 7465    Third paramete
-000218d0: 7220 6465 6669 6e65 6420 696e 205b 302c  r defined in [0,
-000218e0: 2049 6e66 5d0d 0a20 2020 2070 5b22 5164   Inf]..    p["Qd
-000218f0: 225d 3a20 666c 6f61 7420 6f72 206e 6461  "]: float or nda
-00021900: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
-00021910: 5f67 7269 645d 0d0a 2020 2020 2020 2020  _grid]..        
-00021920: 466f 7572 7468 2070 6172 616d 6574 6572  Fourth parameter
-00021930: 2064 6566 696e 6564 2069 6e20 5b30 2c20   defined in [0, 
-00021940: 315d 0d0a 2020 2020 705b 2252 7322 5d3a  1]..    p["Rs"]:
-00021950: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
-00021960: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
-00021970: 6964 5d0d 0a20 2020 2020 2020 2046 6966  id]..        Fif
-00021980: 7468 2070 6172 616d 6574 6572 2064 6566  th parameter def
-00021990: 696e 6564 2069 6e20 5b30 2c20 496e 665d  ined in [0, Inf]
-000219a0: 0d0a 2020 2020 705b 2252 6374 225d 3a20  ..    p["Rct"]: 
-000219b0: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
-000219c0: 206f 6620 666c 6f61 7420 5b6e 5f67 7269   of float [n_gri
-000219d0: 645d 0d0a 2020 2020 2020 2020 5369 7874  d]..        Sixt
-000219e0: 6820 7061 7261 6d65 7465 7220 6465 6669  h parameter defi
-000219f0: 6e65 6420 696e 205b 302c 2049 6e66 5d0d  ned in [0, Inf].
-00021a00: 0a20 2020 2070 5b22 5264 225d 3a20 666c  .    p["Rd"]: fl
-00021a10: 6f61 7420 6f72 206e 6461 7272 6179 206f  oat or ndarray o
-00021a20: 6620 666c 6f61 7420 5b6e 5f67 7269 645d  f float [n_grid]
-00021a30: 0d0a 2020 2020 2020 2020 5365 7665 6e74  ..        Sevent
-00021a40: 6820 7061 7261 6d65 7465 7220 6465 6669  h parameter defi
-00021a50: 6e65 6420 696e 205b 302c 2049 6e66 5d0d  ned in [0, Inf].
-00021a60: 0a20 2020 2070 5b22 7722 5d3a 2066 6c6f  .    p["w"]: flo
-00021a70: 6174 206f 7220 6e64 6172 7261 7920 6f66  at or ndarray of
-00021a80: 2066 6c6f 6174 205b 6e5f 775d 0d0a 2020   float [n_w]..  
-00021a90: 2020 2020 2020 2046 7265 7175 656e 6379         Frequency
-00021aa0: 2076 6172 6961 626c 6520 6465 6669 6e65   variable define
-00021ab0: 6420 696e 205b 302c 2049 6e66 5d0d 0a0d  d in [0, Inf]...
-00021ac0: 0a0d 0a20 2020 2052 6574 7572 6e73 0d0a  ...    Returns..
-00021ad0: 2020 2020 2d2d 2d2d 2d2d 2d0d 0a20 2020      -------..   
-00021ae0: 205a 3a20 6e64 6172 7261 7920 6f66 2066   Z: ndarray of f
-00021af0: 6c6f 6174 205b 6e5f 6772 6964 2078 2031  loat [n_grid x 1
-00021b00: 5d0d 0a20 2020 2020 2020 204f 7574 7075  ]..        Outpu
-00021b10: 740d 0a20 2020 2022 2222 0d0a 0d0a 2020  t..    """....  
-00021b20: 2020 6465 6620 5f5f 696e 6974 5f5f 2873    def __init__(s
-00021b30: 656c 662c 206d 6174 6c61 625f 6d6f 6465  elf, matlab_mode
-00021b40: 6c3d 4661 6c73 6529 3a0d 0a20 2020 2020  l=False):..     
-00021b50: 2020 2073 7570 6572 2874 7970 6528 7365     super(type(se
-00021b60: 6c66 292c 2073 656c 6629 2e5f 5f69 6e69  lf), self).__ini
-00021b70: 745f 5f28 6d61 746c 6162 5f6d 6f64 656c  t__(matlab_model
-00021b80: 3d6d 6174 6c61 625f 6d6f 6465 6c29 0d0a  =matlab_model)..
-00021b90: 2020 2020 2020 2020 7365 6c66 2e66 6e61          self.fna
-00021ba0: 6d65 203d 2069 6e73 7065 6374 2e67 6574  me = inspect.get
-00021bb0: 6669 6c65 2869 6e73 7065 6374 2e63 7572  file(inspect.cur
-00021bc0: 7265 6e74 6672 616d 6528 2929 0d0a 0d0a  rentframe())....
-00021bd0: 2020 2020 6465 6620 7661 6c69 6461 7465      def validate
-00021be0: 2873 656c 6629 3a0d 0a20 2020 2020 2020  (self):..       
-00021bf0: 2070 6173 730d 0a0d 0a20 2020 2064 6566   pass....    def
-00021c00: 2073 696d 756c 6174 6528 7365 6c66 2c20   simulate(self, 
-00021c10: 7072 6f63 6573 735f 6964 3d4e 6f6e 652c  process_id=None,
-00021c20: 206d 6174 6c61 625f 656e 6769 6e65 3d4e   matlab_engine=N
-00021c30: 6f6e 6529 3a0d 0a0d 0a20 2020 2020 2020  one):....       
-00021c40: 2023 205a 203d 2073 656c 662e 705b 2252   # Z = self.p["R
-00021c50: 7322 5d20 2b20 3120 2f20 2831 202f 2028  s"] + 1 / (1 / (
-00021c60: 3120 2f20 2873 656c 662e 705b 2251 646c  1 / (self.p["Qdl
-00021c70: 225d 202a 2028 7365 6c66 2e70 5b22 7722  "] * (self.p["w"
-00021c80: 5d2e 5420 2a20 316a 2920 2a2a 2073 656c  ].T * 1j) ** sel
-00021c90: 662e 705b 226e 5f51 646c 225d 2929 202b  f.p["n_Qdl"])) +
-00021ca0: 0d0a 2020 2020 2020 2020 2320 2020 2020  ..        #     
-00021cb0: 2020 2020 2020 3120 2f20 2873 656c 662e        1 / (self.
-00021cc0: 705b 2252 6374 225d 202b 2031 202f 2028  p["Rct"] + 1 / (
-00021cd0: 3120 2f20 2831 202f 2028 7365 6c66 2e70  1 / (1 / (self.p
-00021ce0: 5b22 5164 225d 202a 2028 7365 6c66 2e70  ["Qd"] * (self.p
-00021cf0: 5b22 7722 5d2e 5420 2a20 316a 2920 2a2a  ["w"].T * 1j) **
-00021d00: 2073 656c 662e 705b 226e 5f51 6422 5d29   self.p["n_Qd"])
-00021d10: 290d 0a20 2020 2020 2020 2023 2020 2020  )..        #    
-00021d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00021d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00021d40: 202b 2031 202f 2073 656c 662e 705b 2252   + 1 / self.p["R
-00021d50: 6422 5d29 2929 0d0a 0d0a 2020 2020 2020  d"])))....      
-00021d60: 2020 5a20 3d20 7365 6c66 2e70 5b22 5273    Z = self.p["Rs
-00021d70: 225d 202b 205c 0d0a 2020 2020 2020 2020  "] + \..        
-00021d80: 2020 2020 2828 7365 6c66 2e70 5b22 5263      ((self.p["Rc
-00021d90: 7422 5d20 2b20 2873 656c 662e 705b 2252  t"] + (self.p["R
-00021da0: 6422 5d2a 312f 2873 656c 662e 705b 2251  d"]*1/(self.p["Q
-00021db0: 6422 5d2a 2831 6a2a 7365 6c66 2e70 5b22  d"]*(1j*self.p["
-00021dc0: 7722 5d2e 5429 2a2a 2873 656c 662e 705b  w"].T)**(self.p[
-00021dd0: 226e 5f51 6422 5d29 2929 2f28 7365 6c66  "n_Qd"])))/(self
-00021de0: 2e70 5b22 5264 225d 2b31 2f28 7365 6c66  .p["Rd"]+1/(self
-00021df0: 2e70 5b22 5164 225d 2a28 316a 2a73 656c  .p["Qd"]*(1j*sel
-00021e00: 662e 705b 2277 225d 2e54 292a 2a28 7365  f.p["w"].T)**(se
-00021e10: 6c66 2e70 5b22 6e5f 5164 225d 2929 2929  lf.p["n_Qd"]))))
-00021e20: 2a31 2f28 7365 6c66 2e70 5b22 5164 6c22  *1/(self.p["Qdl"
-00021e30: 5d2a 2831 6a2a 7365 6c66 2e70 5b22 7722  ]*(1j*self.p["w"
-00021e40: 5d2e 5429 2a2a 2873 656c 662e 705b 226e  ].T)**(self.p["n
-00021e50: 5f51 646c 225d 2929 292f 5c0d 0a20 2020  _Qdl"])))/\..   
-00021e60: 2020 2020 2020 2020 2028 7365 6c66 2e70           (self.p
-00021e70: 5b22 5263 7422 5d20 2b20 2873 656c 662e  ["Rct"] + (self.
-00021e80: 705b 2252 6422 5d2a 312f 2873 656c 662e  p["Rd"]*1/(self.
-00021e90: 705b 2251 6422 5d2a 2831 6a2a 7365 6c66  p["Qd"]*(1j*self
-00021ea0: 2e70 5b22 7722 5d2e 5429 2a2a 2873 656c  .p["w"].T)**(sel
-00021eb0: 662e 705b 226e 5f51 6422 5d29 292f 2873  f.p["n_Qd"]))/(s
-00021ec0: 656c 662e 705b 2252 6422 5d2b 312f 2873  elf.p["Rd"]+1/(s
-00021ed0: 656c 662e 705b 2251 6422 5d2a 2831 6a2a  elf.p["Qd"]*(1j*
-00021ee0: 7365 6c66 2e70 5b22 7722 5d2e 5429 2a2a  self.p["w"].T)**
-00021ef0: 2873 656c 662e 705b 226e 5f51 6422 5d29  (self.p["n_Qd"])
-00021f00: 2929 202b 2031 2f28 7365 6c66 2e70 5b22  )) + 1/(self.p["
-00021f10: 5164 6c22 5d2a 2831 6a2a 7365 6c66 2e70  Qdl"]*(1j*self.p
-00021f20: 5b22 7722 5d2e 5429 2a2a 2873 656c 662e  ["w"].T)**(self.
-00021f30: 705b 226e 5f51 646c 225d 2929 2929 0d0a  p["n_Qdl"]))))..
-00021f40: 2020 2020 2020 2020 5a20 3d20 6e70 2e63          Z = np.c
-00021f50: 6f6e 6361 7465 6e61 7465 2828 6e70 2e72  oncatenate((np.r
-00021f60: 6561 6c28 5a2e 5429 2c20 6e70 2e69 6d61  eal(Z.T), np.ima
-00021f70: 6728 5a2e 5429 292c 2061 7869 733d 3129  g(Z.T)), axis=1)
-00021f80: 0d0a 0d0a 2020 2020 2020 2020 7265 7475  ....        retu
-00021f90: 726e 205a 0d0a 0d0a 0d0a 636c 6173 7320  rn Z......class 
-00021fa0: 4c6f 7265 6e7a 5f53 7973 7465 6d28 4162  Lorenz_System(Ab
-00021fb0: 7374 7261 6374 4d6f 6465 6c29 3a0d 0a20  stractModel):.. 
-00021fc0: 2020 2022 2222 0d0a 2020 2020 4d6f 6465     """..    Mode
-00021fd0: 6c20 666f 7220 7468 6520 4c6f 7265 6e7a  l for the Lorenz
-00021fe0: 2053 7973 7465 6d20 6f66 2064 6966 6665   System of diffe
-00021ff0: 7265 6e74 6961 6c20 6571 7561 7469 6f6e  rential equation
-00022000: 732e 2049 7420 6973 206e 6f6e 6c69 6e65  s. It is nonline
-00022010: 6172 2061 6e64 2073 686f 7773 2063 6861  ar and shows cha
-00022020: 6f74 6963 2062 6568 6176 696f 7572 2073  otic behaviour s
-00022030: 7065 6369 6669 6361 6c6c 7920 666f 720d  pecifically for.
-00022040: 0a20 2020 2074 6865 2074 6872 6565 2070  .    the three p
-00022050: 6172 616d 6574 6572 2076 616c 7565 7320  arameter values 
-00022060: 7369 676d 6120 3d20 3130 2e30 2c20 6265  sigma = 10.0, be
-00022070: 7461 203d 2032 382e 3020 616e 6420 7268  ta = 28.0 and rh
-00022080: 6f20 3d20 382e 302f 332e 302e 2054 6865  o = 8.0/3.0. The
-00022090: 206c 6f72 656e 7a20 6174 7472 6163 746f   lorenz attracto
-000220a0: 7220 6361 6e20 7468 656e 2062 6520 6f62  r can then be ob
-000220b0: 7365 7276 6564 2069 6e0d 0a20 2020 2061  served in..    a
-000220c0: 6e79 2074 6872 6565 2064 696d 656e 7369  ny three dimensi
-000220d0: 6f6e 616c 2074 7261 6a65 6374 6f72 792e  onal trajectory.
-000220e0: 0d0a 0d0a 2020 2020 5061 7261 6d65 7465  ....    Paramete
-000220f0: 7273 0d0a 2020 2020 2d2d 2d2d 2d2d 2d2d  rs..    --------
-00022100: 2d2d 0d0a 2020 2020 705b 2273 6967 6d61  --..    p["sigma
-00022110: 225d 203a 2066 6c6f 6174 206f 7220 6e64  "] : float or nd
-00022120: 6172 7261 7920 6f66 2066 6c6f 6174 205b  array of float [
-00022130: 6e5f 6772 6964 5d0d 0a20 2020 2020 2020  n_grid]..       
-00022140: 2050 6172 616d 6574 6572 206f 6620 7468   Parameter of th
-00022150: 6520 7379 7374 656d 0d0a 2020 2020 705b  e system..    p[
-00022160: 2262 6574 6122 5d20 3a20 666c 6f61 7420  "beta"] : float 
-00022170: 6f72 206e 6461 7272 6179 206f 6620 666c  or ndarray of fl
-00022180: 6f61 7420 5b6e 5f67 7269 645d 0d0a 2020  oat [n_grid]..  
-00022190: 2020 2020 2020 5061 7261 6d65 7465 7220        Parameter 
-000221a0: 6f66 2074 6865 2073 7973 7465 6d0d 0a20  of the system.. 
-000221b0: 2020 2070 5b22 7268 6f22 5d20 3a20 666c     p["rho"] : fl
-000221c0: 6f61 7420 6f72 206e 6461 7272 6179 206f  oat or ndarray o
-000221d0: 6620 666c 6f61 7420 5b6e 5f67 7269 645d  f float [n_grid]
-000221e0: 0d0a 2020 2020 2020 2020 5061 7261 6d65  ..        Parame
-000221f0: 7465 7220 6f66 2074 6865 2073 7973 7465  ter of the syste
-00022200: 6d0d 0a20 2020 2070 5b22 7931 5f30 225d  m..    p["y1_0"]
-00022210: 203a 2066 6c6f 6174 0d0a 2020 2020 2020   : float..      
-00022220: 2020 696e 6974 6961 6c20 7661 6c75 6520    initial value 
-00022230: 6f66 2066 6972 7374 2076 6172 6961 626c  of first variabl
-00022240: 650d 0a20 2020 2070 5b22 7932 5f30 225d  e..    p["y2_0"]
-00022250: 203a 2066 6c6f 6174 0d0a 2020 2020 2020   : float..      
-00022260: 2020 696e 6974 6961 6c20 7661 6c75 6520    initial value 
-00022270: 6f66 2073 6563 6f6e 6420 7661 7269 6162  of second variab
-00022280: 6c65 0d0a 2020 2020 705b 2279 335f 3022  le..    p["y3_0"
-00022290: 5d20 3a20 666c 6f61 740d 0a20 2020 2020  ] : float..     
-000222a0: 2020 2069 6e69 7469 616c 2076 616c 7565     initial value
-000222b0: 206f 6620 7468 6972 6420 7661 7269 6162   of third variab
-000222c0: 6c65 0d0a 2020 2020 705b 2274 5f65 6e64  le..    p["t_end
-000222d0: 225d 203a 2066 6c6f 6174 0d0a 2020 2020  "] : float..    
-000222e0: 2020 2020 7468 6520 656e 6420 6f66 2074      the end of t
-000222f0: 6865 2074 696d 6573 7061 6e20 666f 7220  he timespan for 
-00022300: 7768 6963 6820 7468 6520 7379 7374 656d  which the system
-00022310: 2077 696c 6c20 6265 2065 7661 6c75 6174   will be evaluat
-00022320: 6564 0d0a 2020 2020 705b 2273 7465 705f  ed..    p["step_
-00022330: 7369 7a65 225d 203a 2066 6c6f 6174 0d0a  size"] : float..
-00022340: 2020 2020 2020 2020 7468 6520 7374 6570          the step
-00022350: 2073 697a 6520 666f 7220 7468 6520 7469   size for the ti
-00022360: 6d65 2069 6e63 7265 6d65 6e74 7320 6475  me increments du
-00022370: 7269 6e67 2077 6869 6368 2074 6865 2073  ring which the s
-00022380: 7973 7465 6d20 7769 6c6c 2062 6520 6576  ystem will be ev
-00022390: 616c 7561 7465 640d 0a0d 0a20 2020 2052  aluated....    R
-000223a0: 6574 7572 6e73 0d0a 2020 2020 2d2d 2d2d  eturns..    ----
-000223b0: 2d2d 2d0d 0a20 2020 2078 203a 206e 6461  ---..    x : nda
-000223c0: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
-000223d0: 5f67 7269 6420 7820 6e5f 7469 6d65 5f73  _grid x n_time_s
-000223e0: 7465 7073 5d0d 0a20 2020 2020 2020 2052  teps]..        R
-000223f0: 6573 756c 7473 206f 6620 7820 636f 6f72  esults of x coor
-00022400: 6469 6e61 7465 206f 6620 7468 6520 7379  dinate of the sy
-00022410: 7374 656d 2069 6e20 7469 6d65 2073 7465  stem in time ste
-00022420: 7073 2c20 7468 6520 6750 4320 6973 2063  ps, the gPC is c
-00022430: 6f6e 6475 6374 6564 2066 6f72 2074 6865  onducted for the
-00022440: 2074 6872 6565 2070 6172 616d 6574 6572   three parameter
-00022450: 7320 7369 676d 612c 2062 6574 610d 0a20  s sigma, beta.. 
-00022460: 2020 2020 2020 2061 6e64 2072 686f 0d0a         and rho..
-00022470: 2020 2020 2222 220d 0a0d 0a20 2020 2064      """....    d
-00022480: 6566 205f 5f69 6e69 745f 5f28 7365 6c66  ef __init__(self
-00022490: 293a 0d0a 2020 2020 2020 2020 7365 6c66  ):..        self
-000224a0: 2e66 6e61 6d65 203d 2069 6e73 7065 6374  .fname = inspect
-000224b0: 2e67 6574 6669 6c65 2869 6e73 7065 6374  .getfile(inspect
-000224c0: 2e63 7572 7265 6e74 6672 616d 6528 2929  .currentframe())
-000224d0: 0d0a 0d0a 2020 2020 6465 6620 7661 6c69  ....    def vali
-000224e0: 6461 7465 2873 656c 6629 3a0d 0a20 2020  date(self):..   
-000224f0: 2020 2020 2070 6173 730d 0a0d 0a20 2020       pass....   
-00022500: 2064 6566 2073 696d 756c 6174 6528 7365   def simulate(se
-00022510: 6c66 2c20 7072 6f63 6573 735f 6964 3d4e  lf, process_id=N
-00022520: 6f6e 652c 206d 6174 6c61 625f 656e 6769  one, matlab_engi
-00022530: 6e65 3d4e 6f6e 6529 3a0d 0a0d 0a20 2020  ne=None):....   
-00022540: 2020 2020 2064 6566 206c 6f72 656e 7a28       def lorenz(
-00022550: 742c 2073 7461 7465 2c20 7369 676d 612c  t, state, sigma,
-00022560: 2062 6574 612c 2072 686f 293a 0d0a 2020   beta, rho):..  
-00022570: 2020 2020 2020 2020 2020 782c 2079 2c20            x, y, 
-00022580: 7a20 3d20 7374 6174 650d 0a20 2020 2020  z = state..     
-00022590: 2020 2020 2020 2064 7820 3d20 7369 676d         dx = sigm
-000225a0: 6120 2a20 2879 202d 2078 290d 0a20 2020  a * (y - x)..   
-000225b0: 2020 2020 2020 2020 2064 7920 3d20 7820           dy = x 
-000225c0: 2a20 2872 686f 202d 207a 2920 2d20 790d  * (rho - z) - y.
-000225d0: 0a20 2020 2020 2020 2020 2020 2064 7a20  .            dz 
-000225e0: 3d20 7820 2a20 7920 2d20 6265 7461 202a  = x * y - beta *
-000225f0: 207a 0d0a 0d0a 2020 2020 2020 2020 2020   z....          
-00022600: 2020 7265 7475 726e 205b 6478 2c20 6479    return [dx, dy
-00022610: 2c20 647a 5d0d 0a0d 0a20 2020 2020 2020  , dz]....       
-00022620: 2078 5f6f 7574 5f73 6861 7065 203d 2073   x_out_shape = s
-00022630: 656c 662e 705b 2273 6967 6d61 225d 2e73  elf.p["sigma"].s
-00022640: 6861 7065 5b30 5d0d 0a20 2020 2020 2020  hape[0]..       
-00022650: 2074 5f73 7061 6e20 3d20 2830 2e30 2c20   t_span = (0.0, 
-00022660: 7365 6c66 2e70 5b22 745f 656e 6422 5d29  self.p["t_end"])
-00022670: 0d0a 2020 2020 2020 2020 7420 3d20 6e70  ..        t = np
-00022680: 2e61 7261 6e67 6528 302e 302c 2073 656c  .arange(0.0, sel
-00022690: 662e 705b 2274 5f65 6e64 225d 5b30 5d2c  f.p["t_end"][0],
-000226a0: 2073 656c 662e 705b 2273 7465 705f 7369   self.p["step_si
-000226b0: 7a65 225d 5b30 5d29 0d0a 2020 2020 2020  ze"][0])..      
-000226c0: 2020 736f 6c73 203d 206e 702e 7a65 726f    sols = np.zero
-000226d0: 7328 2878 5f6f 7574 5f73 6861 7065 2c20  s((x_out_shape, 
-000226e0: 742e 7368 6170 655b 305d 2929 0d0a 2020  t.shape[0]))..  
-000226f0: 2020 2020 2020 666f 7220 6920 696e 2072        for i in r
-00022700: 616e 6765 2878 5f6f 7574 5f73 6861 7065  ange(x_out_shape
-00022710: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
-00022720: 7020 3d20 2873 656c 662e 705b 2273 6967  p = (self.p["sig
-00022730: 6d61 225d 5b69 5d2c 2073 656c 662e 705b  ma"][i], self.p[
-00022740: 2262 6574 6122 5d5b 695d 2c20 7365 6c66  "beta"][i], self
-00022750: 2e70 5b22 7268 6f22 5d5b 695d 290d 0a20  .p["rho"][i]).. 
-00022760: 2020 2020 2020 2020 2020 2079 3020 3d20             y0 = 
-00022770: 5b73 656c 662e 705b 2278 5f30 225d 5b69  [self.p["x_0"][i
-00022780: 5d2c 2073 656c 662e 705b 2279 5f30 225d  ], self.p["y_0"]
-00022790: 5b69 5d2c 2073 656c 662e 705b 227a 5f30  [i], self.p["z_0
-000227a0: 225d 5b69 5d5d 0d0a 2020 2020 2020 2020  "][i]]..        
-000227b0: 2020 2020 2320 6f6e 6c79 2073 6176 6520      # only save 
-000227c0: 782d 636f 6f72 6469 6e61 7465 2028 696e  x-coordinate (in
-000227d0: 6465 7820 3029 0d0a 2020 2020 2020 2020  dex 0)..        
-000227e0: 2020 2020 736f 6c73 5b69 2c20 3a5d 203d      sols[i, :] =
-000227f0: 206f 6465 696e 7428 6c6f 7265 6e7a 2c20   odeint(lorenz, 
-00022800: 7930 2c20 742c 2070 2c20 7466 6972 7374  y0, t, p, tfirst
-00022810: 3d54 7275 6529 5b3a 2c20 305d 0d0a 2020  =True)[:, 0]..  
-00022820: 2020 2020 2020 785f 6f75 7420 3d20 736f        x_out = so
-00022830: 6c73 0d0a 0d0a 2020 2020 2020 2020 7265  ls....        re
-00022840: 7475 726e 2078 5f6f 7574 0d0a 0d0a 636c  turn x_out....cl
-00022850: 6173 7320 4c6f 7265 6e7a 5f53 7973 7465  ass Lorenz_Syste
-00022860: 6d5f 6a75 6c69 6128 4162 7374 7261 6374  m_julia(Abstract
-00022870: 4d6f 6465 6c29 3a0d 0a20 2020 2022 2222  Model):..    """
-00022880: 0d0a 2020 2020 4d6f 6465 6c20 666f 7220  ..    Model for 
-00022890: 7468 6520 4c6f 7265 6e7a 2053 7973 7465  the Lorenz Syste
-000228a0: 6d20 6f66 2064 6966 6665 7265 6e74 6961  m of differentia
-000228b0: 6c20 6571 7561 7469 6f6e 7320 696e 206a  l equations in j
-000228c0: 756c 6961 2e20 4974 2069 7320 6e6f 6e6c  ulia. It is nonl
-000228d0: 696e 6561 7220 616e 6420 7368 6f77 7320  inear and shows 
-000228e0: 6368 616f 7469 6320 6265 6861 7669 6f75  chaotic behaviou
-000228f0: 720d 0a20 2020 2073 7065 6369 6669 6361  r..    specifica
-00022900: 6c6c 7920 666f 7220 7468 6520 7468 7265  lly for the thre
-00022910: 6520 7061 7261 6d65 7465 7220 7661 6c75  e parameter valu
-00022920: 6573 2073 6967 6d61 203d 2031 302e 302c  es sigma = 10.0,
-00022930: 2062 6574 6120 3d20 3238 2e30 2061 6e64   beta = 28.0 and
-00022940: 2072 686f 203d 2038 2e30 2f33 2e30 2e20   rho = 8.0/3.0. 
-00022950: 5468 6520 6c6f 7265 6e7a 2061 7474 7261  The lorenz attra
-00022960: 6374 6f72 2063 616e 0d0a 2020 2020 7468  ctor can..    th
-00022970: 656e 2062 6520 6f62 7365 7276 6564 2069  en be observed i
-00022980: 6e20 616e 7920 7468 7265 6520 6469 6d65  n any three dime
-00022990: 6e73 696f 6e61 6c20 7472 616a 6563 746f  nsional trajecto
-000229a0: 7279 2e0d 0a0d 0a20 2020 2050 6172 616d  ry.....    Param
-000229b0: 6574 6572 730d 0a20 2020 202d 2d2d 2d2d  eters..    -----
-000229c0: 2d2d 2d2d 2d0d 0a20 2020 2070 5b22 7369  -----..    p["si
-000229d0: 676d 6122 5d20 3a20 666c 6f61 7420 6f72  gma"] : float or
-000229e0: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
-000229f0: 7420 5b6e 5f67 7269 645d 0d0a 2020 2020  t [n_grid]..    
-00022a00: 2020 2020 5061 7261 6d65 7465 7220 6f66      Parameter of
-00022a10: 2074 6865 2073 7973 7465 6d0d 0a20 2020   the system..   
-00022a20: 2070 5b22 6265 7461 225d 203a 2066 6c6f   p["beta"] : flo
-00022a30: 6174 206f 7220 6e64 6172 7261 7920 6f66  at or ndarray of
-00022a40: 2066 6c6f 6174 205b 6e5f 6772 6964 5d0d   float [n_grid].
-00022a50: 0a20 2020 2020 2020 2050 6172 616d 6574  .        Paramet
-00022a60: 6572 206f 6620 7468 6520 7379 7374 656d  er of the system
-00022a70: 0d0a 2020 2020 705b 2272 686f 225d 203a  ..    p["rho"] :
-00022a80: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
-00022a90: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
-00022aa0: 6964 5d0d 0a20 2020 2020 2020 2050 6172  id]..        Par
-00022ab0: 616d 6574 6572 206f 6620 7468 6520 7379  ameter of the sy
-00022ac0: 7374 656d 0d0a 2020 2020 705b 2279 315f  stem..    p["y1_
-00022ad0: 3022 5d20 3a20 666c 6f61 740d 0a20 2020  0"] : float..   
-00022ae0: 2020 2020 2069 6e69 7469 616c 2076 616c       initial val
-00022af0: 7565 206f 6620 6669 7273 7420 7661 7269  ue of first vari
-00022b00: 6162 6c65 0d0a 2020 2020 705b 2279 325f  able..    p["y2_
-00022b10: 3022 5d20 3a20 666c 6f61 740d 0a20 2020  0"] : float..   
-00022b20: 2020 2020 2069 6e69 7469 616c 2076 616c       initial val
-00022b30: 7565 206f 6620 7365 636f 6e64 2076 6172  ue of second var
-00022b40: 6961 626c 650d 0a20 2020 2070 5b22 7933  iable..    p["y3
-00022b50: 5f30 225d 203a 2066 6c6f 6174 0d0a 2020  _0"] : float..  
-00022b60: 2020 2020 2020 696e 6974 6961 6c20 7661        initial va
-00022b70: 6c75 6520 6f66 2074 6869 7264 2076 6172  lue of third var
-00022b80: 6961 626c 650d 0a20 2020 2070 5b22 745f  iable..    p["t_
-00022b90: 656e 6422 5d20 3a20 666c 6f61 740d 0a20  end"] : float.. 
-00022ba0: 2020 2020 2020 2074 6865 2065 6e64 206f         the end o
-00022bb0: 6620 7468 6520 7469 6d65 7370 616e 2066  f the timespan f
-00022bc0: 6f72 2077 6869 6368 2074 6865 2073 7973  or which the sys
-00022bd0: 7465 6d20 7769 6c6c 2062 6520 6576 616c  tem will be eval
-00022be0: 7561 7465 640d 0a20 2020 2070 5b22 7374  uated..    p["st
-00022bf0: 6570 5f73 697a 6522 5d20 3a20 666c 6f61  ep_size"] : floa
-00022c00: 740d 0a20 2020 2020 2020 2074 6865 2073  t..        the s
-00022c10: 7465 7020 7369 7a65 2066 6f72 2074 6865  tep size for the
-00022c20: 2074 696d 6520 696e 6372 656d 656e 7473   time increments
-00022c30: 2064 7572 696e 6720 7768 6963 6820 7468   during which th
-00022c40: 6520 7379 7374 656d 2077 696c 6c20 6265  e system will be
-00022c50: 2065 7661 6c75 6174 6564 0d0a 0d0a 2020   evaluated....  
-00022c60: 2020 5265 7475 726e 730d 0a20 2020 202d    Returns..    -
-00022c70: 2d2d 2d2d 2d2d 0d0a 2020 2020 7820 3a20  ------..    x : 
-00022c80: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
-00022c90: 205b 6e5f 6772 6964 2078 206e 5f74 696d   [n_grid x n_tim
-00022ca0: 655f 7374 6570 735d 0d0a 2020 2020 2020  e_steps]..      
-00022cb0: 2020 5265 7375 6c74 7320 6f66 2078 2063    Results of x c
-00022cc0: 6f6f 7264 696e 6174 6520 6f66 2074 6865  oordinate of the
-00022cd0: 2073 7973 7465 6d20 696e 2074 696d 6520   system in time 
-00022ce0: 7374 6570 732c 2074 6865 2067 5043 2069  steps, the gPC i
-00022cf0: 7320 636f 6e64 7563 7465 6420 666f 7220  s conducted for 
-00022d00: 7468 6520 7468 7265 6520 7061 7261 6d65  the three parame
-00022d10: 7465 7273 2073 6967 6d61 2c20 6265 7461  ters sigma, beta
-00022d20: 0d0a 2020 2020 2020 2020 616e 6420 7268  ..        and rh
-00022d30: 6f0d 0a20 2020 2022 2222 0d0a 0d0a 2020  o..    """....  
-00022d40: 2020 6465 6620 5f5f 696e 6974 5f5f 2873    def __init__(s
-00022d50: 656c 662c 2066 6e61 6d65 5f6a 756c 6961  elf, fname_julia
-00022d60: 3d4e 6f6e 6529 3a0d 0a20 2020 2020 2020  =None):..       
-00022d70: 2069 6620 666e 616d 655f 6a75 6c69 6120   if fname_julia 
-00022d80: 6973 206e 6f74 204e 6f6e 653a 0d0a 2020  is not None:..  
-00022d90: 2020 2020 2020 2020 2020 7365 6c66 2e66            self.f
-00022da0: 6e61 6d65 5f6a 756c 6961 203d 2066 6e61  name_julia = fna
-00022db0: 6d65 5f6a 756c 6961 0d0a 2020 2020 2020  me_julia..      
-00022dc0: 2020 7365 6c66 2e66 6e61 6d65 203d 2069    self.fname = i
-00022dd0: 6e73 7065 6374 2e67 6574 6669 6c65 2869  nspect.getfile(i
-00022de0: 6e73 7065 6374 2e63 7572 7265 6e74 6672  nspect.currentfr
-00022df0: 616d 6528 2929 0d0a 0d0a 2020 2020 6465  ame())....    de
-00022e00: 6620 7661 6c69 6461 7465 2873 656c 6629  f validate(self)
-00022e10: 3a0d 0a20 2020 2020 2020 2070 6173 730d  :..        pass.
-00022e20: 0a0d 0a20 2020 2064 6566 2073 696d 756c  ...    def simul
-00022e30: 6174 6528 7365 6c66 2c20 7072 6f63 6573  ate(self, proces
-00022e40: 735f 6964 3d4e 6f6e 652c 206d 6174 6c61  s_id=None, matla
-00022e50: 625f 656e 6769 6e65 3d4e 6f6e 6529 3a0d  b_engine=None):.
-00022e60: 0a0d 0a20 2020 2020 2020 2066 726f 6d20  ...        from 
-00022e70: 6a75 6c69 6120 696d 706f 7274 204d 6169  julia import Mai
-00022e80: 6e0d 0a20 2020 2020 2020 2023 2074 6865  n..        # the
-00022e90: 2070 6163 6b61 6765 2044 6966 6665 7265   package Differe
-00022ea0: 6e74 6961 6c45 7175 6174 696f 6e73 2e6a  ntialEquations.j
-00022eb0: 6c20 6e65 6564 7320 746f 2062 6520 696e  l needs to be in
-00022ec0: 7374 616c 6c65 6420 696e 2074 6865 206a  stalled in the j
-00022ed0: 756c 6961 2065 6e76 6972 6f6e 6d65 6e74  ulia environment
-00022ee0: 0d0a 2020 2020 2020 2020 2320 666f 7220  ..        # for 
-00022ef0: 7468 6973 2065 7861 6d70 6c65 2074 6865  this example the
-00022f00: 2066 6f6c 6465 7220 226a 756c 6961 5f65   folder "julia_e
-00022f10: 6e76 2220 6973 206c 6f63 6174 6564 2069  nv" is located i
-00022f20: 6e20 7468 6520 7361 6d65 2066 6f6c 6465  n the same folde
-00022f30: 7220 6173 2074 6865 206a 756c 6961 2066  r as the julia f
-00022f40: 696c 650d 0a20 2020 2020 2020 2066 6e61  ile..        fna
-00022f50: 6d65 5f66 6f6c 6465 7220 3d20 6f73 2e70  me_folder = os.p
-00022f60: 6174 682e 7370 6c69 7428 7365 6c66 2e66  ath.split(self.f
-00022f70: 6e61 6d65 5f6a 756c 6961 295b 305d 0d0a  name_julia)[0]..
-00022f80: 2020 2020 2020 2020 4d61 696e 2e66 6e61          Main.fna
-00022f90: 6d65 5f65 6e76 6972 6f6e 6d65 6e74 203d  me_environment =
-00022fa0: 206f 732e 7061 7468 2e6a 6f69 6e28 666e   os.path.join(fn
-00022fb0: 616d 655f 666f 6c64 6572 2c20 276a 756c  ame_folder, 'jul
-00022fc0: 6961 5f65 6e76 2729 0d0a 2020 2020 2020  ia_env')..      
-00022fd0: 2020 4d61 696e 2e65 7661 6c28 2769 6d70    Main.eval('imp
-00022fe0: 6f72 7420 506b 673b 2050 6b67 2e61 6374  ort Pkg; Pkg.act
-00022ff0: 6976 6174 6528 666e 616d 655f 656e 7669  ivate(fname_envi
-00023000: 726f 6e6d 656e 7429 2729 0d0a 0d0a 2020  ronment)')....  
-00023010: 2020 2020 2020 2320 6163 6365 7373 202e        # access .
-00023020: 6a6c 2066 696c 650d 0a20 2020 2020 2020  jl file..       
-00023030: 204d 6169 6e2e 666e 616d 655f 6a75 6c69   Main.fname_juli
-00023040: 6120 3d20 7365 6c66 2e66 6e61 6d65 5f6a  a = self.fname_j
-00023050: 756c 6961 0d0a 2020 2020 2020 2020 4d61  ulia..        Ma
-00023060: 696e 2e69 6e63 6c75 6465 284d 6169 6e2e  in.include(Main.
-00023070: 666e 616d 655f 6a75 6c69 6129 0d0a 0d0a  fname_julia)....
-00023080: 2020 2020 2020 2020 785f 6f75 745f 7368          x_out_sh
-00023090: 6170 6520 3d20 7365 6c66 2e70 5b22 7369  ape = self.p["si
-000230a0: 676d 6122 5d2e 7368 6170 655b 305d 0d0a  gma"].shape[0]..
-000230b0: 2020 2020 2020 2020 745f 7370 616e 203d          t_span =
-000230c0: 2028 302e 302c 2073 656c 662e 705b 2274   (0.0, self.p["t
-000230d0: 5f65 6e64 225d 5b30 5d29 0d0a 2020 2020  _end"][0])..    
-000230e0: 2020 2020 7420 3d20 6e70 2e61 7261 6e67      t = np.arang
-000230f0: 6528 302e 302c 2073 656c 662e 705b 2274  e(0.0, self.p["t
-00023100: 5f65 6e64 225d 5b30 5d2c 2073 656c 662e  _end"][0], self.
-00023110: 705b 2273 7465 705f 7369 7a65 225d 5b30  p["step_size"][0
-00023120: 5d29 0d0a 2020 2020 2020 2020 736f 6c73  ])..        sols
-00023130: 203d 206e 702e 7a65 726f 7328 2878 5f6f   = np.zeros((x_o
-00023140: 7574 5f73 6861 7065 2c20 742e 7368 6170  ut_shape, t.shap
-00023150: 655b 305d 2929 0d0a 2020 2020 2020 2020  e[0]))..        
-00023160: 666f 7220 6920 696e 2072 616e 6765 2878  for i in range(x
-00023170: 5f6f 7574 5f73 6861 7065 293a 0d0a 2020  _out_shape):..  
-00023180: 2020 2020 2020 2020 2020 7020 3d20 5b73            p = [s
-00023190: 656c 662e 705b 2273 6967 6d61 225d 5b69  elf.p["sigma"][i
-000231a0: 5d2c 2073 656c 662e 705b 2262 6574 6122  ], self.p["beta"
-000231b0: 5d5b 695d 2c20 7365 6c66 2e70 5b22 7268  ][i], self.p["rh
-000231c0: 6f22 5d5b 695d 5d0d 0a20 2020 2020 2020  o"][i]]..       
-000231d0: 2020 2020 2079 3020 3d20 5b73 656c 662e       y0 = [self.
-000231e0: 705b 2279 315f 3022 5d5b 695d 2c20 7365  p["y1_0"][i], se
-000231f0: 6c66 2e70 5b22 7932 5f30 225d 5b69 5d2c  lf.p["y2_0"][i],
-00023200: 2073 656c 662e 705b 2279 335f 3022 5d5b   self.p["y3_0"][
-00023210: 695d 5d0d 0a20 2020 2020 2020 2020 2020  i]]..           
-00023220: 2023 206f 6e6c 7920 7361 7665 2078 2d63   # only save x-c
-00023230: 6f6f 7264 696e 6174 6520 2869 6e64 6578  oordinate (index
-00023240: 2030 290d 0a20 2020 2020 2020 2020 2020   0)..           
-00023250: 2073 6f6c 735b 692c 203a 5d20 3d20 4d61   sols[i, :] = Ma
-00023260: 696e 2e4a 756c 6961 5f4c 6f72 656e 7a28  in.Julia_Lorenz(
-00023270: 702c 2079 302c 2074 295b 305d 0d0a 2020  p, y0, t)[0]..  
-00023280: 2020 2020 2020 785f 6f75 7420 3d20 736f        x_out = so
-00023290: 6c73 0d0a 0d0a 2020 2020 2020 2020 7265  ls....        re
-000232a0: 7475 726e 2078 5f6f 7574 0d0a            turn x_out..
+0001d3d0: 2020 2020 2020 2020 2020 2020 2020 7528                u(
+0001d3e0: 6e69 2920 2a20 2870 5f72 5b73 6b75 6c6c  ni) * (p_r[skull
+0001d3f0: 5f72 6567 696f 6e2c 2030 5d20 2a20 7261  _region, 0] * ra
+0001d400: 6469 7573 5f73 6b69 6e29 202a 2a20 282d  dius_skin) ** (-
+0001d410: 6e69 202d 2031 2929 0a0a 2020 2020 2020  ni - 1))..      
+0001d420: 2020 2020 2020 636f 6566 6669 6369 656e        coefficien
+0001d430: 7473 5b69 692c 2073 6b69 6e5f 7265 6769  ts[ii, skin_regi
+0001d440: 6f6e 5d20 3d20 6e70 2e6e 616e 5f74 6f5f  on] = np.nan_to_
+0001d450: 6e75 6d28 7428 6e69 2920 2a20 2870 5f72  num(t(ni) * (p_r
+0001d460: 5b73 6b69 6e5f 7265 6769 6f6e 2c20 305d  [skin_region, 0]
+0001d470: 202f 2072 6164 6975 735f 736b 696e 2920   / radius_skin) 
+0001d480: 2a2a 206e 690a 2020 2020 2020 2020 2020  ** ni.          
+0001d490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d4a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d4b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d4c0: 2b20 7728 6e69 2920 2a20 2870 5f72 5b73  + w(ni) * (p_r[s
+0001d4d0: 6b69 6e5f 7265 6769 6f6e 2c20 305d 202a  kin_region, 0] *
+0001d4e0: 2072 6164 6975 735f 736b 696e 2920 2a2a   radius_skin) **
+0001d4f0: 2028 2d6e 6920 2d20 3129 290a 0a20 2020   (-ni - 1))..   
+0001d500: 2020 2020 2070 6f74 656e 7469 616c 735b       potentials[
+0001d510: 696e 7369 6465 5f73 7068 6572 655d 203d  inside_sphere] =
+0001d520: 206e 702e 6e61 6e5f 746f 5f6e 756d 280a   np.nan_to_num(.
+0001d530: 2020 2020 2020 2020 2020 2020 6e70 2e70              np.p
+0001d540: 6f6c 796e 6f6d 6961 6c2e 6c65 6765 6e64  olynomial.legend
+0001d550: 7265 2e6c 6567 7661 6c28 636f 735f 7468  re.legval(cos_th
+0001d560: 6574 615f 615b 696e 7369 6465 5f73 7068  eta_a[inside_sph
+0001d570: 6572 655d 2c20 636f 6566 6669 6369 656e  ere], coefficien
+0001d580: 7473 5b3a 2c20 696e 7369 6465 5f73 7068  ts[:, inside_sph
+0001d590: 6572 655d 2c20 7465 6e73 6f72 3d46 616c  ere], tensor=Fal
+0001d5a0: 7365 2920 2d0a 2020 2020 2020 2020 2020  se) -.          
+0001d5b0: 2020 6e70 2e70 6f6c 796e 6f6d 6961 6c2e    np.polynomial.
+0001d5c0: 6c65 6765 6e64 7265 2e6c 6567 7661 6c28  legendre.legval(
+0001d5d0: 636f 735f 7468 6574 615f 625b 696e 7369  cos_theta_b[insi
+0001d5e0: 6465 5f73 7068 6572 655d 2c20 636f 6566  de_sphere], coef
+0001d5f0: 6669 6369 656e 7473 5b3a 2c20 696e 7369  ficients[:, insi
+0001d600: 6465 5f73 7068 6572 655d 2c20 7465 6e73  de_sphere], tens
+0001d610: 6f72 3d46 616c 7365 2929 0a0a 2020 2020  or=False))..    
+0001d620: 2020 2020 706f 7465 6e74 6961 6c73 202a      potentials *
+0001d630: 3d20 312e 3020 2f20 2832 202a 206e 702e  = 1.0 / (2 * np.
+0001d640: 7069 202a 2073 656c 662e 705b 2273 6967  pi * self.p["sig
+0001d650: 6d61 5f33 225d 202a 2072 6164 6975 735f  ma_3"] * radius_
+0001d660: 736b 696e 290a 0a20 2020 2020 2020 2070  skin)..        p
+0001d670: 6f74 656e 7469 616c 735b 6f75 7473 6964  otentials[outsid
+0001d680: 655f 7370 6865 7265 5d20 3d20 302e 300a  e_sphere] = 0.0.
+0001d690: 0a20 2020 2020 2020 2070 6f74 656e 7469  .        potenti
+0001d6a0: 616c 7320 3d20 706f 7465 6e74 6961 6c73  als = potentials
+0001d6b0: 5b6e 702e 6e65 7761 7869 732c 203a 5d0a  [np.newaxis, :].
+0001d6c0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0001d6d0: 706f 7465 6e74 6961 6c73 0a0a 0a63 6c61  potentials...cla
+0001d6e0: 7373 2050 6f74 656e 7469 616c 486f 6d6f  ss PotentialHomo
+0001d6f0: 6765 6e65 6f75 7344 6970 6f6c 6528 4162  geneousDipole(Ab
+0001d700: 7374 7261 6374 4d6f 6465 6c29 3a0a 2020  stractModel):.  
+0001d710: 2020 2222 220a 2020 2020 4361 6c63 756c    """.    Calcul
+0001d720: 6174 6573 2074 6865 2073 7572 6661 6365  ates the surface
+0001d730: 2070 6f74 656e 7469 616c 2067 656e 6572   potential gener
+0001d740: 6174 6564 2062 7920 6120 6469 706f 6c65  ated by a dipole
+0001d750: 2069 6e73 6964 6520 6120 686f 6d6f 6765   inside a homoge
+0001d760: 6e65 6f75 7320 636f 6e64 7563 7469 6e67  neous conducting
+0001d770: 2073 7068 6572 6520 6166 7465 7220 5961   sphere after Ya
+0001d780: 6f20 2832 3030 3029 2e0a 0a20 2020 2050  o (2000)...    P
+0001d790: 6172 616d 6574 6572 730a 2020 2020 2d2d  arameters.    --
+0001d7a0: 2d2d 2d2d 2d2d 2d2d 0a20 2020 2070 5b22  --------.    p["
+0001d7b0: 7370 6865 7265 5f72 6164 6975 7322 5d3a  sphere_radius"]:
+0001d7c0: 2066 6c6f 6174 0a20 2020 2020 2020 2052   float.        R
+0001d7d0: 6164 6975 7320 6f66 2073 7068 6572 6520  adius of sphere 
+0001d7e0: 696e 2028 6d6d 290a 2020 2020 705b 2263  in (mm).    p["c
+0001d7f0: 6f6e 6475 6374 6976 6974 7922 5d3a 2066  onductivity"]: f
+0001d800: 6c6f 6174 0a20 2020 2020 2020 2043 6f6e  loat.        Con
+0001d810: 6475 6374 6976 6974 7920 6f66 206d 6564  ductivity of med
+0001d820: 6975 6d20 696e 2028 532f 6d29 0a20 2020  ium in (S/m).   
+0001d830: 2070 5b22 6469 706f 6c65 5f70 6f73 225d   p["dipole_pos"]
+0001d840: 3a20 6e64 6172 7261 7920 6f66 2066 6c6f  : ndarray of flo
+0001d850: 6174 205b 3320 7820 315d 0a20 2020 2020  at [3 x 1].     
+0001d860: 2020 2050 6f73 6974 696f 6e20 6f66 2064     Position of d
+0001d870: 6970 6f6c 6520 696e 2028 6d6d 290a 2020  ipole in (mm).  
+0001d880: 2020 705b 2264 6970 6f6c 655f 6d6f 6d65    p["dipole_mome
+0001d890: 6e74 225d 3a20 6e64 6172 7261 7920 6f66  nt"]: ndarray of
+0001d8a0: 2066 6c6f 6174 205b 3320 7820 315d 0a20   float [3 x 1]. 
+0001d8b0: 2020 2020 2020 204d 6f6d 656e 7420 6f66         Moment of
+0001d8c0: 2064 6970 6f6c 6520 696e 2028 436d 290a   dipole in (Cm).
+0001d8d0: 2020 2020 705b 2264 6574 6563 746f 725f      p["detector_
+0001d8e0: 706f 7369 7469 6f6e 7322 5d3a 206e 6461  positions"]: nda
+0001d8f0: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
+0001d900: 2078 2033 5d0a 2020 2020 2020 2020 506f   x 3].        Po
+0001d910: 7369 7469 6f6e 206f 6620 6465 7465 6374  sition of detect
+0001d920: 6f72 732c 2077 696c 6c20 6265 2070 726f  ors, will be pro
+0001d930: 6a65 6374 6564 2069 6e74 6f20 7468 6520  jected into the 
+0001d940: 7370 6865 7265 2073 7572 6661 6365 2069  sphere surface i
+0001d950: 6e20 286d 6d29 0a0a 2020 2020 5265 7475  n (mm)..    Retu
+0001d960: 726e 730a 2020 2020 2d2d 2d2d 2d2d 2d0a  rns.    -------.
+0001d970: 2020 2020 706f 7465 6e74 6961 6c3a 206e      potential: n
+0001d980: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+0001d990: 5b31 2078 206e 5f6f 7574 5d0a 2020 2020  [1 x n_out].    
+0001d9a0: 2020 2050 6f74 656e 7469 616c 2061 7420     Potential at 
+0001d9b0: 7468 6520 706f 696e 7473 0a0a 2020 2020  the points..    
+0001d9c0: 4e6f 7465 730a 2020 2020 2d2d 2d2d 2d0a  Notes.    -----.
+0001d9d0: 2020 2020 2e2e 205b 315d 2059 616f 2c20      .. [1] Yao, 
+0001d9e0: 442e 2028 3230 3030 292e 2045 6c65 6374  D. (2000). Elect
+0001d9f0: 7269 6320 706f 7465 6e74 6961 6c20 7072  ric potential pr
+0001da00: 6f64 7563 6564 2062 7920 6120 6469 706f  oduced by a dipo
+0001da10: 6c65 2069 6e20 6120 686f 6d6f 6765 6e65  le in a homogene
+0001da20: 6f75 7320 636f 6e64 7563 7469 6e67 2073  ous conducting s
+0001da30: 7068 6572 652e 0a20 2020 2020 2020 4945  phere..       IE
+0001da40: 4545 2054 7261 6e73 6163 7469 6f6e 7320  EE Transactions 
+0001da50: 6f6e 2042 696f 6d65 6469 6361 6c20 456e  on Biomedical En
+0001da60: 6769 6e65 6572 696e 672c 2034 3728 3729  gineering, 47(7)
+0001da70: 2c20 3936 342d 3936 362e 0a20 2020 2022  , 964-966..    "
+0001da80: 2222 0a0a 2020 2020 6465 6620 5f5f 696e  ""..    def __in
+0001da90: 6974 5f5f 2873 656c 662c 206d 6174 6c61  it__(self, matla
+0001daa0: 625f 6d6f 6465 6c3d 4661 6c73 6529 3a0a  b_model=False):.
+0001dab0: 2020 2020 2020 2020 7375 7065 7228 7479          super(ty
+0001dac0: 7065 2873 656c 6629 2c20 7365 6c66 292e  pe(self), self).
+0001dad0: 5f5f 696e 6974 5f5f 286d 6174 6c61 625f  __init__(matlab_
+0001dae0: 6d6f 6465 6c3d 6d61 746c 6162 5f6d 6f64  model=matlab_mod
+0001daf0: 656c 290a 2020 2020 2020 2020 7365 6c66  el).        self
+0001db00: 2e66 6e61 6d65 203d 2069 6e73 7065 6374  .fname = inspect
+0001db10: 2e67 6574 6669 6c65 2869 6e73 7065 6374  .getfile(inspect
+0001db20: 2e63 7572 7265 6e74 6672 616d 6528 2929  .currentframe())
+0001db30: 0a0a 2020 2020 6465 6620 7661 6c69 6461  ..    def valida
+0001db40: 7465 2873 656c 6629 3a0a 2020 2020 2020  te(self):.      
+0001db50: 2020 7061 7373 0a0a 2020 2020 6465 6620    pass..    def 
+0001db60: 7369 6d75 6c61 7465 2873 656c 662c 2070  simulate(self, p
+0001db70: 726f 6365 7373 5f69 643d 4e6f 6e65 2c20  rocess_id=None, 
+0001db80: 6d61 746c 6162 5f65 6e67 696e 653d 4e6f  matlab_engine=No
+0001db90: 6e65 293a 0a0a 2020 2020 2020 2020 7365  ne):..        se
+0001dba0: 6c66 2e70 5b22 6465 7465 6374 6f72 5f70  lf.p["detector_p
+0001dbb0: 6f73 6974 696f 6e73 225d 203d 206e 702e  ositions"] = np.
+0001dbc0: 6174 6c65 6173 745f 3264 2873 656c 662e  atleast_2d(self.
+0001dbd0: 705b 2264 6574 6563 746f 725f 706f 7369  p["detector_posi
+0001dbe0: 7469 6f6e 7322 5d29 0a20 2020 2020 2020  tions"]).       
+0001dbf0: 2061 7373 6572 7420 7365 6c66 2e70 5b22   assert self.p["
+0001dc00: 6465 7465 6374 6f72 5f70 6f73 6974 696f  detector_positio
+0001dc10: 6e73 225d 2e73 6861 7065 5b31 5d20 3d3d  ns"].shape[1] ==
+0001dc20: 2033 0a20 2020 2020 2020 2061 7373 6572   3.        asser
+0001dc30: 7420 6e70 2e6c 696e 616c 672e 6e6f 726d  t np.linalg.norm
+0001dc40: 2873 656c 662e 705b 2264 6970 6f6c 655f  (self.p["dipole_
+0001dc50: 706f 7322 5d29 203c 2073 656c 662e 705b  pos"]) < self.p[
+0001dc60: 2273 7068 6572 655f 7261 6469 7573 225d  "sphere_radius"]
+0001dc70: 0a0a 2020 2020 2020 2020 7365 6c66 2e70  ..        self.p
+0001dc80: 5b22 7370 6865 7265 5f72 6164 6975 7322  ["sphere_radius"
+0001dc90: 5d20 3d20 6e70 2e66 6c6f 6174 3132 3828  ] = np.float128(
+0001dca0: 7365 6c66 2e70 5b22 7370 6865 7265 5f72  self.p["sphere_r
+0001dcb0: 6164 6975 7322 5d20 2a20 3165 2d33 290a  adius"] * 1e-3).
+0001dcc0: 2020 2020 2020 2020 7365 6c66 2e70 5b22          self.p["
+0001dcd0: 6469 706f 6c65 5f70 6f73 225d 203d 206e  dipole_pos"] = n
+0001dce0: 702e 6172 7261 7928 7365 6c66 2e70 5b22  p.array(self.p["
+0001dcf0: 6469 706f 6c65 5f70 6f73 225d 2c20 6474  dipole_pos"], dt
+0001dd00: 7970 653d 6e70 2e66 6c6f 6174 3132 3829  ype=np.float128)
+0001dd10: 202a 2031 652d 330a 2020 2020 2020 2020   * 1e-3.        
+0001dd20: 7365 6c66 2e70 5b22 6469 706f 6c65 5f6d  self.p["dipole_m
+0001dd30: 6f6d 656e 7422 5d20 3d20 6e70 2e61 7272  oment"] = np.arr
+0001dd40: 6179 2873 656c 662e 705b 2264 6970 6f6c  ay(self.p["dipol
+0001dd50: 655f 6d6f 6d65 6e74 225d 2c20 6474 7970  e_moment"], dtyp
+0001dd60: 653d 6e70 2e66 6c6f 6174 3132 3829 0a20  e=np.float128). 
+0001dd70: 2020 2020 2020 2073 656c 662e 705b 2264         self.p["d
+0001dd80: 6574 6563 746f 725f 706f 7369 7469 6f6e  etector_position
+0001dd90: 7322 5d20 3d20 6e70 2e61 7272 6179 2873  s"] = np.array(s
+0001dda0: 656c 662e 705b 2264 6574 6563 746f 725f  elf.p["detector_
+0001ddb0: 706f 7369 7469 6f6e 7322 5d2c 2064 7479  positions"], dty
+0001ddc0: 7065 3d6e 702e 666c 6f61 7431 3238 2920  pe=np.float128) 
+0001ddd0: 2a20 3165 2d33 0a0a 2020 2020 2020 2020  * 1e-3..        
+0001dde0: 7273 203d 2073 656c 662e 705b 2273 7068  rs = self.p["sph
+0001ddf0: 6572 655f 7261 6469 7573 225d 0a20 2020  ere_radius"].   
+0001de00: 2020 2020 2072 3020 3d20 6e70 2e6c 696e       r0 = np.lin
+0001de10: 616c 672e 6e6f 726d 2873 656c 662e 705b  alg.norm(self.p[
+0001de20: 2264 6970 6f6c 655f 706f 7322 5d29 0a20  "dipole_pos"]). 
+0001de30: 2020 2020 2020 2072 203d 206e 702e 6c69         r = np.li
+0001de40: 6e61 6c67 2e6e 6f72 6d28 7365 6c66 2e70  nalg.norm(self.p
+0001de50: 5b22 6465 7465 6374 6f72 5f70 6f73 6974  ["detector_posit
+0001de60: 696f 6e73 225d 2c20 6178 6973 3d31 290a  ions"], axis=1).
+0001de70: 2020 2020 2020 2020 7270 203d 206e 702e          rp = np.
+0001de80: 6c69 6e61 6c67 2e6e 6f72 6d28 7365 6c66  linalg.norm(self
+0001de90: 2e70 5b22 6469 706f 6c65 5f70 6f73 225d  .p["dipole_pos"]
+0001dea0: 202d 2073 656c 662e 705b 2264 6574 6563   - self.p["detec
+0001deb0: 746f 725f 706f 7369 7469 6f6e 7322 5d2c  tor_positions"],
+0001dec0: 2061 7869 733d 3129 0a0a 2020 2020 2020   axis=1)..      
+0001ded0: 2020 6966 206e 6f74 206e 702e 616c 6c63    if not np.allc
+0001dee0: 6c6f 7365 2872 2c20 7273 293a 0a20 2020  lose(r, rs):.   
+0001def0: 2020 2020 2020 2020 2077 6172 6e69 6e67           warning
+0001df00: 732e 7761 726e 2827 536f 6d65 2070 6f69  s.warn('Some poi
+0001df10: 6e74 7320 6172 6520 6e6f 7420 696e 2074  nts are not in t
+0001df20: 6865 2073 7572 6661 6365 2121 2729 0a0a  he surface!!')..
+0001df30: 2020 2020 2020 2020 6966 206e 702e 6973          if np.is
+0001df40: 636c 6f73 6528 7230 2c20 3029 3a0a 2020  close(r0, 0):.  
+0001df50: 2020 2020 2020 2020 2020 636f 735f 7068            cos_ph
+0001df60: 6920 3d20 6e70 2e7a 6572 6f73 286c 656e  i = np.zeros(len
+0001df70: 2873 656c 662e 705b 2264 6574 6563 746f  (self.p["detecto
+0001df80: 725f 706f 7369 7469 6f6e 7322 5d29 2c20  r_positions"]), 
+0001df90: 6474 7970 653d 6e70 2e66 6c6f 6174 3132  dtype=np.float12
+0001dfa0: 3829 0a20 2020 2020 2020 2065 6c73 653a  8).        else:
+0001dfb0: 0a20 2020 2020 2020 2020 2020 2063 6f73  .            cos
+0001dfc0: 5f70 6869 203d 2073 656c 662e 705b 2264  _phi = self.p["d
+0001dfd0: 6970 6f6c 655f 706f 7322 5d2e 646f 7428  ipole_pos"].dot(
+0001dfe0: 7365 6c66 2e70 5b22 6465 7465 6374 6f72  self.p["detector
+0001dff0: 5f70 6f73 6974 696f 6e73 225d 2e54 2920  _positions"].T) 
+0001e000: 2f20 5c0a 2020 2020 2020 2020 2020 2020  / \.            
+0001e010: 2020 2020 2020 2020 2020 286e 702e 6c69            (np.li
+0001e020: 6e61 6c67 2e6e 6f72 6d28 7365 6c66 2e70  nalg.norm(self.p
+0001e030: 5b22 6469 706f 6c65 5f70 6f73 225d 2920  ["dipole_pos"]) 
+0001e040: 2a20 6e70 2e6c 696e 616c 672e 6e6f 726d  * np.linalg.norm
+0001e050: 2873 656c 662e 705b 2264 6574 6563 746f  (self.p["detecto
+0001e060: 725f 706f 7369 7469 6f6e 7322 5d2c 2061  r_positions"], a
+0001e070: 7869 733d 3129 290a 0a20 2020 2020 2020  xis=1))..       
+0001e080: 2073 6563 6f6e 645f 7465 726d 203d 2031   second_term = 1
+0001e090: 2e20 2f20 2872 705b 3a2c 204e 6f6e 655d  . / (rp[:, None]
+0001e0a0: 202a 2072 7320 2a2a 2032 2920 2a20 280a   * rs ** 2) * (.
+0001e0b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e0c0: 7365 6c66 2e70 5b22 6465 7465 6374 6f72  self.p["detector
+0001e0d0: 5f70 6f73 6974 696f 6e73 225d 202b 2028  _positions"] + (
+0001e0e0: 7365 6c66 2e70 5b22 6465 7465 6374 6f72  self.p["detector
+0001e0f0: 5f70 6f73 6974 696f 6e73 225d 202a 2072  _positions"] * r
+0001e100: 3020 2a20 636f 735f 7068 695b 3a2c 204e  0 * cos_phi[:, N
+0001e110: 6f6e 655d 202d 0a20 2020 2020 2020 2020  one] -.         
+0001e120: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e130: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e140: 2020 2020 2020 2072 7320 2a20 7365 6c66         rs * self
+0001e150: 2e70 5b22 6469 706f 6c65 5f70 6f73 225d  .p["dipole_pos"]
+0001e160: 2920 2f0a 2020 2020 2020 2020 2020 2020  ) /.            
+0001e170: 2020 2020 2872 7320 2b20 7270 202d 2072      (rs + rp - r
+0001e180: 3020 2a20 636f 735f 7068 6929 5b3a 2c20  0 * cos_phi)[:, 
+0001e190: 4e6f 6e65 5d29 0a0a 2020 2020 2020 2020  None])..        
+0001e1a0: 706f 7465 6e74 6961 6c20 3d20 7365 6c66  potential = self
+0001e1b0: 2e70 5b22 6469 706f 6c65 5f6d 6f6d 656e  .p["dipole_momen
+0001e1c0: 7422 5d2e 646f 7428 2832 202a 2028 7365  t"].dot((2 * (se
+0001e1d0: 6c66 2e70 5b22 6465 7465 6374 6f72 5f70  lf.p["detector_p
+0001e1e0: 6f73 6974 696f 6e73 225d 202d 2073 656c  ositions"] - sel
+0001e1f0: 662e 705b 2264 6970 6f6c 655f 706f 7322  f.p["dipole_pos"
+0001e200: 5d29 202f 0a20 2020 2020 2020 2020 2020  ]) /.           
+0001e210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e220: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e230: 2020 2020 2020 2872 7020 2a2a 2033 295b        (rp ** 3)[
+0001e240: 3a2c 204e 6f6e 655d 202b 2073 6563 6f6e  :, None] + secon
+0001e250: 645f 7465 726d 292e 5429 2e54 0a0a 2020  d_term).T).T..  
+0001e260: 2020 2020 2020 706f 7465 6e74 6961 6c20        potential 
+0001e270: 2f3d 2034 202a 206e 702e 7069 202a 2073  /= 4 * np.pi * s
+0001e280: 656c 662e 705b 2263 6f6e 6475 6374 6976  elf.p["conductiv
+0001e290: 6974 7922 5d0a 0a20 2020 2020 2020 2070  ity"]..        p
+0001e2a0: 6f74 656e 7469 616c 203d 2070 6f74 656e  otential = poten
+0001e2b0: 7469 616c 5b6e 702e 6e65 7761 7869 732c  tial[np.newaxis,
+0001e2c0: 203a 5d0a 0a20 2020 2020 2020 2072 6574   :]..        ret
+0001e2d0: 7572 6e20 706f 7465 6e74 6961 6c0a 0a0a  urn potential...
+0001e2e0: 636c 6173 7320 4266 6965 6c64 4f75 7473  class BfieldOuts
+0001e2f0: 6964 6553 7068 6572 6528 4162 7374 7261  ideSphere(Abstra
+0001e300: 6374 4d6f 6465 6c29 3a0a 2020 2020 2222  ctModel):.    ""
+0001e310: 220a 2020 2020 4361 6c63 756c 6174 6573  ".    Calculates
+0001e320: 2074 6865 2042 2d66 6965 6c64 206f 7574   the B-field out
+0001e330: 7369 6465 2061 2073 7068 6572 652c 2064  side a sphere, d
+0001e340: 6f65 7320 6e6f 7420 6465 7065 6e64 206f  oes not depend o
+0001e350: 6e20 636f 6e64 7563 7469 7669 7479 2061  n conductivity a
+0001e360: 6674 6572 204a 6172 7661 7320 2831 3938  fter Jarvas (198
+0001e370: 3729 2e0a 2020 2020 4469 706f 6c65 2069  7)..    Dipole i
+0001e380: 6e20 5349 2075 6e69 7473 2c20 706f 7369  n SI units, posi
+0001e390: 7469 6f6e 7320 696e 2028 6d6d 290a 0a20  tions in (mm).. 
+0001e3a0: 2020 2050 6172 616d 6574 6572 730a 2020     Parameters.  
+0001e3b0: 2020 2d2d 2d2d 2d2d 2d2d 2d2d 0a20 2020    ----------.   
+0001e3c0: 2070 5b22 7370 6865 7265 5f72 6164 6975   p["sphere_radiu
+0001e3d0: 7322 5d3a 2066 6c6f 6174 0a20 2020 2020  s"]: float.     
+0001e3e0: 2020 2052 6164 6975 7320 6f66 2073 7068     Radius of sph
+0001e3f0: 6572 6520 696e 2028 6d6d 290a 2020 2020  ere in (mm).    
+0001e400: 705b 2264 6970 6f6c 655f 706f 7322 5d3a  p["dipole_pos"]:
+0001e410: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
+0001e420: 7420 5b33 2078 2031 5d0a 2020 2020 2020  t [3 x 1].      
+0001e430: 2020 506f 7369 7469 6f6e 206f 6620 6469    Position of di
+0001e440: 706f 6c65 2069 6e20 286d 6d29 0a20 2020  pole in (mm).   
+0001e450: 2070 5b22 6469 706f 6c65 5f6d 6f6d 656e   p["dipole_momen
+0001e460: 7422 5d3a 206e 6461 7272 6179 206f 6620  t"]: ndarray of 
+0001e470: 666c 6f61 7420 5b33 2078 2031 5d0a 2020  float [3 x 1].  
+0001e480: 2020 2020 2020 4d6f 6d65 6e74 206f 6620        Moment of 
+0001e490: 6469 706f 6c65 2069 6e20 2841 6d73 290a  dipole in (Ams).
+0001e4a0: 2020 2020 705b 2264 6574 6563 746f 725f      p["detector_
+0001e4b0: 706f 7369 7469 6f6e 7322 5d3a 206e 6461  positions"]: nda
+0001e4c0: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
+0001e4d0: 2078 2033 5d0a 2020 2020 2020 2020 506f   x 3].        Po
+0001e4e0: 7369 7469 6f6e 206f 6620 6465 7465 6374  sition of detect
+0001e4f0: 6f72 732c 206d 7573 7420 6c69 6520 6f75  ors, must lie ou
+0001e500: 7473 6964 6520 7370 6865 7265 0a0a 2020  tside sphere..  
+0001e510: 2020 5265 7475 726e 730a 2020 2020 2d2d    Returns.    --
+0001e520: 2d2d 2d2d 2d0a 2020 2020 423a 206e 6461  -----.    B: nda
+0001e530: 7272 6179 206f 6620 666c 6f61 7420 5b31  rray of float [1
+0001e540: 2078 2033 2a4e 5d0a 2020 2020 2020 2020   x 3*N].        
+0001e550: 422d 6669 656c 6473 2069 6e20 6465 7465  B-fields in dete
+0001e560: 6374 6f72 2070 6f73 6974 696f 6e73 0a0a  ctor positions..
+0001e570: 2020 2020 4e6f 7465 730a 2020 2020 2d2d      Notes.    --
+0001e580: 2d2d 2d0a 2020 2020 2e2e 205b 315d 2053  ---.    .. [1] S
+0001e590: 6172 7661 732c 204a 2e20 2831 3938 3729  arvas, J. (1987)
+0001e5a0: 2e20 4261 7369 6320 6d61 7468 656d 6174  . Basic mathemat
+0001e5b0: 6963 616c 2061 6e64 2065 6c65 6374 726f  ical and electro
+0001e5c0: 6d61 676e 6574 6963 2063 6f6e 6365 7074  magnetic concept
+0001e5d0: 7320 6f66 2074 6865 2062 696f 6d61 676e  s of the biomagn
+0001e5e0: 6574 6963 2069 6e76 6572 7365 2070 726f  etic inverse pro
+0001e5f0: 626c 656d 2e0a 2020 2020 2020 2050 6879  blem..       Phy
+0001e600: 7369 6373 2069 6e20 4d65 6469 6369 6e65  sics in Medicine
+0001e610: 2026 2042 696f 6c6f 6779 2c20 3332 2831   & Biology, 32(1
+0001e620: 292c 2031 312e 0a20 2020 2022 2222 0a0a  ), 11..    """..
+0001e630: 2020 2020 6465 6620 5f5f 696e 6974 5f5f      def __init__
+0001e640: 2873 656c 662c 206d 6174 6c61 625f 6d6f  (self, matlab_mo
+0001e650: 6465 6c3d 4661 6c73 6529 3a0a 2020 2020  del=False):.    
+0001e660: 2020 2020 7375 7065 7228 7479 7065 2873      super(type(s
+0001e670: 656c 6629 2c20 7365 6c66 292e 5f5f 696e  elf), self).__in
+0001e680: 6974 5f5f 286d 6174 6c61 625f 6d6f 6465  it__(matlab_mode
+0001e690: 6c3d 6d61 746c 6162 5f6d 6f64 656c 290a  l=matlab_model).
+0001e6a0: 2020 2020 2020 2020 7365 6c66 2e66 6e61          self.fna
+0001e6b0: 6d65 203d 2069 6e73 7065 6374 2e67 6574  me = inspect.get
+0001e6c0: 6669 6c65 2869 6e73 7065 6374 2e63 7572  file(inspect.cur
+0001e6d0: 7265 6e74 6672 616d 6528 2929 0a0a 2020  rentframe())..  
+0001e6e0: 2020 6465 6620 7661 6c69 6461 7465 2873    def validate(s
+0001e6f0: 656c 6629 3a0a 2020 2020 2020 2020 7061  elf):.        pa
+0001e700: 7373 0a0a 2020 2020 6465 6620 7369 6d75  ss..    def simu
+0001e710: 6c61 7465 2873 656c 662c 2070 726f 6365  late(self, proce
+0001e720: 7373 5f69 643d 4e6f 6e65 2c20 6d61 746c  ss_id=None, matl
+0001e730: 6162 5f65 6e67 696e 653d 4e6f 6e65 293a  ab_engine=None):
+0001e740: 0a20 2020 2020 2020 2070 6f73 203d 206e  .        pos = n
+0001e750: 702e 6172 7261 7928 7365 6c66 2e70 5b22  p.array(self.p["
+0001e760: 6469 706f 6c65 5f70 6f73 225d 2c20 6474  dipole_pos"], dt
+0001e770: 7970 653d 666c 6f61 7429 202a 2031 652d  ype=float) * 1e-
+0001e780: 330a 2020 2020 2020 2020 6d6f 6d65 6e74  3.        moment
+0001e790: 203d 206e 702e 6172 7261 7928 7365 6c66   = np.array(self
+0001e7a0: 2e70 5b22 6469 706f 6c65 5f6d 6f6d 656e  .p["dipole_momen
+0001e7b0: 7422 5d2c 2064 7479 7065 3d66 6c6f 6174  t"], dtype=float
+0001e7c0: 290a 2020 2020 2020 2020 6465 7465 6374  ).        detect
+0001e7d0: 6f72 203d 206e 702e 6172 7261 7928 7365  or = np.array(se
+0001e7e0: 6c66 2e70 5b22 6465 7465 6374 6f72 5f70  lf.p["detector_p
+0001e7f0: 6f73 6974 696f 6e73 225d 2c20 6474 7970  ositions"], dtyp
+0001e800: 653d 666c 6f61 7429 202a 2031 652d 330a  e=float) * 1e-3.
+0001e810: 0a20 2020 2020 2020 2061 7373 6572 7420  .        assert 
+0001e820: 6e70 2e61 6c6c 286e 702e 6c69 6e61 6c67  np.all(np.linalg
+0001e830: 2e6e 6f72 6d28 7365 6c66 2e70 5b22 6465  .norm(self.p["de
+0001e840: 7465 6374 6f72 5f70 6f73 6974 696f 6e73  tector_positions
+0001e850: 225d 2c20 6178 6973 3d31 2920 3e20 7365  "], axis=1) > se
+0001e860: 6c66 2e70 5b22 7370 6865 7265 5f72 6164  lf.p["sphere_rad
+0001e870: 6975 7322 5d29 2c20 5c0a 2020 2020 2020  ius"]), \.      
+0001e880: 2020 2020 2020 2241 6c6c 2070 6f69 6e74        "All point
+0001e890: 7320 6d75 7374 2062 6520 6f75 7473 6964  s must be outsid
+0001e8a0: 6520 7468 6520 7370 6865 7265 220a 0a20  e the sphere".. 
+0001e8b0: 2020 2020 2020 2061 7373 6572 7420 6e70         assert np
+0001e8c0: 2e61 6c6c 286e 702e 6c69 6e61 6c67 2e6e  .all(np.linalg.n
+0001e8d0: 6f72 6d28 7365 6c66 2e70 5b22 6469 706f  orm(self.p["dipo
+0001e8e0: 6c65 5f70 6f73 225d 2920 3c20 7365 6c66  le_pos"]) < self
+0001e8f0: 2e70 5b22 7370 6865 7265 5f72 6164 6975  .p["sphere_radiu
+0001e900: 7322 5d29 2c20 5c0a 2020 2020 2020 2020  s"]), \.        
+0001e910: 2020 2020 2244 6970 6f6c 6520 6d75 7374      "Dipole must
+0001e920: 2062 6520 6f75 7473 6964 6520 7370 6865   be outside sphe
+0001e930: 7265 220a 0a20 2020 2020 2020 2062 203d  re"..        b =
+0001e940: 206e 702e 7a65 726f 7328 7365 6c66 2e70   np.zeros(self.p
+0001e950: 5b22 6465 7465 6374 6f72 5f70 6f73 6974  ["detector_posit
+0001e960: 696f 6e73 225d 2e73 6861 7065 2c20 6474  ions"].shape, dt
+0001e970: 7970 653d 666c 6f61 7429 0a0a 2020 2020  ype=float)..    
+0001e980: 2020 2020 666f 7220 6969 2c20 7220 696e      for ii, r in
+0001e990: 2065 6e75 6d65 7261 7465 2864 6574 6563   enumerate(detec
+0001e9a0: 746f 7229 3a0a 2020 2020 2020 2020 2020  tor):.          
+0001e9b0: 2020 6e6f 726d 5f72 203d 206e 702e 6c69    norm_r = np.li
+0001e9c0: 6e61 6c67 2e6e 6f72 6d28 7229 0a0a 2020  nalg.norm(r)..  
+0001e9d0: 2020 2020 2020 2020 2020 725f 3020 3d20            r_0 = 
+0001e9e0: 706f 730a 2020 2020 2020 2020 2020 2020  pos.            
+0001e9f0: 2320 6e6f 726d 5f72 3020 3d20 6e70 2e6c  # norm_r0 = np.l
+0001ea00: 696e 616c 672e 6e6f 726d 2870 6f73 290a  inalg.norm(pos).
+0001ea10: 0a20 2020 2020 2020 2020 2020 2061 203d  .            a =
+0001ea20: 2072 202d 2072 5f30 0a20 2020 2020 2020   r - r_0.       
+0001ea30: 2020 2020 206e 6f72 6d5f 6120 3d20 6e70       norm_a = np
+0001ea40: 2e6c 696e 616c 672e 6e6f 726d 2861 290a  .linalg.norm(a).
+0001ea50: 0a20 2020 2020 2020 2020 2020 2066 203d  .            f =
+0001ea60: 206e 6f72 6d5f 6120 2a20 286e 6f72 6d5f   norm_a * (norm_
+0001ea70: 7220 2a20 6e6f 726d 5f61 202b 206e 6f72  r * norm_a + nor
+0001ea80: 6d5f 7220 2a2a 2032 202d 2072 5f30 2e64  m_r ** 2 - r_0.d
+0001ea90: 6f74 2872 2929 0a0a 2020 2020 2020 2020  ot(r))..        
+0001eaa0: 2020 2020 6772 6164 5f66 203d 2028 6e6f      grad_f = (no
+0001eab0: 726d 5f72 202a 2a20 282d 3129 202a 206e  rm_r ** (-1) * n
+0001eac0: 6f72 6d5f 6120 2a2a 2032 202b 206e 6f72  orm_a ** 2 + nor
+0001ead0: 6d5f 6120 2a2a 2028 2d31 2920 2a20 612e  m_a ** (-1) * a.
+0001eae0: 646f 7428 7229 202b 2032 202a 206e 6f72  dot(r) + 2 * nor
+0001eaf0: 6d5f 6120 2b20 3220 2a20 6e6f 726d 5f72  m_a + 2 * norm_r
+0001eb00: 2920 2a20 7220 2d20 5c0a 2020 2020 2020  ) * r - \.      
+0001eb10: 2020 2020 2020 2020 2020 2020 2020 2028                 (
+0001eb20: 6e6f 726d 5f61 202b 2032 202a 206e 6f72  norm_a + 2 * nor
+0001eb30: 6d5f 7220 2b20 6e6f 726d 5f61 202a 2a20  m_r + norm_a ** 
+0001eb40: 282d 3129 202a 2061 2e64 6f74 2872 2929  (-1) * a.dot(r))
+0001eb50: 202a 2072 5f30 0a0a 2020 2020 2020 2020   * r_0..        
+0001eb60: 2020 2020 625b 6969 2c20 3a5d 203d 2028      b[ii, :] = (
+0001eb70: 3420 2a20 6e70 2e70 6920 2a20 3165 2d37  4 * np.pi * 1e-7
+0001eb80: 2920 2f20 5c0a 2020 2020 2020 2020 2020  ) / \.          
+0001eb90: 2020 2020 2020 2020 2020 2020 2028 3420               (4 
+0001eba0: 2a20 6e70 2e70 6920 2a20 6620 2a2a 2032  * np.pi * f ** 2
+0001ebb0: 2920 2a20 2866 202a 206e 702e 6372 6f73  ) * (f * np.cros
+0001ebc0: 7328 6d6f 6d65 6e74 2c20 725f 3029 202d  s(moment, r_0) -
+0001ebd0: 206e 702e 646f 7428 6e70 2e63 726f 7373   np.dot(np.cross
+0001ebe0: 286d 6f6d 656e 742c 2072 5f30 292c 2072  (moment, r_0), r
+0001ebf0: 2920 2a20 6772 6164 5f66 290a 0a20 2020  ) * grad_f)..   
+0001ec00: 2020 2020 2062 203d 2062 2e66 6c61 7474       b = b.flatt
+0001ec10: 656e 2829 5b6e 702e 6e65 7761 7869 732c  en()[np.newaxis,
+0001ec20: 203a 5d0a 0a20 2020 2020 2020 2072 6574   :]..        ret
+0001ec30: 7572 6e20 620a 0a0a 636c 6173 7320 544d  urn b...class TM
+0001ec40: 5345 6669 656c 6453 7068 6572 6528 4162  SEfieldSphere(Ab
+0001ec50: 7374 7261 6374 4d6f 6465 6c29 3a0a 2020  stractModel):.  
+0001ec60: 2020 2222 220a 2020 2020 4361 6c63 756c    """.    Calcul
+0001ec70: 6174 6520 7468 6520 452d 6669 656c 6420  ate the E-field 
+0001ec80: 696e 2061 2073 7068 6572 6520 6361 7573  in a sphere caus
+0001ec90: 6564 2062 7920 6578 7465 726e 616c 206d  ed by external m
+0001eca0: 6167 6e65 7469 6320 6469 706f 6c65 7320  agnetic dipoles 
+0001ecb0: 6166 7465 7220 4865 6c6c 6572 2061 6e64  after Heller and
+0001ecc0: 2076 616e 2048 756c 7374 6579 6e20 2831   van Hulsteyn (1
+0001ecd0: 3939 3229 2e0a 2020 2020 5468 6520 7265  992)..    The re
+0001ece0: 7375 6c74 7320 6172 6520 696e 6465 7065  sults are indepe
+0001ecf0: 6e64 656e 7420 6f66 2063 6f6e 6475 6374  ndent of conduct
+0001ed00: 6976 6974 792e 0a0a 2020 2020 5061 7261  ivity...    Para
+0001ed10: 6d65 7465 7273 0a20 2020 202d 2d2d 2d2d  meters.    -----
+0001ed20: 2d2d 2d2d 2d0a 2020 2020 705b 2264 6970  -----.    p["dip
+0001ed30: 6f6c 655f 706f 7322 5d3a 206e 6461 7272  ole_pos"]: ndarr
+0001ed40: 6179 206f 6620 666c 6f61 7420 5b4d 2078  ay of float [M x
+0001ed50: 2033 5d0a 2020 2020 2020 2020 506f 7369   3].        Posi
+0001ed60: 7469 6f6e 206f 6620 6469 706f 6c65 732c  tion of dipoles,
+0001ed70: 206d 7573 7420 6265 206f 7574 7369 6465   must be outside
+0001ed80: 2073 7068 6572 650a 2020 2020 705b 2264   sphere.    p["d
+0001ed90: 6970 6f6c 655f 6d6f 6d65 6e74 225d 3a20  ipole_moment"]: 
+0001eda0: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
+0001edb0: 205b 6d20 7820 335d 0a20 2020 2020 2020   [m x 3].       
+0001edc0: 204d 6f6d 656e 7420 6f66 2064 6970 6f6c   Moment of dipol
+0001edd0: 6573 0a20 2020 2070 5b22 6469 6474 225d  es.    p["didt"]
+0001ede0: 3a20 666c 6f61 740a 2020 2020 2020 2020  : float.        
+0001edf0: 5661 7269 6174 696f 6e20 7261 7465 206f  Variation rate o
+0001ee00: 6620 6375 7272 656e 7420 696e 2074 6865  f current in the
+0001ee10: 2063 6f69 6c0a 2020 2020 705b 2270 6f73   coil.    p["pos
+0001ee20: 6974 696f 6e73 225d 3a20 6e64 6172 7261  itions"]: ndarra
+0001ee30: 7920 6f66 2066 6c6f 6174 205b 4e20 7820  y of float [N x 
+0001ee40: 335d 0a20 2020 2020 2020 2050 6f73 6974  3].        Posit
+0001ee50: 696f 6e20 7768 6572 6520 6669 656c 6473  ion where fields
+0001ee60: 2073 686f 756c 6420 6265 2063 616c 6375   should be calcu
+0001ee70: 6c61 7465 642c 206d 7573 7420 6c69 6520  lated, must lie 
+0001ee80: 696e 7369 6465 2073 7068 6572 6520 696e  inside sphere in
+0001ee90: 2028 6d6d 290a 0a20 2020 2052 6574 7572   (mm)..    Retur
+0001eea0: 6e73 0a20 2020 202d 2d2d 2d2d 2d2d 0a20  ns.    -------. 
+0001eeb0: 2020 2045 3a20 6e64 6172 7261 7920 6f66     E: ndarray of
+0001eec0: 2066 6c6f 6174 205b 3120 7820 332a 4e5d   float [1 x 3*N]
+0001eed0: 0a20 2020 2020 2020 2045 2d66 6965 6c64  .        E-field
+0001eee0: 7320 6174 2064 6574 6563 746f 7220 706f  s at detector po
+0001eef0: 7369 7469 6f6e 730a 0a20 2020 204e 6f74  sitions..    Not
+0001ef00: 6573 0a20 2020 202d 2d2d 2d2d 0a20 2020  es.    -----.   
+0001ef10: 202e 2e20 5b31 5d20 4865 6c6c 6572 2c20   .. [1] Heller, 
+0001ef20: 4c2e 2c20 2620 7661 6e20 4875 6c73 7465  L., & van Hulste
+0001ef30: 796e 2c20 442e 2042 2e20 2831 3939 3229  yn, D. B. (1992)
+0001ef40: 2e20 4272 6169 6e20 7374 696d 756c 6174  . Brain stimulat
+0001ef50: 696f 6e20 7573 696e 6720 656c 6563 7472  ion using electr
+0001ef60: 6f6d 6167 6e65 7469 6320 736f 7572 6365  omagnetic source
+0001ef70: 733a 0a20 2020 2020 2020 7468 656f 7265  s:.       theore
+0001ef80: 7469 6361 6c20 6173 7065 6374 732e 2042  tical aspects. B
+0001ef90: 696f 7068 7973 6963 616c 204a 6f75 726e  iophysical Journ
+0001efa0: 616c 2c20 3633 2831 292c 2031 3239 2d31  al, 63(1), 129-1
+0001efb0: 3338 2e0a 2020 2020 2222 220a 0a20 2020  38..    """..   
+0001efc0: 2064 6566 205f 5f69 6e69 745f 5f28 7365   def __init__(se
+0001efd0: 6c66 2c20 6d61 746c 6162 5f6d 6f64 656c  lf, matlab_model
+0001efe0: 3d46 616c 7365 293a 0a20 2020 2020 2020  =False):.       
+0001eff0: 2073 7570 6572 2874 7970 6528 7365 6c66   super(type(self
+0001f000: 292c 2073 656c 6629 2e5f 5f69 6e69 745f  ), self).__init_
+0001f010: 5f28 6d61 746c 6162 5f6d 6f64 656c 3d6d  _(matlab_model=m
+0001f020: 6174 6c61 625f 6d6f 6465 6c29 0a20 2020  atlab_model).   
+0001f030: 2020 2020 2073 656c 662e 666e 616d 6520       self.fname 
+0001f040: 3d20 696e 7370 6563 742e 6765 7466 696c  = inspect.getfil
+0001f050: 6528 696e 7370 6563 742e 6375 7272 656e  e(inspect.curren
+0001f060: 7466 7261 6d65 2829 290a 0a20 2020 2064  tframe())..    d
+0001f070: 6566 2076 616c 6964 6174 6528 7365 6c66  ef validate(self
+0001f080: 293a 0a20 2020 2020 2020 2070 6173 730a  ):.        pass.
+0001f090: 0a20 2020 2064 6566 2073 696d 756c 6174  .    def simulat
+0001f0a0: 6528 7365 6c66 2c20 7072 6f63 6573 735f  e(self, process_
+0001f0b0: 6964 3d4e 6f6e 652c 206d 6174 6c61 625f  id=None, matlab_
+0001f0c0: 656e 6769 6e65 3d4e 6f6e 6529 3a0a 0a20  engine=None):.. 
+0001f0d0: 2020 2020 2020 2069 6620 7365 6c66 2e70         if self.p
+0001f0e0: 5b22 6469 706f 6c65 5f70 6f73 225d 2e73  ["dipole_pos"].s
+0001f0f0: 6861 7065 2021 3d20 7365 6c66 2e70 5b22  hape != self.p["
+0001f100: 6469 706f 6c65 5f6d 6f6d 656e 7422 5d2e  dipole_moment"].
+0001f110: 7368 6170 653a 0a20 2020 2020 2020 2020  shape:.         
+0001f120: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
+0001f130: 726f 7228 274c 6973 7420 6f66 2064 6970  ror('List of dip
+0001f140: 6f6c 6520 706f 7369 7469 6f6e 2061 6e64  ole position and
+0001f150: 206d 6f6d 656e 7473 2073 686f 756c 6420   moments should 
+0001f160: 6861 7665 2074 6865 2073 616d 6527 0a20  have the same'. 
+0001f170: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f180: 2020 2020 2020 2020 2020 2020 276c 656e              'len
+0001f190: 6774 6873 2729 0a20 2020 2020 2020 206d  gths').        m
+0001f1a0: 7530 5f34 7069 203d 2031 652d 370a 0a20  u0_4pi = 1e-7.. 
+0001f1b0: 2020 2020 2020 2065 203d 206e 702e 7a65         e = np.ze
+0001f1c0: 726f 7328 7365 6c66 2e70 5b22 706f 7369  ros(self.p["posi
+0001f1d0: 7469 6f6e 7322 5d2e 7368 6170 652c 2064  tions"].shape, d
+0001f1e0: 7479 7065 3d66 6c6f 6174 290a 2020 2020  type=float).    
+0001f1f0: 2020 2020 6470 203d 206e 702e 6174 6c65      dp = np.atle
+0001f200: 6173 745f 3264 2873 656c 662e 705b 2264  ast_2d(self.p["d
+0001f210: 6970 6f6c 655f 706f 7322 5d29 0a20 2020  ipole_pos"]).   
+0001f220: 2020 2020 2064 6d20 3d20 6e70 2e61 746c       dm = np.atl
+0001f230: 6561 7374 5f32 6428 7365 6c66 2e70 5b22  east_2d(self.p["
+0001f240: 6469 706f 6c65 5f6d 6f6d 656e 7422 5d29  dipole_moment"])
+0001f250: 0a0a 2020 2020 2020 2020 7231 203d 2073  ..        r1 = s
+0001f260: 656c 662e 705b 2270 6f73 6974 696f 6e73  elf.p["positions
+0001f270: 225d 0a0a 2020 2020 2020 2020 666f 7220  "]..        for 
+0001f280: 6d2c 2072 3220 696e 207a 6970 2864 6d2c  m, r2 in zip(dm,
+0001f290: 2064 7029 3a0a 2020 2020 2020 2020 2020   dp):.          
+0001f2a0: 2020 6120 3d20 7232 202d 2072 310a 2020    a = r2 - r1.  
+0001f2b0: 2020 2020 2020 2020 2020 6e6f 726d 5f61            norm_a
+0001f2c0: 203d 206e 702e 6c69 6e61 6c67 2e6e 6f72   = np.linalg.nor
+0001f2d0: 6d28 612c 2061 7869 733d 3129 5b3a 2c20  m(a, axis=1)[:, 
+0001f2e0: 4e6f 6e65 5d0a 0a20 2020 2020 2020 2020  None]..         
+0001f2f0: 2020 2023 206e 6f72 6d5f 7231 203d 206e     # norm_r1 = n
+0001f300: 702e 6c69 6e61 6c67 2e6e 6f72 6d28 7231  p.linalg.norm(r1
+0001f310: 2c20 6178 6973 3d31 295b 3a2c 204e 6f6e  , axis=1)[:, Non
+0001f320: 655d 0a20 2020 2020 2020 2020 2020 206e  e].            n
+0001f330: 6f72 6d5f 7232 203d 206e 702e 6c69 6e61  orm_r2 = np.lina
+0001f340: 6c67 2e6e 6f72 6d28 7232 290a 0a20 2020  lg.norm(r2)..   
+0001f350: 2020 2020 2020 2020 2072 325f 646f 745f           r2_dot_
+0001f360: 6120 3d20 6e70 2e73 756d 2872 3220 2a20  a = np.sum(r2 * 
+0001f370: 612c 2061 7869 733d 3129 5b3a 2c20 4e6f  a, axis=1)[:, No
+0001f380: 6e65 5d0a 2020 2020 2020 2020 2020 2020  ne].            
+0001f390: 6620 3d20 6e6f 726d 5f61 202a 2028 6e6f  f = norm_a * (no
+0001f3a0: 726d 5f72 3220 2a20 6e6f 726d 5f61 202b  rm_r2 * norm_a +
+0001f3b0: 2072 325f 646f 745f 6129 0a20 2020 2020   r2_dot_a).     
+0001f3c0: 2020 2020 2020 2067 7261 645f 6620 3d20         grad_f = 
+0001f3d0: 286e 6f72 6d5f 6120 2a2a 2032 202f 206e  (norm_a ** 2 / n
+0001f3e0: 6f72 6d5f 7232 202b 2032 202a 206e 6f72  orm_r2 + 2 * nor
+0001f3f0: 6d5f 6120 2b20 3220 2a20 6e6f 726d 5f72  m_a + 2 * norm_r
+0001f400: 3220 2b20 7232 5f64 6f74 5f61 202f 206e  2 + r2_dot_a / n
+0001f410: 6f72 6d5f 6129 202a 2072 3220 2d20 5c0a  orm_a) * r2 - \.
+0001f420: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f430: 2020 2020 2028 6e6f 726d 5f61 202b 2032       (norm_a + 2
+0001f440: 202a 206e 6f72 6d5f 7232 202b 2072 325f   * norm_r2 + r2_
+0001f450: 646f 745f 6120 2f20 6e6f 726d 5f61 2920  dot_a / norm_a) 
+0001f460: 2a20 7231 0a20 2020 2020 2020 2020 2020  * r1.           
+0001f470: 2065 202b 3d20 2d73 656c 662e 705b 2264   e += -self.p["d
+0001f480: 6964 7422 5d20 2a20 6d75 305f 3470 6920  idt"] * mu0_4pi 
+0001f490: 2f20 6620 2a2a 2032 202a 2028 0a20 2020  / f ** 2 * (.   
+0001f4a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f4b0: 2066 202a 206e 702e 6372 6f73 7328 7231   f * np.cross(r1
+0001f4c0: 2c20 6d29 202d 206e 702e 6372 6f73 7328  , m) - np.cross(
+0001f4d0: 6e70 2e73 756d 286d 202a 2067 7261 645f  np.sum(m * grad_
+0001f4e0: 662c 2061 7869 733d 3129 5b3a 2c20 4e6f  f, axis=1)[:, No
+0001f4f0: 6e65 5d20 2a20 7231 2c20 7232 2929 0a0a  ne] * r1, r2))..
+0001f500: 2020 2020 2020 2020 6520 3d20 652e 666c          e = e.fl
+0001f510: 6174 7465 6e28 295b 6e70 2e6e 6577 6178  atten()[np.newax
+0001f520: 6973 2c20 3a5d 0a0a 2020 2020 2020 2020  is, :]..        
+0001f530: 7265 7475 726e 2065 0a0a 0a63 6c61 7373  return e...class
+0001f540: 2050 6f74 656e 7469 616c 4469 706f 6c65   PotentialDipole
+0001f550: 334c 6179 6572 7328 4162 7374 7261 6374  3Layers(Abstract
+0001f560: 4d6f 6465 6c29 3a0a 2020 2020 2222 220a  Model):.    """.
+0001f570: 2020 2020 4361 6c63 756c 6174 6573 2074      Calculates t
+0001f580: 6865 2065 6c65 6374 7269 6320 706f 7465  he electric pote
+0001f590: 6e74 6961 6c20 696e 2061 2033 2d6c 6179  ntial in a 3-lay
+0001f5a0: 6572 6564 2073 7068 6572 6520 6361 7573  ered sphere caus
+0001f5b0: 6564 2062 7920 6120 6469 706f 6c65 2061  ed by a dipole a
+0001f5c0: 6674 6572 2041 7279 2065 7420 616c 2e20  fter Ary et al. 
+0001f5d0: 2831 3938 3129 2e0a 0a20 2020 2050 6172  (1981)...    Par
+0001f5e0: 616d 6574 6572 730a 2020 2020 2d2d 2d2d  ameters.    ----
+0001f5f0: 2d2d 2d2d 2d2d 0a20 2020 2070 5b22 7261  ------.    p["ra
+0001f600: 6469 6922 5d3a 206c 6973 7420 5b33 5d0a  dii"]: list [3].
+0001f610: 2020 2020 2020 2020 5261 6469 7573 206f          Radius o
+0001f620: 6620 6561 6368 206f 6620 7468 6520 3320  f each of the 3 
+0001f630: 6c61 7965 7273 2028 696e 6e65 726d 6f73  layers (innermos
+0001f640: 7420 746f 206f 7574 6572 6d6f 7374 2920  t to outermost) 
+0001f650: 696e 2028 6d6d 290a 2020 2020 705b 2263  in (mm).    p["c
+0001f660: 6f6e 645f 6272 6169 6e5f 7363 616c 7022  ond_brain_scalp"
+0001f670: 5d3a 2066 6c6f 6174 0a20 2020 2020 2020  ]: float.       
+0001f680: 2043 6f6e 6475 6374 6976 6974 7920 6f66   Conductivity of
+0001f690: 2074 6865 2062 7261 696e 2061 6e64 2073   the brain and s
+0001f6a0: 6361 6c70 206c 6179 6572 7320 696e 2028  calp layers in (
+0001f6b0: 532f 6d29 0a20 2020 2070 5b22 636f 6e64  S/m).    p["cond
+0001f6c0: 5f73 6b75 6c6c 225d 3a20 666c 6f61 740a  _skull"]: float.
+0001f6d0: 2020 2020 2020 2020 436f 6e64 7563 7469          Conducti
+0001f6e0: 7669 7479 206f 6620 7468 6520 736b 756c  vity of the skul
+0001f6f0: 6c20 6c61 7965 7220 696e 2028 532f 6d29  l layer in (S/m)
+0001f700: 0a20 2020 2070 5b22 6469 706f 6c65 5f70  .    p["dipole_p
+0001f710: 6f73 225d 3a20 6e64 6172 7261 7920 6f66  os"]: ndarray of
+0001f720: 2066 6c6f 6174 205b 3320 7820 315d 0a20   float [3 x 1]. 
+0001f730: 2020 2020 2020 2050 6f73 6974 696f 6e20         Position 
+0001f740: 6f66 2074 6865 2064 6970 6f6c 652c 2069  of the dipole, i
+0001f750: 6e20 286d 6d29 0a20 2020 2070 5b22 6469  n (mm).    p["di
+0001f760: 706f 6c65 5f6d 6f6d 656e 7422 5d3a 206e  pole_moment"]: n
+0001f770: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+0001f780: 5b33 2078 2031 5d0a 2020 2020 2020 2020  [3 x 1].        
+0001f790: 4d6f 6d65 6e74 206f 6620 6469 706f 6c65  Moment of dipole
+0001f7a0: 2c20 696e 2028 436d 290a 2020 2020 705b  , in (Cm).    p[
+0001f7b0: 2273 7572 6661 6365 5f70 6f69 6e74 7322  "surface_points"
+0001f7c0: 5d3a 206e 6461 7272 6179 206f 6620 666c  ]: ndarray of fl
+0001f7d0: 6f61 7420 5b4e 2078 2033 5d0a 2020 2020  oat [N x 3].    
+0001f7e0: 2020 2020 4c69 7374 206f 6620 706f 7369      List of posi
+0001f7f0: 7469 6f6e 7320 7768 6572 6520 7468 6520  tions where the 
+0001f800: 706f 7465 6e74 6961 6c20 7368 6f75 6c64  potential should
+0001f810: 2062 6520 6361 6c63 756c 6174 6564 2069   be calculated i
+0001f820: 6e20 286d 6d29 0a0a 2020 2020 5265 7475  n (mm)..    Retu
+0001f830: 726e 730a 2020 2020 2d2d 2d2d 2d2d 2d0a  rns.    -------.
+0001f840: 2020 2020 706f 7465 6e74 6961 6c3a 206e      potential: n
+0001f850: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+0001f860: 5b31 2078 206e 5f6f 7574 5d0a 2020 2020  [1 x n_out].    
+0001f870: 2020 2020 5661 6c75 6573 206f 6620 7468      Values of th
+0001f880: 6520 656c 6563 7472 6963 2070 6f74 656e  e electric poten
+0001f890: 7469 616c 2c20 696e 2028 5629 0a0a 2020  tial, in (V)..  
+0001f8a0: 2020 4e6f 7465 730a 2020 2020 2d2d 2d2d    Notes.    ----
+0001f8b0: 2d0a 2020 2020 2e2e 205b 315d 2041 7279  -.    .. [1] Ary
+0001f8c0: 2c20 4a2e 2050 2e2c 204b 6c65 696e 2c20  , J. P., Klein, 
+0001f8d0: 532e 2041 2e2c 2026 2046 656e 6465 722c  S. A., & Fender,
+0001f8e0: 2044 2e20 482e 2028 3139 3831 292e 204c   D. H. (1981). L
+0001f8f0: 6f63 6174 696f 6e20 6f66 2073 6f75 7263  ocation of sourc
+0001f900: 6573 206f 6620 6576 6f6b 6564 2073 6361  es of evoked sca
+0001f910: 6c70 2070 6f74 656e 7469 616c 733a 0a20  lp potentials:. 
+0001f920: 2020 2020 2020 636f 7272 6563 7469 6f6e        correction
+0001f930: 7320 666f 7220 736b 756c 6c20 616e 6420  s for skull and 
+0001f940: 7363 616c 7020 7468 6963 6b6e 6573 7365  scalp thicknesse
+0001f950: 732e 2049 4545 4520 5472 616e 7361 6374  s. IEEE Transact
+0001f960: 696f 6e73 206f 6e20 4269 6f6d 6564 6963  ions on Biomedic
+0001f970: 616c 2045 6e67 696e 6565 7269 6e67 2c20  al Engineering, 
+0001f980: 2836 292c 2034 3437 2d34 3532 2e0a 2020  (6), 447-452..  
+0001f990: 2020 2020 2065 712e 2032 2061 6e64 2032       eq. 2 and 2
+0001f9a0: 610a 2020 2020 2222 220a 0a20 2020 2064  a.    """..    d
+0001f9b0: 6566 205f 5f69 6e69 745f 5f28 7365 6c66  ef __init__(self
+0001f9c0: 2c20 6d61 746c 6162 5f6d 6f64 656c 3d46  , matlab_model=F
+0001f9d0: 616c 7365 293a 0a20 2020 2020 2020 2073  alse):.        s
+0001f9e0: 7570 6572 2874 7970 6528 7365 6c66 292c  uper(type(self),
+0001f9f0: 2073 656c 6629 2e5f 5f69 6e69 745f 5f28   self).__init__(
+0001fa00: 6d61 746c 6162 5f6d 6f64 656c 3d6d 6174  matlab_model=mat
+0001fa10: 6c61 625f 6d6f 6465 6c29 0a20 2020 2020  lab_model).     
+0001fa20: 2020 2073 656c 662e 666e 616d 6520 3d20     self.fname = 
+0001fa30: 696e 7370 6563 742e 6765 7466 696c 6528  inspect.getfile(
+0001fa40: 696e 7370 6563 742e 6375 7272 656e 7466  inspect.currentf
+0001fa50: 7261 6d65 2829 290a 0a20 2020 2064 6566  rame())..    def
+0001fa60: 2076 616c 6964 6174 6528 7365 6c66 293a   validate(self):
+0001fa70: 0a20 2020 2020 2020 2070 6173 730a 0a20  .        pass.. 
+0001fa80: 2020 2064 6566 2073 696d 756c 6174 6528     def simulate(
+0001fa90: 7365 6c66 2c20 7072 6f63 6573 735f 6964  self, process_id
+0001faa0: 3d4e 6f6e 652c 206d 6174 6c61 625f 656e  =None, matlab_en
+0001fab0: 6769 6e65 3d4e 6f6e 6529 3a0a 0a20 2020  gine=None):..   
+0001fac0: 2020 2020 2061 7373 6572 7420 6c65 6e28       assert len(
+0001fad0: 7365 6c66 2e70 5b22 7261 6469 6922 5d29  self.p["radii"])
+0001fae0: 203d 3d20 330a 2020 2020 2020 2020 6173   == 3.        as
+0001faf0: 7365 7274 2073 656c 662e 705b 2272 6164  sert self.p["rad
+0001fb00: 6969 225d 5b30 5d20 3c20 7365 6c66 2e70  ii"][0] < self.p
+0001fb10: 5b22 7261 6469 6922 5d5b 315d 203c 2073  ["radii"][1] < s
+0001fb20: 656c 662e 705b 2272 6164 6969 225d 5b32  elf.p["radii"][2
+0001fb30: 5d0a 2020 2020 2020 2020 6173 7365 7274  ].        assert
+0001fb40: 206c 656e 2873 656c 662e 705b 2264 6970   len(self.p["dip
+0001fb50: 6f6c 655f 6d6f 6d65 6e74 225d 2920 3d3d  ole_moment"]) ==
+0001fb60: 2033 0a20 2020 2020 2020 2061 7373 6572   3.        asser
+0001fb70: 7420 6c65 6e28 7365 6c66 2e70 5b22 6469  t len(self.p["di
+0001fb80: 706f 6c65 5f70 6f73 225d 2920 3d3d 2033  pole_pos"]) == 3
+0001fb90: 0a20 2020 2020 2020 2061 7373 6572 7420  .        assert 
+0001fba0: 7365 6c66 2e70 5b22 7375 7266 6163 655f  self.p["surface_
+0001fbb0: 706f 696e 7473 225d 2e73 6861 7065 5b31  points"].shape[1
+0001fbc0: 5d20 3d3d 2033 0a20 2020 2020 2020 2061  ] == 3.        a
+0001fbd0: 7373 6572 7420 6e70 2e6c 696e 616c 672e  ssert np.linalg.
+0001fbe0: 6e6f 726d 2873 656c 662e 705b 2264 6970  norm(self.p["dip
+0001fbf0: 6f6c 655f 706f 7322 5d29 203c 2073 656c  ole_pos"]) < sel
+0001fc00: 662e 705b 2272 6164 6969 225d 5b30 5d2c  f.p["radii"][0],
+0001fc10: 2022 4469 706f 6c65 206d 7573 7420 6265   "Dipole must be
+0001fc20: 2069 6e73 6964 6520 696e 6e65 7220 7370   inside inner sp
+0001fc30: 6865 7265 220a 0a20 2020 2020 2020 2078  here"..        x
+0001fc40: 6920 3d20 666c 6f61 7428 7365 6c66 2e70  i = float(self.p
+0001fc50: 5b22 636f 6e64 5f73 6b75 6c6c 225d 2920  ["cond_skull"]) 
+0001fc60: 2f20 666c 6f61 7428 7365 6c66 2e70 5b22  / float(self.p["
+0001fc70: 636f 6e64 5f62 7261 696e 5f73 6361 6c70  cond_brain_scalp
+0001fc80: 225d 290a 2020 2020 2020 2020 7220 3d20  "]).        r = 
+0001fc90: 666c 6f61 7428 7365 6c66 2e70 5b22 7261  float(self.p["ra
+0001fca0: 6469 6922 5d5b 325d 202a 2031 652d 3329  dii"][2] * 1e-3)
+0001fcb0: 0a20 2020 2020 2020 2066 3120 3d20 666c  .        f1 = fl
+0001fcc0: 6f61 7428 7365 6c66 2e70 5b22 7261 6469  oat(self.p["radi
+0001fcd0: 6922 5d5b 305d 202a 2031 652d 3329 202f  i"][0] * 1e-3) /
+0001fce0: 2072 0a20 2020 2020 2020 2066 3220 3d20   r.        f2 = 
+0001fcf0: 666c 6f61 7428 7365 6c66 2e70 5b22 7261  float(self.p["ra
+0001fd00: 6469 6922 5d5b 315d 202a 2031 652d 3329  dii"][1] * 1e-3)
+0001fd10: 202f 2072 0a20 2020 2020 2020 2062 203d   / r.        b =
+0001fd20: 206e 702e 6c69 6e61 6c67 2e6e 6f72 6d28   np.linalg.norm(
+0001fd30: 7365 6c66 2e70 5b22 6469 706f 6c65 5f70  self.p["dipole_p
+0001fd40: 6f73 225d 2920 2a20 3165 2d33 202f 2072  os"]) * 1e-3 / r
+0001fd50: 0a0a 2020 2020 2020 2020 6966 206e 6f74  ..        if not
+0001fd60: 206e 702e 616c 6c63 6c6f 7365 286e 702e   np.allclose(np.
+0001fd70: 6c69 6e61 6c67 2e6e 6f72 6d28 7365 6c66  linalg.norm(self
+0001fd80: 2e70 5b22 7375 7266 6163 655f 706f 696e  .p["surface_poin
+0001fd90: 7473 225d 2c20 6178 6973 3d31 292c 2072  ts"], axis=1), r
+0001fda0: 202a 2031 6533 293a 0a20 2020 2020 2020   * 1e3):.       
+0001fdb0: 2020 2020 2077 6172 6e69 6e67 732e 7761       warnings.wa
+0001fdc0: 726e 2827 536f 6d65 2070 6f69 6e74 7320  rn('Some points 
+0001fdd0: 6172 6520 6e6f 7420 696e 2074 6865 2073  are not in the s
+0001fde0: 7572 6661 6365 2121 2729 0a0a 2020 2020  urface!!')..    
+0001fdf0: 2020 2020 6966 206e 702e 6973 636c 6f73      if np.isclos
+0001fe00: 6528 622c 2030 293a 0a20 2020 2020 2020  e(b, 0):.       
+0001fe10: 2020 2020 2072 5f64 6972 203d 206e 702e       r_dir = np.
+0001fe20: 6172 7261 7928 7365 6c66 2e70 5b22 6469  array(self.p["di
+0001fe30: 706f 6c65 5f6d 6f6d 656e 7422 5d2c 2064  pole_moment"], d
+0001fe40: 7479 7065 3d66 6c6f 6174 290a 2020 2020  type=float).    
+0001fe50: 2020 2020 2020 2020 725f 6469 7220 2f3d          r_dir /=
+0001fe60: 206e 702e 6c69 6e61 6c67 2e6e 6f72 6d28   np.linalg.norm(
+0001fe70: 725f 6469 7229 0a20 2020 2020 2020 2065  r_dir).        e
+0001fe80: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+0001fe90: 2072 5f64 6972 203d 2073 656c 662e 705b   r_dir = self.p[
+0001fea0: 2264 6970 6f6c 655f 706f 7322 5d20 2f20  "dipole_pos"] / 
+0001feb0: 6e70 2e6c 696e 616c 672e 6e6f 726d 2873  np.linalg.norm(s
+0001fec0: 656c 662e 705b 2264 6970 6f6c 655f 706f  elf.p["dipole_po
+0001fed0: 7322 5d29 0a0a 2020 2020 2020 2020 6d5f  s"])..        m_
+0001fee0: 7220 3d20 6e70 2e64 6f74 2873 656c 662e  r = np.dot(self.
+0001fef0: 705b 2264 6970 6f6c 655f 6d6f 6d65 6e74  p["dipole_moment
+0001ff00: 225d 2c20 725f 6469 7229 0a20 2020 2020  "], r_dir).     
+0001ff10: 2020 2063 6f73 5f61 6c70 6861 203d 2073     cos_alpha = s
+0001ff20: 656c 662e 705b 2273 7572 6661 6365 5f70  elf.p["surface_p
+0001ff30: 6f69 6e74 7322 5d2e 646f 7428 725f 6469  oints"].dot(r_di
+0001ff40: 7229 202f 2072 202a 2031 652d 330a 0a20  r) / r * 1e-3.. 
+0001ff50: 2020 2020 2020 2074 5f64 6972 203d 2073         t_dir = s
+0001ff60: 656c 662e 705b 2264 6970 6f6c 655f 6d6f  elf.p["dipole_mo
+0001ff70: 6d65 6e74 225d 202d 206d 5f72 202a 2072  ment"] - m_r * r
+0001ff80: 5f64 6972 0a0a 2020 2020 2020 2020 2320  _dir..        # 
+0001ff90: 6966 2074 6865 2064 6970 6f6c 6520 6973  if the dipole is
+0001ffa0: 2072 6164 6961 6c20 6f6e 6c79 0a20 2020   radial only.   
+0001ffb0: 2020 2020 2069 6620 6e70 2e69 7363 6c6f       if np.isclo
+0001ffc0: 7365 286e 702e 6c69 6e61 6c67 2e6e 6f72  se(np.linalg.nor
+0001ffd0: 6d28 7365 6c66 2e70 5b22 6469 706f 6c65  m(self.p["dipole
+0001ffe0: 5f6d 6f6d 656e 7422 5d29 2c20 6e70 2e61  _moment"]), np.a
+0001fff0: 6273 286e 702e 646f 7428 725f 6469 722c  bs(np.dot(r_dir,
+00020000: 2073 656c 662e 705b 2264 6970 6f6c 655f   self.p["dipole_
+00020010: 6d6f 6d65 6e74 225d 2929 293a 0a20 2020  moment"]))):.   
+00020020: 2020 2020 2020 2020 2023 2074 7279 2074           # try t
+00020030: 6f20 7365 7420 616e 2061 7869 7320 696e  o set an axis in
+00020040: 2078 2c20 6966 2074 6865 2064 6970 6f6c   x, if the dipol
+00020050: 6520 6973 206e 6f74 2069 6e20 780a 2020  e is not in x.  
+00020060: 2020 2020 2020 2020 2020 6966 206e 6f74            if not
+00020070: 206e 702e 616c 6c63 6c6f 7365 286e 702e   np.allclose(np.
+00020080: 6162 7328 725f 6469 722e 646f 7428 5b31  abs(r_dir.dot([1
+00020090: 2c20 302c 2030 5d29 292c 2031 293a 0a20  , 0, 0])), 1):. 
+000200a0: 2020 2020 2020 2020 2020 2020 2020 2074                 t
+000200b0: 5f64 6972 203d 206e 702e 6172 7261 7928  _dir = np.array(
+000200c0: 5b31 2e2c 2030 2e2c 2030 2e5d 2c20 6474  [1., 0., 0.], dt
+000200d0: 7970 653d 666c 6f61 7429 0a20 2020 2020  ype=float).     
+000200e0: 2020 2020 2020 2023 206f 7468 6572 7769         # otherwi
+000200f0: 7365 2c20 7365 7420 6974 2069 6e20 790a  se, set it in y.
+00020100: 2020 2020 2020 2020 2020 2020 656c 7365              else
+00020110: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00020120: 2020 745f 6469 7220 3d20 6e70 2e61 7272    t_dir = np.arr
+00020130: 6179 285b 302e 2c20 312e 2c20 302e 5d2c  ay([0., 1., 0.],
+00020140: 2064 7479 7065 3d66 6c6f 6174 290a 2020   dtype=float).  
+00020150: 2020 2020 2020 2020 2020 745f 6469 7220            t_dir 
+00020160: 3d20 745f 6469 7220 2d20 725f 6469 722e  = t_dir - r_dir.
+00020170: 646f 7428 745f 6469 7229 0a0a 2020 2020  dot(t_dir)..    
+00020180: 2020 2020 745f 6469 7220 2f3d 206e 702e      t_dir /= np.
+00020190: 6c69 6e61 6c67 2e6e 6f72 6d28 745f 6469  linalg.norm(t_di
+000201a0: 7229 0a20 2020 2020 2020 2074 325f 6469  r).        t2_di
+000201b0: 7220 3d20 6e70 2e63 726f 7373 2872 5f64  r = np.cross(r_d
+000201c0: 6972 2c20 745f 6469 7229 0a20 2020 2020  ir, t_dir).     
+000201d0: 2020 206d 5f74 203d 206e 702e 646f 7428     m_t = np.dot(
+000201e0: 7365 6c66 2e70 5b22 6469 706f 6c65 5f6d  self.p["dipole_m
+000201f0: 6f6d 656e 7422 5d2c 2074 5f64 6972 290a  oment"], t_dir).
+00020200: 2020 2020 2020 2020 6265 7461 203d 206e          beta = n
+00020210: 702e 6172 6374 616e 3228 7365 6c66 2e70  p.arctan2(self.p
+00020220: 5b22 7375 7266 6163 655f 706f 696e 7473  ["surface_points
+00020230: 225d 2e64 6f74 2874 325f 6469 7229 2c20  "].dot(t2_dir), 
+00020240: 7365 6c66 2e70 5b22 7375 7266 6163 655f  self.p["surface_
+00020250: 706f 696e 7473 225d 2e64 6f74 2874 5f64  points"].dot(t_d
+00020260: 6972 2929 0a20 2020 2020 2020 2063 6f73  ir)).        cos
+00020270: 5f62 6574 6120 3d20 6e70 2e63 6f73 2862  _beta = np.cos(b
+00020280: 6574 6129 0a0a 2020 2020 2020 2020 6465  eta)..        de
+00020290: 6620 6428 6e29 3a0a 2020 2020 2020 2020  f d(n):.        
+000202a0: 2020 2020 645f 6e20 3d20 2828 6e20 2b20      d_n = ((n + 
+000202b0: 3129 202a 2078 6920 2b20 6e29 202a 2028  1) * xi + n) * (
+000202c0: 286e 202a 2078 6929 202f 2028 6e20 2b20  (n * xi) / (n + 
+000202d0: 3129 202b 2031 2920 2b20 5c0a 2020 2020  1) + 1) + \.    
+000202e0: 2020 2020 2020 2020 2020 2020 2020 2831                (1
+000202f0: 202d 2078 6929 202a 2028 286e 202b 2031   - xi) * ((n + 1
+00020300: 2920 2a20 7869 202b 206e 2920 2a20 2866  ) * xi + n) * (f
+00020310: 3120 2a2a 2028 3220 2a20 6e20 2b20 3129  1 ** (2 * n + 1)
+00020320: 202d 2066 3220 2a2a 2028 3220 2a20 6e20   - f2 ** (2 * n 
+00020330: 2b20 3129 2920 2d20 5c0a 2020 2020 2020  + 1)) - \.      
+00020340: 2020 2020 2020 2020 2020 2020 6e20 2a20              n * 
+00020350: 2831 202d 2078 6929 202a 2a20 3220 2a20  (1 - xi) ** 2 * 
+00020360: 2866 3120 2f20 6632 2920 2a2a 2028 3220  (f1 / f2) ** (2 
+00020370: 2a20 6e20 2b20 3129 0a20 2020 2020 2020  * n + 1).       
+00020380: 2020 2020 2072 6574 7572 6e20 645f 6e0a       return d_n.
+00020390: 0a20 2020 2020 2020 2070 6f74 656e 7469  .        potenti
+000203a0: 616c 203d 206e 702e 7a65 726f 7328 7365  al = np.zeros(se
+000203b0: 6c66 2e70 5b22 7375 7266 6163 655f 706f  lf.p["surface_po
+000203c0: 696e 7473 225d 2e73 6861 7065 5b30 5d2c  ints"].shape[0],
+000203d0: 2064 7479 7065 3d27 666c 6f61 7436 3427   dtype='float64'
+000203e0: 290a 0a20 2020 2020 2020 2070 203d 206e  )..        p = n
+000203f0: 702e 7a65 726f 7328 2832 2c20 7365 6c66  p.zeros((2, self
+00020400: 2e6e 6272 5f70 6f6c 796e 6f6d 6961 6c73  .nbr_polynomials
+00020410: 202b 2031 2c20 7365 6c66 2e70 5b22 7375   + 1, self.p["su
+00020420: 7266 6163 655f 706f 696e 7473 225d 2e73  rface_points"].s
+00020430: 6861 7065 5b30 5d29 2c20 6474 7970 653d  hape[0]), dtype=
+00020440: 2766 6c6f 6174 3634 2729 0a0a 2020 2020  'float64')..    
+00020450: 2020 2020 666f 7220 6969 2c20 6361 2069      for ii, ca i
+00020460: 6e20 656e 756d 6572 6174 6528 636f 735f  n enumerate(cos_
+00020470: 616c 7068 6129 3a0a 2020 2020 2020 2020  alpha):.        
+00020480: 2020 2020 705b 3a2c 203a 2c20 6969 5d2c      p[:, :, ii],
+00020490: 205f 203d 2073 6369 7079 2e73 7065 6369   _ = scipy.speci
+000204a0: 616c 2e6c 706d 6e28 312c 2073 656c 662e  al.lpmn(1, self.
+000204b0: 6e62 725f 706f 6c79 6e6f 6d69 616c 732c  nbr_polynomials,
+000204c0: 2063 6129 0a0a 2020 2020 2020 2020 666f   ca)..        fo
+000204d0: 7220 6969 2069 6e20 7261 6e67 6528 312c  r ii in range(1,
+000204e0: 2073 656c 662e 6e62 725f 706f 6c79 6e6f   self.nbr_polyno
+000204f0: 6d69 616c 7320 2b20 3129 3a0a 2020 2020  mials + 1):.    
+00020500: 2020 2020 2020 2020 6e69 203d 2066 6c6f          ni = flo
+00020510: 6174 2869 6929 0a20 2020 2020 2020 2020  at(ii).         
+00020520: 2020 2070 6f74 656e 7469 616c 202b 3d20     potential += 
+00020530: 6e70 2e6e 616e 5f74 6f5f 6e75 6d28 0a20  np.nan_to_num(. 
+00020540: 2020 2020 2020 2020 2020 2020 2020 2028                 (
+00020550: 3220 2a20 6e69 202b 2031 2920 2f20 6e69  2 * ni + 1) / ni
+00020560: 202a 2062 202a 2a20 286e 6920 2d20 3129   * b ** (ni - 1)
+00020570: 202a 2028 2878 6920 2a20 2832 202a 206e   * ((xi * (2 * n
+00020580: 6920 2b20 3129 202a 2a20 3229 202f 2028  i + 1) ** 2) / (
+00020590: 6428 6e69 2920 2a20 286e 6920 2b20 3129  d(ni) * (ni + 1)
+000205a0: 2929 202a 0a20 2020 2020 2020 2020 2020  )) *.           
+000205b0: 2020 2020 2028 6e69 202a 206d 5f72 202a       (ni * m_r *
+000205c0: 2070 5b30 2c20 6969 2c20 3a5d 202d 206d   p[0, ii, :] - m
+000205d0: 5f74 202a 2070 5b31 2c20 6969 2c20 3a5d  _t * p[1, ii, :]
+000205e0: 202a 2063 6f73 5f62 6574 6129 290a 0a20   * cos_beta)).. 
+000205f0: 2020 2020 2020 2070 6f74 656e 7469 616c         potential
+00020600: 202f 3d20 3420 2a20 6e70 2e70 6920 2a20   /= 4 * np.pi * 
+00020610: 7365 6c66 2e70 5b22 636f 6e64 5f62 7261  self.p["cond_bra
+00020620: 696e 5f73 6361 6c70 225d 202a 2072 202a  in_scalp"] * r *
+00020630: 2a20 320a 0a20 2020 2020 2020 2070 6f74  * 2..        pot
+00020640: 656e 7469 616c 203d 2070 6f74 656e 7469  ential = potenti
+00020650: 616c 5b6e 702e 6e65 7761 7869 732c 203a  al[np.newaxis, :
+00020660: 5d0a 0a20 2020 2020 2020 2072 6574 7572  ]..        retur
+00020670: 6e20 706f 7465 6e74 6961 6c0a 0a0a 636c  n potential...cl
+00020680: 6173 7320 456c 6563 7472 6f64 654d 6f64  ass ElectrodeMod
+00020690: 656c 2841 6273 7472 6163 744d 6f64 656c  el(AbstractModel
+000206a0: 293a 0a20 2020 2022 2222 0a20 2020 204d  ):.    """.    M
+000206b0: 6f64 6966 6965 6420 7665 7273 696f 6e20  odified version 
+000206c0: 6f66 2052 616e 646c 6573 2063 6972 6375  of Randles circu
+000206d0: 6974 2e0a 2020 2020 5468 6973 2063 6972  it..    This cir
+000206e0: 6375 6974 2069 7320 7573 6564 2074 6f20  cuit is used to 
+000206f0: 6d6f 6465 6c20 7468 6520 696d 7065 6461  model the impeda
+00020700: 6e63 6520 6f66 2061 6e20 696e 6572 7420  nce of an inert 
+00020710: 656c 6563 7472 6f64 6520 696e 2061 6e20  electrode in an 
+00020720: 656c 6563 7472 6f6c 7974 6520 7769 7468  electrolyte with
+00020730: 2061 2066 696e 6974 6520 5761 7262 7572   a finite Warbur
+00020740: 6720 6c61 7965 722e 0a20 2020 2043 6972  g layer..    Cir
+00020750: 6375 6974 3a20 2d52 732d 2851 2852 6374  cuit: -Rs-(Q(Rct
+00020760: 2d28 5752 7729 2929 2d0a 0a20 2020 2050  -(WRw)))-..    P
+00020770: 6172 616d 6574 6572 730a 2020 2020 2d2d  arameters.    --
+00020780: 2d2d 2d2d 2d2d 2d2d 0a20 2020 2070 5b22  --------.    p["
+00020790: 6e5f 5164 6c22 5d3a 2066 6c6f 6174 206f  n_Qdl"]: float o
+000207a0: 7220 6e64 6172 7261 7920 6f66 2066 6c6f  r ndarray of flo
+000207b0: 6174 205b 6e5f 6772 6964 5d0a 2020 2020  at [n_grid].    
+000207c0: 2020 2020 4669 7273 7420 7061 7261 6d65      First parame
+000207d0: 7465 7220 6465 6669 6e65 6420 696e 205b  ter defined in [
+000207e0: 302c 2049 6e66 5d0a 2020 2020 705b 2251  0, Inf].    p["Q
+000207f0: 646c 225d 3a20 666c 6f61 7420 6f72 206e  dl"]: float or n
+00020800: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+00020810: 5b6e 5f67 7269 645d 0a20 2020 2020 2020  [n_grid].       
+00020820: 2053 6563 6f6e 6420 7061 7261 6d65 7465   Second paramete
+00020830: 7220 6465 6669 6e65 6420 696e 205b 302c  r defined in [0,
+00020840: 2031 5d0a 2020 2020 705b 226e 5f51 6422   1].    p["n_Qd"
+00020850: 5d3a 2066 6c6f 6174 206f 7220 6e64 6172  ]: float or ndar
+00020860: 7261 7920 6f66 2066 6c6f 6174 205b 6e5f  ray of float [n_
+00020870: 6772 6964 5d0a 2020 2020 2020 2020 5468  grid].        Th
+00020880: 6972 6420 7061 7261 6d65 7465 7220 6465  ird parameter de
+00020890: 6669 6e65 6420 696e 205b 302c 2049 6e66  fined in [0, Inf
+000208a0: 5d0a 2020 2020 705b 2251 6422 5d3a 2066  ].    p["Qd"]: f
+000208b0: 6c6f 6174 206f 7220 6e64 6172 7261 7920  loat or ndarray 
+000208c0: 6f66 2066 6c6f 6174 205b 6e5f 6772 6964  of float [n_grid
+000208d0: 5d0a 2020 2020 2020 2020 466f 7572 7468  ].        Fourth
+000208e0: 2070 6172 616d 6574 6572 2064 6566 696e   parameter defin
+000208f0: 6564 2069 6e20 5b30 2c20 315d 0a20 2020  ed in [0, 1].   
+00020900: 2070 5b22 5273 225d 3a20 666c 6f61 7420   p["Rs"]: float 
+00020910: 6f72 206e 6461 7272 6179 206f 6620 666c  or ndarray of fl
+00020920: 6f61 7420 5b6e 5f67 7269 645d 0a20 2020  oat [n_grid].   
+00020930: 2020 2020 2046 6966 7468 2070 6172 616d       Fifth param
+00020940: 6574 6572 2064 6566 696e 6564 2069 6e20  eter defined in 
+00020950: 5b30 2c20 496e 665d 0a20 2020 2070 5b22  [0, Inf].    p["
+00020960: 5263 7422 5d3a 2066 6c6f 6174 206f 7220  Rct"]: float or 
+00020970: 6e64 6172 7261 7920 6f66 2066 6c6f 6174  ndarray of float
+00020980: 205b 6e5f 6772 6964 5d0a 2020 2020 2020   [n_grid].      
+00020990: 2020 5369 7874 6820 7061 7261 6d65 7465    Sixth paramete
+000209a0: 7220 6465 6669 6e65 6420 696e 205b 302c  r defined in [0,
+000209b0: 2049 6e66 5d0a 2020 2020 705b 2252 6422   Inf].    p["Rd"
+000209c0: 5d3a 2066 6c6f 6174 206f 7220 6e64 6172  ]: float or ndar
+000209d0: 7261 7920 6f66 2066 6c6f 6174 205b 6e5f  ray of float [n_
+000209e0: 6772 6964 5d0a 2020 2020 2020 2020 5365  grid].        Se
+000209f0: 7665 6e74 6820 7061 7261 6d65 7465 7220  venth parameter 
+00020a00: 6465 6669 6e65 6420 696e 205b 302c 2049  defined in [0, I
+00020a10: 6e66 5d0a 2020 2020 705b 2277 225d 3a20  nf].    p["w"]: 
+00020a20: 666c 6f61 7420 6f72 206e 6461 7272 6179  float or ndarray
+00020a30: 206f 6620 666c 6f61 7420 5b6e 5f77 5d0a   of float [n_w].
+00020a40: 2020 2020 2020 2020 2046 7265 7175 656e           Frequen
+00020a50: 6379 2076 6172 6961 626c 6520 6465 6669  cy variable defi
+00020a60: 6e65 6420 696e 205b 302c 2049 6e66 5d0a  ned in [0, Inf].
+00020a70: 0a0a 2020 2020 5265 7475 726e 730a 2020  ..    Returns.  
+00020a80: 2020 2d2d 2d2d 2d2d 2d0a 2020 2020 5a3a    -------.    Z:
+00020a90: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
+00020aa0: 7420 5b6e 5f67 7269 6420 7820 315d 0a20  t [n_grid x 1]. 
+00020ab0: 2020 2020 2020 204f 7574 7075 740a 2020         Output.  
+00020ac0: 2020 2222 220a 0a20 2020 2064 6566 205f    """..    def _
+00020ad0: 5f69 6e69 745f 5f28 7365 6c66 2c20 6d61  _init__(self, ma
+00020ae0: 746c 6162 5f6d 6f64 656c 3d46 616c 7365  tlab_model=False
+00020af0: 293a 0a20 2020 2020 2020 2073 7570 6572  ):.        super
+00020b00: 2874 7970 6528 7365 6c66 292c 2073 656c  (type(self), sel
+00020b10: 6629 2e5f 5f69 6e69 745f 5f28 6d61 746c  f).__init__(matl
+00020b20: 6162 5f6d 6f64 656c 3d6d 6174 6c61 625f  ab_model=matlab_
+00020b30: 6d6f 6465 6c29 0a20 2020 2020 2020 2073  model).        s
+00020b40: 656c 662e 666e 616d 6520 3d20 696e 7370  elf.fname = insp
+00020b50: 6563 742e 6765 7466 696c 6528 696e 7370  ect.getfile(insp
+00020b60: 6563 742e 6375 7272 656e 7466 7261 6d65  ect.currentframe
+00020b70: 2829 290a 0a20 2020 2064 6566 2076 616c  ())..    def val
+00020b80: 6964 6174 6528 7365 6c66 293a 0a20 2020  idate(self):.   
+00020b90: 2020 2020 2070 6173 730a 0a20 2020 2064       pass..    d
+00020ba0: 6566 2073 696d 756c 6174 6528 7365 6c66  ef simulate(self
+00020bb0: 2c20 7072 6f63 6573 735f 6964 3d4e 6f6e  , process_id=Non
+00020bc0: 652c 206d 6174 6c61 625f 656e 6769 6e65  e, matlab_engine
+00020bd0: 3d4e 6f6e 6529 3a0a 0a20 2020 2020 2020  =None):..       
+00020be0: 2023 205a 203d 2073 656c 662e 705b 2252   # Z = self.p["R
+00020bf0: 7322 5d20 2b20 3120 2f20 2831 202f 2028  s"] + 1 / (1 / (
+00020c00: 3120 2f20 2873 656c 662e 705b 2251 646c  1 / (self.p["Qdl
+00020c10: 225d 202a 2028 7365 6c66 2e70 5b22 7722  "] * (self.p["w"
+00020c20: 5d2e 5420 2a20 316a 2920 2a2a 2073 656c  ].T * 1j) ** sel
+00020c30: 662e 705b 226e 5f51 646c 225d 2929 202b  f.p["n_Qdl"])) +
+00020c40: 0a20 2020 2020 2020 2023 2020 2020 2020  .        #      
+00020c50: 2020 2020 2031 202f 2028 7365 6c66 2e70       1 / (self.p
+00020c60: 5b22 5263 7422 5d20 2b20 3120 2f20 2831  ["Rct"] + 1 / (1
+00020c70: 202f 2028 3120 2f20 2873 656c 662e 705b   / (1 / (self.p[
+00020c80: 2251 6422 5d20 2a20 2873 656c 662e 705b  "Qd"] * (self.p[
+00020c90: 2277 225d 2e54 202a 2031 6a29 202a 2a20  "w"].T * 1j) ** 
+00020ca0: 7365 6c66 2e70 5b22 6e5f 5164 225d 2929  self.p["n_Qd"]))
+00020cb0: 0a20 2020 2020 2020 2023 2020 2020 2020  .        #      
+00020cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020cd0: 2020 2020 2020 2020 2020 2020 2020 202b                 +
+00020ce0: 2031 202f 2073 656c 662e 705b 2252 6422   1 / self.p["Rd"
+00020cf0: 5d29 2929 0a0a 2020 2020 2020 2020 5a20  ])))..        Z 
+00020d00: 3d20 7365 6c66 2e70 5b22 5273 225d 202b  = self.p["Rs"] +
+00020d10: 205c 0a20 2020 2020 2020 2020 2020 2028   \.            (
+00020d20: 2873 656c 662e 705b 2252 6374 225d 202b  (self.p["Rct"] +
+00020d30: 2028 7365 6c66 2e70 5b22 5264 225d 2a31   (self.p["Rd"]*1
+00020d40: 2f28 7365 6c66 2e70 5b22 5164 225d 2a28  /(self.p["Qd"]*(
+00020d50: 316a 2a73 656c 662e 705b 2277 225d 2e54  1j*self.p["w"].T
+00020d60: 292a 2a28 7365 6c66 2e70 5b22 6e5f 5164  )**(self.p["n_Qd
+00020d70: 225d 2929 292f 2873 656c 662e 705b 2252  "])))/(self.p["R
+00020d80: 6422 5d2b 312f 2873 656c 662e 705b 2251  d"]+1/(self.p["Q
+00020d90: 6422 5d2a 2831 6a2a 7365 6c66 2e70 5b22  d"]*(1j*self.p["
+00020da0: 7722 5d2e 5429 2a2a 2873 656c 662e 705b  w"].T)**(self.p[
+00020db0: 226e 5f51 6422 5d29 2929 292a 312f 2873  "n_Qd"]))))*1/(s
+00020dc0: 656c 662e 705b 2251 646c 225d 2a28 316a  elf.p["Qdl"]*(1j
+00020dd0: 2a73 656c 662e 705b 2277 225d 2e54 292a  *self.p["w"].T)*
+00020de0: 2a28 7365 6c66 2e70 5b22 6e5f 5164 6c22  *(self.p["n_Qdl"
+00020df0: 5d29 2929 2f5c 0a20 2020 2020 2020 2020  ])))/\.         
+00020e00: 2020 2028 7365 6c66 2e70 5b22 5263 7422     (self.p["Rct"
+00020e10: 5d20 2b20 2873 656c 662e 705b 2252 6422  ] + (self.p["Rd"
+00020e20: 5d2a 312f 2873 656c 662e 705b 2251 6422  ]*1/(self.p["Qd"
+00020e30: 5d2a 2831 6a2a 7365 6c66 2e70 5b22 7722  ]*(1j*self.p["w"
+00020e40: 5d2e 5429 2a2a 2873 656c 662e 705b 226e  ].T)**(self.p["n
+00020e50: 5f51 6422 5d29 292f 2873 656c 662e 705b  _Qd"]))/(self.p[
+00020e60: 2252 6422 5d2b 312f 2873 656c 662e 705b  "Rd"]+1/(self.p[
+00020e70: 2251 6422 5d2a 2831 6a2a 7365 6c66 2e70  "Qd"]*(1j*self.p
+00020e80: 5b22 7722 5d2e 5429 2a2a 2873 656c 662e  ["w"].T)**(self.
+00020e90: 705b 226e 5f51 6422 5d29 2929 202b 2031  p["n_Qd"]))) + 1
+00020ea0: 2f28 7365 6c66 2e70 5b22 5164 6c22 5d2a  /(self.p["Qdl"]*
+00020eb0: 2831 6a2a 7365 6c66 2e70 5b22 7722 5d2e  (1j*self.p["w"].
+00020ec0: 5429 2a2a 2873 656c 662e 705b 226e 5f51  T)**(self.p["n_Q
+00020ed0: 646c 225d 2929 2929 0a20 2020 2020 2020  dl"])))).       
+00020ee0: 205a 203d 206e 702e 636f 6e63 6174 656e   Z = np.concaten
+00020ef0: 6174 6528 286e 702e 7265 616c 285a 2e54  ate((np.real(Z.T
+00020f00: 292c 206e 702e 696d 6167 285a 2e54 2929  ), np.imag(Z.T))
+00020f10: 2c20 6178 6973 3d31 290a 0a20 2020 2020  , axis=1)..     
+00020f20: 2020 2072 6574 7572 6e20 5a0a 0a0a 636c     return Z...cl
+00020f30: 6173 7320 4c6f 7265 6e7a 5f53 7973 7465  ass Lorenz_Syste
+00020f40: 6d28 4162 7374 7261 6374 4d6f 6465 6c29  m(AbstractModel)
+00020f50: 3a0a 2020 2020 2222 220a 2020 2020 4d6f  :.    """.    Mo
+00020f60: 6465 6c20 666f 7220 7468 6520 4c6f 7265  del for the Lore
+00020f70: 6e7a 2053 7973 7465 6d20 6f66 2064 6966  nz System of dif
+00020f80: 6665 7265 6e74 6961 6c20 6571 7561 7469  ferential equati
+00020f90: 6f6e 732e 2049 7420 6973 206e 6f6e 6c69  ons. It is nonli
+00020fa0: 6e65 6172 2061 6e64 2073 686f 7773 2063  near and shows c
+00020fb0: 6861 6f74 6963 2062 6568 6176 696f 7572  haotic behaviour
+00020fc0: 2073 7065 6369 6669 6361 6c6c 7920 666f   specifically fo
+00020fd0: 720a 2020 2020 7468 6520 7468 7265 6520  r.    the three 
+00020fe0: 7061 7261 6d65 7465 7220 7661 6c75 6573  parameter values
+00020ff0: 2073 6967 6d61 203d 2031 302e 302c 2062   sigma = 10.0, b
+00021000: 6574 6120 3d20 3238 2e30 2061 6e64 2072  eta = 28.0 and r
+00021010: 686f 203d 2038 2e30 2f33 2e30 2e20 5468  ho = 8.0/3.0. Th
+00021020: 6520 6c6f 7265 6e7a 2061 7474 7261 6374  e lorenz attract
+00021030: 6f72 2063 616e 2074 6865 6e20 6265 206f  or can then be o
+00021040: 6273 6572 7665 6420 696e 0a20 2020 2061  bserved in.    a
+00021050: 6e79 2074 6872 6565 2064 696d 656e 7369  ny three dimensi
+00021060: 6f6e 616c 2074 7261 6a65 6374 6f72 792e  onal trajectory.
+00021070: 0a0a 2020 2020 5061 7261 6d65 7465 7273  ..    Parameters
+00021080: 0a20 2020 202d 2d2d 2d2d 2d2d 2d2d 2d0a  .    ----------.
+00021090: 2020 2020 705b 2273 6967 6d61 225d 203a      p["sigma"] :
+000210a0: 2066 6c6f 6174 206f 7220 6e64 6172 7261   float or ndarra
+000210b0: 7920 6f66 2066 6c6f 6174 205b 6e5f 6772  y of float [n_gr
+000210c0: 6964 5d0a 2020 2020 2020 2020 5061 7261  id].        Para
+000210d0: 6d65 7465 7220 6f66 2074 6865 2073 7973  meter of the sys
+000210e0: 7465 6d0a 2020 2020 705b 2262 6574 6122  tem.    p["beta"
+000210f0: 5d20 3a20 666c 6f61 7420 6f72 206e 6461  ] : float or nda
+00021100: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
+00021110: 5f67 7269 645d 0a20 2020 2020 2020 2050  _grid].        P
+00021120: 6172 616d 6574 6572 206f 6620 7468 6520  arameter of the 
+00021130: 7379 7374 656d 0a20 2020 2070 5b22 7268  system.    p["rh
+00021140: 6f22 5d20 3a20 666c 6f61 7420 6f72 206e  o"] : float or n
+00021150: 6461 7272 6179 206f 6620 666c 6f61 7420  darray of float 
+00021160: 5b6e 5f67 7269 645d 0a20 2020 2020 2020  [n_grid].       
+00021170: 2050 6172 616d 6574 6572 206f 6620 7468   Parameter of th
+00021180: 6520 7379 7374 656d 0a20 2020 2070 5b22  e system.    p["
+00021190: 7931 5f30 225d 203a 2066 6c6f 6174 0a20  y1_0"] : float. 
+000211a0: 2020 2020 2020 2069 6e69 7469 616c 2076         initial v
+000211b0: 616c 7565 206f 6620 6669 7273 7420 7661  alue of first va
+000211c0: 7269 6162 6c65 0a20 2020 2070 5b22 7932  riable.    p["y2
+000211d0: 5f30 225d 203a 2066 6c6f 6174 0a20 2020  _0"] : float.   
+000211e0: 2020 2020 2069 6e69 7469 616c 2076 616c       initial val
+000211f0: 7565 206f 6620 7365 636f 6e64 2076 6172  ue of second var
+00021200: 6961 626c 650a 2020 2020 705b 2279 335f  iable.    p["y3_
+00021210: 3022 5d20 3a20 666c 6f61 740a 2020 2020  0"] : float.    
+00021220: 2020 2020 696e 6974 6961 6c20 7661 6c75      initial valu
+00021230: 6520 6f66 2074 6869 7264 2076 6172 6961  e of third varia
+00021240: 626c 650a 2020 2020 705b 2274 5f65 6e64  ble.    p["t_end
+00021250: 225d 203a 2066 6c6f 6174 0a20 2020 2020  "] : float.     
+00021260: 2020 2074 6865 2065 6e64 206f 6620 7468     the end of th
+00021270: 6520 7469 6d65 7370 616e 2066 6f72 2077  e timespan for w
+00021280: 6869 6368 2074 6865 2073 7973 7465 6d20  hich the system 
+00021290: 7769 6c6c 2062 6520 6576 616c 7561 7465  will be evaluate
+000212a0: 640a 2020 2020 705b 2273 7465 705f 7369  d.    p["step_si
+000212b0: 7a65 225d 203a 2066 6c6f 6174 0a20 2020  ze"] : float.   
+000212c0: 2020 2020 2074 6865 2073 7465 7020 7369       the step si
+000212d0: 7a65 2066 6f72 2074 6865 2074 696d 6520  ze for the time 
+000212e0: 696e 6372 656d 656e 7473 2064 7572 696e  increments durin
+000212f0: 6720 7768 6963 6820 7468 6520 7379 7374  g which the syst
+00021300: 656d 2077 696c 6c20 6265 2065 7661 6c75  em will be evalu
+00021310: 6174 6564 0a0a 2020 2020 5265 7475 726e  ated..    Return
+00021320: 730a 2020 2020 2d2d 2d2d 2d2d 2d0a 2020  s.    -------.  
+00021330: 2020 7820 3a20 6e64 6172 7261 7920 6f66    x : ndarray of
+00021340: 2066 6c6f 6174 205b 6e5f 6772 6964 2078   float [n_grid x
+00021350: 206e 5f74 696d 655f 7374 6570 735d 0a20   n_time_steps]. 
+00021360: 2020 2020 2020 2052 6573 756c 7473 206f         Results o
+00021370: 6620 7820 636f 6f72 6469 6e61 7465 206f  f x coordinate o
+00021380: 6620 7468 6520 7379 7374 656d 2069 6e20  f the system in 
+00021390: 7469 6d65 2073 7465 7073 2c20 7468 6520  time steps, the 
+000213a0: 6750 4320 6973 2063 6f6e 6475 6374 6564  gPC is conducted
+000213b0: 2066 6f72 2074 6865 2074 6872 6565 2070   for the three p
+000213c0: 6172 616d 6574 6572 7320 7369 676d 612c  arameters sigma,
+000213d0: 2062 6574 610a 2020 2020 2020 2020 616e   beta.        an
+000213e0: 6420 7268 6f0a 2020 2020 2222 220a 0a20  d rho.    """.. 
+000213f0: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
+00021400: 7365 6c66 293a 0a20 2020 2020 2020 2073  self):.        s
+00021410: 656c 662e 666e 616d 6520 3d20 696e 7370  elf.fname = insp
+00021420: 6563 742e 6765 7466 696c 6528 696e 7370  ect.getfile(insp
+00021430: 6563 742e 6375 7272 656e 7466 7261 6d65  ect.currentframe
+00021440: 2829 290a 0a20 2020 2064 6566 2076 616c  ())..    def val
+00021450: 6964 6174 6528 7365 6c66 293a 0a20 2020  idate(self):.   
+00021460: 2020 2020 2070 6173 730a 0a20 2020 2064       pass..    d
+00021470: 6566 2073 696d 756c 6174 6528 7365 6c66  ef simulate(self
+00021480: 2c20 7072 6f63 6573 735f 6964 3d4e 6f6e  , process_id=Non
+00021490: 652c 206d 6174 6c61 625f 656e 6769 6e65  e, matlab_engine
+000214a0: 3d4e 6f6e 6529 3a0a 0a20 2020 2020 2020  =None):..       
+000214b0: 2064 6566 206c 6f72 656e 7a28 742c 2073   def lorenz(t, s
+000214c0: 7461 7465 2c20 7369 676d 612c 2062 6574  tate, sigma, bet
+000214d0: 612c 2072 686f 293a 0a20 2020 2020 2020  a, rho):.       
+000214e0: 2020 2020 2078 2c20 792c 207a 203d 2073       x, y, z = s
+000214f0: 7461 7465 0a20 2020 2020 2020 2020 2020  tate.           
+00021500: 2064 7820 3d20 7369 676d 6120 2a20 2879   dx = sigma * (y
+00021510: 202d 2078 290a 2020 2020 2020 2020 2020   - x).          
+00021520: 2020 6479 203d 2078 202a 2028 7268 6f20    dy = x * (rho 
+00021530: 2d20 7a29 202d 2079 0a20 2020 2020 2020  - z) - y.       
+00021540: 2020 2020 2064 7a20 3d20 7820 2a20 7920       dz = x * y 
+00021550: 2d20 6265 7461 202a 207a 0a0a 2020 2020  - beta * z..    
+00021560: 2020 2020 2020 2020 7265 7475 726e 205b          return [
+00021570: 6478 2c20 6479 2c20 647a 5d0a 0a20 2020  dx, dy, dz]..   
+00021580: 2020 2020 2078 5f6f 7574 5f73 6861 7065       x_out_shape
+00021590: 203d 2073 656c 662e 705b 2273 6967 6d61   = self.p["sigma
+000215a0: 225d 2e73 6861 7065 5b30 5d0a 2020 2020  "].shape[0].    
+000215b0: 2020 2020 745f 7370 616e 203d 2028 302e      t_span = (0.
+000215c0: 302c 2073 656c 662e 705b 2274 5f65 6e64  0, self.p["t_end
+000215d0: 225d 290a 2020 2020 2020 2020 7420 3d20  "]).        t = 
+000215e0: 6e70 2e61 7261 6e67 6528 302e 302c 2073  np.arange(0.0, s
+000215f0: 656c 662e 705b 2274 5f65 6e64 225d 5b30  elf.p["t_end"][0
+00021600: 5d2c 2073 656c 662e 705b 2273 7465 705f  ], self.p["step_
+00021610: 7369 7a65 225d 5b30 5d29 0a20 2020 2020  size"][0]).     
+00021620: 2020 2073 6f6c 7320 3d20 6e70 2e7a 6572     sols = np.zer
+00021630: 6f73 2828 785f 6f75 745f 7368 6170 652c  os((x_out_shape,
+00021640: 2074 2e73 6861 7065 5b30 5d29 290a 2020   t.shape[0])).  
+00021650: 2020 2020 2020 666f 7220 6920 696e 2072        for i in r
+00021660: 616e 6765 2878 5f6f 7574 5f73 6861 7065  ange(x_out_shape
+00021670: 293a 0a20 2020 2020 2020 2020 2020 2070  ):.            p
+00021680: 203d 2028 7365 6c66 2e70 5b22 7369 676d   = (self.p["sigm
+00021690: 6122 5d5b 695d 2c20 7365 6c66 2e70 5b22  a"][i], self.p["
+000216a0: 6265 7461 225d 5b69 5d2c 2073 656c 662e  beta"][i], self.
+000216b0: 705b 2272 686f 225d 5b69 5d29 0a20 2020  p["rho"][i]).   
+000216c0: 2020 2020 2020 2020 2079 3020 3d20 5b73           y0 = [s
+000216d0: 656c 662e 705b 2278 5f30 225d 5b69 5d2c  elf.p["x_0"][i],
+000216e0: 2073 656c 662e 705b 2279 5f30 225d 5b69   self.p["y_0"][i
+000216f0: 5d2c 2073 656c 662e 705b 227a 5f30 225d  ], self.p["z_0"]
+00021700: 5b69 5d5d 0a20 2020 2020 2020 2020 2020  [i]].           
+00021710: 2023 206f 6e6c 7920 7361 7665 2078 2d63   # only save x-c
+00021720: 6f6f 7264 696e 6174 6520 2869 6e64 6578  oordinate (index
+00021730: 2030 290a 2020 2020 2020 2020 2020 2020   0).            
+00021740: 736f 6c73 5b69 2c20 3a5d 203d 206f 6465  sols[i, :] = ode
+00021750: 696e 7428 6c6f 7265 6e7a 2c20 7930 2c20  int(lorenz, y0, 
+00021760: 742c 2070 2c20 7466 6972 7374 3d54 7275  t, p, tfirst=Tru
+00021770: 6529 5b3a 2c20 305d 0a20 2020 2020 2020  e)[:, 0].       
+00021780: 2078 5f6f 7574 203d 2073 6f6c 730a 0a20   x_out = sols.. 
+00021790: 2020 2020 2020 2072 6574 7572 6e20 785f         return x_
+000217a0: 6f75 740a 0a0a 636c 6173 7320 4c6f 7265  out...class Lore
+000217b0: 6e7a 5f53 7973 7465 6d5f 6a75 6c69 6128  nz_System_julia(
+000217c0: 4162 7374 7261 6374 4d6f 6465 6c29 3a0a  AbstractModel):.
+000217d0: 2020 2020 2222 220a 2020 2020 4d6f 6465      """.    Mode
+000217e0: 6c20 666f 7220 7468 6520 4c6f 7265 6e7a  l for the Lorenz
+000217f0: 2053 7973 7465 6d20 6f66 2064 6966 6665   System of diffe
+00021800: 7265 6e74 6961 6c20 6571 7561 7469 6f6e  rential equation
+00021810: 7320 696e 206a 756c 6961 2e20 4974 2069  s in julia. It i
+00021820: 7320 6e6f 6e6c 696e 6561 7220 616e 6420  s nonlinear and 
+00021830: 7368 6f77 7320 6368 616f 7469 6320 6265  shows chaotic be
+00021840: 6861 7669 6f75 720a 2020 2020 7370 6563  haviour.    spec
+00021850: 6966 6963 616c 6c79 2066 6f72 2074 6865  ifically for the
+00021860: 2074 6872 6565 2070 6172 616d 6574 6572   three parameter
+00021870: 2076 616c 7565 7320 7369 676d 6120 3d20   values sigma = 
+00021880: 3130 2e30 2c20 6265 7461 203d 2032 382e  10.0, beta = 28.
+00021890: 3020 616e 6420 7268 6f20 3d20 382e 302f  0 and rho = 8.0/
+000218a0: 332e 302e 2054 6865 206c 6f72 656e 7a20  3.0. The lorenz 
+000218b0: 6174 7472 6163 746f 7220 6361 6e0a 2020  attractor can.  
+000218c0: 2020 7468 656e 2062 6520 6f62 7365 7276    then be observ
+000218d0: 6564 2069 6e20 616e 7920 7468 7265 6520  ed in any three 
+000218e0: 6469 6d65 6e73 696f 6e61 6c20 7472 616a  dimensional traj
+000218f0: 6563 746f 7279 2e0a 0a20 2020 2050 6172  ectory...    Par
+00021900: 616d 6574 6572 730a 2020 2020 2d2d 2d2d  ameters.    ----
+00021910: 2d2d 2d2d 2d2d 0a20 2020 2070 5b22 7369  ------.    p["si
+00021920: 676d 6122 5d20 3a20 666c 6f61 7420 6f72  gma"] : float or
+00021930: 206e 6461 7272 6179 206f 6620 666c 6f61   ndarray of floa
+00021940: 7420 5b6e 5f67 7269 645d 0a20 2020 2020  t [n_grid].     
+00021950: 2020 2050 6172 616d 6574 6572 206f 6620     Parameter of 
+00021960: 7468 6520 7379 7374 656d 0a20 2020 2070  the system.    p
+00021970: 5b22 6265 7461 225d 203a 2066 6c6f 6174  ["beta"] : float
+00021980: 206f 7220 6e64 6172 7261 7920 6f66 2066   or ndarray of f
+00021990: 6c6f 6174 205b 6e5f 6772 6964 5d0a 2020  loat [n_grid].  
+000219a0: 2020 2020 2020 5061 7261 6d65 7465 7220        Parameter 
+000219b0: 6f66 2074 6865 2073 7973 7465 6d0a 2020  of the system.  
+000219c0: 2020 705b 2272 686f 225d 203a 2066 6c6f    p["rho"] : flo
+000219d0: 6174 206f 7220 6e64 6172 7261 7920 6f66  at or ndarray of
+000219e0: 2066 6c6f 6174 205b 6e5f 6772 6964 5d0a   float [n_grid].
+000219f0: 2020 2020 2020 2020 5061 7261 6d65 7465          Paramete
+00021a00: 7220 6f66 2074 6865 2073 7973 7465 6d0a  r of the system.
+00021a10: 2020 2020 705b 2279 315f 3022 5d20 3a20      p["y1_0"] : 
+00021a20: 666c 6f61 740a 2020 2020 2020 2020 696e  float.        in
+00021a30: 6974 6961 6c20 7661 6c75 6520 6f66 2066  itial value of f
+00021a40: 6972 7374 2076 6172 6961 626c 650a 2020  irst variable.  
+00021a50: 2020 705b 2279 325f 3022 5d20 3a20 666c    p["y2_0"] : fl
+00021a60: 6f61 740a 2020 2020 2020 2020 696e 6974  oat.        init
+00021a70: 6961 6c20 7661 6c75 6520 6f66 2073 6563  ial value of sec
+00021a80: 6f6e 6420 7661 7269 6162 6c65 0a20 2020  ond variable.   
+00021a90: 2070 5b22 7933 5f30 225d 203a 2066 6c6f   p["y3_0"] : flo
+00021aa0: 6174 0a20 2020 2020 2020 2069 6e69 7469  at.        initi
+00021ab0: 616c 2076 616c 7565 206f 6620 7468 6972  al value of thir
+00021ac0: 6420 7661 7269 6162 6c65 0a20 2020 2070  d variable.    p
+00021ad0: 5b22 745f 656e 6422 5d20 3a20 666c 6f61  ["t_end"] : floa
+00021ae0: 740a 2020 2020 2020 2020 7468 6520 656e  t.        the en
+00021af0: 6420 6f66 2074 6865 2074 696d 6573 7061  d of the timespa
+00021b00: 6e20 666f 7220 7768 6963 6820 7468 6520  n for which the 
+00021b10: 7379 7374 656d 2077 696c 6c20 6265 2065  system will be e
+00021b20: 7661 6c75 6174 6564 0a20 2020 2070 5b22  valuated.    p["
+00021b30: 7374 6570 5f73 697a 6522 5d20 3a20 666c  step_size"] : fl
+00021b40: 6f61 740a 2020 2020 2020 2020 7468 6520  oat.        the 
+00021b50: 7374 6570 2073 697a 6520 666f 7220 7468  step size for th
+00021b60: 6520 7469 6d65 2069 6e63 7265 6d65 6e74  e time increment
+00021b70: 7320 6475 7269 6e67 2077 6869 6368 2074  s during which t
+00021b80: 6865 2073 7973 7465 6d20 7769 6c6c 2062  he system will b
+00021b90: 6520 6576 616c 7561 7465 640a 0a20 2020  e evaluated..   
+00021ba0: 2052 6574 7572 6e73 0a20 2020 202d 2d2d   Returns.    ---
+00021bb0: 2d2d 2d2d 0a20 2020 2078 203a 206e 6461  ----.    x : nda
+00021bc0: 7272 6179 206f 6620 666c 6f61 7420 5b6e  rray of float [n
+00021bd0: 5f67 7269 6420 7820 6e5f 7469 6d65 5f73  _grid x n_time_s
+00021be0: 7465 7073 5d0a 2020 2020 2020 2020 5265  teps].        Re
+00021bf0: 7375 6c74 7320 6f66 2078 2063 6f6f 7264  sults of x coord
+00021c00: 696e 6174 6520 6f66 2074 6865 2073 7973  inate of the sys
+00021c10: 7465 6d20 696e 2074 696d 6520 7374 6570  tem in time step
+00021c20: 732c 2074 6865 2067 5043 2069 7320 636f  s, the gPC is co
+00021c30: 6e64 7563 7465 6420 666f 7220 7468 6520  nducted for the 
+00021c40: 7468 7265 6520 7061 7261 6d65 7465 7273  three parameters
+00021c50: 2073 6967 6d61 2c20 6265 7461 0a20 2020   sigma, beta.   
+00021c60: 2020 2020 2061 6e64 2072 686f 0a20 2020       and rho.   
+00021c70: 2022 2222 0a0a 2020 2020 6465 6620 5f5f   """..    def __
+00021c80: 696e 6974 5f5f 2873 656c 662c 2066 6e61  init__(self, fna
+00021c90: 6d65 5f6a 756c 6961 3d4e 6f6e 6529 3a0a  me_julia=None):.
+00021ca0: 2020 2020 2020 2020 6966 2066 6e61 6d65          if fname
+00021cb0: 5f6a 756c 6961 2069 7320 6e6f 7420 4e6f  _julia is not No
+00021cc0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+00021cd0: 7365 6c66 2e66 6e61 6d65 5f6a 756c 6961  self.fname_julia
+00021ce0: 203d 2066 6e61 6d65 5f6a 756c 6961 0a20   = fname_julia. 
+00021cf0: 2020 2020 2020 2073 656c 662e 666e 616d         self.fnam
+00021d00: 6520 3d20 696e 7370 6563 742e 6765 7466  e = inspect.getf
+00021d10: 696c 6528 696e 7370 6563 742e 6375 7272  ile(inspect.curr
+00021d20: 656e 7466 7261 6d65 2829 290a 0a20 2020  entframe())..   
+00021d30: 2064 6566 2076 616c 6964 6174 6528 7365   def validate(se
+00021d40: 6c66 293a 0a20 2020 2020 2020 2070 6173  lf):.        pas
+00021d50: 730a 0a20 2020 2064 6566 2073 696d 756c  s..    def simul
+00021d60: 6174 6528 7365 6c66 2c20 7072 6f63 6573  ate(self, proces
+00021d70: 735f 6964 3d4e 6f6e 652c 206d 6174 6c61  s_id=None, matla
+00021d80: 625f 656e 6769 6e65 3d4e 6f6e 6529 3a0a  b_engine=None):.
+00021d90: 0a20 2020 2020 2020 2066 726f 6d20 6a75  .        from ju
+00021da0: 6c69 6120 696d 706f 7274 204d 6169 6e0a  lia import Main.
+00021db0: 2020 2020 2020 2020 2320 7468 6520 7061          # the pa
+00021dc0: 636b 6167 6520 4469 6666 6572 656e 7469  ckage Differenti
+00021dd0: 616c 4571 7561 7469 6f6e 732e 6a6c 206e  alEquations.jl n
+00021de0: 6565 6473 2074 6f20 6265 2069 6e73 7461  eeds to be insta
+00021df0: 6c6c 6564 2069 6e20 7468 6520 6a75 6c69  lled in the juli
+00021e00: 6120 656e 7669 726f 6e6d 656e 740a 2020  a environment.  
+00021e10: 2020 2020 2020 2320 796f 7520 6361 6e20        # you can 
+00021e20: 6164 6420 6465 7065 6e64 656e 6369 6573  add dependencies
+00021e30: 206f 6620 796f 7572 206d 6f64 656c 2062   of your model b
+00021e40: 7920 7573 696e 6720 6120 6465 6469 6361  y using a dedica
+00021e50: 7465 6420 656e 7669 726f 6e6d 656e 742c  ted environment,
+00021e60: 2066 6f72 2074 6869 7320 6578 616d 706c   for this exampl
+00021e70: 650a 2020 2020 2020 2020 2320 7468 6520  e.        # the 
+00021e80: 666f 6c64 6572 2022 6a75 6c69 615f 656e  folder "julia_en
+00021e90: 7622 2069 7320 6c6f 6361 7465 6420 696e  v" is located in
+00021ea0: 2074 6865 2073 616d 6520 666f 6c64 6572   the same folder
+00021eb0: 2061 7320 7468 6520 6a75 6c69 6120 6669   as the julia fi
+00021ec0: 6c65 0a20 2020 2020 2020 2023 2069 6620  le.        # if 
+00021ed0: 796f 7520 696e 7374 616c 6c65 6420 7468  you installed th
+00021ee0: 6520 4469 6666 6572 656e 7469 616c 4571  e DifferentialEq
+00021ef0: 7561 7469 6f6e 7320 7061 636b 6167 6520  uations package 
+00021f00: 6279 2079 6f75 7273 656c 6620 696e 206a  by yourself in j
+00021f10: 756c 6961 2c20 796f 7520 646f 206e 6f74  ulia, you do not
+00021f20: 2068 6176 6520 746f 2075 7365 2061 0a20   have to use a. 
+00021f30: 2020 2020 2020 2023 2064 6564 6963 6174         # dedicat
+00021f40: 6564 2065 6e76 6972 6f6e 6d65 6e74 2028  ed environment (
+00021f50: 6966 206a 756c 6961 2075 7064 6174 6573  if julia updates
+00021f60: 2c20 7468 6520 656e 7669 726f 6e6d 656e  , the environmen
+00021f70: 7473 2061 6c73 6f20 6861 7665 2074 6f20  ts also have to 
+00021f80: 6265 2075 7064 6174 6564 2066 726f 6d20  be updated from 
+00021f90: 7469 6d65 2074 6f20 7469 6d65 0a20 2020  time to time.   
+00021fa0: 2020 2020 2023 2074 6f20 6b65 6570 2077       # to keep w
+00021fb0: 6f72 6b69 6e67 290a 0a20 2020 2020 2020  orking)..       
+00021fc0: 2023 666e 616d 655f 666f 6c64 6572 203d   #fname_folder =
+00021fd0: 206f 732e 7061 7468 2e73 706c 6974 2873   os.path.split(s
+00021fe0: 656c 662e 666e 616d 655f 6a75 6c69 6129  elf.fname_julia)
+00021ff0: 5b30 5d0a 2020 2020 2020 2020 234d 6169  [0].        #Mai
+00022000: 6e2e 666e 616d 655f 656e 7669 726f 6e6d  n.fname_environm
+00022010: 656e 7420 3d20 6f73 2e70 6174 682e 6a6f  ent = os.path.jo
+00022020: 696e 2866 6e61 6d65 5f66 6f6c 6465 722c  in(fname_folder,
+00022030: 2027 6a75 6c69 615f 656e 7627 290a 2020   'julia_env').  
+00022040: 2020 2020 2020 234d 6169 6e2e 6576 616c        #Main.eval
+00022050: 2827 696d 706f 7274 2050 6b67 3b20 506b  ('import Pkg; Pk
+00022060: 672e 6163 7469 7661 7465 2866 6e61 6d65  g.activate(fname
+00022070: 5f65 6e76 6972 6f6e 6d65 6e74 2927 290a  _environment)').
+00022080: 0a20 2020 2020 2020 2023 2061 6363 6573  .        # acces
+00022090: 7320 2e6a 6c20 6669 6c65 0a20 2020 2020  s .jl file.     
+000220a0: 2020 204d 6169 6e2e 666e 616d 655f 6a75     Main.fname_ju
+000220b0: 6c69 6120 3d20 7365 6c66 2e66 6e61 6d65  lia = self.fname
+000220c0: 5f6a 756c 6961 0a20 2020 2020 2020 204d  _julia.        M
+000220d0: 6169 6e2e 696e 636c 7564 6528 4d61 696e  ain.include(Main
+000220e0: 2e66 6e61 6d65 5f6a 756c 6961 290a 0a20  .fname_julia).. 
+000220f0: 2020 2020 2020 2078 5f6f 7574 5f73 6861         x_out_sha
+00022100: 7065 203d 2073 656c 662e 705b 2273 6967  pe = self.p["sig
+00022110: 6d61 225d 2e73 6861 7065 5b30 5d0a 2020  ma"].shape[0].  
+00022120: 2020 2020 2020 7420 3d20 6e70 2e61 7261        t = np.ara
+00022130: 6e67 6528 302e 302c 2073 656c 662e 705b  nge(0.0, self.p[
+00022140: 2274 5f65 6e64 225d 5b30 5d2c 2073 656c  "t_end"][0], sel
+00022150: 662e 705b 2273 7465 705f 7369 7a65 225d  f.p["step_size"]
+00022160: 5b30 5d29 0a20 2020 2020 2020 2073 6f6c  [0]).        sol
+00022170: 7320 3d20 6e70 2e7a 6572 6f73 2828 785f  s = np.zeros((x_
+00022180: 6f75 745f 7368 6170 652c 2074 2e73 6861  out_shape, t.sha
+00022190: 7065 5b30 5d29 290a 2020 2020 2020 2020  pe[0])).        
+000221a0: 666f 7220 6920 696e 2072 616e 6765 2878  for i in range(x
+000221b0: 5f6f 7574 5f73 6861 7065 293a 0a20 2020  _out_shape):.   
+000221c0: 2020 2020 2020 2020 2070 203d 205b 7365           p = [se
+000221d0: 6c66 2e70 5b22 7369 676d 6122 5d5b 695d  lf.p["sigma"][i]
+000221e0: 2c20 7365 6c66 2e70 5b22 6265 7461 225d  , self.p["beta"]
+000221f0: 5b69 5d2c 2073 656c 662e 705b 2272 686f  [i], self.p["rho
+00022200: 225d 5b69 5d5d 0a20 2020 2020 2020 2020  "][i]].         
+00022210: 2020 2079 3020 3d20 5b73 656c 662e 705b     y0 = [self.p[
+00022220: 2278 5f30 225d 5b69 5d2c 2073 656c 662e  "x_0"][i], self.
+00022230: 705b 2279 5f30 225d 5b69 5d2c 2073 656c  p["y_0"][i], sel
+00022240: 662e 705b 227a 5f30 225d 5b69 5d5d 0a20  f.p["z_0"][i]]. 
+00022250: 2020 2020 2020 2020 2020 2023 206f 6e6c             # onl
+00022260: 7920 7361 7665 2078 2d63 6f6f 7264 696e  y save x-coordin
+00022270: 6174 6520 2869 6e64 6578 2030 290a 2020  ate (index 0).  
+00022280: 2020 2020 2020 2020 2020 736f 6c73 5b69            sols[i
+00022290: 2c20 3a5d 203d 204d 6169 6e2e 4a75 6c69  , :] = Main.Juli
+000222a0: 615f 4c6f 7265 6e7a 2870 2c20 7930 2c20  a_Lorenz(p, y0, 
+000222b0: 7429 5b30 5d0a 2020 2020 2020 2020 785f  t)[0].        x_
+000222c0: 6f75 7420 3d20 736f 6c73 0a0a 2020 2020  out = sols..    
+000222d0: 2020 2020 7265 7475 726e 2078 5f6f 7574      return x_out
+000222e0: 0a                                       .
```

## Comparing `pygpc-0.3.8.dist-info/LICENSE` & `pygpc-0.3.9.dist-info/LICENSE`

 * *Ordering differences only*

 * *Files 7% similar despite different names*

```diff
@@ -1,674 +1,674 @@
-                    GNU GENERAL PUBLIC LICENSE
-                       Version 3, 29 June 2007
-
- Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
- Everyone is permitted to copy and distribute verbatim copies
- of this license document, but changing it is not allowed.
-
-                            Preamble
-
-  The GNU General Public License is a free, copyleft license for
-software and other kinds of works.
-
-  The licenses for most software and other practical works are designed
-to take away your freedom to share and change the works.  By contrast,
-the GNU General Public License is intended to guarantee your freedom to
-share and change all versions of a program--to make sure it remains free
-software for all its users.  We, the Free Software Foundation, use the
-GNU General Public License for most of our software; it applies also to
-any other work released this way by its authors.  You can apply it to
-your programs, too.
-
-  When we speak of free software, we are referring to freedom, not
-price.  Our General Public Licenses are designed to make sure that you
-have the freedom to distribute copies of free software (and charge for
-them if you wish), that you receive source code or can get it if you
-want it, that you can change the software or use pieces of it in new
-free programs, and that you know you can do these things.
-
-  To protect your rights, we need to prevent others from denying you
-these rights or asking you to surrender the rights.  Therefore, you have
-certain responsibilities if you distribute copies of the software, or if
-you modify it: responsibilities to respect the freedom of others.
-
-  For example, if you distribute copies of such a program, whether
-gratis or for a fee, you must pass on to the recipients the same
-freedoms that you received.  You must make sure that they, too, receive
-or can get the source code.  And you must show them these terms so they
-know their rights.
-
-  Developers that use the GNU GPL protect your rights with two steps:
-(1) assert copyright on the software, and (2) offer you this License
-giving you legal permission to copy, distribute and/or modify it.
-
-  For the developers' and authors' protection, the GPL clearly explains
-that there is no warranty for this free software.  For both users' and
-authors' sake, the GPL requires that modified versions be marked as
-changed, so that their problems will not be attributed erroneously to
-authors of previous versions.
-
-  Some devices are designed to deny users access to install or run
-modified versions of the software inside them, although the manufacturer
-can do so.  This is fundamentally incompatible with the aim of
-protecting users' freedom to change the software.  The systematic
-pattern of such abuse occurs in the area of products for individuals to
-use, which is precisely where it is most unacceptable.  Therefore, we
-have designed this version of the GPL to prohibit the practice for those
-products.  If such problems arise substantially in other domains, we
-stand ready to extend this provision to those domains in future versions
-of the GPL, as needed to protect the freedom of users.
-
-  Finally, every program is threatened constantly by software patents.
-States should not allow patents to restrict development and use of
-software on general-purpose computers, but in those that do, we wish to
-avoid the special danger that patents applied to a free program could
-make it effectively proprietary.  To prevent this, the GPL assures that
-patents cannot be used to render the program non-free.
-
-  The precise terms and conditions for copying, distribution and
-modification follow.
-
-                       TERMS AND CONDITIONS
-
-  0. Definitions.
-
-  "This License" refers to version 3 of the GNU General Public License.
-
-  "Copyright" also means copyright-like laws that apply to other kinds of
-works, such as semiconductor masks.
-
-  "The Program" refers to any copyrightable work licensed under this
-License.  Each licensee is addressed as "you".  "Licensees" and
-"recipients" may be individuals or organizations.
-
-  To "modify" a work means to copy from or adapt all or part of the work
-in a fashion requiring copyright permission, other than the making of an
-exact copy.  The resulting work is called a "modified version" of the
-earlier work or a work "based on" the earlier work.
-
-  A "covered work" means either the unmodified Program or a work based
-on the Program.
-
-  To "propagate" a work means to do anything with it that, without
-permission, would make you directly or secondarily liable for
-infringement under applicable copyright law, except executing it on a
-computer or modifying a private copy.  Propagation includes copying,
-distribution (with or without modification), making available to the
-public, and in some countries other activities as well.
-
-  To "convey" a work means any kind of propagation that enables other
-parties to make or receive copies.  Mere interaction with a user through
-a computer network, with no transfer of a copy, is not conveying.
-
-  An interactive user interface displays "Appropriate Legal Notices"
-to the extent that it includes a convenient and prominently visible
-feature that (1) displays an appropriate copyright notice, and (2)
-tells the user that there is no warranty for the work (except to the
-extent that warranties are provided), that licensees may convey the
-work under this License, and how to view a copy of this License.  If
-the interface presents a list of user commands or options, such as a
-menu, a prominent item in the list meets this criterion.
-
-  1. Source Code.
-
-  The "source code" for a work means the preferred form of the work
-for making modifications to it.  "Object code" means any non-source
-form of a work.
-
-  A "Standard Interface" means an interface that either is an official
-standard defined by a recognized standards body, or, in the case of
-interfaces specified for a particular programming language, one that
-is widely used among developers working in that language.
-
-  The "System Libraries" of an executable work include anything, other
-than the work as a whole, that (a) is included in the normal form of
-packaging a Major Component, but which is not part of that Major
-Component, and (b) serves only to enable use of the work with that
-Major Component, or to implement a Standard Interface for which an
-implementation is available to the public in source code form.  A
-"Major Component", in this context, means a major essential component
-(kernel, window system, and so on) of the specific operating system
-(if any) on which the executable work runs, or a compiler used to
-produce the work, or an object code interpreter used to run it.
-
-  The "Corresponding Source" for a work in object code form means all
-the source code needed to generate, install, and (for an executable
-work) run the object code and to modify the work, including scripts to
-control those activities.  However, it does not include the work's
-System Libraries, or general-purpose tools or generally available free
-programs which are used unmodified in performing those activities but
-which are not part of the work.  For example, Corresponding Source
-includes interface definition files associated with source files for
-the work, and the source code for shared libraries and dynamically
-linked subprograms that the work is specifically designed to require,
-such as by intimate data communication or control flow between those
-subprograms and other parts of the work.
-
-  The Corresponding Source need not include anything that users
-can regenerate automatically from other parts of the Corresponding
-Source.
-
-  The Corresponding Source for a work in source code form is that
-same work.
-
-  2. Basic Permissions.
-
-  All rights granted under this License are granted for the term of
-copyright on the Program, and are irrevocable provided the stated
-conditions are met.  This License explicitly affirms your unlimited
-permission to run the unmodified Program.  The output from running a
-covered work is covered by this License only if the output, given its
-content, constitutes a covered work.  This License acknowledges your
-rights of fair use or other equivalent, as provided by copyright law.
-
-  You may make, run and propagate covered works that you do not
-convey, without conditions so long as your license otherwise remains
-in force.  You may convey covered works to others for the sole purpose
-of having them make modifications exclusively for you, or provide you
-with facilities for running those works, provided that you comply with
-the terms of this License in conveying all material for which you do
-not control copyright.  Those thus making or running the covered works
-for you must do so exclusively on your behalf, under your direction
-and control, on terms that prohibit them from making any copies of
-your copyrighted material outside their relationship with you.
-
-  Conveying under any other circumstances is permitted solely under
-the conditions stated below.  Sublicensing is not allowed; section 10
-makes it unnecessary.
-
-  3. Protecting Users' Legal Rights From Anti-Circumvention Law.
-
-  No covered work shall be deemed part of an effective technological
-measure under any applicable law fulfilling obligations under article
-11 of the WIPO copyright treaty adopted on 20 December 1996, or
-similar laws prohibiting or restricting circumvention of such
-measures.
-
-  When you convey a covered work, you waive any legal power to forbid
-circumvention of technological measures to the extent such circumvention
-is effected by exercising rights under this License with respect to
-the covered work, and you disclaim any intention to limit operation or
-modification of the work as a means of enforcing, against the work's
-users, your or third parties' legal rights to forbid circumvention of
-technological measures.
-
-  4. Conveying Verbatim Copies.
-
-  You may convey verbatim copies of the Program's source code as you
-receive it, in any medium, provided that you conspicuously and
-appropriately publish on each copy an appropriate copyright notice;
-keep intact all notices stating that this License and any
-non-permissive terms added in accord with section 7 apply to the code;
-keep intact all notices of the absence of any warranty; and give all
-recipients a copy of this License along with the Program.
-
-  You may charge any price or no price for each copy that you convey,
-and you may offer support or warranty protection for a fee.
-
-  5. Conveying Modified Source Versions.
-
-  You may convey a work based on the Program, or the modifications to
-produce it from the Program, in the form of source code under the
-terms of section 4, provided that you also meet all of these conditions:
-
-    a) The work must carry prominent notices stating that you modified
-    it, and giving a relevant date.
-
-    b) The work must carry prominent notices stating that it is
-    released under this License and any conditions added under section
-    7.  This requirement modifies the requirement in section 4 to
-    "keep intact all notices".
-
-    c) You must license the entire work, as a whole, under this
-    License to anyone who comes into possession of a copy.  This
-    License will therefore apply, along with any applicable section 7
-    additional terms, to the whole of the work, and all its parts,
-    regardless of how they are packaged.  This License gives no
-    permission to license the work in any other way, but it does not
-    invalidate such permission if you have separately received it.
-
-    d) If the work has interactive user interfaces, each must display
-    Appropriate Legal Notices; however, if the Program has interactive
-    interfaces that do not display Appropriate Legal Notices, your
-    work need not make them do so.
-
-  A compilation of a covered work with other separate and independent
-works, which are not by their nature extensions of the covered work,
-and which are not combined with it such as to form a larger program,
-in or on a volume of a storage or distribution medium, is called an
-"aggregate" if the compilation and its resulting copyright are not
-used to limit the access or legal rights of the compilation's users
-beyond what the individual works permit.  Inclusion of a covered work
-in an aggregate does not cause this License to apply to the other
-parts of the aggregate.
-
-  6. Conveying Non-Source Forms.
-
-  You may convey a covered work in object code form under the terms
-of sections 4 and 5, provided that you also convey the
-machine-readable Corresponding Source under the terms of this License,
-in one of these ways:
-
-    a) Convey the object code in, or embodied in, a physical product
-    (including a physical distribution medium), accompanied by the
-    Corresponding Source fixed on a durable physical medium
-    customarily used for software interchange.
-
-    b) Convey the object code in, or embodied in, a physical product
-    (including a physical distribution medium), accompanied by a
-    written offer, valid for at least three years and valid for as
-    long as you offer spare parts or customer support for that product
-    model, to give anyone who possesses the object code either (1) a
-    copy of the Corresponding Source for all the software in the
-    product that is covered by this License, on a durable physical
-    medium customarily used for software interchange, for a price no
-    more than your reasonable cost of physically performing this
-    conveying of source, or (2) access to copy the
-    Corresponding Source from a network server at no charge.
-
-    c) Convey individual copies of the object code with a copy of the
-    written offer to provide the Corresponding Source.  This
-    alternative is allowed only occasionally and noncommercially, and
-    only if you received the object code with such an offer, in accord
-    with subsection 6b.
-
-    d) Convey the object code by offering access from a designated
-    place (gratis or for a charge), and offer equivalent access to the
-    Corresponding Source in the same way through the same place at no
-    further charge.  You need not require recipients to copy the
-    Corresponding Source along with the object code.  If the place to
-    copy the object code is a network server, the Corresponding Source
-    may be on a different server (operated by you or a third party)
-    that supports equivalent copying facilities, provided you maintain
-    clear directions next to the object code saying where to find the
-    Corresponding Source.  Regardless of what server hosts the
-    Corresponding Source, you remain obligated to ensure that it is
-    available for as long as needed to satisfy these requirements.
-
-    e) Convey the object code using peer-to-peer transmission, provided
-    you inform other peers where the object code and Corresponding
-    Source of the work are being offered to the general public at no
-    charge under subsection 6d.
-
-  A separable portion of the object code, whose source code is excluded
-from the Corresponding Source as a System Library, need not be
-included in conveying the object code work.
-
-  A "User Product" is either (1) a "consumer product", which means any
-tangible personal property which is normally used for personal, family,
-or household purposes, or (2) anything designed or sold for incorporation
-into a dwelling.  In determining whether a product is a consumer product,
-doubtful cases shall be resolved in favor of coverage.  For a particular
-product received by a particular user, "normally used" refers to a
-typical or common use of that class of product, regardless of the status
-of the particular user or of the way in which the particular user
-actually uses, or expects or is expected to use, the product.  A product
-is a consumer product regardless of whether the product has substantial
-commercial, industrial or non-consumer uses, unless such uses represent
-the only significant mode of use of the product.
-
-  "Installation Information" for a User Product means any methods,
-procedures, authorization keys, or other information required to install
-and execute modified versions of a covered work in that User Product from
-a modified version of its Corresponding Source.  The information must
-suffice to ensure that the continued functioning of the modified object
-code is in no case prevented or interfered with solely because
-modification has been made.
-
-  If you convey an object code work under this section in, or with, or
-specifically for use in, a User Product, and the conveying occurs as
-part of a transaction in which the right of possession and use of the
-User Product is transferred to the recipient in perpetuity or for a
-fixed term (regardless of how the transaction is characterized), the
-Corresponding Source conveyed under this section must be accompanied
-by the Installation Information.  But this requirement does not apply
-if neither you nor any third party retains the ability to install
-modified object code on the User Product (for example, the work has
-been installed in ROM).
-
-  The requirement to provide Installation Information does not include a
-requirement to continue to provide support service, warranty, or updates
-for a work that has been modified or installed by the recipient, or for
-the User Product in which it has been modified or installed.  Access to a
-network may be denied when the modification itself materially and
-adversely affects the operation of the network or violates the rules and
-protocols for communication across the network.
-
-  Corresponding Source conveyed, and Installation Information provided,
-in accord with this section must be in a format that is publicly
-documented (and with an implementation available to the public in
-source code form), and must require no special password or key for
-unpacking, reading or copying.
-
-  7. Additional Terms.
-
-  "Additional permissions" are terms that supplement the terms of this
-License by making exceptions from one or more of its conditions.
-Additional permissions that are applicable to the entire Program shall
-be treated as though they were included in this License, to the extent
-that they are valid under applicable law.  If additional permissions
-apply only to part of the Program, that part may be used separately
-under those permissions, but the entire Program remains governed by
-this License without regard to the additional permissions.
-
-  When you convey a copy of a covered work, you may at your option
-remove any additional permissions from that copy, or from any part of
-it.  (Additional permissions may be written to require their own
-removal in certain cases when you modify the work.)  You may place
-additional permissions on material, added by you to a covered work,
-for which you have or can give appropriate copyright permission.
-
-  Notwithstanding any other provision of this License, for material you
-add to a covered work, you may (if authorized by the copyright holders of
-that material) supplement the terms of this License with terms:
-
-    a) Disclaiming warranty or limiting liability differently from the
-    terms of sections 15 and 16 of this License; or
-
-    b) Requiring preservation of specified reasonable legal notices or
-    author attributions in that material or in the Appropriate Legal
-    Notices displayed by works containing it; or
-
-    c) Prohibiting misrepresentation of the origin of that material, or
-    requiring that modified versions of such material be marked in
-    reasonable ways as different from the original version; or
-
-    d) Limiting the use for publicity purposes of names of licensors or
-    authors of the material; or
-
-    e) Declining to grant rights under trademark law for use of some
-    trade names, trademarks, or service marks; or
-
-    f) Requiring indemnification of licensors and authors of that
-    material by anyone who conveys the material (or modified versions of
-    it) with contractual assumptions of liability to the recipient, for
-    any liability that these contractual assumptions directly impose on
-    those licensors and authors.
-
-  All other non-permissive additional terms are considered "further
-restrictions" within the meaning of section 10.  If the Program as you
-received it, or any part of it, contains a notice stating that it is
-governed by this License along with a term that is a further
-restriction, you may remove that term.  If a license document contains
-a further restriction but permits relicensing or conveying under this
-License, you may add to a covered work material governed by the terms
-of that license document, provided that the further restriction does
-not survive such relicensing or conveying.
-
-  If you add terms to a covered work in accord with this section, you
-must place, in the relevant source files, a statement of the
-additional terms that apply to those files, or a notice indicating
-where to find the applicable terms.
-
-  Additional terms, permissive or non-permissive, may be stated in the
-form of a separately written license, or stated as exceptions;
-the above requirements apply either way.
-
-  8. Termination.
-
-  You may not propagate or modify a covered work except as expressly
-provided under this License.  Any attempt otherwise to propagate or
-modify it is void, and will automatically terminate your rights under
-this License (including any patent licenses granted under the third
-paragraph of section 11).
-
-  However, if you cease all violation of this License, then your
-license from a particular copyright holder is reinstated (a)
-provisionally, unless and until the copyright holder explicitly and
-finally terminates your license, and (b) permanently, if the copyright
-holder fails to notify you of the violation by some reasonable means
-prior to 60 days after the cessation.
-
-  Moreover, your license from a particular copyright holder is
-reinstated permanently if the copyright holder notifies you of the
-violation by some reasonable means, this is the first time you have
-received notice of violation of this License (for any work) from that
-copyright holder, and you cure the violation prior to 30 days after
-your receipt of the notice.
-
-  Termination of your rights under this section does not terminate the
-licenses of parties who have received copies or rights from you under
-this License.  If your rights have been terminated and not permanently
-reinstated, you do not qualify to receive new licenses for the same
-material under section 10.
-
-  9. Acceptance Not Required for Having Copies.
-
-  You are not required to accept this License in order to receive or
-run a copy of the Program.  Ancillary propagation of a covered work
-occurring solely as a consequence of using peer-to-peer transmission
-to receive a copy likewise does not require acceptance.  However,
-nothing other than this License grants you permission to propagate or
-modify any covered work.  These actions infringe copyright if you do
-not accept this License.  Therefore, by modifying or propagating a
-covered work, you indicate your acceptance of this License to do so.
-
-  10. Automatic Licensing of Downstream Recipients.
-
-  Each time you convey a covered work, the recipient automatically
-receives a license from the original licensors, to run, modify and
-propagate that work, subject to this License.  You are not responsible
-for enforcing compliance by third parties with this License.
-
-  An "entity transaction" is a transaction transferring control of an
-organization, or substantially all assets of one, or subdividing an
-organization, or merging organizations.  If propagation of a covered
-work results from an entity transaction, each party to that
-transaction who receives a copy of the work also receives whatever
-licenses to the work the party's predecessor in interest had or could
-give under the previous paragraph, plus a right to possession of the
-Corresponding Source of the work from the predecessor in interest, if
-the predecessor has it or can get it with reasonable efforts.
-
-  You may not impose any further restrictions on the exercise of the
-rights granted or affirmed under this License.  For example, you may
-not impose a license fee, royalty, or other charge for exercise of
-rights granted under this License, and you may not initiate litigation
-(including a cross-claim or counterclaim in a lawsuit) alleging that
-any patent claim is infringed by making, using, selling, offering for
-sale, or importing the Program or any portion of it.
-
-  11. Patents.
-
-  A "contributor" is a copyright holder who authorizes use under this
-License of the Program or a work on which the Program is based.  The
-work thus licensed is called the contributor's "contributor version".
-
-  A contributor's "essential patent claims" are all patent claims
-owned or controlled by the contributor, whether already acquired or
-hereafter acquired, that would be infringed by some manner, permitted
-by this License, of making, using, or selling its contributor version,
-but do not include claims that would be infringed only as a
-consequence of further modification of the contributor version.  For
-purposes of this definition, "control" includes the right to grant
-patent sublicenses in a manner consistent with the requirements of
-this License.
-
-  Each contributor grants you a non-exclusive, worldwide, royalty-free
-patent license under the contributor's essential patent claims, to
-make, use, sell, offer for sale, import and otherwise run, modify and
-propagate the contents of its contributor version.
-
-  In the following three paragraphs, a "patent license" is any express
-agreement or commitment, however denominated, not to enforce a patent
-(such as an express permission to practice a patent or covenant not to
-sue for patent infringement).  To "grant" such a patent license to a
-party means to make such an agreement or commitment not to enforce a
-patent against the party.
-
-  If you convey a covered work, knowingly relying on a patent license,
-and the Corresponding Source of the work is not available for anyone
-to copy, free of charge and under the terms of this License, through a
-publicly available network server or other readily accessible means,
-then you must either (1) cause the Corresponding Source to be so
-available, or (2) arrange to deprive yourself of the benefit of the
-patent license for this particular work, or (3) arrange, in a manner
-consistent with the requirements of this License, to extend the patent
-license to downstream recipients.  "Knowingly relying" means you have
-actual knowledge that, but for the patent license, your conveying the
-covered work in a country, or your recipient's use of the covered work
-in a country, would infringe one or more identifiable patents in that
-country that you have reason to believe are valid.
-
-  If, pursuant to or in connection with a single transaction or
-arrangement, you convey, or propagate by procuring conveyance of, a
-covered work, and grant a patent license to some of the parties
-receiving the covered work authorizing them to use, propagate, modify
-or convey a specific copy of the covered work, then the patent license
-you grant is automatically extended to all recipients of the covered
-work and works based on it.
-
-  A patent license is "discriminatory" if it does not include within
-the scope of its coverage, prohibits the exercise of, or is
-conditioned on the non-exercise of one or more of the rights that are
-specifically granted under this License.  You may not convey a covered
-work if you are a party to an arrangement with a third party that is
-in the business of distributing software, under which you make payment
-to the third party based on the extent of your activity of conveying
-the work, and under which the third party grants, to any of the
-parties who would receive the covered work from you, a discriminatory
-patent license (a) in connection with copies of the covered work
-conveyed by you (or copies made from those copies), or (b) primarily
-for and in connection with specific products or compilations that
-contain the covered work, unless you entered into that arrangement,
-or that patent license was granted, prior to 28 March 2007.
-
-  Nothing in this License shall be construed as excluding or limiting
-any implied license or other defenses to infringement that may
-otherwise be available to you under applicable patent law.
-
-  12. No Surrender of Others' Freedom.
-
-  If conditions are imposed on you (whether by court order, agreement or
-otherwise) that contradict the conditions of this License, they do not
-excuse you from the conditions of this License.  If you cannot convey a
-covered work so as to satisfy simultaneously your obligations under this
-License and any other pertinent obligations, then as a consequence you may
-not convey it at all.  For example, if you agree to terms that obligate you
-to collect a royalty for further conveying from those to whom you convey
-the Program, the only way you could satisfy both those terms and this
-License would be to refrain entirely from conveying the Program.
-
-  13. Use with the GNU Affero General Public License.
-
-  Notwithstanding any other provision of this License, you have
-permission to link or combine any covered work with a work licensed
-under version 3 of the GNU Affero General Public License into a single
-combined work, and to convey the resulting work.  The terms of this
-License will continue to apply to the part which is the covered work,
-but the special requirements of the GNU Affero General Public License,
-section 13, concerning interaction through a network will apply to the
-combination as such.
-
-  14. Revised Versions of this License.
-
-  The Free Software Foundation may publish revised and/or new versions of
-the GNU General Public License from time to time.  Such new versions will
-be similar in spirit to the present version, but may differ in detail to
-address new problems or concerns.
-
-  Each version is given a distinguishing version number.  If the
-Program specifies that a certain numbered version of the GNU General
-Public License "or any later version" applies to it, you have the
-option of following the terms and conditions either of that numbered
-version or of any later version published by the Free Software
-Foundation.  If the Program does not specify a version number of the
-GNU General Public License, you may choose any version ever published
-by the Free Software Foundation.
-
-  If the Program specifies that a proxy can decide which future
-versions of the GNU General Public License can be used, that proxy's
-public statement of acceptance of a version permanently authorizes you
-to choose that version for the Program.
-
-  Later license versions may give you additional or different
-permissions.  However, no additional obligations are imposed on any
-author or copyright holder as a result of your choosing to follow a
-later version.
-
-  15. Disclaimer of Warranty.
-
-  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
-APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
-HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
-OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
-THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
-PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
-IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
-ALL NECESSARY SERVICING, REPAIR OR CORRECTION.
-
-  16. Limitation of Liability.
-
-  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
-WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
-THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
-GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
-USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
-DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
-PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
-EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
-SUCH DAMAGES.
-
-  17. Interpretation of Sections 15 and 16.
-
-  If the disclaimer of warranty and limitation of liability provided
-above cannot be given local legal effect according to their terms,
-reviewing courts shall apply local law that most closely approximates
-an absolute waiver of all civil liability in connection with the
-Program, unless a warranty or assumption of liability accompanies a
-copy of the Program in return for a fee.
-
-                     END OF TERMS AND CONDITIONS
-
-            How to Apply These Terms to Your New Programs
-
-  If you develop a new program, and you want it to be of the greatest
-possible use to the public, the best way to achieve this is to make it
-free software which everyone can redistribute and change under these terms.
-
-  To do so, attach the following notices to the program.  It is safest
-to attach them to the start of each source file to most effectively
-state the exclusion of warranty; and each file should have at least
-the "copyright" line and a pointer to where the full notice is found.
-
-    <one line to give the program's name and a brief idea of what it does.>
-    Copyright (C) <year>  <name of author>
-
-    This program is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 3 of the License, or
-    (at your option) any later version.
-
-    This program is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with this program.  If not, see <https://www.gnu.org/licenses/>.
-
-Also add information on how to contact you by electronic and paper mail.
-
-  If the program does terminal interaction, make it output a short
-notice like this when it starts in an interactive mode:
-
-    <program>  Copyright (C) <year>  <name of author>
-    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
-    This is free software, and you are welcome to redistribute it
-    under certain conditions; type `show c' for details.
-
-The hypothetical commands `show w' and `show c' should show the appropriate
-parts of the General Public License.  Of course, your program's commands
-might be different; for a GUI interface, you would use an "about box".
-
-  You should also get your employer (if you work as a programmer) or school,
-if any, to sign a "copyright disclaimer" for the program, if necessary.
-For more information on this, and how to apply and follow the GNU GPL, see
-<https://www.gnu.org/licenses/>.
-
-  The GNU General Public License does not permit incorporating your program
-into proprietary programs.  If your program is a subroutine library, you
-may consider it more useful to permit linking proprietary applications with
-the library.  If this is what you want to do, use the GNU Lesser General
-Public License instead of this License.  But first, please read
-<https://www.gnu.org/licenses/why-not-lgpl.html>.
+                    GNU GENERAL PUBLIC LICENSE
+                       Version 3, 29 June 2007
+
+ Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
+ Everyone is permitted to copy and distribute verbatim copies
+ of this license document, but changing it is not allowed.
+
+                            Preamble
+
+  The GNU General Public License is a free, copyleft license for
+software and other kinds of works.
+
+  The licenses for most software and other practical works are designed
+to take away your freedom to share and change the works.  By contrast,
+the GNU General Public License is intended to guarantee your freedom to
+share and change all versions of a program--to make sure it remains free
+software for all its users.  We, the Free Software Foundation, use the
+GNU General Public License for most of our software; it applies also to
+any other work released this way by its authors.  You can apply it to
+your programs, too.
+
+  When we speak of free software, we are referring to freedom, not
+price.  Our General Public Licenses are designed to make sure that you
+have the freedom to distribute copies of free software (and charge for
+them if you wish), that you receive source code or can get it if you
+want it, that you can change the software or use pieces of it in new
+free programs, and that you know you can do these things.
+
+  To protect your rights, we need to prevent others from denying you
+these rights or asking you to surrender the rights.  Therefore, you have
+certain responsibilities if you distribute copies of the software, or if
+you modify it: responsibilities to respect the freedom of others.
+
+  For example, if you distribute copies of such a program, whether
+gratis or for a fee, you must pass on to the recipients the same
+freedoms that you received.  You must make sure that they, too, receive
+or can get the source code.  And you must show them these terms so they
+know their rights.
+
+  Developers that use the GNU GPL protect your rights with two steps:
+(1) assert copyright on the software, and (2) offer you this License
+giving you legal permission to copy, distribute and/or modify it.
+
+  For the developers' and authors' protection, the GPL clearly explains
+that there is no warranty for this free software.  For both users' and
+authors' sake, the GPL requires that modified versions be marked as
+changed, so that their problems will not be attributed erroneously to
+authors of previous versions.
+
+  Some devices are designed to deny users access to install or run
+modified versions of the software inside them, although the manufacturer
+can do so.  This is fundamentally incompatible with the aim of
+protecting users' freedom to change the software.  The systematic
+pattern of such abuse occurs in the area of products for individuals to
+use, which is precisely where it is most unacceptable.  Therefore, we
+have designed this version of the GPL to prohibit the practice for those
+products.  If such problems arise substantially in other domains, we
+stand ready to extend this provision to those domains in future versions
+of the GPL, as needed to protect the freedom of users.
+
+  Finally, every program is threatened constantly by software patents.
+States should not allow patents to restrict development and use of
+software on general-purpose computers, but in those that do, we wish to
+avoid the special danger that patents applied to a free program could
+make it effectively proprietary.  To prevent this, the GPL assures that
+patents cannot be used to render the program non-free.
+
+  The precise terms and conditions for copying, distribution and
+modification follow.
+
+                       TERMS AND CONDITIONS
+
+  0. Definitions.
+
+  "This License" refers to version 3 of the GNU General Public License.
+
+  "Copyright" also means copyright-like laws that apply to other kinds of
+works, such as semiconductor masks.
+
+  "The Program" refers to any copyrightable work licensed under this
+License.  Each licensee is addressed as "you".  "Licensees" and
+"recipients" may be individuals or organizations.
+
+  To "modify" a work means to copy from or adapt all or part of the work
+in a fashion requiring copyright permission, other than the making of an
+exact copy.  The resulting work is called a "modified version" of the
+earlier work or a work "based on" the earlier work.
+
+  A "covered work" means either the unmodified Program or a work based
+on the Program.
+
+  To "propagate" a work means to do anything with it that, without
+permission, would make you directly or secondarily liable for
+infringement under applicable copyright law, except executing it on a
+computer or modifying a private copy.  Propagation includes copying,
+distribution (with or without modification), making available to the
+public, and in some countries other activities as well.
+
+  To "convey" a work means any kind of propagation that enables other
+parties to make or receive copies.  Mere interaction with a user through
+a computer network, with no transfer of a copy, is not conveying.
+
+  An interactive user interface displays "Appropriate Legal Notices"
+to the extent that it includes a convenient and prominently visible
+feature that (1) displays an appropriate copyright notice, and (2)
+tells the user that there is no warranty for the work (except to the
+extent that warranties are provided), that licensees may convey the
+work under this License, and how to view a copy of this License.  If
+the interface presents a list of user commands or options, such as a
+menu, a prominent item in the list meets this criterion.
+
+  1. Source Code.
+
+  The "source code" for a work means the preferred form of the work
+for making modifications to it.  "Object code" means any non-source
+form of a work.
+
+  A "Standard Interface" means an interface that either is an official
+standard defined by a recognized standards body, or, in the case of
+interfaces specified for a particular programming language, one that
+is widely used among developers working in that language.
+
+  The "System Libraries" of an executable work include anything, other
+than the work as a whole, that (a) is included in the normal form of
+packaging a Major Component, but which is not part of that Major
+Component, and (b) serves only to enable use of the work with that
+Major Component, or to implement a Standard Interface for which an
+implementation is available to the public in source code form.  A
+"Major Component", in this context, means a major essential component
+(kernel, window system, and so on) of the specific operating system
+(if any) on which the executable work runs, or a compiler used to
+produce the work, or an object code interpreter used to run it.
+
+  The "Corresponding Source" for a work in object code form means all
+the source code needed to generate, install, and (for an executable
+work) run the object code and to modify the work, including scripts to
+control those activities.  However, it does not include the work's
+System Libraries, or general-purpose tools or generally available free
+programs which are used unmodified in performing those activities but
+which are not part of the work.  For example, Corresponding Source
+includes interface definition files associated with source files for
+the work, and the source code for shared libraries and dynamically
+linked subprograms that the work is specifically designed to require,
+such as by intimate data communication or control flow between those
+subprograms and other parts of the work.
+
+  The Corresponding Source need not include anything that users
+can regenerate automatically from other parts of the Corresponding
+Source.
+
+  The Corresponding Source for a work in source code form is that
+same work.
+
+  2. Basic Permissions.
+
+  All rights granted under this License are granted for the term of
+copyright on the Program, and are irrevocable provided the stated
+conditions are met.  This License explicitly affirms your unlimited
+permission to run the unmodified Program.  The output from running a
+covered work is covered by this License only if the output, given its
+content, constitutes a covered work.  This License acknowledges your
+rights of fair use or other equivalent, as provided by copyright law.
+
+  You may make, run and propagate covered works that you do not
+convey, without conditions so long as your license otherwise remains
+in force.  You may convey covered works to others for the sole purpose
+of having them make modifications exclusively for you, or provide you
+with facilities for running those works, provided that you comply with
+the terms of this License in conveying all material for which you do
+not control copyright.  Those thus making or running the covered works
+for you must do so exclusively on your behalf, under your direction
+and control, on terms that prohibit them from making any copies of
+your copyrighted material outside their relationship with you.
+
+  Conveying under any other circumstances is permitted solely under
+the conditions stated below.  Sublicensing is not allowed; section 10
+makes it unnecessary.
+
+  3. Protecting Users' Legal Rights From Anti-Circumvention Law.
+
+  No covered work shall be deemed part of an effective technological
+measure under any applicable law fulfilling obligations under article
+11 of the WIPO copyright treaty adopted on 20 December 1996, or
+similar laws prohibiting or restricting circumvention of such
+measures.
+
+  When you convey a covered work, you waive any legal power to forbid
+circumvention of technological measures to the extent such circumvention
+is effected by exercising rights under this License with respect to
+the covered work, and you disclaim any intention to limit operation or
+modification of the work as a means of enforcing, against the work's
+users, your or third parties' legal rights to forbid circumvention of
+technological measures.
+
+  4. Conveying Verbatim Copies.
+
+  You may convey verbatim copies of the Program's source code as you
+receive it, in any medium, provided that you conspicuously and
+appropriately publish on each copy an appropriate copyright notice;
+keep intact all notices stating that this License and any
+non-permissive terms added in accord with section 7 apply to the code;
+keep intact all notices of the absence of any warranty; and give all
+recipients a copy of this License along with the Program.
+
+  You may charge any price or no price for each copy that you convey,
+and you may offer support or warranty protection for a fee.
+
+  5. Conveying Modified Source Versions.
+
+  You may convey a work based on the Program, or the modifications to
+produce it from the Program, in the form of source code under the
+terms of section 4, provided that you also meet all of these conditions:
+
+    a) The work must carry prominent notices stating that you modified
+    it, and giving a relevant date.
+
+    b) The work must carry prominent notices stating that it is
+    released under this License and any conditions added under section
+    7.  This requirement modifies the requirement in section 4 to
+    "keep intact all notices".
+
+    c) You must license the entire work, as a whole, under this
+    License to anyone who comes into possession of a copy.  This
+    License will therefore apply, along with any applicable section 7
+    additional terms, to the whole of the work, and all its parts,
+    regardless of how they are packaged.  This License gives no
+    permission to license the work in any other way, but it does not
+    invalidate such permission if you have separately received it.
+
+    d) If the work has interactive user interfaces, each must display
+    Appropriate Legal Notices; however, if the Program has interactive
+    interfaces that do not display Appropriate Legal Notices, your
+    work need not make them do so.
+
+  A compilation of a covered work with other separate and independent
+works, which are not by their nature extensions of the covered work,
+and which are not combined with it such as to form a larger program,
+in or on a volume of a storage or distribution medium, is called an
+"aggregate" if the compilation and its resulting copyright are not
+used to limit the access or legal rights of the compilation's users
+beyond what the individual works permit.  Inclusion of a covered work
+in an aggregate does not cause this License to apply to the other
+parts of the aggregate.
+
+  6. Conveying Non-Source Forms.
+
+  You may convey a covered work in object code form under the terms
+of sections 4 and 5, provided that you also convey the
+machine-readable Corresponding Source under the terms of this License,
+in one of these ways:
+
+    a) Convey the object code in, or embodied in, a physical product
+    (including a physical distribution medium), accompanied by the
+    Corresponding Source fixed on a durable physical medium
+    customarily used for software interchange.
+
+    b) Convey the object code in, or embodied in, a physical product
+    (including a physical distribution medium), accompanied by a
+    written offer, valid for at least three years and valid for as
+    long as you offer spare parts or customer support for that product
+    model, to give anyone who possesses the object code either (1) a
+    copy of the Corresponding Source for all the software in the
+    product that is covered by this License, on a durable physical
+    medium customarily used for software interchange, for a price no
+    more than your reasonable cost of physically performing this
+    conveying of source, or (2) access to copy the
+    Corresponding Source from a network server at no charge.
+
+    c) Convey individual copies of the object code with a copy of the
+    written offer to provide the Corresponding Source.  This
+    alternative is allowed only occasionally and noncommercially, and
+    only if you received the object code with such an offer, in accord
+    with subsection 6b.
+
+    d) Convey the object code by offering access from a designated
+    place (gratis or for a charge), and offer equivalent access to the
+    Corresponding Source in the same way through the same place at no
+    further charge.  You need not require recipients to copy the
+    Corresponding Source along with the object code.  If the place to
+    copy the object code is a network server, the Corresponding Source
+    may be on a different server (operated by you or a third party)
+    that supports equivalent copying facilities, provided you maintain
+    clear directions next to the object code saying where to find the
+    Corresponding Source.  Regardless of what server hosts the
+    Corresponding Source, you remain obligated to ensure that it is
+    available for as long as needed to satisfy these requirements.
+
+    e) Convey the object code using peer-to-peer transmission, provided
+    you inform other peers where the object code and Corresponding
+    Source of the work are being offered to the general public at no
+    charge under subsection 6d.
+
+  A separable portion of the object code, whose source code is excluded
+from the Corresponding Source as a System Library, need not be
+included in conveying the object code work.
+
+  A "User Product" is either (1) a "consumer product", which means any
+tangible personal property which is normally used for personal, family,
+or household purposes, or (2) anything designed or sold for incorporation
+into a dwelling.  In determining whether a product is a consumer product,
+doubtful cases shall be resolved in favor of coverage.  For a particular
+product received by a particular user, "normally used" refers to a
+typical or common use of that class of product, regardless of the status
+of the particular user or of the way in which the particular user
+actually uses, or expects or is expected to use, the product.  A product
+is a consumer product regardless of whether the product has substantial
+commercial, industrial or non-consumer uses, unless such uses represent
+the only significant mode of use of the product.
+
+  "Installation Information" for a User Product means any methods,
+procedures, authorization keys, or other information required to install
+and execute modified versions of a covered work in that User Product from
+a modified version of its Corresponding Source.  The information must
+suffice to ensure that the continued functioning of the modified object
+code is in no case prevented or interfered with solely because
+modification has been made.
+
+  If you convey an object code work under this section in, or with, or
+specifically for use in, a User Product, and the conveying occurs as
+part of a transaction in which the right of possession and use of the
+User Product is transferred to the recipient in perpetuity or for a
+fixed term (regardless of how the transaction is characterized), the
+Corresponding Source conveyed under this section must be accompanied
+by the Installation Information.  But this requirement does not apply
+if neither you nor any third party retains the ability to install
+modified object code on the User Product (for example, the work has
+been installed in ROM).
+
+  The requirement to provide Installation Information does not include a
+requirement to continue to provide support service, warranty, or updates
+for a work that has been modified or installed by the recipient, or for
+the User Product in which it has been modified or installed.  Access to a
+network may be denied when the modification itself materially and
+adversely affects the operation of the network or violates the rules and
+protocols for communication across the network.
+
+  Corresponding Source conveyed, and Installation Information provided,
+in accord with this section must be in a format that is publicly
+documented (and with an implementation available to the public in
+source code form), and must require no special password or key for
+unpacking, reading or copying.
+
+  7. Additional Terms.
+
+  "Additional permissions" are terms that supplement the terms of this
+License by making exceptions from one or more of its conditions.
+Additional permissions that are applicable to the entire Program shall
+be treated as though they were included in this License, to the extent
+that they are valid under applicable law.  If additional permissions
+apply only to part of the Program, that part may be used separately
+under those permissions, but the entire Program remains governed by
+this License without regard to the additional permissions.
+
+  When you convey a copy of a covered work, you may at your option
+remove any additional permissions from that copy, or from any part of
+it.  (Additional permissions may be written to require their own
+removal in certain cases when you modify the work.)  You may place
+additional permissions on material, added by you to a covered work,
+for which you have or can give appropriate copyright permission.
+
+  Notwithstanding any other provision of this License, for material you
+add to a covered work, you may (if authorized by the copyright holders of
+that material) supplement the terms of this License with terms:
+
+    a) Disclaiming warranty or limiting liability differently from the
+    terms of sections 15 and 16 of this License; or
+
+    b) Requiring preservation of specified reasonable legal notices or
+    author attributions in that material or in the Appropriate Legal
+    Notices displayed by works containing it; or
+
+    c) Prohibiting misrepresentation of the origin of that material, or
+    requiring that modified versions of such material be marked in
+    reasonable ways as different from the original version; or
+
+    d) Limiting the use for publicity purposes of names of licensors or
+    authors of the material; or
+
+    e) Declining to grant rights under trademark law for use of some
+    trade names, trademarks, or service marks; or
+
+    f) Requiring indemnification of licensors and authors of that
+    material by anyone who conveys the material (or modified versions of
+    it) with contractual assumptions of liability to the recipient, for
+    any liability that these contractual assumptions directly impose on
+    those licensors and authors.
+
+  All other non-permissive additional terms are considered "further
+restrictions" within the meaning of section 10.  If the Program as you
+received it, or any part of it, contains a notice stating that it is
+governed by this License along with a term that is a further
+restriction, you may remove that term.  If a license document contains
+a further restriction but permits relicensing or conveying under this
+License, you may add to a covered work material governed by the terms
+of that license document, provided that the further restriction does
+not survive such relicensing or conveying.
+
+  If you add terms to a covered work in accord with this section, you
+must place, in the relevant source files, a statement of the
+additional terms that apply to those files, or a notice indicating
+where to find the applicable terms.
+
+  Additional terms, permissive or non-permissive, may be stated in the
+form of a separately written license, or stated as exceptions;
+the above requirements apply either way.
+
+  8. Termination.
+
+  You may not propagate or modify a covered work except as expressly
+provided under this License.  Any attempt otherwise to propagate or
+modify it is void, and will automatically terminate your rights under
+this License (including any patent licenses granted under the third
+paragraph of section 11).
+
+  However, if you cease all violation of this License, then your
+license from a particular copyright holder is reinstated (a)
+provisionally, unless and until the copyright holder explicitly and
+finally terminates your license, and (b) permanently, if the copyright
+holder fails to notify you of the violation by some reasonable means
+prior to 60 days after the cessation.
+
+  Moreover, your license from a particular copyright holder is
+reinstated permanently if the copyright holder notifies you of the
+violation by some reasonable means, this is the first time you have
+received notice of violation of this License (for any work) from that
+copyright holder, and you cure the violation prior to 30 days after
+your receipt of the notice.
+
+  Termination of your rights under this section does not terminate the
+licenses of parties who have received copies or rights from you under
+this License.  If your rights have been terminated and not permanently
+reinstated, you do not qualify to receive new licenses for the same
+material under section 10.
+
+  9. Acceptance Not Required for Having Copies.
+
+  You are not required to accept this License in order to receive or
+run a copy of the Program.  Ancillary propagation of a covered work
+occurring solely as a consequence of using peer-to-peer transmission
+to receive a copy likewise does not require acceptance.  However,
+nothing other than this License grants you permission to propagate or
+modify any covered work.  These actions infringe copyright if you do
+not accept this License.  Therefore, by modifying or propagating a
+covered work, you indicate your acceptance of this License to do so.
+
+  10. Automatic Licensing of Downstream Recipients.
+
+  Each time you convey a covered work, the recipient automatically
+receives a license from the original licensors, to run, modify and
+propagate that work, subject to this License.  You are not responsible
+for enforcing compliance by third parties with this License.
+
+  An "entity transaction" is a transaction transferring control of an
+organization, or substantially all assets of one, or subdividing an
+organization, or merging organizations.  If propagation of a covered
+work results from an entity transaction, each party to that
+transaction who receives a copy of the work also receives whatever
+licenses to the work the party's predecessor in interest had or could
+give under the previous paragraph, plus a right to possession of the
+Corresponding Source of the work from the predecessor in interest, if
+the predecessor has it or can get it with reasonable efforts.
+
+  You may not impose any further restrictions on the exercise of the
+rights granted or affirmed under this License.  For example, you may
+not impose a license fee, royalty, or other charge for exercise of
+rights granted under this License, and you may not initiate litigation
+(including a cross-claim or counterclaim in a lawsuit) alleging that
+any patent claim is infringed by making, using, selling, offering for
+sale, or importing the Program or any portion of it.
+
+  11. Patents.
+
+  A "contributor" is a copyright holder who authorizes use under this
+License of the Program or a work on which the Program is based.  The
+work thus licensed is called the contributor's "contributor version".
+
+  A contributor's "essential patent claims" are all patent claims
+owned or controlled by the contributor, whether already acquired or
+hereafter acquired, that would be infringed by some manner, permitted
+by this License, of making, using, or selling its contributor version,
+but do not include claims that would be infringed only as a
+consequence of further modification of the contributor version.  For
+purposes of this definition, "control" includes the right to grant
+patent sublicenses in a manner consistent with the requirements of
+this License.
+
+  Each contributor grants you a non-exclusive, worldwide, royalty-free
+patent license under the contributor's essential patent claims, to
+make, use, sell, offer for sale, import and otherwise run, modify and
+propagate the contents of its contributor version.
+
+  In the following three paragraphs, a "patent license" is any express
+agreement or commitment, however denominated, not to enforce a patent
+(such as an express permission to practice a patent or covenant not to
+sue for patent infringement).  To "grant" such a patent license to a
+party means to make such an agreement or commitment not to enforce a
+patent against the party.
+
+  If you convey a covered work, knowingly relying on a patent license,
+and the Corresponding Source of the work is not available for anyone
+to copy, free of charge and under the terms of this License, through a
+publicly available network server or other readily accessible means,
+then you must either (1) cause the Corresponding Source to be so
+available, or (2) arrange to deprive yourself of the benefit of the
+patent license for this particular work, or (3) arrange, in a manner
+consistent with the requirements of this License, to extend the patent
+license to downstream recipients.  "Knowingly relying" means you have
+actual knowledge that, but for the patent license, your conveying the
+covered work in a country, or your recipient's use of the covered work
+in a country, would infringe one or more identifiable patents in that
+country that you have reason to believe are valid.
+
+  If, pursuant to or in connection with a single transaction or
+arrangement, you convey, or propagate by procuring conveyance of, a
+covered work, and grant a patent license to some of the parties
+receiving the covered work authorizing them to use, propagate, modify
+or convey a specific copy of the covered work, then the patent license
+you grant is automatically extended to all recipients of the covered
+work and works based on it.
+
+  A patent license is "discriminatory" if it does not include within
+the scope of its coverage, prohibits the exercise of, or is
+conditioned on the non-exercise of one or more of the rights that are
+specifically granted under this License.  You may not convey a covered
+work if you are a party to an arrangement with a third party that is
+in the business of distributing software, under which you make payment
+to the third party based on the extent of your activity of conveying
+the work, and under which the third party grants, to any of the
+parties who would receive the covered work from you, a discriminatory
+patent license (a) in connection with copies of the covered work
+conveyed by you (or copies made from those copies), or (b) primarily
+for and in connection with specific products or compilations that
+contain the covered work, unless you entered into that arrangement,
+or that patent license was granted, prior to 28 March 2007.
+
+  Nothing in this License shall be construed as excluding or limiting
+any implied license or other defenses to infringement that may
+otherwise be available to you under applicable patent law.
+
+  12. No Surrender of Others' Freedom.
+
+  If conditions are imposed on you (whether by court order, agreement or
+otherwise) that contradict the conditions of this License, they do not
+excuse you from the conditions of this License.  If you cannot convey a
+covered work so as to satisfy simultaneously your obligations under this
+License and any other pertinent obligations, then as a consequence you may
+not convey it at all.  For example, if you agree to terms that obligate you
+to collect a royalty for further conveying from those to whom you convey
+the Program, the only way you could satisfy both those terms and this
+License would be to refrain entirely from conveying the Program.
+
+  13. Use with the GNU Affero General Public License.
+
+  Notwithstanding any other provision of this License, you have
+permission to link or combine any covered work with a work licensed
+under version 3 of the GNU Affero General Public License into a single
+combined work, and to convey the resulting work.  The terms of this
+License will continue to apply to the part which is the covered work,
+but the special requirements of the GNU Affero General Public License,
+section 13, concerning interaction through a network will apply to the
+combination as such.
+
+  14. Revised Versions of this License.
+
+  The Free Software Foundation may publish revised and/or new versions of
+the GNU General Public License from time to time.  Such new versions will
+be similar in spirit to the present version, but may differ in detail to
+address new problems or concerns.
+
+  Each version is given a distinguishing version number.  If the
+Program specifies that a certain numbered version of the GNU General
+Public License "or any later version" applies to it, you have the
+option of following the terms and conditions either of that numbered
+version or of any later version published by the Free Software
+Foundation.  If the Program does not specify a version number of the
+GNU General Public License, you may choose any version ever published
+by the Free Software Foundation.
+
+  If the Program specifies that a proxy can decide which future
+versions of the GNU General Public License can be used, that proxy's
+public statement of acceptance of a version permanently authorizes you
+to choose that version for the Program.
+
+  Later license versions may give you additional or different
+permissions.  However, no additional obligations are imposed on any
+author or copyright holder as a result of your choosing to follow a
+later version.
+
+  15. Disclaimer of Warranty.
+
+  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
+APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
+HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
+OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
+THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
+IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
+ALL NECESSARY SERVICING, REPAIR OR CORRECTION.
+
+  16. Limitation of Liability.
+
+  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
+WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
+THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
+GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
+USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
+DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
+PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
+EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
+SUCH DAMAGES.
+
+  17. Interpretation of Sections 15 and 16.
+
+  If the disclaimer of warranty and limitation of liability provided
+above cannot be given local legal effect according to their terms,
+reviewing courts shall apply local law that most closely approximates
+an absolute waiver of all civil liability in connection with the
+Program, unless a warranty or assumption of liability accompanies a
+copy of the Program in return for a fee.
+
+                     END OF TERMS AND CONDITIONS
+
+            How to Apply These Terms to Your New Programs
+
+  If you develop a new program, and you want it to be of the greatest
+possible use to the public, the best way to achieve this is to make it
+free software which everyone can redistribute and change under these terms.
+
+  To do so, attach the following notices to the program.  It is safest
+to attach them to the start of each source file to most effectively
+state the exclusion of warranty; and each file should have at least
+the "copyright" line and a pointer to where the full notice is found.
+
+    <one line to give the program's name and a brief idea of what it does.>
+    Copyright (C) <year>  <name of author>
+
+    This program is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with this program.  If not, see <https://www.gnu.org/licenses/>.
+
+Also add information on how to contact you by electronic and paper mail.
+
+  If the program does terminal interaction, make it output a short
+notice like this when it starts in an interactive mode:
+
+    <program>  Copyright (C) <year>  <name of author>
+    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
+    This is free software, and you are welcome to redistribute it
+    under certain conditions; type `show c' for details.
+
+The hypothetical commands `show w' and `show c' should show the appropriate
+parts of the General Public License.  Of course, your program's commands
+might be different; for a GUI interface, you would use an "about box".
+
+  You should also get your employer (if you work as a programmer) or school,
+if any, to sign a "copyright disclaimer" for the program, if necessary.
+For more information on this, and how to apply and follow the GNU GPL, see
+<https://www.gnu.org/licenses/>.
+
+  The GNU General Public License does not permit incorporating your program
+into proprietary programs.  If your program is a subroutine library, you
+may consider it more useful to permit linking proprietary applications with
+the library.  If this is what you want to do, use the GNU Lesser General
+Public License instead of this License.  But first, please read
+<https://www.gnu.org/licenses/why-not-lgpl.html>.
```

