# Comparing `tmp/armada_client-0.2.9-py3-none-any.whl.zip` & `tmp/armada_client-0.3.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,48 +1,49 @@
-Zip file size: 185259 bytes, number of entries: 46
--rw-r--r--  2.0 unx        0 b- defN 24-Feb-23 12:03 armada_client/__init__.py
--rw-r--r--  2.0 unx    13315 b- defN 24-Feb-23 12:03 armada_client/asyncio_client.py
--rw-r--r--  2.0 unx    12978 b- defN 24-Feb-23 12:03 armada_client/client.py
--rw-r--r--  2.0 unx     1092 b- defN 24-Feb-23 12:03 armada_client/event.py
--rw-r--r--  2.0 unx     1110 b- defN 24-Feb-23 12:03 armada_client/permissions.py
--rw-r--r--  2.0 unx        0 b- defN 24-Feb-23 12:02 armada_client/py.typed
--rw-r--r--  2.0 unx     2098 b- defN 24-Feb-23 12:03 armada_client/typings.py
--rw-r--r--  2.0 unx    23778 b- defN 24-Feb-23 12:03 armada_client/armada/event_pb2.py
--rw-r--r--  2.0 unx    47203 b- defN 24-Feb-23 12:03 armada_client/armada/event_pb2.pyi
--rw-r--r--  2.0 unx     5691 b- defN 24-Feb-23 12:03 armada_client/armada/event_pb2_grpc.py
--rw-r--r--  2.0 unx     1596 b- defN 24-Feb-23 12:03 armada_client/armada/health_pb2.py
--rw-r--r--  2.0 unx     1774 b- defN 24-Feb-23 12:03 armada_client/armada/health_pb2.pyi
--rw-r--r--  2.0 unx      159 b- defN 24-Feb-23 12:03 armada_client/armada/health_pb2_grpc.py
--rw-r--r--  2.0 unx     7766 b- defN 24-Feb-23 12:03 armada_client/armada/job_pb2.py
--rw-r--r--  2.0 unx    12882 b- defN 24-Feb-23 12:03 armada_client/armada/job_pb2.pyi
--rw-r--r--  2.0 unx     5623 b- defN 24-Feb-23 12:03 armada_client/armada/job_pb2_grpc.py
--rw-r--r--  2.0 unx    20253 b- defN 24-Feb-23 12:03 armada_client/armada/submit_pb2.py
--rw-r--r--  2.0 unx    37354 b- defN 24-Feb-23 12:03 armada_client/armada/submit_pb2.pyi
--rw-r--r--  2.0 unx    19792 b- defN 24-Feb-23 12:03 armada_client/armada/submit_pb2_grpc.py
--rw-r--r--  2.0 unx     2764 b- defN 24-Feb-23 12:03 armada_client/gen/event_typings.py
--rw-r--r--  2.0 unx     7770 b- defN 24-Feb-23 12:03 armada_client/github/com/gogo/protobuf/gogoproto/gogo_pb2.py
--rw-r--r--  2.0 unx    15509 b- defN 24-Feb-23 12:03 armada_client/github/com/gogo/protobuf/gogoproto/gogo_pb2.pyi
--rw-r--r--  2.0 unx     1590 b- defN 24-Feb-23 12:03 armada_client/google/api/annotations_pb2.py
--rw-r--r--  2.0 unx     1053 b- defN 24-Feb-23 12:03 armada_client/google/api/annotations_pb2.pyi
--rw-r--r--  2.0 unx      159 b- defN 24-Feb-23 12:03 armada_client/google/api/annotations_pb2_grpc.py
--rw-r--r--  2.0 unx     2273 b- defN 24-Feb-23 12:03 armada_client/google/api/http_pb2.py
--rw-r--r--  2.0 unx    15201 b- defN 24-Feb-23 12:03 armada_client/google/api/http_pb2.pyi
--rw-r--r--  2.0 unx      159 b- defN 24-Feb-23 12:03 armada_client/google/api/http_pb2_grpc.py
--rw-r--r--  2.0 unx    92958 b- defN 24-Feb-23 12:03 armada_client/k8s/io/api/core/v1/generated_pb2.py
--rw-r--r--  2.0 unx   502797 b- defN 24-Feb-23 12:03 armada_client/k8s/io/api/core/v1/generated_pb2.pyi
--rw-r--r--  2.0 unx     9202 b- defN 24-Feb-23 12:03 armada_client/k8s/io/api/networking/v1/generated_pb2.py
--rw-r--r--  2.0 unx    42480 b- defN 24-Feb-23 12:03 armada_client/k8s/io/api/networking/v1/generated_pb2.pyi
--rw-r--r--  2.0 unx     1245 b- defN 24-Feb-23 12:03 armada_client/k8s/io/apimachinery/pkg/api/resource/generated_pb2.py
--rw-r--r--  2.0 unx     3698 b- defN 24-Feb-23 12:03 armada_client/k8s/io/apimachinery/pkg/api/resource/generated_pb2.pyi
--rw-r--r--  2.0 unx    15227 b- defN 24-Feb-23 12:03 armada_client/k8s/io/apimachinery/pkg/apis/meta/v1/generated_pb2.py
--rw-r--r--  2.0 unx    89806 b- defN 24-Feb-23 12:03 armada_client/k8s/io/apimachinery/pkg/apis/meta/v1/generated_pb2.pyi
--rw-r--r--  2.0 unx     1737 b- defN 24-Feb-23 12:03 armada_client/k8s/io/apimachinery/pkg/runtime/generated_pb2.py
--rw-r--r--  2.0 unx     6024 b- defN 24-Feb-23 12:03 armada_client/k8s/io/apimachinery/pkg/runtime/generated_pb2.pyi
--rw-r--r--  2.0 unx     1106 b- defN 24-Feb-23 12:03 armada_client/k8s/io/apimachinery/pkg/runtime/schema/generated_pb2.py
--rw-r--r--  2.0 unx      236 b- defN 24-Feb-23 12:03 armada_client/k8s/io/apimachinery/pkg/runtime/schema/generated_pb2.pyi
--rw-r--r--  2.0 unx     1319 b- defN 24-Feb-23 12:03 armada_client/k8s/io/apimachinery/pkg/util/intstr/generated_pb2.py
--rw-r--r--  2.0 unx     1629 b- defN 24-Feb-23 12:03 armada_client/k8s/io/apimachinery/pkg/util/intstr/generated_pb2.pyi
--rw-r--r--  2.0 unx     2351 b- defN 24-Feb-23 12:04 armada_client-0.2.9.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Feb-23 12:04 armada_client-0.2.9.dist-info/WHEEL
--rw-r--r--  2.0 unx       14 b- defN 24-Feb-23 12:04 armada_client-0.2.9.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     4598 b- defN 24-Feb-23 12:04 armada_client-0.2.9.dist-info/RECORD
-46 files, 1037461 bytes uncompressed, 177685 bytes compressed:  82.9%
+Zip file size: 190990 bytes, number of entries: 47
+-rw-r--r--  2.0 unx        0 b- defN 24-May-21 11:21 armada_client/__init__.py
+-rw-r--r--  2.0 unx    15237 b- defN 24-May-21 11:21 armada_client/asyncio_client.py
+-rw-r--r--  2.0 unx    14778 b- defN 24-May-21 11:21 armada_client/client.py
+-rw-r--r--  2.0 unx     1092 b- defN 24-May-21 11:21 armada_client/event.py
+-rw-r--r--  2.0 unx     5743 b- defN 24-May-21 11:21 armada_client/iterators.py
+-rw-r--r--  2.0 unx     1110 b- defN 24-May-21 11:21 armada_client/permissions.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-21 11:19 armada_client/py.typed
+-rw-r--r--  2.0 unx     2176 b- defN 24-May-21 11:21 armada_client/typings.py
+-rw-r--r--  2.0 unx    24704 b- defN 24-May-21 11:21 armada_client/armada/event_pb2.py
+-rw-r--r--  2.0 unx    47707 b- defN 24-May-21 11:21 armada_client/armada/event_pb2.pyi
+-rw-r--r--  2.0 unx     7244 b- defN 24-May-21 11:21 armada_client/armada/event_pb2_grpc.py
+-rw-r--r--  2.0 unx     1598 b- defN 24-May-21 11:21 armada_client/armada/health_pb2.py
+-rw-r--r--  2.0 unx     1753 b- defN 24-May-21 11:21 armada_client/armada/health_pb2.pyi
+-rw-r--r--  2.0 unx     1130 b- defN 24-May-21 11:21 armada_client/armada/health_pb2_grpc.py
+-rw-r--r--  2.0 unx     8761 b- defN 24-May-21 11:21 armada_client/armada/job_pb2.py
+-rw-r--r--  2.0 unx    12599 b- defN 24-May-21 11:21 armada_client/armada/job_pb2.pyi
+-rw-r--r--  2.0 unx     7173 b- defN 24-May-21 11:21 armada_client/armada/job_pb2_grpc.py
+-rw-r--r--  2.0 unx    25230 b- defN 24-May-21 11:21 armada_client/armada/submit_pb2.py
+-rw-r--r--  2.0 unx    42791 b- defN 24-May-21 11:21 armada_client/armada/submit_pb2.pyi
+-rw-r--r--  2.0 unx    24602 b- defN 24-May-21 11:21 armada_client/armada/submit_pb2_grpc.py
+-rw-r--r--  2.0 unx     2764 b- defN 24-May-21 11:21 armada_client/gen/event_typings.py
+-rw-r--r--  2.0 unx     7772 b- defN 24-May-21 11:21 armada_client/github/com/gogo/protobuf/gogoproto/gogo_pb2.py
+-rw-r--r--  2.0 unx    15510 b- defN 24-May-21 11:21 armada_client/github/com/gogo/protobuf/gogoproto/gogo_pb2.pyi
+-rw-r--r--  2.0 unx     1592 b- defN 24-May-21 11:21 armada_client/google/api/annotations_pb2.py
+-rw-r--r--  2.0 unx     1054 b- defN 24-May-21 11:21 armada_client/google/api/annotations_pb2.pyi
+-rw-r--r--  2.0 unx     1139 b- defN 24-May-21 11:21 armada_client/google/api/annotations_pb2_grpc.py
+-rw-r--r--  2.0 unx     2275 b- defN 24-May-21 11:21 armada_client/google/api/http_pb2.py
+-rw-r--r--  2.0 unx    15003 b- defN 24-May-21 11:21 armada_client/google/api/http_pb2.pyi
+-rw-r--r--  2.0 unx     1132 b- defN 24-May-21 11:21 armada_client/google/api/http_pb2_grpc.py
+-rw-r--r--  2.0 unx    93149 b- defN 24-May-21 11:21 armada_client/k8s/io/api/core/v1/generated_pb2.py
+-rw-r--r--  2.0 unx   495575 b- defN 24-May-21 11:21 armada_client/k8s/io/api/core/v1/generated_pb2.pyi
+-rw-r--r--  2.0 unx     9204 b- defN 24-May-21 11:21 armada_client/k8s/io/api/networking/v1/generated_pb2.py
+-rw-r--r--  2.0 unx    41656 b- defN 24-May-21 11:21 armada_client/k8s/io/api/networking/v1/generated_pb2.pyi
+-rw-r--r--  2.0 unx     1247 b- defN 24-May-21 11:21 armada_client/k8s/io/apimachinery/pkg/api/resource/generated_pb2.py
+-rw-r--r--  2.0 unx     3563 b- defN 24-May-21 11:21 armada_client/k8s/io/apimachinery/pkg/api/resource/generated_pb2.pyi
+-rw-r--r--  2.0 unx    15250 b- defN 24-May-21 11:21 armada_client/k8s/io/apimachinery/pkg/apis/meta/v1/generated_pb2.py
+-rw-r--r--  2.0 unx    88269 b- defN 24-May-21 11:21 armada_client/k8s/io/apimachinery/pkg/apis/meta/v1/generated_pb2.pyi
+-rw-r--r--  2.0 unx     1739 b- defN 24-May-21 11:21 armada_client/k8s/io/apimachinery/pkg/runtime/generated_pb2.py
+-rw-r--r--  2.0 unx     5823 b- defN 24-May-21 11:21 armada_client/k8s/io/apimachinery/pkg/runtime/generated_pb2.pyi
+-rw-r--r--  2.0 unx     1108 b- defN 24-May-21 11:21 armada_client/k8s/io/apimachinery/pkg/runtime/schema/generated_pb2.py
+-rw-r--r--  2.0 unx      237 b- defN 24-May-21 11:21 armada_client/k8s/io/apimachinery/pkg/runtime/schema/generated_pb2.pyi
+-rw-r--r--  2.0 unx     1321 b- defN 24-May-21 11:21 armada_client/k8s/io/apimachinery/pkg/util/intstr/generated_pb2.py
+-rw-r--r--  2.0 unx     1494 b- defN 24-May-21 11:21 armada_client/k8s/io/apimachinery/pkg/util/intstr/generated_pb2.pyi
+-rw-r--r--  2.0 unx     2351 b- defN 24-May-21 11:21 armada_client-0.3.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-May-21 11:21 armada_client-0.3.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       14 b- defN 24-May-21 11:21 armada_client-0.3.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     4684 b- defN 24-May-21 11:21 armada_client-0.3.0.dist-info/RECORD
+47 files, 1060445 bytes uncompressed, 183288 bytes compressed:  82.7%
```

## zipnote {}

```diff
@@ -6,14 +6,17 @@
 
 Filename: armada_client/client.py
 Comment: 
 
 Filename: armada_client/event.py
 Comment: 
 
+Filename: armada_client/iterators.py
+Comment: 
+
 Filename: armada_client/permissions.py
 Comment: 
 
 Filename: armada_client/py.typed
 Comment: 
 
 Filename: armada_client/typings.py
@@ -120,20 +123,20 @@
 
 Filename: armada_client/k8s/io/apimachinery/pkg/util/intstr/generated_pb2.py
 Comment: 
 
 Filename: armada_client/k8s/io/apimachinery/pkg/util/intstr/generated_pb2.pyi
 Comment: 
 
-Filename: armada_client-0.2.9.dist-info/METADATA
+Filename: armada_client-0.3.0.dist-info/METADATA
 Comment: 
 
-Filename: armada_client-0.2.9.dist-info/WHEEL
+Filename: armada_client-0.3.0.dist-info/WHEEL
 Comment: 
 
-Filename: armada_client-0.2.9.dist-info/top_level.txt
+Filename: armada_client-0.3.0.dist-info/top_level.txt
 Comment: 
 
-Filename: armada_client-0.2.9.dist-info/RECORD
+Filename: armada_client-0.3.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## armada_client/asyncio_client.py

```diff
@@ -1,14 +1,16 @@
 """
 Armada Python GRPC Client
 
 For the api definitions:
 https://armadaproject.io/api
 """
 
+from datetime import timedelta
+import logging
 from typing import Dict, List, Optional, AsyncIterator
 
 import grpc
 from google.protobuf import empty_pb2
 
 from armada_client.armada import (
     event_pb2,
@@ -17,29 +19,96 @@
     submit_pb2_grpc,
     health_pb2,
 )
 from armada_client.event import Event
 from armada_client.k8s.io.api.core.v1 import generated_pb2 as core_v1
 from armada_client.permissions import Permissions
 from armada_client.typings import JobState
+from armada_client.iterators import AsyncTimeoutIterator, IteratorTimeoutException
+
+
+class _AsyncResilientArmadaEventStream(AsyncIterator[event_pb2.EventStreamMessage]):
+    def __init__(
+        self,
+        *,
+        queue: str,
+        job_set_id: str,
+        from_message_id: Optional[str] = None,
+        event_stub: event_pb2_grpc.EventStub,
+        event_timeout: timedelta,
+    ):
+        self._queue = queue
+        self._job_set_id = job_set_id
+        self._last_message_id = from_message_id or ""
+        self._stream = None
+        self._cancelled = False
+        self._event_stub = event_stub
+        self._event_timeout = event_timeout
+        self._timeout_iterator = None
+
+    def __aiter__(self) -> AsyncIterator[event_pb2.EventStreamMessage]:
+        return self
+
+    async def __anext__(self) -> event_pb2.EventStreamMessage:
+        while True:
+            if self._cancelled:
+                raise StopAsyncIteration()
+            if self._timeout_iterator is None:
+                self._timeout_iterator = self._re_connect()
+            try:
+                # we can't use anext here, as it requires python 3.10+
+                message = await self._timeout_iterator.__anext__()
+                self._last_message_id = message.id
+                return message
+            except IteratorTimeoutException:
+                self._timeout_iterator = None
+
+    def _re_connect(self):
+        self._close_connection()
+        jsr = event_pb2.JobSetRequest(
+            queue=self._queue,
+            id=self._job_set_id,
+            from_message_id=self._last_message_id,
+            watch=True,
+            errorIfMissing=True,
+        )
+        self._stream = self._event_stub.GetJobSetEvents(jsr)
+        return AsyncTimeoutIterator(self._stream, timeout=self._event_timeout)
+
+    def _close_connection(self):
+        if self._stream is not None:
+            self._stream.cancel()
+            self._stream = None
+
+    def cancel(self):
+        self._cancelled = True
+        self._close_connection()
+
+
+logger = logging.getLogger("armada_client.asyncio_client")
 
 
 class ArmadaAsyncIOClient:
     """
     Client for accessing Armada over gRPC with AsyncIO.
 
     :param channel: AsyncIO gRPC channel used for authentication. See
                     https://grpc.github.io/grpc/python/grpc_asyncio.html
                     for more information.
     :return: an Armada client instance
     """
 
-    def __init__(self, channel: grpc.aio.Channel) -> None:
+    def __init__(
+        self,
+        channel: grpc.aio.Channel,
+        event_timeout: timedelta = timedelta(minutes=15),
+    ) -> None:
         self.submit_stub = submit_pb2_grpc.SubmitStub(channel)
         self.event_stub = event_pb2_grpc.EventStub(channel)
+        self.event_timeout = event_timeout
 
     async def get_job_events_stream(
         self,
         queue: str,
         job_set_id: str,
         from_message_id: Optional[str] = None,
     ) -> AsyncIterator[event_pb2.EventStreamMessage]:
@@ -58,27 +127,21 @@
                 print(event)
 
         :param queue: The name of the queue
         :param job_set_id: The name of the job set (a grouping of jobs)
         :param from_message_id: The from message id.
         :return: A job events stream for the job_set_id provided.
         """
-
-        if from_message_id is None:
-            from_message_id = ""
-
-        jsr = event_pb2.JobSetRequest(
+        return _AsyncResilientArmadaEventStream(
             queue=queue,
-            id=job_set_id,
+            job_set_id=job_set_id,
             from_message_id=from_message_id,
-            watch=True,
-            errorIfMissing=True,
+            event_stub=self.event_stub,
+            event_timeout=self.event_timeout,
         )
-        response = self.event_stub.GetJobSetEvents(jsr)
-        return response
 
     @staticmethod
     def unmarshal_event_response(event: event_pb2.EventStreamMessage) -> Event:
         """
         Unmarshal an event response from the gRPC server.
 
         :param event: The event response from the gRPC server.
@@ -120,44 +183,41 @@
             queue=queue, job_set_id=job_set_id, job_request_items=job_request_items
         )
         response = await self.submit_stub.SubmitJobs(request)
         return response
 
     async def cancel_jobs(
         self,
-        queue: Optional[str] = None,
+        queue: str,
+        job_set_id: str,
         job_id: Optional[str] = None,
-        job_set_id: Optional[str] = None,
     ) -> submit_pb2.CancellationResult:
         """Cancel jobs in a given queue.
 
-        Uses the CancelJobs RPC to cancel jobs. Either job_id or
-        job_set_id is required.
+        Uses the CancelJobs RPC to cancel jobs.
 
         :param queue: The name of the queue
-        :param job_id: The name of the job id (this or job_set_id required)
-        :param job_set_id: An array of JobSubmitRequestItems. (this or job_id required)
+        :param job_set_id: The name of the job set id
+        :param job_id: The name of the job id (optional), if empty - cancel all jobs
         :return: A CancellationResult object.
         """
+        if not queue or not job_set_id:
+            raise ValueError("Both queue and job_set_id must be provided.")
 
-        # Checks to ensure that either job_id is provided,
-        # or job_set_id AND queue is provided.
-        # ensure that the others have appropriate empty values.
-
-        if job_id and not queue and not job_set_id:
-            request = submit_pb2.JobCancelRequest(job_id=job_id)
-
-        elif job_set_id and queue and not job_id:
-            request = submit_pb2.JobCancelRequest(queue=queue, job_set_id=job_set_id)
-
+        if job_id and queue and job_set_id:
+            request = submit_pb2.JobCancelRequest(
+                queue=queue, job_set_id=job_set_id, job_id=job_id
+            )
+            return await self.submit_stub.CancelJobs(request)
         else:
-            raise ValueError("Either job_id or job_set_id and queue must be provided.")
-
-        response = await self.submit_stub.CancelJobs(request)
-        return response
+            logger.warning(
+                "cancelling all jobs within a jobset via cancel_jobs is deprecated. "
+                "Use cancel_jobset instead."
+            )
+            return await self.cancel_jobset(queue, job_set_id, [])  # type: ignore
 
     async def cancel_jobset(
         self,
         queue: str,
         job_set_id: str,
         filter_states: List[JobState],
     ) -> empty_pb2.Empty:
@@ -182,51 +242,48 @@
         )
         response = await self.submit_stub.CancelJobSet(request)
         return response
 
     async def reprioritize_jobs(
         self,
         new_priority: float,
-        job_ids: Optional[List[str]] = None,
-        job_set_id: Optional[str] = None,
-        queue: Optional[str] = None,
+        job_ids: Optional[List[str]],
+        job_set_id: str,
+        queue: str,
     ) -> submit_pb2.JobReprioritizeResponse:
         """Reprioritize jobs with new_priority value.
 
         Uses ReprioritizeJobs RPC to set a new priority on a list of jobs
-        or job set.
+        or job set (if job_ids are set to None or empty).
 
         :param new_priority: The new priority value for the jobs
         :param job_ids: A list of job ids to change priority of
         :param job_set_id: A job set id including jobs to change priority of
         :param queue: The queue the jobs are in
         :return: JobReprioritizeResponse object. It is a map of strings.
         """
+        if not queue or not job_set_id:
+            raise ValueError("Both queue and job_set_id must be provided.")
 
-        # Same as in cancel_jobs, ensure that either
-        # job_ids or job_set_id and queue is provided.
-
-        if job_ids and not job_set_id and not queue:
+        if job_ids:
             request = submit_pb2.JobReprioritizeRequest(
+                queue=queue,
+                job_set_id=job_set_id,
                 job_ids=job_ids,
                 new_priority=new_priority,
             )
 
-        elif job_set_id and queue and not job_ids:
+        else:
             request = submit_pb2.JobReprioritizeRequest(
-                job_set_id=job_set_id,
                 queue=queue,
+                job_set_id=job_set_id,
                 new_priority=new_priority,
             )
 
-        else:
-            raise ValueError("Either job_ids or job_set_id and queue must be provided.")
-
-        response = await self.submit_stub.ReprioritizeJobs(request)
-        return response
+        return await self.submit_stub.ReprioritizeJobs(request)
 
     async def create_queue(self, queue: submit_pb2.Queue) -> empty_pb2.Empty:
         """
         Uses the CreateQueue RPC to create a queue.
 
         :param queue: A queue to create.
         """
```

## armada_client/client.py

```diff
@@ -1,14 +1,16 @@
 """
 Armada Python GRPC Client
 
 For the api definitions:
 https://armadaproject.io/api
 """
 
+from datetime import timedelta
+import logging
 from typing import Dict, Iterator, List, Optional
 
 from google.protobuf import empty_pb2
 
 from armada_client.armada import (
     event_pb2,
     event_pb2_grpc,
@@ -16,29 +18,94 @@
     submit_pb2_grpc,
     health_pb2,
 )
 from armada_client.event import Event
 from armada_client.k8s.io.api.core.v1 import generated_pb2 as core_v1
 from armada_client.permissions import Permissions
 from armada_client.typings import JobState
+from armada_client.iterators import (
+    IteratorTimeoutException,
+    TimeoutIterator,
+)
+
+
+class _ResilientArmadaEventStream(Iterator[event_pb2.EventStreamMessage]):
+    def __init__(
+        self,
+        *,
+        queue: str,
+        job_set_id: str,
+        from_message_id: Optional[str] = None,
+        event_stub: event_pb2_grpc.EventStub,
+        event_timeout: timedelta,
+    ):
+        self._queue = queue
+        self._job_set_id = job_set_id
+        self._last_message_id = from_message_id or ""
+        self._stream = None
+        self._cancelled = False
+        self._event_stub = event_stub
+        self._event_timeout = event_timeout
+        self._timeout_iterator = None
+
+    def __iter__(self) -> Iterator[event_pb2.EventStreamMessage]:
+        return self
+
+    def __next__(self) -> event_pb2.EventStreamMessage:
+        while True:
+            if self._cancelled:
+                raise StopIteration()
+            if self._timeout_iterator is None:
+                self._timeout_iterator = self._re_connect()
+            try:
+                message = next(self._timeout_iterator)
+                self._last_message_id = message.id
+                return message
+            except IteratorTimeoutException:
+                self._timeout_iterator = None
+
+    def _re_connect(self):
+        self._close_connection()
+        jsr = event_pb2.JobSetRequest(
+            queue=self._queue,
+            id=self._job_set_id,
+            from_message_id=self._last_message_id,
+            watch=True,
+            errorIfMissing=True,
+        )
+        self._stream = self._event_stub.GetJobSetEvents(jsr)
+        return TimeoutIterator(self._stream, timeout=self._event_timeout)
+
+    def _close_connection(self):
+        if self._stream is not None:
+            self._stream.cancel()
+            self._stream = None
+
+    def cancel(self):
+        self._cancelled = True
+        self._close_connection()
+
+
+logger = logging.getLogger("armada_client.asyncio_client")
 
 
 class ArmadaClient:
     """
     Client for accessing Armada over gRPC.
 
     :param channel: gRPC channel used for authentication. See
                     https://grpc.github.io/grpc/python/grpc.html
                     for more information.
     :return: an Armada client instance
     """
 
-    def __init__(self, channel):
+    def __init__(self, channel, event_timeout: timedelta = timedelta(minutes=15)):
         self.submit_stub = submit_pb2_grpc.SubmitStub(channel)
         self.event_stub = event_pb2_grpc.EventStub(channel)
+        self.event_timeout = event_timeout
 
     def get_job_events_stream(
         self,
         queue: str,
         job_set_id: str,
         from_message_id: Optional[str] = None,
     ) -> Iterator[event_pb2.EventStreamMessage]:
@@ -57,26 +124,21 @@
                 print(event)
 
         :param queue: The name of the queue
         :param job_set_id: The name of the job set (a grouping of jobs)
         :param from_message_id: The from message id.
         :return: A job events stream for the job_set_id provided.
         """
-
-        if from_message_id is None:
-            from_message_id = ""
-
-        jsr = event_pb2.JobSetRequest(
+        return _ResilientArmadaEventStream(
             queue=queue,
-            id=job_set_id,
+            job_set_id=job_set_id,
             from_message_id=from_message_id,
-            watch=True,
-            errorIfMissing=True,
+            event_stub=self.event_stub,
+            event_timeout=self.event_timeout,
         )
-        return self.event_stub.GetJobSetEvents(jsr)
 
     @staticmethod
     def unmarshal_event_response(event: event_pb2.EventStreamMessage) -> Event:
         """
         Unmarshal an event response from the gRPC server.
 
         :param event: The event response from the gRPC server.
@@ -116,44 +178,41 @@
             queue=queue, job_set_id=job_set_id, job_request_items=job_request_items
         )
         response = self.submit_stub.SubmitJobs(request)
         return response
 
     def cancel_jobs(
         self,
-        queue: Optional[str] = None,
+        queue: str,
+        job_set_id: str,
         job_id: Optional[str] = None,
-        job_set_id: Optional[str] = None,
     ) -> submit_pb2.CancellationResult:
         """Cancel jobs in a given queue.
 
-        Uses the CancelJobs RPC to cancel jobs. Either job_id or
-        job_set_id is required.
+        Uses the CancelJobs RPC to cancel jobs.
 
         :param queue: The name of the queue
-        :param job_id: The name of the job id (this or job_set_id required)
-        :param job_set_id: An array of JobSubmitRequestItems. (this or job_id required)
+        :param job_set_id: The name of the job set id
+        :param job_id: The name of the job id (optional), if empty - cancel all jobs
         :return: A CancellationResult object.
         """
+        if not queue or not job_set_id:
+            raise ValueError("Both queue and job_set_id must be provided.")
 
-        # Checks to ensure that either job_id is provided,
-        # or job_set_id AND queue is provided.
-        # ensure that the others have appropriate empty values.
-
-        if job_id and not queue and not job_set_id:
-            request = submit_pb2.JobCancelRequest(job_id=job_id)
-
-        elif job_set_id and queue and not job_id:
-            request = submit_pb2.JobCancelRequest(queue=queue, job_set_id=job_set_id)
-
+        if job_id and queue and job_set_id:
+            request = submit_pb2.JobCancelRequest(
+                queue=queue, job_set_id=job_set_id, job_id=job_id
+            )
+            return self.submit_stub.CancelJobs(request)
         else:
-            raise ValueError("Either job_id or job_set_id and queue must be provided.")
-
-        response = self.submit_stub.CancelJobs(request)
-        return response
+            logger.warning(
+                "cancelling all jobs within a jobset via cancel_jobs is deprecated. "
+                "Use cancel_jobset instead."
+            )
+            return self.cancel_jobset(queue, job_set_id, [])  # type: ignore
 
     def cancel_jobset(
         self,
         queue: str,
         job_set_id: str,
         filter_states: List[JobState],
     ) -> empty_pb2.Empty:
@@ -178,51 +237,48 @@
         )
         response = self.submit_stub.CancelJobSet(request)
         return response
 
     def reprioritize_jobs(
         self,
         new_priority: float,
-        job_ids: Optional[List[str]] = None,
-        job_set_id: Optional[str] = None,
-        queue: Optional[str] = None,
+        job_ids: Optional[List[str]],
+        job_set_id: str,
+        queue: str,
     ) -> submit_pb2.JobReprioritizeResponse:
         """Reprioritize jobs with new_priority value.
 
         Uses ReprioritizeJobs RPC to set a new priority on a list of jobs
-        or job set.
+        or job set (if job_ids are set to None or empty).
 
         :param new_priority: The new priority value for the jobs
         :param job_ids: A list of job ids to change priority of
         :param job_set_id: A job set id including jobs to change priority of
         :param queue: The queue the jobs are in
         :return: JobReprioritizeResponse object. It is a map of strings.
         """
+        if not queue or not job_set_id:
+            raise ValueError("Both queue and job_set_id must be provided.")
 
-        # Same as in cancel_jobs, ensure that either
-        # job_ids or job_set_id and queue is provided.
-
-        if job_ids and not job_set_id and not queue:
+        if job_ids:
             request = submit_pb2.JobReprioritizeRequest(
+                queue=queue,
+                job_set_id=job_set_id,
                 job_ids=job_ids,
                 new_priority=new_priority,
             )
 
-        elif job_set_id and queue and not job_ids:
+        else:
             request = submit_pb2.JobReprioritizeRequest(
-                job_set_id=job_set_id,
                 queue=queue,
+                job_set_id=job_set_id,
                 new_priority=new_priority,
             )
 
-        else:
-            raise ValueError("Either job_ids or job_set_id and queue must be provided.")
-
-        response = self.submit_stub.ReprioritizeJobs(request)
-        return response
+        return self.submit_stub.ReprioritizeJobs(request)
 
     def create_queue(self, queue: submit_pb2.Queue) -> empty_pb2.Empty:
         """
         Uses the CreateQueue RPC to create a queue.
 
         :param queue: A queue to create.
         """
```

## armada_client/typings.py

```diff
@@ -9,14 +9,15 @@
     JobLeaseReturnedEvent,
     JobLeaseExpiredEvent,
     JobPendingEvent,
     JobRunningEvent,
     JobIngressInfoEvent,
     JobUnableToScheduleEvent,
     JobFailedEvent,
+    JobPreemptingEvent,
     JobPreemptedEvent,
     JobSucceededEvent,
     JobUtilisationEvent,
     JobReprioritizingEvent,
     JobReprioritizedEvent,
     JobCancellingEvent,
     JobCancelledEvent,
@@ -47,14 +48,15 @@
     terminated = "terminated"
     utilisation = "utilisation"
     ingress_info = "ingress_info"
     reprioritizing = "reprioritizing"
     updated = "updated"
     failedCompressed = "failedCompressed"
     preempted = "preempted"
+    preempting = "preempting"
 
 
 class JobState(Enum):
     """
     Enum for the job states.
     Used by cancel_jobset.
     """
@@ -80,14 +82,15 @@
     JobLeaseReturnedEvent,
     JobLeaseExpiredEvent,
     JobPendingEvent,
     JobRunningEvent,
     JobIngressInfoEvent,
     JobUnableToScheduleEvent,
     JobFailedEvent,
+    JobPreemptingEvent,
     JobPreemptedEvent,
     JobSucceededEvent,
     JobUtilisationEvent,
     JobReprioritizingEvent,
     JobReprioritizedEvent,
     JobCancellingEvent,
     JobCancelledEvent,
```

## armada_client/armada/event_pb2.py

```diff
@@ -1,11 +1,11 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: armada/event.proto
-# Protobuf Python Version: 4.25.1
+# Protobuf Python Version: 5.26.1
 """Generated protocol buffer code."""
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
 from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
@@ -17,86 +17,88 @@
 from armada_client.armada import health_pb2 as armada_dot_health__pb2
 from google.protobuf import empty_pb2 as google_dot_protobuf_dot_empty__pb2
 from armada_client.github.com.gogo.protobuf.gogoproto import gogo_pb2 as github_dot_com_dot_gogo_dot_protobuf_dot_gogoproto_dot_gogo__pb2
 from armada_client.google.api import annotations_pb2 as google_dot_api_dot_annotations__pb2
 from armada_client.k8s.io.apimachinery.pkg.api.resource import generated_pb2 as k8s_dot_io_dot_apimachinery_dot_pkg_dot_api_dot_resource_dot_generated__pb2
 
 
-DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x12\x61rmada/event.proto\x12\x03\x61pi\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\x13\x61rmada/submit.proto\x1a\x13\x61rmada/health.proto\x1a\x1bgoogle/protobuf/empty.proto\x1a-github.com/gogo/protobuf/gogoproto/gogo.proto\x1a\x1cgoogle/api/annotations.proto\x1a\x34k8s.io/apimachinery/pkg/api/resource/generated.proto\"\x9a\x01\n\x11JobSubmittedEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x1b\n\x03job\x18\x05 \x01(\x0b\x32\x08.api.JobB\x04\xc8\xde\x1f\x00\"z\n\x0eJobQueuedEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\"\x9b\x01\n\x16JobDuplicateFoundEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x17\n\x0foriginal_job_id\x18\x05 \x01(\t\"\x8e\x01\n\x0eJobLeasedEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\"\xe7\x01\n\x15JobLeaseReturnedEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x0e\n\x06reason\x18\x06 \x01(\t\x12\x15\n\rkubernetes_id\x18\x07 \x01(\t\x12\x12\n\npod_number\x18\x08 \x01(\x05\x12\x15\n\rrun_attempted\x18\t \x01(\x08\"\x80\x01\n\x14JobLeaseExpiredEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\"\xe3\x01\n\x0fJobPendingEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x15\n\rkubernetes_id\x18\x06 \x01(\t\x12\x12\n\npod_number\x18\x07 \x01(\x05\x12\x10\n\x08pod_name\x18\x08 \x01(\t\x12\x15\n\rpod_namespace\x18\t \x01(\t\"\xf6\x01\n\x0fJobRunningEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x15\n\rkubernetes_id\x18\x06 \x01(\t\x12\x11\n\tnode_name\x18\x07 \x01(\t\x12\x12\n\npod_number\x18\x08 \x01(\x05\x12\x10\n\x08pod_name\x18\t \x01(\t\x12\x15\n\rpod_namespace\x18\n \x01(\t\"\xfe\x02\n\x13JobIngressInfoEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x15\n\rkubernetes_id\x18\x06 \x01(\t\x12\x11\n\tnode_name\x18\x07 \x01(\t\x12\x12\n\npod_number\x18\x08 \x01(\x05\x12\x10\n\x08pod_name\x18\n \x01(\t\x12\x15\n\rpod_namespace\x18\x0b \x01(\t\x12I\n\x11ingress_addresses\x18\t \x03(\x0b\x32..api.JobIngressInfoEvent.IngressAddressesEntry\x1a\x37\n\x15IngressAddressesEntry\x12\x0b\n\x03key\x18\x01 \x01(\x05\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"\x8f\x02\n\x18JobUnableToScheduleEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x0e\n\x06reason\x18\x06 \x01(\t\x12\x15\n\rkubernetes_id\x18\x07 \x01(\t\x12\x11\n\tnode_name\x18\x08 \x01(\t\x12\x12\n\npod_number\x18\t \x01(\x05\x12\x10\n\x08pod_name\x18\n \x01(\t\x12\x15\n\rpod_namespace\x18\x0b \x01(\t\"\xc0\x03\n\x0eJobFailedEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x0e\n\x06reason\x18\x06 \x01(\t\x12:\n\nexit_codes\x18\x07 \x03(\x0b\x32\".api.JobFailedEvent.ExitCodesEntryB\x02\x18\x01\x12\x15\n\rkubernetes_id\x18\x08 \x01(\t\x12\x11\n\tnode_name\x18\t \x01(\t\x12\x12\n\npod_number\x18\n \x01(\x05\x12\x10\n\x08pod_name\x18\r \x01(\t\x12\x15\n\rpod_namespace\x18\x0e \x01(\t\x12\x30\n\x12\x63ontainer_statuses\x18\x0b \x03(\x0b\x32\x14.api.ContainerStatus\x12\x19\n\x05\x63\x61use\x18\x0c \x01(\x0e\x32\n.api.Cause\x1a\x30\n\x0e\x45xitCodesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\x05:\x02\x38\x01\"\xd7\x01\n\x11JobPreemptedEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x0e\n\x06run_id\x18\x06 \x01(\t\x12\x19\n\x11preemptive_job_id\x18\x07 \x01(\t\x12\x19\n\x11preemptive_run_id\x18\x08 \x01(\t\")\n\x18JobFailedEventCompressed\x12\r\n\x05\x65vent\x18\x01 \x01(\x0c\"\xf8\x01\n\x11JobSucceededEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x15\n\rkubernetes_id\x18\x06 \x01(\t\x12\x11\n\tnode_name\x18\x07 \x01(\t\x12\x12\n\npod_number\x18\x08 \x01(\x05\x12\x10\n\x08pod_name\x18\t \x01(\t\x12\x15\n\rpod_namespace\x18\n \x01(\t\"\x89\x05\n\x13JobUtilisationEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x15\n\rkubernetes_id\x18\x06 \x01(\t\x12X\n\x15MaxResourcesForPeriod\x18\x07 \x03(\x0b\x32\x33.api.JobUtilisationEvent.MaxResourcesForPeriodEntryB\x04\xc8\xde\x1f\x00\x12\x11\n\tnode_name\x18\x08 \x01(\t\x12\x12\n\npod_number\x18\t \x01(\x05\x12\x10\n\x08pod_name\x18\n \x01(\t\x12\x15\n\rpod_namespace\x18\x0b \x01(\t\x12X\n\x16total_cumulative_usage\x18\x0c \x03(\x0b\x32\x32.api.JobUtilisationEvent.TotalCumulativeUsageEntryB\x04\xc8\xde\x1f\x00\x1al\n\x1aMaxResourcesForPeriodEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\x1ak\n\x19TotalCumulativeUsageEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\"\xab\x01\n\x16JobReprioritizingEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x14\n\x0cnew_priority\x18\x05 \x01(\x01\x12\x11\n\trequestor\x18\x06 \x01(\t\"\xaa\x01\n\x15JobReprioritizedEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x14\n\x0cnew_priority\x18\x05 \x01(\x01\x12\x11\n\trequestor\x18\x06 \x01(\t\"\xa1\x01\n\x12JobCancellingEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x11\n\trequestor\x18\x05 \x01(\t\x12\x0e\n\x06reason\x18\x06 \x01(\t\"\xa0\x01\n\x11JobCancelledEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x11\n\trequestor\x18\x05 \x01(\t\x12\x0e\n\x06reason\x18\x06 \x01(\t\"\xf6\x01\n\x12JobTerminatedEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x15\n\rkubernetes_id\x18\x06 \x01(\t\x12\x12\n\npod_number\x18\x07 \x01(\x05\x12\x10\n\x08pod_name\x18\t \x01(\t\x12\x15\n\rpod_namespace\x18\n \x01(\t\x12\x0e\n\x06reason\x18\x08 \x01(\t\"\xab\x01\n\x0fJobUpdatedEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x11\n\trequestor\x18\x05 \x01(\t\x12\x1b\n\x03job\x18\x06 \x01(\x0b\x32\x08.api.JobB\x04\xc8\xde\x1f\x00\"\x83\x08\n\x0c\x45ventMessage\x12+\n\tsubmitted\x18\x01 \x01(\x0b\x32\x16.api.JobSubmittedEventH\x00\x12%\n\x06queued\x18\x02 \x01(\x0b\x32\x13.api.JobQueuedEventH\x00\x12\x36\n\x0f\x64uplicate_found\x18\x10 \x01(\x0b\x32\x1b.api.JobDuplicateFoundEventH\x00\x12%\n\x06leased\x18\x03 \x01(\x0b\x32\x13.api.JobLeasedEventH\x00\x12\x34\n\x0elease_returned\x18\x04 \x01(\x0b\x32\x1a.api.JobLeaseReturnedEventH\x00\x12\x32\n\rlease_expired\x18\x05 \x01(\x0b\x32\x19.api.JobLeaseExpiredEventH\x00\x12\'\n\x07pending\x18\x06 \x01(\x0b\x32\x14.api.JobPendingEventH\x00\x12\'\n\x07running\x18\x07 \x01(\x0b\x32\x14.api.JobRunningEventH\x00\x12;\n\x12unable_to_schedule\x18\x08 \x01(\x0b\x32\x1d.api.JobUnableToScheduleEventH\x00\x12%\n\x06\x66\x61iled\x18\t \x01(\x0b\x32\x13.api.JobFailedEventH\x00\x12+\n\tsucceeded\x18\n \x01(\x0b\x32\x16.api.JobSucceededEventH\x00\x12\x33\n\rreprioritized\x18\x0b \x01(\x0b\x32\x1a.api.JobReprioritizedEventH\x00\x12-\n\ncancelling\x18\x0c \x01(\x0b\x32\x17.api.JobCancellingEventH\x00\x12+\n\tcancelled\x18\r \x01(\x0b\x32\x16.api.JobCancelledEventH\x00\x12-\n\nterminated\x18\x0e \x01(\x0b\x32\x17.api.JobTerminatedEventH\x00\x12/\n\x0butilisation\x18\x0f \x01(\x0b\x32\x18.api.JobUtilisationEventH\x00\x12\x30\n\x0cingress_info\x18\x11 \x01(\x0b\x32\x18.api.JobIngressInfoEventH\x00\x12\x35\n\x0ereprioritizing\x18\x12 \x01(\x0b\x32\x1b.api.JobReprioritizingEventH\x00\x12\'\n\x07updated\x18\x13 \x01(\x0b\x32\x14.api.JobUpdatedEventH\x00\x12\x39\n\x10\x66\x61iledCompressed\x18\x14 \x01(\x0b\x32\x1d.api.JobFailedEventCompressedH\x00\x12+\n\tpreempted\x18\x15 \x01(\x0b\x32\x16.api.JobPreemptedEventH\x00\x42\x08\n\x06\x65vents\"m\n\x0f\x43ontainerStatus\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x10\n\x08\x65xitCode\x18\x02 \x01(\x05\x12\x0f\n\x07message\x18\x03 \x01(\t\x12\x0e\n\x06reason\x18\x04 \x01(\t\x12\x19\n\x05\x63\x61use\x18\x05 \x01(\x0e\x32\n.api.Cause\"D\n\x12\x45ventStreamMessage\x12\n\n\x02id\x18\x01 \x01(\t\x12\"\n\x07message\x18\x02 \x01(\x0b\x32\x11.api.EventMessage\"\x93\x01\n\rJobSetRequest\x12\n\n\x02id\x18\x01 \x01(\t\x12\r\n\x05watch\x18\x02 \x01(\x08\x12\x17\n\x0f\x66rom_message_id\x18\x03 \x01(\t\x12\r\n\x05queue\x18\x04 \x01(\t\x12\x16\n\x0e\x65rrorIfMissing\x18\x05 \x01(\x08\x12\x14\n\x0c\x66orce_legacy\x18\x06 \x01(\x08\x12\x11\n\tforce_new\x18\x07 \x01(\x08\"k\n\x0cWatchRequest\x12\r\n\x05queue\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\x0f\n\x07\x66rom_id\x18\x03 \x01(\t\x12\x14\n\x0c\x66orce_legacy\x18\x04 \x01(\x08\x12\x11\n\tforce_new\x18\x05 \x01(\x08*>\n\x05\x43\x61use\x12\t\n\x05\x45rror\x10\x00\x12\x0b\n\x07\x45victed\x10\x01\x12\x07\n\x03OOM\x10\x02\x12\x14\n\x10\x44\x65\x61\x64lineExceeded\x10\x03\x32\xe6\x01\n\x05\x45vent\x12\x65\n\x0fGetJobSetEvents\x12\x12.api.JobSetRequest\x1a\x17.api.EventStreamMessage\"#\x82\xd3\xe4\x93\x02\x1d\"\x18/v1/job-set/{queue}/{id}:\x01*0\x01\x12:\n\x05Watch\x12\x11.api.WatchRequest\x1a\x17.api.EventStreamMessage\"\x03\x88\x02\x01\x30\x01\x12:\n\x06Health\x12\x16.google.protobuf.Empty\x1a\x18.api.HealthCheckResponseBHZ\'github.com/armadaproject/armada/pkg/api\xaa\x02\x14\x41rmadaProject.Io.Api\xd8\xe1\x1e\x00\x80\xe2\x1e\x01\x62\x06proto3')
+DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x12\x61rmada/event.proto\x12\x03\x61pi\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\x13\x61rmada/submit.proto\x1a\x13\x61rmada/health.proto\x1a\x1bgoogle/protobuf/empty.proto\x1a-github.com/gogo/protobuf/gogoproto/gogo.proto\x1a\x1cgoogle/api/annotations.proto\x1a\x34k8s.io/apimachinery/pkg/api/resource/generated.proto\"\x9a\x01\n\x11JobSubmittedEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x1b\n\x03job\x18\x05 \x01(\x0b\x32\x08.api.JobB\x04\xc8\xde\x1f\x00\"z\n\x0eJobQueuedEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\"\x9b\x01\n\x16JobDuplicateFoundEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x17\n\x0foriginal_job_id\x18\x05 \x01(\t\"\x8e\x01\n\x0eJobLeasedEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\"\xe7\x01\n\x15JobLeaseReturnedEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x0e\n\x06reason\x18\x06 \x01(\t\x12\x15\n\rkubernetes_id\x18\x07 \x01(\t\x12\x12\n\npod_number\x18\x08 \x01(\x05\x12\x15\n\rrun_attempted\x18\t \x01(\x08\"\x80\x01\n\x14JobLeaseExpiredEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\"\xe3\x01\n\x0fJobPendingEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x15\n\rkubernetes_id\x18\x06 \x01(\t\x12\x12\n\npod_number\x18\x07 \x01(\x05\x12\x10\n\x08pod_name\x18\x08 \x01(\t\x12\x15\n\rpod_namespace\x18\t \x01(\t\"\xf6\x01\n\x0fJobRunningEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x15\n\rkubernetes_id\x18\x06 \x01(\t\x12\x11\n\tnode_name\x18\x07 \x01(\t\x12\x12\n\npod_number\x18\x08 \x01(\x05\x12\x10\n\x08pod_name\x18\t \x01(\t\x12\x15\n\rpod_namespace\x18\n \x01(\t\"\xfe\x02\n\x13JobIngressInfoEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x15\n\rkubernetes_id\x18\x06 \x01(\t\x12\x11\n\tnode_name\x18\x07 \x01(\t\x12\x12\n\npod_number\x18\x08 \x01(\x05\x12\x10\n\x08pod_name\x18\n \x01(\t\x12\x15\n\rpod_namespace\x18\x0b \x01(\t\x12I\n\x11ingress_addresses\x18\t \x03(\x0b\x32..api.JobIngressInfoEvent.IngressAddressesEntry\x1a\x37\n\x15IngressAddressesEntry\x12\x0b\n\x03key\x18\x01 \x01(\x05\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"\x8f\x02\n\x18JobUnableToScheduleEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x0e\n\x06reason\x18\x06 \x01(\t\x12\x15\n\rkubernetes_id\x18\x07 \x01(\t\x12\x11\n\tnode_name\x18\x08 \x01(\t\x12\x12\n\npod_number\x18\t \x01(\x05\x12\x10\n\x08pod_name\x18\n \x01(\t\x12\x15\n\rpod_namespace\x18\x0b \x01(\t\"\xc0\x03\n\x0eJobFailedEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x0e\n\x06reason\x18\x06 \x01(\t\x12:\n\nexit_codes\x18\x07 \x03(\x0b\x32\".api.JobFailedEvent.ExitCodesEntryB\x02\x18\x01\x12\x15\n\rkubernetes_id\x18\x08 \x01(\t\x12\x11\n\tnode_name\x18\t \x01(\t\x12\x12\n\npod_number\x18\n \x01(\x05\x12\x10\n\x08pod_name\x18\r \x01(\t\x12\x15\n\rpod_namespace\x18\x0e \x01(\t\x12\x30\n\x12\x63ontainer_statuses\x18\x0b \x03(\x0b\x32\x14.api.ContainerStatus\x12\x19\n\x05\x63\x61use\x18\x0c \x01(\x0e\x32\n.api.Cause\x1a\x30\n\x0e\x45xitCodesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\x05:\x02\x38\x01\"\x91\x01\n\x12JobPreemptingEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x11\n\trequestor\x18\x05 \x01(\t\"\xd7\x01\n\x11JobPreemptedEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x0e\n\x06run_id\x18\x06 \x01(\t\x12\x19\n\x11preemptive_job_id\x18\x07 \x01(\t\x12\x19\n\x11preemptive_run_id\x18\x08 \x01(\t\")\n\x18JobFailedEventCompressed\x12\r\n\x05\x65vent\x18\x01 \x01(\x0c\"\xf8\x01\n\x11JobSucceededEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x15\n\rkubernetes_id\x18\x06 \x01(\t\x12\x11\n\tnode_name\x18\x07 \x01(\t\x12\x12\n\npod_number\x18\x08 \x01(\x05\x12\x10\n\x08pod_name\x18\t \x01(\t\x12\x15\n\rpod_namespace\x18\n \x01(\t\"\x89\x05\n\x13JobUtilisationEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x15\n\rkubernetes_id\x18\x06 \x01(\t\x12X\n\x15MaxResourcesForPeriod\x18\x07 \x03(\x0b\x32\x33.api.JobUtilisationEvent.MaxResourcesForPeriodEntryB\x04\xc8\xde\x1f\x00\x12\x11\n\tnode_name\x18\x08 \x01(\t\x12\x12\n\npod_number\x18\t \x01(\x05\x12\x10\n\x08pod_name\x18\n \x01(\t\x12\x15\n\rpod_namespace\x18\x0b \x01(\t\x12X\n\x16total_cumulative_usage\x18\x0c \x03(\x0b\x32\x32.api.JobUtilisationEvent.TotalCumulativeUsageEntryB\x04\xc8\xde\x1f\x00\x1al\n\x1aMaxResourcesForPeriodEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\x1ak\n\x19TotalCumulativeUsageEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\"\xab\x01\n\x16JobReprioritizingEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x14\n\x0cnew_priority\x18\x05 \x01(\x01\x12\x11\n\trequestor\x18\x06 \x01(\t\"\xaa\x01\n\x15JobReprioritizedEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x14\n\x0cnew_priority\x18\x05 \x01(\x01\x12\x11\n\trequestor\x18\x06 \x01(\t\"\xa1\x01\n\x12JobCancellingEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x11\n\trequestor\x18\x05 \x01(\t\x12\x0e\n\x06reason\x18\x06 \x01(\t\"\xa0\x01\n\x11JobCancelledEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x11\n\trequestor\x18\x05 \x01(\t\x12\x0e\n\x06reason\x18\x06 \x01(\t\"\xf6\x01\n\x12JobTerminatedEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x12\n\ncluster_id\x18\x05 \x01(\t\x12\x15\n\rkubernetes_id\x18\x06 \x01(\t\x12\x12\n\npod_number\x18\x07 \x01(\x05\x12\x10\n\x08pod_name\x18\t \x01(\t\x12\x15\n\rpod_namespace\x18\n \x01(\t\x12\x0e\n\x06reason\x18\x08 \x01(\t\"\xab\x01\n\x0fJobUpdatedEvent\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x35\n\x07\x63reated\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12\x11\n\trequestor\x18\x05 \x01(\t\x12\x1b\n\x03job\x18\x06 \x01(\x0b\x32\x08.api.JobB\x04\xc8\xde\x1f\x00\"\xb2\x08\n\x0c\x45ventMessage\x12+\n\tsubmitted\x18\x01 \x01(\x0b\x32\x16.api.JobSubmittedEventH\x00\x12%\n\x06queued\x18\x02 \x01(\x0b\x32\x13.api.JobQueuedEventH\x00\x12\x36\n\x0f\x64uplicate_found\x18\x10 \x01(\x0b\x32\x1b.api.JobDuplicateFoundEventH\x00\x12%\n\x06leased\x18\x03 \x01(\x0b\x32\x13.api.JobLeasedEventH\x00\x12\x34\n\x0elease_returned\x18\x04 \x01(\x0b\x32\x1a.api.JobLeaseReturnedEventH\x00\x12\x32\n\rlease_expired\x18\x05 \x01(\x0b\x32\x19.api.JobLeaseExpiredEventH\x00\x12\'\n\x07pending\x18\x06 \x01(\x0b\x32\x14.api.JobPendingEventH\x00\x12\'\n\x07running\x18\x07 \x01(\x0b\x32\x14.api.JobRunningEventH\x00\x12;\n\x12unable_to_schedule\x18\x08 \x01(\x0b\x32\x1d.api.JobUnableToScheduleEventH\x00\x12%\n\x06\x66\x61iled\x18\t \x01(\x0b\x32\x13.api.JobFailedEventH\x00\x12+\n\tsucceeded\x18\n \x01(\x0b\x32\x16.api.JobSucceededEventH\x00\x12\x33\n\rreprioritized\x18\x0b \x01(\x0b\x32\x1a.api.JobReprioritizedEventH\x00\x12-\n\ncancelling\x18\x0c \x01(\x0b\x32\x17.api.JobCancellingEventH\x00\x12+\n\tcancelled\x18\r \x01(\x0b\x32\x16.api.JobCancelledEventH\x00\x12-\n\nterminated\x18\x0e \x01(\x0b\x32\x17.api.JobTerminatedEventH\x00\x12/\n\x0butilisation\x18\x0f \x01(\x0b\x32\x18.api.JobUtilisationEventH\x00\x12\x30\n\x0cingress_info\x18\x11 \x01(\x0b\x32\x18.api.JobIngressInfoEventH\x00\x12\x35\n\x0ereprioritizing\x18\x12 \x01(\x0b\x32\x1b.api.JobReprioritizingEventH\x00\x12\'\n\x07updated\x18\x13 \x01(\x0b\x32\x14.api.JobUpdatedEventH\x00\x12\x39\n\x10\x66\x61iledCompressed\x18\x14 \x01(\x0b\x32\x1d.api.JobFailedEventCompressedH\x00\x12+\n\tpreempted\x18\x15 \x01(\x0b\x32\x16.api.JobPreemptedEventH\x00\x12-\n\npreempting\x18\x16 \x01(\x0b\x32\x17.api.JobPreemptingEventH\x00\x42\x08\n\x06\x65vents\"m\n\x0f\x43ontainerStatus\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x10\n\x08\x65xitCode\x18\x02 \x01(\x05\x12\x0f\n\x07message\x18\x03 \x01(\t\x12\x0e\n\x06reason\x18\x04 \x01(\t\x12\x19\n\x05\x63\x61use\x18\x05 \x01(\x0e\x32\n.api.Cause\"D\n\x12\x45ventStreamMessage\x12\n\n\x02id\x18\x01 \x01(\t\x12\"\n\x07message\x18\x02 \x01(\x0b\x32\x11.api.EventMessage\"\x93\x01\n\rJobSetRequest\x12\n\n\x02id\x18\x01 \x01(\t\x12\r\n\x05watch\x18\x02 \x01(\x08\x12\x17\n\x0f\x66rom_message_id\x18\x03 \x01(\t\x12\r\n\x05queue\x18\x04 \x01(\t\x12\x16\n\x0e\x65rrorIfMissing\x18\x05 \x01(\x08\x12\x14\n\x0c\x66orce_legacy\x18\x06 \x01(\x08\x12\x11\n\tforce_new\x18\x07 \x01(\x08\"k\n\x0cWatchRequest\x12\r\n\x05queue\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\x0f\n\x07\x66rom_id\x18\x03 \x01(\t\x12\x14\n\x0c\x66orce_legacy\x18\x04 \x01(\x08\x12\x11\n\tforce_new\x18\x05 \x01(\x08*L\n\x05\x43\x61use\x12\t\n\x05\x45rror\x10\x00\x12\x0b\n\x07\x45victed\x10\x01\x12\x07\n\x03OOM\x10\x02\x12\x14\n\x10\x44\x65\x61\x64lineExceeded\x10\x03\x12\x0c\n\x08Rejected\x10\x04\x32\xe6\x01\n\x05\x45vent\x12\x65\n\x0fGetJobSetEvents\x12\x12.api.JobSetRequest\x1a\x17.api.EventStreamMessage\"#\x82\xd3\xe4\x93\x02\x1d\"\x18/v1/job-set/{queue}/{id}:\x01*0\x01\x12:\n\x05Watch\x12\x11.api.WatchRequest\x1a\x17.api.EventStreamMessage\"\x03\x88\x02\x01\x30\x01\x12:\n\x06Health\x12\x16.google.protobuf.Empty\x1a\x18.api.HealthCheckResponseBHZ\'github.com/armadaproject/armada/pkg/api\xaa\x02\x14\x41rmadaProject.Io.Api\xd8\xe1\x1e\x00\x80\xe2\x1e\x01\x62\x06proto3')
 
 _globals = globals()
 _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
 _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'armada.event_pb2', _globals)
-if _descriptor._USE_C_DESCRIPTORS == False:
-  _globals['DESCRIPTOR']._options = None
+if not _descriptor._USE_C_DESCRIPTORS:
+  _globals['DESCRIPTOR']._loaded_options = None
   _globals['DESCRIPTOR']._serialized_options = b'Z\'github.com/armadaproject/armada/pkg/api\252\002\024ArmadaProject.Io.Api\330\341\036\000\200\342\036\001'
-  _globals['_JOBSUBMITTEDEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBSUBMITTEDEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBSUBMITTEDEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBSUBMITTEDEVENT'].fields_by_name['job']._options = None
+  _globals['_JOBSUBMITTEDEVENT'].fields_by_name['job']._loaded_options = None
   _globals['_JOBSUBMITTEDEVENT'].fields_by_name['job']._serialized_options = b'\310\336\037\000'
-  _globals['_JOBQUEUEDEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBQUEUEDEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBQUEUEDEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBDUPLICATEFOUNDEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBDUPLICATEFOUNDEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBDUPLICATEFOUNDEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBLEASEDEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBLEASEDEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBLEASEDEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBLEASERETURNEDEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBLEASERETURNEDEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBLEASERETURNEDEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBLEASEEXPIREDEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBLEASEEXPIREDEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBLEASEEXPIREDEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBPENDINGEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBPENDINGEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBPENDINGEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBRUNNINGEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBRUNNINGEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBRUNNINGEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBINGRESSINFOEVENT_INGRESSADDRESSESENTRY']._options = None
+  _globals['_JOBINGRESSINFOEVENT_INGRESSADDRESSESENTRY']._loaded_options = None
   _globals['_JOBINGRESSINFOEVENT_INGRESSADDRESSESENTRY']._serialized_options = b'8\001'
-  _globals['_JOBINGRESSINFOEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBINGRESSINFOEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBINGRESSINFOEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBUNABLETOSCHEDULEEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBUNABLETOSCHEDULEEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBUNABLETOSCHEDULEEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBFAILEDEVENT_EXITCODESENTRY']._options = None
+  _globals['_JOBFAILEDEVENT_EXITCODESENTRY']._loaded_options = None
   _globals['_JOBFAILEDEVENT_EXITCODESENTRY']._serialized_options = b'8\001'
-  _globals['_JOBFAILEDEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBFAILEDEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBFAILEDEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBFAILEDEVENT'].fields_by_name['exit_codes']._options = None
+  _globals['_JOBFAILEDEVENT'].fields_by_name['exit_codes']._loaded_options = None
   _globals['_JOBFAILEDEVENT'].fields_by_name['exit_codes']._serialized_options = b'\030\001'
-  _globals['_JOBPREEMPTEDEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBPREEMPTINGEVENT'].fields_by_name['created']._loaded_options = None
+  _globals['_JOBPREEMPTINGEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
+  _globals['_JOBPREEMPTEDEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBPREEMPTEDEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBSUCCEEDEDEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBSUCCEEDEDEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBSUCCEEDEDEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBUTILISATIONEVENT_MAXRESOURCESFORPERIODENTRY']._options = None
+  _globals['_JOBUTILISATIONEVENT_MAXRESOURCESFORPERIODENTRY']._loaded_options = None
   _globals['_JOBUTILISATIONEVENT_MAXRESOURCESFORPERIODENTRY']._serialized_options = b'8\001'
-  _globals['_JOBUTILISATIONEVENT_TOTALCUMULATIVEUSAGEENTRY']._options = None
+  _globals['_JOBUTILISATIONEVENT_TOTALCUMULATIVEUSAGEENTRY']._loaded_options = None
   _globals['_JOBUTILISATIONEVENT_TOTALCUMULATIVEUSAGEENTRY']._serialized_options = b'8\001'
-  _globals['_JOBUTILISATIONEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBUTILISATIONEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBUTILISATIONEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBUTILISATIONEVENT'].fields_by_name['MaxResourcesForPeriod']._options = None
+  _globals['_JOBUTILISATIONEVENT'].fields_by_name['MaxResourcesForPeriod']._loaded_options = None
   _globals['_JOBUTILISATIONEVENT'].fields_by_name['MaxResourcesForPeriod']._serialized_options = b'\310\336\037\000'
-  _globals['_JOBUTILISATIONEVENT'].fields_by_name['total_cumulative_usage']._options = None
+  _globals['_JOBUTILISATIONEVENT'].fields_by_name['total_cumulative_usage']._loaded_options = None
   _globals['_JOBUTILISATIONEVENT'].fields_by_name['total_cumulative_usage']._serialized_options = b'\310\336\037\000'
-  _globals['_JOBREPRIORITIZINGEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBREPRIORITIZINGEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBREPRIORITIZINGEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBREPRIORITIZEDEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBREPRIORITIZEDEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBREPRIORITIZEDEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBCANCELLINGEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBCANCELLINGEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBCANCELLINGEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBCANCELLEDEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBCANCELLEDEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBCANCELLEDEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBTERMINATEDEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBTERMINATEDEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBTERMINATEDEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBUPDATEDEVENT'].fields_by_name['created']._options = None
+  _globals['_JOBUPDATEDEVENT'].fields_by_name['created']._loaded_options = None
   _globals['_JOBUPDATEDEVENT'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBUPDATEDEVENT'].fields_by_name['job']._options = None
+  _globals['_JOBUPDATEDEVENT'].fields_by_name['job']._loaded_options = None
   _globals['_JOBUPDATEDEVENT'].fields_by_name['job']._serialized_options = b'\310\336\037\000'
-  _globals['_EVENT'].methods_by_name['GetJobSetEvents']._options = None
+  _globals['_EVENT'].methods_by_name['GetJobSetEvents']._loaded_options = None
   _globals['_EVENT'].methods_by_name['GetJobSetEvents']._serialized_options = b'\202\323\344\223\002\035\"\030/v1/job-set/{queue}/{id}:\001*'
-  _globals['_EVENT'].methods_by_name['Watch']._options = None
+  _globals['_EVENT'].methods_by_name['Watch']._loaded_options = None
   _globals['_EVENT'].methods_by_name['Watch']._serialized_options = b'\210\002\001'
-  _globals['_CAUSE']._serialized_start=6531
-  _globals['_CAUSE']._serialized_end=6593
+  _globals['_CAUSE']._serialized_start=6726
+  _globals['_CAUSE']._serialized_end=6802
   _globals['_JOBSUBMITTEDEVENT']._serialized_start=263
   _globals['_JOBSUBMITTEDEVENT']._serialized_end=417
   _globals['_JOBQUEUEDEVENT']._serialized_start=419
   _globals['_JOBQUEUEDEVENT']._serialized_end=541
   _globals['_JOBDUPLICATEFOUNDEVENT']._serialized_start=544
   _globals['_JOBDUPLICATEFOUNDEVENT']._serialized_end=699
   _globals['_JOBLEASEDEVENT']._serialized_start=702
@@ -115,44 +117,46 @@
   _globals['_JOBINGRESSINFOEVENT_INGRESSADDRESSESENTRY']._serialized_end=2073
   _globals['_JOBUNABLETOSCHEDULEEVENT']._serialized_start=2076
   _globals['_JOBUNABLETOSCHEDULEEVENT']._serialized_end=2347
   _globals['_JOBFAILEDEVENT']._serialized_start=2350
   _globals['_JOBFAILEDEVENT']._serialized_end=2798
   _globals['_JOBFAILEDEVENT_EXITCODESENTRY']._serialized_start=2750
   _globals['_JOBFAILEDEVENT_EXITCODESENTRY']._serialized_end=2798
-  _globals['_JOBPREEMPTEDEVENT']._serialized_start=2801
-  _globals['_JOBPREEMPTEDEVENT']._serialized_end=3016
-  _globals['_JOBFAILEDEVENTCOMPRESSED']._serialized_start=3018
-  _globals['_JOBFAILEDEVENTCOMPRESSED']._serialized_end=3059
-  _globals['_JOBSUCCEEDEDEVENT']._serialized_start=3062
-  _globals['_JOBSUCCEEDEDEVENT']._serialized_end=3310
-  _globals['_JOBUTILISATIONEVENT']._serialized_start=3313
-  _globals['_JOBUTILISATIONEVENT']._serialized_end=3962
-  _globals['_JOBUTILISATIONEVENT_MAXRESOURCESFORPERIODENTRY']._serialized_start=3745
-  _globals['_JOBUTILISATIONEVENT_MAXRESOURCESFORPERIODENTRY']._serialized_end=3853
-  _globals['_JOBUTILISATIONEVENT_TOTALCUMULATIVEUSAGEENTRY']._serialized_start=3855
-  _globals['_JOBUTILISATIONEVENT_TOTALCUMULATIVEUSAGEENTRY']._serialized_end=3962
-  _globals['_JOBREPRIORITIZINGEVENT']._serialized_start=3965
-  _globals['_JOBREPRIORITIZINGEVENT']._serialized_end=4136
-  _globals['_JOBREPRIORITIZEDEVENT']._serialized_start=4139
-  _globals['_JOBREPRIORITIZEDEVENT']._serialized_end=4309
-  _globals['_JOBCANCELLINGEVENT']._serialized_start=4312
-  _globals['_JOBCANCELLINGEVENT']._serialized_end=4473
-  _globals['_JOBCANCELLEDEVENT']._serialized_start=4476
-  _globals['_JOBCANCELLEDEVENT']._serialized_end=4636
-  _globals['_JOBTERMINATEDEVENT']._serialized_start=4639
-  _globals['_JOBTERMINATEDEVENT']._serialized_end=4885
-  _globals['_JOBUPDATEDEVENT']._serialized_start=4888
-  _globals['_JOBUPDATEDEVENT']._serialized_end=5059
-  _globals['_EVENTMESSAGE']._serialized_start=5062
-  _globals['_EVENTMESSAGE']._serialized_end=6089
-  _globals['_CONTAINERSTATUS']._serialized_start=6091
-  _globals['_CONTAINERSTATUS']._serialized_end=6200
-  _globals['_EVENTSTREAMMESSAGE']._serialized_start=6202
-  _globals['_EVENTSTREAMMESSAGE']._serialized_end=6270
-  _globals['_JOBSETREQUEST']._serialized_start=6273
-  _globals['_JOBSETREQUEST']._serialized_end=6420
-  _globals['_WATCHREQUEST']._serialized_start=6422
-  _globals['_WATCHREQUEST']._serialized_end=6529
-  _globals['_EVENT']._serialized_start=6596
-  _globals['_EVENT']._serialized_end=6826
+  _globals['_JOBPREEMPTINGEVENT']._serialized_start=2801
+  _globals['_JOBPREEMPTINGEVENT']._serialized_end=2946
+  _globals['_JOBPREEMPTEDEVENT']._serialized_start=2949
+  _globals['_JOBPREEMPTEDEVENT']._serialized_end=3164
+  _globals['_JOBFAILEDEVENTCOMPRESSED']._serialized_start=3166
+  _globals['_JOBFAILEDEVENTCOMPRESSED']._serialized_end=3207
+  _globals['_JOBSUCCEEDEDEVENT']._serialized_start=3210
+  _globals['_JOBSUCCEEDEDEVENT']._serialized_end=3458
+  _globals['_JOBUTILISATIONEVENT']._serialized_start=3461
+  _globals['_JOBUTILISATIONEVENT']._serialized_end=4110
+  _globals['_JOBUTILISATIONEVENT_MAXRESOURCESFORPERIODENTRY']._serialized_start=3893
+  _globals['_JOBUTILISATIONEVENT_MAXRESOURCESFORPERIODENTRY']._serialized_end=4001
+  _globals['_JOBUTILISATIONEVENT_TOTALCUMULATIVEUSAGEENTRY']._serialized_start=4003
+  _globals['_JOBUTILISATIONEVENT_TOTALCUMULATIVEUSAGEENTRY']._serialized_end=4110
+  _globals['_JOBREPRIORITIZINGEVENT']._serialized_start=4113
+  _globals['_JOBREPRIORITIZINGEVENT']._serialized_end=4284
+  _globals['_JOBREPRIORITIZEDEVENT']._serialized_start=4287
+  _globals['_JOBREPRIORITIZEDEVENT']._serialized_end=4457
+  _globals['_JOBCANCELLINGEVENT']._serialized_start=4460
+  _globals['_JOBCANCELLINGEVENT']._serialized_end=4621
+  _globals['_JOBCANCELLEDEVENT']._serialized_start=4624
+  _globals['_JOBCANCELLEDEVENT']._serialized_end=4784
+  _globals['_JOBTERMINATEDEVENT']._serialized_start=4787
+  _globals['_JOBTERMINATEDEVENT']._serialized_end=5033
+  _globals['_JOBUPDATEDEVENT']._serialized_start=5036
+  _globals['_JOBUPDATEDEVENT']._serialized_end=5207
+  _globals['_EVENTMESSAGE']._serialized_start=5210
+  _globals['_EVENTMESSAGE']._serialized_end=6284
+  _globals['_CONTAINERSTATUS']._serialized_start=6286
+  _globals['_CONTAINERSTATUS']._serialized_end=6395
+  _globals['_EVENTSTREAMMESSAGE']._serialized_start=6397
+  _globals['_EVENTSTREAMMESSAGE']._serialized_end=6465
+  _globals['_JOBSETREQUEST']._serialized_start=6468
+  _globals['_JOBSETREQUEST']._serialized_end=6615
+  _globals['_WATCHREQUEST']._serialized_start=6617
+  _globals['_WATCHREQUEST']._serialized_end=6724
+  _globals['_EVENT']._serialized_start=6805
+  _globals['_EVENT']._serialized_end=7035
 # @@protoc_insertion_point(module_scope)
```

## armada_client/armada/event_pb2.pyi

```diff
@@ -1,11 +1,12 @@
 """
 @generated by mypy-protobuf.  Do not edit manually!
 isort:skip_file
 """
+
 import armada.submit_pb2
 import builtins
 import collections.abc
 import google.protobuf.descriptor
 import google.protobuf.internal.containers
 import google.protobuf.internal.enum_type_wrapper
 import google.protobuf.message
@@ -27,24 +28,26 @@
 
 class _CauseEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_Cause.ValueType], builtins.type):
     DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
     Error: _Cause.ValueType  # 0
     Evicted: _Cause.ValueType  # 1
     OOM: _Cause.ValueType  # 2
     DeadlineExceeded: _Cause.ValueType  # 3
+    Rejected: _Cause.ValueType  # 4
 
 class Cause(_Cause, metaclass=_CauseEnumTypeWrapper): ...
 
 Error: Cause.ValueType  # 0
 Evicted: Cause.ValueType  # 1
 OOM: Cause.ValueType  # 2
 DeadlineExceeded: Cause.ValueType  # 3
+Rejected: Cause.ValueType  # 4
 global___Cause = Cause
 
-@typing_extensions.final
+@typing.final
 class JobSubmittedEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
@@ -61,20 +64,20 @@
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         created: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         job: armada.submit_pb2.Job | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created", "job", b"job"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["created", b"created", "job", b"job", "job_id", b"job_id", "job_set_id", b"job_set_id", "queue", b"queue"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created", "job", b"job"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["created", b"created", "job", b"job", "job_id", b"job_id", "job_set_id", b"job_set_id", "queue", b"queue"]) -> None: ...
 
 global___JobSubmittedEvent = JobSubmittedEvent
 
-@typing_extensions.final
+@typing.final
 class JobQueuedEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
@@ -87,78 +90,78 @@
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         created: google.protobuf.timestamp_pb2.Timestamp | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "queue", b"queue"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "queue", b"queue"]) -> None: ...
 
 global___JobQueuedEvent = JobQueuedEvent
 
-@typing_extensions.final
+@typing.final
 class JobDuplicateFoundEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
     ORIGINAL_JOB_ID_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     job_set_id: builtins.str
     queue: builtins.str
+    original_job_id: builtins.str
     @property
     def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
-    original_job_id: builtins.str
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         created: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         original_job_id: builtins.str = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "original_job_id", b"original_job_id", "queue", b"queue"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "original_job_id", b"original_job_id", "queue", b"queue"]) -> None: ...
 
 global___JobDuplicateFoundEvent = JobDuplicateFoundEvent
 
-@typing_extensions.final
+@typing.final
 class JobLeasedEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
     CLUSTER_ID_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     job_set_id: builtins.str
     queue: builtins.str
+    cluster_id: builtins.str
     @property
     def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
-    cluster_id: builtins.str
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         created: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         cluster_id: builtins.str = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["cluster_id", b"cluster_id", "created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "queue", b"queue"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["cluster_id", b"cluster_id", "created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "queue", b"queue"]) -> None: ...
 
 global___JobLeasedEvent = JobLeasedEvent
 
-@typing_extensions.final
+@typing.final
 class JobLeaseReturnedEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
@@ -166,40 +169,40 @@
     REASON_FIELD_NUMBER: builtins.int
     KUBERNETES_ID_FIELD_NUMBER: builtins.int
     POD_NUMBER_FIELD_NUMBER: builtins.int
     RUN_ATTEMPTED_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     job_set_id: builtins.str
     queue: builtins.str
-    @property
-    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     cluster_id: builtins.str
     reason: builtins.str
     kubernetes_id: builtins.str
     pod_number: builtins.int
     run_attempted: builtins.bool
+    @property
+    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         created: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         cluster_id: builtins.str = ...,
         reason: builtins.str = ...,
         kubernetes_id: builtins.str = ...,
         pod_number: builtins.int = ...,
         run_attempted: builtins.bool = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["cluster_id", b"cluster_id", "created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "kubernetes_id", b"kubernetes_id", "pod_number", b"pod_number", "queue", b"queue", "reason", b"reason", "run_attempted", b"run_attempted"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["cluster_id", b"cluster_id", "created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "kubernetes_id", b"kubernetes_id", "pod_number", b"pod_number", "queue", b"queue", "reason", b"reason", "run_attempted", b"run_attempted"]) -> None: ...
 
 global___JobLeaseReturnedEvent = JobLeaseReturnedEvent
 
-@typing_extensions.final
+@typing.final
 class JobLeaseExpiredEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
@@ -212,20 +215,20 @@
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         created: google.protobuf.timestamp_pb2.Timestamp | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "queue", b"queue"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "queue", b"queue"]) -> None: ...
 
 global___JobLeaseExpiredEvent = JobLeaseExpiredEvent
 
-@typing_extensions.final
+@typing.final
 class JobPendingEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
@@ -233,40 +236,40 @@
     KUBERNETES_ID_FIELD_NUMBER: builtins.int
     POD_NUMBER_FIELD_NUMBER: builtins.int
     POD_NAME_FIELD_NUMBER: builtins.int
     POD_NAMESPACE_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     job_set_id: builtins.str
     queue: builtins.str
-    @property
-    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     cluster_id: builtins.str
     kubernetes_id: builtins.str
     pod_number: builtins.int
     pod_name: builtins.str
     pod_namespace: builtins.str
+    @property
+    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         created: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         cluster_id: builtins.str = ...,
         kubernetes_id: builtins.str = ...,
         pod_number: builtins.int = ...,
         pod_name: builtins.str = ...,
         pod_namespace: builtins.str = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["cluster_id", b"cluster_id", "created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "kubernetes_id", b"kubernetes_id", "pod_name", b"pod_name", "pod_namespace", b"pod_namespace", "pod_number", b"pod_number", "queue", b"queue"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["cluster_id", b"cluster_id", "created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "kubernetes_id", b"kubernetes_id", "pod_name", b"pod_name", "pod_namespace", b"pod_namespace", "pod_number", b"pod_number", "queue", b"queue"]) -> None: ...
 
 global___JobPendingEvent = JobPendingEvent
 
-@typing_extensions.final
+@typing.final
 class JobRunningEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
@@ -275,60 +278,60 @@
     NODE_NAME_FIELD_NUMBER: builtins.int
     POD_NUMBER_FIELD_NUMBER: builtins.int
     POD_NAME_FIELD_NUMBER: builtins.int
     POD_NAMESPACE_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     job_set_id: builtins.str
     queue: builtins.str
-    @property
-    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     cluster_id: builtins.str
     kubernetes_id: builtins.str
     node_name: builtins.str
     pod_number: builtins.int
     pod_name: builtins.str
     pod_namespace: builtins.str
+    @property
+    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         created: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         cluster_id: builtins.str = ...,
         kubernetes_id: builtins.str = ...,
         node_name: builtins.str = ...,
         pod_number: builtins.int = ...,
         pod_name: builtins.str = ...,
         pod_namespace: builtins.str = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["cluster_id", b"cluster_id", "created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "kubernetes_id", b"kubernetes_id", "node_name", b"node_name", "pod_name", b"pod_name", "pod_namespace", b"pod_namespace", "pod_number", b"pod_number", "queue", b"queue"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["cluster_id", b"cluster_id", "created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "kubernetes_id", b"kubernetes_id", "node_name", b"node_name", "pod_name", b"pod_name", "pod_namespace", b"pod_namespace", "pod_number", b"pod_number", "queue", b"queue"]) -> None: ...
 
 global___JobRunningEvent = JobRunningEvent
 
-@typing_extensions.final
+@typing.final
 class JobIngressInfoEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class IngressAddressesEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.int
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.int = ...,
             value: builtins.str = ...,
         ) -> None: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
     CLUSTER_ID_FIELD_NUMBER: builtins.int
     KUBERNETES_ID_FIELD_NUMBER: builtins.int
@@ -336,23 +339,23 @@
     POD_NUMBER_FIELD_NUMBER: builtins.int
     POD_NAME_FIELD_NUMBER: builtins.int
     POD_NAMESPACE_FIELD_NUMBER: builtins.int
     INGRESS_ADDRESSES_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     job_set_id: builtins.str
     queue: builtins.str
-    @property
-    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     cluster_id: builtins.str
     kubernetes_id: builtins.str
     node_name: builtins.str
     pod_number: builtins.int
     pod_name: builtins.str
     pod_namespace: builtins.str
     @property
+    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
+    @property
     def ingress_addresses(self) -> google.protobuf.internal.containers.ScalarMap[builtins.int, builtins.str]: ...
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
@@ -361,20 +364,20 @@
         kubernetes_id: builtins.str = ...,
         node_name: builtins.str = ...,
         pod_number: builtins.int = ...,
         pod_name: builtins.str = ...,
         pod_namespace: builtins.str = ...,
         ingress_addresses: collections.abc.Mapping[builtins.int, builtins.str] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["cluster_id", b"cluster_id", "created", b"created", "ingress_addresses", b"ingress_addresses", "job_id", b"job_id", "job_set_id", b"job_set_id", "kubernetes_id", b"kubernetes_id", "node_name", b"node_name", "pod_name", b"pod_name", "pod_namespace", b"pod_namespace", "pod_number", b"pod_number", "queue", b"queue"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["cluster_id", b"cluster_id", "created", b"created", "ingress_addresses", b"ingress_addresses", "job_id", b"job_id", "job_set_id", b"job_set_id", "kubernetes_id", b"kubernetes_id", "node_name", b"node_name", "pod_name", b"pod_name", "pod_namespace", b"pod_namespace", "pod_number", b"pod_number", "queue", b"queue"]) -> None: ...
 
 global___JobIngressInfoEvent = JobIngressInfoEvent
 
-@typing_extensions.final
+@typing.final
 class JobUnableToScheduleEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
@@ -384,23 +387,23 @@
     NODE_NAME_FIELD_NUMBER: builtins.int
     POD_NUMBER_FIELD_NUMBER: builtins.int
     POD_NAME_FIELD_NUMBER: builtins.int
     POD_NAMESPACE_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     job_set_id: builtins.str
     queue: builtins.str
-    @property
-    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     cluster_id: builtins.str
     reason: builtins.str
     kubernetes_id: builtins.str
     node_name: builtins.str
     pod_number: builtins.int
     pod_name: builtins.str
     pod_namespace: builtins.str
+    @property
+    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         created: google.protobuf.timestamp_pb2.Timestamp | None = ...,
@@ -408,38 +411,38 @@
         reason: builtins.str = ...,
         kubernetes_id: builtins.str = ...,
         node_name: builtins.str = ...,
         pod_number: builtins.int = ...,
         pod_name: builtins.str = ...,
         pod_namespace: builtins.str = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["cluster_id", b"cluster_id", "created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "kubernetes_id", b"kubernetes_id", "node_name", b"node_name", "pod_name", b"pod_name", "pod_namespace", b"pod_namespace", "pod_number", b"pod_number", "queue", b"queue", "reason", b"reason"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["cluster_id", b"cluster_id", "created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "kubernetes_id", b"kubernetes_id", "node_name", b"node_name", "pod_name", b"pod_name", "pod_namespace", b"pod_namespace", "pod_number", b"pod_number", "queue", b"queue", "reason", b"reason"]) -> None: ...
 
 global___JobUnableToScheduleEvent = JobUnableToScheduleEvent
 
-@typing_extensions.final
+@typing.final
 class JobFailedEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class ExitCodesEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.int
         def __init__(
             self,
             *,
             key: builtins.str = ...,
             value: builtins.int = ...,
         ) -> None: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
     CLUSTER_ID_FIELD_NUMBER: builtins.int
     REASON_FIELD_NUMBER: builtins.int
@@ -450,28 +453,28 @@
     POD_NAME_FIELD_NUMBER: builtins.int
     POD_NAMESPACE_FIELD_NUMBER: builtins.int
     CONTAINER_STATUSES_FIELD_NUMBER: builtins.int
     CAUSE_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     job_set_id: builtins.str
     queue: builtins.str
-    @property
-    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     cluster_id: builtins.str
     reason: builtins.str
-    @property
-    def exit_codes(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.int]: ...
     kubernetes_id: builtins.str
     node_name: builtins.str
     pod_number: builtins.int
     pod_name: builtins.str
     pod_namespace: builtins.str
+    cause: global___Cause.ValueType
+    @property
+    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
+    @property
+    def exit_codes(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.int]: ...
     @property
     def container_statuses(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ContainerStatus]: ...
-    cause: global___Cause.ValueType
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         created: google.protobuf.timestamp_pb2.Timestamp | None = ...,
@@ -482,75 +485,104 @@
         node_name: builtins.str = ...,
         pod_number: builtins.int = ...,
         pod_name: builtins.str = ...,
         pod_namespace: builtins.str = ...,
         container_statuses: collections.abc.Iterable[global___ContainerStatus] | None = ...,
         cause: global___Cause.ValueType = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["cause", b"cause", "cluster_id", b"cluster_id", "container_statuses", b"container_statuses", "created", b"created", "exit_codes", b"exit_codes", "job_id", b"job_id", "job_set_id", b"job_set_id", "kubernetes_id", b"kubernetes_id", "node_name", b"node_name", "pod_name", b"pod_name", "pod_namespace", b"pod_namespace", "pod_number", b"pod_number", "queue", b"queue", "reason", b"reason"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["cause", b"cause", "cluster_id", b"cluster_id", "container_statuses", b"container_statuses", "created", b"created", "exit_codes", b"exit_codes", "job_id", b"job_id", "job_set_id", b"job_set_id", "kubernetes_id", b"kubernetes_id", "node_name", b"node_name", "pod_name", b"pod_name", "pod_namespace", b"pod_namespace", "pod_number", b"pod_number", "queue", b"queue", "reason", b"reason"]) -> None: ...
 
 global___JobFailedEvent = JobFailedEvent
 
-@typing_extensions.final
+@typing.final
+class JobPreemptingEvent(google.protobuf.message.Message):
+    DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+    JOB_ID_FIELD_NUMBER: builtins.int
+    JOB_SET_ID_FIELD_NUMBER: builtins.int
+    QUEUE_FIELD_NUMBER: builtins.int
+    CREATED_FIELD_NUMBER: builtins.int
+    REQUESTOR_FIELD_NUMBER: builtins.int
+    job_id: builtins.str
+    job_set_id: builtins.str
+    queue: builtins.str
+    requestor: builtins.str
+    @property
+    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
+    def __init__(
+        self,
+        *,
+        job_id: builtins.str = ...,
+        job_set_id: builtins.str = ...,
+        queue: builtins.str = ...,
+        created: google.protobuf.timestamp_pb2.Timestamp | None = ...,
+        requestor: builtins.str = ...,
+    ) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "queue", b"queue", "requestor", b"requestor"]) -> None: ...
+
+global___JobPreemptingEvent = JobPreemptingEvent
+
+@typing.final
 class JobPreemptedEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
     CLUSTER_ID_FIELD_NUMBER: builtins.int
     RUN_ID_FIELD_NUMBER: builtins.int
     PREEMPTIVE_JOB_ID_FIELD_NUMBER: builtins.int
     PREEMPTIVE_RUN_ID_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     job_set_id: builtins.str
     queue: builtins.str
-    @property
-    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     cluster_id: builtins.str
     run_id: builtins.str
     preemptive_job_id: builtins.str
     preemptive_run_id: builtins.str
+    @property
+    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         created: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         cluster_id: builtins.str = ...,
         run_id: builtins.str = ...,
         preemptive_job_id: builtins.str = ...,
         preemptive_run_id: builtins.str = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["cluster_id", b"cluster_id", "created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "preemptive_job_id", b"preemptive_job_id", "preemptive_run_id", b"preemptive_run_id", "queue", b"queue", "run_id", b"run_id"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["cluster_id", b"cluster_id", "created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "preemptive_job_id", b"preemptive_job_id", "preemptive_run_id", b"preemptive_run_id", "queue", b"queue", "run_id", b"run_id"]) -> None: ...
 
 global___JobPreemptedEvent = JobPreemptedEvent
 
-@typing_extensions.final
+@typing.final
 class JobFailedEventCompressed(google.protobuf.message.Message):
     """Only used internally by Armada"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     EVENT_FIELD_NUMBER: builtins.int
     event: builtins.bytes
     def __init__(
         self,
         *,
         event: builtins.bytes = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["event", b"event"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["event", b"event"]) -> None: ...
 
 global___JobFailedEventCompressed = JobFailedEventCompressed
 
-@typing_extensions.final
+@typing.final
 class JobSucceededEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
@@ -559,80 +591,80 @@
     NODE_NAME_FIELD_NUMBER: builtins.int
     POD_NUMBER_FIELD_NUMBER: builtins.int
     POD_NAME_FIELD_NUMBER: builtins.int
     POD_NAMESPACE_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     job_set_id: builtins.str
     queue: builtins.str
-    @property
-    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     cluster_id: builtins.str
     kubernetes_id: builtins.str
     node_name: builtins.str
     pod_number: builtins.int
     pod_name: builtins.str
     pod_namespace: builtins.str
+    @property
+    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         created: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         cluster_id: builtins.str = ...,
         kubernetes_id: builtins.str = ...,
         node_name: builtins.str = ...,
         pod_number: builtins.int = ...,
         pod_name: builtins.str = ...,
         pod_namespace: builtins.str = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["cluster_id", b"cluster_id", "created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "kubernetes_id", b"kubernetes_id", "node_name", b"node_name", "pod_name", b"pod_name", "pod_namespace", b"pod_namespace", "pod_number", b"pod_number", "queue", b"queue"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["cluster_id", b"cluster_id", "created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "kubernetes_id", b"kubernetes_id", "node_name", b"node_name", "pod_name", b"pod_name", "pod_namespace", b"pod_namespace", "pod_number", b"pod_number", "queue", b"queue"]) -> None: ...
 
 global___JobSucceededEvent = JobSucceededEvent
 
-@typing_extensions.final
+@typing.final
 class JobUtilisationEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class MaxResourcesForPeriodEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity: ...
         def __init__(
             self,
             *,
             key: builtins.str = ...,
             value: k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
-    @typing_extensions.final
+    @typing.final
     class TotalCumulativeUsageEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity: ...
         def __init__(
             self,
             *,
             key: builtins.str = ...,
             value: k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
     CLUSTER_ID_FIELD_NUMBER: builtins.int
     KUBERNETES_ID_FIELD_NUMBER: builtins.int
@@ -641,25 +673,25 @@
     POD_NUMBER_FIELD_NUMBER: builtins.int
     POD_NAME_FIELD_NUMBER: builtins.int
     POD_NAMESPACE_FIELD_NUMBER: builtins.int
     TOTAL_CUMULATIVE_USAGE_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     job_set_id: builtins.str
     queue: builtins.str
-    @property
-    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     cluster_id: builtins.str
     kubernetes_id: builtins.str
-    @property
-    def MaxResourcesForPeriod(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity]: ...
     node_name: builtins.str
     pod_number: builtins.int
     pod_name: builtins.str
     pod_namespace: builtins.str
     @property
+    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
+    @property
+    def MaxResourcesForPeriod(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity]: ...
+    @property
     def total_cumulative_usage(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity]: ...
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
@@ -669,148 +701,148 @@
         MaxResourcesForPeriod: collections.abc.Mapping[builtins.str, k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity] | None = ...,
         node_name: builtins.str = ...,
         pod_number: builtins.int = ...,
         pod_name: builtins.str = ...,
         pod_namespace: builtins.str = ...,
         total_cumulative_usage: collections.abc.Mapping[builtins.str, k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["MaxResourcesForPeriod", b"MaxResourcesForPeriod", "cluster_id", b"cluster_id", "created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "kubernetes_id", b"kubernetes_id", "node_name", b"node_name", "pod_name", b"pod_name", "pod_namespace", b"pod_namespace", "pod_number", b"pod_number", "queue", b"queue", "total_cumulative_usage", b"total_cumulative_usage"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["MaxResourcesForPeriod", b"MaxResourcesForPeriod", "cluster_id", b"cluster_id", "created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "kubernetes_id", b"kubernetes_id", "node_name", b"node_name", "pod_name", b"pod_name", "pod_namespace", b"pod_namespace", "pod_number", b"pod_number", "queue", b"queue", "total_cumulative_usage", b"total_cumulative_usage"]) -> None: ...
 
 global___JobUtilisationEvent = JobUtilisationEvent
 
-@typing_extensions.final
+@typing.final
 class JobReprioritizingEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
     NEW_PRIORITY_FIELD_NUMBER: builtins.int
     REQUESTOR_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     job_set_id: builtins.str
     queue: builtins.str
-    @property
-    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     new_priority: builtins.float
     requestor: builtins.str
+    @property
+    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         created: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         new_priority: builtins.float = ...,
         requestor: builtins.str = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "new_priority", b"new_priority", "queue", b"queue", "requestor", b"requestor"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "new_priority", b"new_priority", "queue", b"queue", "requestor", b"requestor"]) -> None: ...
 
 global___JobReprioritizingEvent = JobReprioritizingEvent
 
-@typing_extensions.final
+@typing.final
 class JobReprioritizedEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
     NEW_PRIORITY_FIELD_NUMBER: builtins.int
     REQUESTOR_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     job_set_id: builtins.str
     queue: builtins.str
-    @property
-    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     new_priority: builtins.float
     requestor: builtins.str
+    @property
+    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         created: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         new_priority: builtins.float = ...,
         requestor: builtins.str = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "new_priority", b"new_priority", "queue", b"queue", "requestor", b"requestor"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "new_priority", b"new_priority", "queue", b"queue", "requestor", b"requestor"]) -> None: ...
 
 global___JobReprioritizedEvent = JobReprioritizedEvent
 
-@typing_extensions.final
+@typing.final
 class JobCancellingEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
     REQUESTOR_FIELD_NUMBER: builtins.int
     REASON_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     job_set_id: builtins.str
     queue: builtins.str
-    @property
-    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     requestor: builtins.str
     reason: builtins.str
+    @property
+    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         created: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         requestor: builtins.str = ...,
         reason: builtins.str = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "queue", b"queue", "reason", b"reason", "requestor", b"requestor"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "queue", b"queue", "reason", b"reason", "requestor", b"requestor"]) -> None: ...
 
 global___JobCancellingEvent = JobCancellingEvent
 
-@typing_extensions.final
+@typing.final
 class JobCancelledEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
     REQUESTOR_FIELD_NUMBER: builtins.int
     REASON_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     job_set_id: builtins.str
     queue: builtins.str
-    @property
-    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     requestor: builtins.str
     reason: builtins.str
+    @property
+    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         created: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         requestor: builtins.str = ...,
         reason: builtins.str = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "queue", b"queue", "reason", b"reason", "requestor", b"requestor"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "queue", b"queue", "reason", b"reason", "requestor", b"requestor"]) -> None: ...
 
 global___JobCancelledEvent = JobCancelledEvent
 
-@typing_extensions.final
+@typing.final
 class JobTerminatedEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
@@ -819,75 +851,75 @@
     POD_NUMBER_FIELD_NUMBER: builtins.int
     POD_NAME_FIELD_NUMBER: builtins.int
     POD_NAMESPACE_FIELD_NUMBER: builtins.int
     REASON_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     job_set_id: builtins.str
     queue: builtins.str
-    @property
-    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     cluster_id: builtins.str
     kubernetes_id: builtins.str
     pod_number: builtins.int
     pod_name: builtins.str
     pod_namespace: builtins.str
     reason: builtins.str
+    @property
+    def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         created: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         cluster_id: builtins.str = ...,
         kubernetes_id: builtins.str = ...,
         pod_number: builtins.int = ...,
         pod_name: builtins.str = ...,
         pod_namespace: builtins.str = ...,
         reason: builtins.str = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["cluster_id", b"cluster_id", "created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "kubernetes_id", b"kubernetes_id", "pod_name", b"pod_name", "pod_namespace", b"pod_namespace", "pod_number", b"pod_number", "queue", b"queue", "reason", b"reason"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["cluster_id", b"cluster_id", "created", b"created", "job_id", b"job_id", "job_set_id", b"job_set_id", "kubernetes_id", b"kubernetes_id", "pod_name", b"pod_name", "pod_namespace", b"pod_namespace", "pod_number", b"pod_number", "queue", b"queue", "reason", b"reason"]) -> None: ...
 
 global___JobTerminatedEvent = JobTerminatedEvent
 
-@typing_extensions.final
+@typing.final
 class JobUpdatedEvent(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     CREATED_FIELD_NUMBER: builtins.int
     REQUESTOR_FIELD_NUMBER: builtins.int
     JOB_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     job_set_id: builtins.str
     queue: builtins.str
+    requestor: builtins.str
     @property
     def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
-    requestor: builtins.str
     @property
     def job(self) -> armada.submit_pb2.Job: ...
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         created: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         requestor: builtins.str = ...,
         job: armada.submit_pb2.Job | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created", "job", b"job"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["created", b"created", "job", b"job", "job_id", b"job_id", "job_set_id", b"job_set_id", "queue", b"queue", "requestor", b"requestor"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created", "job", b"job"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["created", b"created", "job", b"job", "job_id", b"job_id", "job_set_id", b"job_set_id", "queue", b"queue", "requestor", b"requestor"]) -> None: ...
 
 global___JobUpdatedEvent = JobUpdatedEvent
 
-@typing_extensions.final
+@typing.final
 class EventMessage(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SUBMITTED_FIELD_NUMBER: builtins.int
     QUEUED_FIELD_NUMBER: builtins.int
     DUPLICATE_FOUND_FIELD_NUMBER: builtins.int
     LEASED_FIELD_NUMBER: builtins.int
@@ -904,14 +936,15 @@
     TERMINATED_FIELD_NUMBER: builtins.int
     UTILISATION_FIELD_NUMBER: builtins.int
     INGRESS_INFO_FIELD_NUMBER: builtins.int
     REPRIORITIZING_FIELD_NUMBER: builtins.int
     UPDATED_FIELD_NUMBER: builtins.int
     FAILEDCOMPRESSED_FIELD_NUMBER: builtins.int
     PREEMPTED_FIELD_NUMBER: builtins.int
+    PREEMPTING_FIELD_NUMBER: builtins.int
     @property
     def submitted(self) -> global___JobSubmittedEvent: ...
     @property
     def queued(self) -> global___JobQueuedEvent: ...
     @property
     def duplicate_found(self) -> global___JobDuplicateFoundEvent: ...
     @property
@@ -945,16 +978,19 @@
     @property
     def reprioritizing(self) -> global___JobReprioritizingEvent: ...
     @property
     def updated(self) -> global___JobUpdatedEvent: ...
     @property
     def failedCompressed(self) -> global___JobFailedEventCompressed:
         """This event is for internal armada use only"""
+
     @property
     def preempted(self) -> global___JobPreemptedEvent: ...
+    @property
+    def preempting(self) -> global___JobPreemptingEvent: ...
     def __init__(
         self,
         *,
         submitted: global___JobSubmittedEvent | None = ...,
         queued: global___JobQueuedEvent | None = ...,
         duplicate_found: global___JobDuplicateFoundEvent | None = ...,
         leased: global___JobLeasedEvent | None = ...,
@@ -971,22 +1007,23 @@
         terminated: global___JobTerminatedEvent | None = ...,
         utilisation: global___JobUtilisationEvent | None = ...,
         ingress_info: global___JobIngressInfoEvent | None = ...,
         reprioritizing: global___JobReprioritizingEvent | None = ...,
         updated: global___JobUpdatedEvent | None = ...,
         failedCompressed: global___JobFailedEventCompressed | None = ...,
         preempted: global___JobPreemptedEvent | None = ...,
+        preempting: global___JobPreemptingEvent | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["cancelled", b"cancelled", "cancelling", b"cancelling", "duplicate_found", b"duplicate_found", "events", b"events", "failed", b"failed", "failedCompressed", b"failedCompressed", "ingress_info", b"ingress_info", "lease_expired", b"lease_expired", "lease_returned", b"lease_returned", "leased", b"leased", "pending", b"pending", "preempted", b"preempted", "queued", b"queued", "reprioritized", b"reprioritized", "reprioritizing", b"reprioritizing", "running", b"running", "submitted", b"submitted", "succeeded", b"succeeded", "terminated", b"terminated", "unable_to_schedule", b"unable_to_schedule", "updated", b"updated", "utilisation", b"utilisation"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["cancelled", b"cancelled", "cancelling", b"cancelling", "duplicate_found", b"duplicate_found", "events", b"events", "failed", b"failed", "failedCompressed", b"failedCompressed", "ingress_info", b"ingress_info", "lease_expired", b"lease_expired", "lease_returned", b"lease_returned", "leased", b"leased", "pending", b"pending", "preempted", b"preempted", "queued", b"queued", "reprioritized", b"reprioritized", "reprioritizing", b"reprioritizing", "running", b"running", "submitted", b"submitted", "succeeded", b"succeeded", "terminated", b"terminated", "unable_to_schedule", b"unable_to_schedule", "updated", b"updated", "utilisation", b"utilisation"]) -> None: ...
-    def WhichOneof(self, oneof_group: typing_extensions.Literal["events", b"events"]) -> typing_extensions.Literal["submitted", "queued", "duplicate_found", "leased", "lease_returned", "lease_expired", "pending", "running", "unable_to_schedule", "failed", "succeeded", "reprioritized", "cancelling", "cancelled", "terminated", "utilisation", "ingress_info", "reprioritizing", "updated", "failedCompressed", "preempted"] | None: ...
+    def HasField(self, field_name: typing.Literal["cancelled", b"cancelled", "cancelling", b"cancelling", "duplicate_found", b"duplicate_found", "events", b"events", "failed", b"failed", "failedCompressed", b"failedCompressed", "ingress_info", b"ingress_info", "lease_expired", b"lease_expired", "lease_returned", b"lease_returned", "leased", b"leased", "pending", b"pending", "preempted", b"preempted", "preempting", b"preempting", "queued", b"queued", "reprioritized", b"reprioritized", "reprioritizing", b"reprioritizing", "running", b"running", "submitted", b"submitted", "succeeded", b"succeeded", "terminated", b"terminated", "unable_to_schedule", b"unable_to_schedule", "updated", b"updated", "utilisation", b"utilisation"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["cancelled", b"cancelled", "cancelling", b"cancelling", "duplicate_found", b"duplicate_found", "events", b"events", "failed", b"failed", "failedCompressed", b"failedCompressed", "ingress_info", b"ingress_info", "lease_expired", b"lease_expired", "lease_returned", b"lease_returned", "leased", b"leased", "pending", b"pending", "preempted", b"preempted", "preempting", b"preempting", "queued", b"queued", "reprioritized", b"reprioritized", "reprioritizing", b"reprioritizing", "running", b"running", "submitted", b"submitted", "succeeded", b"succeeded", "terminated", b"terminated", "unable_to_schedule", b"unable_to_schedule", "updated", b"updated", "utilisation", b"utilisation"]) -> None: ...
+    def WhichOneof(self, oneof_group: typing.Literal["events", b"events"]) -> typing.Literal["submitted", "queued", "duplicate_found", "leased", "lease_returned", "lease_expired", "pending", "running", "unable_to_schedule", "failed", "succeeded", "reprioritized", "cancelling", "cancelled", "terminated", "utilisation", "ingress_info", "reprioritizing", "updated", "failedCompressed", "preempted", "preempting"] | None: ...
 
 global___EventMessage = EventMessage
 
-@typing_extensions.final
+@typing.final
 class ContainerStatus(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     EXITCODE_FIELD_NUMBER: builtins.int
     MESSAGE_FIELD_NUMBER: builtins.int
     REASON_FIELD_NUMBER: builtins.int
@@ -1001,19 +1038,19 @@
         *,
         name: builtins.str = ...,
         exitCode: builtins.int = ...,
         message: builtins.str = ...,
         reason: builtins.str = ...,
         cause: global___Cause.ValueType = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["cause", b"cause", "exitCode", b"exitCode", "message", b"message", "name", b"name", "reason", b"reason"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["cause", b"cause", "exitCode", b"exitCode", "message", b"message", "name", b"name", "reason", b"reason"]) -> None: ...
 
 global___ContainerStatus = ContainerStatus
 
-@typing_extensions.final
+@typing.final
 class EventStreamMessage(google.protobuf.message.Message):
     """swagger:model"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     ID_FIELD_NUMBER: builtins.int
     MESSAGE_FIELD_NUMBER: builtins.int
@@ -1022,20 +1059,20 @@
     def message(self) -> global___EventMessage: ...
     def __init__(
         self,
         *,
         id: builtins.str = ...,
         message: global___EventMessage | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["message", b"message"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["id", b"id", "message", b"message"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["message", b"message"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["id", b"id", "message", b"message"]) -> None: ...
 
 global___EventStreamMessage = EventStreamMessage
 
-@typing_extensions.final
+@typing.final
 class JobSetRequest(google.protobuf.message.Message):
     """swagger:model"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     ID_FIELD_NUMBER: builtins.int
     WATCH_FIELD_NUMBER: builtins.int
@@ -1060,19 +1097,19 @@
         watch: builtins.bool = ...,
         from_message_id: builtins.str = ...,
         queue: builtins.str = ...,
         errorIfMissing: builtins.bool = ...,
         force_legacy: builtins.bool = ...,
         force_new: builtins.bool = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["errorIfMissing", b"errorIfMissing", "force_legacy", b"force_legacy", "force_new", b"force_new", "from_message_id", b"from_message_id", "id", b"id", "queue", b"queue", "watch", b"watch"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["errorIfMissing", b"errorIfMissing", "force_legacy", b"force_legacy", "force_new", b"force_new", "from_message_id", b"from_message_id", "id", b"id", "queue", b"queue", "watch", b"watch"]) -> None: ...
 
 global___JobSetRequest = JobSetRequest
 
-@typing_extensions.final
+@typing.final
 class WatchRequest(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     QUEUE_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     FROM_ID_FIELD_NUMBER: builtins.int
     FORCE_LEGACY_FIELD_NUMBER: builtins.int
@@ -1089,10 +1126,10 @@
         *,
         queue: builtins.str = ...,
         job_set_id: builtins.str = ...,
         from_id: builtins.str = ...,
         force_legacy: builtins.bool = ...,
         force_new: builtins.bool = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["force_legacy", b"force_legacy", "force_new", b"force_new", "from_id", b"from_id", "job_set_id", b"job_set_id", "queue", b"queue"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["force_legacy", b"force_legacy", "force_new", b"force_new", "from_id", b"from_id", "job_set_id", b"job_set_id", "queue", b"queue"]) -> None: ...
 
 global___WatchRequest = WatchRequest
```

## armada_client/armada/event_pb2_grpc.py

```diff
@@ -1,40 +1,65 @@
 # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
 """Client and server classes corresponding to protobuf-defined services."""
 import grpc
+import warnings
 
 from armada_client.armada import event_pb2 as armada_dot_event__pb2
 from armada_client.armada import health_pb2 as armada_dot_health__pb2
 from google.protobuf import empty_pb2 as google_dot_protobuf_dot_empty__pb2
 
+GRPC_GENERATED_VERSION = '1.64.0'
+GRPC_VERSION = grpc.__version__
+EXPECTED_ERROR_RELEASE = '1.65.0'
+SCHEDULED_RELEASE_DATE = 'June 25, 2024'
+_version_not_supported = False
+
+try:
+    from grpc._utilities import first_version_is_lower
+    _version_not_supported = first_version_is_lower(GRPC_VERSION, GRPC_GENERATED_VERSION)
+except ImportError:
+    _version_not_supported = True
+
+if _version_not_supported:
+    warnings.warn(
+        f'The grpc package installed is at version {GRPC_VERSION},'
+        + f' but the generated code in armada/event_pb2_grpc.py depends on'
+        + f' grpcio>={GRPC_GENERATED_VERSION}.'
+        + f' Please upgrade your grpc module to grpcio>={GRPC_GENERATED_VERSION}'
+        + f' or downgrade your generated code using grpcio-tools<={GRPC_VERSION}.'
+        + f' This warning will become an error in {EXPECTED_ERROR_RELEASE},'
+        + f' scheduled for release on {SCHEDULED_RELEASE_DATE}.',
+        RuntimeWarning
+    )
+
 
 class EventStub(object):
     """Missing associated documentation comment in .proto file."""
 
     def __init__(self, channel):
         """Constructor.
 
         Args:
             channel: A grpc.Channel.
         """
         self.GetJobSetEvents = channel.unary_stream(
                 '/api.Event/GetJobSetEvents',
                 request_serializer=armada_dot_event__pb2.JobSetRequest.SerializeToString,
                 response_deserializer=armada_dot_event__pb2.EventStreamMessage.FromString,
-                )
+                _registered_method=True)
         self.Watch = channel.unary_stream(
                 '/api.Event/Watch',
                 request_serializer=armada_dot_event__pb2.WatchRequest.SerializeToString,
                 response_deserializer=armada_dot_event__pb2.EventStreamMessage.FromString,
-                )
+                _registered_method=True)
         self.Health = channel.unary_unary(
                 '/api.Event/Health',
                 request_serializer=google_dot_protobuf_dot_empty__pb2.Empty.SerializeToString,
                 response_deserializer=armada_dot_health__pb2.HealthCheckResponse.FromString,
-                )
+                _registered_method=True)
 
 
 class EventServicer(object):
     """Missing associated documentation comment in .proto file."""
 
     def GetJobSetEvents(self, request, context):
         """Missing associated documentation comment in .proto file."""
@@ -72,14 +97,15 @@
                     request_deserializer=google_dot_protobuf_dot_empty__pb2.Empty.FromString,
                     response_serializer=armada_dot_health__pb2.HealthCheckResponse.SerializeToString,
             ),
     }
     generic_handler = grpc.method_handlers_generic_handler(
             'api.Event', rpc_method_handlers)
     server.add_generic_rpc_handlers((generic_handler,))
+    server.add_registered_method_handlers('api.Event', rpc_method_handlers)
 
 
  # This class is part of an EXPERIMENTAL API.
 class Event(object):
     """Missing associated documentation comment in .proto file."""
 
     @staticmethod
@@ -89,46 +115,76 @@
             channel_credentials=None,
             call_credentials=None,
             insecure=False,
             compression=None,
             wait_for_ready=None,
             timeout=None,
             metadata=None):
-        return grpc.experimental.unary_stream(request, target, '/api.Event/GetJobSetEvents',
+        return grpc.experimental.unary_stream(
+            request,
+            target,
+            '/api.Event/GetJobSetEvents',
             armada_dot_event__pb2.JobSetRequest.SerializeToString,
             armada_dot_event__pb2.EventStreamMessage.FromString,
-            options, channel_credentials,
-            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
 
     @staticmethod
     def Watch(request,
             target,
             options=(),
             channel_credentials=None,
             call_credentials=None,
             insecure=False,
             compression=None,
             wait_for_ready=None,
             timeout=None,
             metadata=None):
-        return grpc.experimental.unary_stream(request, target, '/api.Event/Watch',
+        return grpc.experimental.unary_stream(
+            request,
+            target,
+            '/api.Event/Watch',
             armada_dot_event__pb2.WatchRequest.SerializeToString,
             armada_dot_event__pb2.EventStreamMessage.FromString,
-            options, channel_credentials,
-            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
 
     @staticmethod
     def Health(request,
             target,
             options=(),
             channel_credentials=None,
             call_credentials=None,
             insecure=False,
             compression=None,
             wait_for_ready=None,
             timeout=None,
             metadata=None):
-        return grpc.experimental.unary_unary(request, target, '/api.Event/Health',
+        return grpc.experimental.unary_unary(
+            request,
+            target,
+            '/api.Event/Health',
             google_dot_protobuf_dot_empty__pb2.Empty.SerializeToString,
             armada_dot_health__pb2.HealthCheckResponse.FromString,
-            options, channel_credentials,
-            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
```

## armada_client/armada/health_pb2.py

```diff
@@ -1,11 +1,11 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: armada/health.proto
-# Protobuf Python Version: 4.25.1
+# Protobuf Python Version: 5.26.1
 """Generated protocol buffer code."""
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
 from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
@@ -15,15 +15,15 @@
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x13\x61rmada/health.proto\x12\x03\x61pi\"\x89\x01\n\x13HealthCheckResponse\x12\x36\n\x06status\x18\x01 \x01(\x0e\x32&.api.HealthCheckResponse.ServingStatus\":\n\rServingStatus\x12\x0b\n\x07UNKNOWN\x10\x00\x12\x0b\n\x07SERVING\x10\x01\x12\x0f\n\x0bNOT_SERVING\x10\x02\x42@Z\'github.com/armadaproject/armada/pkg/api\xaa\x02\x14\x41rmadaProject.Io.Apib\x06proto3')
 
 _globals = globals()
 _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
 _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'armada.health_pb2', _globals)
-if _descriptor._USE_C_DESCRIPTORS == False:
-  _globals['DESCRIPTOR']._options = None
+if not _descriptor._USE_C_DESCRIPTORS:
+  _globals['DESCRIPTOR']._loaded_options = None
   _globals['DESCRIPTOR']._serialized_options = b'Z\'github.com/armadaproject/armada/pkg/api\252\002\024ArmadaProject.Io.Api'
   _globals['_HEALTHCHECKRESPONSE']._serialized_start=29
   _globals['_HEALTHCHECKRESPONSE']._serialized_end=166
   _globals['_HEALTHCHECKRESPONSE_SERVINGSTATUS']._serialized_start=108
   _globals['_HEALTHCHECKRESPONSE_SERVINGSTATUS']._serialized_end=166
 # @@protoc_insertion_point(module_scope)
```

## armada_client/armada/health_pb2.pyi

```diff
@@ -1,26 +1,27 @@
 """
 @generated by mypy-protobuf.  Do not edit manually!
 isort:skip_file
 """
+
 import builtins
 import google.protobuf.descriptor
 import google.protobuf.internal.enum_type_wrapper
 import google.protobuf.message
 import sys
 import typing
 
 if sys.version_info >= (3, 10):
     import typing as typing_extensions
 else:
     import typing_extensions
 
 DESCRIPTOR: google.protobuf.descriptor.FileDescriptor
 
-@typing_extensions.final
+@typing.final
 class HealthCheckResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     class _ServingStatus:
         ValueType = typing.NewType("ValueType", builtins.int)
         V: typing_extensions.TypeAlias = ValueType
 
@@ -38,10 +39,10 @@
     STATUS_FIELD_NUMBER: builtins.int
     status: global___HealthCheckResponse.ServingStatus.ValueType
     def __init__(
         self,
         *,
         status: global___HealthCheckResponse.ServingStatus.ValueType = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["status", b"status"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["status", b"status"]) -> None: ...
 
 global___HealthCheckResponse = HealthCheckResponse
```

## armada_client/armada/health_pb2_grpc.py

```diff
@@ -1,4 +1,29 @@
 # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
 """Client and server classes corresponding to protobuf-defined services."""
 import grpc
+import warnings
 
+
+GRPC_GENERATED_VERSION = '1.64.0'
+GRPC_VERSION = grpc.__version__
+EXPECTED_ERROR_RELEASE = '1.65.0'
+SCHEDULED_RELEASE_DATE = 'June 25, 2024'
+_version_not_supported = False
+
+try:
+    from grpc._utilities import first_version_is_lower
+    _version_not_supported = first_version_is_lower(GRPC_VERSION, GRPC_GENERATED_VERSION)
+except ImportError:
+    _version_not_supported = True
+
+if _version_not_supported:
+    warnings.warn(
+        f'The grpc package installed is at version {GRPC_VERSION},'
+        + f' but the generated code in armada/health_pb2_grpc.py depends on'
+        + f' grpcio>={GRPC_GENERATED_VERSION}.'
+        + f' Please upgrade your grpc module to grpcio>={GRPC_GENERATED_VERSION}'
+        + f' or downgrade your generated code using grpcio-tools<={GRPC_VERSION}.'
+        + f' This warning will become an error in {EXPECTED_ERROR_RELEASE},'
+        + f' scheduled for release on {SCHEDULED_RELEASE_DATE}.',
+        RuntimeWarning
+    )
```

## armada_client/armada/job_pb2.py

```diff
@@ -1,74 +1,81 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: armada/job.proto
-# Protobuf Python Version: 4.25.1
+# Protobuf Python Version: 5.26.1
 """Generated protocol buffer code."""
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
 from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 from armada_client.github.com.gogo.protobuf.gogoproto import gogo_pb2 as github_dot_com_dot_gogo_dot_protobuf_dot_gogoproto_dot_gogo__pb2
 from armada_client.armada import submit_pb2 as armada_dot_submit__pb2
 from google.protobuf import timestamp_pb2 as google_dot_protobuf_dot_timestamp__pb2
+from armada_client.google.api import annotations_pb2 as google_dot_api_dot_annotations__pb2
 
 
-DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x10\x61rmada/job.proto\x12\x03\x61pi\x1a-github.com/gogo/protobuf/gogoproto/gogo.proto\x1a\x13\x61rmada/submit.proto\x1a\x1fgoogle/protobuf/timestamp.proto\"\xc7\x02\n\rJobRunDetails\x12\x0e\n\x06run_id\x18\x01 \x01(\t\x12\x0e\n\x06job_id\x18\x02 \x01(\t\x12\x1f\n\x05state\x18\x03 \x01(\x0e\x32\x10.api.JobRunState\x12\x0f\n\x07\x63luster\x18\x04 \x01(\t\x12\x0c\n\x04node\x18\x05 \x01(\t\x12\x33\n\tleased_ts\x18\x07 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x34\n\npending_ts\x18\x08 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x34\n\nstarted_ts\x18\t \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x35\n\x0b\x66inished_ts\x18\n \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\"\x87\x03\n\nJobDetails\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\r\n\x05queue\x18\x02 \x01(\t\x12\x0e\n\x06jobset\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x04 \x01(\t\x12\x1c\n\x05state\x18\x05 \x01(\x0e\x32\r.api.JobState\x12\x36\n\x0csubmitted_ts\x18\x06 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x33\n\tcancel_ts\x18\x07 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x15\n\rcancel_reason\x18\x08 \x01(\t\x12<\n\x12last_transition_ts\x18\t \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x15\n\rlatest_run_id\x18\n \x01(\t\x12\x1a\n\x08job_spec\x18\x0b \x01(\x0b\x32\x08.api.Job\x12$\n\x08job_runs\x18\x0c \x03(\x0b\x32\x12.api.JobRunDetails\"U\n\x11JobDetailsRequest\x12\x0f\n\x07job_ids\x18\x01 \x03(\t\x12\x17\n\x0f\x65xpand_job_spec\x18\x02 \x01(\x08\x12\x16\n\x0e\x65xpand_job_run\x18\x03 \x01(\x08\"\x96\x01\n\x12JobDetailsResponse\x12<\n\x0bjob_details\x18\x01 \x03(\x0b\x32\'.api.JobDetailsResponse.JobDetailsEntry\x1a\x42\n\x0fJobDetailsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x1e\n\x05value\x18\x02 \x01(\x0b\x32\x0f.api.JobDetails:\x02\x38\x01\"\xa9\x01\n\x15JobRunDetailsResponse\x12\x46\n\x0fjob_run_details\x18\x01 \x03(\x0b\x32-.api.JobRunDetailsResponse.JobRunDetailsEntry\x1aH\n\x12JobRunDetailsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12!\n\x05value\x18\x02 \x01(\x0b\x32\x12.api.JobRunDetails:\x02\x38\x01\"\'\n\x14JobRunDetailsRequest\x12\x0f\n\x07run_ids\x18\x01 \x03(\t\"#\n\x10JobStatusRequest\x12\x0f\n\x07job_ids\x18\x01 \x03(\t\"\x8f\x01\n\x11JobStatusResponse\x12\x39\n\njob_states\x18\x01 \x03(\x0b\x32%.api.JobStatusResponse.JobStatesEntry\x1a?\n\x0eJobStatesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x1c\n\x05value\x18\x02 \x01(\x0e\x32\r.api.JobState:\x02\x38\x01*\x85\x02\n\x0bJobRunState\x12\x15\n\x11RUN_STATE_UNKNOWN\x10\x00\x12\x14\n\x10RUN_STATE_LEASED\x10\x01\x12\x15\n\x11RUN_STATE_PENDING\x10\x02\x12\x15\n\x11RUN_STATE_RUNNING\x10\x03\x12\x17\n\x13RUN_STATE_SUCCEEDED\x10\x04\x12\x14\n\x10RUN_STATE_FAILED\x10\x05\x12\x17\n\x13RUN_STATE_PREEMPTED\x10\x06\x12\x17\n\x13RUN_STATE_CANCELLED\x10\x07\x12\x1b\n\x17RUN_STATE_LEASE_EXPIRED\x10\x08\x12\x1d\n\x19RUNS_STATE_LEASE_RETURNED\x10\t2\xd2\x01\n\x04Jobs\x12=\n\x0cGetJobStatus\x12\x15.api.JobStatusRequest\x1a\x16.api.JobStatusResponse\x12@\n\rGetJobDetails\x12\x16.api.JobDetailsRequest\x1a\x17.api.JobDetailsResponse\x12I\n\x10GetJobRunDetails\x12\x19.api.JobRunDetailsRequest\x1a\x1a.api.JobRunDetailsResponseB1Z\'github.com/armadaproject/armada/pkg/api\xd8\xe1\x1e\x00\x80\xe2\x1e\x01\x62\x06proto3')
+DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x10\x61rmada/job.proto\x12\x03\x61pi\x1a-github.com/gogo/protobuf/gogoproto/gogo.proto\x1a\x13\x61rmada/submit.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\x1cgoogle/api/annotations.proto\"\xc7\x02\n\rJobRunDetails\x12\x0e\n\x06run_id\x18\x01 \x01(\t\x12\x0e\n\x06job_id\x18\x02 \x01(\t\x12\x1f\n\x05state\x18\x03 \x01(\x0e\x32\x10.api.JobRunState\x12\x0f\n\x07\x63luster\x18\x04 \x01(\t\x12\x0c\n\x04node\x18\x05 \x01(\t\x12\x33\n\tleased_ts\x18\x07 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x34\n\npending_ts\x18\x08 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x34\n\nstarted_ts\x18\t \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x35\n\x0b\x66inished_ts\x18\n \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\"\x87\x03\n\nJobDetails\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\r\n\x05queue\x18\x02 \x01(\t\x12\x0e\n\x06jobset\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x04 \x01(\t\x12\x1c\n\x05state\x18\x05 \x01(\x0e\x32\r.api.JobState\x12\x36\n\x0csubmitted_ts\x18\x06 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x33\n\tcancel_ts\x18\x07 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x15\n\rcancel_reason\x18\x08 \x01(\t\x12<\n\x12last_transition_ts\x18\t \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x15\n\rlatest_run_id\x18\n \x01(\t\x12\x1a\n\x08job_spec\x18\x0b \x01(\x0b\x32\x08.api.Job\x12$\n\x08job_runs\x18\x0c \x03(\x0b\x32\x12.api.JobRunDetails\"U\n\x11JobDetailsRequest\x12\x0f\n\x07job_ids\x18\x01 \x03(\t\x12\x17\n\x0f\x65xpand_job_spec\x18\x02 \x01(\x08\x12\x16\n\x0e\x65xpand_job_run\x18\x03 \x01(\x08\"\x96\x01\n\x12JobDetailsResponse\x12<\n\x0bjob_details\x18\x01 \x03(\x0b\x32\'.api.JobDetailsResponse.JobDetailsEntry\x1a\x42\n\x0fJobDetailsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x1e\n\x05value\x18\x02 \x01(\x0b\x32\x0f.api.JobDetails:\x02\x38\x01\"\xa9\x01\n\x15JobRunDetailsResponse\x12\x46\n\x0fjob_run_details\x18\x01 \x03(\x0b\x32-.api.JobRunDetailsResponse.JobRunDetailsEntry\x1aH\n\x12JobRunDetailsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12!\n\x05value\x18\x02 \x01(\x0b\x32\x12.api.JobRunDetails:\x02\x38\x01\"\'\n\x14JobRunDetailsRequest\x12\x0f\n\x07run_ids\x18\x01 \x03(\t\"#\n\x10JobStatusRequest\x12\x0f\n\x07job_ids\x18\x01 \x03(\t\"\x8f\x01\n\x11JobStatusResponse\x12\x39\n\njob_states\x18\x01 \x03(\x0b\x32%.api.JobStatusResponse.JobStatesEntry\x1a?\n\x0eJobStatesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x1c\n\x05value\x18\x02 \x01(\x0e\x32\r.api.JobState:\x02\x38\x01*\x85\x02\n\x0bJobRunState\x12\x15\n\x11RUN_STATE_UNKNOWN\x10\x00\x12\x14\n\x10RUN_STATE_LEASED\x10\x01\x12\x15\n\x11RUN_STATE_PENDING\x10\x02\x12\x15\n\x11RUN_STATE_RUNNING\x10\x03\x12\x17\n\x13RUN_STATE_SUCCEEDED\x10\x04\x12\x14\n\x10RUN_STATE_FAILED\x10\x05\x12\x17\n\x13RUN_STATE_PREEMPTED\x10\x06\x12\x17\n\x13RUN_STATE_CANCELLED\x10\x07\x12\x1b\n\x17RUN_STATE_LEASE_EXPIRED\x10\x08\x12\x1d\n\x19RUNS_STATE_LEASE_RETURNED\x10\t2\xa5\x02\n\x04Jobs\x12X\n\x0cGetJobStatus\x12\x15.api.JobStatusRequest\x1a\x16.api.JobStatusResponse\"\x19\x82\xd3\xe4\x93\x02\x13\"\x0e/v1/job/status:\x01*\x12\\\n\rGetJobDetails\x12\x16.api.JobDetailsRequest\x1a\x17.api.JobDetailsResponse\"\x1a\x82\xd3\xe4\x93\x02\x14\"\x0f/v1/job/details:\x01*\x12\x65\n\x10GetJobRunDetails\x12\x19.api.JobRunDetailsRequest\x1a\x1a.api.JobRunDetailsResponse\"\x1a\x82\xd3\xe4\x93\x02\x14\"\x0f/v1/run/details:\x01*B1Z\'github.com/armadaproject/armada/pkg/api\xd8\xe1\x1e\x00\x80\xe2\x1e\x01\x62\x06proto3')
 
 _globals = globals()
 _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
 _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'armada.job_pb2', _globals)
-if _descriptor._USE_C_DESCRIPTORS == False:
-  _globals['DESCRIPTOR']._options = None
+if not _descriptor._USE_C_DESCRIPTORS:
+  _globals['DESCRIPTOR']._loaded_options = None
   _globals['DESCRIPTOR']._serialized_options = b'Z\'github.com/armadaproject/armada/pkg/api\330\341\036\000\200\342\036\001'
-  _globals['_JOBRUNDETAILS'].fields_by_name['leased_ts']._options = None
+  _globals['_JOBRUNDETAILS'].fields_by_name['leased_ts']._loaded_options = None
   _globals['_JOBRUNDETAILS'].fields_by_name['leased_ts']._serialized_options = b'\220\337\037\001'
-  _globals['_JOBRUNDETAILS'].fields_by_name['pending_ts']._options = None
+  _globals['_JOBRUNDETAILS'].fields_by_name['pending_ts']._loaded_options = None
   _globals['_JOBRUNDETAILS'].fields_by_name['pending_ts']._serialized_options = b'\220\337\037\001'
-  _globals['_JOBRUNDETAILS'].fields_by_name['started_ts']._options = None
+  _globals['_JOBRUNDETAILS'].fields_by_name['started_ts']._loaded_options = None
   _globals['_JOBRUNDETAILS'].fields_by_name['started_ts']._serialized_options = b'\220\337\037\001'
-  _globals['_JOBRUNDETAILS'].fields_by_name['finished_ts']._options = None
+  _globals['_JOBRUNDETAILS'].fields_by_name['finished_ts']._loaded_options = None
   _globals['_JOBRUNDETAILS'].fields_by_name['finished_ts']._serialized_options = b'\220\337\037\001'
-  _globals['_JOBDETAILS'].fields_by_name['submitted_ts']._options = None
+  _globals['_JOBDETAILS'].fields_by_name['submitted_ts']._loaded_options = None
   _globals['_JOBDETAILS'].fields_by_name['submitted_ts']._serialized_options = b'\220\337\037\001'
-  _globals['_JOBDETAILS'].fields_by_name['cancel_ts']._options = None
+  _globals['_JOBDETAILS'].fields_by_name['cancel_ts']._loaded_options = None
   _globals['_JOBDETAILS'].fields_by_name['cancel_ts']._serialized_options = b'\220\337\037\001'
-  _globals['_JOBDETAILS'].fields_by_name['last_transition_ts']._options = None
+  _globals['_JOBDETAILS'].fields_by_name['last_transition_ts']._loaded_options = None
   _globals['_JOBDETAILS'].fields_by_name['last_transition_ts']._serialized_options = b'\220\337\037\001'
-  _globals['_JOBDETAILSRESPONSE_JOBDETAILSENTRY']._options = None
+  _globals['_JOBDETAILSRESPONSE_JOBDETAILSENTRY']._loaded_options = None
   _globals['_JOBDETAILSRESPONSE_JOBDETAILSENTRY']._serialized_options = b'8\001'
-  _globals['_JOBRUNDETAILSRESPONSE_JOBRUNDETAILSENTRY']._options = None
+  _globals['_JOBRUNDETAILSRESPONSE_JOBRUNDETAILSENTRY']._loaded_options = None
   _globals['_JOBRUNDETAILSRESPONSE_JOBRUNDETAILSENTRY']._serialized_options = b'8\001'
-  _globals['_JOBSTATUSRESPONSE_JOBSTATESENTRY']._options = None
+  _globals['_JOBSTATUSRESPONSE_JOBSTATESENTRY']._loaded_options = None
   _globals['_JOBSTATUSRESPONSE_JOBSTATESENTRY']._serialized_options = b'8\001'
-  _globals['_JOBRUNSTATE']._serialized_start=1487
-  _globals['_JOBRUNSTATE']._serialized_end=1748
-  _globals['_JOBRUNDETAILS']._serialized_start=127
-  _globals['_JOBRUNDETAILS']._serialized_end=454
-  _globals['_JOBDETAILS']._serialized_start=457
-  _globals['_JOBDETAILS']._serialized_end=848
-  _globals['_JOBDETAILSREQUEST']._serialized_start=850
-  _globals['_JOBDETAILSREQUEST']._serialized_end=935
-  _globals['_JOBDETAILSRESPONSE']._serialized_start=938
-  _globals['_JOBDETAILSRESPONSE']._serialized_end=1088
-  _globals['_JOBDETAILSRESPONSE_JOBDETAILSENTRY']._serialized_start=1022
-  _globals['_JOBDETAILSRESPONSE_JOBDETAILSENTRY']._serialized_end=1088
-  _globals['_JOBRUNDETAILSRESPONSE']._serialized_start=1091
-  _globals['_JOBRUNDETAILSRESPONSE']._serialized_end=1260
-  _globals['_JOBRUNDETAILSRESPONSE_JOBRUNDETAILSENTRY']._serialized_start=1188
-  _globals['_JOBRUNDETAILSRESPONSE_JOBRUNDETAILSENTRY']._serialized_end=1260
-  _globals['_JOBRUNDETAILSREQUEST']._serialized_start=1262
-  _globals['_JOBRUNDETAILSREQUEST']._serialized_end=1301
-  _globals['_JOBSTATUSREQUEST']._serialized_start=1303
-  _globals['_JOBSTATUSREQUEST']._serialized_end=1338
-  _globals['_JOBSTATUSRESPONSE']._serialized_start=1341
-  _globals['_JOBSTATUSRESPONSE']._serialized_end=1484
-  _globals['_JOBSTATUSRESPONSE_JOBSTATESENTRY']._serialized_start=1421
-  _globals['_JOBSTATUSRESPONSE_JOBSTATESENTRY']._serialized_end=1484
-  _globals['_JOBS']._serialized_start=1751
-  _globals['_JOBS']._serialized_end=1961
+  _globals['_JOBS'].methods_by_name['GetJobStatus']._loaded_options = None
+  _globals['_JOBS'].methods_by_name['GetJobStatus']._serialized_options = b'\202\323\344\223\002\023\"\016/v1/job/status:\001*'
+  _globals['_JOBS'].methods_by_name['GetJobDetails']._loaded_options = None
+  _globals['_JOBS'].methods_by_name['GetJobDetails']._serialized_options = b'\202\323\344\223\002\024\"\017/v1/job/details:\001*'
+  _globals['_JOBS'].methods_by_name['GetJobRunDetails']._loaded_options = None
+  _globals['_JOBS'].methods_by_name['GetJobRunDetails']._serialized_options = b'\202\323\344\223\002\024\"\017/v1/run/details:\001*'
+  _globals['_JOBRUNSTATE']._serialized_start=1517
+  _globals['_JOBRUNSTATE']._serialized_end=1778
+  _globals['_JOBRUNDETAILS']._serialized_start=157
+  _globals['_JOBRUNDETAILS']._serialized_end=484
+  _globals['_JOBDETAILS']._serialized_start=487
+  _globals['_JOBDETAILS']._serialized_end=878
+  _globals['_JOBDETAILSREQUEST']._serialized_start=880
+  _globals['_JOBDETAILSREQUEST']._serialized_end=965
+  _globals['_JOBDETAILSRESPONSE']._serialized_start=968
+  _globals['_JOBDETAILSRESPONSE']._serialized_end=1118
+  _globals['_JOBDETAILSRESPONSE_JOBDETAILSENTRY']._serialized_start=1052
+  _globals['_JOBDETAILSRESPONSE_JOBDETAILSENTRY']._serialized_end=1118
+  _globals['_JOBRUNDETAILSRESPONSE']._serialized_start=1121
+  _globals['_JOBRUNDETAILSRESPONSE']._serialized_end=1290
+  _globals['_JOBRUNDETAILSRESPONSE_JOBRUNDETAILSENTRY']._serialized_start=1218
+  _globals['_JOBRUNDETAILSRESPONSE_JOBRUNDETAILSENTRY']._serialized_end=1290
+  _globals['_JOBRUNDETAILSREQUEST']._serialized_start=1292
+  _globals['_JOBRUNDETAILSREQUEST']._serialized_end=1331
+  _globals['_JOBSTATUSREQUEST']._serialized_start=1333
+  _globals['_JOBSTATUSREQUEST']._serialized_end=1368
+  _globals['_JOBSTATUSRESPONSE']._serialized_start=1371
+  _globals['_JOBSTATUSRESPONSE']._serialized_end=1514
+  _globals['_JOBSTATUSRESPONSE_JOBSTATESENTRY']._serialized_start=1451
+  _globals['_JOBSTATUSRESPONSE_JOBSTATESENTRY']._serialized_end=1514
+  _globals['_JOBS']._serialized_start=1781
+  _globals['_JOBS']._serialized_end=2074
 # @@protoc_insertion_point(module_scope)
```

## armada_client/armada/job_pb2.pyi

```diff
@@ -1,11 +1,12 @@
 """
 @generated by mypy-protobuf.  Do not edit manually!
 isort:skip_file
 """
+
 import armada.submit_pb2
 import builtins
 import collections.abc
 import google.protobuf.descriptor
 import google.protobuf.internal.containers
 import google.protobuf.internal.enum_type_wrapper
 import google.protobuf.message
@@ -47,15 +48,15 @@
 RUN_STATE_FAILED: JobRunState.ValueType  # 5
 RUN_STATE_PREEMPTED: JobRunState.ValueType  # 6
 RUN_STATE_CANCELLED: JobRunState.ValueType  # 7
 RUN_STATE_LEASE_EXPIRED: JobRunState.ValueType  # 8
 RUNS_STATE_LEASE_RETURNED: JobRunState.ValueType  # 9
 global___JobRunState = JobRunState
 
-@typing_extensions.final
+@typing.final
 class JobRunDetails(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     RUN_ID_FIELD_NUMBER: builtins.int
     JOB_ID_FIELD_NUMBER: builtins.int
     STATE_FIELD_NUMBER: builtins.int
     CLUSTER_FIELD_NUMBER: builtins.int
@@ -86,20 +87,20 @@
         cluster: builtins.str = ...,
         node: builtins.str = ...,
         leased_ts: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         pending_ts: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         started_ts: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         finished_ts: google.protobuf.timestamp_pb2.Timestamp | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["finished_ts", b"finished_ts", "leased_ts", b"leased_ts", "pending_ts", b"pending_ts", "started_ts", b"started_ts"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["cluster", b"cluster", "finished_ts", b"finished_ts", "job_id", b"job_id", "leased_ts", b"leased_ts", "node", b"node", "pending_ts", b"pending_ts", "run_id", b"run_id", "started_ts", b"started_ts", "state", b"state"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["finished_ts", b"finished_ts", "leased_ts", b"leased_ts", "pending_ts", b"pending_ts", "started_ts", b"started_ts"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["cluster", b"cluster", "finished_ts", b"finished_ts", "job_id", b"job_id", "leased_ts", b"leased_ts", "node", b"node", "pending_ts", b"pending_ts", "run_id", b"run_id", "started_ts", b"started_ts", "state", b"state"]) -> None: ...
 
 global___JobRunDetails = JobRunDetails
 
-@typing_extensions.final
+@typing.final
 class JobDetails(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     JOBSET_FIELD_NUMBER: builtins.int
     NAMESPACE_FIELD_NUMBER: builtins.int
@@ -112,28 +113,30 @@
     JOB_SPEC_FIELD_NUMBER: builtins.int
     JOB_RUNS_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     queue: builtins.str
     jobset: builtins.str
     namespace: builtins.str
     state: armada.submit_pb2.JobState.ValueType
+    cancel_reason: builtins.str
+    latest_run_id: builtins.str
     @property
     def submitted_ts(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     @property
     def cancel_ts(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
-    cancel_reason: builtins.str
     @property
     def last_transition_ts(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
-    latest_run_id: builtins.str
     @property
     def job_spec(self) -> armada.submit_pb2.Job:
         """Only filled in if expand_job_spec is true"""
+
     @property
     def job_runs(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___JobRunDetails]:
         """Only filled in if expand_job_run is true;"""
+
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         queue: builtins.str = ...,
         jobset: builtins.str = ...,
         namespace: builtins.str = ...,
@@ -142,165 +145,165 @@
         cancel_ts: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         cancel_reason: builtins.str = ...,
         last_transition_ts: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         latest_run_id: builtins.str = ...,
         job_spec: armada.submit_pb2.Job | None = ...,
         job_runs: collections.abc.Iterable[global___JobRunDetails] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["cancel_ts", b"cancel_ts", "job_spec", b"job_spec", "last_transition_ts", b"last_transition_ts", "submitted_ts", b"submitted_ts"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["cancel_reason", b"cancel_reason", "cancel_ts", b"cancel_ts", "job_id", b"job_id", "job_runs", b"job_runs", "job_spec", b"job_spec", "jobset", b"jobset", "last_transition_ts", b"last_transition_ts", "latest_run_id", b"latest_run_id", "namespace", b"namespace", "queue", b"queue", "state", b"state", "submitted_ts", b"submitted_ts"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["cancel_ts", b"cancel_ts", "job_spec", b"job_spec", "last_transition_ts", b"last_transition_ts", "submitted_ts", b"submitted_ts"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["cancel_reason", b"cancel_reason", "cancel_ts", b"cancel_ts", "job_id", b"job_id", "job_runs", b"job_runs", "job_spec", b"job_spec", "jobset", b"jobset", "last_transition_ts", b"last_transition_ts", "latest_run_id", b"latest_run_id", "namespace", b"namespace", "queue", b"queue", "state", b"state", "submitted_ts", b"submitted_ts"]) -> None: ...
 
 global___JobDetails = JobDetails
 
-@typing_extensions.final
+@typing.final
 class JobDetailsRequest(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_IDS_FIELD_NUMBER: builtins.int
     EXPAND_JOB_SPEC_FIELD_NUMBER: builtins.int
     EXPAND_JOB_RUN_FIELD_NUMBER: builtins.int
-    @property
-    def job_ids(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]: ...
     expand_job_spec: builtins.bool
     expand_job_run: builtins.bool
+    @property
+    def job_ids(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]: ...
     def __init__(
         self,
         *,
         job_ids: collections.abc.Iterable[builtins.str] | None = ...,
         expand_job_spec: builtins.bool = ...,
         expand_job_run: builtins.bool = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["expand_job_run", b"expand_job_run", "expand_job_spec", b"expand_job_spec", "job_ids", b"job_ids"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["expand_job_run", b"expand_job_run", "expand_job_spec", b"expand_job_spec", "job_ids", b"job_ids"]) -> None: ...
 
 global___JobDetailsRequest = JobDetailsRequest
 
-@typing_extensions.final
+@typing.final
 class JobDetailsResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class JobDetailsEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> global___JobDetails: ...
         def __init__(
             self,
             *,
             key: builtins.str = ...,
             value: global___JobDetails | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     JOB_DETAILS_FIELD_NUMBER: builtins.int
     @property
     def job_details(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, global___JobDetails]: ...
     def __init__(
         self,
         *,
         job_details: collections.abc.Mapping[builtins.str, global___JobDetails] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["job_details", b"job_details"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["job_details", b"job_details"]) -> None: ...
 
 global___JobDetailsResponse = JobDetailsResponse
 
-@typing_extensions.final
+@typing.final
 class JobRunDetailsResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class JobRunDetailsEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> global___JobRunDetails: ...
         def __init__(
             self,
             *,
             key: builtins.str = ...,
             value: global___JobRunDetails | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     JOB_RUN_DETAILS_FIELD_NUMBER: builtins.int
     @property
     def job_run_details(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, global___JobRunDetails]: ...
     def __init__(
         self,
         *,
         job_run_details: collections.abc.Mapping[builtins.str, global___JobRunDetails] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["job_run_details", b"job_run_details"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["job_run_details", b"job_run_details"]) -> None: ...
 
 global___JobRunDetailsResponse = JobRunDetailsResponse
 
-@typing_extensions.final
+@typing.final
 class JobRunDetailsRequest(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     RUN_IDS_FIELD_NUMBER: builtins.int
     @property
     def run_ids(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]: ...
     def __init__(
         self,
         *,
         run_ids: collections.abc.Iterable[builtins.str] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["run_ids", b"run_ids"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["run_ids", b"run_ids"]) -> None: ...
 
 global___JobRunDetailsRequest = JobRunDetailsRequest
 
-@typing_extensions.final
+@typing.final
 class JobStatusRequest(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_IDS_FIELD_NUMBER: builtins.int
     @property
     def job_ids(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]: ...
     def __init__(
         self,
         *,
         job_ids: collections.abc.Iterable[builtins.str] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["job_ids", b"job_ids"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["job_ids", b"job_ids"]) -> None: ...
 
 global___JobStatusRequest = JobStatusRequest
 
-@typing_extensions.final
+@typing.final
 class JobStatusResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class JobStatesEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: armada.submit_pb2.JobState.ValueType
         def __init__(
             self,
             *,
             key: builtins.str = ...,
             value: armada.submit_pb2.JobState.ValueType = ...,
         ) -> None: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     JOB_STATES_FIELD_NUMBER: builtins.int
     @property
     def job_states(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, armada.submit_pb2.JobState.ValueType]: ...
     def __init__(
         self,
         *,
         job_states: collections.abc.Mapping[builtins.str, armada.submit_pb2.JobState.ValueType] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["job_states", b"job_states"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["job_states", b"job_states"]) -> None: ...
 
 global___JobStatusResponse = JobStatusResponse
```

## armada_client/armada/job_pb2_grpc.py

```diff
@@ -1,38 +1,63 @@
 # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
 """Client and server classes corresponding to protobuf-defined services."""
 import grpc
+import warnings
 
 from armada_client.armada import job_pb2 as armada_dot_job__pb2
 
+GRPC_GENERATED_VERSION = '1.64.0'
+GRPC_VERSION = grpc.__version__
+EXPECTED_ERROR_RELEASE = '1.65.0'
+SCHEDULED_RELEASE_DATE = 'June 25, 2024'
+_version_not_supported = False
+
+try:
+    from grpc._utilities import first_version_is_lower
+    _version_not_supported = first_version_is_lower(GRPC_VERSION, GRPC_GENERATED_VERSION)
+except ImportError:
+    _version_not_supported = True
+
+if _version_not_supported:
+    warnings.warn(
+        f'The grpc package installed is at version {GRPC_VERSION},'
+        + f' but the generated code in armada/job_pb2_grpc.py depends on'
+        + f' grpcio>={GRPC_GENERATED_VERSION}.'
+        + f' Please upgrade your grpc module to grpcio>={GRPC_GENERATED_VERSION}'
+        + f' or downgrade your generated code using grpcio-tools<={GRPC_VERSION}.'
+        + f' This warning will become an error in {EXPECTED_ERROR_RELEASE},'
+        + f' scheduled for release on {SCHEDULED_RELEASE_DATE}.',
+        RuntimeWarning
+    )
+
 
 class JobsStub(object):
     """Missing associated documentation comment in .proto file."""
 
     def __init__(self, channel):
         """Constructor.
 
         Args:
             channel: A grpc.Channel.
         """
         self.GetJobStatus = channel.unary_unary(
                 '/api.Jobs/GetJobStatus',
                 request_serializer=armada_dot_job__pb2.JobStatusRequest.SerializeToString,
                 response_deserializer=armada_dot_job__pb2.JobStatusResponse.FromString,
-                )
+                _registered_method=True)
         self.GetJobDetails = channel.unary_unary(
                 '/api.Jobs/GetJobDetails',
                 request_serializer=armada_dot_job__pb2.JobDetailsRequest.SerializeToString,
                 response_deserializer=armada_dot_job__pb2.JobDetailsResponse.FromString,
-                )
+                _registered_method=True)
         self.GetJobRunDetails = channel.unary_unary(
                 '/api.Jobs/GetJobRunDetails',
                 request_serializer=armada_dot_job__pb2.JobRunDetailsRequest.SerializeToString,
                 response_deserializer=armada_dot_job__pb2.JobRunDetailsResponse.FromString,
-                )
+                _registered_method=True)
 
 
 class JobsServicer(object):
     """Missing associated documentation comment in .proto file."""
 
     def GetJobStatus(self, request, context):
         """Missing associated documentation comment in .proto file."""
@@ -70,14 +95,15 @@
                     request_deserializer=armada_dot_job__pb2.JobRunDetailsRequest.FromString,
                     response_serializer=armada_dot_job__pb2.JobRunDetailsResponse.SerializeToString,
             ),
     }
     generic_handler = grpc.method_handlers_generic_handler(
             'api.Jobs', rpc_method_handlers)
     server.add_generic_rpc_handlers((generic_handler,))
+    server.add_registered_method_handlers('api.Jobs', rpc_method_handlers)
 
 
  # This class is part of an EXPERIMENTAL API.
 class Jobs(object):
     """Missing associated documentation comment in .proto file."""
 
     @staticmethod
@@ -87,46 +113,76 @@
             channel_credentials=None,
             call_credentials=None,
             insecure=False,
             compression=None,
             wait_for_ready=None,
             timeout=None,
             metadata=None):
-        return grpc.experimental.unary_unary(request, target, '/api.Jobs/GetJobStatus',
+        return grpc.experimental.unary_unary(
+            request,
+            target,
+            '/api.Jobs/GetJobStatus',
             armada_dot_job__pb2.JobStatusRequest.SerializeToString,
             armada_dot_job__pb2.JobStatusResponse.FromString,
-            options, channel_credentials,
-            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
 
     @staticmethod
     def GetJobDetails(request,
             target,
             options=(),
             channel_credentials=None,
             call_credentials=None,
             insecure=False,
             compression=None,
             wait_for_ready=None,
             timeout=None,
             metadata=None):
-        return grpc.experimental.unary_unary(request, target, '/api.Jobs/GetJobDetails',
+        return grpc.experimental.unary_unary(
+            request,
+            target,
+            '/api.Jobs/GetJobDetails',
             armada_dot_job__pb2.JobDetailsRequest.SerializeToString,
             armada_dot_job__pb2.JobDetailsResponse.FromString,
-            options, channel_credentials,
-            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
 
     @staticmethod
     def GetJobRunDetails(request,
             target,
             options=(),
             channel_credentials=None,
             call_credentials=None,
             insecure=False,
             compression=None,
             wait_for_ready=None,
             timeout=None,
             metadata=None):
-        return grpc.experimental.unary_unary(request, target, '/api.Jobs/GetJobRunDetails',
+        return grpc.experimental.unary_unary(
+            request,
+            target,
+            '/api.Jobs/GetJobRunDetails',
             armada_dot_job__pb2.JobRunDetailsRequest.SerializeToString,
             armada_dot_job__pb2.JobRunDetailsResponse.FromString,
-            options, channel_credentials,
-            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
```

## armada_client/armada/submit_pb2.py

```diff
@@ -1,11 +1,11 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: armada/submit.proto
-# Protobuf Python Version: 4.25.1
+# Protobuf Python Version: 5.26.1
 """Generated protocol buffer code."""
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
 from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
@@ -17,84 +17,104 @@
 from armada_client.k8s.io.api.core.v1 import generated_pb2 as k8s_dot_io_dot_api_dot_core_dot_v1_dot_generated__pb2
 from armada_client.k8s.io.api.networking.v1 import generated_pb2 as k8s_dot_io_dot_api_dot_networking_dot_v1_dot_generated__pb2
 from armada_client.google.api import annotations_pb2 as google_dot_api_dot_annotations__pb2
 from armada_client.github.com.gogo.protobuf.gogoproto import gogo_pb2 as github_dot_com_dot_gogo_dot_protobuf_dot_gogoproto_dot_gogo__pb2
 from armada_client.armada import health_pb2 as armada_dot_health__pb2
 
 
-DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x13\x61rmada/submit.proto\x12\x03\x61pi\x1a\x1bgoogle/protobuf/empty.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\"k8s.io/api/core/v1/generated.proto\x1a(k8s.io/api/networking/v1/generated.proto\x1a\x1cgoogle/api/annotations.proto\x1a-github.com/gogo/protobuf/gogoproto/gogo.proto\x1a\x13\x61rmada/health.proto\"\x95\x05\n\x14JobSubmitRequestItem\x12\x10\n\x08priority\x18\x01 \x01(\x01\x12\x11\n\tnamespace\x18\x03 \x01(\t\x12\x11\n\tclient_id\x18\x08 \x01(\t\x12\x35\n\x06labels\x18\x04 \x03(\x0b\x32%.api.JobSubmitRequestItem.LabelsEntry\x12?\n\x0b\x61nnotations\x18\x05 \x03(\x0b\x32*.api.JobSubmitRequestItem.AnnotationsEntry\x12S\n\x14required_node_labels\x18\x06 \x03(\x0b\x32\x31.api.JobSubmitRequestItem.RequiredNodeLabelsEntryB\x02\x18\x01\x12\x31\n\x08pod_spec\x18\x02 \x01(\x0b\x32\x1b.k8s.io.api.core.v1.PodSpecB\x02\x18\x01\x12.\n\tpod_specs\x18\x07 \x03(\x0b\x32\x1b.k8s.io.api.core.v1.PodSpec\x12#\n\x07ingress\x18\t \x03(\x0b\x32\x12.api.IngressConfig\x12$\n\x08services\x18\n \x03(\x0b\x32\x12.api.ServiceConfig\x12\x11\n\tscheduler\x18\x0b \x01(\t\x12\x19\n\x11queue_ttl_seconds\x18\x0c \x01(\x03\x1a-\n\x0bLabelsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a\x32\n\x10\x41nnotationsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a\x39\n\x17RequiredNodeLabelsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"\xef\x01\n\rIngressConfig\x12\"\n\x04type\x18\x01 \x01(\x0e\x32\x10.api.IngressTypeB\x02\x18\x01\x12\r\n\x05ports\x18\x02 \x03(\r\x12\x38\n\x0b\x61nnotations\x18\x03 \x03(\x0b\x32#.api.IngressConfig.AnnotationsEntry\x12\x13\n\x0btls_enabled\x18\x04 \x01(\x08\x12\x11\n\tcert_name\x18\x05 \x01(\t\x12\x15\n\ruse_clusterIP\x18\x06 \x01(\x08\x1a\x32\n\x10\x41nnotationsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\">\n\rServiceConfig\x12\x1e\n\x04type\x18\x01 \x01(\x0e\x32\x10.api.ServiceType\x12\r\n\x05ports\x18\x02 \x03(\r\"k\n\x10JobSubmitRequest\x12\r\n\x05queue\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\x34\n\x11job_request_items\x18\x03 \x03(\x0b\x32\x19.api.JobSubmitRequestItem\"f\n\x10JobCancelRequest\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x0f\n\x07job_ids\x18\x04 \x03(\t\x12\x0e\n\x06reason\x18\x05 \x01(\t\"k\n\x13JobSetCancelRequest\x12\x12\n\njob_set_id\x18\x01 \x01(\t\x12\r\n\x05queue\x18\x02 \x01(\t\x12!\n\x06\x66ilter\x18\x03 \x01(\x0b\x32\x11.api.JobSetFilter\x12\x0e\n\x06reason\x18\x04 \x01(\t\"-\n\x0cJobSetFilter\x12\x1d\n\x06states\x18\x01 \x03(\x0e\x32\r.api.JobState\"\xdf\x07\n\x03Job\x12\n\n\x02id\x18\x01 \x01(\t\x12\x11\n\tclient_id\x18\r \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x07 \x01(\t\x12$\n\x06labels\x18\t \x03(\x0b\x32\x14.api.Job.LabelsEntry\x12.\n\x0b\x61nnotations\x18\n \x03(\x0b\x32\x19.api.Job.AnnotationsEntry\x12\x42\n\x14required_node_labels\x18\x0b \x03(\x0b\x32 .api.Job.RequiredNodeLabelsEntryB\x02\x18\x01\x12\r\n\x05owner\x18\x08 \x01(\t\x12#\n\x1bqueue_ownership_user_groups\x18\x0f \x03(\t\x12.\n&compressed_queue_ownership_user_groups\x18\x13 \x01(\x0c\x12\x10\n\x08priority\x18\x04 \x01(\x01\x12\x31\n\x08pod_spec\x18\x05 \x01(\x0b\x32\x1b.k8s.io.api.core.v1.PodSpecB\x02\x18\x01\x12.\n\tpod_specs\x18\x0c \x03(\x0b\x32\x1b.k8s.io.api.core.v1.PodSpec\x12X\n scheduling_resource_requirements\x18\x15 \x01(\x0b\x32(.k8s.io.api.core.v1.ResourceRequirementsB\x04\xc8\xde\x1f\x00\x12\x35\n\x07\x63reated\x18\x06 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12#\n\x07ingress\x18\x0e \x03(\x0b\x32\x12.api.IngressConfig\x12$\n\x08services\x18\x10 \x03(\x0b\x32\x12.api.ServiceConfig\x12\x36\n\x0bk8s_ingress\x18\x11 \x03(\x0b\x32!.k8s.io.api.networking.v1.Ingress\x12\x30\n\x0bk8s_service\x18\x12 \x03(\x0b\x32\x1b.k8s.io.api.core.v1.Service\x12\x11\n\tscheduler\x18\x14 \x01(\t\x12\x19\n\x11queue_ttl_seconds\x18\x16 \x01(\x03\x1a-\n\x0bLabelsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a\x32\n\x10\x41nnotationsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a\x39\n\x17RequiredNodeLabelsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"b\n\x16JobReprioritizeRequest\x12\x0f\n\x07job_ids\x18\x01 \x03(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x14\n\x0cnew_priority\x18\x04 \x01(\x01\"\xb6\x01\n\x17JobReprioritizeResponse\x12[\n\x18reprioritization_results\x18\x01 \x03(\x0b\x32\x39.api.JobReprioritizeResponse.ReprioritizationResultsEntry\x1a>\n\x1cReprioritizationResultsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"6\n\x15JobSubmitResponseItem\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\r\n\x05\x65rror\x18\x02 \x01(\t\"K\n\x11JobSubmitResponse\x12\x36\n\x12job_response_items\x18\x01 \x03(\x0b\x32\x1a.api.JobSubmitResponseItem\"\xed\x02\n\x05Queue\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x17\n\x0fpriority_factor\x18\x02 \x01(\x01\x12\x13\n\x0buser_owners\x18\x03 \x03(\t\x12\x14\n\x0cgroup_owners\x18\x04 \x03(\t\x12\x37\n\x0fresource_limits\x18\x05 \x03(\x0b\x32\x1e.api.Queue.ResourceLimitsEntry\x12+\n\x0bpermissions\x18\x06 \x03(\x0b\x32\x16.api.Queue.Permissions\x1au\n\x0bPermissions\x12\x30\n\x08subjects\x18\x01 \x03(\x0b\x32\x1e.api.Queue.Permissions.Subject\x12\r\n\x05verbs\x18\x02 \x03(\t\x1a%\n\x07Subject\x12\x0c\n\x04kind\x18\x01 \x01(\t\x12\x0c\n\x04name\x18\x02 \x01(\t\x1a\x35\n\x13ResourceLimitsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\x01:\x02\x38\x01\"\'\n\tQueueList\x12\x1a\n\x06queues\x18\x01 \x03(\x0b\x32\n.api.Queue\"=\n\x12\x43\x61ncellationResult\x12\'\n\rcancelled_ids\x18\x01 \x03(\tB\x10\xea\xde\x1f\x0c\x63\x61ncelledIds\"\x1f\n\x0fQueueGetRequest\x12\x0c\n\x04name\x18\x01 \x01(\t\"\'\n\x18StreamingQueueGetRequest\x12\x0b\n\x03num\x18\x01 \x01(\r\"\"\n\x12QueueDeleteRequest\x12\x0c\n\x04name\x18\x01 \x01(\t\"D\n\nJobSetInfo\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x13\n\x0bqueued_jobs\x18\x02 \x01(\x05\x12\x13\n\x0bleased_jobs\x18\x03 \x01(\x05\"?\n\x13QueueUpdateResponse\x12\x19\n\x05queue\x18\x01 \x01(\x0b\x32\n.api.Queue\x12\r\n\x05\x65rror\x18\x02 \x01(\t\"K\n\x18\x42\x61tchQueueUpdateResponse\x12/\n\rfailed_queues\x18\x01 \x03(\x0b\x32\x18.api.QueueUpdateResponse\"?\n\x13QueueCreateResponse\x12\x19\n\x05queue\x18\x01 \x01(\x0b\x32\n.api.Queue\x12\r\n\x05\x65rror\x18\x02 \x01(\t\"K\n\x18\x42\x61tchQueueCreateResponse\x12/\n\rfailed_queues\x18\x01 \x03(\x0b\x32\x18.api.QueueCreateResponse\"\x0b\n\tEndMarker\"\\\n\x15StreamingQueueMessage\x12\x1b\n\x05queue\x18\x01 \x01(\x0b\x32\n.api.QueueH\x00\x12\x1d\n\x03\x65nd\x18\x02 \x01(\x0b\x32\x0e.api.EndMarkerH\x00\x42\x07\n\x05\x65vent*\x1a\n\x0bIngressType\x12\x0b\n\x07Ingress\x10\x00*)\n\x0bServiceType\x12\x0c\n\x08NodePort\x10\x00\x12\x0c\n\x08Headless\x10\x01*\x91\x01\n\x08JobState\x12\n\n\x06QUEUED\x10\x00\x12\x0b\n\x07PENDING\x10\x01\x12\x0b\n\x07RUNNING\x10\x02\x12\r\n\tSUCCEEDED\x10\x03\x12\n\n\x06\x46\x41ILED\x10\x04\x12\x0b\n\x07UNKNOWN\x10\x05\x12\r\n\tSUBMITTED\x10\x06\x12\n\n\x06LEASED\x10\x07\x12\r\n\tPREEMPTED\x10\x08\x12\r\n\tCANCELLED\x10\t2\xb0\x08\n\x06Submit\x12V\n\nSubmitJobs\x12\x15.api.JobSubmitRequest\x1a\x16.api.JobSubmitResponse\"\x19\x82\xd3\xe4\x93\x02\x13\"\x0e/v1/job/submit:\x01*\x12W\n\nCancelJobs\x12\x15.api.JobCancelRequest\x1a\x17.api.CancellationResult\"\x19\x82\xd3\xe4\x93\x02\x13\"\x0e/v1/job/cancel:\x01*\x12^\n\x0c\x43\x61ncelJobSet\x12\x18.api.JobSetCancelRequest\x1a\x16.google.protobuf.Empty\"\x1c\x82\xd3\xe4\x93\x02\x16\"\x11/v1/jobset/cancel:\x01*\x12n\n\x10ReprioritizeJobs\x12\x1b.api.JobReprioritizeRequest\x1a\x1c.api.JobReprioritizeResponse\"\x1f\x82\xd3\xe4\x93\x02\x19\"\x14/v1/job/reprioritize:\x01*\x12G\n\x0b\x43reateQueue\x12\n.api.Queue\x1a\x16.google.protobuf.Empty\"\x14\x82\xd3\xe4\x93\x02\x0e\"\t/v1/queue:\x01*\x12\x63\n\x0c\x43reateQueues\x12\x0e.api.QueueList\x1a\x1d.api.BatchQueueCreateResponse\"$\x82\xd3\xe4\x93\x02\x1e\"\x19/v1/batched/create_queues:\x01*\x12N\n\x0bUpdateQueue\x12\n.api.Queue\x1a\x16.google.protobuf.Empty\"\x1b\x82\xd3\xe4\x93\x02\x15\x1a\x10/v1/queue/{name}:\x01*\x12\x63\n\x0cUpdateQueues\x12\x0e.api.QueueList\x1a\x1d.api.BatchQueueUpdateResponse\"$\x82\xd3\xe4\x93\x02\x1e\x1a\x19/v1/batched/update_queues:\x01*\x12X\n\x0b\x44\x65leteQueue\x12\x17.api.QueueDeleteRequest\x1a\x16.google.protobuf.Empty\"\x18\x82\xd3\xe4\x93\x02\x12*\x10/v1/queue/{name}\x12\x46\n\x08GetQueue\x12\x14.api.QueueGetRequest\x1a\n.api.Queue\"\x18\x82\xd3\xe4\x93\x02\x12\x12\x10/v1/queue/{name}\x12\x64\n\tGetQueues\x12\x1d.api.StreamingQueueGetRequest\x1a\x1a.api.StreamingQueueMessage\"\x1a\x82\xd3\xe4\x93\x02\x14\x12\x12/v1/batched/queues0\x01\x12:\n\x06Health\x12\x16.google.protobuf.Empty\x1a\x18.api.HealthCheckResponseBHZ\'github.com/armadaproject/armada/pkg/api\xaa\x02\x14\x41rmadaProject.Io.Api\xd8\xe1\x1e\x00\x80\xe2\x1e\x01\x62\x06proto3')
+DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x13\x61rmada/submit.proto\x12\x03\x61pi\x1a\x1bgoogle/protobuf/empty.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\"k8s.io/api/core/v1/generated.proto\x1a(k8s.io/api/networking/v1/generated.proto\x1a\x1cgoogle/api/annotations.proto\x1a-github.com/gogo/protobuf/gogoproto/gogo.proto\x1a\x13\x61rmada/health.proto\"\x95\x05\n\x14JobSubmitRequestItem\x12\x10\n\x08priority\x18\x01 \x01(\x01\x12\x11\n\tnamespace\x18\x03 \x01(\t\x12\x11\n\tclient_id\x18\x08 \x01(\t\x12\x35\n\x06labels\x18\x04 \x03(\x0b\x32%.api.JobSubmitRequestItem.LabelsEntry\x12?\n\x0b\x61nnotations\x18\x05 \x03(\x0b\x32*.api.JobSubmitRequestItem.AnnotationsEntry\x12S\n\x14required_node_labels\x18\x06 \x03(\x0b\x32\x31.api.JobSubmitRequestItem.RequiredNodeLabelsEntryB\x02\x18\x01\x12\x31\n\x08pod_spec\x18\x02 \x01(\x0b\x32\x1b.k8s.io.api.core.v1.PodSpecB\x02\x18\x01\x12.\n\tpod_specs\x18\x07 \x03(\x0b\x32\x1b.k8s.io.api.core.v1.PodSpec\x12#\n\x07ingress\x18\t \x03(\x0b\x32\x12.api.IngressConfig\x12$\n\x08services\x18\n \x03(\x0b\x32\x12.api.ServiceConfig\x12\x11\n\tscheduler\x18\x0b \x01(\t\x12\x19\n\x11queue_ttl_seconds\x18\x0c \x01(\x03\x1a-\n\x0bLabelsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a\x32\n\x10\x41nnotationsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a\x39\n\x17RequiredNodeLabelsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"\xef\x01\n\rIngressConfig\x12\"\n\x04type\x18\x01 \x01(\x0e\x32\x10.api.IngressTypeB\x02\x18\x01\x12\r\n\x05ports\x18\x02 \x03(\r\x12\x38\n\x0b\x61nnotations\x18\x03 \x03(\x0b\x32#.api.IngressConfig.AnnotationsEntry\x12\x13\n\x0btls_enabled\x18\x04 \x01(\x08\x12\x11\n\tcert_name\x18\x05 \x01(\t\x12\x15\n\ruse_clusterIP\x18\x06 \x01(\x08\x1a\x32\n\x10\x41nnotationsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\">\n\rServiceConfig\x12\x1e\n\x04type\x18\x01 \x01(\x0e\x32\x10.api.ServiceType\x12\r\n\x05ports\x18\x02 \x03(\r\"k\n\x10JobSubmitRequest\x12\r\n\x05queue\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\x34\n\x11job_request_items\x18\x03 \x03(\x0b\x32\x19.api.JobSubmitRequestItem\"G\n\x11JobPreemptRequest\x12\r\n\x05queue\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\x0f\n\x07job_ids\x18\x03 \x03(\t\"f\n\x10JobCancelRequest\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x0f\n\x07job_ids\x18\x04 \x03(\t\x12\x0e\n\x06reason\x18\x05 \x01(\t\"k\n\x13JobSetCancelRequest\x12\x12\n\njob_set_id\x18\x01 \x01(\t\x12\r\n\x05queue\x18\x02 \x01(\t\x12!\n\x06\x66ilter\x18\x03 \x01(\x0b\x32\x11.api.JobSetFilter\x12\x0e\n\x06reason\x18\x04 \x01(\t\"-\n\x0cJobSetFilter\x12\x1d\n\x06states\x18\x01 \x03(\x0e\x32\r.api.JobState\"\xdf\x07\n\x03Job\x12\n\n\x02id\x18\x01 \x01(\t\x12\x11\n\tclient_id\x18\r \x01(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x07 \x01(\t\x12$\n\x06labels\x18\t \x03(\x0b\x32\x14.api.Job.LabelsEntry\x12.\n\x0b\x61nnotations\x18\n \x03(\x0b\x32\x19.api.Job.AnnotationsEntry\x12\x42\n\x14required_node_labels\x18\x0b \x03(\x0b\x32 .api.Job.RequiredNodeLabelsEntryB\x02\x18\x01\x12\r\n\x05owner\x18\x08 \x01(\t\x12#\n\x1bqueue_ownership_user_groups\x18\x0f \x03(\t\x12.\n&compressed_queue_ownership_user_groups\x18\x13 \x01(\x0c\x12\x10\n\x08priority\x18\x04 \x01(\x01\x12\x31\n\x08pod_spec\x18\x05 \x01(\x0b\x32\x1b.k8s.io.api.core.v1.PodSpecB\x02\x18\x01\x12.\n\tpod_specs\x18\x0c \x03(\x0b\x32\x1b.k8s.io.api.core.v1.PodSpec\x12X\n scheduling_resource_requirements\x18\x15 \x01(\x0b\x32(.k8s.io.api.core.v1.ResourceRequirementsB\x04\xc8\xde\x1f\x00\x12\x35\n\x07\x63reated\x18\x06 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x08\xc8\xde\x1f\x00\x90\xdf\x1f\x01\x12#\n\x07ingress\x18\x0e \x03(\x0b\x32\x12.api.IngressConfig\x12$\n\x08services\x18\x10 \x03(\x0b\x32\x12.api.ServiceConfig\x12\x36\n\x0bk8s_ingress\x18\x11 \x03(\x0b\x32!.k8s.io.api.networking.v1.Ingress\x12\x30\n\x0bk8s_service\x18\x12 \x03(\x0b\x32\x1b.k8s.io.api.core.v1.Service\x12\x11\n\tscheduler\x18\x14 \x01(\t\x12\x19\n\x11queue_ttl_seconds\x18\x16 \x01(\x03\x1a-\n\x0bLabelsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a\x32\n\x10\x41nnotationsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a\x39\n\x17RequiredNodeLabelsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"b\n\x16JobReprioritizeRequest\x12\x0f\n\x07job_ids\x18\x01 \x03(\t\x12\x12\n\njob_set_id\x18\x02 \x01(\t\x12\r\n\x05queue\x18\x03 \x01(\t\x12\x14\n\x0cnew_priority\x18\x04 \x01(\x01\"\xb6\x01\n\x17JobReprioritizeResponse\x12[\n\x18reprioritization_results\x18\x01 \x03(\x0b\x32\x39.api.JobReprioritizeResponse.ReprioritizationResultsEntry\x1a>\n\x1cReprioritizationResultsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"6\n\x15JobSubmitResponseItem\x12\x0e\n\x06job_id\x18\x01 \x01(\t\x12\r\n\x05\x65rror\x18\x02 \x01(\t\"K\n\x11JobSubmitResponse\x12\x36\n\x12job_response_items\x18\x01 \x03(\x0b\x32\x1a.api.JobSubmitResponseItem\"\xc6\x04\n\x05Queue\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x17\n\x0fpriority_factor\x18\x02 \x01(\x01\x12\x13\n\x0buser_owners\x18\x03 \x03(\t\x12\x14\n\x0cgroup_owners\x18\x04 \x03(\t\x12;\n\x0fresource_limits\x18\x05 \x03(\x0b\x32\x1e.api.Queue.ResourceLimitsEntryB\x02\x18\x01\x12g\n&resource_limits_by_priority_class_name\x18\x07 \x03(\x0b\x32\x31.api.Queue.ResourceLimitsByPriorityClassNameEntryB\x04\xc8\xde\x1f\x00\x12+\n\x0bpermissions\x18\x06 \x03(\x0b\x32\x16.api.Queue.Permissions\x1au\n\x0bPermissions\x12\x30\n\x08subjects\x18\x01 \x03(\x0b\x32\x1e.api.Queue.Permissions.Subject\x12\r\n\x05verbs\x18\x02 \x03(\t\x1a%\n\x07Subject\x12\x0c\n\x04kind\x18\x01 \x01(\t\x12\x0c\n\x04name\x18\x02 \x01(\t\x1a\x35\n\x13ResourceLimitsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\x01:\x02\x38\x01\x1aj\n&ResourceLimitsByPriorityClassNameEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12/\n\x05value\x18\x02 \x01(\x0b\x32 .api.PriorityClassResourceLimits:\x02\x38\x01\"\xa7\x03\n\x1bPriorityClassResourceLimits\x12\x66\n\x19maximum_resource_fraction\x18\x01 \x03(\x0b\x32=.api.PriorityClassResourceLimits.MaximumResourceFractionEntryB\x04\xc8\xde\x1f\x00\x12t\n!maximum_resource_fraction_by_pool\x18\x02 \x03(\x0b\x32\x43.api.PriorityClassResourceLimits.MaximumResourceFractionByPoolEntryB\x04\xc8\xde\x1f\x00\x1a>\n\x1cMaximumResourceFractionEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\x01:\x02\x38\x01\x1aj\n\"MaximumResourceFractionByPoolEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x33\n\x05value\x18\x02 \x01(\x0b\x32$.api.PriorityClassPoolResourceLimits:\x02\x38\x01\"\xcd\x01\n\x1fPriorityClassPoolResourceLimits\x12j\n\x19maximum_resource_fraction\x18\x01 \x03(\x0b\x32\x41.api.PriorityClassPoolResourceLimits.MaximumResourceFractionEntryB\x04\xc8\xde\x1f\x00\x1a>\n\x1cMaximumResourceFractionEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\x01:\x02\x38\x01\"\'\n\tQueueList\x12\x1a\n\x06queues\x18\x01 \x03(\x0b\x32\n.api.Queue\"=\n\x12\x43\x61ncellationResult\x12\'\n\rcancelled_ids\x18\x01 \x03(\tB\x10\xea\xde\x1f\x0c\x63\x61ncelledIds\"\x1f\n\x0fQueueGetRequest\x12\x0c\n\x04name\x18\x01 \x01(\t\"\'\n\x18StreamingQueueGetRequest\x12\x0b\n\x03num\x18\x01 \x01(\r\"\"\n\x12QueueDeleteRequest\x12\x0c\n\x04name\x18\x01 \x01(\t\"D\n\nJobSetInfo\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x13\n\x0bqueued_jobs\x18\x02 \x01(\x05\x12\x13\n\x0bleased_jobs\x18\x03 \x01(\x05\"?\n\x13QueueUpdateResponse\x12\x19\n\x05queue\x18\x01 \x01(\x0b\x32\n.api.Queue\x12\r\n\x05\x65rror\x18\x02 \x01(\t\"K\n\x18\x42\x61tchQueueUpdateResponse\x12/\n\rfailed_queues\x18\x01 \x03(\x0b\x32\x18.api.QueueUpdateResponse\"?\n\x13QueueCreateResponse\x12\x19\n\x05queue\x18\x01 \x01(\x0b\x32\n.api.Queue\x12\r\n\x05\x65rror\x18\x02 \x01(\t\"K\n\x18\x42\x61tchQueueCreateResponse\x12/\n\rfailed_queues\x18\x01 \x03(\x0b\x32\x18.api.QueueCreateResponse\"\x0b\n\tEndMarker\"\\\n\x15StreamingQueueMessage\x12\x1b\n\x05queue\x18\x01 \x01(\x0b\x32\n.api.QueueH\x00\x12\x1d\n\x03\x65nd\x18\x02 \x01(\x0b\x32\x0e.api.EndMarkerH\x00\x42\x07\n\x05\x65vent*\x1a\n\x0bIngressType\x12\x0b\n\x07Ingress\x10\x00*)\n\x0bServiceType\x12\x0c\n\x08NodePort\x10\x00\x12\x0c\n\x08Headless\x10\x01*\x91\x01\n\x08JobState\x12\n\n\x06QUEUED\x10\x00\x12\x0b\n\x07PENDING\x10\x01\x12\x0b\n\x07RUNNING\x10\x02\x12\r\n\tSUCCEEDED\x10\x03\x12\n\n\x06\x46\x41ILED\x10\x04\x12\x0b\n\x07UNKNOWN\x10\x05\x12\r\n\tSUBMITTED\x10\x06\x12\n\n\x06LEASED\x10\x07\x12\r\n\tPREEMPTED\x10\x08\x12\r\n\tCANCELLED\x10\t2\x8b\t\n\x06Submit\x12V\n\nSubmitJobs\x12\x15.api.JobSubmitRequest\x1a\x16.api.JobSubmitResponse\"\x19\x82\xd3\xe4\x93\x02\x13\"\x0e/v1/job/submit:\x01*\x12W\n\nCancelJobs\x12\x15.api.JobCancelRequest\x1a\x17.api.CancellationResult\"\x19\x82\xd3\xe4\x93\x02\x13\"\x0e/v1/job/cancel:\x01*\x12^\n\x0c\x43\x61ncelJobSet\x12\x18.api.JobSetCancelRequest\x1a\x16.google.protobuf.Empty\"\x1c\x82\xd3\xe4\x93\x02\x16\"\x11/v1/jobset/cancel:\x01*\x12n\n\x10ReprioritizeJobs\x12\x1b.api.JobReprioritizeRequest\x1a\x1c.api.JobReprioritizeResponse\"\x1f\x82\xd3\xe4\x93\x02\x19\"\x14/v1/job/reprioritize:\x01*\x12Y\n\x0bPreemptJobs\x12\x16.api.JobPreemptRequest\x1a\x16.google.protobuf.Empty\"\x1a\x82\xd3\xe4\x93\x02\x14\"\x0f/v1/job/preempt:\x01*\x12G\n\x0b\x43reateQueue\x12\n.api.Queue\x1a\x16.google.protobuf.Empty\"\x14\x82\xd3\xe4\x93\x02\x0e\"\t/v1/queue:\x01*\x12\x63\n\x0c\x43reateQueues\x12\x0e.api.QueueList\x1a\x1d.api.BatchQueueCreateResponse\"$\x82\xd3\xe4\x93\x02\x1e\"\x19/v1/batched/create_queues:\x01*\x12N\n\x0bUpdateQueue\x12\n.api.Queue\x1a\x16.google.protobuf.Empty\"\x1b\x82\xd3\xe4\x93\x02\x15\x1a\x10/v1/queue/{name}:\x01*\x12\x63\n\x0cUpdateQueues\x12\x0e.api.QueueList\x1a\x1d.api.BatchQueueUpdateResponse\"$\x82\xd3\xe4\x93\x02\x1e\x1a\x19/v1/batched/update_queues:\x01*\x12X\n\x0b\x44\x65leteQueue\x12\x17.api.QueueDeleteRequest\x1a\x16.google.protobuf.Empty\"\x18\x82\xd3\xe4\x93\x02\x12*\x10/v1/queue/{name}\x12\x46\n\x08GetQueue\x12\x14.api.QueueGetRequest\x1a\n.api.Queue\"\x18\x82\xd3\xe4\x93\x02\x12\x12\x10/v1/queue/{name}\x12\x64\n\tGetQueues\x12\x1d.api.StreamingQueueGetRequest\x1a\x1a.api.StreamingQueueMessage\"\x1a\x82\xd3\xe4\x93\x02\x14\x12\x12/v1/batched/queues0\x01\x12:\n\x06Health\x12\x16.google.protobuf.Empty\x1a\x18.api.HealthCheckResponseBHZ\'github.com/armadaproject/armada/pkg/api\xaa\x02\x14\x41rmadaProject.Io.Api\xd8\xe1\x1e\x00\x80\xe2\x1e\x01\x62\x06proto3')
 
 _globals = globals()
 _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
 _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'armada.submit_pb2', _globals)
-if _descriptor._USE_C_DESCRIPTORS == False:
-  _globals['DESCRIPTOR']._options = None
+if not _descriptor._USE_C_DESCRIPTORS:
+  _globals['DESCRIPTOR']._loaded_options = None
   _globals['DESCRIPTOR']._serialized_options = b'Z\'github.com/armadaproject/armada/pkg/api\252\002\024ArmadaProject.Io.Api\330\341\036\000\200\342\036\001'
-  _globals['_JOBSUBMITREQUESTITEM_LABELSENTRY']._options = None
+  _globals['_JOBSUBMITREQUESTITEM_LABELSENTRY']._loaded_options = None
   _globals['_JOBSUBMITREQUESTITEM_LABELSENTRY']._serialized_options = b'8\001'
-  _globals['_JOBSUBMITREQUESTITEM_ANNOTATIONSENTRY']._options = None
+  _globals['_JOBSUBMITREQUESTITEM_ANNOTATIONSENTRY']._loaded_options = None
   _globals['_JOBSUBMITREQUESTITEM_ANNOTATIONSENTRY']._serialized_options = b'8\001'
-  _globals['_JOBSUBMITREQUESTITEM_REQUIREDNODELABELSENTRY']._options = None
+  _globals['_JOBSUBMITREQUESTITEM_REQUIREDNODELABELSENTRY']._loaded_options = None
   _globals['_JOBSUBMITREQUESTITEM_REQUIREDNODELABELSENTRY']._serialized_options = b'8\001'
-  _globals['_JOBSUBMITREQUESTITEM'].fields_by_name['required_node_labels']._options = None
+  _globals['_JOBSUBMITREQUESTITEM'].fields_by_name['required_node_labels']._loaded_options = None
   _globals['_JOBSUBMITREQUESTITEM'].fields_by_name['required_node_labels']._serialized_options = b'\030\001'
-  _globals['_JOBSUBMITREQUESTITEM'].fields_by_name['pod_spec']._options = None
+  _globals['_JOBSUBMITREQUESTITEM'].fields_by_name['pod_spec']._loaded_options = None
   _globals['_JOBSUBMITREQUESTITEM'].fields_by_name['pod_spec']._serialized_options = b'\030\001'
-  _globals['_INGRESSCONFIG_ANNOTATIONSENTRY']._options = None
+  _globals['_INGRESSCONFIG_ANNOTATIONSENTRY']._loaded_options = None
   _globals['_INGRESSCONFIG_ANNOTATIONSENTRY']._serialized_options = b'8\001'
-  _globals['_INGRESSCONFIG'].fields_by_name['type']._options = None
+  _globals['_INGRESSCONFIG'].fields_by_name['type']._loaded_options = None
   _globals['_INGRESSCONFIG'].fields_by_name['type']._serialized_options = b'\030\001'
-  _globals['_JOB_LABELSENTRY']._options = None
+  _globals['_JOB_LABELSENTRY']._loaded_options = None
   _globals['_JOB_LABELSENTRY']._serialized_options = b'8\001'
-  _globals['_JOB_ANNOTATIONSENTRY']._options = None
+  _globals['_JOB_ANNOTATIONSENTRY']._loaded_options = None
   _globals['_JOB_ANNOTATIONSENTRY']._serialized_options = b'8\001'
-  _globals['_JOB_REQUIREDNODELABELSENTRY']._options = None
+  _globals['_JOB_REQUIREDNODELABELSENTRY']._loaded_options = None
   _globals['_JOB_REQUIREDNODELABELSENTRY']._serialized_options = b'8\001'
-  _globals['_JOB'].fields_by_name['required_node_labels']._options = None
+  _globals['_JOB'].fields_by_name['required_node_labels']._loaded_options = None
   _globals['_JOB'].fields_by_name['required_node_labels']._serialized_options = b'\030\001'
-  _globals['_JOB'].fields_by_name['pod_spec']._options = None
+  _globals['_JOB'].fields_by_name['pod_spec']._loaded_options = None
   _globals['_JOB'].fields_by_name['pod_spec']._serialized_options = b'\030\001'
-  _globals['_JOB'].fields_by_name['scheduling_resource_requirements']._options = None
+  _globals['_JOB'].fields_by_name['scheduling_resource_requirements']._loaded_options = None
   _globals['_JOB'].fields_by_name['scheduling_resource_requirements']._serialized_options = b'\310\336\037\000'
-  _globals['_JOB'].fields_by_name['created']._options = None
+  _globals['_JOB'].fields_by_name['created']._loaded_options = None
   _globals['_JOB'].fields_by_name['created']._serialized_options = b'\310\336\037\000\220\337\037\001'
-  _globals['_JOBREPRIORITIZERESPONSE_REPRIORITIZATIONRESULTSENTRY']._options = None
+  _globals['_JOBREPRIORITIZERESPONSE_REPRIORITIZATIONRESULTSENTRY']._loaded_options = None
   _globals['_JOBREPRIORITIZERESPONSE_REPRIORITIZATIONRESULTSENTRY']._serialized_options = b'8\001'
-  _globals['_QUEUE_RESOURCELIMITSENTRY']._options = None
+  _globals['_QUEUE_RESOURCELIMITSENTRY']._loaded_options = None
   _globals['_QUEUE_RESOURCELIMITSENTRY']._serialized_options = b'8\001'
-  _globals['_CANCELLATIONRESULT'].fields_by_name['cancelled_ids']._options = None
+  _globals['_QUEUE_RESOURCELIMITSBYPRIORITYCLASSNAMEENTRY']._loaded_options = None
+  _globals['_QUEUE_RESOURCELIMITSBYPRIORITYCLASSNAMEENTRY']._serialized_options = b'8\001'
+  _globals['_QUEUE'].fields_by_name['resource_limits']._loaded_options = None
+  _globals['_QUEUE'].fields_by_name['resource_limits']._serialized_options = b'\030\001'
+  _globals['_QUEUE'].fields_by_name['resource_limits_by_priority_class_name']._loaded_options = None
+  _globals['_QUEUE'].fields_by_name['resource_limits_by_priority_class_name']._serialized_options = b'\310\336\037\000'
+  _globals['_PRIORITYCLASSRESOURCELIMITS_MAXIMUMRESOURCEFRACTIONENTRY']._loaded_options = None
+  _globals['_PRIORITYCLASSRESOURCELIMITS_MAXIMUMRESOURCEFRACTIONENTRY']._serialized_options = b'8\001'
+  _globals['_PRIORITYCLASSRESOURCELIMITS_MAXIMUMRESOURCEFRACTIONBYPOOLENTRY']._loaded_options = None
+  _globals['_PRIORITYCLASSRESOURCELIMITS_MAXIMUMRESOURCEFRACTIONBYPOOLENTRY']._serialized_options = b'8\001'
+  _globals['_PRIORITYCLASSRESOURCELIMITS'].fields_by_name['maximum_resource_fraction']._loaded_options = None
+  _globals['_PRIORITYCLASSRESOURCELIMITS'].fields_by_name['maximum_resource_fraction']._serialized_options = b'\310\336\037\000'
+  _globals['_PRIORITYCLASSRESOURCELIMITS'].fields_by_name['maximum_resource_fraction_by_pool']._loaded_options = None
+  _globals['_PRIORITYCLASSRESOURCELIMITS'].fields_by_name['maximum_resource_fraction_by_pool']._serialized_options = b'\310\336\037\000'
+  _globals['_PRIORITYCLASSPOOLRESOURCELIMITS_MAXIMUMRESOURCEFRACTIONENTRY']._loaded_options = None
+  _globals['_PRIORITYCLASSPOOLRESOURCELIMITS_MAXIMUMRESOURCEFRACTIONENTRY']._serialized_options = b'8\001'
+  _globals['_PRIORITYCLASSPOOLRESOURCELIMITS'].fields_by_name['maximum_resource_fraction']._loaded_options = None
+  _globals['_PRIORITYCLASSPOOLRESOURCELIMITS'].fields_by_name['maximum_resource_fraction']._serialized_options = b'\310\336\037\000'
+  _globals['_CANCELLATIONRESULT'].fields_by_name['cancelled_ids']._loaded_options = None
   _globals['_CANCELLATIONRESULT'].fields_by_name['cancelled_ids']._serialized_options = b'\352\336\037\014cancelledIds'
-  _globals['_SUBMIT'].methods_by_name['SubmitJobs']._options = None
+  _globals['_SUBMIT'].methods_by_name['SubmitJobs']._loaded_options = None
   _globals['_SUBMIT'].methods_by_name['SubmitJobs']._serialized_options = b'\202\323\344\223\002\023\"\016/v1/job/submit:\001*'
-  _globals['_SUBMIT'].methods_by_name['CancelJobs']._options = None
+  _globals['_SUBMIT'].methods_by_name['CancelJobs']._loaded_options = None
   _globals['_SUBMIT'].methods_by_name['CancelJobs']._serialized_options = b'\202\323\344\223\002\023\"\016/v1/job/cancel:\001*'
-  _globals['_SUBMIT'].methods_by_name['CancelJobSet']._options = None
+  _globals['_SUBMIT'].methods_by_name['CancelJobSet']._loaded_options = None
   _globals['_SUBMIT'].methods_by_name['CancelJobSet']._serialized_options = b'\202\323\344\223\002\026\"\021/v1/jobset/cancel:\001*'
-  _globals['_SUBMIT'].methods_by_name['ReprioritizeJobs']._options = None
+  _globals['_SUBMIT'].methods_by_name['ReprioritizeJobs']._loaded_options = None
   _globals['_SUBMIT'].methods_by_name['ReprioritizeJobs']._serialized_options = b'\202\323\344\223\002\031\"\024/v1/job/reprioritize:\001*'
-  _globals['_SUBMIT'].methods_by_name['CreateQueue']._options = None
+  _globals['_SUBMIT'].methods_by_name['PreemptJobs']._loaded_options = None
+  _globals['_SUBMIT'].methods_by_name['PreemptJobs']._serialized_options = b'\202\323\344\223\002\024\"\017/v1/job/preempt:\001*'
+  _globals['_SUBMIT'].methods_by_name['CreateQueue']._loaded_options = None
   _globals['_SUBMIT'].methods_by_name['CreateQueue']._serialized_options = b'\202\323\344\223\002\016\"\t/v1/queue:\001*'
-  _globals['_SUBMIT'].methods_by_name['CreateQueues']._options = None
+  _globals['_SUBMIT'].methods_by_name['CreateQueues']._loaded_options = None
   _globals['_SUBMIT'].methods_by_name['CreateQueues']._serialized_options = b'\202\323\344\223\002\036\"\031/v1/batched/create_queues:\001*'
-  _globals['_SUBMIT'].methods_by_name['UpdateQueue']._options = None
+  _globals['_SUBMIT'].methods_by_name['UpdateQueue']._loaded_options = None
   _globals['_SUBMIT'].methods_by_name['UpdateQueue']._serialized_options = b'\202\323\344\223\002\025\032\020/v1/queue/{name}:\001*'
-  _globals['_SUBMIT'].methods_by_name['UpdateQueues']._options = None
+  _globals['_SUBMIT'].methods_by_name['UpdateQueues']._loaded_options = None
   _globals['_SUBMIT'].methods_by_name['UpdateQueues']._serialized_options = b'\202\323\344\223\002\036\032\031/v1/batched/update_queues:\001*'
-  _globals['_SUBMIT'].methods_by_name['DeleteQueue']._options = None
+  _globals['_SUBMIT'].methods_by_name['DeleteQueue']._loaded_options = None
   _globals['_SUBMIT'].methods_by_name['DeleteQueue']._serialized_options = b'\202\323\344\223\002\022*\020/v1/queue/{name}'
-  _globals['_SUBMIT'].methods_by_name['GetQueue']._options = None
+  _globals['_SUBMIT'].methods_by_name['GetQueue']._loaded_options = None
   _globals['_SUBMIT'].methods_by_name['GetQueue']._serialized_options = b'\202\323\344\223\002\022\022\020/v1/queue/{name}'
-  _globals['_SUBMIT'].methods_by_name['GetQueues']._options = None
+  _globals['_SUBMIT'].methods_by_name['GetQueues']._loaded_options = None
   _globals['_SUBMIT'].methods_by_name['GetQueues']._serialized_options = b'\202\323\344\223\002\024\022\022/v1/batched/queues'
-  _globals['_INGRESSTYPE']._serialized_start=4060
-  _globals['_INGRESSTYPE']._serialized_end=4086
-  _globals['_SERVICETYPE']._serialized_start=4088
-  _globals['_SERVICETYPE']._serialized_end=4129
-  _globals['_JOBSTATE']._serialized_start=4132
-  _globals['_JOBSTATE']._serialized_end=4277
+  _globals['_INGRESSTYPE']._serialized_start=4984
+  _globals['_INGRESSTYPE']._serialized_end=5010
+  _globals['_SERVICETYPE']._serialized_start=5012
+  _globals['_SERVICETYPE']._serialized_end=5053
+  _globals['_JOBSTATE']._serialized_start=5056
+  _globals['_JOBSTATE']._serialized_end=5201
   _globals['_JOBSUBMITREQUESTITEM']._serialized_start=267
   _globals['_JOBSUBMITREQUESTITEM']._serialized_end=928
   _globals['_JOBSUBMITREQUESTITEM_LABELSENTRY']._serialized_start=772
   _globals['_JOBSUBMITREQUESTITEM_LABELSENTRY']._serialized_end=817
   _globals['_JOBSUBMITREQUESTITEM_ANNOTATIONSENTRY']._serialized_start=819
   _globals['_JOBSUBMITREQUESTITEM_ANNOTATIONSENTRY']._serialized_end=869
   _globals['_JOBSUBMITREQUESTITEM_REQUIREDNODELABELSENTRY']._serialized_start=871
@@ -103,66 +123,80 @@
   _globals['_INGRESSCONFIG']._serialized_end=1170
   _globals['_INGRESSCONFIG_ANNOTATIONSENTRY']._serialized_start=819
   _globals['_INGRESSCONFIG_ANNOTATIONSENTRY']._serialized_end=869
   _globals['_SERVICECONFIG']._serialized_start=1172
   _globals['_SERVICECONFIG']._serialized_end=1234
   _globals['_JOBSUBMITREQUEST']._serialized_start=1236
   _globals['_JOBSUBMITREQUEST']._serialized_end=1343
-  _globals['_JOBCANCELREQUEST']._serialized_start=1345
-  _globals['_JOBCANCELREQUEST']._serialized_end=1447
-  _globals['_JOBSETCANCELREQUEST']._serialized_start=1449
-  _globals['_JOBSETCANCELREQUEST']._serialized_end=1556
-  _globals['_JOBSETFILTER']._serialized_start=1558
-  _globals['_JOBSETFILTER']._serialized_end=1603
-  _globals['_JOB']._serialized_start=1606
-  _globals['_JOB']._serialized_end=2597
+  _globals['_JOBPREEMPTREQUEST']._serialized_start=1345
+  _globals['_JOBPREEMPTREQUEST']._serialized_end=1416
+  _globals['_JOBCANCELREQUEST']._serialized_start=1418
+  _globals['_JOBCANCELREQUEST']._serialized_end=1520
+  _globals['_JOBSETCANCELREQUEST']._serialized_start=1522
+  _globals['_JOBSETCANCELREQUEST']._serialized_end=1629
+  _globals['_JOBSETFILTER']._serialized_start=1631
+  _globals['_JOBSETFILTER']._serialized_end=1676
+  _globals['_JOB']._serialized_start=1679
+  _globals['_JOB']._serialized_end=2670
   _globals['_JOB_LABELSENTRY']._serialized_start=772
   _globals['_JOB_LABELSENTRY']._serialized_end=817
   _globals['_JOB_ANNOTATIONSENTRY']._serialized_start=819
   _globals['_JOB_ANNOTATIONSENTRY']._serialized_end=869
   _globals['_JOB_REQUIREDNODELABELSENTRY']._serialized_start=871
   _globals['_JOB_REQUIREDNODELABELSENTRY']._serialized_end=928
-  _globals['_JOBREPRIORITIZEREQUEST']._serialized_start=2599
-  _globals['_JOBREPRIORITIZEREQUEST']._serialized_end=2697
-  _globals['_JOBREPRIORITIZERESPONSE']._serialized_start=2700
-  _globals['_JOBREPRIORITIZERESPONSE']._serialized_end=2882
-  _globals['_JOBREPRIORITIZERESPONSE_REPRIORITIZATIONRESULTSENTRY']._serialized_start=2820
-  _globals['_JOBREPRIORITIZERESPONSE_REPRIORITIZATIONRESULTSENTRY']._serialized_end=2882
-  _globals['_JOBSUBMITRESPONSEITEM']._serialized_start=2884
-  _globals['_JOBSUBMITRESPONSEITEM']._serialized_end=2938
-  _globals['_JOBSUBMITRESPONSE']._serialized_start=2940
-  _globals['_JOBSUBMITRESPONSE']._serialized_end=3015
-  _globals['_QUEUE']._serialized_start=3018
-  _globals['_QUEUE']._serialized_end=3383
-  _globals['_QUEUE_PERMISSIONS']._serialized_start=3211
-  _globals['_QUEUE_PERMISSIONS']._serialized_end=3328
-  _globals['_QUEUE_PERMISSIONS_SUBJECT']._serialized_start=3291
-  _globals['_QUEUE_PERMISSIONS_SUBJECT']._serialized_end=3328
-  _globals['_QUEUE_RESOURCELIMITSENTRY']._serialized_start=3330
-  _globals['_QUEUE_RESOURCELIMITSENTRY']._serialized_end=3383
-  _globals['_QUEUELIST']._serialized_start=3385
-  _globals['_QUEUELIST']._serialized_end=3424
-  _globals['_CANCELLATIONRESULT']._serialized_start=3426
-  _globals['_CANCELLATIONRESULT']._serialized_end=3487
-  _globals['_QUEUEGETREQUEST']._serialized_start=3489
-  _globals['_QUEUEGETREQUEST']._serialized_end=3520
-  _globals['_STREAMINGQUEUEGETREQUEST']._serialized_start=3522
-  _globals['_STREAMINGQUEUEGETREQUEST']._serialized_end=3561
-  _globals['_QUEUEDELETEREQUEST']._serialized_start=3563
-  _globals['_QUEUEDELETEREQUEST']._serialized_end=3597
-  _globals['_JOBSETINFO']._serialized_start=3599
-  _globals['_JOBSETINFO']._serialized_end=3667
-  _globals['_QUEUEUPDATERESPONSE']._serialized_start=3669
-  _globals['_QUEUEUPDATERESPONSE']._serialized_end=3732
-  _globals['_BATCHQUEUEUPDATERESPONSE']._serialized_start=3734
-  _globals['_BATCHQUEUEUPDATERESPONSE']._serialized_end=3809
-  _globals['_QUEUECREATERESPONSE']._serialized_start=3811
-  _globals['_QUEUECREATERESPONSE']._serialized_end=3874
-  _globals['_BATCHQUEUECREATERESPONSE']._serialized_start=3876
-  _globals['_BATCHQUEUECREATERESPONSE']._serialized_end=3951
-  _globals['_ENDMARKER']._serialized_start=3953
-  _globals['_ENDMARKER']._serialized_end=3964
-  _globals['_STREAMINGQUEUEMESSAGE']._serialized_start=3966
-  _globals['_STREAMINGQUEUEMESSAGE']._serialized_end=4058
-  _globals['_SUBMIT']._serialized_start=4280
-  _globals['_SUBMIT']._serialized_end=5352
+  _globals['_JOBREPRIORITIZEREQUEST']._serialized_start=2672
+  _globals['_JOBREPRIORITIZEREQUEST']._serialized_end=2770
+  _globals['_JOBREPRIORITIZERESPONSE']._serialized_start=2773
+  _globals['_JOBREPRIORITIZERESPONSE']._serialized_end=2955
+  _globals['_JOBREPRIORITIZERESPONSE_REPRIORITIZATIONRESULTSENTRY']._serialized_start=2893
+  _globals['_JOBREPRIORITIZERESPONSE_REPRIORITIZATIONRESULTSENTRY']._serialized_end=2955
+  _globals['_JOBSUBMITRESPONSEITEM']._serialized_start=2957
+  _globals['_JOBSUBMITRESPONSEITEM']._serialized_end=3011
+  _globals['_JOBSUBMITRESPONSE']._serialized_start=3013
+  _globals['_JOBSUBMITRESPONSE']._serialized_end=3088
+  _globals['_QUEUE']._serialized_start=3091
+  _globals['_QUEUE']._serialized_end=3673
+  _globals['_QUEUE_PERMISSIONS']._serialized_start=3393
+  _globals['_QUEUE_PERMISSIONS']._serialized_end=3510
+  _globals['_QUEUE_PERMISSIONS_SUBJECT']._serialized_start=3473
+  _globals['_QUEUE_PERMISSIONS_SUBJECT']._serialized_end=3510
+  _globals['_QUEUE_RESOURCELIMITSENTRY']._serialized_start=3512
+  _globals['_QUEUE_RESOURCELIMITSENTRY']._serialized_end=3565
+  _globals['_QUEUE_RESOURCELIMITSBYPRIORITYCLASSNAMEENTRY']._serialized_start=3567
+  _globals['_QUEUE_RESOURCELIMITSBYPRIORITYCLASSNAMEENTRY']._serialized_end=3673
+  _globals['_PRIORITYCLASSRESOURCELIMITS']._serialized_start=3676
+  _globals['_PRIORITYCLASSRESOURCELIMITS']._serialized_end=4099
+  _globals['_PRIORITYCLASSRESOURCELIMITS_MAXIMUMRESOURCEFRACTIONENTRY']._serialized_start=3929
+  _globals['_PRIORITYCLASSRESOURCELIMITS_MAXIMUMRESOURCEFRACTIONENTRY']._serialized_end=3991
+  _globals['_PRIORITYCLASSRESOURCELIMITS_MAXIMUMRESOURCEFRACTIONBYPOOLENTRY']._serialized_start=3993
+  _globals['_PRIORITYCLASSRESOURCELIMITS_MAXIMUMRESOURCEFRACTIONBYPOOLENTRY']._serialized_end=4099
+  _globals['_PRIORITYCLASSPOOLRESOURCELIMITS']._serialized_start=4102
+  _globals['_PRIORITYCLASSPOOLRESOURCELIMITS']._serialized_end=4307
+  _globals['_PRIORITYCLASSPOOLRESOURCELIMITS_MAXIMUMRESOURCEFRACTIONENTRY']._serialized_start=3929
+  _globals['_PRIORITYCLASSPOOLRESOURCELIMITS_MAXIMUMRESOURCEFRACTIONENTRY']._serialized_end=3991
+  _globals['_QUEUELIST']._serialized_start=4309
+  _globals['_QUEUELIST']._serialized_end=4348
+  _globals['_CANCELLATIONRESULT']._serialized_start=4350
+  _globals['_CANCELLATIONRESULT']._serialized_end=4411
+  _globals['_QUEUEGETREQUEST']._serialized_start=4413
+  _globals['_QUEUEGETREQUEST']._serialized_end=4444
+  _globals['_STREAMINGQUEUEGETREQUEST']._serialized_start=4446
+  _globals['_STREAMINGQUEUEGETREQUEST']._serialized_end=4485
+  _globals['_QUEUEDELETEREQUEST']._serialized_start=4487
+  _globals['_QUEUEDELETEREQUEST']._serialized_end=4521
+  _globals['_JOBSETINFO']._serialized_start=4523
+  _globals['_JOBSETINFO']._serialized_end=4591
+  _globals['_QUEUEUPDATERESPONSE']._serialized_start=4593
+  _globals['_QUEUEUPDATERESPONSE']._serialized_end=4656
+  _globals['_BATCHQUEUEUPDATERESPONSE']._serialized_start=4658
+  _globals['_BATCHQUEUEUPDATERESPONSE']._serialized_end=4733
+  _globals['_QUEUECREATERESPONSE']._serialized_start=4735
+  _globals['_QUEUECREATERESPONSE']._serialized_end=4798
+  _globals['_BATCHQUEUECREATERESPONSE']._serialized_start=4800
+  _globals['_BATCHQUEUECREATERESPONSE']._serialized_end=4875
+  _globals['_ENDMARKER']._serialized_start=4877
+  _globals['_ENDMARKER']._serialized_end=4888
+  _globals['_STREAMINGQUEUEMESSAGE']._serialized_start=4890
+  _globals['_STREAMINGQUEUEMESSAGE']._serialized_end=4982
+  _globals['_SUBMIT']._serialized_start=5204
+  _globals['_SUBMIT']._serialized_end=6367
 # @@protoc_insertion_point(module_scope)
```

## armada_client/armada/submit_pb2.pyi

```diff
@@ -1,11 +1,12 @@
 """
 @generated by mypy-protobuf.  Do not edit manually!
 isort:skip_file
 """
+
 import builtins
 import collections.abc
 import google.protobuf.descriptor
 import google.protobuf.internal.containers
 import google.protobuf.internal.enum_type_wrapper
 import google.protobuf.message
 import google.protobuf.timestamp_pb2
@@ -78,65 +79,65 @@
 UNKNOWN: JobState.ValueType  # 5
 SUBMITTED: JobState.ValueType  # 6
 LEASED: JobState.ValueType  # 7
 PREEMPTED: JobState.ValueType  # 8
 CANCELLED: JobState.ValueType  # 9
 global___JobState = JobState
 
-@typing_extensions.final
+@typing.final
 class JobSubmitRequestItem(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class LabelsEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str = ...,
             value: builtins.str = ...,
         ) -> None: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
-    @typing_extensions.final
+    @typing.final
     class AnnotationsEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str = ...,
             value: builtins.str = ...,
         ) -> None: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
-    @typing_extensions.final
+    @typing.final
     class RequiredNodeLabelsEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str = ...,
             value: builtins.str = ...,
         ) -> None: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     PRIORITY_FIELD_NUMBER: builtins.int
     NAMESPACE_FIELD_NUMBER: builtins.int
     CLIENT_ID_FIELD_NUMBER: builtins.int
     LABELS_FIELD_NUMBER: builtins.int
     ANNOTATIONS_FIELD_NUMBER: builtins.int
     REQUIRED_NODE_LABELS_FIELD_NUMBER: builtins.int
@@ -145,36 +146,38 @@
     INGRESS_FIELD_NUMBER: builtins.int
     SERVICES_FIELD_NUMBER: builtins.int
     SCHEDULER_FIELD_NUMBER: builtins.int
     QUEUE_TTL_SECONDS_FIELD_NUMBER: builtins.int
     priority: builtins.float
     namespace: builtins.str
     client_id: builtins.str
+    scheduler: builtins.str
+    """Indicates which scheduler should manage this job.
+    If empty, the default scheduler is used.
+    """
+    queue_ttl_seconds: builtins.int
+    """Queuing TTL for this job in seconds. If this job queues for more than this duration it will be cancelled. Zero indicates an infinite lifetime."""
     @property
     def labels(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]: ...
     @property
     def annotations(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]: ...
     @property
     def required_node_labels(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]:
         """Use PodSpec.NodeSelector instead"""
+
     @property
     def pod_spec(self) -> k8s.io.api.core.v1.generated_pb2.PodSpec:
         """Use PodSpecs instead"""
+
     @property
     def pod_specs(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[k8s.io.api.core.v1.generated_pb2.PodSpec]: ...
     @property
     def ingress(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___IngressConfig]: ...
     @property
     def services(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ServiceConfig]: ...
-    scheduler: builtins.str
-    """Indicates which scheduler should manage this job.
-    If empty, the default scheduler is used.
-    """
-    queue_ttl_seconds: builtins.int
-    """Queuing TTL for this job in seconds. If this job queues for more than this duration it will be cancelled. Zero indicates an infinite lifetime."""
     def __init__(
         self,
         *,
         priority: builtins.float = ...,
         namespace: builtins.str = ...,
         client_id: builtins.str = ...,
         labels: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
@@ -183,87 +186,87 @@
         pod_spec: k8s.io.api.core.v1.generated_pb2.PodSpec | None = ...,
         pod_specs: collections.abc.Iterable[k8s.io.api.core.v1.generated_pb2.PodSpec] | None = ...,
         ingress: collections.abc.Iterable[global___IngressConfig] | None = ...,
         services: collections.abc.Iterable[global___ServiceConfig] | None = ...,
         scheduler: builtins.str = ...,
         queue_ttl_seconds: builtins.int = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["pod_spec", b"pod_spec"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["annotations", b"annotations", "client_id", b"client_id", "ingress", b"ingress", "labels", b"labels", "namespace", b"namespace", "pod_spec", b"pod_spec", "pod_specs", b"pod_specs", "priority", b"priority", "queue_ttl_seconds", b"queue_ttl_seconds", "required_node_labels", b"required_node_labels", "scheduler", b"scheduler", "services", b"services"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["pod_spec", b"pod_spec"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["annotations", b"annotations", "client_id", b"client_id", "ingress", b"ingress", "labels", b"labels", "namespace", b"namespace", "pod_spec", b"pod_spec", "pod_specs", b"pod_specs", "priority", b"priority", "queue_ttl_seconds", b"queue_ttl_seconds", "required_node_labels", b"required_node_labels", "scheduler", b"scheduler", "services", b"services"]) -> None: ...
 
 global___JobSubmitRequestItem = JobSubmitRequestItem
 
-@typing_extensions.final
+@typing.final
 class IngressConfig(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class AnnotationsEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str = ...,
             value: builtins.str = ...,
         ) -> None: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     TYPE_FIELD_NUMBER: builtins.int
     PORTS_FIELD_NUMBER: builtins.int
     ANNOTATIONS_FIELD_NUMBER: builtins.int
     TLS_ENABLED_FIELD_NUMBER: builtins.int
     CERT_NAME_FIELD_NUMBER: builtins.int
     USE_CLUSTERIP_FIELD_NUMBER: builtins.int
     type: global___IngressType.ValueType
+    tls_enabled: builtins.bool
+    cert_name: builtins.str
+    use_clusterIP: builtins.bool
     @property
     def ports(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.int]: ...
     @property
     def annotations(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]: ...
-    tls_enabled: builtins.bool
-    cert_name: builtins.str
-    use_clusterIP: builtins.bool
     def __init__(
         self,
         *,
         type: global___IngressType.ValueType = ...,
         ports: collections.abc.Iterable[builtins.int] | None = ...,
         annotations: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
         tls_enabled: builtins.bool = ...,
         cert_name: builtins.str = ...,
         use_clusterIP: builtins.bool = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["annotations", b"annotations", "cert_name", b"cert_name", "ports", b"ports", "tls_enabled", b"tls_enabled", "type", b"type", "use_clusterIP", b"use_clusterIP"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["annotations", b"annotations", "cert_name", b"cert_name", "ports", b"ports", "tls_enabled", b"tls_enabled", "type", b"type", "use_clusterIP", b"use_clusterIP"]) -> None: ...
 
 global___IngressConfig = IngressConfig
 
-@typing_extensions.final
+@typing.final
 class ServiceConfig(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     TYPE_FIELD_NUMBER: builtins.int
     PORTS_FIELD_NUMBER: builtins.int
     type: global___ServiceType.ValueType
     @property
     def ports(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.int]: ...
     def __init__(
         self,
         *,
         type: global___ServiceType.ValueType = ...,
         ports: collections.abc.Iterable[builtins.int] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["ports", b"ports", "type", b"type"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["ports", b"ports", "type", b"type"]) -> None: ...
 
 global___ServiceConfig = ServiceConfig
 
-@typing_extensions.final
+@typing.final
 class JobSubmitRequest(google.protobuf.message.Message):
     """swagger:model"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     QUEUE_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
@@ -275,145 +278,169 @@
     def __init__(
         self,
         *,
         queue: builtins.str = ...,
         job_set_id: builtins.str = ...,
         job_request_items: collections.abc.Iterable[global___JobSubmitRequestItem] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["job_request_items", b"job_request_items", "job_set_id", b"job_set_id", "queue", b"queue"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["job_request_items", b"job_request_items", "job_set_id", b"job_set_id", "queue", b"queue"]) -> None: ...
 
 global___JobSubmitRequest = JobSubmitRequest
 
-@typing_extensions.final
+@typing.final
+class JobPreemptRequest(google.protobuf.message.Message):
+    """swagger:model"""
+
+    DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+    QUEUE_FIELD_NUMBER: builtins.int
+    JOB_SET_ID_FIELD_NUMBER: builtins.int
+    JOB_IDS_FIELD_NUMBER: builtins.int
+    queue: builtins.str
+    job_set_id: builtins.str
+    @property
+    def job_ids(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]: ...
+    def __init__(
+        self,
+        *,
+        queue: builtins.str = ...,
+        job_set_id: builtins.str = ...,
+        job_ids: collections.abc.Iterable[builtins.str] | None = ...,
+    ) -> None: ...
+    def ClearField(self, field_name: typing.Literal["job_ids", b"job_ids", "job_set_id", b"job_set_id", "queue", b"queue"]) -> None: ...
+
+global___JobPreemptRequest = JobPreemptRequest
+
+@typing.final
 class JobCancelRequest(google.protobuf.message.Message):
     """swagger:model"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     JOB_IDS_FIELD_NUMBER: builtins.int
     REASON_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     job_set_id: builtins.str
     queue: builtins.str
+    reason: builtins.str
     @property
     def job_ids(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]: ...
-    reason: builtins.str
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         job_ids: collections.abc.Iterable[builtins.str] | None = ...,
         reason: builtins.str = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["job_id", b"job_id", "job_ids", b"job_ids", "job_set_id", b"job_set_id", "queue", b"queue", "reason", b"reason"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["job_id", b"job_id", "job_ids", b"job_ids", "job_set_id", b"job_set_id", "queue", b"queue", "reason", b"reason"]) -> None: ...
 
 global___JobCancelRequest = JobCancelRequest
 
-@typing_extensions.final
+@typing.final
 class JobSetCancelRequest(google.protobuf.message.Message):
     """swagger:model"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     FILTER_FIELD_NUMBER: builtins.int
     REASON_FIELD_NUMBER: builtins.int
     job_set_id: builtins.str
     queue: builtins.str
+    reason: builtins.str
     @property
     def filter(self) -> global___JobSetFilter: ...
-    reason: builtins.str
     def __init__(
         self,
         *,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         filter: global___JobSetFilter | None = ...,
         reason: builtins.str = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["filter", b"filter"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["filter", b"filter", "job_set_id", b"job_set_id", "queue", b"queue", "reason", b"reason"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["filter", b"filter"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["filter", b"filter", "job_set_id", b"job_set_id", "queue", b"queue", "reason", b"reason"]) -> None: ...
 
 global___JobSetCancelRequest = JobSetCancelRequest
 
-@typing_extensions.final
+@typing.final
 class JobSetFilter(google.protobuf.message.Message):
     """swagger:model"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     STATES_FIELD_NUMBER: builtins.int
     @property
     def states(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[global___JobState.ValueType]: ...
     def __init__(
         self,
         *,
         states: collections.abc.Iterable[global___JobState.ValueType] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["states", b"states"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["states", b"states"]) -> None: ...
 
 global___JobSetFilter = JobSetFilter
 
-@typing_extensions.final
+@typing.final
 class Job(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class LabelsEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str = ...,
             value: builtins.str = ...,
         ) -> None: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
-    @typing_extensions.final
+    @typing.final
     class AnnotationsEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str = ...,
             value: builtins.str = ...,
         ) -> None: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
-    @typing_extensions.final
+    @typing.final
     class RequiredNodeLabelsEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str = ...,
             value: builtins.str = ...,
         ) -> None: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     ID_FIELD_NUMBER: builtins.int
     CLIENT_ID_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     NAMESPACE_FIELD_NUMBER: builtins.int
     LABELS_FIELD_NUMBER: builtins.int
@@ -434,28 +461,35 @@
     SCHEDULER_FIELD_NUMBER: builtins.int
     QUEUE_TTL_SECONDS_FIELD_NUMBER: builtins.int
     id: builtins.str
     client_id: builtins.str
     job_set_id: builtins.str
     queue: builtins.str
     namespace: builtins.str
+    owner: builtins.str
+    compressed_queue_ownership_user_groups: builtins.bytes
+    priority: builtins.float
+    scheduler: builtins.str
+    """Indicates which scheduler should manage this job.
+    If empty, the default scheduler is used.
+    """
+    queue_ttl_seconds: builtins.int
+    """Queuing TTL for this job in seconds. If this job queues for more than this duration it will be cancelled. Zero indicates an infinite lifetime."""
     @property
     def labels(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]: ...
     @property
     def annotations(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]: ...
     @property
     def required_node_labels(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]: ...
-    owner: builtins.str
     @property
     def queue_ownership_user_groups(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]: ...
-    compressed_queue_ownership_user_groups: builtins.bytes
-    priority: builtins.float
     @property
     def pod_spec(self) -> k8s.io.api.core.v1.generated_pb2.PodSpec:
         """Use PodSpecs instead"""
+
     @property
     def pod_specs(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[k8s.io.api.core.v1.generated_pb2.PodSpec]: ...
     @property
     def scheduling_resource_requirements(self) -> k8s.io.api.core.v1.generated_pb2.ResourceRequirements:
         """Resource requests and limits necessary for scheduling the main pod of this job.
         The requests and limits herein are set to:
 
@@ -466,34 +500,30 @@
 
         )
 
         This is because containers run in parallel, whereas initContainers run serially.
         This field is populated automatically at submission.
         Submitting a job with this field already populated results in an error.
         """
+
     @property
     def created(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     @property
     def ingress(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___IngressConfig]:
         """Services can be provided either as Armada-specific config objects or as proper k8s objects.
         These options are exclusive, i.e., if either ingress or services is provided,
         then neither of k8s_ingress or k8s_service can be provided, and vice versa.
         """
+
     @property
     def services(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ServiceConfig]: ...
     @property
     def k8s_ingress(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[k8s.io.api.networking.v1.generated_pb2.Ingress]: ...
     @property
     def k8s_service(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[k8s.io.api.core.v1.generated_pb2.Service]: ...
-    scheduler: builtins.str
-    """Indicates which scheduler should manage this job.
-    If empty, the default scheduler is used.
-    """
-    queue_ttl_seconds: builtins.int
-    """Queuing TTL for this job in seconds. If this job queues for more than this duration it will be cancelled. Zero indicates an infinite lifetime."""
     def __init__(
         self,
         *,
         id: builtins.str = ...,
         client_id: builtins.str = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
@@ -512,290 +542,410 @@
         ingress: collections.abc.Iterable[global___IngressConfig] | None = ...,
         services: collections.abc.Iterable[global___ServiceConfig] | None = ...,
         k8s_ingress: collections.abc.Iterable[k8s.io.api.networking.v1.generated_pb2.Ingress] | None = ...,
         k8s_service: collections.abc.Iterable[k8s.io.api.core.v1.generated_pb2.Service] | None = ...,
         scheduler: builtins.str = ...,
         queue_ttl_seconds: builtins.int = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["created", b"created", "pod_spec", b"pod_spec", "scheduling_resource_requirements", b"scheduling_resource_requirements"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["annotations", b"annotations", "client_id", b"client_id", "compressed_queue_ownership_user_groups", b"compressed_queue_ownership_user_groups", "created", b"created", "id", b"id", "ingress", b"ingress", "job_set_id", b"job_set_id", "k8s_ingress", b"k8s_ingress", "k8s_service", b"k8s_service", "labels", b"labels", "namespace", b"namespace", "owner", b"owner", "pod_spec", b"pod_spec", "pod_specs", b"pod_specs", "priority", b"priority", "queue", b"queue", "queue_ownership_user_groups", b"queue_ownership_user_groups", "queue_ttl_seconds", b"queue_ttl_seconds", "required_node_labels", b"required_node_labels", "scheduler", b"scheduler", "scheduling_resource_requirements", b"scheduling_resource_requirements", "services", b"services"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["created", b"created", "pod_spec", b"pod_spec", "scheduling_resource_requirements", b"scheduling_resource_requirements"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["annotations", b"annotations", "client_id", b"client_id", "compressed_queue_ownership_user_groups", b"compressed_queue_ownership_user_groups", "created", b"created", "id", b"id", "ingress", b"ingress", "job_set_id", b"job_set_id", "k8s_ingress", b"k8s_ingress", "k8s_service", b"k8s_service", "labels", b"labels", "namespace", b"namespace", "owner", b"owner", "pod_spec", b"pod_spec", "pod_specs", b"pod_specs", "priority", b"priority", "queue", b"queue", "queue_ownership_user_groups", b"queue_ownership_user_groups", "queue_ttl_seconds", b"queue_ttl_seconds", "required_node_labels", b"required_node_labels", "scheduler", b"scheduler", "scheduling_resource_requirements", b"scheduling_resource_requirements", "services", b"services"]) -> None: ...
 
 global___Job = Job
 
-@typing_extensions.final
+@typing.final
 class JobReprioritizeRequest(google.protobuf.message.Message):
     """swagger:model"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_IDS_FIELD_NUMBER: builtins.int
     JOB_SET_ID_FIELD_NUMBER: builtins.int
     QUEUE_FIELD_NUMBER: builtins.int
     NEW_PRIORITY_FIELD_NUMBER: builtins.int
-    @property
-    def job_ids(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]: ...
     job_set_id: builtins.str
     queue: builtins.str
     new_priority: builtins.float
+    @property
+    def job_ids(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]: ...
     def __init__(
         self,
         *,
         job_ids: collections.abc.Iterable[builtins.str] | None = ...,
         job_set_id: builtins.str = ...,
         queue: builtins.str = ...,
         new_priority: builtins.float = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["job_ids", b"job_ids", "job_set_id", b"job_set_id", "new_priority", b"new_priority", "queue", b"queue"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["job_ids", b"job_ids", "job_set_id", b"job_set_id", "new_priority", b"new_priority", "queue", b"queue"]) -> None: ...
 
 global___JobReprioritizeRequest = JobReprioritizeRequest
 
-@typing_extensions.final
+@typing.final
 class JobReprioritizeResponse(google.protobuf.message.Message):
     """swagger:model"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class ReprioritizationResultsEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str = ...,
             value: builtins.str = ...,
         ) -> None: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     REPRIORITIZATION_RESULTS_FIELD_NUMBER: builtins.int
     @property
     def reprioritization_results(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]: ...
     def __init__(
         self,
         *,
         reprioritization_results: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["reprioritization_results", b"reprioritization_results"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["reprioritization_results", b"reprioritization_results"]) -> None: ...
 
 global___JobReprioritizeResponse = JobReprioritizeResponse
 
-@typing_extensions.final
+@typing.final
 class JobSubmitResponseItem(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_ID_FIELD_NUMBER: builtins.int
     ERROR_FIELD_NUMBER: builtins.int
     job_id: builtins.str
     error: builtins.str
     def __init__(
         self,
         *,
         job_id: builtins.str = ...,
         error: builtins.str = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["error", b"error", "job_id", b"job_id"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["error", b"error", "job_id", b"job_id"]) -> None: ...
 
 global___JobSubmitResponseItem = JobSubmitResponseItem
 
-@typing_extensions.final
+@typing.final
 class JobSubmitResponse(google.protobuf.message.Message):
     """swagger:model"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     JOB_RESPONSE_ITEMS_FIELD_NUMBER: builtins.int
     @property
     def job_response_items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___JobSubmitResponseItem]: ...
     def __init__(
         self,
         *,
         job_response_items: collections.abc.Iterable[global___JobSubmitResponseItem] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["job_response_items", b"job_response_items"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["job_response_items", b"job_response_items"]) -> None: ...
 
 global___JobSubmitResponse = JobSubmitResponse
 
-@typing_extensions.final
+@typing.final
 class Queue(google.protobuf.message.Message):
     """swagger:model"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class Permissions(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-        @typing_extensions.final
+        @typing.final
         class Subject(google.protobuf.message.Message):
             DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
             KIND_FIELD_NUMBER: builtins.int
             NAME_FIELD_NUMBER: builtins.int
             kind: builtins.str
             name: builtins.str
             def __init__(
                 self,
                 *,
                 kind: builtins.str = ...,
                 name: builtins.str = ...,
             ) -> None: ...
-            def ClearField(self, field_name: typing_extensions.Literal["kind", b"kind", "name", b"name"]) -> None: ...
+            def ClearField(self, field_name: typing.Literal["kind", b"kind", "name", b"name"]) -> None: ...
 
         SUBJECTS_FIELD_NUMBER: builtins.int
         VERBS_FIELD_NUMBER: builtins.int
         @property
         def subjects(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Queue.Permissions.Subject]: ...
         @property
         def verbs(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]: ...
         def __init__(
             self,
             *,
             subjects: collections.abc.Iterable[global___Queue.Permissions.Subject] | None = ...,
             verbs: collections.abc.Iterable[builtins.str] | None = ...,
         ) -> None: ...
-        def ClearField(self, field_name: typing_extensions.Literal["subjects", b"subjects", "verbs", b"verbs"]) -> None: ...
+        def ClearField(self, field_name: typing.Literal["subjects", b"subjects", "verbs", b"verbs"]) -> None: ...
 
-    @typing_extensions.final
+    @typing.final
     class ResourceLimitsEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.float
         def __init__(
             self,
             *,
             key: builtins.str = ...,
             value: builtins.float = ...,
         ) -> None: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
+
+    @typing.final
+    class ResourceLimitsByPriorityClassNameEntry(google.protobuf.message.Message):
+        DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+        KEY_FIELD_NUMBER: builtins.int
+        VALUE_FIELD_NUMBER: builtins.int
+        key: builtins.str
+        @property
+        def value(self) -> global___PriorityClassResourceLimits: ...
+        def __init__(
+            self,
+            *,
+            key: builtins.str = ...,
+            value: global___PriorityClassResourceLimits | None = ...,
+        ) -> None: ...
+        def HasField(self, field_name: typing.Literal["value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     NAME_FIELD_NUMBER: builtins.int
     PRIORITY_FACTOR_FIELD_NUMBER: builtins.int
     USER_OWNERS_FIELD_NUMBER: builtins.int
     GROUP_OWNERS_FIELD_NUMBER: builtins.int
     RESOURCE_LIMITS_FIELD_NUMBER: builtins.int
+    RESOURCE_LIMITS_BY_PRIORITY_CLASS_NAME_FIELD_NUMBER: builtins.int
     PERMISSIONS_FIELD_NUMBER: builtins.int
     name: builtins.str
     priority_factor: builtins.float
     @property
     def user_owners(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]: ...
     @property
     def group_owners(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]: ...
     @property
     def resource_limits(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.float]: ...
     @property
+    def resource_limits_by_priority_class_name(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, global___PriorityClassResourceLimits]:
+        """Map from priority class name to resource limit overrides for this queue and priority class.
+        If provided for a priority class, global limits for that priority class do not apply to this queue.
+        """
+
+    @property
     def permissions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Queue.Permissions]: ...
     def __init__(
         self,
         *,
         name: builtins.str = ...,
         priority_factor: builtins.float = ...,
         user_owners: collections.abc.Iterable[builtins.str] | None = ...,
         group_owners: collections.abc.Iterable[builtins.str] | None = ...,
         resource_limits: collections.abc.Mapping[builtins.str, builtins.float] | None = ...,
+        resource_limits_by_priority_class_name: collections.abc.Mapping[builtins.str, global___PriorityClassResourceLimits] | None = ...,
         permissions: collections.abc.Iterable[global___Queue.Permissions] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["group_owners", b"group_owners", "name", b"name", "permissions", b"permissions", "priority_factor", b"priority_factor", "resource_limits", b"resource_limits", "user_owners", b"user_owners"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["group_owners", b"group_owners", "name", b"name", "permissions", b"permissions", "priority_factor", b"priority_factor", "resource_limits", b"resource_limits", "resource_limits_by_priority_class_name", b"resource_limits_by_priority_class_name", "user_owners", b"user_owners"]) -> None: ...
 
 global___Queue = Queue
 
-@typing_extensions.final
+@typing.final
+class PriorityClassResourceLimits(google.protobuf.message.Message):
+    DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+    @typing.final
+    class MaximumResourceFractionEntry(google.protobuf.message.Message):
+        DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+        KEY_FIELD_NUMBER: builtins.int
+        VALUE_FIELD_NUMBER: builtins.int
+        key: builtins.str
+        value: builtins.float
+        def __init__(
+            self,
+            *,
+            key: builtins.str = ...,
+            value: builtins.float = ...,
+        ) -> None: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
+
+    @typing.final
+    class MaximumResourceFractionByPoolEntry(google.protobuf.message.Message):
+        DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+        KEY_FIELD_NUMBER: builtins.int
+        VALUE_FIELD_NUMBER: builtins.int
+        key: builtins.str
+        @property
+        def value(self) -> global___PriorityClassPoolResourceLimits: ...
+        def __init__(
+            self,
+            *,
+            key: builtins.str = ...,
+            value: global___PriorityClassPoolResourceLimits | None = ...,
+        ) -> None: ...
+        def HasField(self, field_name: typing.Literal["value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
+
+    MAXIMUM_RESOURCE_FRACTION_FIELD_NUMBER: builtins.int
+    MAXIMUM_RESOURCE_FRACTION_BY_POOL_FIELD_NUMBER: builtins.int
+    @property
+    def maximum_resource_fraction(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.float]:
+        """Limits resources assigned to jobs of this priority class.
+        Specifically, jobs of this priority class are only scheduled if doing so does not exceed this limit.
+        """
+
+    @property
+    def maximum_resource_fraction_by_pool(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, global___PriorityClassPoolResourceLimits]:
+        """Per-pool override of maximum_resource_fraction.
+        If missing for a particular pool, maximum_resource_fraction is used instead for that pool.
+        """
+
+    def __init__(
+        self,
+        *,
+        maximum_resource_fraction: collections.abc.Mapping[builtins.str, builtins.float] | None = ...,
+        maximum_resource_fraction_by_pool: collections.abc.Mapping[builtins.str, global___PriorityClassPoolResourceLimits] | None = ...,
+    ) -> None: ...
+    def ClearField(self, field_name: typing.Literal["maximum_resource_fraction", b"maximum_resource_fraction", "maximum_resource_fraction_by_pool", b"maximum_resource_fraction_by_pool"]) -> None: ...
+
+global___PriorityClassResourceLimits = PriorityClassResourceLimits
+
+@typing.final
+class PriorityClassPoolResourceLimits(google.protobuf.message.Message):
+    DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+    @typing.final
+    class MaximumResourceFractionEntry(google.protobuf.message.Message):
+        DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+        KEY_FIELD_NUMBER: builtins.int
+        VALUE_FIELD_NUMBER: builtins.int
+        key: builtins.str
+        value: builtins.float
+        def __init__(
+            self,
+            *,
+            key: builtins.str = ...,
+            value: builtins.float = ...,
+        ) -> None: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
+
+    MAXIMUM_RESOURCE_FRACTION_FIELD_NUMBER: builtins.int
+    @property
+    def maximum_resource_fraction(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.float]: ...
+    def __init__(
+        self,
+        *,
+        maximum_resource_fraction: collections.abc.Mapping[builtins.str, builtins.float] | None = ...,
+    ) -> None: ...
+    def ClearField(self, field_name: typing.Literal["maximum_resource_fraction", b"maximum_resource_fraction"]) -> None: ...
+
+global___PriorityClassPoolResourceLimits = PriorityClassPoolResourceLimits
+
+@typing.final
 class QueueList(google.protobuf.message.Message):
     """swagger:model"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     QUEUES_FIELD_NUMBER: builtins.int
     @property
     def queues(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Queue]: ...
     def __init__(
         self,
         *,
         queues: collections.abc.Iterable[global___Queue] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["queues", b"queues"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["queues", b"queues"]) -> None: ...
 
 global___QueueList = QueueList
 
-@typing_extensions.final
+@typing.final
 class CancellationResult(google.protobuf.message.Message):
     """swagger:model"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     CANCELLED_IDS_FIELD_NUMBER: builtins.int
     @property
     def cancelled_ids(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]: ...
     def __init__(
         self,
         *,
         cancelled_ids: collections.abc.Iterable[builtins.str] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["cancelled_ids", b"cancelled_ids"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["cancelled_ids", b"cancelled_ids"]) -> None: ...
 
 global___CancellationResult = CancellationResult
 
-@typing_extensions.final
+@typing.final
 class QueueGetRequest(google.protobuf.message.Message):
     """swagger:model"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     name: builtins.str
     def __init__(
         self,
         *,
         name: builtins.str = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["name", b"name"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["name", b"name"]) -> None: ...
 
 global___QueueGetRequest = QueueGetRequest
 
-@typing_extensions.final
+@typing.final
 class StreamingQueueGetRequest(google.protobuf.message.Message):
     """swagger:model"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NUM_FIELD_NUMBER: builtins.int
     num: builtins.int
     def __init__(
         self,
         *,
         num: builtins.int = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["num", b"num"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["num", b"num"]) -> None: ...
 
 global___StreamingQueueGetRequest = StreamingQueueGetRequest
 
-@typing_extensions.final
+@typing.final
 class QueueDeleteRequest(google.protobuf.message.Message):
     """swagger:model"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     name: builtins.str
     def __init__(
         self,
         *,
         name: builtins.str = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["name", b"name"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["name", b"name"]) -> None: ...
 
 global___QueueDeleteRequest = QueueDeleteRequest
 
-@typing_extensions.final
+@typing.final
 class JobSetInfo(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     QUEUED_JOBS_FIELD_NUMBER: builtins.int
     LEASED_JOBS_FIELD_NUMBER: builtins.int
     name: builtins.str
@@ -804,103 +954,103 @@
     def __init__(
         self,
         *,
         name: builtins.str = ...,
         queued_jobs: builtins.int = ...,
         leased_jobs: builtins.int = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["leased_jobs", b"leased_jobs", "name", b"name", "queued_jobs", b"queued_jobs"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["leased_jobs", b"leased_jobs", "name", b"name", "queued_jobs", b"queued_jobs"]) -> None: ...
 
 global___JobSetInfo = JobSetInfo
 
-@typing_extensions.final
+@typing.final
 class QueueUpdateResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     QUEUE_FIELD_NUMBER: builtins.int
     ERROR_FIELD_NUMBER: builtins.int
+    error: builtins.str
     @property
     def queue(self) -> global___Queue: ...
-    error: builtins.str
     def __init__(
         self,
         *,
         queue: global___Queue | None = ...,
         error: builtins.str = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["queue", b"queue"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["error", b"error", "queue", b"queue"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["queue", b"queue"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["error", b"error", "queue", b"queue"]) -> None: ...
 
 global___QueueUpdateResponse = QueueUpdateResponse
 
-@typing_extensions.final
+@typing.final
 class BatchQueueUpdateResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     FAILED_QUEUES_FIELD_NUMBER: builtins.int
     @property
     def failed_queues(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___QueueUpdateResponse]: ...
     def __init__(
         self,
         *,
         failed_queues: collections.abc.Iterable[global___QueueUpdateResponse] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["failed_queues", b"failed_queues"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["failed_queues", b"failed_queues"]) -> None: ...
 
 global___BatchQueueUpdateResponse = BatchQueueUpdateResponse
 
-@typing_extensions.final
+@typing.final
 class QueueCreateResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     QUEUE_FIELD_NUMBER: builtins.int
     ERROR_FIELD_NUMBER: builtins.int
+    error: builtins.str
     @property
     def queue(self) -> global___Queue: ...
-    error: builtins.str
     def __init__(
         self,
         *,
         queue: global___Queue | None = ...,
         error: builtins.str = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["queue", b"queue"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["error", b"error", "queue", b"queue"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["queue", b"queue"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["error", b"error", "queue", b"queue"]) -> None: ...
 
 global___QueueCreateResponse = QueueCreateResponse
 
-@typing_extensions.final
+@typing.final
 class BatchQueueCreateResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     FAILED_QUEUES_FIELD_NUMBER: builtins.int
     @property
     def failed_queues(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___QueueCreateResponse]: ...
     def __init__(
         self,
         *,
         failed_queues: collections.abc.Iterable[global___QueueCreateResponse] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["failed_queues", b"failed_queues"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["failed_queues", b"failed_queues"]) -> None: ...
 
 global___BatchQueueCreateResponse = BatchQueueCreateResponse
 
-@typing_extensions.final
+@typing.final
 class EndMarker(google.protobuf.message.Message):
     """Indicates the end of streams"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     def __init__(
         self,
     ) -> None: ...
 
 global___EndMarker = EndMarker
 
-@typing_extensions.final
+@typing.final
 class StreamingQueueMessage(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     QUEUE_FIELD_NUMBER: builtins.int
     END_FIELD_NUMBER: builtins.int
     @property
     def queue(self) -> global___Queue: ...
@@ -908,12 +1058,12 @@
     def end(self) -> global___EndMarker: ...
     def __init__(
         self,
         *,
         queue: global___Queue | None = ...,
         end: global___EndMarker | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["end", b"end", "event", b"event", "queue", b"queue"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["end", b"end", "event", b"event", "queue", b"queue"]) -> None: ...
-    def WhichOneof(self, oneof_group: typing_extensions.Literal["event", b"event"]) -> typing_extensions.Literal["queue", "end"] | None: ...
+    def HasField(self, field_name: typing.Literal["end", b"end", "event", b"event", "queue", b"queue"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["end", b"end", "event", b"event", "queue", b"queue"]) -> None: ...
+    def WhichOneof(self, oneof_group: typing.Literal["event", b"event"]) -> typing.Literal["queue", "end"] | None: ...
 
 global___StreamingQueueMessage = StreamingQueueMessage
```

## armada_client/armada/submit_pb2_grpc.py

```diff
@@ -1,85 +1,115 @@
 # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
 """Client and server classes corresponding to protobuf-defined services."""
 import grpc
+import warnings
 
 from armada_client.armada import health_pb2 as armada_dot_health__pb2
 from armada_client.armada import submit_pb2 as armada_dot_submit__pb2
 from google.protobuf import empty_pb2 as google_dot_protobuf_dot_empty__pb2
 
+GRPC_GENERATED_VERSION = '1.64.0'
+GRPC_VERSION = grpc.__version__
+EXPECTED_ERROR_RELEASE = '1.65.0'
+SCHEDULED_RELEASE_DATE = 'June 25, 2024'
+_version_not_supported = False
+
+try:
+    from grpc._utilities import first_version_is_lower
+    _version_not_supported = first_version_is_lower(GRPC_VERSION, GRPC_GENERATED_VERSION)
+except ImportError:
+    _version_not_supported = True
+
+if _version_not_supported:
+    warnings.warn(
+        f'The grpc package installed is at version {GRPC_VERSION},'
+        + f' but the generated code in armada/submit_pb2_grpc.py depends on'
+        + f' grpcio>={GRPC_GENERATED_VERSION}.'
+        + f' Please upgrade your grpc module to grpcio>={GRPC_GENERATED_VERSION}'
+        + f' or downgrade your generated code using grpcio-tools<={GRPC_VERSION}.'
+        + f' This warning will become an error in {EXPECTED_ERROR_RELEASE},'
+        + f' scheduled for release on {SCHEDULED_RELEASE_DATE}.',
+        RuntimeWarning
+    )
+
 
 class SubmitStub(object):
     """Missing associated documentation comment in .proto file."""
 
     def __init__(self, channel):
         """Constructor.
 
         Args:
             channel: A grpc.Channel.
         """
         self.SubmitJobs = channel.unary_unary(
                 '/api.Submit/SubmitJobs',
                 request_serializer=armada_dot_submit__pb2.JobSubmitRequest.SerializeToString,
                 response_deserializer=armada_dot_submit__pb2.JobSubmitResponse.FromString,
-                )
+                _registered_method=True)
         self.CancelJobs = channel.unary_unary(
                 '/api.Submit/CancelJobs',
                 request_serializer=armada_dot_submit__pb2.JobCancelRequest.SerializeToString,
                 response_deserializer=armada_dot_submit__pb2.CancellationResult.FromString,
-                )
+                _registered_method=True)
         self.CancelJobSet = channel.unary_unary(
                 '/api.Submit/CancelJobSet',
                 request_serializer=armada_dot_submit__pb2.JobSetCancelRequest.SerializeToString,
                 response_deserializer=google_dot_protobuf_dot_empty__pb2.Empty.FromString,
-                )
+                _registered_method=True)
         self.ReprioritizeJobs = channel.unary_unary(
                 '/api.Submit/ReprioritizeJobs',
                 request_serializer=armada_dot_submit__pb2.JobReprioritizeRequest.SerializeToString,
                 response_deserializer=armada_dot_submit__pb2.JobReprioritizeResponse.FromString,
-                )
+                _registered_method=True)
+        self.PreemptJobs = channel.unary_unary(
+                '/api.Submit/PreemptJobs',
+                request_serializer=armada_dot_submit__pb2.JobPreemptRequest.SerializeToString,
+                response_deserializer=google_dot_protobuf_dot_empty__pb2.Empty.FromString,
+                _registered_method=True)
         self.CreateQueue = channel.unary_unary(
                 '/api.Submit/CreateQueue',
                 request_serializer=armada_dot_submit__pb2.Queue.SerializeToString,
                 response_deserializer=google_dot_protobuf_dot_empty__pb2.Empty.FromString,
-                )
+                _registered_method=True)
         self.CreateQueues = channel.unary_unary(
                 '/api.Submit/CreateQueues',
                 request_serializer=armada_dot_submit__pb2.QueueList.SerializeToString,
                 response_deserializer=armada_dot_submit__pb2.BatchQueueCreateResponse.FromString,
-                )
+                _registered_method=True)
         self.UpdateQueue = channel.unary_unary(
                 '/api.Submit/UpdateQueue',
                 request_serializer=armada_dot_submit__pb2.Queue.SerializeToString,
                 response_deserializer=google_dot_protobuf_dot_empty__pb2.Empty.FromString,
-                )
+                _registered_method=True)
         self.UpdateQueues = channel.unary_unary(
                 '/api.Submit/UpdateQueues',
                 request_serializer=armada_dot_submit__pb2.QueueList.SerializeToString,
                 response_deserializer=armada_dot_submit__pb2.BatchQueueUpdateResponse.FromString,
-                )
+                _registered_method=True)
         self.DeleteQueue = channel.unary_unary(
                 '/api.Submit/DeleteQueue',
                 request_serializer=armada_dot_submit__pb2.QueueDeleteRequest.SerializeToString,
                 response_deserializer=google_dot_protobuf_dot_empty__pb2.Empty.FromString,
-                )
+                _registered_method=True)
         self.GetQueue = channel.unary_unary(
                 '/api.Submit/GetQueue',
                 request_serializer=armada_dot_submit__pb2.QueueGetRequest.SerializeToString,
                 response_deserializer=armada_dot_submit__pb2.Queue.FromString,
-                )
+                _registered_method=True)
         self.GetQueues = channel.unary_stream(
                 '/api.Submit/GetQueues',
                 request_serializer=armada_dot_submit__pb2.StreamingQueueGetRequest.SerializeToString,
                 response_deserializer=armada_dot_submit__pb2.StreamingQueueMessage.FromString,
-                )
+                _registered_method=True)
         self.Health = channel.unary_unary(
                 '/api.Submit/Health',
                 request_serializer=google_dot_protobuf_dot_empty__pb2.Empty.SerializeToString,
                 response_deserializer=armada_dot_health__pb2.HealthCheckResponse.FromString,
-                )
+                _registered_method=True)
 
 
 class SubmitServicer(object):
     """Missing associated documentation comment in .proto file."""
 
     def SubmitJobs(self, request, context):
         """Missing associated documentation comment in .proto file."""
@@ -101,14 +131,20 @@
 
     def ReprioritizeJobs(self, request, context):
         """Missing associated documentation comment in .proto file."""
         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
         context.set_details('Method not implemented!')
         raise NotImplementedError('Method not implemented!')
 
+    def PreemptJobs(self, request, context):
+        """Missing associated documentation comment in .proto file."""
+        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
+        context.set_details('Method not implemented!')
+        raise NotImplementedError('Method not implemented!')
+
     def CreateQueue(self, request, context):
         """Missing associated documentation comment in .proto file."""
         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
         context.set_details('Method not implemented!')
         raise NotImplementedError('Method not implemented!')
 
     def CreateQueues(self, request, context):
@@ -172,14 +208,19 @@
                     response_serializer=google_dot_protobuf_dot_empty__pb2.Empty.SerializeToString,
             ),
             'ReprioritizeJobs': grpc.unary_unary_rpc_method_handler(
                     servicer.ReprioritizeJobs,
                     request_deserializer=armada_dot_submit__pb2.JobReprioritizeRequest.FromString,
                     response_serializer=armada_dot_submit__pb2.JobReprioritizeResponse.SerializeToString,
             ),
+            'PreemptJobs': grpc.unary_unary_rpc_method_handler(
+                    servicer.PreemptJobs,
+                    request_deserializer=armada_dot_submit__pb2.JobPreemptRequest.FromString,
+                    response_serializer=google_dot_protobuf_dot_empty__pb2.Empty.SerializeToString,
+            ),
             'CreateQueue': grpc.unary_unary_rpc_method_handler(
                     servicer.CreateQueue,
                     request_deserializer=armada_dot_submit__pb2.Queue.FromString,
                     response_serializer=google_dot_protobuf_dot_empty__pb2.Empty.SerializeToString,
             ),
             'CreateQueues': grpc.unary_unary_rpc_method_handler(
                     servicer.CreateQueues,
@@ -216,14 +257,15 @@
                     request_deserializer=google_dot_protobuf_dot_empty__pb2.Empty.FromString,
                     response_serializer=armada_dot_health__pb2.HealthCheckResponse.SerializeToString,
             ),
     }
     generic_handler = grpc.method_handlers_generic_handler(
             'api.Submit', rpc_method_handlers)
     server.add_generic_rpc_handlers((generic_handler,))
+    server.add_registered_method_handlers('api.Submit', rpc_method_handlers)
 
 
  # This class is part of an EXPERIMENTAL API.
 class Submit(object):
     """Missing associated documentation comment in .proto file."""
 
     @staticmethod
@@ -233,199 +275,346 @@
             channel_credentials=None,
             call_credentials=None,
             insecure=False,
             compression=None,
             wait_for_ready=None,
             timeout=None,
             metadata=None):
-        return grpc.experimental.unary_unary(request, target, '/api.Submit/SubmitJobs',
+        return grpc.experimental.unary_unary(
+            request,
+            target,
+            '/api.Submit/SubmitJobs',
             armada_dot_submit__pb2.JobSubmitRequest.SerializeToString,
             armada_dot_submit__pb2.JobSubmitResponse.FromString,
-            options, channel_credentials,
-            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
 
     @staticmethod
     def CancelJobs(request,
             target,
             options=(),
             channel_credentials=None,
             call_credentials=None,
             insecure=False,
             compression=None,
             wait_for_ready=None,
             timeout=None,
             metadata=None):
-        return grpc.experimental.unary_unary(request, target, '/api.Submit/CancelJobs',
+        return grpc.experimental.unary_unary(
+            request,
+            target,
+            '/api.Submit/CancelJobs',
             armada_dot_submit__pb2.JobCancelRequest.SerializeToString,
             armada_dot_submit__pb2.CancellationResult.FromString,
-            options, channel_credentials,
-            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
 
     @staticmethod
     def CancelJobSet(request,
             target,
             options=(),
             channel_credentials=None,
             call_credentials=None,
             insecure=False,
             compression=None,
             wait_for_ready=None,
             timeout=None,
             metadata=None):
-        return grpc.experimental.unary_unary(request, target, '/api.Submit/CancelJobSet',
+        return grpc.experimental.unary_unary(
+            request,
+            target,
+            '/api.Submit/CancelJobSet',
             armada_dot_submit__pb2.JobSetCancelRequest.SerializeToString,
             google_dot_protobuf_dot_empty__pb2.Empty.FromString,
-            options, channel_credentials,
-            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
 
     @staticmethod
     def ReprioritizeJobs(request,
             target,
             options=(),
             channel_credentials=None,
             call_credentials=None,
             insecure=False,
             compression=None,
             wait_for_ready=None,
             timeout=None,
             metadata=None):
-        return grpc.experimental.unary_unary(request, target, '/api.Submit/ReprioritizeJobs',
+        return grpc.experimental.unary_unary(
+            request,
+            target,
+            '/api.Submit/ReprioritizeJobs',
             armada_dot_submit__pb2.JobReprioritizeRequest.SerializeToString,
             armada_dot_submit__pb2.JobReprioritizeResponse.FromString,
-            options, channel_credentials,
-            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
+
+    @staticmethod
+    def PreemptJobs(request,
+            target,
+            options=(),
+            channel_credentials=None,
+            call_credentials=None,
+            insecure=False,
+            compression=None,
+            wait_for_ready=None,
+            timeout=None,
+            metadata=None):
+        return grpc.experimental.unary_unary(
+            request,
+            target,
+            '/api.Submit/PreemptJobs',
+            armada_dot_submit__pb2.JobPreemptRequest.SerializeToString,
+            google_dot_protobuf_dot_empty__pb2.Empty.FromString,
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
 
     @staticmethod
     def CreateQueue(request,
             target,
             options=(),
             channel_credentials=None,
             call_credentials=None,
             insecure=False,
             compression=None,
             wait_for_ready=None,
             timeout=None,
             metadata=None):
-        return grpc.experimental.unary_unary(request, target, '/api.Submit/CreateQueue',
+        return grpc.experimental.unary_unary(
+            request,
+            target,
+            '/api.Submit/CreateQueue',
             armada_dot_submit__pb2.Queue.SerializeToString,
             google_dot_protobuf_dot_empty__pb2.Empty.FromString,
-            options, channel_credentials,
-            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
 
     @staticmethod
     def CreateQueues(request,
             target,
             options=(),
             channel_credentials=None,
             call_credentials=None,
             insecure=False,
             compression=None,
             wait_for_ready=None,
             timeout=None,
             metadata=None):
-        return grpc.experimental.unary_unary(request, target, '/api.Submit/CreateQueues',
+        return grpc.experimental.unary_unary(
+            request,
+            target,
+            '/api.Submit/CreateQueues',
             armada_dot_submit__pb2.QueueList.SerializeToString,
             armada_dot_submit__pb2.BatchQueueCreateResponse.FromString,
-            options, channel_credentials,
-            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
 
     @staticmethod
     def UpdateQueue(request,
             target,
             options=(),
             channel_credentials=None,
             call_credentials=None,
             insecure=False,
             compression=None,
             wait_for_ready=None,
             timeout=None,
             metadata=None):
-        return grpc.experimental.unary_unary(request, target, '/api.Submit/UpdateQueue',
+        return grpc.experimental.unary_unary(
+            request,
+            target,
+            '/api.Submit/UpdateQueue',
             armada_dot_submit__pb2.Queue.SerializeToString,
             google_dot_protobuf_dot_empty__pb2.Empty.FromString,
-            options, channel_credentials,
-            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
 
     @staticmethod
     def UpdateQueues(request,
             target,
             options=(),
             channel_credentials=None,
             call_credentials=None,
             insecure=False,
             compression=None,
             wait_for_ready=None,
             timeout=None,
             metadata=None):
-        return grpc.experimental.unary_unary(request, target, '/api.Submit/UpdateQueues',
+        return grpc.experimental.unary_unary(
+            request,
+            target,
+            '/api.Submit/UpdateQueues',
             armada_dot_submit__pb2.QueueList.SerializeToString,
             armada_dot_submit__pb2.BatchQueueUpdateResponse.FromString,
-            options, channel_credentials,
-            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
 
     @staticmethod
     def DeleteQueue(request,
             target,
             options=(),
             channel_credentials=None,
             call_credentials=None,
             insecure=False,
             compression=None,
             wait_for_ready=None,
             timeout=None,
             metadata=None):
-        return grpc.experimental.unary_unary(request, target, '/api.Submit/DeleteQueue',
+        return grpc.experimental.unary_unary(
+            request,
+            target,
+            '/api.Submit/DeleteQueue',
             armada_dot_submit__pb2.QueueDeleteRequest.SerializeToString,
             google_dot_protobuf_dot_empty__pb2.Empty.FromString,
-            options, channel_credentials,
-            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
 
     @staticmethod
     def GetQueue(request,
             target,
             options=(),
             channel_credentials=None,
             call_credentials=None,
             insecure=False,
             compression=None,
             wait_for_ready=None,
             timeout=None,
             metadata=None):
-        return grpc.experimental.unary_unary(request, target, '/api.Submit/GetQueue',
+        return grpc.experimental.unary_unary(
+            request,
+            target,
+            '/api.Submit/GetQueue',
             armada_dot_submit__pb2.QueueGetRequest.SerializeToString,
             armada_dot_submit__pb2.Queue.FromString,
-            options, channel_credentials,
-            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
 
     @staticmethod
     def GetQueues(request,
             target,
             options=(),
             channel_credentials=None,
             call_credentials=None,
             insecure=False,
             compression=None,
             wait_for_ready=None,
             timeout=None,
             metadata=None):
-        return grpc.experimental.unary_stream(request, target, '/api.Submit/GetQueues',
+        return grpc.experimental.unary_stream(
+            request,
+            target,
+            '/api.Submit/GetQueues',
             armada_dot_submit__pb2.StreamingQueueGetRequest.SerializeToString,
             armada_dot_submit__pb2.StreamingQueueMessage.FromString,
-            options, channel_credentials,
-            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
 
     @staticmethod
     def Health(request,
             target,
             options=(),
             channel_credentials=None,
             call_credentials=None,
             insecure=False,
             compression=None,
             wait_for_ready=None,
             timeout=None,
             metadata=None):
-        return grpc.experimental.unary_unary(request, target, '/api.Submit/Health',
+        return grpc.experimental.unary_unary(
+            request,
+            target,
+            '/api.Submit/Health',
             google_dot_protobuf_dot_empty__pb2.Empty.SerializeToString,
             armada_dot_health__pb2.HealthCheckResponse.FromString,
-            options, channel_credentials,
-            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
```

## armada_client/github/com/gogo/protobuf/gogoproto/gogo_pb2.py

```diff
@@ -1,11 +1,11 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: github.com/gogo/protobuf/gogoproto/gogo.proto
-# Protobuf Python Version: 4.25.1
+# Protobuf Python Version: 5.26.1
 """Generated protocol buffer code."""
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
 from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
@@ -16,11 +16,11 @@
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n-github.com/gogo/protobuf/gogoproto/gogo.proto\x12\tgogoproto\x1a google/protobuf/descriptor.proto:;\n\x13goproto_enum_prefix\x12\x1c.google.protobuf.EnumOptions\x18\xb1\xe4\x03 \x01(\x08:=\n\x15goproto_enum_stringer\x12\x1c.google.protobuf.EnumOptions\x18\xc5\xe4\x03 \x01(\x08:5\n\renum_stringer\x12\x1c.google.protobuf.EnumOptions\x18\xc6\xe4\x03 \x01(\x08:7\n\x0f\x65num_customname\x12\x1c.google.protobuf.EnumOptions\x18\xc7\xe4\x03 \x01(\t:0\n\x08\x65numdecl\x12\x1c.google.protobuf.EnumOptions\x18\xc8\xe4\x03 \x01(\x08:A\n\x14\x65numvalue_customname\x12!.google.protobuf.EnumValueOptions\x18\xd1\x83\x04 \x01(\t:;\n\x13goproto_getters_all\x12\x1c.google.protobuf.FileOptions\x18\x99\xec\x03 \x01(\x08:?\n\x17goproto_enum_prefix_all\x12\x1c.google.protobuf.FileOptions\x18\x9a\xec\x03 \x01(\x08:<\n\x14goproto_stringer_all\x12\x1c.google.protobuf.FileOptions\x18\x9b\xec\x03 \x01(\x08:9\n\x11verbose_equal_all\x12\x1c.google.protobuf.FileOptions\x18\x9c\xec\x03 \x01(\x08:0\n\x08\x66\x61\x63\x65_all\x12\x1c.google.protobuf.FileOptions\x18\x9d\xec\x03 \x01(\x08:4\n\x0cgostring_all\x12\x1c.google.protobuf.FileOptions\x18\x9e\xec\x03 \x01(\x08:4\n\x0cpopulate_all\x12\x1c.google.protobuf.FileOptions\x18\x9f\xec\x03 \x01(\x08:4\n\x0cstringer_all\x12\x1c.google.protobuf.FileOptions\x18\xa0\xec\x03 \x01(\x08:3\n\x0bonlyone_all\x12\x1c.google.protobuf.FileOptions\x18\xa1\xec\x03 \x01(\x08:1\n\tequal_all\x12\x1c.google.protobuf.FileOptions\x18\xa5\xec\x03 \x01(\x08:7\n\x0f\x64\x65scription_all\x12\x1c.google.protobuf.FileOptions\x18\xa6\xec\x03 \x01(\x08:3\n\x0btestgen_all\x12\x1c.google.protobuf.FileOptions\x18\xa7\xec\x03 \x01(\x08:4\n\x0c\x62\x65nchgen_all\x12\x1c.google.protobuf.FileOptions\x18\xa8\xec\x03 \x01(\x08:5\n\rmarshaler_all\x12\x1c.google.protobuf.FileOptions\x18\xa9\xec\x03 \x01(\x08:7\n\x0funmarshaler_all\x12\x1c.google.protobuf.FileOptions\x18\xaa\xec\x03 \x01(\x08:<\n\x14stable_marshaler_all\x12\x1c.google.protobuf.FileOptions\x18\xab\xec\x03 \x01(\x08:1\n\tsizer_all\x12\x1c.google.protobuf.FileOptions\x18\xac\xec\x03 \x01(\x08:A\n\x19goproto_enum_stringer_all\x12\x1c.google.protobuf.FileOptions\x18\xad\xec\x03 \x01(\x08:9\n\x11\x65num_stringer_all\x12\x1c.google.protobuf.FileOptions\x18\xae\xec\x03 \x01(\x08:<\n\x14unsafe_marshaler_all\x12\x1c.google.protobuf.FileOptions\x18\xaf\xec\x03 \x01(\x08:>\n\x16unsafe_unmarshaler_all\x12\x1c.google.protobuf.FileOptions\x18\xb0\xec\x03 \x01(\x08:B\n\x1agoproto_extensions_map_all\x12\x1c.google.protobuf.FileOptions\x18\xb1\xec\x03 \x01(\x08:@\n\x18goproto_unrecognized_all\x12\x1c.google.protobuf.FileOptions\x18\xb2\xec\x03 \x01(\x08:8\n\x10gogoproto_import\x12\x1c.google.protobuf.FileOptions\x18\xb3\xec\x03 \x01(\x08:6\n\x0eprotosizer_all\x12\x1c.google.protobuf.FileOptions\x18\xb4\xec\x03 \x01(\x08:3\n\x0b\x63ompare_all\x12\x1c.google.protobuf.FileOptions\x18\xb5\xec\x03 \x01(\x08:4\n\x0ctypedecl_all\x12\x1c.google.protobuf.FileOptions\x18\xb6\xec\x03 \x01(\x08:4\n\x0c\x65numdecl_all\x12\x1c.google.protobuf.FileOptions\x18\xb7\xec\x03 \x01(\x08:<\n\x14goproto_registration\x12\x1c.google.protobuf.FileOptions\x18\xb8\xec\x03 \x01(\x08:7\n\x0fmessagename_all\x12\x1c.google.protobuf.FileOptions\x18\xb9\xec\x03 \x01(\x08:=\n\x15goproto_sizecache_all\x12\x1c.google.protobuf.FileOptions\x18\xba\xec\x03 \x01(\x08:;\n\x13goproto_unkeyed_all\x12\x1c.google.protobuf.FileOptions\x18\xbb\xec\x03 \x01(\x08::\n\x0fgoproto_getters\x12\x1f.google.protobuf.MessageOptions\x18\x81\xf4\x03 \x01(\x08:;\n\x10goproto_stringer\x12\x1f.google.protobuf.MessageOptions\x18\x83\xf4\x03 \x01(\x08:8\n\rverbose_equal\x12\x1f.google.protobuf.MessageOptions\x18\x84\xf4\x03 \x01(\x08:/\n\x04\x66\x61\x63\x65\x12\x1f.google.protobuf.MessageOptions\x18\x85\xf4\x03 \x01(\x08:3\n\x08gostring\x12\x1f.google.protobuf.MessageOptions\x18\x86\xf4\x03 \x01(\x08:3\n\x08populate\x12\x1f.google.protobuf.MessageOptions\x18\x87\xf4\x03 \x01(\x08:3\n\x08stringer\x12\x1f.google.protobuf.MessageOptions\x18\xc0\x8b\x04 \x01(\x08:2\n\x07onlyone\x12\x1f.google.protobuf.MessageOptions\x18\x89\xf4\x03 \x01(\x08:0\n\x05\x65qual\x12\x1f.google.protobuf.MessageOptions\x18\x8d\xf4\x03 \x01(\x08:6\n\x0b\x64\x65scription\x12\x1f.google.protobuf.MessageOptions\x18\x8e\xf4\x03 \x01(\x08:2\n\x07testgen\x12\x1f.google.protobuf.MessageOptions\x18\x8f\xf4\x03 \x01(\x08:3\n\x08\x62\x65nchgen\x12\x1f.google.protobuf.MessageOptions\x18\x90\xf4\x03 \x01(\x08:4\n\tmarshaler\x12\x1f.google.protobuf.MessageOptions\x18\x91\xf4\x03 \x01(\x08:6\n\x0bunmarshaler\x12\x1f.google.protobuf.MessageOptions\x18\x92\xf4\x03 \x01(\x08:;\n\x10stable_marshaler\x12\x1f.google.protobuf.MessageOptions\x18\x93\xf4\x03 \x01(\x08:0\n\x05sizer\x12\x1f.google.protobuf.MessageOptions\x18\x94\xf4\x03 \x01(\x08:;\n\x10unsafe_marshaler\x12\x1f.google.protobuf.MessageOptions\x18\x97\xf4\x03 \x01(\x08:=\n\x12unsafe_unmarshaler\x12\x1f.google.protobuf.MessageOptions\x18\x98\xf4\x03 \x01(\x08:A\n\x16goproto_extensions_map\x12\x1f.google.protobuf.MessageOptions\x18\x99\xf4\x03 \x01(\x08:?\n\x14goproto_unrecognized\x12\x1f.google.protobuf.MessageOptions\x18\x9a\xf4\x03 \x01(\x08:5\n\nprotosizer\x12\x1f.google.protobuf.MessageOptions\x18\x9c\xf4\x03 \x01(\x08:2\n\x07\x63ompare\x12\x1f.google.protobuf.MessageOptions\x18\x9d\xf4\x03 \x01(\x08:3\n\x08typedecl\x12\x1f.google.protobuf.MessageOptions\x18\x9e\xf4\x03 \x01(\x08:6\n\x0bmessagename\x12\x1f.google.protobuf.MessageOptions\x18\xa1\xf4\x03 \x01(\x08:<\n\x11goproto_sizecache\x12\x1f.google.protobuf.MessageOptions\x18\xa2\xf4\x03 \x01(\x08::\n\x0fgoproto_unkeyed\x12\x1f.google.protobuf.MessageOptions\x18\xa3\xf4\x03 \x01(\x08:1\n\x08nullable\x12\x1d.google.protobuf.FieldOptions\x18\xe9\xfb\x03 \x01(\x08:.\n\x05\x65mbed\x12\x1d.google.protobuf.FieldOptions\x18\xea\xfb\x03 \x01(\x08:3\n\ncustomtype\x12\x1d.google.protobuf.FieldOptions\x18\xeb\xfb\x03 \x01(\t:3\n\ncustomname\x12\x1d.google.protobuf.FieldOptions\x18\xec\xfb\x03 \x01(\t:0\n\x07jsontag\x12\x1d.google.protobuf.FieldOptions\x18\xed\xfb\x03 \x01(\t:1\n\x08moretags\x12\x1d.google.protobuf.FieldOptions\x18\xee\xfb\x03 \x01(\t:1\n\x08\x63\x61sttype\x12\x1d.google.protobuf.FieldOptions\x18\xef\xfb\x03 \x01(\t:0\n\x07\x63\x61stkey\x12\x1d.google.protobuf.FieldOptions\x18\xf0\xfb\x03 \x01(\t:2\n\tcastvalue\x12\x1d.google.protobuf.FieldOptions\x18\xf1\xfb\x03 \x01(\t:0\n\x07stdtime\x12\x1d.google.protobuf.FieldOptions\x18\xf2\xfb\x03 \x01(\x08:4\n\x0bstdduration\x12\x1d.google.protobuf.FieldOptions\x18\xf3\xfb\x03 \x01(\x08:3\n\nwktpointer\x12\x1d.google.protobuf.FieldOptions\x18\xf4\xfb\x03 \x01(\x08\x42\x45\n\x13\x63om.google.protobufB\nGoGoProtosZ\"github.com/gogo/protobuf/gogoproto')
 
 _globals = globals()
 _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
 _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'github.com.gogo.protobuf.gogoproto.gogo_pb2', _globals)
-if _descriptor._USE_C_DESCRIPTORS == False:
-  _globals['DESCRIPTOR']._options = None
+if not _descriptor._USE_C_DESCRIPTORS:
+  _globals['DESCRIPTOR']._loaded_options = None
   _globals['DESCRIPTOR']._serialized_options = b'\n\023com.google.protobufB\nGoGoProtosZ\"github.com/gogo/protobuf/gogoproto'
 # @@protoc_insertion_point(module_scope)
```

## armada_client/github/com/gogo/protobuf/gogoproto/gogo_pb2.pyi

```diff
@@ -25,14 +25,15 @@
 SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 """
+
 import builtins
 import google.protobuf.descriptor
 import google.protobuf.descriptor_pb2
 import google.protobuf.internal.extension_dict
 
 DESCRIPTOR: google.protobuf.descriptor.FileDescriptor
```

## armada_client/google/api/annotations_pb2.py

```diff
@@ -1,11 +1,11 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: google/api/annotations.proto
-# Protobuf Python Version: 4.25.1
+# Protobuf Python Version: 5.26.1
 """Generated protocol buffer code."""
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
 from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
@@ -17,11 +17,11 @@
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x1cgoogle/api/annotations.proto\x12\ngoogle.api\x1a\x15google/api/http.proto\x1a google/protobuf/descriptor.proto:E\n\x04http\x12\x1e.google.protobuf.MethodOptions\x18\xb0\xca\xbc\" \x01(\x0b\x32\x14.google.api.HttpRuleBn\n\x0e\x63om.google.apiB\x10\x41nnotationsProtoP\x01ZAgoogle.golang.org/genproto/googleapis/api/annotations;annotations\xa2\x02\x04GAPIb\x06proto3')
 
 _globals = globals()
 _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
 _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'google.api.annotations_pb2', _globals)
-if _descriptor._USE_C_DESCRIPTORS == False:
-  _globals['DESCRIPTOR']._options = None
+if not _descriptor._USE_C_DESCRIPTORS:
+  _globals['DESCRIPTOR']._loaded_options = None
   _globals['DESCRIPTOR']._serialized_options = b'\n\016com.google.apiB\020AnnotationsProtoP\001ZAgoogle.golang.org/genproto/googleapis/api/annotations;annotations\242\002\004GAPI'
 # @@protoc_insertion_point(module_scope)
```

## armada_client/google/api/annotations_pb2.pyi

```diff
@@ -11,14 +11,15 @@
 
 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
 """
+
 import builtins
 import google.api.http_pb2
 import google.protobuf.descriptor
 import google.protobuf.descriptor_pb2
 import google.protobuf.internal.extension_dict
 
 DESCRIPTOR: google.protobuf.descriptor.FileDescriptor
```

## armada_client/google/api/annotations_pb2_grpc.py

```diff
@@ -1,4 +1,29 @@
 # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
 """Client and server classes corresponding to protobuf-defined services."""
 import grpc
+import warnings
 
+
+GRPC_GENERATED_VERSION = '1.64.0'
+GRPC_VERSION = grpc.__version__
+EXPECTED_ERROR_RELEASE = '1.65.0'
+SCHEDULED_RELEASE_DATE = 'June 25, 2024'
+_version_not_supported = False
+
+try:
+    from grpc._utilities import first_version_is_lower
+    _version_not_supported = first_version_is_lower(GRPC_VERSION, GRPC_GENERATED_VERSION)
+except ImportError:
+    _version_not_supported = True
+
+if _version_not_supported:
+    warnings.warn(
+        f'The grpc package installed is at version {GRPC_VERSION},'
+        + f' but the generated code in google/api/annotations_pb2_grpc.py depends on'
+        + f' grpcio>={GRPC_GENERATED_VERSION}.'
+        + f' Please upgrade your grpc module to grpcio>={GRPC_GENERATED_VERSION}'
+        + f' or downgrade your generated code using grpcio-tools<={GRPC_VERSION}.'
+        + f' This warning will become an error in {EXPECTED_ERROR_RELEASE},'
+        + f' scheduled for release on {SCHEDULED_RELEASE_DATE}.',
+        RuntimeWarning
+    )
```

## armada_client/google/api/http_pb2.py

```diff
@@ -1,11 +1,11 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: google/api/http.proto
-# Protobuf Python Version: 4.25.1
+# Protobuf Python Version: 5.26.1
 """Generated protocol buffer code."""
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
 from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
@@ -15,16 +15,16 @@
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x15google/api/http.proto\x12\ngoogle.api\"T\n\x04Http\x12#\n\x05rules\x18\x01 \x03(\x0b\x32\x14.google.api.HttpRule\x12\'\n\x1f\x66ully_decode_reserved_expansion\x18\x02 \x01(\x08\"\x81\x02\n\x08HttpRule\x12\x10\n\x08selector\x18\x01 \x01(\t\x12\r\n\x03get\x18\x02 \x01(\tH\x00\x12\r\n\x03put\x18\x03 \x01(\tH\x00\x12\x0e\n\x04post\x18\x04 \x01(\tH\x00\x12\x10\n\x06\x64\x65lete\x18\x05 \x01(\tH\x00\x12\x0f\n\x05patch\x18\x06 \x01(\tH\x00\x12/\n\x06\x63ustom\x18\x08 \x01(\x0b\x32\x1d.google.api.CustomHttpPatternH\x00\x12\x0c\n\x04\x62ody\x18\x07 \x01(\t\x12\x15\n\rresponse_body\x18\x0c \x01(\t\x12\x31\n\x13\x61\x64\x64itional_bindings\x18\x0b \x03(\x0b\x32\x14.google.api.HttpRuleB\t\n\x07pattern\"/\n\x11\x43ustomHttpPattern\x12\x0c\n\x04kind\x18\x01 \x01(\t\x12\x0c\n\x04path\x18\x02 \x01(\tBj\n\x0e\x63om.google.apiB\tHttpProtoP\x01ZAgoogle.golang.org/genproto/googleapis/api/annotations;annotations\xf8\x01\x01\xa2\x02\x04GAPIb\x06proto3')
 
 _globals = globals()
 _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
 _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'google.api.http_pb2', _globals)
-if _descriptor._USE_C_DESCRIPTORS == False:
-  _globals['DESCRIPTOR']._options = None
+if not _descriptor._USE_C_DESCRIPTORS:
+  _globals['DESCRIPTOR']._loaded_options = None
   _globals['DESCRIPTOR']._serialized_options = b'\n\016com.google.apiB\tHttpProtoP\001ZAgoogle.golang.org/genproto/googleapis/api/annotations;annotations\370\001\001\242\002\004GAPI'
   _globals['_HTTP']._serialized_start=37
   _globals['_HTTP']._serialized_end=121
   _globals['_HTTPRULE']._serialized_start=124
   _globals['_HTTPRULE']._serialized_end=381
   _globals['_CUSTOMHTTPPATTERN']._serialized_start=383
   _globals['_CUSTOMHTTPPATTERN']._serialized_end=430
```

## armada_client/google/api/http_pb2.pyi

```diff
@@ -11,64 +11,61 @@
 
 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
 """
+
 import builtins
 import collections.abc
 import google.protobuf.descriptor
 import google.protobuf.internal.containers
 import google.protobuf.message
-import sys
-
-if sys.version_info >= (3, 8):
-    import typing as typing_extensions
-else:
-    import typing_extensions
+import typing
 
 DESCRIPTOR: google.protobuf.descriptor.FileDescriptor
 
-@typing_extensions.final
+@typing.final
 class Http(google.protobuf.message.Message):
     """Defines the HTTP configuration for an API service. It contains a list of
     [HttpRule][google.api.HttpRule], each specifying the mapping of an RPC method
     to one or more HTTP REST API methods.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     RULES_FIELD_NUMBER: builtins.int
     FULLY_DECODE_RESERVED_EXPANSION_FIELD_NUMBER: builtins.int
-    @property
-    def rules(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___HttpRule]:
-        """A list of HTTP configuration rules that apply to individual API methods.
-
-        **NOTE:** All service configuration rules follow "last one wins" order.
-        """
     fully_decode_reserved_expansion: builtins.bool
     """When set to true, URL path parmeters will be fully URI-decoded except in
     cases of single segment matches in reserved expansion, where "%2F" will be
     left encoded.
 
     The default behavior is to not decode RFC 6570 reserved characters in multi
     segment matches.
     """
+    @property
+    def rules(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___HttpRule]:
+        """A list of HTTP configuration rules that apply to individual API methods.
+
+        **NOTE:** All service configuration rules follow "last one wins" order.
+        """
+
     def __init__(
         self,
         *,
         rules: collections.abc.Iterable[global___HttpRule] | None = ...,
         fully_decode_reserved_expansion: builtins.bool = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["fully_decode_reserved_expansion", b"fully_decode_reserved_expansion", "rules", b"rules"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["fully_decode_reserved_expansion", b"fully_decode_reserved_expansion", "rules", b"rules"]) -> None: ...
 
 global___Http = Http
 
-@typing_extensions.final
+@typing.final
 class HttpRule(google.protobuf.message.Message):
     """`HttpRule` defines the mapping of an RPC method to one or more HTTP
     REST API methods. The mapping specifies how different portions of the RPC
     request message are mapped to URL path, URL query parameters, and
     HTTP request body. The mapping is typically specified as an
     `google.api.http` annotation on the RPC method,
     see "google/api/annotations.proto" for details.
@@ -308,59 +305,61 @@
     """Used for updating a resource."""
     post: builtins.str
     """Used for creating a resource."""
     delete: builtins.str
     """Used for deleting a resource."""
     patch: builtins.str
     """Used for updating a resource."""
-    @property
-    def custom(self) -> global___CustomHttpPattern:
-        """The custom pattern is used for specifying an HTTP method that is not
-        included in the `pattern` field, such as HEAD, or "*" to leave the
-        HTTP method unspecified for this rule. The wild-card rule is useful
-        for services that provide content to Web (HTML) clients.
-        """
     body: builtins.str
     """The name of the request field whose value is mapped to the HTTP body, or
     `*` for mapping all fields not captured by the path pattern to the HTTP
     body. NOTE: the referred field must not be a repeated field and must be
     present at the top-level of request message type.
     """
     response_body: builtins.str
     """Optional. The name of the response field whose value is mapped to the HTTP
     body of response. Other response fields are ignored. When
     not set, the response message will be used as HTTP body of response.
     """
     @property
+    def custom(self) -> global___CustomHttpPattern:
+        """The custom pattern is used for specifying an HTTP method that is not
+        included in the `pattern` field, such as HEAD, or "*" to leave the
+        HTTP method unspecified for this rule. The wild-card rule is useful
+        for services that provide content to Web (HTML) clients.
+        """
+
+    @property
     def additional_bindings(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___HttpRule]:
         """Additional HTTP bindings for the selector. Nested bindings must
         not contain an `additional_bindings` field themselves (that is,
         the nesting may only be one level deep).
         """
+
     def __init__(
         self,
         *,
         selector: builtins.str = ...,
         get: builtins.str = ...,
         put: builtins.str = ...,
         post: builtins.str = ...,
         delete: builtins.str = ...,
         patch: builtins.str = ...,
         custom: global___CustomHttpPattern | None = ...,
         body: builtins.str = ...,
         response_body: builtins.str = ...,
         additional_bindings: collections.abc.Iterable[global___HttpRule] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["custom", b"custom", "delete", b"delete", "get", b"get", "patch", b"patch", "pattern", b"pattern", "post", b"post", "put", b"put"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["additional_bindings", b"additional_bindings", "body", b"body", "custom", b"custom", "delete", b"delete", "get", b"get", "patch", b"patch", "pattern", b"pattern", "post", b"post", "put", b"put", "response_body", b"response_body", "selector", b"selector"]) -> None: ...
-    def WhichOneof(self, oneof_group: typing_extensions.Literal["pattern", b"pattern"]) -> typing_extensions.Literal["get", "put", "post", "delete", "patch", "custom"] | None: ...
+    def HasField(self, field_name: typing.Literal["custom", b"custom", "delete", b"delete", "get", b"get", "patch", b"patch", "pattern", b"pattern", "post", b"post", "put", b"put"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["additional_bindings", b"additional_bindings", "body", b"body", "custom", b"custom", "delete", b"delete", "get", b"get", "patch", b"patch", "pattern", b"pattern", "post", b"post", "put", b"put", "response_body", b"response_body", "selector", b"selector"]) -> None: ...
+    def WhichOneof(self, oneof_group: typing.Literal["pattern", b"pattern"]) -> typing.Literal["get", "put", "post", "delete", "patch", "custom"] | None: ...
 
 global___HttpRule = HttpRule
 
-@typing_extensions.final
+@typing.final
 class CustomHttpPattern(google.protobuf.message.Message):
     """A custom pattern is used for defining custom HTTP verb."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     KIND_FIELD_NUMBER: builtins.int
     PATH_FIELD_NUMBER: builtins.int
@@ -370,10 +369,10 @@
     """The path matched by this custom verb."""
     def __init__(
         self,
         *,
         kind: builtins.str = ...,
         path: builtins.str = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["kind", b"kind", "path", b"path"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["kind", b"kind", "path", b"path"]) -> None: ...
 
 global___CustomHttpPattern = CustomHttpPattern
```

## armada_client/google/api/http_pb2_grpc.py

```diff
@@ -1,4 +1,29 @@
 # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
 """Client and server classes corresponding to protobuf-defined services."""
 import grpc
+import warnings
 
+
+GRPC_GENERATED_VERSION = '1.64.0'
+GRPC_VERSION = grpc.__version__
+EXPECTED_ERROR_RELEASE = '1.65.0'
+SCHEDULED_RELEASE_DATE = 'June 25, 2024'
+_version_not_supported = False
+
+try:
+    from grpc._utilities import first_version_is_lower
+    _version_not_supported = first_version_is_lower(GRPC_VERSION, GRPC_GENERATED_VERSION)
+except ImportError:
+    _version_not_supported = True
+
+if _version_not_supported:
+    warnings.warn(
+        f'The grpc package installed is at version {GRPC_VERSION},'
+        + f' but the generated code in google/api/http_pb2_grpc.py depends on'
+        + f' grpcio>={GRPC_GENERATED_VERSION}.'
+        + f' Please upgrade your grpc module to grpcio>={GRPC_GENERATED_VERSION}'
+        + f' or downgrade your generated code using grpcio-tools<={GRPC_VERSION}.'
+        + f' This warning will become an error in {EXPECTED_ERROR_RELEASE},'
+        + f' scheduled for release on {SCHEDULED_RELEASE_DATE}.',
+        RuntimeWarning
+    )
```

## armada_client/k8s/io/api/core/v1/generated_pb2.py

```diff
@@ -1,11 +1,11 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: k8s.io/api/core/v1/generated.proto
-# Protobuf Python Version: 4.25.1
+# Protobuf Python Version: 5.26.1
 """Generated protocol buffer code."""
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
 from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
@@ -20,70 +20,70 @@
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\"k8s.io/api/core/v1/generated.proto\x12\x12k8s.io.api.core.v1\x1a\x34k8s.io/apimachinery/pkg/api/resource/generated.proto\x1a\x34k8s.io/apimachinery/pkg/apis/meta/v1/generated.proto\x1a/k8s.io/apimachinery/pkg/runtime/generated.proto\x1a\x36k8s.io/apimachinery/pkg/runtime/schema/generated.proto\x1a\x33k8s.io/apimachinery/pkg/util/intstr/generated.proto\"i\n AWSElasticBlockStoreVolumeSource\x12\x10\n\x08volumeID\x18\x01 \x01(\t\x12\x0e\n\x06\x66sType\x18\x02 \x01(\t\x12\x11\n\tpartition\x18\x03 \x01(\x05\x12\x10\n\x08readOnly\x18\x04 \x01(\x08\"\xb6\x01\n\x08\x41\x66\x66inity\x12\x36\n\x0cnodeAffinity\x18\x01 \x01(\x0b\x32 .k8s.io.api.core.v1.NodeAffinity\x12\x34\n\x0bpodAffinity\x18\x02 \x01(\x0b\x32\x1f.k8s.io.api.core.v1.PodAffinity\x12<\n\x0fpodAntiAffinity\x18\x03 \x01(\x0b\x32#.k8s.io.api.core.v1.PodAntiAffinity\"2\n\x0e\x41ttachedVolume\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x12\n\ndevicePath\x18\x02 \x01(\t\"N\n\tAvoidPods\x12\x41\n\x0fpreferAvoidPods\x18\x01 \x03(\x0b\x32(.k8s.io.api.core.v1.PreferAvoidPodsEntry\"\x7f\n\x15\x41zureDiskVolumeSource\x12\x10\n\x08\x64iskName\x18\x01 \x01(\t\x12\x0f\n\x07\x64iskURI\x18\x02 \x01(\t\x12\x13\n\x0b\x63\x61\x63hingMode\x18\x03 \x01(\t\x12\x0e\n\x06\x66sType\x18\x04 \x01(\t\x12\x10\n\x08readOnly\x18\x05 \x01(\x08\x12\x0c\n\x04kind\x18\x06 \x01(\t\"s\n\x1f\x41zureFilePersistentVolumeSource\x12\x12\n\nsecretName\x18\x01 \x01(\t\x12\x11\n\tshareName\x18\x02 \x01(\t\x12\x10\n\x08readOnly\x18\x03 \x01(\x08\x12\x17\n\x0fsecretNamespace\x18\x04 \x01(\t\"P\n\x15\x41zureFileVolumeSource\x12\x12\n\nsecretName\x18\x01 \x01(\t\x12\x11\n\tshareName\x18\x02 \x01(\t\x12\x10\n\x08readOnly\x18\x03 \x01(\x08\"\x82\x01\n\x07\x42inding\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12\x33\n\x06target\x18\x02 \x01(\x0b\x32#.k8s.io.api.core.v1.ObjectReference\"\x90\x04\n\x19\x43SIPersistentVolumeSource\x12\x0e\n\x06\x64river\x18\x01 \x01(\t\x12\x14\n\x0cvolumeHandle\x18\x02 \x01(\t\x12\x10\n\x08readOnly\x18\x03 \x01(\x08\x12\x0e\n\x06\x66sType\x18\x04 \x01(\t\x12]\n\x10volumeAttributes\x18\x05 \x03(\x0b\x32\x43.k8s.io.api.core.v1.CSIPersistentVolumeSource.VolumeAttributesEntry\x12G\n\x1a\x63ontrollerPublishSecretRef\x18\x06 \x01(\x0b\x32#.k8s.io.api.core.v1.SecretReference\x12?\n\x12nodeStageSecretRef\x18\x07 \x01(\x0b\x32#.k8s.io.api.core.v1.SecretReference\x12\x41\n\x14nodePublishSecretRef\x18\x08 \x01(\x0b\x32#.k8s.io.api.core.v1.SecretReference\x12\x46\n\x19\x63ontrollerExpandSecretRef\x18\t \x01(\x0b\x32#.k8s.io.api.core.v1.SecretReference\x1a\x37\n\x15VolumeAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"\x99\x02\n\x0f\x43SIVolumeSource\x12\x0e\n\x06\x64river\x18\x01 \x01(\t\x12\x10\n\x08readOnly\x18\x02 \x01(\x08\x12\x0e\n\x06\x66sType\x18\x03 \x01(\t\x12S\n\x10volumeAttributes\x18\x04 \x03(\x0b\x32\x39.k8s.io.api.core.v1.CSIVolumeSource.VolumeAttributesEntry\x12\x46\n\x14nodePublishSecretRef\x18\x05 \x01(\x0b\x32(.k8s.io.api.core.v1.LocalObjectReference\x1a\x37\n\x15VolumeAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\")\n\x0c\x43\x61pabilities\x12\x0b\n\x03\x61\x64\x64\x18\x01 \x03(\t\x12\x0c\n\x04\x64rop\x18\x02 \x03(\t\"\xaa\x01\n\x1c\x43\x65phFSPersistentVolumeSource\x12\x10\n\x08monitors\x18\x01 \x03(\t\x12\x0c\n\x04path\x18\x02 \x01(\t\x12\x0c\n\x04user\x18\x03 \x01(\t\x12\x12\n\nsecretFile\x18\x04 \x01(\t\x12\x36\n\tsecretRef\x18\x05 \x01(\x0b\x32#.k8s.io.api.core.v1.SecretReference\x12\x10\n\x08readOnly\x18\x06 \x01(\x08\"\xa5\x01\n\x12\x43\x65phFSVolumeSource\x12\x10\n\x08monitors\x18\x01 \x03(\t\x12\x0c\n\x04path\x18\x02 \x01(\t\x12\x0c\n\x04user\x18\x03 \x01(\t\x12\x12\n\nsecretFile\x18\x04 \x01(\t\x12;\n\tsecretRef\x18\x05 \x01(\x0b\x32(.k8s.io.api.core.v1.LocalObjectReference\x12\x10\n\x08readOnly\x18\x06 \x01(\x08\"\x8a\x01\n\x1c\x43inderPersistentVolumeSource\x12\x10\n\x08volumeID\x18\x01 \x01(\t\x12\x0e\n\x06\x66sType\x18\x02 \x01(\t\x12\x10\n\x08readOnly\x18\x03 \x01(\x08\x12\x36\n\tsecretRef\x18\x04 \x01(\x0b\x32#.k8s.io.api.core.v1.SecretReference\"\x85\x01\n\x12\x43inderVolumeSource\x12\x10\n\x08volumeID\x18\x01 \x01(\t\x12\x0e\n\x06\x66sType\x18\x02 \x01(\t\x12\x10\n\x08readOnly\x18\x03 \x01(\x08\x12;\n\tsecretRef\x18\x04 \x01(\x0b\x32(.k8s.io.api.core.v1.LocalObjectReference\"(\n\x0e\x43lientIPConfig\x12\x16\n\x0etimeoutSeconds\x18\x01 \x01(\x05\"R\n\x12\x43omponentCondition\x12\x0c\n\x04type\x18\x01 \x01(\t\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x0f\n\x07message\x18\x03 \x01(\t\x12\r\n\x05\x65rror\x18\x04 \x01(\t\"\x91\x01\n\x0f\x43omponentStatus\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12:\n\nconditions\x18\x02 \x03(\x0b\x32&.k8s.io.api.core.v1.ComponentCondition\"\x8b\x01\n\x13\x43omponentStatusList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12\x32\n\x05items\x18\x02 \x03(\x0b\x32#.k8s.io.api.core.v1.ComponentStatus\"\xbc\x02\n\tConfigMap\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12\x11\n\timmutable\x18\x04 \x01(\x08\x12\x35\n\x04\x64\x61ta\x18\x02 \x03(\x0b\x32\'.k8s.io.api.core.v1.ConfigMap.DataEntry\x12\x41\n\nbinaryData\x18\x03 \x03(\x0b\x32-.k8s.io.api.core.v1.ConfigMap.BinaryDataEntry\x1a+\n\tDataEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a\x31\n\x0f\x42inaryDataEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\x0c:\x02\x38\x01\"n\n\x12\x43onfigMapEnvSource\x12\x46\n\x14localObjectReference\x18\x01 \x01(\x0b\x32(.k8s.io.api.core.v1.LocalObjectReference\x12\x10\n\x08optional\x18\x02 \x01(\x08\"}\n\x14\x43onfigMapKeySelector\x12\x46\n\x14localObjectReference\x18\x01 \x01(\x0b\x32(.k8s.io.api.core.v1.LocalObjectReference\x12\x0b\n\x03key\x18\x02 \x01(\t\x12\x10\n\x08optional\x18\x03 \x01(\x08\"\x7f\n\rConfigMapList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12,\n\x05items\x18\x02 \x03(\x0b\x32\x1d.k8s.io.api.core.v1.ConfigMap\"|\n\x19\x43onfigMapNodeConfigSource\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x0c\n\x04name\x18\x02 \x01(\t\x12\x0b\n\x03uid\x18\x03 \x01(\t\x12\x17\n\x0fresourceVersion\x18\x04 \x01(\t\x12\x18\n\x10kubeletConfigKey\x18\x05 \x01(\t\"\x9d\x01\n\x13\x43onfigMapProjection\x12\x46\n\x14localObjectReference\x18\x01 \x01(\x0b\x32(.k8s.io.api.core.v1.LocalObjectReference\x12,\n\x05items\x18\x02 \x03(\x0b\x32\x1d.k8s.io.api.core.v1.KeyToPath\x12\x10\n\x08optional\x18\x04 \x01(\x08\"\xb4\x01\n\x15\x43onfigMapVolumeSource\x12\x46\n\x14localObjectReference\x18\x01 \x01(\x0b\x32(.k8s.io.api.core.v1.LocalObjectReference\x12,\n\x05items\x18\x02 \x03(\x0b\x32\x1d.k8s.io.api.core.v1.KeyToPath\x12\x13\n\x0b\x64\x65\x66\x61ultMode\x18\x03 \x01(\x05\x12\x10\n\x08optional\x18\x04 \x01(\x08\"\xa7\x06\n\tContainer\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\r\n\x05image\x18\x02 \x01(\t\x12\x0f\n\x07\x63ommand\x18\x03 \x03(\t\x12\x0c\n\x04\x61rgs\x18\x04 \x03(\t\x12\x12\n\nworkingDir\x18\x05 \x01(\t\x12\x30\n\x05ports\x18\x06 \x03(\x0b\x32!.k8s.io.api.core.v1.ContainerPort\x12\x32\n\x07\x65nvFrom\x18\x13 \x03(\x0b\x32!.k8s.io.api.core.v1.EnvFromSource\x12\'\n\x03\x65nv\x18\x07 \x03(\x0b\x32\x1a.k8s.io.api.core.v1.EnvVar\x12;\n\tresources\x18\x08 \x01(\x0b\x32(.k8s.io.api.core.v1.ResourceRequirements\x12\x35\n\x0cvolumeMounts\x18\t \x03(\x0b\x32\x1f.k8s.io.api.core.v1.VolumeMount\x12\x37\n\rvolumeDevices\x18\x15 \x03(\x0b\x32 .k8s.io.api.core.v1.VolumeDevice\x12\x30\n\rlivenessProbe\x18\n \x01(\x0b\x32\x19.k8s.io.api.core.v1.Probe\x12\x31\n\x0ereadinessProbe\x18\x0b \x01(\x0b\x32\x19.k8s.io.api.core.v1.Probe\x12/\n\x0cstartupProbe\x18\x16 \x01(\x0b\x32\x19.k8s.io.api.core.v1.Probe\x12\x30\n\tlifecycle\x18\x0c \x01(\x0b\x32\x1d.k8s.io.api.core.v1.Lifecycle\x12\x1e\n\x16terminationMessagePath\x18\r \x01(\t\x12 \n\x18terminationMessagePolicy\x18\x14 \x01(\t\x12\x17\n\x0fimagePullPolicy\x18\x0e \x01(\t\x12<\n\x0fsecurityContext\x18\x0f \x01(\x0b\x32#.k8s.io.api.core.v1.SecurityContext\x12\r\n\x05stdin\x18\x10 \x01(\x08\x12\x11\n\tstdinOnce\x18\x11 \x01(\x08\x12\x0b\n\x03tty\x18\x12 \x01(\x08\"2\n\x0e\x43ontainerImage\x12\r\n\x05names\x18\x01 \x03(\t\x12\x11\n\tsizeBytes\x18\x02 \x01(\x03\"h\n\rContainerPort\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x10\n\x08hostPort\x18\x02 \x01(\x05\x12\x15\n\rcontainerPort\x18\x03 \x01(\x05\x12\x10\n\x08protocol\x18\x04 \x01(\t\x12\x0e\n\x06hostIP\x18\x05 \x01(\t\"\xca\x01\n\x0e\x43ontainerState\x12:\n\x07waiting\x18\x01 \x01(\x0b\x32).k8s.io.api.core.v1.ContainerStateWaiting\x12:\n\x07running\x18\x02 \x01(\x0b\x32).k8s.io.api.core.v1.ContainerStateRunning\x12@\n\nterminated\x18\x03 \x01(\x0b\x32,.k8s.io.api.core.v1.ContainerStateTerminated\"V\n\x15\x43ontainerStateRunning\x12=\n\tstartedAt\x18\x01 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\"\xf1\x01\n\x18\x43ontainerStateTerminated\x12\x10\n\x08\x65xitCode\x18\x01 \x01(\x05\x12\x0e\n\x06signal\x18\x02 \x01(\x05\x12\x0e\n\x06reason\x18\x03 \x01(\t\x12\x0f\n\x07message\x18\x04 \x01(\t\x12=\n\tstartedAt\x18\x05 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\x12>\n\nfinishedAt\x18\x06 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\x12\x13\n\x0b\x63ontainerID\x18\x07 \x01(\t\"8\n\x15\x43ontainerStateWaiting\x12\x0e\n\x06reason\x18\x01 \x01(\t\x12\x0f\n\x07message\x18\x02 \x01(\t\"\xf4\x01\n\x0f\x43ontainerStatus\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x31\n\x05state\x18\x02 \x01(\x0b\x32\".k8s.io.api.core.v1.ContainerState\x12\x35\n\tlastState\x18\x03 \x01(\x0b\x32\".k8s.io.api.core.v1.ContainerState\x12\r\n\x05ready\x18\x04 \x01(\x08\x12\x14\n\x0crestartCount\x18\x05 \x01(\x05\x12\r\n\x05image\x18\x06 \x01(\t\x12\x0f\n\x07imageID\x18\x07 \x01(\t\x12\x13\n\x0b\x63ontainerID\x18\x08 \x01(\t\x12\x0f\n\x07started\x18\t \x01(\x08\"\x1e\n\x0e\x44\x61\x65monEndpoint\x12\x0c\n\x04Port\x18\x01 \x01(\x05\"Q\n\x15\x44ownwardAPIProjection\x12\x38\n\x05items\x18\x01 \x03(\x0b\x32).k8s.io.api.core.v1.DownwardAPIVolumeFile\"\xb3\x01\n\x15\x44ownwardAPIVolumeFile\x12\x0c\n\x04path\x18\x01 \x01(\t\x12\x39\n\x08\x66ieldRef\x18\x02 \x01(\x0b\x32\'.k8s.io.api.core.v1.ObjectFieldSelector\x12\x43\n\x10resourceFieldRef\x18\x03 \x01(\x0b\x32).k8s.io.api.core.v1.ResourceFieldSelector\x12\x0c\n\x04mode\x18\x04 \x01(\x05\"h\n\x17\x44ownwardAPIVolumeSource\x12\x38\n\x05items\x18\x01 \x03(\x0b\x32).k8s.io.api.core.v1.DownwardAPIVolumeFile\x12\x13\n\x0b\x64\x65\x66\x61ultMode\x18\x02 \x01(\x05\"i\n\x14\x45mptyDirVolumeSource\x12\x0e\n\x06medium\x18\x01 \x01(\t\x12\x41\n\tsizeLimit\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity\"y\n\x0f\x45ndpointAddress\x12\n\n\x02ip\x18\x01 \x01(\t\x12\x10\n\x08hostname\x18\x03 \x01(\t\x12\x10\n\x08nodeName\x18\x04 \x01(\t\x12\x36\n\ttargetRef\x18\x02 \x01(\x0b\x32#.k8s.io.api.core.v1.ObjectReference\"Q\n\x0c\x45ndpointPort\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0c\n\x04port\x18\x02 \x01(\x05\x12\x10\n\x08protocol\x18\x03 \x01(\t\x12\x13\n\x0b\x61ppProtocol\x18\x04 \x01(\t\"\xb9\x01\n\x0e\x45ndpointSubset\x12\x36\n\taddresses\x18\x01 \x03(\x0b\x32#.k8s.io.api.core.v1.EndpointAddress\x12>\n\x11notReadyAddresses\x18\x02 \x03(\x0b\x32#.k8s.io.api.core.v1.EndpointAddress\x12/\n\x05ports\x18\x03 \x03(\x0b\x32 .k8s.io.api.core.v1.EndpointPort\"\x84\x01\n\tEndpoints\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12\x33\n\x07subsets\x18\x02 \x03(\x0b\x32\".k8s.io.api.core.v1.EndpointSubset\"\x7f\n\rEndpointsList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12,\n\x05items\x18\x02 \x03(\x0b\x32\x1d.k8s.io.api.core.v1.Endpoints\"\x95\x01\n\rEnvFromSource\x12\x0e\n\x06prefix\x18\x01 \x01(\t\x12<\n\x0c\x63onfigMapRef\x18\x02 \x01(\x0b\x32&.k8s.io.api.core.v1.ConfigMapEnvSource\x12\x36\n\tsecretRef\x18\x03 \x01(\x0b\x32#.k8s.io.api.core.v1.SecretEnvSource\"Z\n\x06\x45nvVar\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t\x12\x33\n\tvalueFrom\x18\x03 \x01(\x0b\x32 .k8s.io.api.core.v1.EnvVarSource\"\x8e\x02\n\x0c\x45nvVarSource\x12\x39\n\x08\x66ieldRef\x18\x01 \x01(\x0b\x32\'.k8s.io.api.core.v1.ObjectFieldSelector\x12\x43\n\x10resourceFieldRef\x18\x02 \x01(\x0b\x32).k8s.io.api.core.v1.ResourceFieldSelector\x12\x41\n\x0f\x63onfigMapKeyRef\x18\x03 \x01(\x0b\x32(.k8s.io.api.core.v1.ConfigMapKeySelector\x12;\n\x0csecretKeyRef\x18\x04 \x01(\x0b\x32%.k8s.io.api.core.v1.SecretKeySelector\"\x81\x01\n\x12\x45phemeralContainer\x12N\n\x18\x65phemeralContainerCommon\x18\x01 \x01(\x0b\x32,.k8s.io.api.core.v1.EphemeralContainerCommon\x12\x1b\n\x13targetContainerName\x18\x02 \x01(\t\"\xb6\x06\n\x18\x45phemeralContainerCommon\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\r\n\x05image\x18\x02 \x01(\t\x12\x0f\n\x07\x63ommand\x18\x03 \x03(\t\x12\x0c\n\x04\x61rgs\x18\x04 \x03(\t\x12\x12\n\nworkingDir\x18\x05 \x01(\t\x12\x30\n\x05ports\x18\x06 \x03(\x0b\x32!.k8s.io.api.core.v1.ContainerPort\x12\x32\n\x07\x65nvFrom\x18\x13 \x03(\x0b\x32!.k8s.io.api.core.v1.EnvFromSource\x12\'\n\x03\x65nv\x18\x07 \x03(\x0b\x32\x1a.k8s.io.api.core.v1.EnvVar\x12;\n\tresources\x18\x08 \x01(\x0b\x32(.k8s.io.api.core.v1.ResourceRequirements\x12\x35\n\x0cvolumeMounts\x18\t \x03(\x0b\x32\x1f.k8s.io.api.core.v1.VolumeMount\x12\x37\n\rvolumeDevices\x18\x15 \x03(\x0b\x32 .k8s.io.api.core.v1.VolumeDevice\x12\x30\n\rlivenessProbe\x18\n \x01(\x0b\x32\x19.k8s.io.api.core.v1.Probe\x12\x31\n\x0ereadinessProbe\x18\x0b \x01(\x0b\x32\x19.k8s.io.api.core.v1.Probe\x12/\n\x0cstartupProbe\x18\x16 \x01(\x0b\x32\x19.k8s.io.api.core.v1.Probe\x12\x30\n\tlifecycle\x18\x0c \x01(\x0b\x32\x1d.k8s.io.api.core.v1.Lifecycle\x12\x1e\n\x16terminationMessagePath\x18\r \x01(\t\x12 \n\x18terminationMessagePolicy\x18\x14 \x01(\t\x12\x17\n\x0fimagePullPolicy\x18\x0e \x01(\t\x12<\n\x0fsecurityContext\x18\x0f \x01(\x0b\x32#.k8s.io.api.core.v1.SecurityContext\x12\r\n\x05stdin\x18\x10 \x01(\x08\x12\x11\n\tstdinOnce\x18\x11 \x01(\x08\x12\x0b\n\x03tty\x18\x12 \x01(\x08\"g\n\x15\x45phemeralVolumeSource\x12N\n\x13volumeClaimTemplate\x18\x01 \x01(\x0b\x32\x31.k8s.io.api.core.v1.PersistentVolumeClaimTemplate\"\xf0\x04\n\x05\x45vent\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12;\n\x0einvolvedObject\x18\x02 \x01(\x0b\x32#.k8s.io.api.core.v1.ObjectReference\x12\x0e\n\x06reason\x18\x03 \x01(\t\x12\x0f\n\x07message\x18\x04 \x01(\t\x12/\n\x06source\x18\x05 \x01(\x0b\x32\x1f.k8s.io.api.core.v1.EventSource\x12\x42\n\x0e\x66irstTimestamp\x18\x06 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\x12\x41\n\rlastTimestamp\x18\x07 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\x12\r\n\x05\x63ount\x18\x08 \x01(\x05\x12\x0c\n\x04type\x18\t \x01(\t\x12\x42\n\teventTime\x18\n \x01(\x0b\x32/.k8s.io.apimachinery.pkg.apis.meta.v1.MicroTime\x12/\n\x06series\x18\x0b \x01(\x0b\x32\x1f.k8s.io.api.core.v1.EventSeries\x12\x0e\n\x06\x61\x63tion\x18\x0c \x01(\t\x12\x34\n\x07related\x18\r \x01(\x0b\x32#.k8s.io.api.core.v1.ObjectReference\x12\x1a\n\x12reportingComponent\x18\x0e \x01(\t\x12\x19\n\x11reportingInstance\x18\x0f \x01(\t\"w\n\tEventList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12(\n\x05items\x18\x02 \x03(\x0b\x32\x19.k8s.io.api.core.v1.Event\"g\n\x0b\x45ventSeries\x12\r\n\x05\x63ount\x18\x01 \x01(\x05\x12I\n\x10lastObservedTime\x18\x02 \x01(\x0b\x32/.k8s.io.apimachinery.pkg.apis.meta.v1.MicroTime\".\n\x0b\x45ventSource\x12\x11\n\tcomponent\x18\x01 \x01(\t\x12\x0c\n\x04host\x18\x02 \x01(\t\"\x1d\n\nExecAction\x12\x0f\n\x07\x63ommand\x18\x01 \x03(\t\"b\n\x0e\x46\x43VolumeSource\x12\x12\n\ntargetWWNs\x18\x01 \x03(\t\x12\x0b\n\x03lun\x18\x02 \x01(\x05\x12\x0e\n\x06\x66sType\x18\x03 \x01(\t\x12\x10\n\x08readOnly\x18\x04 \x01(\x08\x12\r\n\x05wwids\x18\x05 \x03(\t\"\x84\x02\n\x1a\x46lexPersistentVolumeSource\x12\x0e\n\x06\x64river\x18\x01 \x01(\t\x12\x0e\n\x06\x66sType\x18\x02 \x01(\t\x12\x36\n\tsecretRef\x18\x03 \x01(\x0b\x32#.k8s.io.api.core.v1.SecretReference\x12\x10\n\x08readOnly\x18\x04 \x01(\x08\x12L\n\x07options\x18\x05 \x03(\x0b\x32;.k8s.io.api.core.v1.FlexPersistentVolumeSource.OptionsEntry\x1a.\n\x0cOptionsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"\xf5\x01\n\x10\x46lexVolumeSource\x12\x0e\n\x06\x64river\x18\x01 \x01(\t\x12\x0e\n\x06\x66sType\x18\x02 \x01(\t\x12;\n\tsecretRef\x18\x03 \x01(\x0b\x32(.k8s.io.api.core.v1.LocalObjectReference\x12\x10\n\x08readOnly\x18\x04 \x01(\x08\x12\x42\n\x07options\x18\x05 \x03(\x0b\x32\x31.k8s.io.api.core.v1.FlexVolumeSource.OptionsEntry\x1a.\n\x0cOptionsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"?\n\x13\x46lockerVolumeSource\x12\x13\n\x0b\x64\x61tasetName\x18\x01 \x01(\t\x12\x13\n\x0b\x64\x61tasetUUID\x18\x02 \x01(\t\"d\n\x1dGCEPersistentDiskVolumeSource\x12\x0e\n\x06pdName\x18\x01 \x01(\t\x12\x0e\n\x06\x66sType\x18\x02 \x01(\t\x12\x11\n\tpartition\x18\x03 \x01(\x05\x12\x10\n\x08readOnly\x18\x04 \x01(\x08\"N\n\x13GitRepoVolumeSource\x12\x12\n\nrepository\x18\x01 \x01(\t\x12\x10\n\x08revision\x18\x02 \x01(\t\x12\x11\n\tdirectory\x18\x03 \x01(\t\"p\n\x1fGlusterfsPersistentVolumeSource\x12\x11\n\tendpoints\x18\x01 \x01(\t\x12\x0c\n\x04path\x18\x02 \x01(\t\x12\x10\n\x08readOnly\x18\x03 \x01(\x08\x12\x1a\n\x12\x65ndpointsNamespace\x18\x04 \x01(\t\"J\n\x15GlusterfsVolumeSource\x12\x11\n\tendpoints\x18\x01 \x01(\t\x12\x0c\n\x04path\x18\x02 \x01(\t\x12\x10\n\x08readOnly\x18\x03 \x01(\x08\"\xb0\x01\n\rHTTPGetAction\x12\x0c\n\x04path\x18\x01 \x01(\t\x12>\n\x04port\x18\x02 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.util.intstr.IntOrString\x12\x0c\n\x04host\x18\x03 \x01(\t\x12\x0e\n\x06scheme\x18\x04 \x01(\t\x12\x33\n\x0bhttpHeaders\x18\x05 \x03(\x0b\x32\x1e.k8s.io.api.core.v1.HTTPHeader\")\n\nHTTPHeader\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t\"\xa3\x01\n\x07Handler\x12,\n\x04\x65xec\x18\x01 \x01(\x0b\x32\x1e.k8s.io.api.core.v1.ExecAction\x12\x32\n\x07httpGet\x18\x02 \x01(\x0b\x32!.k8s.io.api.core.v1.HTTPGetAction\x12\x36\n\ttcpSocket\x18\x03 \x01(\x0b\x32#.k8s.io.api.core.v1.TCPSocketAction\"*\n\tHostAlias\x12\n\n\x02ip\x18\x01 \x01(\t\x12\x11\n\thostnames\x18\x02 \x03(\t\"2\n\x14HostPathVolumeSource\x12\x0c\n\x04path\x18\x01 \x01(\t\x12\x0c\n\x04type\x18\x02 \x01(\t\"\x9b\x02\n\x1bISCSIPersistentVolumeSource\x12\x14\n\x0ctargetPortal\x18\x01 \x01(\t\x12\x0b\n\x03iqn\x18\x02 \x01(\t\x12\x0b\n\x03lun\x18\x03 \x01(\x05\x12\x16\n\x0eiscsiInterface\x18\x04 \x01(\t\x12\x0e\n\x06\x66sType\x18\x05 \x01(\t\x12\x10\n\x08readOnly\x18\x06 \x01(\x08\x12\x0f\n\x07portals\x18\x07 \x03(\t\x12\x19\n\x11\x63hapAuthDiscovery\x18\x08 \x01(\x08\x12\x17\n\x0f\x63hapAuthSession\x18\x0b \x01(\x08\x12\x36\n\tsecretRef\x18\n \x01(\x0b\x32#.k8s.io.api.core.v1.SecretReference\x12\x15\n\rinitiatorName\x18\x0c \x01(\t\"\x96\x02\n\x11ISCSIVolumeSource\x12\x14\n\x0ctargetPortal\x18\x01 \x01(\t\x12\x0b\n\x03iqn\x18\x02 \x01(\t\x12\x0b\n\x03lun\x18\x03 \x01(\x05\x12\x16\n\x0eiscsiInterface\x18\x04 \x01(\t\x12\x0e\n\x06\x66sType\x18\x05 \x01(\t\x12\x10\n\x08readOnly\x18\x06 \x01(\x08\x12\x0f\n\x07portals\x18\x07 \x03(\t\x12\x19\n\x11\x63hapAuthDiscovery\x18\x08 \x01(\x08\x12\x17\n\x0f\x63hapAuthSession\x18\x0b \x01(\x08\x12;\n\tsecretRef\x18\n \x01(\x0b\x32(.k8s.io.api.core.v1.LocalObjectReference\x12\x15\n\rinitiatorName\x18\x0c \x01(\t\"4\n\tKeyToPath\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x0c\n\x04path\x18\x02 \x01(\t\x12\x0c\n\x04mode\x18\x03 \x01(\x05\"i\n\tLifecycle\x12.\n\tpostStart\x18\x01 \x01(\x0b\x32\x1b.k8s.io.api.core.v1.Handler\x12,\n\x07preStop\x18\x02 \x01(\x0b\x32\x1b.k8s.io.api.core.v1.Handler\"\x82\x01\n\nLimitRange\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12\x30\n\x04spec\x18\x02 \x01(\x0b\x32\".k8s.io.api.core.v1.LimitRangeSpec\"\xec\x06\n\x0eLimitRangeItem\x12\x0c\n\x04type\x18\x01 \x01(\t\x12\x38\n\x03max\x18\x02 \x03(\x0b\x32+.k8s.io.api.core.v1.LimitRangeItem.MaxEntry\x12\x38\n\x03min\x18\x03 \x03(\x0b\x32+.k8s.io.api.core.v1.LimitRangeItem.MinEntry\x12@\n\x07\x64\x65\x66\x61ult\x18\x04 \x03(\x0b\x32/.k8s.io.api.core.v1.LimitRangeItem.DefaultEntry\x12N\n\x0e\x64\x65\x66\x61ultRequest\x18\x05 \x03(\x0b\x32\x36.k8s.io.api.core.v1.LimitRangeItem.DefaultRequestEntry\x12Z\n\x14maxLimitRequestRatio\x18\x06 \x03(\x0b\x32<.k8s.io.api.core.v1.LimitRangeItem.MaxLimitRequestRatioEntry\x1aZ\n\x08MaxEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\x1aZ\n\x08MinEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\x1a^\n\x0c\x44\x65\x66\x61ultEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\x1a\x65\n\x13\x44\x65\x66\x61ultRequestEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\x1ak\n\x19MaxLimitRequestRatioEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\"\x81\x01\n\x0eLimitRangeList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12-\n\x05items\x18\x02 \x03(\x0b\x32\x1e.k8s.io.api.core.v1.LimitRange\"D\n\x0eLimitRangeSpec\x12\x32\n\x06limits\x18\x01 \x03(\x0b\x32\".k8s.io.api.core.v1.LimitRangeItem\"\x86\x01\n\x04List\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12<\n\x05items\x18\x02 \x03(\x0b\x32-.k8s.io.apimachinery.pkg.runtime.RawExtension\"b\n\x13LoadBalancerIngress\x12\n\n\x02ip\x18\x01 \x01(\t\x12\x10\n\x08hostname\x18\x02 \x01(\t\x12-\n\x05ports\x18\x04 \x03(\x0b\x32\x1e.k8s.io.api.core.v1.PortStatus\"N\n\x12LoadBalancerStatus\x12\x38\n\x07ingress\x18\x01 \x03(\x0b\x32\'.k8s.io.api.core.v1.LoadBalancerIngress\"$\n\x14LocalObjectReference\x12\x0c\n\x04name\x18\x01 \x01(\t\"1\n\x11LocalVolumeSource\x12\x0c\n\x04path\x18\x01 \x01(\t\x12\x0e\n\x06\x66sType\x18\x02 \x01(\t\"A\n\x0fNFSVolumeSource\x12\x0e\n\x06server\x18\x01 \x01(\t\x12\x0c\n\x04path\x18\x02 \x01(\t\x12\x10\n\x08readOnly\x18\x03 \x01(\x08\"\xb5\x01\n\tNamespace\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12/\n\x04spec\x18\x02 \x01(\x0b\x32!.k8s.io.api.core.v1.NamespaceSpec\x12\x33\n\x06status\x18\x03 \x01(\x0b\x32#.k8s.io.api.core.v1.NamespaceStatus\"\x9b\x01\n\x12NamespaceCondition\x12\x0c\n\x04type\x18\x01 \x01(\t\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x46\n\x12lastTransitionTime\x18\x04 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\x12\x0e\n\x06reason\x18\x05 \x01(\t\x12\x0f\n\x07message\x18\x06 \x01(\t\"\x7f\n\rNamespaceList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12,\n\x05items\x18\x02 \x03(\x0b\x32\x1d.k8s.io.api.core.v1.Namespace\"#\n\rNamespaceSpec\x12\x12\n\nfinalizers\x18\x01 \x03(\t\"\\\n\x0fNamespaceStatus\x12\r\n\x05phase\x18\x01 \x01(\t\x12:\n\nconditions\x18\x02 \x03(\x0b\x32&.k8s.io.api.core.v1.NamespaceCondition\"\xa6\x01\n\x04Node\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12*\n\x04spec\x18\x02 \x01(\x0b\x32\x1c.k8s.io.api.core.v1.NodeSpec\x12.\n\x06status\x18\x03 \x01(\x0b\x32\x1e.k8s.io.api.core.v1.NodeStatus\",\n\x0bNodeAddress\x12\x0c\n\x04type\x18\x01 \x01(\t\x12\x0f\n\x07\x61\x64\x64ress\x18\x02 \x01(\t\"\xce\x01\n\x0cNodeAffinity\x12X\n.requiredDuringSchedulingIgnoredDuringExecution\x18\x01 \x01(\x0b\x32 .k8s.io.api.core.v1.NodeSelector\x12\x64\n/preferredDuringSchedulingIgnoredDuringExecution\x18\x02 \x03(\x0b\x32+.k8s.io.api.core.v1.PreferredSchedulingTerm\"\xdd\x01\n\rNodeCondition\x12\x0c\n\x04type\x18\x01 \x01(\t\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x45\n\x11lastHeartbeatTime\x18\x03 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\x12\x46\n\x12lastTransitionTime\x18\x04 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\x12\x0e\n\x06reason\x18\x05 \x01(\t\x12\x0f\n\x07message\x18\x06 \x01(\t\"T\n\x10NodeConfigSource\x12@\n\tconfigMap\x18\x02 \x01(\x0b\x32-.k8s.io.api.core.v1.ConfigMapNodeConfigSource\"\xcc\x01\n\x10NodeConfigStatus\x12\x36\n\x08\x61ssigned\x18\x01 \x01(\x0b\x32$.k8s.io.api.core.v1.NodeConfigSource\x12\x34\n\x06\x61\x63tive\x18\x02 \x01(\x0b\x32$.k8s.io.api.core.v1.NodeConfigSource\x12;\n\rlastKnownGood\x18\x03 \x01(\x0b\x32$.k8s.io.api.core.v1.NodeConfigSource\x12\r\n\x05\x65rror\x18\x04 \x01(\t\"R\n\x13NodeDaemonEndpoints\x12;\n\x0fkubeletEndpoint\x18\x01 \x01(\x0b\x32\".k8s.io.api.core.v1.DaemonEndpoint\"u\n\x08NodeList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12\'\n\x05items\x18\x02 \x03(\x0b\x32\x18.k8s.io.api.core.v1.Node\" \n\x10NodeProxyOptions\x12\x0c\n\x04path\x18\x01 \x01(\t\"\xb3\x01\n\rNodeResources\x12\x41\n\x08\x63\x61pacity\x18\x01 \x03(\x0b\x32/.k8s.io.api.core.v1.NodeResources.CapacityEntry\x1a_\n\rCapacityEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\"O\n\x0cNodeSelector\x12?\n\x11nodeSelectorTerms\x18\x01 \x03(\x0b\x32$.k8s.io.api.core.v1.NodeSelectorTerm\"H\n\x17NodeSelectorRequirement\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x10\n\x08operator\x18\x02 \x01(\t\x12\x0e\n\x06values\x18\x03 \x03(\t\"\x9b\x01\n\x10NodeSelectorTerm\x12\x45\n\x10matchExpressions\x18\x01 \x03(\x0b\x32+.k8s.io.api.core.v1.NodeSelectorRequirement\x12@\n\x0bmatchFields\x18\x02 \x03(\x0b\x32+.k8s.io.api.core.v1.NodeSelectorRequirement\"\xd3\x01\n\x08NodeSpec\x12\x0f\n\x07podCIDR\x18\x01 \x01(\t\x12\x10\n\x08podCIDRs\x18\x07 \x03(\t\x12\x12\n\nproviderID\x18\x03 \x01(\t\x12\x15\n\runschedulable\x18\x04 \x01(\x08\x12)\n\x06taints\x18\x05 \x03(\x0b\x32\x19.k8s.io.api.core.v1.Taint\x12:\n\x0c\x63onfigSource\x18\x06 \x01(\x0b\x32$.k8s.io.api.core.v1.NodeConfigSource\x12\x12\n\nexternalID\x18\x02 \x01(\t\"\x86\x06\n\nNodeStatus\x12>\n\x08\x63\x61pacity\x18\x01 \x03(\x0b\x32,.k8s.io.api.core.v1.NodeStatus.CapacityEntry\x12\x44\n\x0b\x61llocatable\x18\x02 \x03(\x0b\x32/.k8s.io.api.core.v1.NodeStatus.AllocatableEntry\x12\r\n\x05phase\x18\x03 \x01(\t\x12\x35\n\nconditions\x18\x04 \x03(\x0b\x32!.k8s.io.api.core.v1.NodeCondition\x12\x32\n\taddresses\x18\x05 \x03(\x0b\x32\x1f.k8s.io.api.core.v1.NodeAddress\x12@\n\x0f\x64\x61\x65monEndpoints\x18\x06 \x01(\x0b\x32\'.k8s.io.api.core.v1.NodeDaemonEndpoints\x12\x34\n\x08nodeInfo\x18\x07 \x01(\x0b\x32\".k8s.io.api.core.v1.NodeSystemInfo\x12\x32\n\x06images\x18\x08 \x03(\x0b\x32\".k8s.io.api.core.v1.ContainerImage\x12\x14\n\x0cvolumesInUse\x18\t \x03(\t\x12;\n\x0fvolumesAttached\x18\n \x03(\x0b\x32\".k8s.io.api.core.v1.AttachedVolume\x12\x34\n\x06\x63onfig\x18\x0b \x01(\x0b\x32$.k8s.io.api.core.v1.NodeConfigStatus\x1a_\n\rCapacityEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\x1a\x62\n\x10\x41llocatableEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\"\xf1\x01\n\x0eNodeSystemInfo\x12\x11\n\tmachineID\x18\x01 \x01(\t\x12\x12\n\nsystemUUID\x18\x02 \x01(\t\x12\x0e\n\x06\x62ootID\x18\x03 \x01(\t\x12\x15\n\rkernelVersion\x18\x04 \x01(\t\x12\x0f\n\x07osImage\x18\x05 \x01(\t\x12\x1f\n\x17\x63ontainerRuntimeVersion\x18\x06 \x01(\t\x12\x16\n\x0ekubeletVersion\x18\x07 \x01(\t\x12\x18\n\x10kubeProxyVersion\x18\x08 \x01(\t\x12\x17\n\x0foperatingSystem\x18\t \x01(\t\x12\x14\n\x0c\x61rchitecture\x18\n \x01(\t\"<\n\x13ObjectFieldSelector\x12\x12\n\napiVersion\x18\x01 \x01(\t\x12\x11\n\tfieldPath\x18\x02 \x01(\t\"\x8d\x01\n\x0fObjectReference\x12\x0c\n\x04kind\x18\x01 \x01(\t\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x0b\n\x03uid\x18\x04 \x01(\t\x12\x12\n\napiVersion\x18\x05 \x01(\t\x12\x17\n\x0fresourceVersion\x18\x06 \x01(\t\x12\x11\n\tfieldPath\x18\x07 \x01(\t\"\xca\x01\n\x10PersistentVolume\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12\x36\n\x04spec\x18\x02 \x01(\x0b\x32(.k8s.io.api.core.v1.PersistentVolumeSpec\x12:\n\x06status\x18\x03 \x01(\x0b\x32*.k8s.io.api.core.v1.PersistentVolumeStatus\"\xd9\x01\n\x15PersistentVolumeClaim\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12;\n\x04spec\x18\x02 \x01(\x0b\x32-.k8s.io.api.core.v1.PersistentVolumeClaimSpec\x12?\n\x06status\x18\x03 \x01(\x0b\x32/.k8s.io.api.core.v1.PersistentVolumeClaimStatus\"\xea\x01\n\x1ePersistentVolumeClaimCondition\x12\x0c\n\x04type\x18\x01 \x01(\t\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x41\n\rlastProbeTime\x18\x03 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\x12\x46\n\x12lastTransitionTime\x18\x04 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\x12\x0e\n\x06reason\x18\x05 \x01(\t\x12\x0f\n\x07message\x18\x06 \x01(\t\"\x97\x01\n\x19PersistentVolumeClaimList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12\x38\n\x05items\x18\x02 \x03(\x0b\x32).k8s.io.api.core.v1.PersistentVolumeClaim\"\xff\x02\n\x19PersistentVolumeClaimSpec\x12\x13\n\x0b\x61\x63\x63\x65ssModes\x18\x01 \x03(\t\x12\x45\n\x08selector\x18\x04 \x01(\x0b\x32\x33.k8s.io.apimachinery.pkg.apis.meta.v1.LabelSelector\x12;\n\tresources\x18\x02 \x01(\x0b\x32(.k8s.io.api.core.v1.ResourceRequirements\x12\x12\n\nvolumeName\x18\x03 \x01(\t\x12\x18\n\x10storageClassName\x18\x05 \x01(\t\x12\x12\n\nvolumeMode\x18\x06 \x01(\t\x12\x41\n\ndataSource\x18\x07 \x01(\x0b\x32-.k8s.io.api.core.v1.TypedLocalObjectReference\x12\x44\n\rdataSourceRef\x18\x08 \x01(\x0b\x32-.k8s.io.api.core.v1.TypedLocalObjectReference\"\xbb\x02\n\x1bPersistentVolumeClaimStatus\x12\r\n\x05phase\x18\x01 \x01(\t\x12\x13\n\x0b\x61\x63\x63\x65ssModes\x18\x02 \x03(\t\x12O\n\x08\x63\x61pacity\x18\x03 \x03(\x0b\x32=.k8s.io.api.core.v1.PersistentVolumeClaimStatus.CapacityEntry\x12\x46\n\nconditions\x18\x04 \x03(\x0b\x32\x32.k8s.io.api.core.v1.PersistentVolumeClaimCondition\x1a_\n\rCapacityEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\"\xa0\x01\n\x1dPersistentVolumeClaimTemplate\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12;\n\x04spec\x18\x02 \x01(\x0b\x32-.k8s.io.api.core.v1.PersistentVolumeClaimSpec\"H\n!PersistentVolumeClaimVolumeSource\x12\x11\n\tclaimName\x18\x01 \x01(\t\x12\x10\n\x08readOnly\x18\x02 \x01(\x08\"\x8d\x01\n\x14PersistentVolumeList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12\x33\n\x05items\x18\x02 \x03(\x0b\x32$.k8s.io.api.core.v1.PersistentVolume\"\xbd\x0b\n\x16PersistentVolumeSource\x12L\n\x11gcePersistentDisk\x18\x01 \x01(\x0b\x32\x31.k8s.io.api.core.v1.GCEPersistentDiskVolumeSource\x12R\n\x14\x61wsElasticBlockStore\x18\x02 \x01(\x0b\x32\x34.k8s.io.api.core.v1.AWSElasticBlockStoreVolumeSource\x12:\n\x08hostPath\x18\x03 \x01(\x0b\x32(.k8s.io.api.core.v1.HostPathVolumeSource\x12\x46\n\tglusterfs\x18\x04 \x01(\x0b\x32\x33.k8s.io.api.core.v1.GlusterfsPersistentVolumeSource\x12\x30\n\x03nfs\x18\x05 \x01(\x0b\x32#.k8s.io.api.core.v1.NFSVolumeSource\x12:\n\x03rbd\x18\x06 \x01(\x0b\x32-.k8s.io.api.core.v1.RBDPersistentVolumeSource\x12>\n\x05iscsi\x18\x07 \x01(\x0b\x32/.k8s.io.api.core.v1.ISCSIPersistentVolumeSource\x12@\n\x06\x63inder\x18\x08 \x01(\x0b\x32\x30.k8s.io.api.core.v1.CinderPersistentVolumeSource\x12@\n\x06\x63\x65phfs\x18\t \x01(\x0b\x32\x30.k8s.io.api.core.v1.CephFSPersistentVolumeSource\x12.\n\x02\x66\x63\x18\n \x01(\x0b\x32\".k8s.io.api.core.v1.FCVolumeSource\x12\x38\n\x07\x66locker\x18\x0b \x01(\x0b\x32\'.k8s.io.api.core.v1.FlockerVolumeSource\x12\x42\n\nflexVolume\x18\x0c \x01(\x0b\x32..k8s.io.api.core.v1.FlexPersistentVolumeSource\x12\x46\n\tazureFile\x18\r \x01(\x0b\x32\x33.k8s.io.api.core.v1.AzureFilePersistentVolumeSource\x12I\n\rvsphereVolume\x18\x0e \x01(\x0b\x32\x32.k8s.io.api.core.v1.VsphereVirtualDiskVolumeSource\x12\x38\n\x07quobyte\x18\x0f \x01(\x0b\x32\'.k8s.io.api.core.v1.QuobyteVolumeSource\x12<\n\tazureDisk\x18\x10 \x01(\x0b\x32).k8s.io.api.core.v1.AzureDiskVolumeSource\x12R\n\x14photonPersistentDisk\x18\x11 \x01(\x0b\x32\x34.k8s.io.api.core.v1.PhotonPersistentDiskVolumeSource\x12@\n\x0eportworxVolume\x18\x12 \x01(\x0b\x32(.k8s.io.api.core.v1.PortworxVolumeSource\x12\x42\n\x07scaleIO\x18\x13 \x01(\x0b\x32\x31.k8s.io.api.core.v1.ScaleIOPersistentVolumeSource\x12\x34\n\x05local\x18\x14 \x01(\x0b\x32%.k8s.io.api.core.v1.LocalVolumeSource\x12\x46\n\tstorageos\x18\x15 \x01(\x0b\x32\x33.k8s.io.api.core.v1.StorageOSPersistentVolumeSource\x12:\n\x03\x63si\x18\x16 \x01(\x0b\x32-.k8s.io.api.core.v1.CSIPersistentVolumeSource\"\x82\x04\n\x14PersistentVolumeSpec\x12H\n\x08\x63\x61pacity\x18\x01 \x03(\x0b\x32\x36.k8s.io.api.core.v1.PersistentVolumeSpec.CapacityEntry\x12J\n\x16persistentVolumeSource\x18\x02 \x01(\x0b\x32*.k8s.io.api.core.v1.PersistentVolumeSource\x12\x13\n\x0b\x61\x63\x63\x65ssModes\x18\x03 \x03(\t\x12\x35\n\x08\x63laimRef\x18\x04 \x01(\x0b\x32#.k8s.io.api.core.v1.ObjectReference\x12%\n\x1dpersistentVolumeReclaimPolicy\x18\x05 \x01(\t\x12\x18\n\x10storageClassName\x18\x06 \x01(\t\x12\x14\n\x0cmountOptions\x18\x07 \x03(\t\x12\x12\n\nvolumeMode\x18\x08 \x01(\t\x12<\n\x0cnodeAffinity\x18\t \x01(\x0b\x32&.k8s.io.api.core.v1.VolumeNodeAffinity\x1a_\n\rCapacityEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\"H\n\x16PersistentVolumeStatus\x12\r\n\x05phase\x18\x01 \x01(\t\x12\x0f\n\x07message\x18\x02 \x01(\t\x12\x0e\n\x06reason\x18\x03 \x01(\t\"@\n PhotonPersistentDiskVolumeSource\x12\x0c\n\x04pdID\x18\x01 \x01(\t\x12\x0e\n\x06\x66sType\x18\x02 \x01(\t\"\xa3\x01\n\x03Pod\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12)\n\x04spec\x18\x02 \x01(\x0b\x32\x1b.k8s.io.api.core.v1.PodSpec\x12-\n\x06status\x18\x03 \x01(\x0b\x32\x1d.k8s.io.api.core.v1.PodStatus\"\xd0\x01\n\x0bPodAffinity\x12[\n.requiredDuringSchedulingIgnoredDuringExecution\x18\x01 \x03(\x0b\x32#.k8s.io.api.core.v1.PodAffinityTerm\x12\x64\n/preferredDuringSchedulingIgnoredDuringExecution\x18\x02 \x03(\x0b\x32+.k8s.io.api.core.v1.WeightedPodAffinityTerm\"\xd6\x01\n\x0fPodAffinityTerm\x12J\n\rlabelSelector\x18\x01 \x01(\x0b\x32\x33.k8s.io.apimachinery.pkg.apis.meta.v1.LabelSelector\x12\x12\n\nnamespaces\x18\x02 \x03(\t\x12\x13\n\x0btopologyKey\x18\x03 \x01(\t\x12N\n\x11namespaceSelector\x18\x04 \x01(\x0b\x32\x33.k8s.io.apimachinery.pkg.apis.meta.v1.LabelSelector\"\xd4\x01\n\x0fPodAntiAffinity\x12[\n.requiredDuringSchedulingIgnoredDuringExecution\x18\x01 \x03(\x0b\x32#.k8s.io.api.core.v1.PodAffinityTerm\x12\x64\n/preferredDuringSchedulingIgnoredDuringExecution\x18\x02 \x03(\x0b\x32+.k8s.io.api.core.v1.WeightedPodAffinityTerm\"a\n\x10PodAttachOptions\x12\r\n\x05stdin\x18\x01 \x01(\x08\x12\x0e\n\x06stdout\x18\x02 \x01(\x08\x12\x0e\n\x06stderr\x18\x03 \x01(\x08\x12\x0b\n\x03tty\x18\x04 \x01(\x08\x12\x11\n\tcontainer\x18\x05 \x01(\t\"\xd8\x01\n\x0cPodCondition\x12\x0c\n\x04type\x18\x01 \x01(\t\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x41\n\rlastProbeTime\x18\x03 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\x12\x46\n\x12lastTransitionTime\x18\x04 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\x12\x0e\n\x06reason\x18\x05 \x01(\t\x12\x0f\n\x07message\x18\x06 \x01(\t\"n\n\x0cPodDNSConfig\x12\x13\n\x0bnameservers\x18\x01 \x03(\t\x12\x10\n\x08searches\x18\x02 \x03(\t\x12\x37\n\x07options\x18\x03 \x03(\x0b\x32&.k8s.io.api.core.v1.PodDNSConfigOption\"1\n\x12PodDNSConfigOption\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t\"p\n\x0ePodExecOptions\x12\r\n\x05stdin\x18\x01 \x01(\x08\x12\x0e\n\x06stdout\x18\x02 \x01(\x08\x12\x0e\n\x06stderr\x18\x03 \x01(\x08\x12\x0b\n\x03tty\x18\x04 \x01(\x08\x12\x11\n\tcontainer\x18\x05 \x01(\t\x12\x0f\n\x07\x63ommand\x18\x06 \x03(\t\"\x13\n\x05PodIP\x12\n\n\x02ip\x18\x01 \x01(\t\"s\n\x07PodList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12&\n\x05items\x18\x02 \x03(\x0b\x32\x17.k8s.io.api.core.v1.Pod\"\xfa\x01\n\rPodLogOptions\x12\x11\n\tcontainer\x18\x01 \x01(\t\x12\x0e\n\x06\x66ollow\x18\x02 \x01(\x08\x12\x10\n\x08previous\x18\x03 \x01(\x08\x12\x14\n\x0csinceSeconds\x18\x04 \x01(\x03\x12=\n\tsinceTime\x18\x05 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\x12\x12\n\ntimestamps\x18\x06 \x01(\x08\x12\x11\n\ttailLines\x18\x07 \x01(\x03\x12\x12\n\nlimitBytes\x18\x08 \x01(\x03\x12$\n\x1cinsecureSkipTLSVerifyBackend\x18\t \x01(\x08\"&\n\x15PodPortForwardOptions\x12\r\n\x05ports\x18\x01 \x03(\x05\"\x1f\n\x0fPodProxyOptions\x12\x0c\n\x04path\x18\x01 \x01(\t\")\n\x10PodReadinessGate\x12\x15\n\rconditionType\x18\x01 \x01(\t\"\x8b\x03\n\x12PodSecurityContext\x12:\n\x0eseLinuxOptions\x18\x01 \x01(\x0b\x32\".k8s.io.api.core.v1.SELinuxOptions\x12I\n\x0ewindowsOptions\x18\x08 \x01(\x0b\x32\x31.k8s.io.api.core.v1.WindowsSecurityContextOptions\x12\x11\n\trunAsUser\x18\x02 \x01(\x03\x12\x12\n\nrunAsGroup\x18\x06 \x01(\x03\x12\x14\n\x0crunAsNonRoot\x18\x03 \x01(\x08\x12\x1a\n\x12supplementalGroups\x18\x04 \x03(\x03\x12\x0f\n\x07\x66sGroup\x18\x05 \x01(\x03\x12+\n\x07sysctls\x18\x07 \x03(\x0b\x32\x1a.k8s.io.api.core.v1.Sysctl\x12\x1b\n\x13\x66sGroupChangePolicy\x18\t \x01(\t\x12:\n\x0eseccompProfile\x18\n \x01(\x0b\x32\".k8s.io.api.core.v1.SeccompProfile\"[\n\x0cPodSignature\x12K\n\rpodController\x18\x01 \x01(\x0b\x32\x34.k8s.io.apimachinery.pkg.apis.meta.v1.OwnerReference\"\xe5\x0b\n\x07PodSpec\x12+\n\x07volumes\x18\x01 \x03(\x0b\x32\x1a.k8s.io.api.core.v1.Volume\x12\x35\n\x0einitContainers\x18\x14 \x03(\x0b\x32\x1d.k8s.io.api.core.v1.Container\x12\x31\n\ncontainers\x18\x02 \x03(\x0b\x32\x1d.k8s.io.api.core.v1.Container\x12\x43\n\x13\x65phemeralContainers\x18\" \x03(\x0b\x32&.k8s.io.api.core.v1.EphemeralContainer\x12\x15\n\rrestartPolicy\x18\x03 \x01(\t\x12%\n\x1dterminationGracePeriodSeconds\x18\x04 \x01(\x03\x12\x1d\n\x15\x61\x63tiveDeadlineSeconds\x18\x05 \x01(\x03\x12\x11\n\tdnsPolicy\x18\x06 \x01(\t\x12\x43\n\x0cnodeSelector\x18\x07 \x03(\x0b\x32-.k8s.io.api.core.v1.PodSpec.NodeSelectorEntry\x12\x1a\n\x12serviceAccountName\x18\x08 \x01(\t\x12\x16\n\x0eserviceAccount\x18\t \x01(\t\x12$\n\x1c\x61utomountServiceAccountToken\x18\x15 \x01(\x08\x12\x10\n\x08nodeName\x18\n \x01(\t\x12\x13\n\x0bhostNetwork\x18\x0b \x01(\x08\x12\x0f\n\x07hostPID\x18\x0c \x01(\x08\x12\x0f\n\x07hostIPC\x18\r \x01(\x08\x12\x1d\n\x15shareProcessNamespace\x18\x1b \x01(\x08\x12?\n\x0fsecurityContext\x18\x0e \x01(\x0b\x32&.k8s.io.api.core.v1.PodSecurityContext\x12\x42\n\x10imagePullSecrets\x18\x0f \x03(\x0b\x32(.k8s.io.api.core.v1.LocalObjectReference\x12\x10\n\x08hostname\x18\x10 \x01(\t\x12\x11\n\tsubdomain\x18\x11 \x01(\t\x12.\n\x08\x61\x66\x66inity\x18\x12 \x01(\x0b\x32\x1c.k8s.io.api.core.v1.Affinity\x12\x15\n\rschedulerName\x18\x13 \x01(\t\x12\x33\n\x0btolerations\x18\x16 \x03(\x0b\x32\x1e.k8s.io.api.core.v1.Toleration\x12\x32\n\x0bhostAliases\x18\x17 \x03(\x0b\x32\x1d.k8s.io.api.core.v1.HostAlias\x12\x19\n\x11priorityClassName\x18\x18 \x01(\t\x12\x10\n\x08priority\x18\x19 \x01(\x05\x12\x33\n\tdnsConfig\x18\x1a \x01(\x0b\x32 .k8s.io.api.core.v1.PodDNSConfig\x12<\n\x0ereadinessGates\x18\x1c \x03(\x0b\x32$.k8s.io.api.core.v1.PodReadinessGate\x12\x18\n\x10runtimeClassName\x18\x1d \x01(\t\x12\x1a\n\x12\x65nableServiceLinks\x18\x1e \x01(\x08\x12\x18\n\x10preemptionPolicy\x18\x1f \x01(\t\x12;\n\x08overhead\x18  \x03(\x0b\x32).k8s.io.api.core.v1.PodSpec.OverheadEntry\x12O\n\x19topologySpreadConstraints\x18! \x03(\x0b\x32,.k8s.io.api.core.v1.TopologySpreadConstraint\x12\x19\n\x11setHostnameAsFQDN\x18# \x01(\x08\x1a\x33\n\x11NodeSelectorEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a_\n\rOverheadEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\"\xf4\x03\n\tPodStatus\x12\r\n\x05phase\x18\x01 \x01(\t\x12\x34\n\nconditions\x18\x02 \x03(\x0b\x32 .k8s.io.api.core.v1.PodCondition\x12\x0f\n\x07message\x18\x03 \x01(\t\x12\x0e\n\x06reason\x18\x04 \x01(\t\x12\x19\n\x11nominatedNodeName\x18\x0b \x01(\t\x12\x0e\n\x06hostIP\x18\x05 \x01(\t\x12\r\n\x05podIP\x18\x06 \x01(\t\x12)\n\x06podIPs\x18\x0c \x03(\x0b\x32\x19.k8s.io.api.core.v1.PodIP\x12=\n\tstartTime\x18\x07 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\x12\x42\n\x15initContainerStatuses\x18\n \x03(\x0b\x32#.k8s.io.api.core.v1.ContainerStatus\x12>\n\x11\x63ontainerStatuses\x18\x08 \x03(\x0b\x32#.k8s.io.api.core.v1.ContainerStatus\x12\x10\n\x08qosClass\x18\t \x01(\t\x12G\n\x1a\x65phemeralContainerStatuses\x18\r \x03(\x0b\x32#.k8s.io.api.core.v1.ContainerStatus\"\x84\x01\n\x0fPodStatusResult\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12-\n\x06status\x18\x02 \x01(\x0b\x32\x1d.k8s.io.api.core.v1.PodStatus\"\x88\x01\n\x0bPodTemplate\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12\x35\n\x08template\x18\x02 \x01(\x0b\x32#.k8s.io.api.core.v1.PodTemplateSpec\"\x83\x01\n\x0fPodTemplateList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12.\n\x05items\x18\x02 \x03(\x0b\x32\x1f.k8s.io.api.core.v1.PodTemplate\"\x80\x01\n\x0fPodTemplateSpec\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12)\n\x04spec\x18\x02 \x01(\x0b\x32\x1b.k8s.io.api.core.v1.PodSpec\";\n\nPortStatus\x12\x0c\n\x04port\x18\x01 \x01(\x05\x12\x10\n\x08protocol\x18\x02 \x01(\t\x12\r\n\x05\x65rror\x18\x03 \x01(\t\"J\n\x14PortworxVolumeSource\x12\x10\n\x08volumeID\x18\x01 \x01(\t\x12\x0e\n\x06\x66sType\x18\x02 \x01(\t\x12\x10\n\x08readOnly\x18\x03 \x01(\x08\"\x1c\n\rPreconditions\x12\x0b\n\x03uid\x18\x01 \x01(\t\"\xb1\x01\n\x14PreferAvoidPodsEntry\x12\x36\n\x0cpodSignature\x18\x01 \x01(\x0b\x32 .k8s.io.api.core.v1.PodSignature\x12@\n\x0c\x65victionTime\x18\x02 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\x12\x0e\n\x06reason\x18\x03 \x01(\t\x12\x0f\n\x07message\x18\x04 \x01(\t\"c\n\x17PreferredSchedulingTerm\x12\x0e\n\x06weight\x18\x01 \x01(\x05\x12\x38\n\npreference\x18\x02 \x01(\x0b\x32$.k8s.io.api.core.v1.NodeSelectorTerm\"\xdc\x01\n\x05Probe\x12,\n\x07handler\x18\x01 \x01(\x0b\x32\x1b.k8s.io.api.core.v1.Handler\x12\x1b\n\x13initialDelaySeconds\x18\x02 \x01(\x05\x12\x16\n\x0etimeoutSeconds\x18\x03 \x01(\x05\x12\x15\n\rperiodSeconds\x18\x04 \x01(\x05\x12\x18\n\x10successThreshold\x18\x05 \x01(\x05\x12\x18\n\x10\x66\x61ilureThreshold\x18\x06 \x01(\x05\x12%\n\x1dterminationGracePeriodSeconds\x18\x07 \x01(\x03\"c\n\x15ProjectedVolumeSource\x12\x35\n\x07sources\x18\x01 \x03(\x0b\x32$.k8s.io.api.core.v1.VolumeProjection\x12\x13\n\x0b\x64\x65\x66\x61ultMode\x18\x02 \x01(\x05\"v\n\x13QuobyteVolumeSource\x12\x10\n\x08registry\x18\x01 \x01(\t\x12\x0e\n\x06volume\x18\x02 \x01(\t\x12\x10\n\x08readOnly\x18\x03 \x01(\x08\x12\x0c\n\x04user\x18\x04 \x01(\t\x12\r\n\x05group\x18\x05 \x01(\t\x12\x0e\n\x06tenant\x18\x06 \x01(\t\"\xc3\x01\n\x19RBDPersistentVolumeSource\x12\x10\n\x08monitors\x18\x01 \x03(\t\x12\r\n\x05image\x18\x02 \x01(\t\x12\x0e\n\x06\x66sType\x18\x03 \x01(\t\x12\x0c\n\x04pool\x18\x04 \x01(\t\x12\x0c\n\x04user\x18\x05 \x01(\t\x12\x0f\n\x07keyring\x18\x06 \x01(\t\x12\x36\n\tsecretRef\x18\x07 \x01(\x0b\x32#.k8s.io.api.core.v1.SecretReference\x12\x10\n\x08readOnly\x18\x08 \x01(\x08\"\xbe\x01\n\x0fRBDVolumeSource\x12\x10\n\x08monitors\x18\x01 \x03(\t\x12\r\n\x05image\x18\x02 \x01(\t\x12\x0e\n\x06\x66sType\x18\x03 \x01(\t\x12\x0c\n\x04pool\x18\x04 \x01(\t\x12\x0c\n\x04user\x18\x05 \x01(\t\x12\x0f\n\x07keyring\x18\x06 \x01(\t\x12;\n\tsecretRef\x18\x07 \x01(\x0b\x32(.k8s.io.api.core.v1.LocalObjectReference\x12\x10\n\x08readOnly\x18\x08 \x01(\x08\"r\n\x0fRangeAllocation\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12\r\n\x05range\x18\x02 \x01(\t\x12\x0c\n\x04\x64\x61ta\x18\x03 \x01(\x0c\"\xd9\x01\n\x15ReplicationController\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12;\n\x04spec\x18\x02 \x01(\x0b\x32-.k8s.io.api.core.v1.ReplicationControllerSpec\x12?\n\x06status\x18\x03 \x01(\x0b\x32/.k8s.io.api.core.v1.ReplicationControllerStatus\"\xa7\x01\n\x1eReplicationControllerCondition\x12\x0c\n\x04type\x18\x01 \x01(\t\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x46\n\x12lastTransitionTime\x18\x03 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\x12\x0e\n\x06reason\x18\x04 \x01(\t\x12\x0f\n\x07message\x18\x05 \x01(\t\"\x97\x01\n\x19ReplicationControllerList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12\x38\n\x05items\x18\x02 \x03(\x0b\x32).k8s.io.api.core.v1.ReplicationController\"\xfd\x01\n\x19ReplicationControllerSpec\x12\x10\n\x08replicas\x18\x01 \x01(\x05\x12\x17\n\x0fminReadySeconds\x18\x04 \x01(\x05\x12M\n\x08selector\x18\x02 \x03(\x0b\x32;.k8s.io.api.core.v1.ReplicationControllerSpec.SelectorEntry\x12\x35\n\x08template\x18\x03 \x01(\x0b\x32#.k8s.io.api.core.v1.PodTemplateSpec\x1a/\n\rSelectorEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"\xe3\x01\n\x1bReplicationControllerStatus\x12\x10\n\x08replicas\x18\x01 \x01(\x05\x12\x1c\n\x14\x66ullyLabeledReplicas\x18\x02 \x01(\x05\x12\x15\n\rreadyReplicas\x18\x04 \x01(\x05\x12\x19\n\x11\x61vailableReplicas\x18\x05 \x01(\x05\x12\x1a\n\x12observedGeneration\x18\x03 \x01(\x03\x12\x46\n\nconditions\x18\x06 \x03(\x0b\x32\x32.k8s.io.api.core.v1.ReplicationControllerCondition\"\x81\x01\n\x15ResourceFieldSelector\x12\x15\n\rcontainerName\x18\x01 \x01(\t\x12\x10\n\x08resource\x18\x02 \x01(\t\x12?\n\x07\x64ivisor\x18\x03 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity\"\xc1\x01\n\rResourceQuota\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12\x33\n\x04spec\x18\x02 \x01(\x0b\x32%.k8s.io.api.core.v1.ResourceQuotaSpec\x12\x37\n\x06status\x18\x03 \x01(\x0b\x32\'.k8s.io.api.core.v1.ResourceQuotaStatus\"\x87\x01\n\x11ResourceQuotaList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12\x30\n\x05items\x18\x02 \x03(\x0b\x32!.k8s.io.api.core.v1.ResourceQuota\"\xf9\x01\n\x11ResourceQuotaSpec\x12=\n\x04hard\x18\x01 \x03(\x0b\x32/.k8s.io.api.core.v1.ResourceQuotaSpec.HardEntry\x12\x0e\n\x06scopes\x18\x02 \x03(\t\x12\x38\n\rscopeSelector\x18\x03 \x01(\x0b\x32!.k8s.io.api.core.v1.ScopeSelector\x1a[\n\tHardEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\"\xd1\x02\n\x13ResourceQuotaStatus\x12?\n\x04hard\x18\x01 \x03(\x0b\x32\x31.k8s.io.api.core.v1.ResourceQuotaStatus.HardEntry\x12?\n\x04used\x18\x02 \x03(\x0b\x32\x31.k8s.io.api.core.v1.ResourceQuotaStatus.UsedEntry\x1a[\n\tHardEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\x1a[\n\tUsedEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\"\xe6\x02\n\x14ResourceRequirements\x12\x44\n\x06limits\x18\x01 \x03(\x0b\x32\x34.k8s.io.api.core.v1.ResourceRequirements.LimitsEntry\x12H\n\x08requests\x18\x02 \x03(\x0b\x32\x36.k8s.io.api.core.v1.ResourceRequirements.RequestsEntry\x1a]\n\x0bLimitsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\x1a_\n\rRequestsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12=\n\x05value\x18\x02 \x01(\x0b\x32..k8s.io.apimachinery.pkg.api.resource.Quantity:\x02\x38\x01\"I\n\x0eSELinuxOptions\x12\x0c\n\x04user\x18\x01 \x01(\t\x12\x0c\n\x04role\x18\x02 \x01(\t\x12\x0c\n\x04type\x18\x03 \x01(\t\x12\r\n\x05level\x18\x04 \x01(\t\"\x86\x02\n\x1dScaleIOPersistentVolumeSource\x12\x0f\n\x07gateway\x18\x01 \x01(\t\x12\x0e\n\x06system\x18\x02 \x01(\t\x12\x36\n\tsecretRef\x18\x03 \x01(\x0b\x32#.k8s.io.api.core.v1.SecretReference\x12\x12\n\nsslEnabled\x18\x04 \x01(\x08\x12\x18\n\x10protectionDomain\x18\x05 \x01(\t\x12\x13\n\x0bstoragePool\x18\x06 \x01(\t\x12\x13\n\x0bstorageMode\x18\x07 \x01(\t\x12\x12\n\nvolumeName\x18\x08 \x01(\t\x12\x0e\n\x06\x66sType\x18\t \x01(\t\x12\x10\n\x08readOnly\x18\n \x01(\x08\"\x81\x02\n\x13ScaleIOVolumeSource\x12\x0f\n\x07gateway\x18\x01 \x01(\t\x12\x0e\n\x06system\x18\x02 \x01(\t\x12;\n\tsecretRef\x18\x03 \x01(\x0b\x32(.k8s.io.api.core.v1.LocalObjectReference\x12\x12\n\nsslEnabled\x18\x04 \x01(\x08\x12\x18\n\x10protectionDomain\x18\x05 \x01(\t\x12\x13\n\x0bstoragePool\x18\x06 \x01(\t\x12\x13\n\x0bstorageMode\x18\x07 \x01(\t\x12\x12\n\nvolumeName\x18\x08 \x01(\t\x12\x0e\n\x06\x66sType\x18\t \x01(\t\x12\x10\n\x08readOnly\x18\n \x01(\x08\"`\n\rScopeSelector\x12O\n\x10matchExpressions\x18\x01 \x03(\x0b\x32\x35.k8s.io.api.core.v1.ScopedResourceSelectorRequirement\"X\n!ScopedResourceSelectorRequirement\x12\x11\n\tscopeName\x18\x01 \x01(\t\x12\x10\n\x08operator\x18\x02 \x01(\t\x12\x0e\n\x06values\x18\x03 \x03(\t\"8\n\x0eSeccompProfile\x12\x0c\n\x04type\x18\x01 \x01(\t\x12\x18\n\x10localhostProfile\x18\x02 \x01(\t\"\xc1\x02\n\x06Secret\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12\x11\n\timmutable\x18\x05 \x01(\x08\x12\x32\n\x04\x64\x61ta\x18\x02 \x03(\x0b\x32$.k8s.io.api.core.v1.Secret.DataEntry\x12>\n\nstringData\x18\x04 \x03(\x0b\x32*.k8s.io.api.core.v1.Secret.StringDataEntry\x12\x0c\n\x04type\x18\x03 \x01(\t\x1a+\n\tDataEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\x0c:\x02\x38\x01\x1a\x31\n\x0fStringDataEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"k\n\x0fSecretEnvSource\x12\x46\n\x14localObjectReference\x18\x01 \x01(\x0b\x32(.k8s.io.api.core.v1.LocalObjectReference\x12\x10\n\x08optional\x18\x02 \x01(\x08\"z\n\x11SecretKeySelector\x12\x46\n\x14localObjectReference\x18\x01 \x01(\x0b\x32(.k8s.io.api.core.v1.LocalObjectReference\x12\x0b\n\x03key\x18\x02 \x01(\t\x12\x10\n\x08optional\x18\x03 \x01(\x08\"y\n\nSecretList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12)\n\x05items\x18\x02 \x03(\x0b\x32\x1a.k8s.io.api.core.v1.Secret\"\x9a\x01\n\x10SecretProjection\x12\x46\n\x14localObjectReference\x18\x01 \x01(\x0b\x32(.k8s.io.api.core.v1.LocalObjectReference\x12,\n\x05items\x18\x02 \x03(\x0b\x32\x1d.k8s.io.api.core.v1.KeyToPath\x12\x10\n\x08optional\x18\x04 \x01(\x08\"2\n\x0fSecretReference\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x11\n\tnamespace\x18\x02 \x01(\t\"}\n\x12SecretVolumeSource\x12\x12\n\nsecretName\x18\x01 \x01(\t\x12,\n\x05items\x18\x02 \x03(\x0b\x32\x1d.k8s.io.api.core.v1.KeyToPath\x12\x13\n\x0b\x64\x65\x66\x61ultMode\x18\x03 \x01(\x05\x12\x10\n\x08optional\x18\x04 \x01(\x08\"\xb2\x03\n\x0fSecurityContext\x12\x36\n\x0c\x63\x61pabilities\x18\x01 \x01(\x0b\x32 .k8s.io.api.core.v1.Capabilities\x12\x12\n\nprivileged\x18\x02 \x01(\x08\x12:\n\x0eseLinuxOptions\x18\x03 \x01(\x0b\x32\".k8s.io.api.core.v1.SELinuxOptions\x12I\n\x0ewindowsOptions\x18\n \x01(\x0b\x32\x31.k8s.io.api.core.v1.WindowsSecurityContextOptions\x12\x11\n\trunAsUser\x18\x04 \x01(\x03\x12\x12\n\nrunAsGroup\x18\x08 \x01(\x03\x12\x14\n\x0crunAsNonRoot\x18\x05 \x01(\x08\x12\x1e\n\x16readOnlyRootFilesystem\x18\x06 \x01(\x08\x12 \n\x18\x61llowPrivilegeEscalation\x18\x07 \x01(\x08\x12\x11\n\tprocMount\x18\t \x01(\t\x12:\n\x0eseccompProfile\x18\x0b \x01(\x0b\x32\".k8s.io.api.core.v1.SeccompProfile\"M\n\x13SerializedReference\x12\x36\n\treference\x18\x01 \x01(\x0b\x32#.k8s.io.api.core.v1.ObjectReference\"\xaf\x01\n\x07Service\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12-\n\x04spec\x18\x02 \x01(\x0b\x32\x1f.k8s.io.api.core.v1.ServiceSpec\x12\x31\n\x06status\x18\x03 \x01(\x0b\x32!.k8s.io.api.core.v1.ServiceStatus\"\xf4\x01\n\x0eServiceAccount\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12\x34\n\x07secrets\x18\x02 \x03(\x0b\x32#.k8s.io.api.core.v1.ObjectReference\x12\x42\n\x10imagePullSecrets\x18\x03 \x03(\x0b\x32(.k8s.io.api.core.v1.LocalObjectReference\x12$\n\x1c\x61utomountServiceAccountToken\x18\x04 \x01(\x08\"\x89\x01\n\x12ServiceAccountList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12\x31\n\x05items\x18\x02 \x03(\x0b\x32\".k8s.io.api.core.v1.ServiceAccount\"Z\n\x1dServiceAccountTokenProjection\x12\x10\n\x08\x61udience\x18\x01 \x01(\t\x12\x19\n\x11\x65xpirationSeconds\x18\x02 \x01(\x03\x12\x0c\n\x04path\x18\x03 \x01(\t\"{\n\x0bServiceList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12*\n\x05items\x18\x02 \x03(\x0b\x32\x1b.k8s.io.api.core.v1.Service\"\xa8\x01\n\x0bServicePort\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x10\n\x08protocol\x18\x02 \x01(\t\x12\x13\n\x0b\x61ppProtocol\x18\x06 \x01(\t\x12\x0c\n\x04port\x18\x03 \x01(\x05\x12\x44\n\ntargetPort\x18\x04 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.util.intstr.IntOrString\x12\x10\n\x08nodePort\x18\x05 \x01(\x05\"#\n\x13ServiceProxyOptions\x12\x0c\n\x04path\x18\x01 \x01(\t\"\x97\x05\n\x0bServiceSpec\x12.\n\x05ports\x18\x01 \x03(\x0b\x32\x1f.k8s.io.api.core.v1.ServicePort\x12?\n\x08selector\x18\x02 \x03(\x0b\x32-.k8s.io.api.core.v1.ServiceSpec.SelectorEntry\x12\x11\n\tclusterIP\x18\x03 \x01(\t\x12\x12\n\nclusterIPs\x18\x12 \x03(\t\x12\x0c\n\x04type\x18\x04 \x01(\t\x12\x13\n\x0b\x65xternalIPs\x18\x05 \x03(\t\x12\x17\n\x0fsessionAffinity\x18\x07 \x01(\t\x12\x16\n\x0eloadBalancerIP\x18\x08 \x01(\t\x12 \n\x18loadBalancerSourceRanges\x18\t \x03(\t\x12\x14\n\x0c\x65xternalName\x18\n \x01(\t\x12\x1d\n\x15\x65xternalTrafficPolicy\x18\x0b \x01(\t\x12\x1b\n\x13healthCheckNodePort\x18\x0c \x01(\x05\x12 \n\x18publishNotReadyAddresses\x18\r \x01(\x08\x12H\n\x15sessionAffinityConfig\x18\x0e \x01(\x0b\x32).k8s.io.api.core.v1.SessionAffinityConfig\x12\x12\n\nipFamilies\x18\x13 \x03(\t\x12\x16\n\x0eipFamilyPolicy\x18\x11 \x01(\t\x12%\n\x1d\x61llocateLoadBalancerNodePorts\x18\x14 \x01(\x08\x12\x19\n\x11loadBalancerClass\x18\x15 \x01(\t\x12\x1d\n\x15internalTrafficPolicy\x18\x16 \x01(\t\x1a/\n\rSelectorEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"\x92\x01\n\rServiceStatus\x12<\n\x0cloadBalancer\x18\x01 \x01(\x0b\x32&.k8s.io.api.core.v1.LoadBalancerStatus\x12\x43\n\nconditions\x18\x02 \x03(\x0b\x32/.k8s.io.apimachinery.pkg.apis.meta.v1.Condition\"M\n\x15SessionAffinityConfig\x12\x34\n\x08\x63lientIP\x18\x01 \x01(\x0b\x32\".k8s.io.api.core.v1.ClientIPConfig\"\xa8\x01\n\x1fStorageOSPersistentVolumeSource\x12\x12\n\nvolumeName\x18\x01 \x01(\t\x12\x17\n\x0fvolumeNamespace\x18\x02 \x01(\t\x12\x0e\n\x06\x66sType\x18\x03 \x01(\t\x12\x10\n\x08readOnly\x18\x04 \x01(\x08\x12\x36\n\tsecretRef\x18\x05 \x01(\x0b\x32#.k8s.io.api.core.v1.ObjectReference\"\xa3\x01\n\x15StorageOSVolumeSource\x12\x12\n\nvolumeName\x18\x01 \x01(\t\x12\x17\n\x0fvolumeNamespace\x18\x02 \x01(\t\x12\x0e\n\x06\x66sType\x18\x03 \x01(\t\x12\x10\n\x08readOnly\x18\x04 \x01(\x08\x12;\n\tsecretRef\x18\x05 \x01(\x0b\x32(.k8s.io.api.core.v1.LocalObjectReference\"%\n\x06Sysctl\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t\"_\n\x0fTCPSocketAction\x12>\n\x04port\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.util.intstr.IntOrString\x12\x0c\n\x04host\x18\x02 \x01(\t\"r\n\x05Taint\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t\x12\x0e\n\x06\x65\x66\x66\x65\x63t\x18\x03 \x01(\t\x12=\n\ttimeAdded\x18\x04 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\"e\n\nToleration\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x10\n\x08operator\x18\x02 \x01(\t\x12\r\n\x05value\x18\x03 \x01(\t\x12\x0e\n\x06\x65\x66\x66\x65\x63t\x18\x04 \x01(\t\x12\x19\n\x11tolerationSeconds\x18\x05 \x01(\x03\"?\n TopologySelectorLabelRequirement\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x0e\n\x06values\x18\x02 \x03(\t\"k\n\x14TopologySelectorTerm\x12S\n\x15matchLabelExpressions\x18\x01 \x03(\x0b\x32\x34.k8s.io.api.core.v1.TopologySelectorLabelRequirement\"\xa7\x01\n\x18TopologySpreadConstraint\x12\x0f\n\x07maxSkew\x18\x01 \x01(\x05\x12\x13\n\x0btopologyKey\x18\x02 \x01(\t\x12\x19\n\x11whenUnsatisfiable\x18\x03 \x01(\t\x12J\n\rlabelSelector\x18\x04 \x01(\x0b\x32\x33.k8s.io.apimachinery.pkg.apis.meta.v1.LabelSelector\"I\n\x19TypedLocalObjectReference\x12\x10\n\x08\x61piGroup\x18\x01 \x01(\t\x12\x0c\n\x04kind\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\"N\n\x06Volume\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x36\n\x0cvolumeSource\x18\x02 \x01(\x0b\x32 .k8s.io.api.core.v1.VolumeSource\"0\n\x0cVolumeDevice\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x12\n\ndevicePath\x18\x02 \x01(\t\"\x80\x01\n\x0bVolumeMount\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x10\n\x08readOnly\x18\x02 \x01(\x08\x12\x11\n\tmountPath\x18\x03 \x01(\t\x12\x0f\n\x07subPath\x18\x04 \x01(\t\x12\x18\n\x10mountPropagation\x18\x05 \x01(\t\x12\x13\n\x0bsubPathExpr\x18\x06 \x01(\t\"H\n\x12VolumeNodeAffinity\x12\x32\n\x08required\x18\x01 \x01(\x0b\x32 .k8s.io.api.core.v1.NodeSelector\"\x94\x02\n\x10VolumeProjection\x12\x34\n\x06secret\x18\x01 \x01(\x0b\x32$.k8s.io.api.core.v1.SecretProjection\x12>\n\x0b\x64ownwardAPI\x18\x02 \x01(\x0b\x32).k8s.io.api.core.v1.DownwardAPIProjection\x12:\n\tconfigMap\x18\x03 \x01(\x0b\x32\'.k8s.io.api.core.v1.ConfigMapProjection\x12N\n\x13serviceAccountToken\x18\x04 \x01(\x0b\x32\x31.k8s.io.api.core.v1.ServiceAccountTokenProjection\"\x99\x0e\n\x0cVolumeSource\x12:\n\x08hostPath\x18\x01 \x01(\x0b\x32(.k8s.io.api.core.v1.HostPathVolumeSource\x12:\n\x08\x65mptyDir\x18\x02 \x01(\x0b\x32(.k8s.io.api.core.v1.EmptyDirVolumeSource\x12L\n\x11gcePersistentDisk\x18\x03 \x01(\x0b\x32\x31.k8s.io.api.core.v1.GCEPersistentDiskVolumeSource\x12R\n\x14\x61wsElasticBlockStore\x18\x04 \x01(\x0b\x32\x34.k8s.io.api.core.v1.AWSElasticBlockStoreVolumeSource\x12\x38\n\x07gitRepo\x18\x05 \x01(\x0b\x32\'.k8s.io.api.core.v1.GitRepoVolumeSource\x12\x36\n\x06secret\x18\x06 \x01(\x0b\x32&.k8s.io.api.core.v1.SecretVolumeSource\x12\x30\n\x03nfs\x18\x07 \x01(\x0b\x32#.k8s.io.api.core.v1.NFSVolumeSource\x12\x34\n\x05iscsi\x18\x08 \x01(\x0b\x32%.k8s.io.api.core.v1.ISCSIVolumeSource\x12<\n\tglusterfs\x18\t \x01(\x0b\x32).k8s.io.api.core.v1.GlusterfsVolumeSource\x12T\n\x15persistentVolumeClaim\x18\n \x01(\x0b\x32\x35.k8s.io.api.core.v1.PersistentVolumeClaimVolumeSource\x12\x30\n\x03rbd\x18\x0b \x01(\x0b\x32#.k8s.io.api.core.v1.RBDVolumeSource\x12\x38\n\nflexVolume\x18\x0c \x01(\x0b\x32$.k8s.io.api.core.v1.FlexVolumeSource\x12\x36\n\x06\x63inder\x18\r \x01(\x0b\x32&.k8s.io.api.core.v1.CinderVolumeSource\x12\x36\n\x06\x63\x65phfs\x18\x0e \x01(\x0b\x32&.k8s.io.api.core.v1.CephFSVolumeSource\x12\x38\n\x07\x66locker\x18\x0f \x01(\x0b\x32\'.k8s.io.api.core.v1.FlockerVolumeSource\x12@\n\x0b\x64ownwardAPI\x18\x10 \x01(\x0b\x32+.k8s.io.api.core.v1.DownwardAPIVolumeSource\x12.\n\x02\x66\x63\x18\x11 \x01(\x0b\x32\".k8s.io.api.core.v1.FCVolumeSource\x12<\n\tazureFile\x18\x12 \x01(\x0b\x32).k8s.io.api.core.v1.AzureFileVolumeSource\x12<\n\tconfigMap\x18\x13 \x01(\x0b\x32).k8s.io.api.core.v1.ConfigMapVolumeSource\x12I\n\rvsphereVolume\x18\x14 \x01(\x0b\x32\x32.k8s.io.api.core.v1.VsphereVirtualDiskVolumeSource\x12\x38\n\x07quobyte\x18\x15 \x01(\x0b\x32\'.k8s.io.api.core.v1.QuobyteVolumeSource\x12<\n\tazureDisk\x18\x16 \x01(\x0b\x32).k8s.io.api.core.v1.AzureDiskVolumeSource\x12R\n\x14photonPersistentDisk\x18\x17 \x01(\x0b\x32\x34.k8s.io.api.core.v1.PhotonPersistentDiskVolumeSource\x12<\n\tprojected\x18\x1a \x01(\x0b\x32).k8s.io.api.core.v1.ProjectedVolumeSource\x12@\n\x0eportworxVolume\x18\x18 \x01(\x0b\x32(.k8s.io.api.core.v1.PortworxVolumeSource\x12\x38\n\x07scaleIO\x18\x19 \x01(\x0b\x32\'.k8s.io.api.core.v1.ScaleIOVolumeSource\x12<\n\tstorageos\x18\x1b \x01(\x0b\x32).k8s.io.api.core.v1.StorageOSVolumeSource\x12\x30\n\x03\x63si\x18\x1c \x01(\x0b\x32#.k8s.io.api.core.v1.CSIVolumeSource\x12<\n\tephemeral\x18\x1d \x01(\x0b\x32).k8s.io.api.core.v1.EphemeralVolumeSource\"x\n\x1eVsphereVirtualDiskVolumeSource\x12\x12\n\nvolumePath\x18\x01 \x01(\t\x12\x0e\n\x06\x66sType\x18\x02 \x01(\t\x12\x19\n\x11storagePolicyName\x18\x03 \x01(\t\x12\x17\n\x0fstoragePolicyID\x18\x04 \x01(\t\"g\n\x17WeightedPodAffinityTerm\x12\x0e\n\x06weight\x18\x01 \x01(\x05\x12<\n\x0fpodAffinityTerm\x18\x02 \x01(\x0b\x32#.k8s.io.api.core.v1.PodAffinityTerm\"\x87\x01\n\x1dWindowsSecurityContextOptions\x12\x1e\n\x16gmsaCredentialSpecName\x18\x01 \x01(\t\x12\x1a\n\x12gmsaCredentialSpec\x18\x02 \x01(\t\x12\x15\n\rrunAsUserName\x18\x03 \x01(\t\x12\x13\n\x0bhostProcess\x18\x04 \x01(\x08\x42\x04Z\x02v1')
 
 _globals = globals()
 _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
 _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'k8s.io.api.core.v1.generated_pb2', _globals)
-if _descriptor._USE_C_DESCRIPTORS == False:
-  _globals['DESCRIPTOR']._options = None
+if not _descriptor._USE_C_DESCRIPTORS:
+  _globals['DESCRIPTOR']._loaded_options = None
   _globals['DESCRIPTOR']._serialized_options = b'Z\002v1'
-  _globals['_CSIPERSISTENTVOLUMESOURCE_VOLUMEATTRIBUTESENTRY']._options = None
+  _globals['_CSIPERSISTENTVOLUMESOURCE_VOLUMEATTRIBUTESENTRY']._loaded_options = None
   _globals['_CSIPERSISTENTVOLUMESOURCE_VOLUMEATTRIBUTESENTRY']._serialized_options = b'8\001'
-  _globals['_CSIVOLUMESOURCE_VOLUMEATTRIBUTESENTRY']._options = None
+  _globals['_CSIVOLUMESOURCE_VOLUMEATTRIBUTESENTRY']._loaded_options = None
   _globals['_CSIVOLUMESOURCE_VOLUMEATTRIBUTESENTRY']._serialized_options = b'8\001'
-  _globals['_CONFIGMAP_DATAENTRY']._options = None
+  _globals['_CONFIGMAP_DATAENTRY']._loaded_options = None
   _globals['_CONFIGMAP_DATAENTRY']._serialized_options = b'8\001'
-  _globals['_CONFIGMAP_BINARYDATAENTRY']._options = None
+  _globals['_CONFIGMAP_BINARYDATAENTRY']._loaded_options = None
   _globals['_CONFIGMAP_BINARYDATAENTRY']._serialized_options = b'8\001'
-  _globals['_FLEXPERSISTENTVOLUMESOURCE_OPTIONSENTRY']._options = None
+  _globals['_FLEXPERSISTENTVOLUMESOURCE_OPTIONSENTRY']._loaded_options = None
   _globals['_FLEXPERSISTENTVOLUMESOURCE_OPTIONSENTRY']._serialized_options = b'8\001'
-  _globals['_FLEXVOLUMESOURCE_OPTIONSENTRY']._options = None
+  _globals['_FLEXVOLUMESOURCE_OPTIONSENTRY']._loaded_options = None
   _globals['_FLEXVOLUMESOURCE_OPTIONSENTRY']._serialized_options = b'8\001'
-  _globals['_LIMITRANGEITEM_MAXENTRY']._options = None
+  _globals['_LIMITRANGEITEM_MAXENTRY']._loaded_options = None
   _globals['_LIMITRANGEITEM_MAXENTRY']._serialized_options = b'8\001'
-  _globals['_LIMITRANGEITEM_MINENTRY']._options = None
+  _globals['_LIMITRANGEITEM_MINENTRY']._loaded_options = None
   _globals['_LIMITRANGEITEM_MINENTRY']._serialized_options = b'8\001'
-  _globals['_LIMITRANGEITEM_DEFAULTENTRY']._options = None
+  _globals['_LIMITRANGEITEM_DEFAULTENTRY']._loaded_options = None
   _globals['_LIMITRANGEITEM_DEFAULTENTRY']._serialized_options = b'8\001'
-  _globals['_LIMITRANGEITEM_DEFAULTREQUESTENTRY']._options = None
+  _globals['_LIMITRANGEITEM_DEFAULTREQUESTENTRY']._loaded_options = None
   _globals['_LIMITRANGEITEM_DEFAULTREQUESTENTRY']._serialized_options = b'8\001'
-  _globals['_LIMITRANGEITEM_MAXLIMITREQUESTRATIOENTRY']._options = None
+  _globals['_LIMITRANGEITEM_MAXLIMITREQUESTRATIOENTRY']._loaded_options = None
   _globals['_LIMITRANGEITEM_MAXLIMITREQUESTRATIOENTRY']._serialized_options = b'8\001'
-  _globals['_NODERESOURCES_CAPACITYENTRY']._options = None
+  _globals['_NODERESOURCES_CAPACITYENTRY']._loaded_options = None
   _globals['_NODERESOURCES_CAPACITYENTRY']._serialized_options = b'8\001'
-  _globals['_NODESTATUS_CAPACITYENTRY']._options = None
+  _globals['_NODESTATUS_CAPACITYENTRY']._loaded_options = None
   _globals['_NODESTATUS_CAPACITYENTRY']._serialized_options = b'8\001'
-  _globals['_NODESTATUS_ALLOCATABLEENTRY']._options = None
+  _globals['_NODESTATUS_ALLOCATABLEENTRY']._loaded_options = None
   _globals['_NODESTATUS_ALLOCATABLEENTRY']._serialized_options = b'8\001'
-  _globals['_PERSISTENTVOLUMECLAIMSTATUS_CAPACITYENTRY']._options = None
+  _globals['_PERSISTENTVOLUMECLAIMSTATUS_CAPACITYENTRY']._loaded_options = None
   _globals['_PERSISTENTVOLUMECLAIMSTATUS_CAPACITYENTRY']._serialized_options = b'8\001'
-  _globals['_PERSISTENTVOLUMESPEC_CAPACITYENTRY']._options = None
+  _globals['_PERSISTENTVOLUMESPEC_CAPACITYENTRY']._loaded_options = None
   _globals['_PERSISTENTVOLUMESPEC_CAPACITYENTRY']._serialized_options = b'8\001'
-  _globals['_PODSPEC_NODESELECTORENTRY']._options = None
+  _globals['_PODSPEC_NODESELECTORENTRY']._loaded_options = None
   _globals['_PODSPEC_NODESELECTORENTRY']._serialized_options = b'8\001'
-  _globals['_PODSPEC_OVERHEADENTRY']._options = None
+  _globals['_PODSPEC_OVERHEADENTRY']._loaded_options = None
   _globals['_PODSPEC_OVERHEADENTRY']._serialized_options = b'8\001'
-  _globals['_REPLICATIONCONTROLLERSPEC_SELECTORENTRY']._options = None
+  _globals['_REPLICATIONCONTROLLERSPEC_SELECTORENTRY']._loaded_options = None
   _globals['_REPLICATIONCONTROLLERSPEC_SELECTORENTRY']._serialized_options = b'8\001'
-  _globals['_RESOURCEQUOTASPEC_HARDENTRY']._options = None
+  _globals['_RESOURCEQUOTASPEC_HARDENTRY']._loaded_options = None
   _globals['_RESOURCEQUOTASPEC_HARDENTRY']._serialized_options = b'8\001'
-  _globals['_RESOURCEQUOTASTATUS_HARDENTRY']._options = None
+  _globals['_RESOURCEQUOTASTATUS_HARDENTRY']._loaded_options = None
   _globals['_RESOURCEQUOTASTATUS_HARDENTRY']._serialized_options = b'8\001'
-  _globals['_RESOURCEQUOTASTATUS_USEDENTRY']._options = None
+  _globals['_RESOURCEQUOTASTATUS_USEDENTRY']._loaded_options = None
   _globals['_RESOURCEQUOTASTATUS_USEDENTRY']._serialized_options = b'8\001'
-  _globals['_RESOURCEREQUIREMENTS_LIMITSENTRY']._options = None
+  _globals['_RESOURCEREQUIREMENTS_LIMITSENTRY']._loaded_options = None
   _globals['_RESOURCEREQUIREMENTS_LIMITSENTRY']._serialized_options = b'8\001'
-  _globals['_RESOURCEREQUIREMENTS_REQUESTSENTRY']._options = None
+  _globals['_RESOURCEREQUIREMENTS_REQUESTSENTRY']._loaded_options = None
   _globals['_RESOURCEREQUIREMENTS_REQUESTSENTRY']._serialized_options = b'8\001'
-  _globals['_SECRET_DATAENTRY']._options = None
+  _globals['_SECRET_DATAENTRY']._loaded_options = None
   _globals['_SECRET_DATAENTRY']._serialized_options = b'8\001'
-  _globals['_SECRET_STRINGDATAENTRY']._options = None
+  _globals['_SECRET_STRINGDATAENTRY']._loaded_options = None
   _globals['_SECRET_STRINGDATAENTRY']._serialized_options = b'8\001'
-  _globals['_SERVICESPEC_SELECTORENTRY']._options = None
+  _globals['_SERVICESPEC_SELECTORENTRY']._loaded_options = None
   _globals['_SERVICESPEC_SELECTORENTRY']._serialized_options = b'8\001'
   _globals['_AWSELASTICBLOCKSTOREVOLUMESOURCE']._serialized_start=324
   _globals['_AWSELASTICBLOCKSTOREVOLUMESOURCE']._serialized_end=429
   _globals['_AFFINITY']._serialized_start=432
   _globals['_AFFINITY']._serialized_end=614
   _globals['_ATTACHEDVOLUME']._serialized_start=616
   _globals['_ATTACHEDVOLUME']._serialized_end=666
```

## armada_client/k8s/io/api/core/v1/generated_pb2.pyi

```diff
@@ -1,30 +1,26 @@
 """
 @generated by mypy-protobuf.  Do not edit manually!
 isort:skip_file
 This file was autogenerated by go-to-protobuf. Do not edit it manually!"""
+
 import builtins
 import collections.abc
 import google.protobuf.descriptor
 import google.protobuf.internal.containers
 import google.protobuf.message
 import armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2
 import armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2
 import armada_client.k8s.io.apimachinery.pkg.runtime.generated_pb2
 import armada_client.k8s.io.apimachinery.pkg.util.intstr.generated_pb2
-import sys
-
-if sys.version_info >= (3, 8):
-    import typing as typing_extensions
-else:
-    import typing_extensions
+import typing
 
 DESCRIPTOR: google.protobuf.descriptor.FileDescriptor
 
-@typing_extensions.final
+@typing.final
 class AWSElasticBlockStoreVolumeSource(google.protobuf.message.Message):
     """Represents a Persistent Disk resource in AWS.
 
     An AWS EBS disk must exist before mounting to a container. The disk
     must also be in the same AWS zone as the kubelet. An AWS EBS disk
     can only be mounted as read/write once. AWS EBS volumes support
     ownership management and SELinux relabeling.
@@ -65,56 +61,59 @@
         self,
         *,
         volumeID: builtins.str | None = ...,
         fsType: builtins.str | None = ...,
         partition: builtins.int | None = ...,
         readOnly: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "partition", b"partition", "readOnly", b"readOnly", "volumeID", b"volumeID"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "partition", b"partition", "readOnly", b"readOnly", "volumeID", b"volumeID"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fsType", b"fsType", "partition", b"partition", "readOnly", b"readOnly", "volumeID", b"volumeID"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["fsType", b"fsType", "partition", b"partition", "readOnly", b"readOnly", "volumeID", b"volumeID"]) -> None: ...
 
 global___AWSElasticBlockStoreVolumeSource = AWSElasticBlockStoreVolumeSource
 
-@typing_extensions.final
+@typing.final
 class Affinity(google.protobuf.message.Message):
     """Affinity is a group of affinity scheduling rules."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NODEAFFINITY_FIELD_NUMBER: builtins.int
     PODAFFINITY_FIELD_NUMBER: builtins.int
     PODANTIAFFINITY_FIELD_NUMBER: builtins.int
     @property
     def nodeAffinity(self) -> global___NodeAffinity:
         """Describes node affinity scheduling rules for the pod.
         +optional
         """
+
     @property
     def podAffinity(self) -> global___PodAffinity:
         """Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
         +optional
         """
+
     @property
     def podAntiAffinity(self) -> global___PodAntiAffinity:
         """Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
         +optional
         """
+
     def __init__(
         self,
         *,
         nodeAffinity: global___NodeAffinity | None = ...,
         podAffinity: global___PodAffinity | None = ...,
         podAntiAffinity: global___PodAntiAffinity | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["nodeAffinity", b"nodeAffinity", "podAffinity", b"podAffinity", "podAntiAffinity", b"podAntiAffinity"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["nodeAffinity", b"nodeAffinity", "podAffinity", b"podAffinity", "podAntiAffinity", b"podAntiAffinity"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["nodeAffinity", b"nodeAffinity", "podAffinity", b"podAffinity", "podAntiAffinity", b"podAntiAffinity"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["nodeAffinity", b"nodeAffinity", "podAffinity", b"podAffinity", "podAntiAffinity", b"podAntiAffinity"]) -> None: ...
 
 global___Affinity = Affinity
 
-@typing_extensions.final
+@typing.final
 class AttachedVolume(google.protobuf.message.Message):
     """AttachedVolume describes a volume attached to a node"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     DEVICEPATH_FIELD_NUMBER: builtins.int
@@ -124,20 +123,20 @@
     """DevicePath represents the device path where the volume should be available"""
     def __init__(
         self,
         *,
         name: builtins.str | None = ...,
         devicePath: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["devicePath", b"devicePath", "name", b"name"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["devicePath", b"devicePath", "name", b"name"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["devicePath", b"devicePath", "name", b"name"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["devicePath", b"devicePath", "name", b"name"]) -> None: ...
 
 global___AttachedVolume = AttachedVolume
 
-@typing_extensions.final
+@typing.final
 class AvoidPods(google.protobuf.message.Message):
     """AvoidPods describes pods that should avoid this node. This is the value for a
     Node annotation with key scheduler.alpha.kubernetes.io/preferAvoidPods and
     will eventually become a field of NodeStatus.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -145,24 +144,25 @@
     PREFERAVOIDPODS_FIELD_NUMBER: builtins.int
     @property
     def preferAvoidPods(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PreferAvoidPodsEntry]:
         """Bounded-sized list of signatures of pods that should avoid this node, sorted
         in timestamp order from oldest to newest. Size of the slice is unspecified.
         +optional
         """
+
     def __init__(
         self,
         *,
         preferAvoidPods: collections.abc.Iterable[global___PreferAvoidPodsEntry] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["preferAvoidPods", b"preferAvoidPods"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["preferAvoidPods", b"preferAvoidPods"]) -> None: ...
 
 global___AvoidPods = AvoidPods
 
-@typing_extensions.final
+@typing.final
 class AzureDiskVolumeSource(google.protobuf.message.Message):
     """AzureDisk represents an Azure Data Disk mount on the host and bind mount to the pod."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     DISKNAME_FIELD_NUMBER: builtins.int
     DISKURI_FIELD_NUMBER: builtins.int
@@ -197,20 +197,20 @@
         diskName: builtins.str | None = ...,
         diskURI: builtins.str | None = ...,
         cachingMode: builtins.str | None = ...,
         fsType: builtins.str | None = ...,
         readOnly: builtins.bool | None = ...,
         kind: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["cachingMode", b"cachingMode", "diskName", b"diskName", "diskURI", b"diskURI", "fsType", b"fsType", "kind", b"kind", "readOnly", b"readOnly"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["cachingMode", b"cachingMode", "diskName", b"diskName", "diskURI", b"diskURI", "fsType", b"fsType", "kind", b"kind", "readOnly", b"readOnly"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["cachingMode", b"cachingMode", "diskName", b"diskName", "diskURI", b"diskURI", "fsType", b"fsType", "kind", b"kind", "readOnly", b"readOnly"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["cachingMode", b"cachingMode", "diskName", b"diskName", "diskURI", b"diskURI", "fsType", b"fsType", "kind", b"kind", "readOnly", b"readOnly"]) -> None: ...
 
 global___AzureDiskVolumeSource = AzureDiskVolumeSource
 
-@typing_extensions.final
+@typing.final
 class AzureFilePersistentVolumeSource(google.protobuf.message.Message):
     """AzureFile represents an Azure File Service mount on the host and bind mount to the pod."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SECRETNAME_FIELD_NUMBER: builtins.int
     SHARENAME_FIELD_NUMBER: builtins.int
@@ -234,20 +234,20 @@
         self,
         *,
         secretName: builtins.str | None = ...,
         shareName: builtins.str | None = ...,
         readOnly: builtins.bool | None = ...,
         secretNamespace: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["readOnly", b"readOnly", "secretName", b"secretName", "secretNamespace", b"secretNamespace", "shareName", b"shareName"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["readOnly", b"readOnly", "secretName", b"secretName", "secretNamespace", b"secretNamespace", "shareName", b"shareName"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["readOnly", b"readOnly", "secretName", b"secretName", "secretNamespace", b"secretNamespace", "shareName", b"shareName"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["readOnly", b"readOnly", "secretName", b"secretName", "secretNamespace", b"secretNamespace", "shareName", b"shareName"]) -> None: ...
 
 global___AzureFilePersistentVolumeSource = AzureFilePersistentVolumeSource
 
-@typing_extensions.final
+@typing.final
 class AzureFileVolumeSource(google.protobuf.message.Message):
     """AzureFile represents an Azure File Service mount on the host and bind mount to the pod."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SECRETNAME_FIELD_NUMBER: builtins.int
     SHARENAME_FIELD_NUMBER: builtins.int
@@ -264,20 +264,20 @@
     def __init__(
         self,
         *,
         secretName: builtins.str | None = ...,
         shareName: builtins.str | None = ...,
         readOnly: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["readOnly", b"readOnly", "secretName", b"secretName", "shareName", b"shareName"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["readOnly", b"readOnly", "secretName", b"secretName", "shareName", b"shareName"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["readOnly", b"readOnly", "secretName", b"secretName", "shareName", b"shareName"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["readOnly", b"readOnly", "secretName", b"secretName", "shareName", b"shareName"]) -> None: ...
 
 global___AzureFileVolumeSource = AzureFileVolumeSource
 
-@typing_extensions.final
+@typing.final
 class Binding(google.protobuf.message.Message):
     """Binding ties one object to another; for example, a pod is bound to a node by a scheduler.
     Deprecated in 1.7, please use the bindings subresource of pods instead.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -285,50 +285,52 @@
     TARGET_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def target(self) -> global___ObjectReference:
         """The target object that you want to bind to the standard object."""
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         target: global___ObjectReference | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "target", b"target"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "target", b"target"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata", "target", b"target"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["metadata", b"metadata", "target", b"target"]) -> None: ...
 
 global___Binding = Binding
 
-@typing_extensions.final
+@typing.final
 class CSIPersistentVolumeSource(google.protobuf.message.Message):
     """Represents storage that is managed by an external CSI volume driver (Beta feature)"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class VolumeAttributesEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: builtins.str | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     DRIVER_FIELD_NUMBER: builtins.int
     VOLUMEHANDLE_FIELD_NUMBER: builtins.int
     READONLY_FIELD_NUMBER: builtins.int
     FSTYPE_FIELD_NUMBER: builtins.int
     VOLUMEATTRIBUTES_FIELD_NUMBER: builtins.int
     CONTROLLERPUBLISHSECRETREF_FIELD_NUMBER: builtins.int
@@ -356,91 +358,96 @@
     +optional
     """
     @property
     def volumeAttributes(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]:
         """Attributes of the volume to publish.
         +optional
         """
+
     @property
     def controllerPublishSecretRef(self) -> global___SecretReference:
         """ControllerPublishSecretRef is a reference to the secret object containing
         sensitive information to pass to the CSI driver to complete the CSI
         ControllerPublishVolume and ControllerUnpublishVolume calls.
         This field is optional, and may be empty if no secret is required. If the
         secret object contains more than one secret, all secrets are passed.
         +optional
         """
+
     @property
     def nodeStageSecretRef(self) -> global___SecretReference:
         """NodeStageSecretRef is a reference to the secret object containing sensitive
         information to pass to the CSI driver to complete the CSI NodeStageVolume
         and NodeStageVolume and NodeUnstageVolume calls.
         This field is optional, and may be empty if no secret is required. If the
         secret object contains more than one secret, all secrets are passed.
         +optional
         """
+
     @property
     def nodePublishSecretRef(self) -> global___SecretReference:
         """NodePublishSecretRef is a reference to the secret object containing
         sensitive information to pass to the CSI driver to complete the CSI
         NodePublishVolume and NodeUnpublishVolume calls.
         This field is optional, and may be empty if no secret is required. If the
         secret object contains more than one secret, all secrets are passed.
         +optional
         """
+
     @property
     def controllerExpandSecretRef(self) -> global___SecretReference:
         """ControllerExpandSecretRef is a reference to the secret object containing
         sensitive information to pass to the CSI driver to complete the CSI
         ControllerExpandVolume call.
         This is an alpha field and requires enabling ExpandCSIVolumes feature gate.
         This field is optional, and may be empty if no secret is required. If the
         secret object contains more than one secret, all secrets are passed.
         +optional
         """
+
     def __init__(
         self,
         *,
         driver: builtins.str | None = ...,
         volumeHandle: builtins.str | None = ...,
         readOnly: builtins.bool | None = ...,
         fsType: builtins.str | None = ...,
         volumeAttributes: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
         controllerPublishSecretRef: global___SecretReference | None = ...,
         nodeStageSecretRef: global___SecretReference | None = ...,
         nodePublishSecretRef: global___SecretReference | None = ...,
         controllerExpandSecretRef: global___SecretReference | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["controllerExpandSecretRef", b"controllerExpandSecretRef", "controllerPublishSecretRef", b"controllerPublishSecretRef", "driver", b"driver", "fsType", b"fsType", "nodePublishSecretRef", b"nodePublishSecretRef", "nodeStageSecretRef", b"nodeStageSecretRef", "readOnly", b"readOnly", "volumeHandle", b"volumeHandle"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["controllerExpandSecretRef", b"controllerExpandSecretRef", "controllerPublishSecretRef", b"controllerPublishSecretRef", "driver", b"driver", "fsType", b"fsType", "nodePublishSecretRef", b"nodePublishSecretRef", "nodeStageSecretRef", b"nodeStageSecretRef", "readOnly", b"readOnly", "volumeAttributes", b"volumeAttributes", "volumeHandle", b"volumeHandle"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["controllerExpandSecretRef", b"controllerExpandSecretRef", "controllerPublishSecretRef", b"controllerPublishSecretRef", "driver", b"driver", "fsType", b"fsType", "nodePublishSecretRef", b"nodePublishSecretRef", "nodeStageSecretRef", b"nodeStageSecretRef", "readOnly", b"readOnly", "volumeHandle", b"volumeHandle"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["controllerExpandSecretRef", b"controllerExpandSecretRef", "controllerPublishSecretRef", b"controllerPublishSecretRef", "driver", b"driver", "fsType", b"fsType", "nodePublishSecretRef", b"nodePublishSecretRef", "nodeStageSecretRef", b"nodeStageSecretRef", "readOnly", b"readOnly", "volumeAttributes", b"volumeAttributes", "volumeHandle", b"volumeHandle"]) -> None: ...
 
 global___CSIPersistentVolumeSource = CSIPersistentVolumeSource
 
-@typing_extensions.final
+@typing.final
 class CSIVolumeSource(google.protobuf.message.Message):
     """Represents a source location of a volume to mount, managed by an external CSI driver"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class VolumeAttributesEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: builtins.str | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     DRIVER_FIELD_NUMBER: builtins.int
     READONLY_FIELD_NUMBER: builtins.int
     FSTYPE_FIELD_NUMBER: builtins.int
     VOLUMEATTRIBUTES_FIELD_NUMBER: builtins.int
     NODEPUBLISHSECRETREF_FIELD_NUMBER: builtins.int
     driver: builtins.str
@@ -460,186 +467,194 @@
     """
     @property
     def volumeAttributes(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]:
         """VolumeAttributes stores driver-specific properties that are passed to the CSI
         driver. Consult your driver's documentation for supported values.
         +optional
         """
+
     @property
     def nodePublishSecretRef(self) -> global___LocalObjectReference:
         """NodePublishSecretRef is a reference to the secret object containing
         sensitive information to pass to the CSI driver to complete the CSI
         NodePublishVolume and NodeUnpublishVolume calls.
         This field is optional, and  may be empty if no secret is required. If the
         secret object contains more than one secret, all secret references are passed.
         +optional
         """
+
     def __init__(
         self,
         *,
         driver: builtins.str | None = ...,
         readOnly: builtins.bool | None = ...,
         fsType: builtins.str | None = ...,
         volumeAttributes: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
         nodePublishSecretRef: global___LocalObjectReference | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["driver", b"driver", "fsType", b"fsType", "nodePublishSecretRef", b"nodePublishSecretRef", "readOnly", b"readOnly"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["driver", b"driver", "fsType", b"fsType", "nodePublishSecretRef", b"nodePublishSecretRef", "readOnly", b"readOnly", "volumeAttributes", b"volumeAttributes"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["driver", b"driver", "fsType", b"fsType", "nodePublishSecretRef", b"nodePublishSecretRef", "readOnly", b"readOnly"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["driver", b"driver", "fsType", b"fsType", "nodePublishSecretRef", b"nodePublishSecretRef", "readOnly", b"readOnly", "volumeAttributes", b"volumeAttributes"]) -> None: ...
 
 global___CSIVolumeSource = CSIVolumeSource
 
-@typing_extensions.final
+@typing.final
 class Capabilities(google.protobuf.message.Message):
     """Adds and removes POSIX capabilities from running containers."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     ADD_FIELD_NUMBER: builtins.int
     DROP_FIELD_NUMBER: builtins.int
     @property
     def add(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """Added capabilities
         +optional
         """
+
     @property
     def drop(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """Removed capabilities
         +optional
         """
+
     def __init__(
         self,
         *,
         add: collections.abc.Iterable[builtins.str] | None = ...,
         drop: collections.abc.Iterable[builtins.str] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["add", b"add", "drop", b"drop"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["add", b"add", "drop", b"drop"]) -> None: ...
 
 global___Capabilities = Capabilities
 
-@typing_extensions.final
+@typing.final
 class CephFSPersistentVolumeSource(google.protobuf.message.Message):
     """Represents a Ceph Filesystem mount that lasts the lifetime of a pod
     Cephfs volumes do not support ownership management or SELinux relabeling.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     MONITORS_FIELD_NUMBER: builtins.int
     PATH_FIELD_NUMBER: builtins.int
     USER_FIELD_NUMBER: builtins.int
     SECRETFILE_FIELD_NUMBER: builtins.int
     SECRETREF_FIELD_NUMBER: builtins.int
     READONLY_FIELD_NUMBER: builtins.int
-    @property
-    def monitors(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
-        """Required: Monitors is a collection of Ceph monitors
-        More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
-        """
     path: builtins.str
     """Optional: Used as the mounted root, rather than the full Ceph tree, default is /
     +optional
     """
     user: builtins.str
     """Optional: User is the rados user name, default is admin
     More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
     +optional
     """
     secretFile: builtins.str
     """Optional: SecretFile is the path to key ring for User, default is /etc/ceph/user.secret
     More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
     +optional
     """
-    @property
-    def secretRef(self) -> global___SecretReference:
-        """Optional: SecretRef is reference to the authentication secret for User, default is empty.
-        More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
-        +optional
-        """
     readOnly: builtins.bool
     """Optional: Defaults to false (read/write). ReadOnly here will force
     the ReadOnly setting in VolumeMounts.
     More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
     +optional
     """
+    @property
+    def monitors(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
+        """Required: Monitors is a collection of Ceph monitors
+        More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
+        """
+
+    @property
+    def secretRef(self) -> global___SecretReference:
+        """Optional: SecretRef is reference to the authentication secret for User, default is empty.
+        More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
+        +optional
+        """
+
     def __init__(
         self,
         *,
         monitors: collections.abc.Iterable[builtins.str] | None = ...,
         path: builtins.str | None = ...,
         user: builtins.str | None = ...,
         secretFile: builtins.str | None = ...,
         secretRef: global___SecretReference | None = ...,
         readOnly: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["path", b"path", "readOnly", b"readOnly", "secretFile", b"secretFile", "secretRef", b"secretRef", "user", b"user"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["monitors", b"monitors", "path", b"path", "readOnly", b"readOnly", "secretFile", b"secretFile", "secretRef", b"secretRef", "user", b"user"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["path", b"path", "readOnly", b"readOnly", "secretFile", b"secretFile", "secretRef", b"secretRef", "user", b"user"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["monitors", b"monitors", "path", b"path", "readOnly", b"readOnly", "secretFile", b"secretFile", "secretRef", b"secretRef", "user", b"user"]) -> None: ...
 
 global___CephFSPersistentVolumeSource = CephFSPersistentVolumeSource
 
-@typing_extensions.final
+@typing.final
 class CephFSVolumeSource(google.protobuf.message.Message):
     """Represents a Ceph Filesystem mount that lasts the lifetime of a pod
     Cephfs volumes do not support ownership management or SELinux relabeling.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     MONITORS_FIELD_NUMBER: builtins.int
     PATH_FIELD_NUMBER: builtins.int
     USER_FIELD_NUMBER: builtins.int
     SECRETFILE_FIELD_NUMBER: builtins.int
     SECRETREF_FIELD_NUMBER: builtins.int
     READONLY_FIELD_NUMBER: builtins.int
-    @property
-    def monitors(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
-        """Required: Monitors is a collection of Ceph monitors
-        More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
-        """
     path: builtins.str
     """Optional: Used as the mounted root, rather than the full Ceph tree, default is /
     +optional
     """
     user: builtins.str
     """Optional: User is the rados user name, default is admin
     More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
     +optional
     """
     secretFile: builtins.str
     """Optional: SecretFile is the path to key ring for User, default is /etc/ceph/user.secret
     More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
     +optional
     """
-    @property
-    def secretRef(self) -> global___LocalObjectReference:
-        """Optional: SecretRef is reference to the authentication secret for User, default is empty.
-        More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
-        +optional
-        """
     readOnly: builtins.bool
     """Optional: Defaults to false (read/write). ReadOnly here will force
     the ReadOnly setting in VolumeMounts.
     More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
     +optional
     """
+    @property
+    def monitors(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
+        """Required: Monitors is a collection of Ceph monitors
+        More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
+        """
+
+    @property
+    def secretRef(self) -> global___LocalObjectReference:
+        """Optional: SecretRef is reference to the authentication secret for User, default is empty.
+        More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
+        +optional
+        """
+
     def __init__(
         self,
         *,
         monitors: collections.abc.Iterable[builtins.str] | None = ...,
         path: builtins.str | None = ...,
         user: builtins.str | None = ...,
         secretFile: builtins.str | None = ...,
         secretRef: global___LocalObjectReference | None = ...,
         readOnly: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["path", b"path", "readOnly", b"readOnly", "secretFile", b"secretFile", "secretRef", b"secretRef", "user", b"user"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["monitors", b"monitors", "path", b"path", "readOnly", b"readOnly", "secretFile", b"secretFile", "secretRef", b"secretRef", "user", b"user"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["path", b"path", "readOnly", b"readOnly", "secretFile", b"secretFile", "secretRef", b"secretRef", "user", b"user"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["monitors", b"monitors", "path", b"path", "readOnly", b"readOnly", "secretFile", b"secretFile", "secretRef", b"secretRef", "user", b"user"]) -> None: ...
 
 global___CephFSVolumeSource = CephFSVolumeSource
 
-@typing_extensions.final
+@typing.final
 class CinderPersistentVolumeSource(google.protobuf.message.Message):
     """Represents a cinder volume resource in Openstack.
     A Cinder volume must exist before mounting to a container.
     The volume must also be in the same region as the kubelet.
     Cinder volumes support ownership management and SELinux relabeling.
     """
 
@@ -668,28 +683,29 @@
     """
     @property
     def secretRef(self) -> global___SecretReference:
         """Optional: points to a secret object containing parameters used to connect
         to OpenStack.
         +optional
         """
+
     def __init__(
         self,
         *,
         volumeID: builtins.str | None = ...,
         fsType: builtins.str | None = ...,
         readOnly: builtins.bool | None = ...,
         secretRef: global___SecretReference | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef", "volumeID", b"volumeID"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef", "volumeID", b"volumeID"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef", "volumeID", b"volumeID"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef", "volumeID", b"volumeID"]) -> None: ...
 
 global___CinderPersistentVolumeSource = CinderPersistentVolumeSource
 
-@typing_extensions.final
+@typing.final
 class CinderVolumeSource(google.protobuf.message.Message):
     """Represents a cinder volume resource in Openstack.
     A Cinder volume must exist before mounting to a container.
     The volume must also be in the same region as the kubelet.
     Cinder volumes support ownership management and SELinux relabeling.
     """
 
@@ -718,28 +734,29 @@
     """
     @property
     def secretRef(self) -> global___LocalObjectReference:
         """Optional: points to a secret object containing parameters used to connect
         to OpenStack.
         +optional
         """
+
     def __init__(
         self,
         *,
         volumeID: builtins.str | None = ...,
         fsType: builtins.str | None = ...,
         readOnly: builtins.bool | None = ...,
         secretRef: global___LocalObjectReference | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef", "volumeID", b"volumeID"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef", "volumeID", b"volumeID"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef", "volumeID", b"volumeID"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef", "volumeID", b"volumeID"]) -> None: ...
 
 global___CinderVolumeSource = CinderVolumeSource
 
-@typing_extensions.final
+@typing.final
 class ClientIPConfig(google.protobuf.message.Message):
     """ClientIPConfig represents the configurations of Client IP based session affinity."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     TIMEOUTSECONDS_FIELD_NUMBER: builtins.int
     timeoutSeconds: builtins.int
@@ -749,20 +766,20 @@
     +optional
     """
     def __init__(
         self,
         *,
         timeoutSeconds: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["timeoutSeconds", b"timeoutSeconds"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["timeoutSeconds", b"timeoutSeconds"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["timeoutSeconds", b"timeoutSeconds"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["timeoutSeconds", b"timeoutSeconds"]) -> None: ...
 
 global___ClientIPConfig = ClientIPConfig
 
-@typing_extensions.final
+@typing.final
 class ComponentCondition(google.protobuf.message.Message):
     """Information about the condition of a component."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     TYPE_FIELD_NUMBER: builtins.int
     STATUS_FIELD_NUMBER: builtins.int
@@ -790,20 +807,20 @@
         self,
         *,
         type: builtins.str | None = ...,
         status: builtins.str | None = ...,
         message: builtins.str | None = ...,
         error: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["error", b"error", "message", b"message", "status", b"status", "type", b"type"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["error", b"error", "message", b"message", "status", b"status", "type", b"type"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["error", b"error", "message", b"message", "status", b"status", "type", b"type"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["error", b"error", "message", b"message", "status", b"status", "type", b"type"]) -> None: ...
 
 global___ComponentCondition = ComponentCondition
 
-@typing_extensions.final
+@typing.final
 class ComponentStatus(google.protobuf.message.Message):
     """ComponentStatus (and ComponentStatusList) holds the cluster validation info.
     Deprecated: This API is deprecated in v1.19+
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -811,33 +828,35 @@
     CONDITIONS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def conditions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ComponentCondition]:
         """List of component conditions observed
         +optional
         +patchMergeKey=type
         +patchStrategy=merge
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         conditions: collections.abc.Iterable[global___ComponentCondition] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["conditions", b"conditions", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["conditions", b"conditions", "metadata", b"metadata"]) -> None: ...
 
 global___ComponentStatus = ComponentStatus
 
-@typing_extensions.final
+@typing.final
 class ComponentStatusList(google.protobuf.message.Message):
     """Status of all the conditions for the component as a list of ComponentStatus objects.
     Deprecated: This API is deprecated in v1.19+
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -845,209 +864,218 @@
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """Standard list metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ComponentStatus]:
         """List of ComponentStatus objects."""
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[global___ComponentStatus] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___ComponentStatusList = ComponentStatusList
 
-@typing_extensions.final
+@typing.final
 class ConfigMap(google.protobuf.message.Message):
     """ConfigMap holds configuration data for pods to consume."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class DataEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: builtins.str | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
-    @typing_extensions.final
+    @typing.final
     class BinaryDataEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.bytes
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: builtins.bytes | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     METADATA_FIELD_NUMBER: builtins.int
     IMMUTABLE_FIELD_NUMBER: builtins.int
     DATA_FIELD_NUMBER: builtins.int
     BINARYDATA_FIELD_NUMBER: builtins.int
-    @property
-    def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
-        """Standard object's metadata.
-        More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
-        +optional
-        """
     immutable: builtins.bool
     """Immutable, if set to true, ensures that data stored in the ConfigMap cannot
     be updated (only object metadata can be modified).
     If not set to true, the field can be modified at any time.
     Defaulted to nil.
     +optional
     """
     @property
+    def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
+        """Standard object's metadata.
+        More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
+        +optional
+        """
+
+    @property
     def data(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]:
         """Data contains the configuration data.
         Each key must consist of alphanumeric characters, '-', '_' or '.'.
         Values with non-UTF-8 byte sequences must use the BinaryData field.
         The keys stored in Data must not overlap with the keys in
         the BinaryData field, this is enforced during validation process.
         +optional
         """
+
     @property
     def binaryData(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.bytes]:
         """BinaryData contains the binary data.
         Each key must consist of alphanumeric characters, '-', '_' or '.'.
         BinaryData can contain byte sequences that are not in the UTF-8 range.
         The keys stored in BinaryData must not overlap with the ones in
         the Data field, this is enforced during validation process.
         Using this field will require 1.10+ apiserver and
         kubelet.
         +optional
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         immutable: builtins.bool | None = ...,
         data: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
         binaryData: collections.abc.Mapping[builtins.str, builtins.bytes] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["immutable", b"immutable", "metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["binaryData", b"binaryData", "data", b"data", "immutable", b"immutable", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["immutable", b"immutable", "metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["binaryData", b"binaryData", "data", b"data", "immutable", b"immutable", "metadata", b"metadata"]) -> None: ...
 
 global___ConfigMap = ConfigMap
 
-@typing_extensions.final
+@typing.final
 class ConfigMapEnvSource(google.protobuf.message.Message):
     """ConfigMapEnvSource selects a ConfigMap to populate the environment
     variables with.
 
     The contents of the target ConfigMap's Data field will represent the
     key-value pairs as environment variables.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     LOCALOBJECTREFERENCE_FIELD_NUMBER: builtins.int
     OPTIONAL_FIELD_NUMBER: builtins.int
-    @property
-    def localObjectReference(self) -> global___LocalObjectReference:
-        """The ConfigMap to select from."""
     optional: builtins.bool
     """Specify whether the ConfigMap must be defined
     +optional
     """
+    @property
+    def localObjectReference(self) -> global___LocalObjectReference:
+        """The ConfigMap to select from."""
+
     def __init__(
         self,
         *,
         localObjectReference: global___LocalObjectReference | None = ...,
         optional: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["localObjectReference", b"localObjectReference", "optional", b"optional"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["localObjectReference", b"localObjectReference", "optional", b"optional"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["localObjectReference", b"localObjectReference", "optional", b"optional"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["localObjectReference", b"localObjectReference", "optional", b"optional"]) -> None: ...
 
 global___ConfigMapEnvSource = ConfigMapEnvSource
 
-@typing_extensions.final
+@typing.final
 class ConfigMapKeySelector(google.protobuf.message.Message):
     """Selects a key from a ConfigMap.
     +structType=atomic
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     LOCALOBJECTREFERENCE_FIELD_NUMBER: builtins.int
     KEY_FIELD_NUMBER: builtins.int
     OPTIONAL_FIELD_NUMBER: builtins.int
-    @property
-    def localObjectReference(self) -> global___LocalObjectReference:
-        """The ConfigMap to select from."""
     key: builtins.str
     """The key to select."""
     optional: builtins.bool
     """Specify whether the ConfigMap or its key must be defined
     +optional
     """
+    @property
+    def localObjectReference(self) -> global___LocalObjectReference:
+        """The ConfigMap to select from."""
+
     def __init__(
         self,
         *,
         localObjectReference: global___LocalObjectReference | None = ...,
         key: builtins.str | None = ...,
         optional: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["key", b"key", "localObjectReference", b"localObjectReference", "optional", b"optional"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "localObjectReference", b"localObjectReference", "optional", b"optional"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["key", b"key", "localObjectReference", b"localObjectReference", "optional", b"optional"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["key", b"key", "localObjectReference", b"localObjectReference", "optional", b"optional"]) -> None: ...
 
 global___ConfigMapKeySelector = ConfigMapKeySelector
 
-@typing_extensions.final
+@typing.final
 class ConfigMapList(google.protobuf.message.Message):
     """ConfigMapList is a resource containing a list of ConfigMap objects."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ConfigMap]:
         """Items is the list of ConfigMaps."""
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[global___ConfigMap] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___ConfigMapList = ConfigMapList
 
-@typing_extensions.final
+@typing.final
 class ConfigMapNodeConfigSource(google.protobuf.message.Message):
     """ConfigMapNodeConfigSource contains the information to reference a ConfigMap as a config source for the Node.
     This API is deprecated since 1.22: https://git.k8s.io/enhancements/keps/sig-node/281-dynamic-kubelet-configuration
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -1083,20 +1111,20 @@
         *,
         namespace: builtins.str | None = ...,
         name: builtins.str | None = ...,
         uid: builtins.str | None = ...,
         resourceVersion: builtins.str | None = ...,
         kubeletConfigKey: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["kubeletConfigKey", b"kubeletConfigKey", "name", b"name", "namespace", b"namespace", "resourceVersion", b"resourceVersion", "uid", b"uid"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["kubeletConfigKey", b"kubeletConfigKey", "name", b"name", "namespace", b"namespace", "resourceVersion", b"resourceVersion", "uid", b"uid"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["kubeletConfigKey", b"kubeletConfigKey", "name", b"name", "namespace", b"namespace", "resourceVersion", b"resourceVersion", "uid", b"uid"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["kubeletConfigKey", b"kubeletConfigKey", "name", b"name", "namespace", b"namespace", "resourceVersion", b"resourceVersion", "uid", b"uid"]) -> None: ...
 
 global___ConfigMapNodeConfigSource = ConfigMapNodeConfigSource
 
-@typing_extensions.final
+@typing.final
 class ConfigMapProjection(google.protobuf.message.Message):
     """Adapts a ConfigMap into a projected volume.
 
     The contents of the target ConfigMap's Data field will be presented in a
     projected volume as files using the keys in the Data field as the file names,
     unless the items element is populated with specific mappings of keys to paths.
     Note that this is identical to a configmap volume source without the default
@@ -1104,44 +1132,45 @@
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     LOCALOBJECTREFERENCE_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     OPTIONAL_FIELD_NUMBER: builtins.int
+    optional: builtins.bool
+    """Specify whether the ConfigMap or its keys must be defined
+    +optional
+    """
     @property
     def localObjectReference(self) -> global___LocalObjectReference: ...
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___KeyToPath]:
         """If unspecified, each key-value pair in the Data field of the referenced
         ConfigMap will be projected into the volume as a file whose name is the
         key and content is the value. If specified, the listed keys will be
         projected into the specified paths, and unlisted keys will not be
         present. If a key is specified which is not present in the ConfigMap,
         the volume setup will error unless it is marked optional. Paths must be
         relative and may not contain the '..' path or start with '..'.
         +optional
         """
-    optional: builtins.bool
-    """Specify whether the ConfigMap or its keys must be defined
-    +optional
-    """
+
     def __init__(
         self,
         *,
         localObjectReference: global___LocalObjectReference | None = ...,
         items: collections.abc.Iterable[global___KeyToPath] | None = ...,
         optional: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["localObjectReference", b"localObjectReference", "optional", b"optional"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "localObjectReference", b"localObjectReference", "optional", b"optional"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["localObjectReference", b"localObjectReference", "optional", b"optional"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "localObjectReference", b"localObjectReference", "optional", b"optional"]) -> None: ...
 
 global___ConfigMapProjection = ConfigMapProjection
 
-@typing_extensions.final
+@typing.final
 class ConfigMapVolumeSource(google.protobuf.message.Message):
     """Adapts a ConfigMap into a volume.
 
     The contents of the target ConfigMap's Data field will be presented in a
     volume as files using the keys in the Data field as the file names, unless
     the items element is populated with specific mappings of keys to paths.
     ConfigMap volumes support ownership management and SELinux relabeling.
@@ -1149,55 +1178,56 @@
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     LOCALOBJECTREFERENCE_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     DEFAULTMODE_FIELD_NUMBER: builtins.int
     OPTIONAL_FIELD_NUMBER: builtins.int
-    @property
-    def localObjectReference(self) -> global___LocalObjectReference: ...
-    @property
-    def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___KeyToPath]:
-        """If unspecified, each key-value pair in the Data field of the referenced
-        ConfigMap will be projected into the volume as a file whose name is the
-        key and content is the value. If specified, the listed keys will be
-        projected into the specified paths, and unlisted keys will not be
-        present. If a key is specified which is not present in the ConfigMap,
-        the volume setup will error unless it is marked optional. Paths must be
-        relative and may not contain the '..' path or start with '..'.
-        +optional
-        """
     defaultMode: builtins.int
     """Optional: mode bits used to set permissions on created files by default.
     Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511.
     YAML accepts both octal and decimal values, JSON requires decimal values for mode bits.
     Defaults to 0644.
     Directories within the path are not affected by this setting.
     This might be in conflict with other options that affect the file
     mode, like fsGroup, and the result can be other mode bits set.
     +optional
     """
     optional: builtins.bool
     """Specify whether the ConfigMap or its keys must be defined
     +optional
     """
+    @property
+    def localObjectReference(self) -> global___LocalObjectReference: ...
+    @property
+    def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___KeyToPath]:
+        """If unspecified, each key-value pair in the Data field of the referenced
+        ConfigMap will be projected into the volume as a file whose name is the
+        key and content is the value. If specified, the listed keys will be
+        projected into the specified paths, and unlisted keys will not be
+        present. If a key is specified which is not present in the ConfigMap,
+        the volume setup will error unless it is marked optional. Paths must be
+        relative and may not contain the '..' path or start with '..'.
+        +optional
+        """
+
     def __init__(
         self,
         *,
         localObjectReference: global___LocalObjectReference | None = ...,
         items: collections.abc.Iterable[global___KeyToPath] | None = ...,
         defaultMode: builtins.int | None = ...,
         optional: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["defaultMode", b"defaultMode", "localObjectReference", b"localObjectReference", "optional", b"optional"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["defaultMode", b"defaultMode", "items", b"items", "localObjectReference", b"localObjectReference", "optional", b"optional"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["defaultMode", b"defaultMode", "localObjectReference", b"localObjectReference", "optional", b"optional"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["defaultMode", b"defaultMode", "items", b"items", "localObjectReference", b"localObjectReference", "optional", b"optional"]) -> None: ...
 
 global___ConfigMapVolumeSource = ConfigMapVolumeSource
 
-@typing_extensions.final
+@typing.final
 class Container(google.protobuf.message.Message):
     """A single application container that you want to run within a pod."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     IMAGE_FIELD_NUMBER: builtins.int
@@ -1229,45 +1259,96 @@
     image: builtins.str
     """Docker image name.
     More info: https://kubernetes.io/docs/concepts/containers/images
     This field is optional to allow higher level config management to default or override
     container images in workload controllers like Deployments and StatefulSets.
     +optional
     """
+    workingDir: builtins.str
+    """Container's working directory.
+    If not specified, the container runtime's default will be used, which
+    might be configured in the container image.
+    Cannot be updated.
+    +optional
+    """
+    terminationMessagePath: builtins.str
+    """Optional: Path at which the file to which the container's termination message
+    will be written is mounted into the container's filesystem.
+    Message written is intended to be brief final status, such as an assertion failure message.
+    Will be truncated by the node if greater than 4096 bytes. The total message length across
+    all containers will be limited to 12kb.
+    Defaults to /dev/termination-log.
+    Cannot be updated.
+    +optional
+    """
+    terminationMessagePolicy: builtins.str
+    """Indicate how the termination message should be populated. File will use the contents of
+    terminationMessagePath to populate the container status message on both success and failure.
+    FallbackToLogsOnError will use the last chunk of container log output if the termination
+    message file is empty and the container exited with an error.
+    The log output is limited to 2048 bytes or 80 lines, whichever is smaller.
+    Defaults to File.
+    Cannot be updated.
+    +optional
+    """
+    imagePullPolicy: builtins.str
+    """Image pull policy.
+    One of Always, Never, IfNotPresent.
+    Defaults to Always if :latest tag is specified, or IfNotPresent otherwise.
+    Cannot be updated.
+    More info: https://kubernetes.io/docs/concepts/containers/images#updating-images
+    +optional
+    """
+    stdin: builtins.bool
+    """Whether this container should allocate a buffer for stdin in the container runtime. If this
+    is not set, reads from stdin in the container will always result in EOF.
+    Default is false.
+    +optional
+    """
+    stdinOnce: builtins.bool
+    """Whether the container runtime should close the stdin channel after it has been opened by
+    a single attach. When stdin is true the stdin stream will remain open across multiple attach
+    sessions. If stdinOnce is set to true, stdin is opened on container start, is empty until the
+    first client attaches to stdin, and then remains open and accepts data until the client disconnects,
+    at which time stdin is closed and remains closed until the container is restarted. If this
+    flag is false, a container processes that reads from stdin will never receive an EOF.
+    Default is false
+    +optional
+    """
+    tty: builtins.bool
+    """Whether this container should allocate a TTY for itself, also requires 'stdin' to be true.
+    Default is false.
+    +optional
+    """
     @property
     def command(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """Entrypoint array. Not executed within a shell.
         The docker image's ENTRYPOINT is used if this is not provided.
         Variable references $(VAR_NAME) are expanded using the container's environment. If a variable
         cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced
         to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. "$$(VAR_NAME)" will
         produce the string literal "$(VAR_NAME)". Escaped references will never be expanded, regardless
         of whether the variable exists or not. Cannot be updated.
         More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell
         +optional
         """
+
     @property
     def args(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """Arguments to the entrypoint.
         The docker image's CMD is used if this is not provided.
         Variable references $(VAR_NAME) are expanded using the container's environment. If a variable
         cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced
         to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. "$$(VAR_NAME)" will
         produce the string literal "$(VAR_NAME)". Escaped references will never be expanded, regardless
         of whether the variable exists or not. Cannot be updated.
         More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell
         +optional
         """
-    workingDir: builtins.str
-    """Container's working directory.
-    If not specified, the container runtime's default will be used, which
-    might be configured in the container image.
-    Cannot be updated.
-    +optional
-    """
+
     @property
     def ports(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ContainerPort]:
         """List of ports to expose from the container. Exposing a port here gives
         the system additional information about the network connections a
         container uses, but is primarily informational. Not specifying a port here
         DOES NOT prevent that port from being exposed. Any port which is
         listening on the default "0.0.0.0" address inside a container will be
@@ -1276,143 +1357,105 @@
         +optional
         +patchMergeKey=containerPort
         +patchStrategy=merge
         +listType=map
         +listMapKey=containerPort
         +listMapKey=protocol
         """
+
     @property
     def envFrom(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___EnvFromSource]:
         """List of sources to populate environment variables in the container.
         The keys defined within a source must be a C_IDENTIFIER. All invalid keys
         will be reported as an event when the container is starting. When a key exists in multiple
         sources, the value associated with the last source will take precedence.
         Values defined by an Env with a duplicate key will take precedence.
         Cannot be updated.
         +optional
         """
+
     @property
     def env(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___EnvVar]:
         """List of environment variables to set in the container.
         Cannot be updated.
         +optional
         +patchMergeKey=name
         +patchStrategy=merge
         """
+
     @property
     def resources(self) -> global___ResourceRequirements:
         """Compute Resources required by this container.
         Cannot be updated.
         More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
         +optional
         """
+
     @property
     def volumeMounts(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___VolumeMount]:
         """Pod volumes to mount into the container's filesystem.
         Cannot be updated.
         +optional
         +patchMergeKey=mountPath
         +patchStrategy=merge
         """
+
     @property
     def volumeDevices(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___VolumeDevice]:
         """volumeDevices is the list of block devices to be used by the container.
         +patchMergeKey=devicePath
         +patchStrategy=merge
         +optional
         """
+
     @property
     def livenessProbe(self) -> global___Probe:
         """Periodic probe of container liveness.
         Container will be restarted if the probe fails.
         Cannot be updated.
         More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         +optional
         """
+
     @property
     def readinessProbe(self) -> global___Probe:
         """Periodic probe of container service readiness.
         Container will be removed from service endpoints if the probe fails.
         Cannot be updated.
         More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         +optional
         """
+
     @property
     def startupProbe(self) -> global___Probe:
         """StartupProbe indicates that the Pod has successfully initialized.
         If specified, no other probes are executed until this completes successfully.
         If this probe fails, the Pod will be restarted, just as if the livenessProbe failed.
         This can be used to provide different probe parameters at the beginning of a Pod's lifecycle,
         when it might take a long time to load data or warm a cache, than during steady-state operation.
         This cannot be updated.
         More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         +optional
         """
+
     @property
     def lifecycle(self) -> global___Lifecycle:
         """Actions that the management system should take in response to container lifecycle events.
         Cannot be updated.
         +optional
         """
-    terminationMessagePath: builtins.str
-    """Optional: Path at which the file to which the container's termination message
-    will be written is mounted into the container's filesystem.
-    Message written is intended to be brief final status, such as an assertion failure message.
-    Will be truncated by the node if greater than 4096 bytes. The total message length across
-    all containers will be limited to 12kb.
-    Defaults to /dev/termination-log.
-    Cannot be updated.
-    +optional
-    """
-    terminationMessagePolicy: builtins.str
-    """Indicate how the termination message should be populated. File will use the contents of
-    terminationMessagePath to populate the container status message on both success and failure.
-    FallbackToLogsOnError will use the last chunk of container log output if the termination
-    message file is empty and the container exited with an error.
-    The log output is limited to 2048 bytes or 80 lines, whichever is smaller.
-    Defaults to File.
-    Cannot be updated.
-    +optional
-    """
-    imagePullPolicy: builtins.str
-    """Image pull policy.
-    One of Always, Never, IfNotPresent.
-    Defaults to Always if :latest tag is specified, or IfNotPresent otherwise.
-    Cannot be updated.
-    More info: https://kubernetes.io/docs/concepts/containers/images#updating-images
-    +optional
-    """
+
     @property
     def securityContext(self) -> global___SecurityContext:
         """SecurityContext defines the security options the container should be run with.
         If set, the fields of SecurityContext override the equivalent fields of PodSecurityContext.
         More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
         +optional
         """
-    stdin: builtins.bool
-    """Whether this container should allocate a buffer for stdin in the container runtime. If this
-    is not set, reads from stdin in the container will always result in EOF.
-    Default is false.
-    +optional
-    """
-    stdinOnce: builtins.bool
-    """Whether the container runtime should close the stdin channel after it has been opened by
-    a single attach. When stdin is true the stdin stream will remain open across multiple attach
-    sessions. If stdinOnce is set to true, stdin is opened on container start, is empty until the
-    first client attaches to stdin, and then remains open and accepts data until the client disconnects,
-    at which time stdin is closed and remains closed until the container is restarted. If this
-    flag is false, a container processes that reads from stdin will never receive an EOF.
-    Default is false
-    +optional
-    """
-    tty: builtins.bool
-    """Whether this container should allocate a TTY for itself, also requires 'stdin' to be true.
-    Default is false.
-    +optional
-    """
+
     def __init__(
         self,
         *,
         name: builtins.str | None = ...,
         image: builtins.str | None = ...,
         command: collections.abc.Iterable[builtins.str] | None = ...,
         args: collections.abc.Iterable[builtins.str] | None = ...,
@@ -1431,49 +1474,50 @@
         terminationMessagePolicy: builtins.str | None = ...,
         imagePullPolicy: builtins.str | None = ...,
         securityContext: global___SecurityContext | None = ...,
         stdin: builtins.bool | None = ...,
         stdinOnce: builtins.bool | None = ...,
         tty: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["image", b"image", "imagePullPolicy", b"imagePullPolicy", "lifecycle", b"lifecycle", "livenessProbe", b"livenessProbe", "name", b"name", "readinessProbe", b"readinessProbe", "resources", b"resources", "securityContext", b"securityContext", "startupProbe", b"startupProbe", "stdin", b"stdin", "stdinOnce", b"stdinOnce", "terminationMessagePath", b"terminationMessagePath", "terminationMessagePolicy", b"terminationMessagePolicy", "tty", b"tty", "workingDir", b"workingDir"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["args", b"args", "command", b"command", "env", b"env", "envFrom", b"envFrom", "image", b"image", "imagePullPolicy", b"imagePullPolicy", "lifecycle", b"lifecycle", "livenessProbe", b"livenessProbe", "name", b"name", "ports", b"ports", "readinessProbe", b"readinessProbe", "resources", b"resources", "securityContext", b"securityContext", "startupProbe", b"startupProbe", "stdin", b"stdin", "stdinOnce", b"stdinOnce", "terminationMessagePath", b"terminationMessagePath", "terminationMessagePolicy", b"terminationMessagePolicy", "tty", b"tty", "volumeDevices", b"volumeDevices", "volumeMounts", b"volumeMounts", "workingDir", b"workingDir"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["image", b"image", "imagePullPolicy", b"imagePullPolicy", "lifecycle", b"lifecycle", "livenessProbe", b"livenessProbe", "name", b"name", "readinessProbe", b"readinessProbe", "resources", b"resources", "securityContext", b"securityContext", "startupProbe", b"startupProbe", "stdin", b"stdin", "stdinOnce", b"stdinOnce", "terminationMessagePath", b"terminationMessagePath", "terminationMessagePolicy", b"terminationMessagePolicy", "tty", b"tty", "workingDir", b"workingDir"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["args", b"args", "command", b"command", "env", b"env", "envFrom", b"envFrom", "image", b"image", "imagePullPolicy", b"imagePullPolicy", "lifecycle", b"lifecycle", "livenessProbe", b"livenessProbe", "name", b"name", "ports", b"ports", "readinessProbe", b"readinessProbe", "resources", b"resources", "securityContext", b"securityContext", "startupProbe", b"startupProbe", "stdin", b"stdin", "stdinOnce", b"stdinOnce", "terminationMessagePath", b"terminationMessagePath", "terminationMessagePolicy", b"terminationMessagePolicy", "tty", b"tty", "volumeDevices", b"volumeDevices", "volumeMounts", b"volumeMounts", "workingDir", b"workingDir"]) -> None: ...
 
 global___Container = Container
 
-@typing_extensions.final
+@typing.final
 class ContainerImage(google.protobuf.message.Message):
     """Describe a container image"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAMES_FIELD_NUMBER: builtins.int
     SIZEBYTES_FIELD_NUMBER: builtins.int
+    sizeBytes: builtins.int
+    """The size of the image in bytes.
+    +optional
+    """
     @property
     def names(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """Names by which this image is known.
         e.g. ["k8s.gcr.io/hyperkube:v1.0.7", "dockerhub.io/google_containers/hyperkube:v1.0.7"]
         +optional
         """
-    sizeBytes: builtins.int
-    """The size of the image in bytes.
-    +optional
-    """
+
     def __init__(
         self,
         *,
         names: collections.abc.Iterable[builtins.str] | None = ...,
         sizeBytes: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["sizeBytes", b"sizeBytes"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["names", b"names", "sizeBytes", b"sizeBytes"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["sizeBytes", b"sizeBytes"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["names", b"names", "sizeBytes", b"sizeBytes"]) -> None: ...
 
 global___ContainerImage = ContainerImage
 
-@typing_extensions.final
+@typing.final
 class ContainerPort(google.protobuf.message.Message):
     """ContainerPort represents a network port in a single container."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     HOSTPORT_FIELD_NUMBER: builtins.int
@@ -1512,20 +1556,20 @@
         *,
         name: builtins.str | None = ...,
         hostPort: builtins.int | None = ...,
         containerPort: builtins.int | None = ...,
         protocol: builtins.str | None = ...,
         hostIP: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["containerPort", b"containerPort", "hostIP", b"hostIP", "hostPort", b"hostPort", "name", b"name", "protocol", b"protocol"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["containerPort", b"containerPort", "hostIP", b"hostIP", "hostPort", b"hostPort", "name", b"name", "protocol", b"protocol"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["containerPort", b"containerPort", "hostIP", b"hostIP", "hostPort", b"hostPort", "name", b"name", "protocol", b"protocol"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["containerPort", b"containerPort", "hostIP", b"hostIP", "hostPort", b"hostPort", "name", b"name", "protocol", b"protocol"]) -> None: ...
 
 global___ContainerPort = ContainerPort
 
-@typing_extensions.final
+@typing.final
 class ContainerState(google.protobuf.message.Message):
     """ContainerState holds a possible state of container.
     Only one of its members may be specified.
     If none of them is specified, the default one is ContainerStateWaiting.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -1534,59 +1578,63 @@
     RUNNING_FIELD_NUMBER: builtins.int
     TERMINATED_FIELD_NUMBER: builtins.int
     @property
     def waiting(self) -> global___ContainerStateWaiting:
         """Details about a waiting container
         +optional
         """
+
     @property
     def running(self) -> global___ContainerStateRunning:
         """Details about a running container
         +optional
         """
+
     @property
     def terminated(self) -> global___ContainerStateTerminated:
         """Details about a terminated container
         +optional
         """
+
     def __init__(
         self,
         *,
         waiting: global___ContainerStateWaiting | None = ...,
         running: global___ContainerStateRunning | None = ...,
         terminated: global___ContainerStateTerminated | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["running", b"running", "terminated", b"terminated", "waiting", b"waiting"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["running", b"running", "terminated", b"terminated", "waiting", b"waiting"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["running", b"running", "terminated", b"terminated", "waiting", b"waiting"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["running", b"running", "terminated", b"terminated", "waiting", b"waiting"]) -> None: ...
 
 global___ContainerState = ContainerState
 
-@typing_extensions.final
+@typing.final
 class ContainerStateRunning(google.protobuf.message.Message):
     """ContainerStateRunning is a running state of a container."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     STARTEDAT_FIELD_NUMBER: builtins.int
     @property
     def startedAt(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
         """Time at which the container was last (re-)started
         +optional
         """
+
     def __init__(
         self,
         *,
         startedAt: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["startedAt", b"startedAt"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["startedAt", b"startedAt"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["startedAt", b"startedAt"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["startedAt", b"startedAt"]) -> None: ...
 
 global___ContainerStateRunning = ContainerStateRunning
 
-@typing_extensions.final
+@typing.final
 class ContainerStateTerminated(google.protobuf.message.Message):
     """ContainerStateTerminated is a terminated state of a container."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     EXITCODE_FIELD_NUMBER: builtins.int
     SIGNAL_FIELD_NUMBER: builtins.int
@@ -1605,45 +1653,47 @@
     """(brief) reason from the last termination of the container
     +optional
     """
     message: builtins.str
     """Message regarding the last termination of the container
     +optional
     """
+    containerID: builtins.str
+    """Container's ID in the format 'docker://<container_id>'
+    +optional
+    """
     @property
     def startedAt(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
         """Time at which previous execution of the container started
         +optional
         """
+
     @property
     def finishedAt(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
         """Time at which the container last terminated
         +optional
         """
-    containerID: builtins.str
-    """Container's ID in the format 'docker://<container_id>'
-    +optional
-    """
+
     def __init__(
         self,
         *,
         exitCode: builtins.int | None = ...,
         signal: builtins.int | None = ...,
         reason: builtins.str | None = ...,
         message: builtins.str | None = ...,
         startedAt: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time | None = ...,
         finishedAt: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time | None = ...,
         containerID: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["containerID", b"containerID", "exitCode", b"exitCode", "finishedAt", b"finishedAt", "message", b"message", "reason", b"reason", "signal", b"signal", "startedAt", b"startedAt"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["containerID", b"containerID", "exitCode", b"exitCode", "finishedAt", b"finishedAt", "message", b"message", "reason", b"reason", "signal", b"signal", "startedAt", b"startedAt"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["containerID", b"containerID", "exitCode", b"exitCode", "finishedAt", b"finishedAt", "message", b"message", "reason", b"reason", "signal", b"signal", "startedAt", b"startedAt"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["containerID", b"containerID", "exitCode", b"exitCode", "finishedAt", b"finishedAt", "message", b"message", "reason", b"reason", "signal", b"signal", "startedAt", b"startedAt"]) -> None: ...
 
 global___ContainerStateTerminated = ContainerStateTerminated
 
-@typing_extensions.final
+@typing.final
 class ContainerStateWaiting(google.protobuf.message.Message):
     """ContainerStateWaiting is a waiting state of a container."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     REASON_FIELD_NUMBER: builtins.int
     MESSAGE_FIELD_NUMBER: builtins.int
@@ -1657,20 +1707,20 @@
     """
     def __init__(
         self,
         *,
         reason: builtins.str | None = ...,
         message: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["message", b"message", "reason", b"reason"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["message", b"message", "reason", b"reason"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["message", b"message", "reason", b"reason"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["message", b"message", "reason", b"reason"]) -> None: ...
 
 global___ContainerStateWaiting = ContainerStateWaiting
 
-@typing_extensions.final
+@typing.final
 class ContainerStatus(google.protobuf.message.Message):
     """ContainerStatus contains details for the current status of this container."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     STATE_FIELD_NUMBER: builtins.int
@@ -1681,24 +1731,14 @@
     IMAGEID_FIELD_NUMBER: builtins.int
     CONTAINERID_FIELD_NUMBER: builtins.int
     STARTED_FIELD_NUMBER: builtins.int
     name: builtins.str
     """This must be a DNS_LABEL. Each container in a pod must have a unique name.
     Cannot be updated.
     """
-    @property
-    def state(self) -> global___ContainerState:
-        """Details about the container's current condition.
-        +optional
-        """
-    @property
-    def lastState(self) -> global___ContainerState:
-        """Details about the container's last termination condition.
-        +optional
-        """
     ready: builtins.bool
     """Specifies whether the container has passed its readiness probe."""
     restartCount: builtins.int
     """The number of times the container has been restarted, currently based on
     the number of dead containers that have not yet been removed.
     Note that this is calculated from dead containers. But those containers are subject to
     garbage collection. This value will get capped at 5 by GC.
@@ -1717,158 +1757,174 @@
     started: builtins.bool
     """Specifies whether the container has passed its startup probe.
     Initialized as false, becomes true after startupProbe is considered successful.
     Resets to false when the container is restarted, or if kubelet loses state temporarily.
     Is always true when no startupProbe is defined.
     +optional
     """
+    @property
+    def state(self) -> global___ContainerState:
+        """Details about the container's current condition.
+        +optional
+        """
+
+    @property
+    def lastState(self) -> global___ContainerState:
+        """Details about the container's last termination condition.
+        +optional
+        """
+
     def __init__(
         self,
         *,
         name: builtins.str | None = ...,
         state: global___ContainerState | None = ...,
         lastState: global___ContainerState | None = ...,
         ready: builtins.bool | None = ...,
         restartCount: builtins.int | None = ...,
         image: builtins.str | None = ...,
         imageID: builtins.str | None = ...,
         containerID: builtins.str | None = ...,
         started: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["containerID", b"containerID", "image", b"image", "imageID", b"imageID", "lastState", b"lastState", "name", b"name", "ready", b"ready", "restartCount", b"restartCount", "started", b"started", "state", b"state"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["containerID", b"containerID", "image", b"image", "imageID", b"imageID", "lastState", b"lastState", "name", b"name", "ready", b"ready", "restartCount", b"restartCount", "started", b"started", "state", b"state"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["containerID", b"containerID", "image", b"image", "imageID", b"imageID", "lastState", b"lastState", "name", b"name", "ready", b"ready", "restartCount", b"restartCount", "started", b"started", "state", b"state"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["containerID", b"containerID", "image", b"image", "imageID", b"imageID", "lastState", b"lastState", "name", b"name", "ready", b"ready", "restartCount", b"restartCount", "started", b"started", "state", b"state"]) -> None: ...
 
 global___ContainerStatus = ContainerStatus
 
-@typing_extensions.final
+@typing.final
 class DaemonEndpoint(google.protobuf.message.Message):
     """DaemonEndpoint contains information about a single Daemon endpoint."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PORT_FIELD_NUMBER: builtins.int
     Port: builtins.int
     """Port number of the given endpoint."""
     def __init__(
         self,
         *,
         Port: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["Port", b"Port"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["Port", b"Port"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["Port", b"Port"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["Port", b"Port"]) -> None: ...
 
 global___DaemonEndpoint = DaemonEndpoint
 
-@typing_extensions.final
+@typing.final
 class DownwardAPIProjection(google.protobuf.message.Message):
     """Represents downward API info for projecting into a projected volume.
     Note that this is identical to a downwardAPI volume source without the default
     mode.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___DownwardAPIVolumeFile]:
         """Items is a list of DownwardAPIVolume file
         +optional
         """
+
     def __init__(
         self,
         *,
         items: collections.abc.Iterable[global___DownwardAPIVolumeFile] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items"]) -> None: ...
 
 global___DownwardAPIProjection = DownwardAPIProjection
 
-@typing_extensions.final
+@typing.final
 class DownwardAPIVolumeFile(google.protobuf.message.Message):
     """DownwardAPIVolumeFile represents information to create the file containing the pod field"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PATH_FIELD_NUMBER: builtins.int
     FIELDREF_FIELD_NUMBER: builtins.int
     RESOURCEFIELDREF_FIELD_NUMBER: builtins.int
     MODE_FIELD_NUMBER: builtins.int
     path: builtins.str
     """Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'"""
+    mode: builtins.int
+    """Optional: mode bits used to set permissions on this file, must be an octal value
+    between 0000 and 0777 or a decimal value between 0 and 511.
+    YAML accepts both octal and decimal values, JSON requires decimal values for mode bits.
+    If not specified, the volume defaultMode will be used.
+    This might be in conflict with other options that affect the file
+    mode, like fsGroup, and the result can be other mode bits set.
+    +optional
+    """
     @property
     def fieldRef(self) -> global___ObjectFieldSelector:
         """Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
         +optional
         """
+
     @property
     def resourceFieldRef(self) -> global___ResourceFieldSelector:
         """Selects a resource of the container: only resources limits and requests
         (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
         +optional
         """
-    mode: builtins.int
-    """Optional: mode bits used to set permissions on this file, must be an octal value
-    between 0000 and 0777 or a decimal value between 0 and 511.
-    YAML accepts both octal and decimal values, JSON requires decimal values for mode bits.
-    If not specified, the volume defaultMode will be used.
-    This might be in conflict with other options that affect the file
-    mode, like fsGroup, and the result can be other mode bits set.
-    +optional
-    """
+
     def __init__(
         self,
         *,
         path: builtins.str | None = ...,
         fieldRef: global___ObjectFieldSelector | None = ...,
         resourceFieldRef: global___ResourceFieldSelector | None = ...,
         mode: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fieldRef", b"fieldRef", "mode", b"mode", "path", b"path", "resourceFieldRef", b"resourceFieldRef"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["fieldRef", b"fieldRef", "mode", b"mode", "path", b"path", "resourceFieldRef", b"resourceFieldRef"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fieldRef", b"fieldRef", "mode", b"mode", "path", b"path", "resourceFieldRef", b"resourceFieldRef"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["fieldRef", b"fieldRef", "mode", b"mode", "path", b"path", "resourceFieldRef", b"resourceFieldRef"]) -> None: ...
 
 global___DownwardAPIVolumeFile = DownwardAPIVolumeFile
 
-@typing_extensions.final
+@typing.final
 class DownwardAPIVolumeSource(google.protobuf.message.Message):
     """DownwardAPIVolumeSource represents a volume containing downward API info.
     Downward API volumes support ownership management and SELinux relabeling.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     ITEMS_FIELD_NUMBER: builtins.int
     DEFAULTMODE_FIELD_NUMBER: builtins.int
-    @property
-    def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___DownwardAPIVolumeFile]:
-        """Items is a list of downward API volume file
-        +optional
-        """
     defaultMode: builtins.int
     """Optional: mode bits to use on created files by default. Must be a
     Optional: mode bits used to set permissions on created files by default.
     Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511.
     YAML accepts both octal and decimal values, JSON requires decimal values for mode bits.
     Defaults to 0644.
     Directories within the path are not affected by this setting.
     This might be in conflict with other options that affect the file
     mode, like fsGroup, and the result can be other mode bits set.
     +optional
     """
+    @property
+    def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___DownwardAPIVolumeFile]:
+        """Items is a list of downward API volume file
+        +optional
+        """
+
     def __init__(
         self,
         *,
         items: collections.abc.Iterable[global___DownwardAPIVolumeFile] | None = ...,
         defaultMode: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["defaultMode", b"defaultMode"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["defaultMode", b"defaultMode", "items", b"items"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["defaultMode", b"defaultMode"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["defaultMode", b"defaultMode", "items", b"items"]) -> None: ...
 
 global___DownwardAPIVolumeSource = DownwardAPIVolumeSource
 
-@typing_extensions.final
+@typing.final
 class EmptyDirVolumeSource(google.protobuf.message.Message):
     """Represents an empty directory for a pod.
     Empty directory volumes support ownership management and SELinux relabeling.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -1887,26 +1943,27 @@
         The size limit is also applicable for memory medium.
         The maximum usage on memory medium EmptyDir would be the minimum value between
         the SizeLimit specified here and the sum of memory limits of all containers in a pod.
         The default is nil which means that the limit is undefined.
         More info: http://kubernetes.io/docs/user-guide/volumes#emptydir
         +optional
         """
+
     def __init__(
         self,
         *,
         medium: builtins.str | None = ...,
         sizeLimit: armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["medium", b"medium", "sizeLimit", b"sizeLimit"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["medium", b"medium", "sizeLimit", b"sizeLimit"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["medium", b"medium", "sizeLimit", b"sizeLimit"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["medium", b"medium", "sizeLimit", b"sizeLimit"]) -> None: ...
 
 global___EmptyDirVolumeSource = EmptyDirVolumeSource
 
-@typing_extensions.final
+@typing.final
 class EndpointAddress(google.protobuf.message.Message):
     """EndpointAddress is a tuple that describes single IP address.
     +structType=atomic
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -1931,28 +1988,29 @@
     +optional
     """
     @property
     def targetRef(self) -> global___ObjectReference:
         """Reference to object providing the endpoint.
         +optional
         """
+
     def __init__(
         self,
         *,
         ip: builtins.str | None = ...,
         hostname: builtins.str | None = ...,
         nodeName: builtins.str | None = ...,
         targetRef: global___ObjectReference | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["hostname", b"hostname", "ip", b"ip", "nodeName", b"nodeName", "targetRef", b"targetRef"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["hostname", b"hostname", "ip", b"ip", "nodeName", b"nodeName", "targetRef", b"targetRef"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["hostname", b"hostname", "ip", b"ip", "nodeName", b"nodeName", "targetRef", b"targetRef"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["hostname", b"hostname", "ip", b"ip", "nodeName", b"nodeName", "targetRef", b"targetRef"]) -> None: ...
 
 global___EndpointAddress = EndpointAddress
 
-@typing_extensions.final
+@typing.final
 class EndpointPort(google.protobuf.message.Message):
     """EndpointPort is a tuple that describes a single port.
     +structType=atomic
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -1988,20 +2046,20 @@
         self,
         *,
         name: builtins.str | None = ...,
         port: builtins.int | None = ...,
         protocol: builtins.str | None = ...,
         appProtocol: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["appProtocol", b"appProtocol", "name", b"name", "port", b"port", "protocol", b"protocol"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["appProtocol", b"appProtocol", "name", b"name", "port", b"port", "protocol", b"protocol"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["appProtocol", b"appProtocol", "name", b"name", "port", b"port", "protocol", b"protocol"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["appProtocol", b"appProtocol", "name", b"name", "port", b"port", "protocol", b"protocol"]) -> None: ...
 
 global___EndpointPort = EndpointPort
 
-@typing_extensions.final
+@typing.final
 class EndpointSubset(google.protobuf.message.Message):
     """EndpointSubset is a group of addresses with a common set of ports. The
     expanded set of endpoints is the Cartesian product of Addresses x Ports.
     For example, given:
       {
         Addresses: [{"ip": "10.10.1.1"}, {"ip": "10.10.2.2"}],
         Ports:     [{"name": "a", "port": 8675}, {"name": "b", "port": 309}]
@@ -2018,38 +2076,41 @@
     PORTS_FIELD_NUMBER: builtins.int
     @property
     def addresses(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___EndpointAddress]:
         """IP addresses which offer the related ports that are marked as ready. These endpoints
         should be considered safe for load balancers and clients to utilize.
         +optional
         """
+
     @property
     def notReadyAddresses(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___EndpointAddress]:
         """IP addresses which offer the related ports but are not currently marked as ready
         because they have not yet finished starting, have recently failed a readiness check,
         or have recently failed a liveness check.
         +optional
         """
+
     @property
     def ports(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___EndpointPort]:
         """Port numbers available on the related IP addresses.
         +optional
         """
+
     def __init__(
         self,
         *,
         addresses: collections.abc.Iterable[global___EndpointAddress] | None = ...,
         notReadyAddresses: collections.abc.Iterable[global___EndpointAddress] | None = ...,
         ports: collections.abc.Iterable[global___EndpointPort] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["addresses", b"addresses", "notReadyAddresses", b"notReadyAddresses", "ports", b"ports"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["addresses", b"addresses", "notReadyAddresses", b"notReadyAddresses", "ports", b"ports"]) -> None: ...
 
 global___EndpointSubset = EndpointSubset
 
-@typing_extensions.final
+@typing.final
 class Endpoints(google.protobuf.message.Message):
     """Endpoints is a collection of endpoints that implement the actual service. Example:
       Name: "mysvc",
       Subsets: [
         {
           Addresses: [{"ip": "10.10.1.1"}, {"ip": "10.10.2.2"}],
           Ports: [{"name": "a", "port": 8675}, {"name": "b", "port": 309}]
@@ -2067,65 +2128,69 @@
     SUBSETS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def subsets(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___EndpointSubset]:
         """The set of all endpoints is the union of all subsets. Addresses are placed into
         subsets according to the IPs they share. A single address with multiple ports,
         some of which are ready and some of which are not (because they come from
         different containers) will result in the address being displayed in different
         subsets for the different ports. No address will appear in both Addresses and
         NotReadyAddresses in the same subset.
         Sets of addresses and ports that comprise a service.
         +optional
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         subsets: collections.abc.Iterable[global___EndpointSubset] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "subsets", b"subsets"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["metadata", b"metadata", "subsets", b"subsets"]) -> None: ...
 
 global___Endpoints = Endpoints
 
-@typing_extensions.final
+@typing.final
 class EndpointsList(google.protobuf.message.Message):
     """EndpointsList is a list of endpoints."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """Standard list metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Endpoints]:
         """List of endpoints."""
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[global___Endpoints] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___EndpointsList = EndpointsList
 
-@typing_extensions.final
+@typing.final
 class EnvFromSource(google.protobuf.message.Message):
     """EnvFromSource represents the source of a set of ConfigMaps"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PREFIX_FIELD_NUMBER: builtins.int
     CONFIGMAPREF_FIELD_NUMBER: builtins.int
@@ -2135,32 +2200,34 @@
     +optional
     """
     @property
     def configMapRef(self) -> global___ConfigMapEnvSource:
         """The ConfigMap to select from
         +optional
         """
+
     @property
     def secretRef(self) -> global___SecretEnvSource:
         """The Secret to select from
         +optional
         """
+
     def __init__(
         self,
         *,
         prefix: builtins.str | None = ...,
         configMapRef: global___ConfigMapEnvSource | None = ...,
         secretRef: global___SecretEnvSource | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["configMapRef", b"configMapRef", "prefix", b"prefix", "secretRef", b"secretRef"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["configMapRef", b"configMapRef", "prefix", b"prefix", "secretRef", b"secretRef"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["configMapRef", b"configMapRef", "prefix", b"prefix", "secretRef", b"secretRef"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["configMapRef", b"configMapRef", "prefix", b"prefix", "secretRef", b"secretRef"]) -> None: ...
 
 global___EnvFromSource = EnvFromSource
 
-@typing_extensions.final
+@typing.final
 class EnvVar(google.protobuf.message.Message):
     """EnvVar represents an environment variable present in a Container."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     VALUE_FIELD_NUMBER: builtins.int
@@ -2180,27 +2247,28 @@
     +optional
     """
     @property
     def valueFrom(self) -> global___EnvVarSource:
         """Source for the environment variable's value. Cannot be used if value is not empty.
         +optional
         """
+
     def __init__(
         self,
         *,
         name: builtins.str | None = ...,
         value: builtins.str | None = ...,
         valueFrom: global___EnvVarSource | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["name", b"name", "value", b"value", "valueFrom", b"valueFrom"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["name", b"name", "value", b"value", "valueFrom", b"valueFrom"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["name", b"name", "value", b"value", "valueFrom", b"valueFrom"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["name", b"name", "value", b"value", "valueFrom", b"valueFrom"]) -> None: ...
 
 global___EnvVar = EnvVar
 
-@typing_extensions.final
+@typing.final
 class EnvVarSource(google.protobuf.message.Message):
     """EnvVarSource represents a source for the value of an EnvVar."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     FIELDREF_FIELD_NUMBER: builtins.int
     RESOURCEFIELDREF_FIELD_NUMBER: builtins.int
@@ -2208,44 +2276,48 @@
     SECRETKEYREF_FIELD_NUMBER: builtins.int
     @property
     def fieldRef(self) -> global___ObjectFieldSelector:
         """Selects a field of the pod: supports metadata.name, metadata.namespace, `metadata.labels['<KEY>']`, `metadata.annotations['<KEY>']`,
         spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.
         +optional
         """
+
     @property
     def resourceFieldRef(self) -> global___ResourceFieldSelector:
         """Selects a resource of the container: only resources limits and requests
         (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported.
         +optional
         """
+
     @property
     def configMapKeyRef(self) -> global___ConfigMapKeySelector:
         """Selects a key of a ConfigMap.
         +optional
         """
+
     @property
     def secretKeyRef(self) -> global___SecretKeySelector:
         """Selects a key of a secret in the pod's namespace
         +optional
         """
+
     def __init__(
         self,
         *,
         fieldRef: global___ObjectFieldSelector | None = ...,
         resourceFieldRef: global___ResourceFieldSelector | None = ...,
         configMapKeyRef: global___ConfigMapKeySelector | None = ...,
         secretKeyRef: global___SecretKeySelector | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["configMapKeyRef", b"configMapKeyRef", "fieldRef", b"fieldRef", "resourceFieldRef", b"resourceFieldRef", "secretKeyRef", b"secretKeyRef"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["configMapKeyRef", b"configMapKeyRef", "fieldRef", b"fieldRef", "resourceFieldRef", b"resourceFieldRef", "secretKeyRef", b"secretKeyRef"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["configMapKeyRef", b"configMapKeyRef", "fieldRef", b"fieldRef", "resourceFieldRef", b"resourceFieldRef", "secretKeyRef", b"secretKeyRef"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["configMapKeyRef", b"configMapKeyRef", "fieldRef", b"fieldRef", "resourceFieldRef", b"resourceFieldRef", "secretKeyRef", b"secretKeyRef"]) -> None: ...
 
 global___EnvVarSource = EnvVarSource
 
-@typing_extensions.final
+@typing.final
 class EphemeralContainer(google.protobuf.message.Message):
     """An EphemeralContainer is a container that may be added temporarily to an existing pod for
     user-initiated activities such as debugging. Ephemeral containers have no resource or
     scheduling guarantees, and they will not be restarted when they exit or when a pod is
     removed or restarted. If an ephemeral container causes a pod to exceed its resource
     allocation, the pod may be evicted.
     Ephemeral containers may not be added by directly updating the pod spec. They must be added
@@ -2254,40 +2326,41 @@
     This is an alpha feature enabled by the EphemeralContainers feature flag.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     EPHEMERALCONTAINERCOMMON_FIELD_NUMBER: builtins.int
     TARGETCONTAINERNAME_FIELD_NUMBER: builtins.int
-    @property
-    def ephemeralContainerCommon(self) -> global___EphemeralContainerCommon:
-        """Ephemeral containers have all of the fields of Container, plus additional fields
-        specific to ephemeral containers. Fields in common with Container are in the
-        following inlined struct so than an EphemeralContainer may easily be converted
-        to a Container.
-        """
     targetContainerName: builtins.str
     """If set, the name of the container from PodSpec that this ephemeral container targets.
     The ephemeral container will be run in the namespaces (IPC, PID, etc) of this container.
     If not set then the ephemeral container is run in whatever namespaces are shared
     for the pod. Note that the container runtime must support this feature.
     +optional
     """
+    @property
+    def ephemeralContainerCommon(self) -> global___EphemeralContainerCommon:
+        """Ephemeral containers have all of the fields of Container, plus additional fields
+        specific to ephemeral containers. Fields in common with Container are in the
+        following inlined struct so than an EphemeralContainer may easily be converted
+        to a Container.
+        """
+
     def __init__(
         self,
         *,
         ephemeralContainerCommon: global___EphemeralContainerCommon | None = ...,
         targetContainerName: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["ephemeralContainerCommon", b"ephemeralContainerCommon", "targetContainerName", b"targetContainerName"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["ephemeralContainerCommon", b"ephemeralContainerCommon", "targetContainerName", b"targetContainerName"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["ephemeralContainerCommon", b"ephemeralContainerCommon", "targetContainerName", b"targetContainerName"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["ephemeralContainerCommon", b"ephemeralContainerCommon", "targetContainerName", b"targetContainerName"]) -> None: ...
 
 global___EphemeralContainer = EphemeralContainer
 
-@typing_extensions.final
+@typing.final
 class EphemeralContainerCommon(google.protobuf.message.Message):
     """EphemeralContainerCommon is a copy of all fields in Container to be inlined in
     EphemeralContainer. This separate type allows easy conversion from EphemeralContainer
     to Container and allows separate documentation for the fields of EphemeralContainer.
     When a new field is added to Container it must be added here as well.
     """
 
@@ -2319,162 +2392,175 @@
     """Name of the ephemeral container specified as a DNS_LABEL.
     This name must be unique among all containers, init containers and ephemeral containers.
     """
     image: builtins.str
     """Docker image name.
     More info: https://kubernetes.io/docs/concepts/containers/images
     """
+    workingDir: builtins.str
+    """Container's working directory.
+    If not specified, the container runtime's default will be used, which
+    might be configured in the container image.
+    Cannot be updated.
+    +optional
+    """
+    terminationMessagePath: builtins.str
+    """Optional: Path at which the file to which the container's termination message
+    will be written is mounted into the container's filesystem.
+    Message written is intended to be brief final status, such as an assertion failure message.
+    Will be truncated by the node if greater than 4096 bytes. The total message length across
+    all containers will be limited to 12kb.
+    Defaults to /dev/termination-log.
+    Cannot be updated.
+    +optional
+    """
+    terminationMessagePolicy: builtins.str
+    """Indicate how the termination message should be populated. File will use the contents of
+    terminationMessagePath to populate the container status message on both success and failure.
+    FallbackToLogsOnError will use the last chunk of container log output if the termination
+    message file is empty and the container exited with an error.
+    The log output is limited to 2048 bytes or 80 lines, whichever is smaller.
+    Defaults to File.
+    Cannot be updated.
+    +optional
+    """
+    imagePullPolicy: builtins.str
+    """Image pull policy.
+    One of Always, Never, IfNotPresent.
+    Defaults to Always if :latest tag is specified, or IfNotPresent otherwise.
+    Cannot be updated.
+    More info: https://kubernetes.io/docs/concepts/containers/images#updating-images
+    +optional
+    """
+    stdin: builtins.bool
+    """Whether this container should allocate a buffer for stdin in the container runtime. If this
+    is not set, reads from stdin in the container will always result in EOF.
+    Default is false.
+    +optional
+    """
+    stdinOnce: builtins.bool
+    """Whether the container runtime should close the stdin channel after it has been opened by
+    a single attach. When stdin is true the stdin stream will remain open across multiple attach
+    sessions. If stdinOnce is set to true, stdin is opened on container start, is empty until the
+    first client attaches to stdin, and then remains open and accepts data until the client disconnects,
+    at which time stdin is closed and remains closed until the container is restarted. If this
+    flag is false, a container processes that reads from stdin will never receive an EOF.
+    Default is false
+    +optional
+    """
+    tty: builtins.bool
+    """Whether this container should allocate a TTY for itself, also requires 'stdin' to be true.
+    Default is false.
+    +optional
+    """
     @property
     def command(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """Entrypoint array. Not executed within a shell.
         The docker image's ENTRYPOINT is used if this is not provided.
         Variable references $(VAR_NAME) are expanded using the container's environment. If a variable
         cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced
         to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. "$$(VAR_NAME)" will
         produce the string literal "$(VAR_NAME)". Escaped references will never be expanded, regardless
         of whether the variable exists or not. Cannot be updated.
         More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell
         +optional
         """
+
     @property
     def args(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """Arguments to the entrypoint.
         The docker image's CMD is used if this is not provided.
         Variable references $(VAR_NAME) are expanded using the container's environment. If a variable
         cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced
         to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. "$$(VAR_NAME)" will
         produce the string literal "$(VAR_NAME)". Escaped references will never be expanded, regardless
         of whether the variable exists or not. Cannot be updated.
         More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell
         +optional
         """
-    workingDir: builtins.str
-    """Container's working directory.
-    If not specified, the container runtime's default will be used, which
-    might be configured in the container image.
-    Cannot be updated.
-    +optional
-    """
+
     @property
     def ports(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ContainerPort]:
         """Ports are not allowed for ephemeral containers."""
+
     @property
     def envFrom(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___EnvFromSource]:
         """List of sources to populate environment variables in the container.
         The keys defined within a source must be a C_IDENTIFIER. All invalid keys
         will be reported as an event when the container is starting. When a key exists in multiple
         sources, the value associated with the last source will take precedence.
         Values defined by an Env with a duplicate key will take precedence.
         Cannot be updated.
         +optional
         """
+
     @property
     def env(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___EnvVar]:
         """List of environment variables to set in the container.
         Cannot be updated.
         +optional
         +patchMergeKey=name
         +patchStrategy=merge
         """
+
     @property
     def resources(self) -> global___ResourceRequirements:
         """Resources are not allowed for ephemeral containers. Ephemeral containers use spare resources
         already allocated to the pod.
         +optional
         """
+
     @property
     def volumeMounts(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___VolumeMount]:
         """Pod volumes to mount into the container's filesystem.
         Cannot be updated.
         +optional
         +patchMergeKey=mountPath
         +patchStrategy=merge
         """
+
     @property
     def volumeDevices(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___VolumeDevice]:
         """volumeDevices is the list of block devices to be used by the container.
         +patchMergeKey=devicePath
         +patchStrategy=merge
         +optional
         """
+
     @property
     def livenessProbe(self) -> global___Probe:
         """Probes are not allowed for ephemeral containers.
         +optional
         """
+
     @property
     def readinessProbe(self) -> global___Probe:
         """Probes are not allowed for ephemeral containers.
         +optional
         """
+
     @property
     def startupProbe(self) -> global___Probe:
         """Probes are not allowed for ephemeral containers.
         +optional
         """
+
     @property
     def lifecycle(self) -> global___Lifecycle:
         """Lifecycle is not allowed for ephemeral containers.
         +optional
         """
-    terminationMessagePath: builtins.str
-    """Optional: Path at which the file to which the container's termination message
-    will be written is mounted into the container's filesystem.
-    Message written is intended to be brief final status, such as an assertion failure message.
-    Will be truncated by the node if greater than 4096 bytes. The total message length across
-    all containers will be limited to 12kb.
-    Defaults to /dev/termination-log.
-    Cannot be updated.
-    +optional
-    """
-    terminationMessagePolicy: builtins.str
-    """Indicate how the termination message should be populated. File will use the contents of
-    terminationMessagePath to populate the container status message on both success and failure.
-    FallbackToLogsOnError will use the last chunk of container log output if the termination
-    message file is empty and the container exited with an error.
-    The log output is limited to 2048 bytes or 80 lines, whichever is smaller.
-    Defaults to File.
-    Cannot be updated.
-    +optional
-    """
-    imagePullPolicy: builtins.str
-    """Image pull policy.
-    One of Always, Never, IfNotPresent.
-    Defaults to Always if :latest tag is specified, or IfNotPresent otherwise.
-    Cannot be updated.
-    More info: https://kubernetes.io/docs/concepts/containers/images#updating-images
-    +optional
-    """
+
     @property
     def securityContext(self) -> global___SecurityContext:
         """Optional: SecurityContext defines the security options the ephemeral container should be run with.
         If set, the fields of SecurityContext override the equivalent fields of PodSecurityContext.
         +optional
         """
-    stdin: builtins.bool
-    """Whether this container should allocate a buffer for stdin in the container runtime. If this
-    is not set, reads from stdin in the container will always result in EOF.
-    Default is false.
-    +optional
-    """
-    stdinOnce: builtins.bool
-    """Whether the container runtime should close the stdin channel after it has been opened by
-    a single attach. When stdin is true the stdin stream will remain open across multiple attach
-    sessions. If stdinOnce is set to true, stdin is opened on container start, is empty until the
-    first client attaches to stdin, and then remains open and accepts data until the client disconnects,
-    at which time stdin is closed and remains closed until the container is restarted. If this
-    flag is false, a container processes that reads from stdin will never receive an EOF.
-    Default is false
-    +optional
-    """
-    tty: builtins.bool
-    """Whether this container should allocate a TTY for itself, also requires 'stdin' to be true.
-    Default is false.
-    +optional
-    """
+
     def __init__(
         self,
         *,
         name: builtins.str | None = ...,
         image: builtins.str | None = ...,
         command: collections.abc.Iterable[builtins.str] | None = ...,
         args: collections.abc.Iterable[builtins.str] | None = ...,
@@ -2493,20 +2579,20 @@
         terminationMessagePolicy: builtins.str | None = ...,
         imagePullPolicy: builtins.str | None = ...,
         securityContext: global___SecurityContext | None = ...,
         stdin: builtins.bool | None = ...,
         stdinOnce: builtins.bool | None = ...,
         tty: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["image", b"image", "imagePullPolicy", b"imagePullPolicy", "lifecycle", b"lifecycle", "livenessProbe", b"livenessProbe", "name", b"name", "readinessProbe", b"readinessProbe", "resources", b"resources", "securityContext", b"securityContext", "startupProbe", b"startupProbe", "stdin", b"stdin", "stdinOnce", b"stdinOnce", "terminationMessagePath", b"terminationMessagePath", "terminationMessagePolicy", b"terminationMessagePolicy", "tty", b"tty", "workingDir", b"workingDir"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["args", b"args", "command", b"command", "env", b"env", "envFrom", b"envFrom", "image", b"image", "imagePullPolicy", b"imagePullPolicy", "lifecycle", b"lifecycle", "livenessProbe", b"livenessProbe", "name", b"name", "ports", b"ports", "readinessProbe", b"readinessProbe", "resources", b"resources", "securityContext", b"securityContext", "startupProbe", b"startupProbe", "stdin", b"stdin", "stdinOnce", b"stdinOnce", "terminationMessagePath", b"terminationMessagePath", "terminationMessagePolicy", b"terminationMessagePolicy", "tty", b"tty", "volumeDevices", b"volumeDevices", "volumeMounts", b"volumeMounts", "workingDir", b"workingDir"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["image", b"image", "imagePullPolicy", b"imagePullPolicy", "lifecycle", b"lifecycle", "livenessProbe", b"livenessProbe", "name", b"name", "readinessProbe", b"readinessProbe", "resources", b"resources", "securityContext", b"securityContext", "startupProbe", b"startupProbe", "stdin", b"stdin", "stdinOnce", b"stdinOnce", "terminationMessagePath", b"terminationMessagePath", "terminationMessagePolicy", b"terminationMessagePolicy", "tty", b"tty", "workingDir", b"workingDir"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["args", b"args", "command", b"command", "env", b"env", "envFrom", b"envFrom", "image", b"image", "imagePullPolicy", b"imagePullPolicy", "lifecycle", b"lifecycle", "livenessProbe", b"livenessProbe", "name", b"name", "ports", b"ports", "readinessProbe", b"readinessProbe", "resources", b"resources", "securityContext", b"securityContext", "startupProbe", b"startupProbe", "stdin", b"stdin", "stdinOnce", b"stdinOnce", "terminationMessagePath", b"terminationMessagePath", "terminationMessagePolicy", b"terminationMessagePolicy", "tty", b"tty", "volumeDevices", b"volumeDevices", "volumeMounts", b"volumeMounts", "workingDir", b"workingDir"]) -> None: ...
 
 global___EphemeralContainerCommon = EphemeralContainerCommon
 
-@typing_extensions.final
+@typing.final
 class EphemeralVolumeSource(google.protobuf.message.Message):
     """Represents an ephemeral volume that is handled by a normal storage driver."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     VOLUMECLAIMTEMPLATE_FIELD_NUMBER: builtins.int
     @property
@@ -2529,25 +2615,26 @@
         manually reconstructing a broken cluster.
 
         This field is read-only and no changes will be made by Kubernetes
         to the PVC after it has been created.
 
         Required, must not be nil.
         """
+
     def __init__(
         self,
         *,
         volumeClaimTemplate: global___PersistentVolumeClaimTemplate | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["volumeClaimTemplate", b"volumeClaimTemplate"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["volumeClaimTemplate", b"volumeClaimTemplate"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["volumeClaimTemplate", b"volumeClaimTemplate"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["volumeClaimTemplate", b"volumeClaimTemplate"]) -> None: ...
 
 global___EphemeralVolumeSource = EphemeralVolumeSource
 
-@typing_extensions.final
+@typing.final
 class Event(google.protobuf.message.Message):
     """Event is a report of an event somewhere in the cluster.  Events
     have a limited retention time and triggers and messages may evolve
     with time.  Event consumers should not rely on the timing of an event
     with a given Reason reflecting a consistent underlying trigger, or the
     continued existence of events with that Reason.  Events should be
     treated as informative, best-effort, supplemental data.
@@ -2566,83 +2653,91 @@
     TYPE_FIELD_NUMBER: builtins.int
     EVENTTIME_FIELD_NUMBER: builtins.int
     SERIES_FIELD_NUMBER: builtins.int
     ACTION_FIELD_NUMBER: builtins.int
     RELATED_FIELD_NUMBER: builtins.int
     REPORTINGCOMPONENT_FIELD_NUMBER: builtins.int
     REPORTINGINSTANCE_FIELD_NUMBER: builtins.int
-    @property
-    def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
-        """Standard object's metadata.
-        More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
-        """
-    @property
-    def involvedObject(self) -> global___ObjectReference:
-        """The object that this event is about."""
     reason: builtins.str
     """This should be a short, machine understandable string that gives the reason
     for the transition into the object's current status.
     TODO: provide exact specification for format.
     +optional
     """
     message: builtins.str
     """A human-readable description of the status of this operation.
     TODO: decide on maximum length.
     +optional
     """
+    count: builtins.int
+    """The number of times this event has occurred.
+    +optional
+    """
+    type: builtins.str
+    """Type of this event (Normal, Warning), new types could be added in the future
+    +optional
+    """
+    action: builtins.str
+    """What action was taken/failed regarding to the Regarding object.
+    +optional
+    """
+    reportingComponent: builtins.str
+    """Name of the controller that emitted this Event, e.g. `kubernetes.io/kubelet`.
+    +optional
+    """
+    reportingInstance: builtins.str
+    """ID of the controller instance, e.g. `kubelet-xyzf`.
+    +optional
+    """
+    @property
+    def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
+        """Standard object's metadata.
+        More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
+        """
+
+    @property
+    def involvedObject(self) -> global___ObjectReference:
+        """The object that this event is about."""
+
     @property
     def source(self) -> global___EventSource:
         """The component reporting this event. Should be a short machine understandable string.
         +optional
         """
+
     @property
     def firstTimestamp(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
         """The time at which the event was first recorded. (Time of server receipt is in TypeMeta.)
         +optional
         """
+
     @property
     def lastTimestamp(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
         """The time at which the most recent occurrence of this event was recorded.
         +optional
         """
-    count: builtins.int
-    """The number of times this event has occurred.
-    +optional
-    """
-    type: builtins.str
-    """Type of this event (Normal, Warning), new types could be added in the future
-    +optional
-    """
+
     @property
     def eventTime(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.MicroTime:
         """Time when this Event was first observed.
         +optional
         """
+
     @property
     def series(self) -> global___EventSeries:
         """Data about the Event series this event represents or nil if it's a singleton Event.
         +optional
         """
-    action: builtins.str
-    """What action was taken/failed regarding to the Regarding object.
-    +optional
-    """
+
     @property
     def related(self) -> global___ObjectReference:
         """Optional secondary object for more complex actions.
         +optional
         """
-    reportingComponent: builtins.str
-    """Name of the controller that emitted this Event, e.g. `kubernetes.io/kubelet`.
-    +optional
-    """
-    reportingInstance: builtins.str
-    """ID of the controller instance, e.g. `kubelet-xyzf`.
-    +optional
-    """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         involvedObject: global___ObjectReference | None = ...,
         reason: builtins.str | None = ...,
         message: builtins.str | None = ...,
@@ -2654,74 +2749,77 @@
         eventTime: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.MicroTime | None = ...,
         series: global___EventSeries | None = ...,
         action: builtins.str | None = ...,
         related: global___ObjectReference | None = ...,
         reportingComponent: builtins.str | None = ...,
         reportingInstance: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["action", b"action", "count", b"count", "eventTime", b"eventTime", "firstTimestamp", b"firstTimestamp", "involvedObject", b"involvedObject", "lastTimestamp", b"lastTimestamp", "message", b"message", "metadata", b"metadata", "reason", b"reason", "related", b"related", "reportingComponent", b"reportingComponent", "reportingInstance", b"reportingInstance", "series", b"series", "source", b"source", "type", b"type"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["action", b"action", "count", b"count", "eventTime", b"eventTime", "firstTimestamp", b"firstTimestamp", "involvedObject", b"involvedObject", "lastTimestamp", b"lastTimestamp", "message", b"message", "metadata", b"metadata", "reason", b"reason", "related", b"related", "reportingComponent", b"reportingComponent", "reportingInstance", b"reportingInstance", "series", b"series", "source", b"source", "type", b"type"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["action", b"action", "count", b"count", "eventTime", b"eventTime", "firstTimestamp", b"firstTimestamp", "involvedObject", b"involvedObject", "lastTimestamp", b"lastTimestamp", "message", b"message", "metadata", b"metadata", "reason", b"reason", "related", b"related", "reportingComponent", b"reportingComponent", "reportingInstance", b"reportingInstance", "series", b"series", "source", b"source", "type", b"type"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["action", b"action", "count", b"count", "eventTime", b"eventTime", "firstTimestamp", b"firstTimestamp", "involvedObject", b"involvedObject", "lastTimestamp", b"lastTimestamp", "message", b"message", "metadata", b"metadata", "reason", b"reason", "related", b"related", "reportingComponent", b"reportingComponent", "reportingInstance", b"reportingInstance", "series", b"series", "source", b"source", "type", b"type"]) -> None: ...
 
 global___Event = Event
 
-@typing_extensions.final
+@typing.final
 class EventList(google.protobuf.message.Message):
     """EventList is a list of events."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """Standard list metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Event]:
         """List of events"""
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[global___Event] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___EventList = EventList
 
-@typing_extensions.final
+@typing.final
 class EventSeries(google.protobuf.message.Message):
     """EventSeries contain information on series of events, i.e. thing that was/is happening
     continuously for some time.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     COUNT_FIELD_NUMBER: builtins.int
     LASTOBSERVEDTIME_FIELD_NUMBER: builtins.int
     count: builtins.int
     """Number of occurrences in this series up to the last heartbeat time"""
     @property
     def lastObservedTime(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.MicroTime:
         """Time of the last occurrence observed"""
+
     def __init__(
         self,
         *,
         count: builtins.int | None = ...,
         lastObservedTime: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.MicroTime | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["count", b"count", "lastObservedTime", b"lastObservedTime"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["count", b"count", "lastObservedTime", b"lastObservedTime"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["count", b"count", "lastObservedTime", b"lastObservedTime"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["count", b"count", "lastObservedTime", b"lastObservedTime"]) -> None: ...
 
 global___EventSeries = EventSeries
 
-@typing_extensions.final
+@typing.final
 class EventSource(google.protobuf.message.Message):
     """EventSource contains information for an event."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     COMPONENT_FIELD_NUMBER: builtins.int
     HOST_FIELD_NUMBER: builtins.int
@@ -2735,20 +2833,20 @@
     """
     def __init__(
         self,
         *,
         component: builtins.str | None = ...,
         host: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["component", b"component", "host", b"host"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["component", b"component", "host", b"host"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["component", b"component", "host", b"host"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["component", b"component", "host", b"host"]) -> None: ...
 
 global___EventSource = EventSource
 
-@typing_extensions.final
+@typing.final
 class ExecAction(google.protobuf.message.Message):
     """ExecAction describes a "run in container" action."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     COMMAND_FIELD_NUMBER: builtins.int
     @property
@@ -2756,42 +2854,38 @@
         """Command is the command line to execute inside the container, the working directory for the
         command  is root ('/') in the container's filesystem. The command is simply exec'd, it is
         not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use
         a shell, you need to explicitly call out to that shell.
         Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
         +optional
         """
+
     def __init__(
         self,
         *,
         command: collections.abc.Iterable[builtins.str] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["command", b"command"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["command", b"command"]) -> None: ...
 
 global___ExecAction = ExecAction
 
-@typing_extensions.final
+@typing.final
 class FCVolumeSource(google.protobuf.message.Message):
     """Represents a Fibre Channel volume.
     Fibre Channel volumes can only be mounted as read/write once.
     Fibre Channel volumes support ownership management and SELinux relabeling.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     TARGETWWNS_FIELD_NUMBER: builtins.int
     LUN_FIELD_NUMBER: builtins.int
     FSTYPE_FIELD_NUMBER: builtins.int
     READONLY_FIELD_NUMBER: builtins.int
     WWIDS_FIELD_NUMBER: builtins.int
-    @property
-    def targetWWNs(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
-        """Optional: FC target worldwide names (WWNs)
-        +optional
-        """
     lun: builtins.int
     """Optional: FC target lun number
     +optional
     """
     fsType: builtins.str
     """Filesystem type to mount.
     Must be a filesystem type supported by the host operating system.
@@ -2801,176 +2895,187 @@
     """
     readOnly: builtins.bool
     """Optional: Defaults to false (read/write). ReadOnly here will force
     the ReadOnly setting in VolumeMounts.
     +optional
     """
     @property
+    def targetWWNs(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
+        """Optional: FC target worldwide names (WWNs)
+        +optional
+        """
+
+    @property
     def wwids(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """Optional: FC volume world wide identifiers (wwids)
         Either wwids or combination of targetWWNs and lun must be set, but not both simultaneously.
         +optional
         """
+
     def __init__(
         self,
         *,
         targetWWNs: collections.abc.Iterable[builtins.str] | None = ...,
         lun: builtins.int | None = ...,
         fsType: builtins.str | None = ...,
         readOnly: builtins.bool | None = ...,
         wwids: collections.abc.Iterable[builtins.str] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "lun", b"lun", "readOnly", b"readOnly"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "lun", b"lun", "readOnly", b"readOnly", "targetWWNs", b"targetWWNs", "wwids", b"wwids"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fsType", b"fsType", "lun", b"lun", "readOnly", b"readOnly"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["fsType", b"fsType", "lun", b"lun", "readOnly", b"readOnly", "targetWWNs", b"targetWWNs", "wwids", b"wwids"]) -> None: ...
 
 global___FCVolumeSource = FCVolumeSource
 
-@typing_extensions.final
+@typing.final
 class FlexPersistentVolumeSource(google.protobuf.message.Message):
     """FlexPersistentVolumeSource represents a generic persistent volume resource that is
     provisioned/attached using an exec based plugin.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class OptionsEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: builtins.str | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     DRIVER_FIELD_NUMBER: builtins.int
     FSTYPE_FIELD_NUMBER: builtins.int
     SECRETREF_FIELD_NUMBER: builtins.int
     READONLY_FIELD_NUMBER: builtins.int
     OPTIONS_FIELD_NUMBER: builtins.int
     driver: builtins.str
     """Driver is the name of the driver to use for this volume."""
     fsType: builtins.str
     """Filesystem type to mount.
     Must be a filesystem type supported by the host operating system.
     Ex. "ext4", "xfs", "ntfs". The default filesystem depends on FlexVolume script.
     +optional
     """
+    readOnly: builtins.bool
+    """Optional: Defaults to false (read/write). ReadOnly here will force
+    the ReadOnly setting in VolumeMounts.
+    +optional
+    """
     @property
     def secretRef(self) -> global___SecretReference:
         """Optional: SecretRef is reference to the secret object containing
         sensitive information to pass to the plugin scripts. This may be
         empty if no secret object is specified. If the secret object
         contains more than one secret, all secrets are passed to the plugin
         scripts.
         +optional
         """
-    readOnly: builtins.bool
-    """Optional: Defaults to false (read/write). ReadOnly here will force
-    the ReadOnly setting in VolumeMounts.
-    +optional
-    """
+
     @property
     def options(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]:
         """Optional: Extra command options if any.
         +optional
         """
+
     def __init__(
         self,
         *,
         driver: builtins.str | None = ...,
         fsType: builtins.str | None = ...,
         secretRef: global___SecretReference | None = ...,
         readOnly: builtins.bool | None = ...,
         options: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["driver", b"driver", "fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["driver", b"driver", "fsType", b"fsType", "options", b"options", "readOnly", b"readOnly", "secretRef", b"secretRef"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["driver", b"driver", "fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["driver", b"driver", "fsType", b"fsType", "options", b"options", "readOnly", b"readOnly", "secretRef", b"secretRef"]) -> None: ...
 
 global___FlexPersistentVolumeSource = FlexPersistentVolumeSource
 
-@typing_extensions.final
+@typing.final
 class FlexVolumeSource(google.protobuf.message.Message):
     """FlexVolume represents a generic volume resource that is
     provisioned/attached using an exec based plugin.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class OptionsEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: builtins.str | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     DRIVER_FIELD_NUMBER: builtins.int
     FSTYPE_FIELD_NUMBER: builtins.int
     SECRETREF_FIELD_NUMBER: builtins.int
     READONLY_FIELD_NUMBER: builtins.int
     OPTIONS_FIELD_NUMBER: builtins.int
     driver: builtins.str
     """Driver is the name of the driver to use for this volume."""
     fsType: builtins.str
     """Filesystem type to mount.
     Must be a filesystem type supported by the host operating system.
     Ex. "ext4", "xfs", "ntfs". The default filesystem depends on FlexVolume script.
     +optional
     """
+    readOnly: builtins.bool
+    """Optional: Defaults to false (read/write). ReadOnly here will force
+    the ReadOnly setting in VolumeMounts.
+    +optional
+    """
     @property
     def secretRef(self) -> global___LocalObjectReference:
         """Optional: SecretRef is reference to the secret object containing
         sensitive information to pass to the plugin scripts. This may be
         empty if no secret object is specified. If the secret object
         contains more than one secret, all secrets are passed to the plugin
         scripts.
         +optional
         """
-    readOnly: builtins.bool
-    """Optional: Defaults to false (read/write). ReadOnly here will force
-    the ReadOnly setting in VolumeMounts.
-    +optional
-    """
+
     @property
     def options(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]:
         """Optional: Extra command options if any.
         +optional
         """
+
     def __init__(
         self,
         *,
         driver: builtins.str | None = ...,
         fsType: builtins.str | None = ...,
         secretRef: global___LocalObjectReference | None = ...,
         readOnly: builtins.bool | None = ...,
         options: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["driver", b"driver", "fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["driver", b"driver", "fsType", b"fsType", "options", b"options", "readOnly", b"readOnly", "secretRef", b"secretRef"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["driver", b"driver", "fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["driver", b"driver", "fsType", b"fsType", "options", b"options", "readOnly", b"readOnly", "secretRef", b"secretRef"]) -> None: ...
 
 global___FlexVolumeSource = FlexVolumeSource
 
-@typing_extensions.final
+@typing.final
 class FlockerVolumeSource(google.protobuf.message.Message):
     """Represents a Flocker volume mounted by the Flocker agent.
     One and only one of datasetName and datasetUUID should be set.
     Flocker volumes do not support ownership management or SELinux relabeling.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -2988,20 +3093,20 @@
     """
     def __init__(
         self,
         *,
         datasetName: builtins.str | None = ...,
         datasetUUID: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["datasetName", b"datasetName", "datasetUUID", b"datasetUUID"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["datasetName", b"datasetName", "datasetUUID", b"datasetUUID"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["datasetName", b"datasetName", "datasetUUID", b"datasetUUID"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["datasetName", b"datasetName", "datasetUUID", b"datasetUUID"]) -> None: ...
 
 global___FlockerVolumeSource = FlockerVolumeSource
 
-@typing_extensions.final
+@typing.final
 class GCEPersistentDiskVolumeSource(google.protobuf.message.Message):
     """Represents a Persistent Disk resource in Google Compute Engine.
 
     A GCE PD must exist before mounting to a container. The disk must
     also be in the same GCE project and zone as the kubelet. A GCE PD
     can only be mounted as read/write once or read-only many times. GCE
     PDs support ownership management and SELinux relabeling.
@@ -3043,20 +3148,20 @@
         self,
         *,
         pdName: builtins.str | None = ...,
         fsType: builtins.str | None = ...,
         partition: builtins.int | None = ...,
         readOnly: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "partition", b"partition", "pdName", b"pdName", "readOnly", b"readOnly"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "partition", b"partition", "pdName", b"pdName", "readOnly", b"readOnly"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fsType", b"fsType", "partition", b"partition", "pdName", b"pdName", "readOnly", b"readOnly"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["fsType", b"fsType", "partition", b"partition", "pdName", b"pdName", "readOnly", b"readOnly"]) -> None: ...
 
 global___GCEPersistentDiskVolumeSource = GCEPersistentDiskVolumeSource
 
-@typing_extensions.final
+@typing.final
 class GitRepoVolumeSource(google.protobuf.message.Message):
     """Represents a volume that is populated with the contents of a git repository.
     Git repo volumes do not support ownership management.
     Git repo volumes support SELinux relabeling.
 
     DEPRECATED: GitRepo is deprecated. To provision a container with a git repo, mount an
     EmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir
@@ -3084,20 +3189,20 @@
     def __init__(
         self,
         *,
         repository: builtins.str | None = ...,
         revision: builtins.str | None = ...,
         directory: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["directory", b"directory", "repository", b"repository", "revision", b"revision"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["directory", b"directory", "repository", b"repository", "revision", b"revision"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["directory", b"directory", "repository", b"repository", "revision", b"revision"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["directory", b"directory", "repository", b"repository", "revision", b"revision"]) -> None: ...
 
 global___GitRepoVolumeSource = GitRepoVolumeSource
 
-@typing_extensions.final
+@typing.final
 class GlusterfsPersistentVolumeSource(google.protobuf.message.Message):
     """Represents a Glusterfs mount that lasts the lifetime of a pod.
     Glusterfs volumes do not support ownership management or SELinux relabeling.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -3129,20 +3234,20 @@
         self,
         *,
         endpoints: builtins.str | None = ...,
         path: builtins.str | None = ...,
         readOnly: builtins.bool | None = ...,
         endpointsNamespace: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["endpoints", b"endpoints", "endpointsNamespace", b"endpointsNamespace", "path", b"path", "readOnly", b"readOnly"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["endpoints", b"endpoints", "endpointsNamespace", b"endpointsNamespace", "path", b"path", "readOnly", b"readOnly"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["endpoints", b"endpoints", "endpointsNamespace", b"endpointsNamespace", "path", b"path", "readOnly", b"readOnly"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["endpoints", b"endpoints", "endpointsNamespace", b"endpointsNamespace", "path", b"path", "readOnly", b"readOnly"]) -> None: ...
 
 global___GlusterfsPersistentVolumeSource = GlusterfsPersistentVolumeSource
 
-@typing_extensions.final
+@typing.final
 class GlusterfsVolumeSource(google.protobuf.message.Message):
     """Represents a Glusterfs mount that lasts the lifetime of a pod.
     Glusterfs volumes do not support ownership management or SELinux relabeling.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -3166,70 +3271,72 @@
     def __init__(
         self,
         *,
         endpoints: builtins.str | None = ...,
         path: builtins.str | None = ...,
         readOnly: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["endpoints", b"endpoints", "path", b"path", "readOnly", b"readOnly"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["endpoints", b"endpoints", "path", b"path", "readOnly", b"readOnly"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["endpoints", b"endpoints", "path", b"path", "readOnly", b"readOnly"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["endpoints", b"endpoints", "path", b"path", "readOnly", b"readOnly"]) -> None: ...
 
 global___GlusterfsVolumeSource = GlusterfsVolumeSource
 
-@typing_extensions.final
+@typing.final
 class HTTPGetAction(google.protobuf.message.Message):
     """HTTPGetAction describes an action based on HTTP Get requests."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PATH_FIELD_NUMBER: builtins.int
     PORT_FIELD_NUMBER: builtins.int
     HOST_FIELD_NUMBER: builtins.int
     SCHEME_FIELD_NUMBER: builtins.int
     HTTPHEADERS_FIELD_NUMBER: builtins.int
     path: builtins.str
     """Path to access on the HTTP server.
     +optional
     """
-    @property
-    def port(self) -> armada_client.k8s.io.apimachinery.pkg.util.intstr.generated_pb2.IntOrString:
-        """Name or number of the port to access on the container.
-        Number must be in the range 1 to 65535.
-        Name must be an IANA_SVC_NAME.
-        """
     host: builtins.str
     """Host name to connect to, defaults to the pod IP. You probably want to set
     "Host" in httpHeaders instead.
     +optional
     """
     scheme: builtins.str
     """Scheme to use for connecting to the host.
     Defaults to HTTP.
     +optional
     """
     @property
+    def port(self) -> armada_client.k8s.io.apimachinery.pkg.util.intstr.generated_pb2.IntOrString:
+        """Name or number of the port to access on the container.
+        Number must be in the range 1 to 65535.
+        Name must be an IANA_SVC_NAME.
+        """
+
+    @property
     def httpHeaders(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___HTTPHeader]:
         """Custom headers to set in the request. HTTP allows repeated headers.
         +optional
         """
+
     def __init__(
         self,
         *,
         path: builtins.str | None = ...,
         port: armada_client.k8s.io.apimachinery.pkg.util.intstr.generated_pb2.IntOrString | None = ...,
         host: builtins.str | None = ...,
         scheme: builtins.str | None = ...,
         httpHeaders: collections.abc.Iterable[global___HTTPHeader] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["host", b"host", "path", b"path", "port", b"port", "scheme", b"scheme"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["host", b"host", "httpHeaders", b"httpHeaders", "path", b"path", "port", b"port", "scheme", b"scheme"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["host", b"host", "path", b"path", "port", b"port", "scheme", b"scheme"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["host", b"host", "httpHeaders", b"httpHeaders", "path", b"path", "port", b"port", "scheme", b"scheme"]) -> None: ...
 
 global___HTTPGetAction = HTTPGetAction
 
-@typing_extensions.final
+@typing.final
 class HTTPHeader(google.protobuf.message.Message):
     """HTTPHeader describes a custom header to be used in HTTP probes"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     VALUE_FIELD_NUMBER: builtins.int
@@ -3239,20 +3346,20 @@
     """The header field value"""
     def __init__(
         self,
         *,
         name: builtins.str | None = ...,
         value: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["name", b"name", "value", b"value"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["name", b"name", "value", b"value"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["name", b"name", "value", b"value"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["name", b"name", "value", b"value"]) -> None: ...
 
 global___HTTPHeader = HTTPHeader
 
-@typing_extensions.final
+@typing.final
 class Handler(google.protobuf.message.Message):
     """Handler defines a specific action that should be taken
     TODO: pass structured data to these actions, and document that data here.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -3261,65 +3368,69 @@
     TCPSOCKET_FIELD_NUMBER: builtins.int
     @property
     def exec(self) -> global___ExecAction:
         """One and only one of the following should be specified.
         Exec specifies the action to take.
         +optional
         """
+
     @property
     def httpGet(self) -> global___HTTPGetAction:
         """HTTPGet specifies the http request to perform.
         +optional
         """
+
     @property
     def tcpSocket(self) -> global___TCPSocketAction:
         """TCPSocket specifies an action involving a TCP port.
         TCP hooks not yet supported
         TODO: implement a realistic TCP lifecycle hook
         +optional
         """
+
     def __init__(
         self,
         *,
         exec: global___ExecAction | None = ...,
         httpGet: global___HTTPGetAction | None = ...,
         tcpSocket: global___TCPSocketAction | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["exec", b"exec", "httpGet", b"httpGet", "tcpSocket", b"tcpSocket"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["exec", b"exec", "httpGet", b"httpGet", "tcpSocket", b"tcpSocket"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["exec", b"exec", "httpGet", b"httpGet", "tcpSocket", b"tcpSocket"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["exec", b"exec", "httpGet", b"httpGet", "tcpSocket", b"tcpSocket"]) -> None: ...
 
 global___Handler = Handler
 
-@typing_extensions.final
+@typing.final
 class HostAlias(google.protobuf.message.Message):
     """HostAlias holds the mapping between IP and hostnames that will be injected as an entry in the
     pod's hosts file.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     IP_FIELD_NUMBER: builtins.int
     HOSTNAMES_FIELD_NUMBER: builtins.int
     ip: builtins.str
     """IP address of the host file entry."""
     @property
     def hostnames(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """Hostnames for the above IP address."""
+
     def __init__(
         self,
         *,
         ip: builtins.str | None = ...,
         hostnames: collections.abc.Iterable[builtins.str] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["ip", b"ip"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["hostnames", b"hostnames", "ip", b"ip"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["ip", b"ip"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["hostnames", b"hostnames", "ip", b"ip"]) -> None: ...
 
 global___HostAlias = HostAlias
 
-@typing_extensions.final
+@typing.final
 class HostPathVolumeSource(google.protobuf.message.Message):
     """Represents a host path mapped into a pod.
     Host path volumes do not support ownership management or SELinux relabeling.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -3338,20 +3449,20 @@
     """
     def __init__(
         self,
         *,
         path: builtins.str | None = ...,
         type: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["path", b"path", "type", b"type"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["path", b"path", "type", b"type"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["path", b"path", "type", b"type"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["path", b"path", "type", b"type"]) -> None: ...
 
 global___HostPathVolumeSource = HostPathVolumeSource
 
-@typing_extensions.final
+@typing.final
 class ISCSIPersistentVolumeSource(google.protobuf.message.Message):
     """ISCSIPersistentVolumeSource represents an ISCSI disk.
     ISCSI volumes can only be mounted as read/write once.
     ISCSI volumes support ownership management and SELinux relabeling.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -3389,39 +3500,41 @@
     +optional
     """
     readOnly: builtins.bool
     """ReadOnly here will force the ReadOnly setting in VolumeMounts.
     Defaults to false.
     +optional
     """
-    @property
-    def portals(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
-        """iSCSI Target Portal List. The Portal is either an IP or ip_addr:port if the port
-        is other than default (typically TCP ports 860 and 3260).
-        +optional
-        """
     chapAuthDiscovery: builtins.bool
     """whether support iSCSI Discovery CHAP authentication
     +optional
     """
     chapAuthSession: builtins.bool
     """whether support iSCSI Session CHAP authentication
     +optional
     """
-    @property
-    def secretRef(self) -> global___SecretReference:
-        """CHAP Secret for iSCSI target and initiator authentication
-        +optional
-        """
     initiatorName: builtins.str
     """Custom iSCSI Initiator Name.
     If initiatorName is specified with iscsiInterface simultaneously, new iSCSI interface
     <target portal>:<volume name> will be created for the connection.
     +optional
     """
+    @property
+    def portals(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
+        """iSCSI Target Portal List. The Portal is either an IP or ip_addr:port if the port
+        is other than default (typically TCP ports 860 and 3260).
+        +optional
+        """
+
+    @property
+    def secretRef(self) -> global___SecretReference:
+        """CHAP Secret for iSCSI target and initiator authentication
+        +optional
+        """
+
     def __init__(
         self,
         *,
         targetPortal: builtins.str | None = ...,
         iqn: builtins.str | None = ...,
         lun: builtins.int | None = ...,
         iscsiInterface: builtins.str | None = ...,
@@ -3429,20 +3542,20 @@
         readOnly: builtins.bool | None = ...,
         portals: collections.abc.Iterable[builtins.str] | None = ...,
         chapAuthDiscovery: builtins.bool | None = ...,
         chapAuthSession: builtins.bool | None = ...,
         secretRef: global___SecretReference | None = ...,
         initiatorName: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["chapAuthDiscovery", b"chapAuthDiscovery", "chapAuthSession", b"chapAuthSession", "fsType", b"fsType", "initiatorName", b"initiatorName", "iqn", b"iqn", "iscsiInterface", b"iscsiInterface", "lun", b"lun", "readOnly", b"readOnly", "secretRef", b"secretRef", "targetPortal", b"targetPortal"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["chapAuthDiscovery", b"chapAuthDiscovery", "chapAuthSession", b"chapAuthSession", "fsType", b"fsType", "initiatorName", b"initiatorName", "iqn", b"iqn", "iscsiInterface", b"iscsiInterface", "lun", b"lun", "portals", b"portals", "readOnly", b"readOnly", "secretRef", b"secretRef", "targetPortal", b"targetPortal"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["chapAuthDiscovery", b"chapAuthDiscovery", "chapAuthSession", b"chapAuthSession", "fsType", b"fsType", "initiatorName", b"initiatorName", "iqn", b"iqn", "iscsiInterface", b"iscsiInterface", "lun", b"lun", "readOnly", b"readOnly", "secretRef", b"secretRef", "targetPortal", b"targetPortal"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["chapAuthDiscovery", b"chapAuthDiscovery", "chapAuthSession", b"chapAuthSession", "fsType", b"fsType", "initiatorName", b"initiatorName", "iqn", b"iqn", "iscsiInterface", b"iscsiInterface", "lun", b"lun", "portals", b"portals", "readOnly", b"readOnly", "secretRef", b"secretRef", "targetPortal", b"targetPortal"]) -> None: ...
 
 global___ISCSIPersistentVolumeSource = ISCSIPersistentVolumeSource
 
-@typing_extensions.final
+@typing.final
 class ISCSIVolumeSource(google.protobuf.message.Message):
     """Represents an ISCSI disk.
     ISCSI volumes can only be mounted as read/write once.
     ISCSI volumes support ownership management and SELinux relabeling.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -3480,39 +3593,41 @@
     +optional
     """
     readOnly: builtins.bool
     """ReadOnly here will force the ReadOnly setting in VolumeMounts.
     Defaults to false.
     +optional
     """
-    @property
-    def portals(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
-        """iSCSI Target Portal List. The portal is either an IP or ip_addr:port if the port
-        is other than default (typically TCP ports 860 and 3260).
-        +optional
-        """
     chapAuthDiscovery: builtins.bool
     """whether support iSCSI Discovery CHAP authentication
     +optional
     """
     chapAuthSession: builtins.bool
     """whether support iSCSI Session CHAP authentication
     +optional
     """
-    @property
-    def secretRef(self) -> global___LocalObjectReference:
-        """CHAP Secret for iSCSI target and initiator authentication
-        +optional
-        """
     initiatorName: builtins.str
     """Custom iSCSI Initiator Name.
     If initiatorName is specified with iscsiInterface simultaneously, new iSCSI interface
     <target portal>:<volume name> will be created for the connection.
     +optional
     """
+    @property
+    def portals(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
+        """iSCSI Target Portal List. The portal is either an IP or ip_addr:port if the port
+        is other than default (typically TCP ports 860 and 3260).
+        +optional
+        """
+
+    @property
+    def secretRef(self) -> global___LocalObjectReference:
+        """CHAP Secret for iSCSI target and initiator authentication
+        +optional
+        """
+
     def __init__(
         self,
         *,
         targetPortal: builtins.str | None = ...,
         iqn: builtins.str | None = ...,
         lun: builtins.int | None = ...,
         iscsiInterface: builtins.str | None = ...,
@@ -3520,20 +3635,20 @@
         readOnly: builtins.bool | None = ...,
         portals: collections.abc.Iterable[builtins.str] | None = ...,
         chapAuthDiscovery: builtins.bool | None = ...,
         chapAuthSession: builtins.bool | None = ...,
         secretRef: global___LocalObjectReference | None = ...,
         initiatorName: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["chapAuthDiscovery", b"chapAuthDiscovery", "chapAuthSession", b"chapAuthSession", "fsType", b"fsType", "initiatorName", b"initiatorName", "iqn", b"iqn", "iscsiInterface", b"iscsiInterface", "lun", b"lun", "readOnly", b"readOnly", "secretRef", b"secretRef", "targetPortal", b"targetPortal"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["chapAuthDiscovery", b"chapAuthDiscovery", "chapAuthSession", b"chapAuthSession", "fsType", b"fsType", "initiatorName", b"initiatorName", "iqn", b"iqn", "iscsiInterface", b"iscsiInterface", "lun", b"lun", "portals", b"portals", "readOnly", b"readOnly", "secretRef", b"secretRef", "targetPortal", b"targetPortal"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["chapAuthDiscovery", b"chapAuthDiscovery", "chapAuthSession", b"chapAuthSession", "fsType", b"fsType", "initiatorName", b"initiatorName", "iqn", b"iqn", "iscsiInterface", b"iscsiInterface", "lun", b"lun", "readOnly", b"readOnly", "secretRef", b"secretRef", "targetPortal", b"targetPortal"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["chapAuthDiscovery", b"chapAuthDiscovery", "chapAuthSession", b"chapAuthSession", "fsType", b"fsType", "initiatorName", b"initiatorName", "iqn", b"iqn", "iscsiInterface", b"iscsiInterface", "lun", b"lun", "portals", b"portals", "readOnly", b"readOnly", "secretRef", b"secretRef", "targetPortal", b"targetPortal"]) -> None: ...
 
 global___ISCSIVolumeSource = ISCSIVolumeSource
 
-@typing_extensions.final
+@typing.final
 class KeyToPath(google.protobuf.message.Message):
     """Maps a string key to a path within a volume."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     KEY_FIELD_NUMBER: builtins.int
     PATH_FIELD_NUMBER: builtins.int
@@ -3558,20 +3673,20 @@
     def __init__(
         self,
         *,
         key: builtins.str | None = ...,
         path: builtins.str | None = ...,
         mode: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["key", b"key", "mode", b"mode", "path", b"path"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "mode", b"mode", "path", b"path"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["key", b"key", "mode", b"mode", "path", b"path"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["key", b"key", "mode", b"mode", "path", b"path"]) -> None: ...
 
 global___KeyToPath = KeyToPath
 
-@typing_extensions.final
+@typing.final
 class Lifecycle(google.protobuf.message.Message):
     """Lifecycle describes actions that the management system should take in response to container lifecycle
     events. For the PostStart and PreStop lifecycle handlers, management of the container blocks
     until the action is complete, unless the container process fails, in which case the handler is aborted.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -3582,292 +3697,306 @@
     def postStart(self) -> global___Handler:
         """PostStart is called immediately after a container is created. If the handler fails,
         the container is terminated and restarted according to its restart policy.
         Other management of the container blocks until the hook completes.
         More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
         +optional
         """
+
     @property
     def preStop(self) -> global___Handler:
         """PreStop is called immediately before a container is terminated due to an
         API request or management event such as liveness/startup probe failure,
         preemption, resource contention, etc. The handler is not called if the
         container crashes or exits. The reason for termination is passed to the
         handler. The Pod's termination grace period countdown begins before the
         PreStop hooked is executed. Regardless of the outcome of the handler, the
         container will eventually terminate within the Pod's termination grace
         period. Other management of the container blocks until the hook completes
         or until the termination grace period is reached.
         More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
         +optional
         """
+
     def __init__(
         self,
         *,
         postStart: global___Handler | None = ...,
         preStop: global___Handler | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["postStart", b"postStart", "preStop", b"preStop"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["postStart", b"postStart", "preStop", b"preStop"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["postStart", b"postStart", "preStop", b"preStop"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["postStart", b"postStart", "preStop", b"preStop"]) -> None: ...
 
 global___Lifecycle = Lifecycle
 
-@typing_extensions.final
+@typing.final
 class LimitRange(google.protobuf.message.Message):
     """LimitRange sets resource usage limits for each kind of resource in a Namespace."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     SPEC_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def spec(self) -> global___LimitRangeSpec:
         """Spec defines the limits enforced.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         +optional
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         spec: global___LimitRangeSpec | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec"]) -> None: ...
 
 global___LimitRange = LimitRange
 
-@typing_extensions.final
+@typing.final
 class LimitRangeItem(google.protobuf.message.Message):
     """LimitRangeItem defines a min/max usage limit for any resource that matches on kind."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class MaxEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity: ...
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
-    @typing_extensions.final
+    @typing.final
     class MinEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity: ...
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
-    @typing_extensions.final
+    @typing.final
     class DefaultEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity: ...
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
-    @typing_extensions.final
+    @typing.final
     class DefaultRequestEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity: ...
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
-    @typing_extensions.final
+    @typing.final
     class MaxLimitRequestRatioEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity: ...
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     TYPE_FIELD_NUMBER: builtins.int
     MAX_FIELD_NUMBER: builtins.int
     MIN_FIELD_NUMBER: builtins.int
     DEFAULT_FIELD_NUMBER: builtins.int
     DEFAULTREQUEST_FIELD_NUMBER: builtins.int
     MAXLIMITREQUESTRATIO_FIELD_NUMBER: builtins.int
     type: builtins.str
     """Type of resource that this limit applies to."""
     @property
     def max(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity]:
         """Max usage constraints on this kind by resource name.
         +optional
         """
+
     @property
     def min(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity]:
         """Min usage constraints on this kind by resource name.
         +optional
         """
+
     @property
     def default(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity]:
         """Default resource requirement limit value by resource name if resource limit is omitted.
         +optional
         """
+
     @property
     def defaultRequest(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity]:
         """DefaultRequest is the default resource requirement request value by resource name if resource request is omitted.
         +optional
         """
+
     @property
     def maxLimitRequestRatio(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity]:
         """MaxLimitRequestRatio if specified, the named resource must have a request and limit that are both non-zero where limit divided by request is less than or equal to the enumerated value; this represents the max burst for the named resource.
         +optional
         """
+
     def __init__(
         self,
         *,
         type: builtins.str | None = ...,
         max: collections.abc.Mapping[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity] | None = ...,
         min: collections.abc.Mapping[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity] | None = ...,
         default: collections.abc.Mapping[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity] | None = ...,
         defaultRequest: collections.abc.Mapping[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity] | None = ...,
         maxLimitRequestRatio: collections.abc.Mapping[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["type", b"type"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["default", b"default", "defaultRequest", b"defaultRequest", "max", b"max", "maxLimitRequestRatio", b"maxLimitRequestRatio", "min", b"min", "type", b"type"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["type", b"type"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["default", b"default", "defaultRequest", b"defaultRequest", "max", b"max", "maxLimitRequestRatio", b"maxLimitRequestRatio", "min", b"min", "type", b"type"]) -> None: ...
 
 global___LimitRangeItem = LimitRangeItem
 
-@typing_extensions.final
+@typing.final
 class LimitRangeList(google.protobuf.message.Message):
     """LimitRangeList is a list of LimitRange items."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """Standard list metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___LimitRange]:
         """Items is a list of LimitRange objects.
         More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[global___LimitRange] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___LimitRangeList = LimitRangeList
 
-@typing_extensions.final
+@typing.final
 class LimitRangeSpec(google.protobuf.message.Message):
     """LimitRangeSpec defines a min/max usage limit for resources that match on kind."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     LIMITS_FIELD_NUMBER: builtins.int
     @property
     def limits(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___LimitRangeItem]:
         """Limits is the list of LimitRangeItem objects that are enforced."""
+
     def __init__(
         self,
         *,
         limits: collections.abc.Iterable[global___LimitRangeItem] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["limits", b"limits"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["limits", b"limits"]) -> None: ...
 
 global___LimitRangeSpec = LimitRangeSpec
 
-@typing_extensions.final
+@typing.final
 class List(google.protobuf.message.Message):
     """List holds a list of objects, which may not be known by the server."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """Standard list metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[armada_client.k8s.io.apimachinery.pkg.runtime.generated_pb2.RawExtension]:
         """List of objects"""
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[armada_client.k8s.io.apimachinery.pkg.runtime.generated_pb2.RawExtension] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___List = List
 
-@typing_extensions.final
+@typing.final
 class LoadBalancerIngress(google.protobuf.message.Message):
     """LoadBalancerIngress represents the status of a load-balancer ingress point:
     traffic intended for the service should be sent to an ingress point.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -3887,49 +4016,51 @@
     @property
     def ports(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PortStatus]:
         """Ports is a list of records of service ports
         If used, every port defined in the service should have an entry in it
         +listType=atomic
         +optional
         """
+
     def __init__(
         self,
         *,
         ip: builtins.str | None = ...,
         hostname: builtins.str | None = ...,
         ports: collections.abc.Iterable[global___PortStatus] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["hostname", b"hostname", "ip", b"ip"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["hostname", b"hostname", "ip", b"ip", "ports", b"ports"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["hostname", b"hostname", "ip", b"ip"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["hostname", b"hostname", "ip", b"ip", "ports", b"ports"]) -> None: ...
 
 global___LoadBalancerIngress = LoadBalancerIngress
 
-@typing_extensions.final
+@typing.final
 class LoadBalancerStatus(google.protobuf.message.Message):
     """LoadBalancerStatus represents the status of a load-balancer."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     INGRESS_FIELD_NUMBER: builtins.int
     @property
     def ingress(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___LoadBalancerIngress]:
         """Ingress is a list containing ingress points for the load-balancer.
         Traffic intended for the service should be sent to these ingress points.
         +optional
         """
+
     def __init__(
         self,
         *,
         ingress: collections.abc.Iterable[global___LoadBalancerIngress] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["ingress", b"ingress"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["ingress", b"ingress"]) -> None: ...
 
 global___LoadBalancerStatus = LoadBalancerStatus
 
-@typing_extensions.final
+@typing.final
 class LocalObjectReference(google.protobuf.message.Message):
     """LocalObjectReference contains enough information to let you locate the
     referenced object inside the same namespace.
     +structType=atomic
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -3942,20 +4073,20 @@
     +optional
     """
     def __init__(
         self,
         *,
         name: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["name", b"name"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["name", b"name"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["name", b"name"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["name", b"name"]) -> None: ...
 
 global___LocalObjectReference = LocalObjectReference
 
-@typing_extensions.final
+@typing.final
 class LocalVolumeSource(google.protobuf.message.Message):
     """Local represents directly-attached storage with node affinity (Beta feature)"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PATH_FIELD_NUMBER: builtins.int
     FSTYPE_FIELD_NUMBER: builtins.int
@@ -3972,20 +4103,20 @@
     """
     def __init__(
         self,
         *,
         path: builtins.str | None = ...,
         fsType: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "path", b"path"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "path", b"path"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fsType", b"fsType", "path", b"path"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["fsType", b"fsType", "path", b"path"]) -> None: ...
 
 global___LocalVolumeSource = LocalVolumeSource
 
-@typing_extensions.final
+@typing.final
 class NFSVolumeSource(google.protobuf.message.Message):
     """Represents an NFS mount that lasts the lifetime of a pod.
     NFS volumes do not support ownership management or SELinux relabeling.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -4010,20 +4141,20 @@
     def __init__(
         self,
         *,
         server: builtins.str | None = ...,
         path: builtins.str | None = ...,
         readOnly: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["path", b"path", "readOnly", b"readOnly", "server", b"server"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["path", b"path", "readOnly", b"readOnly", "server", b"server"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["path", b"path", "readOnly", b"readOnly", "server", b"server"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["path", b"path", "readOnly", b"readOnly", "server", b"server"]) -> None: ...
 
 global___NFSVolumeSource = NFSVolumeSource
 
-@typing_extensions.final
+@typing.final
 class Namespace(google.protobuf.message.Message):
     """Namespace provides a scope for Names.
     Use of multiple namespaces is optional.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -4032,127 +4163,134 @@
     STATUS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def spec(self) -> global___NamespaceSpec:
         """Spec defines the behavior of the Namespace.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         +optional
         """
+
     @property
     def status(self) -> global___NamespaceStatus:
         """Status describes the current status of a Namespace.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         +optional
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         spec: global___NamespaceSpec | None = ...,
         status: global___NamespaceStatus | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> None: ...
 
 global___Namespace = Namespace
 
-@typing_extensions.final
+@typing.final
 class NamespaceCondition(google.protobuf.message.Message):
     """NamespaceCondition contains details about state of namespace."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     TYPE_FIELD_NUMBER: builtins.int
     STATUS_FIELD_NUMBER: builtins.int
     LASTTRANSITIONTIME_FIELD_NUMBER: builtins.int
     REASON_FIELD_NUMBER: builtins.int
     MESSAGE_FIELD_NUMBER: builtins.int
     type: builtins.str
     """Type of namespace controller condition."""
     status: builtins.str
     """Status of the condition, one of True, False, Unknown."""
-    @property
-    def lastTransitionTime(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
-        """+optional"""
     reason: builtins.str
     """+optional"""
     message: builtins.str
     """+optional"""
+    @property
+    def lastTransitionTime(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
+        """+optional"""
+
     def __init__(
         self,
         *,
         type: builtins.str | None = ...,
         status: builtins.str | None = ...,
         lastTransitionTime: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time | None = ...,
         reason: builtins.str | None = ...,
         message: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> None: ...
 
 global___NamespaceCondition = NamespaceCondition
 
-@typing_extensions.final
+@typing.final
 class NamespaceList(google.protobuf.message.Message):
     """NamespaceList is a list of Namespaces."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """Standard list metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Namespace]:
         """Items is the list of Namespace objects in the list.
         More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[global___Namespace] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___NamespaceList = NamespaceList
 
-@typing_extensions.final
+@typing.final
 class NamespaceSpec(google.protobuf.message.Message):
     """NamespaceSpec describes the attributes on a Namespace."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     FINALIZERS_FIELD_NUMBER: builtins.int
     @property
     def finalizers(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """Finalizers is an opaque list of values that must be empty to permanently remove object from storage.
         More info: https://kubernetes.io/docs/tasks/administer-cluster/namespaces/
         +optional
         """
+
     def __init__(
         self,
         *,
         finalizers: collections.abc.Iterable[builtins.str] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["finalizers", b"finalizers"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["finalizers", b"finalizers"]) -> None: ...
 
 global___NamespaceSpec = NamespaceSpec
 
-@typing_extensions.final
+@typing.final
 class NamespaceStatus(google.protobuf.message.Message):
     """NamespaceStatus is information about the current status of a Namespace."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PHASE_FIELD_NUMBER: builtins.int
     CONDITIONS_FIELD_NUMBER: builtins.int
@@ -4164,26 +4302,27 @@
     @property
     def conditions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___NamespaceCondition]:
         """Represents the latest available observations of a namespace's current state.
         +optional
         +patchMergeKey=type
         +patchStrategy=merge
         """
+
     def __init__(
         self,
         *,
         phase: builtins.str | None = ...,
         conditions: collections.abc.Iterable[global___NamespaceCondition] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["phase", b"phase"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["conditions", b"conditions", "phase", b"phase"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["phase", b"phase"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["conditions", b"conditions", "phase", b"phase"]) -> None: ...
 
 global___NamespaceStatus = NamespaceStatus
 
-@typing_extensions.final
+@typing.final
 class Node(google.protobuf.message.Message):
     """Node is a worker node in Kubernetes.
     Each node will have a unique identifier in the cache (i.e. in etcd).
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -4192,41 +4331,44 @@
     STATUS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def spec(self) -> global___NodeSpec:
         """Spec defines the behavior of a node.
         https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         +optional
         """
+
     @property
     def status(self) -> global___NodeStatus:
         """Most recently observed status of the node.
         Populated by the system.
         Read-only.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         +optional
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         spec: global___NodeSpec | None = ...,
         status: global___NodeStatus | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> None: ...
 
 global___Node = Node
 
-@typing_extensions.final
+@typing.final
 class NodeAddress(google.protobuf.message.Message):
     """NodeAddress contains information for the node's address."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     TYPE_FIELD_NUMBER: builtins.int
     ADDRESS_FIELD_NUMBER: builtins.int
@@ -4236,20 +4378,20 @@
     """The node address."""
     def __init__(
         self,
         *,
         type: builtins.str | None = ...,
         address: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["address", b"address", "type", b"type"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["address", b"address", "type", b"type"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["address", b"address", "type", b"type"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["address", b"address", "type", b"type"]) -> None: ...
 
 global___NodeAddress = NodeAddress
 
-@typing_extensions.final
+@typing.final
 class NodeAffinity(google.protobuf.message.Message):
     """Node affinity is a group of node affinity scheduling rules."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     REQUIREDDURINGSCHEDULINGIGNOREDDURINGEXECUTION_FIELD_NUMBER: builtins.int
     PREFERREDDURINGSCHEDULINGIGNOREDDURINGEXECUTION_FIELD_NUMBER: builtins.int
@@ -4258,39 +4400,41 @@
         """If the affinity requirements specified by this field are not met at
         scheduling time, the pod will not be scheduled onto the node.
         If the affinity requirements specified by this field cease to be met
         at some point during pod execution (e.g. due to an update), the system
         may or may not try to eventually evict the pod from its node.
         +optional
         """
+
     @property
     def preferredDuringSchedulingIgnoredDuringExecution(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PreferredSchedulingTerm]:
         """The scheduler will prefer to schedule pods to nodes that satisfy
         the affinity expressions specified by this field, but it may choose
         a node that violates one or more of the expressions. The node that is
         most preferred is the one with the greatest sum of weights, i.e.
         for each node that meets all of the scheduling requirements (resource
         request, requiredDuringScheduling affinity expressions, etc.),
         compute a sum by iterating through the elements of this field and adding
         "weight" to the sum if the node matches the corresponding matchExpressions; the
         node(s) with the highest sum are the most preferred.
         +optional
         """
+
     def __init__(
         self,
         *,
         requiredDuringSchedulingIgnoredDuringExecution: global___NodeSelector | None = ...,
         preferredDuringSchedulingIgnoredDuringExecution: collections.abc.Iterable[global___PreferredSchedulingTerm] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["requiredDuringSchedulingIgnoredDuringExecution", b"requiredDuringSchedulingIgnoredDuringExecution"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["preferredDuringSchedulingIgnoredDuringExecution", b"preferredDuringSchedulingIgnoredDuringExecution", "requiredDuringSchedulingIgnoredDuringExecution", b"requiredDuringSchedulingIgnoredDuringExecution"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["requiredDuringSchedulingIgnoredDuringExecution", b"requiredDuringSchedulingIgnoredDuringExecution"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["preferredDuringSchedulingIgnoredDuringExecution", b"preferredDuringSchedulingIgnoredDuringExecution", "requiredDuringSchedulingIgnoredDuringExecution", b"requiredDuringSchedulingIgnoredDuringExecution"]) -> None: ...
 
 global___NodeAffinity = NodeAffinity
 
-@typing_extensions.final
+@typing.final
 class NodeCondition(google.protobuf.message.Message):
     """NodeCondition contains condition information for a node."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     TYPE_FIELD_NUMBER: builtins.int
     STATUS_FIELD_NUMBER: builtins.int
@@ -4298,99 +4442,119 @@
     LASTTRANSITIONTIME_FIELD_NUMBER: builtins.int
     REASON_FIELD_NUMBER: builtins.int
     MESSAGE_FIELD_NUMBER: builtins.int
     type: builtins.str
     """Type of node condition."""
     status: builtins.str
     """Status of the condition, one of True, False, Unknown."""
+    reason: builtins.str
+    """(brief) reason for the condition's last transition.
+    +optional
+    """
+    message: builtins.str
+    """Human readable message indicating details about last transition.
+    +optional
+    """
     @property
     def lastHeartbeatTime(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
         """Last time we got an update on a given condition.
         +optional
         """
+
     @property
     def lastTransitionTime(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
         """Last time the condition transit from one status to another.
         +optional
         """
-    reason: builtins.str
-    """(brief) reason for the condition's last transition.
-    +optional
-    """
-    message: builtins.str
-    """Human readable message indicating details about last transition.
-    +optional
-    """
+
     def __init__(
         self,
         *,
         type: builtins.str | None = ...,
         status: builtins.str | None = ...,
         lastHeartbeatTime: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time | None = ...,
         lastTransitionTime: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time | None = ...,
         reason: builtins.str | None = ...,
         message: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["lastHeartbeatTime", b"lastHeartbeatTime", "lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["lastHeartbeatTime", b"lastHeartbeatTime", "lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["lastHeartbeatTime", b"lastHeartbeatTime", "lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["lastHeartbeatTime", b"lastHeartbeatTime", "lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> None: ...
 
 global___NodeCondition = NodeCondition
 
-@typing_extensions.final
+@typing.final
 class NodeConfigSource(google.protobuf.message.Message):
     """NodeConfigSource specifies a source of node configuration. Exactly one subfield (excluding metadata) must be non-nil.
     This API is deprecated since 1.22
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     CONFIGMAP_FIELD_NUMBER: builtins.int
     @property
     def configMap(self) -> global___ConfigMapNodeConfigSource:
         """ConfigMap is a reference to a Node's ConfigMap"""
+
     def __init__(
         self,
         *,
         configMap: global___ConfigMapNodeConfigSource | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["configMap", b"configMap"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["configMap", b"configMap"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["configMap", b"configMap"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["configMap", b"configMap"]) -> None: ...
 
 global___NodeConfigSource = NodeConfigSource
 
-@typing_extensions.final
+@typing.final
 class NodeConfigStatus(google.protobuf.message.Message):
     """NodeConfigStatus describes the status of the config assigned by Node.Spec.ConfigSource."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     ASSIGNED_FIELD_NUMBER: builtins.int
     ACTIVE_FIELD_NUMBER: builtins.int
     LASTKNOWNGOOD_FIELD_NUMBER: builtins.int
     ERROR_FIELD_NUMBER: builtins.int
+    error: builtins.str
+    """Error describes any problems reconciling the Spec.ConfigSource to the Active config.
+    Errors may occur, for example, attempting to checkpoint Spec.ConfigSource to the local Assigned
+    record, attempting to checkpoint the payload associated with Spec.ConfigSource, attempting
+    to load or validate the Assigned config, etc.
+    Errors may occur at different points while syncing config. Earlier errors (e.g. download or
+    checkpointing errors) will not result in a rollback to LastKnownGood, and may resolve across
+    Kubelet retries. Later errors (e.g. loading or validating a checkpointed config) will result in
+    a rollback to LastKnownGood. In the latter case, it is usually possible to resolve the error
+    by fixing the config assigned in Spec.ConfigSource.
+    You can find additional information for debugging by searching the error message in the Kubelet log.
+    Error is a human-readable description of the error state; machines can check whether or not Error
+    is empty, but should not rely on the stability of the Error text across Kubelet versions.
+    +optional
+    """
     @property
     def assigned(self) -> global___NodeConfigSource:
         """Assigned reports the checkpointed config the node will try to use.
         When Node.Spec.ConfigSource is updated, the node checkpoints the associated
         config payload to local disk, along with a record indicating intended
         config. The node refers to this record to choose its config checkpoint, and
         reports this record in Assigned. Assigned only updates in the status after
         the record has been checkpointed to disk. When the Kubelet is restarted,
         it tries to make the Assigned config the Active config by loading and
         validating the checkpointed payload identified by Assigned.
         +optional
         """
+
     @property
     def active(self) -> global___NodeConfigSource:
         """Active reports the checkpointed config the node is actively using.
         Active will represent either the current version of the Assigned config,
         or the current LastKnownGood config, depending on whether attempting to use the
         Assigned config results in an error.
         +optional
         """
+
     @property
     def lastKnownGood(self) -> global___NodeConfigSource:
         """LastKnownGood reports the checkpointed config the node will fall back to
         when it encounters an error attempting to use the Assigned config.
         The Assigned config becomes the LastKnownGood config when the node determines
         that the Assigned config is stable and correct.
         This is currently implemented as a 10-minute soak period starting when the local
@@ -4398,93 +4562,82 @@
         of this period, it becomes the LastKnownGood. Note that if Spec.ConfigSource is
         reset to nil (use local defaults), the LastKnownGood is also immediately reset to nil,
         because the local default config is always assumed good.
         You should not make assumptions about the node's method of determining config stability
         and correctness, as this may change or become configurable in the future.
         +optional
         """
-    error: builtins.str
-    """Error describes any problems reconciling the Spec.ConfigSource to the Active config.
-    Errors may occur, for example, attempting to checkpoint Spec.ConfigSource to the local Assigned
-    record, attempting to checkpoint the payload associated with Spec.ConfigSource, attempting
-    to load or validate the Assigned config, etc.
-    Errors may occur at different points while syncing config. Earlier errors (e.g. download or
-    checkpointing errors) will not result in a rollback to LastKnownGood, and may resolve across
-    Kubelet retries. Later errors (e.g. loading or validating a checkpointed config) will result in
-    a rollback to LastKnownGood. In the latter case, it is usually possible to resolve the error
-    by fixing the config assigned in Spec.ConfigSource.
-    You can find additional information for debugging by searching the error message in the Kubelet log.
-    Error is a human-readable description of the error state; machines can check whether or not Error
-    is empty, but should not rely on the stability of the Error text across Kubelet versions.
-    +optional
-    """
+
     def __init__(
         self,
         *,
         assigned: global___NodeConfigSource | None = ...,
         active: global___NodeConfigSource | None = ...,
         lastKnownGood: global___NodeConfigSource | None = ...,
         error: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["active", b"active", "assigned", b"assigned", "error", b"error", "lastKnownGood", b"lastKnownGood"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["active", b"active", "assigned", b"assigned", "error", b"error", "lastKnownGood", b"lastKnownGood"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["active", b"active", "assigned", b"assigned", "error", b"error", "lastKnownGood", b"lastKnownGood"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["active", b"active", "assigned", b"assigned", "error", b"error", "lastKnownGood", b"lastKnownGood"]) -> None: ...
 
 global___NodeConfigStatus = NodeConfigStatus
 
-@typing_extensions.final
+@typing.final
 class NodeDaemonEndpoints(google.protobuf.message.Message):
     """NodeDaemonEndpoints lists ports opened by daemons running on the Node."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     KUBELETENDPOINT_FIELD_NUMBER: builtins.int
     @property
     def kubeletEndpoint(self) -> global___DaemonEndpoint:
         """Endpoint on which Kubelet is listening.
         +optional
         """
+
     def __init__(
         self,
         *,
         kubeletEndpoint: global___DaemonEndpoint | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["kubeletEndpoint", b"kubeletEndpoint"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["kubeletEndpoint", b"kubeletEndpoint"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["kubeletEndpoint", b"kubeletEndpoint"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["kubeletEndpoint", b"kubeletEndpoint"]) -> None: ...
 
 global___NodeDaemonEndpoints = NodeDaemonEndpoints
 
-@typing_extensions.final
+@typing.final
 class NodeList(google.protobuf.message.Message):
     """NodeList is the whole list of all Nodes which have been registered with master."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """Standard list metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Node]:
         """List of nodes"""
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[global___Node] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___NodeList = NodeList
 
-@typing_extensions.final
+@typing.final
 class NodeProxyOptions(google.protobuf.message.Message):
     """NodeProxyOptions is the query options to a Node's proxy call."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PATH_FIELD_NUMBER: builtins.int
     path: builtins.str
@@ -4492,82 +4645,84 @@
     +optional
     """
     def __init__(
         self,
         *,
         path: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["path", b"path"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["path", b"path"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["path", b"path"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["path", b"path"]) -> None: ...
 
 global___NodeProxyOptions = NodeProxyOptions
 
-@typing_extensions.final
+@typing.final
 class NodeResources(google.protobuf.message.Message):
     """NodeResources is an object for conveying resource information about a node.
     see https://kubernetes.io/docs/concepts/architecture/nodes/#capacity for more details.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class CapacityEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity: ...
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     CAPACITY_FIELD_NUMBER: builtins.int
     @property
     def capacity(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity]:
         """Capacity represents the available resources of a node"""
+
     def __init__(
         self,
         *,
         capacity: collections.abc.Mapping[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["capacity", b"capacity"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["capacity", b"capacity"]) -> None: ...
 
 global___NodeResources = NodeResources
 
-@typing_extensions.final
+@typing.final
 class NodeSelector(google.protobuf.message.Message):
     """A node selector represents the union of the results of one or more label queries
     over a set of nodes; that is, it represents the OR of the selectors represented
     by the node selector terms.
     +structType=atomic
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NODESELECTORTERMS_FIELD_NUMBER: builtins.int
     @property
     def nodeSelectorTerms(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___NodeSelectorTerm]:
         """Required. A list of node selector terms. The terms are ORed."""
+
     def __init__(
         self,
         *,
         nodeSelectorTerms: collections.abc.Iterable[global___NodeSelectorTerm] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["nodeSelectorTerms", b"nodeSelectorTerms"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["nodeSelectorTerms", b"nodeSelectorTerms"]) -> None: ...
 
 global___NodeSelector = NodeSelector
 
-@typing_extensions.final
+@typing.final
 class NodeSelectorRequirement(google.protobuf.message.Message):
     """A node selector requirement is a selector that contains values, a key, and an operator
     that relates the key and values.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -4585,27 +4740,28 @@
         """An array of string values. If the operator is In or NotIn,
         the values array must be non-empty. If the operator is Exists or DoesNotExist,
         the values array must be empty. If the operator is Gt or Lt, the values
         array must have a single element, which will be interpreted as an integer.
         This array is replaced during a strategic merge patch.
         +optional
         """
+
     def __init__(
         self,
         *,
         key: builtins.str | None = ...,
         operator: builtins.str | None = ...,
         values: collections.abc.Iterable[builtins.str] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["key", b"key", "operator", b"operator"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "operator", b"operator", "values", b"values"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["key", b"key", "operator", b"operator"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["key", b"key", "operator", b"operator", "values", b"values"]) -> None: ...
 
 global___NodeSelectorRequirement = NodeSelectorRequirement
 
-@typing_extensions.final
+@typing.final
 class NodeSelectorTerm(google.protobuf.message.Message):
     """A null or empty node selector term matches no objects. The requirements of
     them are ANDed.
     The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
     +structType=atomic
     """
 
@@ -4614,30 +4770,32 @@
     MATCHEXPRESSIONS_FIELD_NUMBER: builtins.int
     MATCHFIELDS_FIELD_NUMBER: builtins.int
     @property
     def matchExpressions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___NodeSelectorRequirement]:
         """A list of node selector requirements by node's labels.
         +optional
         """
+
     @property
     def matchFields(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___NodeSelectorRequirement]:
         """A list of node selector requirements by node's fields.
         +optional
         """
+
     def __init__(
         self,
         *,
         matchExpressions: collections.abc.Iterable[global___NodeSelectorRequirement] | None = ...,
         matchFields: collections.abc.Iterable[global___NodeSelectorRequirement] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["matchExpressions", b"matchExpressions", "matchFields", b"matchFields"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["matchExpressions", b"matchExpressions", "matchFields", b"matchFields"]) -> None: ...
 
 global___NodeSelectorTerm = NodeSelectorTerm
 
-@typing_extensions.final
+@typing.final
 class NodeSpec(google.protobuf.message.Message):
     """NodeSpec describes the attributes that a node is created with."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PODCIDR_FIELD_NUMBER: builtins.int
     PODCIDRS_FIELD_NUMBER: builtins.int
@@ -4646,186 +4804,199 @@
     TAINTS_FIELD_NUMBER: builtins.int
     CONFIGSOURCE_FIELD_NUMBER: builtins.int
     EXTERNALID_FIELD_NUMBER: builtins.int
     podCIDR: builtins.str
     """PodCIDR represents the pod IP range assigned to the node.
     +optional
     """
-    @property
-    def podCIDRs(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
-        """podCIDRs represents the IP ranges assigned to the node for usage by Pods on that node. If this
-        field is specified, the 0th entry must match the podCIDR field. It may contain at most 1 value for
-        each of IPv4 and IPv6.
-        +optional
-        +patchStrategy=merge
-        """
     providerID: builtins.str
     """ID of the node assigned by the cloud provider in the format: <ProviderName>://<ProviderSpecificNodeID>
     +optional
     """
     unschedulable: builtins.bool
     """Unschedulable controls node schedulability of new pods. By default, node is schedulable.
     More info: https://kubernetes.io/docs/concepts/nodes/node/#manual-node-administration
     +optional
     """
+    externalID: builtins.str
+    """Deprecated. Not all kubelets will set this field. Remove field after 1.13.
+    see: https://issues.k8s.io/61966
+    +optional
+    """
+    @property
+    def podCIDRs(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
+        """podCIDRs represents the IP ranges assigned to the node for usage by Pods on that node. If this
+        field is specified, the 0th entry must match the podCIDR field. It may contain at most 1 value for
+        each of IPv4 and IPv6.
+        +optional
+        +patchStrategy=merge
+        """
+
     @property
     def taints(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Taint]:
         """If specified, the node's taints.
         +optional
         """
+
     @property
     def configSource(self) -> global___NodeConfigSource:
         """Deprecated. If specified, the source of the node's configuration.
         The DynamicKubeletConfig feature gate must be enabled for the Kubelet to use this field.
         This field is deprecated as of 1.22: https://git.k8s.io/enhancements/keps/sig-node/281-dynamic-kubelet-configuration
         +optional
         """
-    externalID: builtins.str
-    """Deprecated. Not all kubelets will set this field. Remove field after 1.13.
-    see: https://issues.k8s.io/61966
-    +optional
-    """
+
     def __init__(
         self,
         *,
         podCIDR: builtins.str | None = ...,
         podCIDRs: collections.abc.Iterable[builtins.str] | None = ...,
         providerID: builtins.str | None = ...,
         unschedulable: builtins.bool | None = ...,
         taints: collections.abc.Iterable[global___Taint] | None = ...,
         configSource: global___NodeConfigSource | None = ...,
         externalID: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["configSource", b"configSource", "externalID", b"externalID", "podCIDR", b"podCIDR", "providerID", b"providerID", "unschedulable", b"unschedulable"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["configSource", b"configSource", "externalID", b"externalID", "podCIDR", b"podCIDR", "podCIDRs", b"podCIDRs", "providerID", b"providerID", "taints", b"taints", "unschedulable", b"unschedulable"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["configSource", b"configSource", "externalID", b"externalID", "podCIDR", b"podCIDR", "providerID", b"providerID", "unschedulable", b"unschedulable"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["configSource", b"configSource", "externalID", b"externalID", "podCIDR", b"podCIDR", "podCIDRs", b"podCIDRs", "providerID", b"providerID", "taints", b"taints", "unschedulable", b"unschedulable"]) -> None: ...
 
 global___NodeSpec = NodeSpec
 
-@typing_extensions.final
+@typing.final
 class NodeStatus(google.protobuf.message.Message):
     """NodeStatus is information about the current status of a node."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class CapacityEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity: ...
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
-    @typing_extensions.final
+    @typing.final
     class AllocatableEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity: ...
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     CAPACITY_FIELD_NUMBER: builtins.int
     ALLOCATABLE_FIELD_NUMBER: builtins.int
     PHASE_FIELD_NUMBER: builtins.int
     CONDITIONS_FIELD_NUMBER: builtins.int
     ADDRESSES_FIELD_NUMBER: builtins.int
     DAEMONENDPOINTS_FIELD_NUMBER: builtins.int
     NODEINFO_FIELD_NUMBER: builtins.int
     IMAGES_FIELD_NUMBER: builtins.int
     VOLUMESINUSE_FIELD_NUMBER: builtins.int
     VOLUMESATTACHED_FIELD_NUMBER: builtins.int
     CONFIG_FIELD_NUMBER: builtins.int
+    phase: builtins.str
+    """NodePhase is the recently observed lifecycle phase of the node.
+    More info: https://kubernetes.io/docs/concepts/nodes/node/#phase
+    The field is never populated, and now is deprecated.
+    +optional
+    """
     @property
     def capacity(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity]:
         """Capacity represents the total resources of a node.
         More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#capacity
         +optional
         """
+
     @property
     def allocatable(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity]:
         """Allocatable represents the resources of a node that are available for scheduling.
         Defaults to Capacity.
         +optional
         """
-    phase: builtins.str
-    """NodePhase is the recently observed lifecycle phase of the node.
-    More info: https://kubernetes.io/docs/concepts/nodes/node/#phase
-    The field is never populated, and now is deprecated.
-    +optional
-    """
+
     @property
     def conditions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___NodeCondition]:
         """Conditions is an array of current observed node conditions.
         More info: https://kubernetes.io/docs/concepts/nodes/node/#condition
         +optional
         +patchMergeKey=type
         +patchStrategy=merge
         """
+
     @property
     def addresses(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___NodeAddress]:
         """List of addresses reachable to the node.
         Queried from cloud provider, if available.
         More info: https://kubernetes.io/docs/concepts/nodes/node/#addresses
         Note: This field is declared as mergeable, but the merge key is not sufficiently
         unique, which can cause data corruption when it is merged. Callers should instead
         use a full-replacement patch. See http://pr.k8s.io/79391 for an example.
         +optional
         +patchMergeKey=type
         +patchStrategy=merge
         """
+
     @property
     def daemonEndpoints(self) -> global___NodeDaemonEndpoints:
         """Endpoints of daemons running on the Node.
         +optional
         """
+
     @property
     def nodeInfo(self) -> global___NodeSystemInfo:
         """Set of ids/uuids to uniquely identify the node.
         More info: https://kubernetes.io/docs/concepts/nodes/node/#info
         +optional
         """
+
     @property
     def images(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ContainerImage]:
         """List of container images on this node
         +optional
         """
+
     @property
     def volumesInUse(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """List of attachable volumes in use (mounted) by the node.
         +optional
         """
+
     @property
     def volumesAttached(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___AttachedVolume]:
         """List of volumes that are attached to the node.
         +optional
         """
+
     @property
     def config(self) -> global___NodeConfigStatus:
         """Status of the config assigned to the node via the dynamic Kubelet config feature.
         +optional
         """
+
     def __init__(
         self,
         *,
         capacity: collections.abc.Mapping[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity] | None = ...,
         allocatable: collections.abc.Mapping[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity] | None = ...,
         phase: builtins.str | None = ...,
         conditions: collections.abc.Iterable[global___NodeCondition] | None = ...,
@@ -4833,20 +5004,20 @@
         daemonEndpoints: global___NodeDaemonEndpoints | None = ...,
         nodeInfo: global___NodeSystemInfo | None = ...,
         images: collections.abc.Iterable[global___ContainerImage] | None = ...,
         volumesInUse: collections.abc.Iterable[builtins.str] | None = ...,
         volumesAttached: collections.abc.Iterable[global___AttachedVolume] | None = ...,
         config: global___NodeConfigStatus | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["config", b"config", "daemonEndpoints", b"daemonEndpoints", "nodeInfo", b"nodeInfo", "phase", b"phase"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["addresses", b"addresses", "allocatable", b"allocatable", "capacity", b"capacity", "conditions", b"conditions", "config", b"config", "daemonEndpoints", b"daemonEndpoints", "images", b"images", "nodeInfo", b"nodeInfo", "phase", b"phase", "volumesAttached", b"volumesAttached", "volumesInUse", b"volumesInUse"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["config", b"config", "daemonEndpoints", b"daemonEndpoints", "nodeInfo", b"nodeInfo", "phase", b"phase"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["addresses", b"addresses", "allocatable", b"allocatable", "capacity", b"capacity", "conditions", b"conditions", "config", b"config", "daemonEndpoints", b"daemonEndpoints", "images", b"images", "nodeInfo", b"nodeInfo", "phase", b"phase", "volumesAttached", b"volumesAttached", "volumesInUse", b"volumesInUse"]) -> None: ...
 
 global___NodeStatus = NodeStatus
 
-@typing_extensions.final
+@typing.final
 class NodeSystemInfo(google.protobuf.message.Message):
     """NodeSystemInfo is a set of ids/uuids to uniquely identify the node."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     MACHINEID_FIELD_NUMBER: builtins.int
     SYSTEMUUID_FIELD_NUMBER: builtins.int
@@ -4894,20 +5065,20 @@
         osImage: builtins.str | None = ...,
         containerRuntimeVersion: builtins.str | None = ...,
         kubeletVersion: builtins.str | None = ...,
         kubeProxyVersion: builtins.str | None = ...,
         operatingSystem: builtins.str | None = ...,
         architecture: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["architecture", b"architecture", "bootID", b"bootID", "containerRuntimeVersion", b"containerRuntimeVersion", "kernelVersion", b"kernelVersion", "kubeProxyVersion", b"kubeProxyVersion", "kubeletVersion", b"kubeletVersion", "machineID", b"machineID", "operatingSystem", b"operatingSystem", "osImage", b"osImage", "systemUUID", b"systemUUID"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["architecture", b"architecture", "bootID", b"bootID", "containerRuntimeVersion", b"containerRuntimeVersion", "kernelVersion", b"kernelVersion", "kubeProxyVersion", b"kubeProxyVersion", "kubeletVersion", b"kubeletVersion", "machineID", b"machineID", "operatingSystem", b"operatingSystem", "osImage", b"osImage", "systemUUID", b"systemUUID"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["architecture", b"architecture", "bootID", b"bootID", "containerRuntimeVersion", b"containerRuntimeVersion", "kernelVersion", b"kernelVersion", "kubeProxyVersion", b"kubeProxyVersion", "kubeletVersion", b"kubeletVersion", "machineID", b"machineID", "operatingSystem", b"operatingSystem", "osImage", b"osImage", "systemUUID", b"systemUUID"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["architecture", b"architecture", "bootID", b"bootID", "containerRuntimeVersion", b"containerRuntimeVersion", "kernelVersion", b"kernelVersion", "kubeProxyVersion", b"kubeProxyVersion", "kubeletVersion", b"kubeletVersion", "machineID", b"machineID", "operatingSystem", b"operatingSystem", "osImage", b"osImage", "systemUUID", b"systemUUID"]) -> None: ...
 
 global___NodeSystemInfo = NodeSystemInfo
 
-@typing_extensions.final
+@typing.final
 class ObjectFieldSelector(google.protobuf.message.Message):
     """ObjectFieldSelector selects an APIVersioned field of an object.
     +structType=atomic
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -4921,20 +5092,20 @@
     """Path of the field to select in the specified API version."""
     def __init__(
         self,
         *,
         apiVersion: builtins.str | None = ...,
         fieldPath: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["apiVersion", b"apiVersion", "fieldPath", b"fieldPath"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["apiVersion", b"apiVersion", "fieldPath", b"fieldPath"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["apiVersion", b"apiVersion", "fieldPath", b"fieldPath"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["apiVersion", b"apiVersion", "fieldPath", b"fieldPath"]) -> None: ...
 
 global___ObjectFieldSelector = ObjectFieldSelector
 
-@typing_extensions.final
+@typing.final
 class ObjectReference(google.protobuf.message.Message):
     """ObjectReference contains enough information to let you inspect or modify the referred object.
     ---
     New uses of this type are discouraged because of difficulty describing its usage when embedded in APIs.
      1. Ignored fields.  It includes many fields which are not generally honored.  For instance, ResourceVersion and FieldPath are both very rarely valid in actual usage.
      2. Invalid usage help.  It is impossible to add specific help for individual usage.  In most embedded usages, there are particular
         restrictions like, "must refer only to types A and B" or "UID not honored" or "name must be restricted".
@@ -5007,20 +5178,20 @@
         namespace: builtins.str | None = ...,
         name: builtins.str | None = ...,
         uid: builtins.str | None = ...,
         apiVersion: builtins.str | None = ...,
         resourceVersion: builtins.str | None = ...,
         fieldPath: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["apiVersion", b"apiVersion", "fieldPath", b"fieldPath", "kind", b"kind", "name", b"name", "namespace", b"namespace", "resourceVersion", b"resourceVersion", "uid", b"uid"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["apiVersion", b"apiVersion", "fieldPath", b"fieldPath", "kind", b"kind", "name", b"name", "namespace", b"namespace", "resourceVersion", b"resourceVersion", "uid", b"uid"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["apiVersion", b"apiVersion", "fieldPath", b"fieldPath", "kind", b"kind", "name", b"name", "namespace", b"namespace", "resourceVersion", b"resourceVersion", "uid", b"uid"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["apiVersion", b"apiVersion", "fieldPath", b"fieldPath", "kind", b"kind", "name", b"name", "namespace", b"namespace", "resourceVersion", b"resourceVersion", "uid", b"uid"]) -> None: ...
 
 global___ObjectReference = ObjectReference
 
-@typing_extensions.final
+@typing.final
 class PersistentVolume(google.protobuf.message.Message):
     """PersistentVolume (PV) is a storage resource provisioned by an administrator.
     It is analogous to a node.
     More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -5030,161 +5201,171 @@
     STATUS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def spec(self) -> global___PersistentVolumeSpec:
         """Spec defines a specification of a persistent volume owned by the cluster.
         Provisioned by an administrator.
         More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistent-volumes
         +optional
         """
+
     @property
     def status(self) -> global___PersistentVolumeStatus:
         """Status represents the current information/status for the persistent volume.
         Populated by the system.
         Read-only.
         More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistent-volumes
         +optional
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         spec: global___PersistentVolumeSpec | None = ...,
         status: global___PersistentVolumeStatus | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> None: ...
 
 global___PersistentVolume = PersistentVolume
 
-@typing_extensions.final
+@typing.final
 class PersistentVolumeClaim(google.protobuf.message.Message):
     """PersistentVolumeClaim is a user's request for and claim to a persistent volume"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     SPEC_FIELD_NUMBER: builtins.int
     STATUS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def spec(self) -> global___PersistentVolumeClaimSpec:
         """Spec defines the desired characteristics of a volume requested by a pod author.
         More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         +optional
         """
+
     @property
     def status(self) -> global___PersistentVolumeClaimStatus:
         """Status represents the current information/status of a persistent volume claim.
         Read-only.
         More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         +optional
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         spec: global___PersistentVolumeClaimSpec | None = ...,
         status: global___PersistentVolumeClaimStatus | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> None: ...
 
 global___PersistentVolumeClaim = PersistentVolumeClaim
 
-@typing_extensions.final
+@typing.final
 class PersistentVolumeClaimCondition(google.protobuf.message.Message):
     """PersistentVolumeClaimCondition contails details about state of pvc"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     TYPE_FIELD_NUMBER: builtins.int
     STATUS_FIELD_NUMBER: builtins.int
     LASTPROBETIME_FIELD_NUMBER: builtins.int
     LASTTRANSITIONTIME_FIELD_NUMBER: builtins.int
     REASON_FIELD_NUMBER: builtins.int
     MESSAGE_FIELD_NUMBER: builtins.int
     type: builtins.str
     status: builtins.str
-    @property
-    def lastProbeTime(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
-        """Last time we probed the condition.
-        +optional
-        """
-    @property
-    def lastTransitionTime(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
-        """Last time the condition transitioned from one status to another.
-        +optional
-        """
     reason: builtins.str
     """Unique, this should be a short, machine understandable string that gives the reason
     for condition's last transition. If it reports "ResizeStarted" that means the underlying
     persistent volume is being resized.
     +optional
     """
     message: builtins.str
     """Human-readable message indicating details about last transition.
     +optional
     """
+    @property
+    def lastProbeTime(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
+        """Last time we probed the condition.
+        +optional
+        """
+
+    @property
+    def lastTransitionTime(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
+        """Last time the condition transitioned from one status to another.
+        +optional
+        """
+
     def __init__(
         self,
         *,
         type: builtins.str | None = ...,
         status: builtins.str | None = ...,
         lastProbeTime: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time | None = ...,
         lastTransitionTime: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time | None = ...,
         reason: builtins.str | None = ...,
         message: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["lastProbeTime", b"lastProbeTime", "lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["lastProbeTime", b"lastProbeTime", "lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["lastProbeTime", b"lastProbeTime", "lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["lastProbeTime", b"lastProbeTime", "lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> None: ...
 
 global___PersistentVolumeClaimCondition = PersistentVolumeClaimCondition
 
-@typing_extensions.final
+@typing.final
 class PersistentVolumeClaimList(google.protobuf.message.Message):
     """PersistentVolumeClaimList is a list of PersistentVolumeClaim items."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """Standard list metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PersistentVolumeClaim]:
         """A list of persistent volume claims.
         More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[global___PersistentVolumeClaim] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___PersistentVolumeClaimList = PersistentVolumeClaimList
 
-@typing_extensions.final
+@typing.final
 class PersistentVolumeClaimSpec(google.protobuf.message.Message):
     """PersistentVolumeClaimSpec describes the common attributes of storage devices
     and allows a Source for provider-specific attributes
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -5192,56 +5373,60 @@
     SELECTOR_FIELD_NUMBER: builtins.int
     RESOURCES_FIELD_NUMBER: builtins.int
     VOLUMENAME_FIELD_NUMBER: builtins.int
     STORAGECLASSNAME_FIELD_NUMBER: builtins.int
     VOLUMEMODE_FIELD_NUMBER: builtins.int
     DATASOURCE_FIELD_NUMBER: builtins.int
     DATASOURCEREF_FIELD_NUMBER: builtins.int
+    volumeName: builtins.str
+    """VolumeName is the binding reference to the PersistentVolume backing this claim.
+    +optional
+    """
+    storageClassName: builtins.str
+    """Name of the StorageClass required by the claim.
+    More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1
+    +optional
+    """
+    volumeMode: builtins.str
+    """volumeMode defines what type of volume is required by the claim.
+    Value of Filesystem is implied when not included in claim spec.
+    +optional
+    """
     @property
     def accessModes(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """AccessModes contains the desired access modes the volume should have.
         More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1
         +optional
         """
+
     @property
     def selector(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.LabelSelector:
         """A label query over volumes to consider for binding.
         +optional
         """
+
     @property
     def resources(self) -> global___ResourceRequirements:
         """Resources represents the minimum resources the volume should have.
         More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
         +optional
         """
-    volumeName: builtins.str
-    """VolumeName is the binding reference to the PersistentVolume backing this claim.
-    +optional
-    """
-    storageClassName: builtins.str
-    """Name of the StorageClass required by the claim.
-    More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1
-    +optional
-    """
-    volumeMode: builtins.str
-    """volumeMode defines what type of volume is required by the claim.
-    Value of Filesystem is implied when not included in claim spec.
-    +optional
-    """
+
     @property
     def dataSource(self) -> global___TypedLocalObjectReference:
         """This field can be used to specify either:
         * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot)
         * An existing PVC (PersistentVolumeClaim)
         If the provisioner or an external controller can support the specified data source,
         it will create a new volume based on the contents of the specified data source.
         If the AnyVolumeDataSource feature gate is enabled, this field will always have
         the same contents as the DataSourceRef field.
         +optional
         """
+
     @property
     def dataSourceRef(self) -> global___TypedLocalObjectReference:
         """Specifies the object from which to populate the volume with data, if a non-empty
         volume is desired. This may be any local object from a non-empty API group (non
         core object) or a PersistentVolumeClaim object.
         When this field is specified, volume binding will only succeed if the type of
         the specified object matches some installed volume populator or dynamic
@@ -5255,54 +5440,55 @@
           allows any non-core object, as well as PersistentVolumeClaim objects.
         * While DataSource ignores disallowed values (dropping them), DataSourceRef
           preserves all values, and generates an error if a disallowed value is
           specified.
         (Alpha) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
         +optional
         """
+
     def __init__(
         self,
         *,
         accessModes: collections.abc.Iterable[builtins.str] | None = ...,
         selector: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.LabelSelector | None = ...,
         resources: global___ResourceRequirements | None = ...,
         volumeName: builtins.str | None = ...,
         storageClassName: builtins.str | None = ...,
         volumeMode: builtins.str | None = ...,
         dataSource: global___TypedLocalObjectReference | None = ...,
         dataSourceRef: global___TypedLocalObjectReference | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["dataSource", b"dataSource", "dataSourceRef", b"dataSourceRef", "resources", b"resources", "selector", b"selector", "storageClassName", b"storageClassName", "volumeMode", b"volumeMode", "volumeName", b"volumeName"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["accessModes", b"accessModes", "dataSource", b"dataSource", "dataSourceRef", b"dataSourceRef", "resources", b"resources", "selector", b"selector", "storageClassName", b"storageClassName", "volumeMode", b"volumeMode", "volumeName", b"volumeName"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["dataSource", b"dataSource", "dataSourceRef", b"dataSourceRef", "resources", b"resources", "selector", b"selector", "storageClassName", b"storageClassName", "volumeMode", b"volumeMode", "volumeName", b"volumeName"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["accessModes", b"accessModes", "dataSource", b"dataSource", "dataSourceRef", b"dataSourceRef", "resources", b"resources", "selector", b"selector", "storageClassName", b"storageClassName", "volumeMode", b"volumeMode", "volumeName", b"volumeName"]) -> None: ...
 
 global___PersistentVolumeClaimSpec = PersistentVolumeClaimSpec
 
-@typing_extensions.final
+@typing.final
 class PersistentVolumeClaimStatus(google.protobuf.message.Message):
     """PersistentVolumeClaimStatus is the current status of a persistent volume claim."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class CapacityEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity: ...
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     PHASE_FIELD_NUMBER: builtins.int
     ACCESSMODES_FIELD_NUMBER: builtins.int
     CAPACITY_FIELD_NUMBER: builtins.int
     CONDITIONS_FIELD_NUMBER: builtins.int
     phase: builtins.str
     """Phase represents the current phase of PersistentVolumeClaim.
@@ -5310,41 +5496,44 @@
     """
     @property
     def accessModes(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """AccessModes contains the actual access modes the volume backing the PVC has.
         More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1
         +optional
         """
+
     @property
     def capacity(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity]:
         """Represents the actual resources of the underlying volume.
         +optional
         """
+
     @property
     def conditions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PersistentVolumeClaimCondition]:
         """Current Condition of persistent volume claim. If underlying persistent volume is being
         resized then the Condition will be set to 'ResizeStarted'.
         +optional
         +patchMergeKey=type
         +patchStrategy=merge
         """
+
     def __init__(
         self,
         *,
         phase: builtins.str | None = ...,
         accessModes: collections.abc.Iterable[builtins.str] | None = ...,
         capacity: collections.abc.Mapping[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity] | None = ...,
         conditions: collections.abc.Iterable[global___PersistentVolumeClaimCondition] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["phase", b"phase"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["accessModes", b"accessModes", "capacity", b"capacity", "conditions", b"conditions", "phase", b"phase"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["phase", b"phase"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["accessModes", b"accessModes", "capacity", b"capacity", "conditions", b"conditions", "phase", b"phase"]) -> None: ...
 
 global___PersistentVolumeClaimStatus = PersistentVolumeClaimStatus
 
-@typing_extensions.final
+@typing.final
 class PersistentVolumeClaimTemplate(google.protobuf.message.Message):
     """PersistentVolumeClaimTemplate is used to produce
     PersistentVolumeClaim objects as part of an EphemeralVolumeSource.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -5354,33 +5543,35 @@
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """May contain labels and annotations that will be copied into the PVC
         when creating it. No other fields are allowed and will be rejected during
         validation.
 
         +optional
         """
+
     @property
     def spec(self) -> global___PersistentVolumeClaimSpec:
         """The specification for the PersistentVolumeClaim. The entire content is
         copied unchanged into the PVC that gets created from this
         template. The same fields as in a PersistentVolumeClaim
         are also valid here.
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         spec: global___PersistentVolumeClaimSpec | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec"]) -> None: ...
 
 global___PersistentVolumeClaimTemplate = PersistentVolumeClaimTemplate
 
-@typing_extensions.final
+@typing.final
 class PersistentVolumeClaimVolumeSource(google.protobuf.message.Message):
     """PersistentVolumeClaimVolumeSource references the user's PVC in the same namespace.
     This volume finds the bound PV and mounts that volume for the pod. A
     PersistentVolumeClaimVolumeSource is, essentially, a wrapper around another
     type of volume that is owned by someone else (the system).
     """
 
@@ -5399,50 +5590,52 @@
     """
     def __init__(
         self,
         *,
         claimName: builtins.str | None = ...,
         readOnly: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["claimName", b"claimName", "readOnly", b"readOnly"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["claimName", b"claimName", "readOnly", b"readOnly"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["claimName", b"claimName", "readOnly", b"readOnly"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["claimName", b"claimName", "readOnly", b"readOnly"]) -> None: ...
 
 global___PersistentVolumeClaimVolumeSource = PersistentVolumeClaimVolumeSource
 
-@typing_extensions.final
+@typing.final
 class PersistentVolumeList(google.protobuf.message.Message):
     """PersistentVolumeList is a list of PersistentVolume items."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """Standard list metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PersistentVolume]:
         """List of persistent volumes.
         More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[global___PersistentVolume] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___PersistentVolumeList = PersistentVolumeList
 
-@typing_extensions.final
+@typing.final
 class PersistentVolumeSource(google.protobuf.message.Message):
     """PersistentVolumeSource is similar to VolumeSource but meant for the
     administrator who creates PVs. Exactly one of its members must be set.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -5471,131 +5664,153 @@
     @property
     def gcePersistentDisk(self) -> global___GCEPersistentDiskVolumeSource:
         """GCEPersistentDisk represents a GCE Disk resource that is attached to a
         kubelet's host machine and then exposed to the pod. Provisioned by an admin.
         More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
         +optional
         """
+
     @property
     def awsElasticBlockStore(self) -> global___AWSElasticBlockStoreVolumeSource:
         """AWSElasticBlockStore represents an AWS Disk resource that is attached to a
         kubelet's host machine and then exposed to the pod.
         More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
         +optional
         """
+
     @property
     def hostPath(self) -> global___HostPathVolumeSource:
         """HostPath represents a directory on the host.
         Provisioned by a developer or tester.
         This is useful for single-node development and testing only!
         On-host storage is not supported in any way and WILL NOT WORK in a multi-node cluster.
         More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
         +optional
         """
+
     @property
     def glusterfs(self) -> global___GlusterfsPersistentVolumeSource:
         """Glusterfs represents a Glusterfs volume that is attached to a host and
         exposed to the pod. Provisioned by an admin.
         More info: https://examples.k8s.io/volumes/glusterfs/README.md
         +optional
         """
+
     @property
     def nfs(self) -> global___NFSVolumeSource:
         """NFS represents an NFS mount on the host. Provisioned by an admin.
         More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
         +optional
         """
+
     @property
     def rbd(self) -> global___RBDPersistentVolumeSource:
         """RBD represents a Rados Block Device mount on the host that shares a pod's lifetime.
         More info: https://examples.k8s.io/volumes/rbd/README.md
         +optional
         """
+
     @property
     def iscsi(self) -> global___ISCSIPersistentVolumeSource:
         """ISCSI represents an ISCSI Disk resource that is attached to a
         kubelet's host machine and then exposed to the pod. Provisioned by an admin.
         +optional
         """
+
     @property
     def cinder(self) -> global___CinderPersistentVolumeSource:
         """Cinder represents a cinder volume attached and mounted on kubelets host machine.
         More info: https://examples.k8s.io/mysql-cinder-pd/README.md
         +optional
         """
+
     @property
     def cephfs(self) -> global___CephFSPersistentVolumeSource:
         """CephFS represents a Ceph FS mount on the host that shares a pod's lifetime
         +optional
         """
+
     @property
     def fc(self) -> global___FCVolumeSource:
         """FC represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod.
         +optional
         """
+
     @property
     def flocker(self) -> global___FlockerVolumeSource:
         """Flocker represents a Flocker volume attached to a kubelet's host machine and exposed to the pod for its usage. This depends on the Flocker control service being running
         +optional
         """
+
     @property
     def flexVolume(self) -> global___FlexPersistentVolumeSource:
         """FlexVolume represents a generic volume resource that is
         provisioned/attached using an exec based plugin.
         +optional
         """
+
     @property
     def azureFile(self) -> global___AzureFilePersistentVolumeSource:
         """AzureFile represents an Azure File Service mount on the host and bind mount to the pod.
         +optional
         """
+
     @property
     def vsphereVolume(self) -> global___VsphereVirtualDiskVolumeSource:
         """VsphereVolume represents a vSphere volume attached and mounted on kubelets host machine
         +optional
         """
+
     @property
     def quobyte(self) -> global___QuobyteVolumeSource:
         """Quobyte represents a Quobyte mount on the host that shares a pod's lifetime
         +optional
         """
+
     @property
     def azureDisk(self) -> global___AzureDiskVolumeSource:
         """AzureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
         +optional
         """
+
     @property
     def photonPersistentDisk(self) -> global___PhotonPersistentDiskVolumeSource:
         """PhotonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine"""
+
     @property
     def portworxVolume(self) -> global___PortworxVolumeSource:
         """PortworxVolume represents a portworx volume attached and mounted on kubelets host machine
         +optional
         """
+
     @property
     def scaleIO(self) -> global___ScaleIOPersistentVolumeSource:
         """ScaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.
         +optional
         """
+
     @property
     def local(self) -> global___LocalVolumeSource:
         """Local represents directly-attached storage with node affinity
         +optional
         """
+
     @property
     def storageos(self) -> global___StorageOSPersistentVolumeSource:
         """StorageOS represents a StorageOS volume that is attached to the kubelet's host machine and mounted into the pod
         More info: https://examples.k8s.io/volumes/storageos/README.md
         +optional
         """
+
     @property
     def csi(self) -> global___CSIPersistentVolumeSource:
         """CSI represents storage that is handled by an external CSI driver (Beta feature).
         +optional
         """
+
     def __init__(
         self,
         *,
         gcePersistentDisk: global___GCEPersistentDiskVolumeSource | None = ...,
         awsElasticBlockStore: global___AWSElasticBlockStoreVolumeSource | None = ...,
         hostPath: global___HostPathVolumeSource | None = ...,
         glusterfs: global___GlusterfsPersistentVolumeSource | None = ...,
@@ -5614,125 +5829,131 @@
         photonPersistentDisk: global___PhotonPersistentDiskVolumeSource | None = ...,
         portworxVolume: global___PortworxVolumeSource | None = ...,
         scaleIO: global___ScaleIOPersistentVolumeSource | None = ...,
         local: global___LocalVolumeSource | None = ...,
         storageos: global___StorageOSPersistentVolumeSource | None = ...,
         csi: global___CSIPersistentVolumeSource | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["awsElasticBlockStore", b"awsElasticBlockStore", "azureDisk", b"azureDisk", "azureFile", b"azureFile", "cephfs", b"cephfs", "cinder", b"cinder", "csi", b"csi", "fc", b"fc", "flexVolume", b"flexVolume", "flocker", b"flocker", "gcePersistentDisk", b"gcePersistentDisk", "glusterfs", b"glusterfs", "hostPath", b"hostPath", "iscsi", b"iscsi", "local", b"local", "nfs", b"nfs", "photonPersistentDisk", b"photonPersistentDisk", "portworxVolume", b"portworxVolume", "quobyte", b"quobyte", "rbd", b"rbd", "scaleIO", b"scaleIO", "storageos", b"storageos", "vsphereVolume", b"vsphereVolume"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["awsElasticBlockStore", b"awsElasticBlockStore", "azureDisk", b"azureDisk", "azureFile", b"azureFile", "cephfs", b"cephfs", "cinder", b"cinder", "csi", b"csi", "fc", b"fc", "flexVolume", b"flexVolume", "flocker", b"flocker", "gcePersistentDisk", b"gcePersistentDisk", "glusterfs", b"glusterfs", "hostPath", b"hostPath", "iscsi", b"iscsi", "local", b"local", "nfs", b"nfs", "photonPersistentDisk", b"photonPersistentDisk", "portworxVolume", b"portworxVolume", "quobyte", b"quobyte", "rbd", b"rbd", "scaleIO", b"scaleIO", "storageos", b"storageos", "vsphereVolume", b"vsphereVolume"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["awsElasticBlockStore", b"awsElasticBlockStore", "azureDisk", b"azureDisk", "azureFile", b"azureFile", "cephfs", b"cephfs", "cinder", b"cinder", "csi", b"csi", "fc", b"fc", "flexVolume", b"flexVolume", "flocker", b"flocker", "gcePersistentDisk", b"gcePersistentDisk", "glusterfs", b"glusterfs", "hostPath", b"hostPath", "iscsi", b"iscsi", "local", b"local", "nfs", b"nfs", "photonPersistentDisk", b"photonPersistentDisk", "portworxVolume", b"portworxVolume", "quobyte", b"quobyte", "rbd", b"rbd", "scaleIO", b"scaleIO", "storageos", b"storageos", "vsphereVolume", b"vsphereVolume"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["awsElasticBlockStore", b"awsElasticBlockStore", "azureDisk", b"azureDisk", "azureFile", b"azureFile", "cephfs", b"cephfs", "cinder", b"cinder", "csi", b"csi", "fc", b"fc", "flexVolume", b"flexVolume", "flocker", b"flocker", "gcePersistentDisk", b"gcePersistentDisk", "glusterfs", b"glusterfs", "hostPath", b"hostPath", "iscsi", b"iscsi", "local", b"local", "nfs", b"nfs", "photonPersistentDisk", b"photonPersistentDisk", "portworxVolume", b"portworxVolume", "quobyte", b"quobyte", "rbd", b"rbd", "scaleIO", b"scaleIO", "storageos", b"storageos", "vsphereVolume", b"vsphereVolume"]) -> None: ...
 
 global___PersistentVolumeSource = PersistentVolumeSource
 
-@typing_extensions.final
+@typing.final
 class PersistentVolumeSpec(google.protobuf.message.Message):
     """PersistentVolumeSpec is the specification of a persistent volume."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class CapacityEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity: ...
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     CAPACITY_FIELD_NUMBER: builtins.int
     PERSISTENTVOLUMESOURCE_FIELD_NUMBER: builtins.int
     ACCESSMODES_FIELD_NUMBER: builtins.int
     CLAIMREF_FIELD_NUMBER: builtins.int
     PERSISTENTVOLUMERECLAIMPOLICY_FIELD_NUMBER: builtins.int
     STORAGECLASSNAME_FIELD_NUMBER: builtins.int
     MOUNTOPTIONS_FIELD_NUMBER: builtins.int
     VOLUMEMODE_FIELD_NUMBER: builtins.int
     NODEAFFINITY_FIELD_NUMBER: builtins.int
+    persistentVolumeReclaimPolicy: builtins.str
+    """What happens to a persistent volume when released from its claim.
+    Valid options are Retain (default for manually created PersistentVolumes), Delete (default
+    for dynamically provisioned PersistentVolumes), and Recycle (deprecated).
+    Recycle must be supported by the volume plugin underlying this PersistentVolume.
+    More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#reclaiming
+    +optional
+    """
+    storageClassName: builtins.str
+    """Name of StorageClass to which this persistent volume belongs. Empty value
+    means that this volume does not belong to any StorageClass.
+    +optional
+    """
+    volumeMode: builtins.str
+    """volumeMode defines if a volume is intended to be used with a formatted filesystem
+    or to remain in raw block state. Value of Filesystem is implied when not included in spec.
+    +optional
+    """
     @property
     def capacity(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity]:
         """A description of the persistent volume's resources and capacity.
         More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#capacity
         +optional
         """
+
     @property
     def persistentVolumeSource(self) -> global___PersistentVolumeSource:
         """The actual volume backing the persistent volume."""
+
     @property
     def accessModes(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """AccessModes contains all ways the volume can be mounted.
         More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes
         +optional
         """
+
     @property
     def claimRef(self) -> global___ObjectReference:
         """ClaimRef is part of a bi-directional binding between PersistentVolume and PersistentVolumeClaim.
         Expected to be non-nil when bound.
         claim.VolumeName is the authoritative bind between PV and PVC.
         More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#binding
         +optional
         """
-    persistentVolumeReclaimPolicy: builtins.str
-    """What happens to a persistent volume when released from its claim.
-    Valid options are Retain (default for manually created PersistentVolumes), Delete (default
-    for dynamically provisioned PersistentVolumes), and Recycle (deprecated).
-    Recycle must be supported by the volume plugin underlying this PersistentVolume.
-    More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#reclaiming
-    +optional
-    """
-    storageClassName: builtins.str
-    """Name of StorageClass to which this persistent volume belongs. Empty value
-    means that this volume does not belong to any StorageClass.
-    +optional
-    """
+
     @property
     def mountOptions(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """A list of mount options, e.g. ["ro", "soft"]. Not validated - mount will
         simply fail if one is invalid.
         More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes/#mount-options
         +optional
         """
-    volumeMode: builtins.str
-    """volumeMode defines if a volume is intended to be used with a formatted filesystem
-    or to remain in raw block state. Value of Filesystem is implied when not included in spec.
-    +optional
-    """
+
     @property
     def nodeAffinity(self) -> global___VolumeNodeAffinity:
         """NodeAffinity defines constraints that limit what nodes this volume can be accessed from.
         This field influences the scheduling of pods that use this volume.
         +optional
         """
+
     def __init__(
         self,
         *,
         capacity: collections.abc.Mapping[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity] | None = ...,
         persistentVolumeSource: global___PersistentVolumeSource | None = ...,
         accessModes: collections.abc.Iterable[builtins.str] | None = ...,
         claimRef: global___ObjectReference | None = ...,
         persistentVolumeReclaimPolicy: builtins.str | None = ...,
         storageClassName: builtins.str | None = ...,
         mountOptions: collections.abc.Iterable[builtins.str] | None = ...,
         volumeMode: builtins.str | None = ...,
         nodeAffinity: global___VolumeNodeAffinity | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["claimRef", b"claimRef", "nodeAffinity", b"nodeAffinity", "persistentVolumeReclaimPolicy", b"persistentVolumeReclaimPolicy", "persistentVolumeSource", b"persistentVolumeSource", "storageClassName", b"storageClassName", "volumeMode", b"volumeMode"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["accessModes", b"accessModes", "capacity", b"capacity", "claimRef", b"claimRef", "mountOptions", b"mountOptions", "nodeAffinity", b"nodeAffinity", "persistentVolumeReclaimPolicy", b"persistentVolumeReclaimPolicy", "persistentVolumeSource", b"persistentVolumeSource", "storageClassName", b"storageClassName", "volumeMode", b"volumeMode"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["claimRef", b"claimRef", "nodeAffinity", b"nodeAffinity", "persistentVolumeReclaimPolicy", b"persistentVolumeReclaimPolicy", "persistentVolumeSource", b"persistentVolumeSource", "storageClassName", b"storageClassName", "volumeMode", b"volumeMode"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["accessModes", b"accessModes", "capacity", b"capacity", "claimRef", b"claimRef", "mountOptions", b"mountOptions", "nodeAffinity", b"nodeAffinity", "persistentVolumeReclaimPolicy", b"persistentVolumeReclaimPolicy", "persistentVolumeSource", b"persistentVolumeSource", "storageClassName", b"storageClassName", "volumeMode", b"volumeMode"]) -> None: ...
 
 global___PersistentVolumeSpec = PersistentVolumeSpec
 
-@typing_extensions.final
+@typing.final
 class PersistentVolumeStatus(google.protobuf.message.Message):
     """PersistentVolumeStatus is the current status of a persistent volume."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PHASE_FIELD_NUMBER: builtins.int
     MESSAGE_FIELD_NUMBER: builtins.int
@@ -5754,20 +5975,20 @@
     def __init__(
         self,
         *,
         phase: builtins.str | None = ...,
         message: builtins.str | None = ...,
         reason: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["message", b"message", "phase", b"phase", "reason", b"reason"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["message", b"message", "phase", b"phase", "reason", b"reason"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["message", b"message", "phase", b"phase", "reason", b"reason"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["message", b"message", "phase", b"phase", "reason", b"reason"]) -> None: ...
 
 global___PersistentVolumeStatus = PersistentVolumeStatus
 
-@typing_extensions.final
+@typing.final
 class PhotonPersistentDiskVolumeSource(google.protobuf.message.Message):
     """Represents a Photon Controller persistent disk resource."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PDID_FIELD_NUMBER: builtins.int
     FSTYPE_FIELD_NUMBER: builtins.int
@@ -5780,20 +6001,20 @@
     """
     def __init__(
         self,
         *,
         pdID: builtins.str | None = ...,
         fsType: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "pdID", b"pdID"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "pdID", b"pdID"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fsType", b"fsType", "pdID", b"pdID"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["fsType", b"fsType", "pdID", b"pdID"]) -> None: ...
 
 global___PhotonPersistentDiskVolumeSource = PhotonPersistentDiskVolumeSource
 
-@typing_extensions.final
+@typing.final
 class Pod(google.protobuf.message.Message):
     """Pod is a collection of containers that can run on a host. This resource is created
     by clients and scheduled onto hosts.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -5802,42 +6023,45 @@
     STATUS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def spec(self) -> global___PodSpec:
         """Specification of the desired behavior of the pod.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         +optional
         """
+
     @property
     def status(self) -> global___PodStatus:
         """Most recently observed status of the pod.
         This data may not be up to date.
         Populated by the system.
         Read-only.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         +optional
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         spec: global___PodSpec | None = ...,
         status: global___PodStatus | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> None: ...
 
 global___Pod = Pod
 
-@typing_extensions.final
+@typing.final
 class PodAffinity(google.protobuf.message.Message):
     """Pod affinity is a group of inter pod affinity scheduling rules."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     REQUIREDDURINGSCHEDULINGIGNOREDDURINGEXECUTION_FIELD_NUMBER: builtins.int
     PREFERREDDURINGSCHEDULINGIGNOREDDURINGEXECUTION_FIELD_NUMBER: builtins.int
@@ -5848,38 +6072,40 @@
         If the affinity requirements specified by this field cease to be met
         at some point during pod execution (e.g. due to a pod label update), the
         system may or may not try to eventually evict the pod from its node.
         When there are multiple elements, the lists of nodes corresponding to each
         podAffinityTerm are intersected, i.e. all terms must be satisfied.
         +optional
         """
+
     @property
     def preferredDuringSchedulingIgnoredDuringExecution(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___WeightedPodAffinityTerm]:
         """The scheduler will prefer to schedule pods to nodes that satisfy
         the affinity expressions specified by this field, but it may choose
         a node that violates one or more of the expressions. The node that is
         most preferred is the one with the greatest sum of weights, i.e.
         for each node that meets all of the scheduling requirements (resource
         request, requiredDuringScheduling affinity expressions, etc.),
         compute a sum by iterating through the elements of this field and adding
         "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
         node(s) with the highest sum are the most preferred.
         +optional
         """
+
     def __init__(
         self,
         *,
         requiredDuringSchedulingIgnoredDuringExecution: collections.abc.Iterable[global___PodAffinityTerm] | None = ...,
         preferredDuringSchedulingIgnoredDuringExecution: collections.abc.Iterable[global___WeightedPodAffinityTerm] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["preferredDuringSchedulingIgnoredDuringExecution", b"preferredDuringSchedulingIgnoredDuringExecution", "requiredDuringSchedulingIgnoredDuringExecution", b"requiredDuringSchedulingIgnoredDuringExecution"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["preferredDuringSchedulingIgnoredDuringExecution", b"preferredDuringSchedulingIgnoredDuringExecution", "requiredDuringSchedulingIgnoredDuringExecution", b"requiredDuringSchedulingIgnoredDuringExecution"]) -> None: ...
 
 global___PodAffinity = PodAffinity
 
-@typing_extensions.final
+@typing.final
 class PodAffinityTerm(google.protobuf.message.Message):
     """Defines a set of pods (namely those matching the labelSelector
     relative to the given namespace(s)) that this pod should be
     co-located (affinity) or not co-located (anti-affinity) with,
     where co-located is defined as running on a node whose value of
     the label with key <topologyKey> matches that of any node on which
     a pod of the set of pods is running
@@ -5887,58 +6113,61 @@
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     LABELSELECTOR_FIELD_NUMBER: builtins.int
     NAMESPACES_FIELD_NUMBER: builtins.int
     TOPOLOGYKEY_FIELD_NUMBER: builtins.int
     NAMESPACESELECTOR_FIELD_NUMBER: builtins.int
+    topologyKey: builtins.str
+    """This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
+    the labelSelector in the specified namespaces, where co-located is defined as running on a node
+    whose value of the label with key topologyKey matches that of any node on which any of the
+    selected pods is running.
+    Empty topologyKey is not allowed.
+    """
     @property
     def labelSelector(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.LabelSelector:
         """A label query over a set of resources, in this case pods.
         +optional
         """
+
     @property
     def namespaces(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """namespaces specifies a static list of namespace names that the term applies to.
         The term is applied to the union of the namespaces listed in this field
         and the ones selected by namespaceSelector.
         null or empty namespaces list and null namespaceSelector means "this pod's namespace"
         +optional
         """
-    topologyKey: builtins.str
-    """This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
-    the labelSelector in the specified namespaces, where co-located is defined as running on a node
-    whose value of the label with key topologyKey matches that of any node on which any of the
-    selected pods is running.
-    Empty topologyKey is not allowed.
-    """
+
     @property
     def namespaceSelector(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.LabelSelector:
         """A label query over the set of namespaces that the term applies to.
         The term is applied to the union of the namespaces selected by this field
         and the ones listed in the namespaces field.
         null selector and null or empty namespaces list means "this pod's namespace".
         An empty selector ({}) matches all namespaces.
         This field is beta-level and is only honored when PodAffinityNamespaceSelector feature is enabled.
         +optional
         """
+
     def __init__(
         self,
         *,
         labelSelector: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.LabelSelector | None = ...,
         namespaces: collections.abc.Iterable[builtins.str] | None = ...,
         topologyKey: builtins.str | None = ...,
         namespaceSelector: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.LabelSelector | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["labelSelector", b"labelSelector", "namespaceSelector", b"namespaceSelector", "topologyKey", b"topologyKey"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["labelSelector", b"labelSelector", "namespaceSelector", b"namespaceSelector", "namespaces", b"namespaces", "topologyKey", b"topologyKey"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["labelSelector", b"labelSelector", "namespaceSelector", b"namespaceSelector", "topologyKey", b"topologyKey"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["labelSelector", b"labelSelector", "namespaceSelector", b"namespaceSelector", "namespaces", b"namespaces", "topologyKey", b"topologyKey"]) -> None: ...
 
 global___PodAffinityTerm = PodAffinityTerm
 
-@typing_extensions.final
+@typing.final
 class PodAntiAffinity(google.protobuf.message.Message):
     """Pod anti affinity is a group of inter pod anti affinity scheduling rules."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     REQUIREDDURINGSCHEDULINGIGNOREDDURINGEXECUTION_FIELD_NUMBER: builtins.int
     PREFERREDDURINGSCHEDULINGIGNOREDDURINGEXECUTION_FIELD_NUMBER: builtins.int
@@ -5949,38 +6178,40 @@
         If the anti-affinity requirements specified by this field cease to be met
         at some point during pod execution (e.g. due to a pod label update), the
         system may or may not try to eventually evict the pod from its node.
         When there are multiple elements, the lists of nodes corresponding to each
         podAffinityTerm are intersected, i.e. all terms must be satisfied.
         +optional
         """
+
     @property
     def preferredDuringSchedulingIgnoredDuringExecution(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___WeightedPodAffinityTerm]:
         """The scheduler will prefer to schedule pods to nodes that satisfy
         the anti-affinity expressions specified by this field, but it may choose
         a node that violates one or more of the expressions. The node that is
         most preferred is the one with the greatest sum of weights, i.e.
         for each node that meets all of the scheduling requirements (resource
         request, requiredDuringScheduling anti-affinity expressions, etc.),
         compute a sum by iterating through the elements of this field and adding
         "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
         node(s) with the highest sum are the most preferred.
         +optional
         """
+
     def __init__(
         self,
         *,
         requiredDuringSchedulingIgnoredDuringExecution: collections.abc.Iterable[global___PodAffinityTerm] | None = ...,
         preferredDuringSchedulingIgnoredDuringExecution: collections.abc.Iterable[global___WeightedPodAffinityTerm] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["preferredDuringSchedulingIgnoredDuringExecution", b"preferredDuringSchedulingIgnoredDuringExecution", "requiredDuringSchedulingIgnoredDuringExecution", b"requiredDuringSchedulingIgnoredDuringExecution"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["preferredDuringSchedulingIgnoredDuringExecution", b"preferredDuringSchedulingIgnoredDuringExecution", "requiredDuringSchedulingIgnoredDuringExecution", b"requiredDuringSchedulingIgnoredDuringExecution"]) -> None: ...
 
 global___PodAntiAffinity = PodAntiAffinity
 
-@typing_extensions.final
+@typing.final
 class PodAttachOptions(google.protobuf.message.Message):
     """PodAttachOptions is the query options to a Pod's remote attach call.
     ---
     TODO: merge w/ PodExecOptions below for stdin, stdout, etc
     and also when we cut V2, we should export a "StreamOptions" or somesuch that contains Stdin, Stdout, Stder and TTY
     """
 
@@ -6023,20 +6254,20 @@
         *,
         stdin: builtins.bool | None = ...,
         stdout: builtins.bool | None = ...,
         stderr: builtins.bool | None = ...,
         tty: builtins.bool | None = ...,
         container: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["container", b"container", "stderr", b"stderr", "stdin", b"stdin", "stdout", b"stdout", "tty", b"tty"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["container", b"container", "stderr", b"stderr", "stdin", b"stdin", "stdout", b"stdout", "tty", b"tty"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["container", b"container", "stderr", b"stderr", "stdin", b"stdin", "stdout", b"stdout", "tty", b"tty"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["container", b"container", "stderr", b"stderr", "stdin", b"stdin", "stdout", b"stdout", "tty", b"tty"]) -> None: ...
 
 global___PodAttachOptions = PodAttachOptions
 
-@typing_extensions.final
+@typing.final
 class PodCondition(google.protobuf.message.Message):
     """PodCondition contains details for the current condition of this pod."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     TYPE_FIELD_NUMBER: builtins.int
     STATUS_FIELD_NUMBER: builtins.int
@@ -6049,48 +6280,50 @@
     More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#pod-conditions
     """
     status: builtins.str
     """Status is the status of the condition.
     Can be True, False, Unknown.
     More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#pod-conditions
     """
+    reason: builtins.str
+    """Unique, one-word, CamelCase reason for the condition's last transition.
+    +optional
+    """
+    message: builtins.str
+    """Human-readable message indicating details about last transition.
+    +optional
+    """
     @property
     def lastProbeTime(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
         """Last time we probed the condition.
         +optional
         """
+
     @property
     def lastTransitionTime(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
         """Last time the condition transitioned from one status to another.
         +optional
         """
-    reason: builtins.str
-    """Unique, one-word, CamelCase reason for the condition's last transition.
-    +optional
-    """
-    message: builtins.str
-    """Human-readable message indicating details about last transition.
-    +optional
-    """
+
     def __init__(
         self,
         *,
         type: builtins.str | None = ...,
         status: builtins.str | None = ...,
         lastProbeTime: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time | None = ...,
         lastTransitionTime: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time | None = ...,
         reason: builtins.str | None = ...,
         message: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["lastProbeTime", b"lastProbeTime", "lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["lastProbeTime", b"lastProbeTime", "lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["lastProbeTime", b"lastProbeTime", "lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["lastProbeTime", b"lastProbeTime", "lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> None: ...
 
 global___PodCondition = PodCondition
 
-@typing_extensions.final
+@typing.final
 class PodDNSConfig(google.protobuf.message.Message):
     """PodDNSConfig defines the DNS parameters of a pod in addition to
     those generated from DNSPolicy.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -6100,41 +6333,44 @@
     @property
     def nameservers(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """A list of DNS name server IP addresses.
         This will be appended to the base nameservers generated from DNSPolicy.
         Duplicated nameservers will be removed.
         +optional
         """
+
     @property
     def searches(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """A list of DNS search domains for host-name lookup.
         This will be appended to the base search paths generated from DNSPolicy.
         Duplicated search paths will be removed.
         +optional
         """
+
     @property
     def options(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PodDNSConfigOption]:
         """A list of DNS resolver options.
         This will be merged with the base options generated from DNSPolicy.
         Duplicated entries will be removed. Resolution options given in Options
         will override those that appear in the base DNSPolicy.
         +optional
         """
+
     def __init__(
         self,
         *,
         nameservers: collections.abc.Iterable[builtins.str] | None = ...,
         searches: collections.abc.Iterable[builtins.str] | None = ...,
         options: collections.abc.Iterable[global___PodDNSConfigOption] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["nameservers", b"nameservers", "options", b"options", "searches", b"searches"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["nameservers", b"nameservers", "options", b"options", "searches", b"searches"]) -> None: ...
 
 global___PodDNSConfig = PodDNSConfig
 
-@typing_extensions.final
+@typing.final
 class PodDNSConfigOption(google.protobuf.message.Message):
     """PodDNSConfigOption defines DNS resolver options of a pod."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     VALUE_FIELD_NUMBER: builtins.int
@@ -6144,20 +6380,20 @@
     """+optional"""
     def __init__(
         self,
         *,
         name: builtins.str | None = ...,
         value: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["name", b"name", "value", b"value"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["name", b"name", "value", b"value"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["name", b"name", "value", b"value"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["name", b"name", "value", b"value"]) -> None: ...
 
 global___PodDNSConfigOption = PodDNSConfigOption
 
-@typing_extensions.final
+@typing.final
 class PodExecOptions(google.protobuf.message.Message):
     """PodExecOptions is the query options to a Pod's remote exec call.
     ---
     TODO: This is largely identical to PodAttachOptions above, make sure they stay in sync and see about merging
     and also when we cut V2, we should export a "StreamOptions" or somesuch that contains Stdin, Stdout, Stder and TTY
     """
 
@@ -6193,30 +6429,31 @@
     """Container in which to execute the command.
     Defaults to only container if there is only one container in the pod.
     +optional
     """
     @property
     def command(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """Command is the remote command to execute. argv array. Not executed within a shell."""
+
     def __init__(
         self,
         *,
         stdin: builtins.bool | None = ...,
         stdout: builtins.bool | None = ...,
         stderr: builtins.bool | None = ...,
         tty: builtins.bool | None = ...,
         container: builtins.str | None = ...,
         command: collections.abc.Iterable[builtins.str] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["container", b"container", "stderr", b"stderr", "stdin", b"stdin", "stdout", b"stdout", "tty", b"tty"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["command", b"command", "container", b"container", "stderr", b"stderr", "stdin", b"stdin", "stdout", b"stdout", "tty", b"tty"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["container", b"container", "stderr", b"stderr", "stdin", b"stdin", "stdout", b"stdout", "tty", b"tty"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["command", b"command", "container", b"container", "stderr", b"stderr", "stdin", b"stdin", "stdout", b"stdout", "tty", b"tty"]) -> None: ...
 
 global___PodExecOptions = PodExecOptions
 
-@typing_extensions.final
+@typing.final
 class PodIP(google.protobuf.message.Message):
     """IP address information for entries in the (plural) PodIPs field.
     Each entry includes:
        IP: An IP address allocated to the pod. Routable at least within the cluster.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -6225,50 +6462,52 @@
     ip: builtins.str
     """ip is an IP address (IPv4 or IPv6) assigned to the pod"""
     def __init__(
         self,
         *,
         ip: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["ip", b"ip"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["ip", b"ip"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["ip", b"ip"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["ip", b"ip"]) -> None: ...
 
 global___PodIP = PodIP
 
-@typing_extensions.final
+@typing.final
 class PodList(google.protobuf.message.Message):
     """PodList is a list of Pods."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """Standard list metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Pod]:
         """List of pods.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[global___Pod] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___PodList = PodList
 
-@typing_extensions.final
+@typing.final
 class PodLogOptions(google.protobuf.message.Message):
     """PodLogOptions is the query options for a Pod's logs REST call."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     CONTAINER_FIELD_NUMBER: builtins.int
     FOLLOW_FIELD_NUMBER: builtins.int
@@ -6294,22 +6533,14 @@
     sinceSeconds: builtins.int
     """A relative time in seconds before the current time from which to show logs. If this value
     precedes the time a pod was started, only logs since the pod start will be returned.
     If this value is in the future, no logs will be returned.
     Only one of sinceSeconds or sinceTime may be specified.
     +optional
     """
-    @property
-    def sinceTime(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
-        """An RFC3339 timestamp from which to show logs. If this value
-        precedes the time a pod was started, only logs since the pod start will be returned.
-        If this value is in the future, no logs will be returned.
-        Only one of sinceSeconds or sinceTime may be specified.
-        +optional
-        """
     timestamps: builtins.bool
     """If true, add an RFC3339 or RFC3339Nano timestamp at the beginning of every line
     of log output. Defaults to false.
     +optional
     """
     tailLines: builtins.int
     """If set, the number of lines from the end of the logs to show. If not specified,
@@ -6327,33 +6558,42 @@
     serving certificate of the backend it is connecting to.  This will make the HTTPS connection between the apiserver
     and the backend insecure. This means the apiserver cannot verify the log data it is receiving came from the real
     kubelet.  If the kubelet is configured to verify the apiserver's TLS credentials, it does not mean the
     connection to the real kubelet is vulnerable to a man in the middle attack (e.g. an attacker could not intercept
     the actual log data coming from the real kubelet).
     +optional
     """
+    @property
+    def sinceTime(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
+        """An RFC3339 timestamp from which to show logs. If this value
+        precedes the time a pod was started, only logs since the pod start will be returned.
+        If this value is in the future, no logs will be returned.
+        Only one of sinceSeconds or sinceTime may be specified.
+        +optional
+        """
+
     def __init__(
         self,
         *,
         container: builtins.str | None = ...,
         follow: builtins.bool | None = ...,
         previous: builtins.bool | None = ...,
         sinceSeconds: builtins.int | None = ...,
         sinceTime: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time | None = ...,
         timestamps: builtins.bool | None = ...,
         tailLines: builtins.int | None = ...,
         limitBytes: builtins.int | None = ...,
         insecureSkipTLSVerifyBackend: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["container", b"container", "follow", b"follow", "insecureSkipTLSVerifyBackend", b"insecureSkipTLSVerifyBackend", "limitBytes", b"limitBytes", "previous", b"previous", "sinceSeconds", b"sinceSeconds", "sinceTime", b"sinceTime", "tailLines", b"tailLines", "timestamps", b"timestamps"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["container", b"container", "follow", b"follow", "insecureSkipTLSVerifyBackend", b"insecureSkipTLSVerifyBackend", "limitBytes", b"limitBytes", "previous", b"previous", "sinceSeconds", b"sinceSeconds", "sinceTime", b"sinceTime", "tailLines", b"tailLines", "timestamps", b"timestamps"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["container", b"container", "follow", b"follow", "insecureSkipTLSVerifyBackend", b"insecureSkipTLSVerifyBackend", "limitBytes", b"limitBytes", "previous", b"previous", "sinceSeconds", b"sinceSeconds", "sinceTime", b"sinceTime", "tailLines", b"tailLines", "timestamps", b"timestamps"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["container", b"container", "follow", b"follow", "insecureSkipTLSVerifyBackend", b"insecureSkipTLSVerifyBackend", "limitBytes", b"limitBytes", "previous", b"previous", "sinceSeconds", b"sinceSeconds", "sinceTime", b"sinceTime", "tailLines", b"tailLines", "timestamps", b"timestamps"]) -> None: ...
 
 global___PodLogOptions = PodLogOptions
 
-@typing_extensions.final
+@typing.final
 class PodPortForwardOptions(google.protobuf.message.Message):
     """PodPortForwardOptions is the query options to a Pod's port forward call
     when using WebSockets.
     The `port` query parameter must specify the port or
     ports (comma separated) to forward over.
     Port forwarding over SPDY does not use these options. It requires the port
     to be passed in the `port` header as part of request.
@@ -6364,24 +6604,25 @@
     PORTS_FIELD_NUMBER: builtins.int
     @property
     def ports(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.int]:
         """List of ports to forward
         Required when using WebSockets
         +optional
         """
+
     def __init__(
         self,
         *,
         ports: collections.abc.Iterable[builtins.int] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["ports", b"ports"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["ports", b"ports"]) -> None: ...
 
 global___PodPortForwardOptions = PodPortForwardOptions
 
-@typing_extensions.final
+@typing.final
 class PodProxyOptions(google.protobuf.message.Message):
     """PodProxyOptions is the query options to a Pod's proxy call."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PATH_FIELD_NUMBER: builtins.int
     path: builtins.str
@@ -6389,39 +6630,39 @@
     +optional
     """
     def __init__(
         self,
         *,
         path: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["path", b"path"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["path", b"path"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["path", b"path"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["path", b"path"]) -> None: ...
 
 global___PodProxyOptions = PodProxyOptions
 
-@typing_extensions.final
+@typing.final
 class PodReadinessGate(google.protobuf.message.Message):
     """PodReadinessGate contains the reference to a pod condition"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     CONDITIONTYPE_FIELD_NUMBER: builtins.int
     conditionType: builtins.str
     """ConditionType refers to a condition in the pod's condition list with matching type."""
     def __init__(
         self,
         *,
         conditionType: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["conditionType", b"conditionType"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["conditionType", b"conditionType"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["conditionType", b"conditionType"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["conditionType", b"conditionType"]) -> None: ...
 
 global___PodReadinessGate = PodReadinessGate
 
-@typing_extensions.final
+@typing.final
 class PodSecurityContext(google.protobuf.message.Message):
     """PodSecurityContext holds pod-level security attributes and common container settings.
     Some fields are also present in container.securityContext.  Field values of
     container.securityContext take precedence over field values of PodSecurityContext.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -6432,30 +6673,14 @@
     RUNASGROUP_FIELD_NUMBER: builtins.int
     RUNASNONROOT_FIELD_NUMBER: builtins.int
     SUPPLEMENTALGROUPS_FIELD_NUMBER: builtins.int
     FSGROUP_FIELD_NUMBER: builtins.int
     SYSCTLS_FIELD_NUMBER: builtins.int
     FSGROUPCHANGEPOLICY_FIELD_NUMBER: builtins.int
     SECCOMPPROFILE_FIELD_NUMBER: builtins.int
-    @property
-    def seLinuxOptions(self) -> global___SELinuxOptions:
-        """The SELinux context to be applied to all containers.
-        If unspecified, the container runtime will allocate a random SELinux context for each
-        container.  May also be set in SecurityContext.  If set in
-        both SecurityContext and PodSecurityContext, the value specified in SecurityContext
-        takes precedence for that container.
-        +optional
-        """
-    @property
-    def windowsOptions(self) -> global___WindowsSecurityContextOptions:
-        """The Windows specific settings applied to all containers.
-        If unspecified, the options within a container's SecurityContext will be used.
-        If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
-        +optional
-        """
     runAsUser: builtins.int
     """The UID to run the entrypoint of the container process.
     Defaults to user specified in image metadata if unspecified.
     May also be set in SecurityContext.  If set in both SecurityContext and
     PodSecurityContext, the value specified in SecurityContext takes precedence
     for that container.
     +optional
@@ -6473,136 +6698,158 @@
     If true, the Kubelet will validate the image at runtime to ensure that it
     does not run as UID 0 (root) and fail to start the container if it does.
     If unset or false, no such validation will be performed.
     May also be set in SecurityContext.  If set in both SecurityContext and
     PodSecurityContext, the value specified in SecurityContext takes precedence.
     +optional
     """
-    @property
-    def supplementalGroups(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.int]:
-        """A list of groups applied to the first process run in each container, in addition
-        to the container's primary GID.  If unspecified, no groups will be added to
-        any container.
-        +optional
-        """
     fsGroup: builtins.int
     """A special supplemental group that applies to all containers in a pod.
     Some volume types allow the Kubelet to change the ownership of that volume
     to be owned by the pod:
 
     1. The owning GID will be the FSGroup
     2. The setgid bit is set (new files created in the volume will be owned by FSGroup)
     3. The permission bits are OR'd with rw-rw----
 
     If unset, the Kubelet will not modify the ownership and permissions of any volume.
     +optional
     """
-    @property
-    def sysctls(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Sysctl]:
-        """Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported
-        sysctls (by the container runtime) might fail to launch.
-        +optional
-        """
     fsGroupChangePolicy: builtins.str
     """fsGroupChangePolicy defines behavior of changing ownership and permission of the volume
     before being exposed inside Pod. This field will only apply to
     volume types which support fsGroup based ownership(and permissions).
     It will have no effect on ephemeral volume types such as: secret, configmaps
     and emptydir.
     Valid values are "OnRootMismatch" and "Always". If not specified, "Always" is used.
     +optional
     """
     @property
+    def seLinuxOptions(self) -> global___SELinuxOptions:
+        """The SELinux context to be applied to all containers.
+        If unspecified, the container runtime will allocate a random SELinux context for each
+        container.  May also be set in SecurityContext.  If set in
+        both SecurityContext and PodSecurityContext, the value specified in SecurityContext
+        takes precedence for that container.
+        +optional
+        """
+
+    @property
+    def windowsOptions(self) -> global___WindowsSecurityContextOptions:
+        """The Windows specific settings applied to all containers.
+        If unspecified, the options within a container's SecurityContext will be used.
+        If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
+        +optional
+        """
+
+    @property
+    def supplementalGroups(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.int]:
+        """A list of groups applied to the first process run in each container, in addition
+        to the container's primary GID.  If unspecified, no groups will be added to
+        any container.
+        +optional
+        """
+
+    @property
+    def sysctls(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Sysctl]:
+        """Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported
+        sysctls (by the container runtime) might fail to launch.
+        +optional
+        """
+
+    @property
     def seccompProfile(self) -> global___SeccompProfile:
         """The seccomp options to use by the containers in this pod.
         +optional
         """
+
     def __init__(
         self,
         *,
         seLinuxOptions: global___SELinuxOptions | None = ...,
         windowsOptions: global___WindowsSecurityContextOptions | None = ...,
         runAsUser: builtins.int | None = ...,
         runAsGroup: builtins.int | None = ...,
         runAsNonRoot: builtins.bool | None = ...,
         supplementalGroups: collections.abc.Iterable[builtins.int] | None = ...,
         fsGroup: builtins.int | None = ...,
         sysctls: collections.abc.Iterable[global___Sysctl] | None = ...,
         fsGroupChangePolicy: builtins.str | None = ...,
         seccompProfile: global___SeccompProfile | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fsGroup", b"fsGroup", "fsGroupChangePolicy", b"fsGroupChangePolicy", "runAsGroup", b"runAsGroup", "runAsNonRoot", b"runAsNonRoot", "runAsUser", b"runAsUser", "seLinuxOptions", b"seLinuxOptions", "seccompProfile", b"seccompProfile", "windowsOptions", b"windowsOptions"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["fsGroup", b"fsGroup", "fsGroupChangePolicy", b"fsGroupChangePolicy", "runAsGroup", b"runAsGroup", "runAsNonRoot", b"runAsNonRoot", "runAsUser", b"runAsUser", "seLinuxOptions", b"seLinuxOptions", "seccompProfile", b"seccompProfile", "supplementalGroups", b"supplementalGroups", "sysctls", b"sysctls", "windowsOptions", b"windowsOptions"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fsGroup", b"fsGroup", "fsGroupChangePolicy", b"fsGroupChangePolicy", "runAsGroup", b"runAsGroup", "runAsNonRoot", b"runAsNonRoot", "runAsUser", b"runAsUser", "seLinuxOptions", b"seLinuxOptions", "seccompProfile", b"seccompProfile", "windowsOptions", b"windowsOptions"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["fsGroup", b"fsGroup", "fsGroupChangePolicy", b"fsGroupChangePolicy", "runAsGroup", b"runAsGroup", "runAsNonRoot", b"runAsNonRoot", "runAsUser", b"runAsUser", "seLinuxOptions", b"seLinuxOptions", "seccompProfile", b"seccompProfile", "supplementalGroups", b"supplementalGroups", "sysctls", b"sysctls", "windowsOptions", b"windowsOptions"]) -> None: ...
 
 global___PodSecurityContext = PodSecurityContext
 
-@typing_extensions.final
+@typing.final
 class PodSignature(google.protobuf.message.Message):
     """Describes the class of pods that should avoid this node.
     Exactly one field should be set.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PODCONTROLLER_FIELD_NUMBER: builtins.int
     @property
     def podController(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.OwnerReference:
         """Reference to controller whose pods should avoid this node.
         +optional
         """
+
     def __init__(
         self,
         *,
         podController: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.OwnerReference | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["podController", b"podController"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["podController", b"podController"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["podController", b"podController"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["podController", b"podController"]) -> None: ...
 
 global___PodSignature = PodSignature
 
-@typing_extensions.final
+@typing.final
 class PodSpec(google.protobuf.message.Message):
     """PodSpec is a description of a pod."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class NodeSelectorEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: builtins.str | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
-    @typing_extensions.final
+    @typing.final
     class OverheadEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity: ...
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     VOLUMES_FIELD_NUMBER: builtins.int
     INITCONTAINERS_FIELD_NUMBER: builtins.int
     CONTAINERS_FIELD_NUMBER: builtins.int
     EPHEMERALCONTAINERS_FIELD_NUMBER: builtins.int
     RESTARTPOLICY_FIELD_NUMBER: builtins.int
     TERMINATIONGRACEPERIODSECONDS_FIELD_NUMBER: builtins.int
@@ -6631,60 +6878,14 @@
     READINESSGATES_FIELD_NUMBER: builtins.int
     RUNTIMECLASSNAME_FIELD_NUMBER: builtins.int
     ENABLESERVICELINKS_FIELD_NUMBER: builtins.int
     PREEMPTIONPOLICY_FIELD_NUMBER: builtins.int
     OVERHEAD_FIELD_NUMBER: builtins.int
     TOPOLOGYSPREADCONSTRAINTS_FIELD_NUMBER: builtins.int
     SETHOSTNAMEASFQDN_FIELD_NUMBER: builtins.int
-    @property
-    def volumes(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Volume]:
-        """List of volumes that can be mounted by containers belonging to the pod.
-        More info: https://kubernetes.io/docs/concepts/storage/volumes
-        +optional
-        +patchMergeKey=name
-        +patchStrategy=merge,retainKeys
-        """
-    @property
-    def initContainers(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Container]:
-        """List of initialization containers belonging to the pod.
-        Init containers are executed in order prior to containers being started. If any
-        init container fails, the pod is considered to have failed and is handled according
-        to its restartPolicy. The name for an init container or normal container must be
-        unique among all containers.
-        Init containers may not have Lifecycle actions, Readiness probes, Liveness probes, or Startup probes.
-        The resourceRequirements of an init container are taken into account during scheduling
-        by finding the highest request/limit for each resource type, and then using the max of
-        of that value or the sum of the normal containers. Limits are applied to init containers
-        in a similar fashion.
-        Init containers cannot currently be added or removed.
-        Cannot be updated.
-        More info: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
-        +patchMergeKey=name
-        +patchStrategy=merge
-        """
-    @property
-    def containers(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Container]:
-        """List of containers belonging to the pod.
-        Containers cannot currently be added or removed.
-        There must be at least one container in a Pod.
-        Cannot be updated.
-        +patchMergeKey=name
-        +patchStrategy=merge
-        """
-    @property
-    def ephemeralContainers(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___EphemeralContainer]:
-        """List of ephemeral containers run in this pod. Ephemeral containers may be run in an existing
-        pod to perform user-initiated actions such as debugging. This list cannot be specified when
-        creating a pod, and it cannot be modified by updating the pod spec. In order to add an
-        ephemeral container to an existing pod, use the pod's ephemeralcontainers subresource.
-        This field is alpha-level and is only honored by servers that enable the EphemeralContainers feature.
-        +optional
-        +patchMergeKey=name
-        +patchStrategy=merge
-        """
     restartPolicy: builtins.str
     """Restart policy for all containers within the pod.
     One of Always, OnFailure, Never.
     Default to Always.
     More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy
     +optional
     """
@@ -6710,22 +6911,14 @@
     Defaults to "ClusterFirst".
     Valid values are 'ClusterFirstWithHostNet', 'ClusterFirst', 'Default' or 'None'.
     DNS parameters given in DNSConfig will be merged with the policy selected with DNSPolicy.
     To have DNS options set along with hostNetwork, you have to specify DNS policy
     explicitly to 'ClusterFirstWithHostNet'.
     +optional
     """
-    @property
-    def nodeSelector(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]:
-        """NodeSelector is a selector which must be true for the pod to fit on a node.
-        Selector which must match a node's labels for the pod to be scheduled on that node.
-        More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
-        +optional
-        +mapType=atomic
-        """
     serviceAccountName: builtins.str
     """ServiceAccountName is the name of the ServiceAccount to use to run this pod.
     More info: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
     +optional
     """
     serviceAccount: builtins.str
     """DeprecatedServiceAccount is a depreciated alias for ServiceAccountName.
@@ -6767,63 +6960,29 @@
     When this is set containers will be able to view and signal processes from other containers
     in the same pod, and the first process in each container will not be assigned PID 1.
     HostPID and ShareProcessNamespace cannot both be set.
     Optional: Default to false.
     +k8s:conversion-gen=false
     +optional
     """
-    @property
-    def securityContext(self) -> global___PodSecurityContext:
-        """SecurityContext holds pod-level security attributes and common container settings.
-        Optional: Defaults to empty.  See type description for default values of each field.
-        +optional
-        """
-    @property
-    def imagePullSecrets(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___LocalObjectReference]:
-        """ImagePullSecrets is an optional list of references to secrets in the same namespace to use for pulling any of the images used by this PodSpec.
-        If specified, these secrets will be passed to individual puller implementations for them to use. For example,
-        in the case of docker, only DockerConfig type secrets are honored.
-        More info: https://kubernetes.io/docs/concepts/containers/images#specifying-imagepullsecrets-on-a-pod
-        +optional
-        +patchMergeKey=name
-        +patchStrategy=merge
-        """
     hostname: builtins.str
     """Specifies the hostname of the Pod
     If not specified, the pod's hostname will be set to a system-defined value.
     +optional
     """
     subdomain: builtins.str
     """If specified, the fully qualified Pod hostname will be "<hostname>.<subdomain>.<pod namespace>.svc.<cluster domain>".
     If not specified, the pod will not have a domainname at all.
     +optional
     """
-    @property
-    def affinity(self) -> global___Affinity:
-        """If specified, the pod's scheduling constraints
-        +optional
-        """
     schedulerName: builtins.str
     """If specified, the pod will be dispatched by specified scheduler.
     If not specified, the pod will be dispatched by default scheduler.
     +optional
     """
-    @property
-    def tolerations(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Toleration]:
-        """If specified, the pod's tolerations.
-        +optional
-        """
-    @property
-    def hostAliases(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___HostAlias]:
-        """HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts
-        file if specified. This is only valid for non-hostNetwork pods.
-        +optional
-        +patchMergeKey=ip
-        +patchStrategy=merge
-        """
     priorityClassName: builtins.str
     """If specified, indicates the pod's priority. "system-node-critical" and
     "system-cluster-critical" are two special keywords which indicate the
     highest priorities with the former being the highest priority. Any other
     name must be defined by creating a PriorityClass object with that name.
     If not specified, the pod priority will be default or zero if there is no
     default.
@@ -6833,29 +6992,14 @@
     """The priority value. Various system components use this field to find the
     priority of the pod. When Priority Admission Controller is enabled, it
     prevents users from setting this field. The admission controller populates
     this field from PriorityClassName.
     The higher the value, the higher the priority.
     +optional
     """
-    @property
-    def dnsConfig(self) -> global___PodDNSConfig:
-        """Specifies the DNS parameters of a pod.
-        Parameters specified here will be merged to the generated DNS
-        configuration based on DNSPolicy.
-        +optional
-        """
-    @property
-    def readinessGates(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PodReadinessGate]:
-        """If specified, all readiness gates will be evaluated for pod readiness.
-        A pod is ready when all its containers are ready AND
-        all conditions specified in the readiness gates have status equal to "True"
-        More info: https://git.k8s.io/enhancements/keps/sig-network/580-pod-readiness-gates
-        +optional
-        """
     runtimeClassName: builtins.str
     """RuntimeClassName refers to a RuntimeClass object in the node.k8s.io group, which should be used
     to run this pod.  If no RuntimeClass resource matches the named class, the pod will not be run.
     If unset or empty, the "legacy" RuntimeClass will be used, which is an implicit class with an
     empty definition that uses the default runtime handler.
     More info: https://git.k8s.io/enhancements/keps/sig-node/585-runtime-class
     This is a beta feature as of Kubernetes v1.14.
@@ -6870,46 +7014,163 @@
     preemptionPolicy: builtins.str
     """PreemptionPolicy is the Policy for preempting pods with lower priority.
     One of Never, PreemptLowerPriority.
     Defaults to PreemptLowerPriority if unset.
     This field is beta-level, gated by the NonPreemptingPriority feature-gate.
     +optional
     """
+    setHostnameAsFQDN: builtins.bool
+    """If true the pod's hostname will be configured as the pod's FQDN, rather than the leaf name (the default).
+    In Linux containers, this means setting the FQDN in the hostname field of the kernel (the nodename field of struct utsname).
+    In Windows containers, this means setting the registry value of hostname for the registry key HKEY_LOCAL_MACHINE\\\\SYSTEM\\\\CurrentControlSet\\\\Services\\\\Tcpip\\\\Parameters to FQDN.
+    If a pod does not have FQDN, this has no effect.
+    Default to false.
+    +optional
+    """
+    @property
+    def volumes(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Volume]:
+        """List of volumes that can be mounted by containers belonging to the pod.
+        More info: https://kubernetes.io/docs/concepts/storage/volumes
+        +optional
+        +patchMergeKey=name
+        +patchStrategy=merge,retainKeys
+        """
+
+    @property
+    def initContainers(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Container]:
+        """List of initialization containers belonging to the pod.
+        Init containers are executed in order prior to containers being started. If any
+        init container fails, the pod is considered to have failed and is handled according
+        to its restartPolicy. The name for an init container or normal container must be
+        unique among all containers.
+        Init containers may not have Lifecycle actions, Readiness probes, Liveness probes, or Startup probes.
+        The resourceRequirements of an init container are taken into account during scheduling
+        by finding the highest request/limit for each resource type, and then using the max of
+        of that value or the sum of the normal containers. Limits are applied to init containers
+        in a similar fashion.
+        Init containers cannot currently be added or removed.
+        Cannot be updated.
+        More info: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
+        +patchMergeKey=name
+        +patchStrategy=merge
+        """
+
+    @property
+    def containers(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Container]:
+        """List of containers belonging to the pod.
+        Containers cannot currently be added or removed.
+        There must be at least one container in a Pod.
+        Cannot be updated.
+        +patchMergeKey=name
+        +patchStrategy=merge
+        """
+
+    @property
+    def ephemeralContainers(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___EphemeralContainer]:
+        """List of ephemeral containers run in this pod. Ephemeral containers may be run in an existing
+        pod to perform user-initiated actions such as debugging. This list cannot be specified when
+        creating a pod, and it cannot be modified by updating the pod spec. In order to add an
+        ephemeral container to an existing pod, use the pod's ephemeralcontainers subresource.
+        This field is alpha-level and is only honored by servers that enable the EphemeralContainers feature.
+        +optional
+        +patchMergeKey=name
+        +patchStrategy=merge
+        """
+
+    @property
+    def nodeSelector(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]:
+        """NodeSelector is a selector which must be true for the pod to fit on a node.
+        Selector which must match a node's labels for the pod to be scheduled on that node.
+        More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
+        +optional
+        +mapType=atomic
+        """
+
+    @property
+    def securityContext(self) -> global___PodSecurityContext:
+        """SecurityContext holds pod-level security attributes and common container settings.
+        Optional: Defaults to empty.  See type description for default values of each field.
+        +optional
+        """
+
+    @property
+    def imagePullSecrets(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___LocalObjectReference]:
+        """ImagePullSecrets is an optional list of references to secrets in the same namespace to use for pulling any of the images used by this PodSpec.
+        If specified, these secrets will be passed to individual puller implementations for them to use. For example,
+        in the case of docker, only DockerConfig type secrets are honored.
+        More info: https://kubernetes.io/docs/concepts/containers/images#specifying-imagepullsecrets-on-a-pod
+        +optional
+        +patchMergeKey=name
+        +patchStrategy=merge
+        """
+
+    @property
+    def affinity(self) -> global___Affinity:
+        """If specified, the pod's scheduling constraints
+        +optional
+        """
+
+    @property
+    def tolerations(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Toleration]:
+        """If specified, the pod's tolerations.
+        +optional
+        """
+
+    @property
+    def hostAliases(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___HostAlias]:
+        """HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts
+        file if specified. This is only valid for non-hostNetwork pods.
+        +optional
+        +patchMergeKey=ip
+        +patchStrategy=merge
+        """
+
+    @property
+    def dnsConfig(self) -> global___PodDNSConfig:
+        """Specifies the DNS parameters of a pod.
+        Parameters specified here will be merged to the generated DNS
+        configuration based on DNSPolicy.
+        +optional
+        """
+
+    @property
+    def readinessGates(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PodReadinessGate]:
+        """If specified, all readiness gates will be evaluated for pod readiness.
+        A pod is ready when all its containers are ready AND
+        all conditions specified in the readiness gates have status equal to "True"
+        More info: https://git.k8s.io/enhancements/keps/sig-network/580-pod-readiness-gates
+        +optional
+        """
+
     @property
     def overhead(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity]:
         """Overhead represents the resource overhead associated with running a pod for a given RuntimeClass.
         This field will be autopopulated at admission time by the RuntimeClass admission controller. If
         the RuntimeClass admission controller is enabled, overhead must not be set in Pod create requests.
         The RuntimeClass admission controller will reject Pod create requests which have the overhead already
         set. If RuntimeClass is configured and selected in the PodSpec, Overhead will be set to the value
         defined in the corresponding RuntimeClass, otherwise it will remain unset and treated as zero.
         More info: https://git.k8s.io/enhancements/keps/sig-node/688-pod-overhead/README.md
         This field is beta-level as of Kubernetes v1.18, and is only honored by servers that enable the PodOverhead feature.
         +optional
         """
+
     @property
     def topologySpreadConstraints(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___TopologySpreadConstraint]:
         """TopologySpreadConstraints describes how a group of pods ought to spread across topology
         domains. Scheduler will schedule pods in a way which abides by the constraints.
         All topologySpreadConstraints are ANDed.
         +optional
         +patchMergeKey=topologyKey
         +patchStrategy=merge
         +listType=map
         +listMapKey=topologyKey
         +listMapKey=whenUnsatisfiable
         """
-    setHostnameAsFQDN: builtins.bool
-    """If true the pod's hostname will be configured as the pod's FQDN, rather than the leaf name (the default).
-    In Linux containers, this means setting the FQDN in the hostname field of the kernel (the nodename field of struct utsname).
-    In Windows containers, this means setting the registry value of hostname for the registry key HKEY_LOCAL_MACHINE\\\\SYSTEM\\\\CurrentControlSet\\\\Services\\\\Tcpip\\\\Parameters to FQDN.
-    If a pod does not have FQDN, this has no effect.
-    Default to false.
-    +optional
-    """
+
     def __init__(
         self,
         *,
         volumes: collections.abc.Iterable[global___Volume] | None = ...,
         initContainers: collections.abc.Iterable[global___Container] | None = ...,
         containers: collections.abc.Iterable[global___Container] | None = ...,
         ephemeralContainers: collections.abc.Iterable[global___EphemeralContainer] | None = ...,
@@ -6941,20 +7202,20 @@
         runtimeClassName: builtins.str | None = ...,
         enableServiceLinks: builtins.bool | None = ...,
         preemptionPolicy: builtins.str | None = ...,
         overhead: collections.abc.Mapping[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity] | None = ...,
         topologySpreadConstraints: collections.abc.Iterable[global___TopologySpreadConstraint] | None = ...,
         setHostnameAsFQDN: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["activeDeadlineSeconds", b"activeDeadlineSeconds", "affinity", b"affinity", "automountServiceAccountToken", b"automountServiceAccountToken", "dnsConfig", b"dnsConfig", "dnsPolicy", b"dnsPolicy", "enableServiceLinks", b"enableServiceLinks", "hostIPC", b"hostIPC", "hostNetwork", b"hostNetwork", "hostPID", b"hostPID", "hostname", b"hostname", "nodeName", b"nodeName", "preemptionPolicy", b"preemptionPolicy", "priority", b"priority", "priorityClassName", b"priorityClassName", "restartPolicy", b"restartPolicy", "runtimeClassName", b"runtimeClassName", "schedulerName", b"schedulerName", "securityContext", b"securityContext", "serviceAccount", b"serviceAccount", "serviceAccountName", b"serviceAccountName", "setHostnameAsFQDN", b"setHostnameAsFQDN", "shareProcessNamespace", b"shareProcessNamespace", "subdomain", b"subdomain", "terminationGracePeriodSeconds", b"terminationGracePeriodSeconds"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["activeDeadlineSeconds", b"activeDeadlineSeconds", "affinity", b"affinity", "automountServiceAccountToken", b"automountServiceAccountToken", "containers", b"containers", "dnsConfig", b"dnsConfig", "dnsPolicy", b"dnsPolicy", "enableServiceLinks", b"enableServiceLinks", "ephemeralContainers", b"ephemeralContainers", "hostAliases", b"hostAliases", "hostIPC", b"hostIPC", "hostNetwork", b"hostNetwork", "hostPID", b"hostPID", "hostname", b"hostname", "imagePullSecrets", b"imagePullSecrets", "initContainers", b"initContainers", "nodeName", b"nodeName", "nodeSelector", b"nodeSelector", "overhead", b"overhead", "preemptionPolicy", b"preemptionPolicy", "priority", b"priority", "priorityClassName", b"priorityClassName", "readinessGates", b"readinessGates", "restartPolicy", b"restartPolicy", "runtimeClassName", b"runtimeClassName", "schedulerName", b"schedulerName", "securityContext", b"securityContext", "serviceAccount", b"serviceAccount", "serviceAccountName", b"serviceAccountName", "setHostnameAsFQDN", b"setHostnameAsFQDN", "shareProcessNamespace", b"shareProcessNamespace", "subdomain", b"subdomain", "terminationGracePeriodSeconds", b"terminationGracePeriodSeconds", "tolerations", b"tolerations", "topologySpreadConstraints", b"topologySpreadConstraints", "volumes", b"volumes"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["activeDeadlineSeconds", b"activeDeadlineSeconds", "affinity", b"affinity", "automountServiceAccountToken", b"automountServiceAccountToken", "dnsConfig", b"dnsConfig", "dnsPolicy", b"dnsPolicy", "enableServiceLinks", b"enableServiceLinks", "hostIPC", b"hostIPC", "hostNetwork", b"hostNetwork", "hostPID", b"hostPID", "hostname", b"hostname", "nodeName", b"nodeName", "preemptionPolicy", b"preemptionPolicy", "priority", b"priority", "priorityClassName", b"priorityClassName", "restartPolicy", b"restartPolicy", "runtimeClassName", b"runtimeClassName", "schedulerName", b"schedulerName", "securityContext", b"securityContext", "serviceAccount", b"serviceAccount", "serviceAccountName", b"serviceAccountName", "setHostnameAsFQDN", b"setHostnameAsFQDN", "shareProcessNamespace", b"shareProcessNamespace", "subdomain", b"subdomain", "terminationGracePeriodSeconds", b"terminationGracePeriodSeconds"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["activeDeadlineSeconds", b"activeDeadlineSeconds", "affinity", b"affinity", "automountServiceAccountToken", b"automountServiceAccountToken", "containers", b"containers", "dnsConfig", b"dnsConfig", "dnsPolicy", b"dnsPolicy", "enableServiceLinks", b"enableServiceLinks", "ephemeralContainers", b"ephemeralContainers", "hostAliases", b"hostAliases", "hostIPC", b"hostIPC", "hostNetwork", b"hostNetwork", "hostPID", b"hostPID", "hostname", b"hostname", "imagePullSecrets", b"imagePullSecrets", "initContainers", b"initContainers", "nodeName", b"nodeName", "nodeSelector", b"nodeSelector", "overhead", b"overhead", "preemptionPolicy", b"preemptionPolicy", "priority", b"priority", "priorityClassName", b"priorityClassName", "readinessGates", b"readinessGates", "restartPolicy", b"restartPolicy", "runtimeClassName", b"runtimeClassName", "schedulerName", b"schedulerName", "securityContext", b"securityContext", "serviceAccount", b"serviceAccount", "serviceAccountName", b"serviceAccountName", "setHostnameAsFQDN", b"setHostnameAsFQDN", "shareProcessNamespace", b"shareProcessNamespace", "subdomain", b"subdomain", "terminationGracePeriodSeconds", b"terminationGracePeriodSeconds", "tolerations", b"tolerations", "topologySpreadConstraints", b"topologySpreadConstraints", "volumes", b"volumes"]) -> None: ...
 
 global___PodSpec = PodSpec
 
-@typing_extensions.final
+@typing.final
 class PodStatus(google.protobuf.message.Message):
     """PodStatus represents information about the status of a pod. Status may trail the actual
     state of a system, especially if the node that hosts the pod cannot contact the control
     plane.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -6989,22 +7250,14 @@
     by the system.
     Unknown: For some reason the state of the pod could not be obtained, typically due to an
     error in communicating with the host of the pod.
 
     More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#pod-phase
     +optional
     """
-    @property
-    def conditions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PodCondition]:
-        """Current service state of pod.
-        More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#pod-conditions
-        +optional
-        +patchMergeKey=type
-        +patchStrategy=merge
-        """
     message: builtins.str
     """A human readable message indicating details about why the pod is in this condition.
     +optional
     """
     reason: builtins.str
     """A brief CamelCase message indicating details about why the pod is in this state.
     e.g. 'Evicted'
@@ -7025,55 +7278,69 @@
     +optional
     """
     podIP: builtins.str
     """IP address allocated to the pod. Routable at least within the cluster.
     Empty if not yet allocated.
     +optional
     """
+    qosClass: builtins.str
+    """The Quality of Service (QOS) classification assigned to the pod based on resource requirements
+    See PodQOSClass type for available QOS classes
+    More info: https://git.k8s.io/community/contributors/design-proposals/node/resource-qos.md
+    +optional
+    """
+    @property
+    def conditions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PodCondition]:
+        """Current service state of pod.
+        More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#pod-conditions
+        +optional
+        +patchMergeKey=type
+        +patchStrategy=merge
+        """
+
     @property
     def podIPs(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PodIP]:
         """podIPs holds the IP addresses allocated to the pod. If this field is specified, the 0th entry must
         match the podIP field. Pods may be allocated at most 1 value for each of IPv4 and IPv6. This list
         is empty if no IPs have been allocated yet.
         +optional
         +patchStrategy=merge
         +patchMergeKey=ip
         """
+
     @property
     def startTime(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
         """RFC 3339 date and time at which the object was acknowledged by the Kubelet.
         This is before the Kubelet pulled the container image(s) for the pod.
         +optional
         """
+
     @property
     def initContainerStatuses(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ContainerStatus]:
         """The list has one entry per init container in the manifest. The most recent successful
         init container will have ready = true, the most recently started container will have
         startTime set.
         More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#pod-and-container-status
         """
+
     @property
     def containerStatuses(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ContainerStatus]:
         """The list has one entry per container in the manifest. Each entry is currently the output
         of `docker inspect`.
         More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#pod-and-container-status
         +optional
         """
-    qosClass: builtins.str
-    """The Quality of Service (QOS) classification assigned to the pod based on resource requirements
-    See PodQOSClass type for available QOS classes
-    More info: https://git.k8s.io/community/contributors/design-proposals/node/resource-qos.md
-    +optional
-    """
+
     @property
     def ephemeralContainerStatuses(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ContainerStatus]:
         """Status for any ephemeral containers that have run in this pod.
         This field is alpha-level and is only populated by servers that enable the EphemeralContainers feature.
         +optional
         """
+
     def __init__(
         self,
         *,
         phase: builtins.str | None = ...,
         conditions: collections.abc.Iterable[global___PodCondition] | None = ...,
         message: builtins.str | None = ...,
         reason: builtins.str | None = ...,
@@ -7083,144 +7350,152 @@
         podIPs: collections.abc.Iterable[global___PodIP] | None = ...,
         startTime: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time | None = ...,
         initContainerStatuses: collections.abc.Iterable[global___ContainerStatus] | None = ...,
         containerStatuses: collections.abc.Iterable[global___ContainerStatus] | None = ...,
         qosClass: builtins.str | None = ...,
         ephemeralContainerStatuses: collections.abc.Iterable[global___ContainerStatus] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["hostIP", b"hostIP", "message", b"message", "nominatedNodeName", b"nominatedNodeName", "phase", b"phase", "podIP", b"podIP", "qosClass", b"qosClass", "reason", b"reason", "startTime", b"startTime"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["conditions", b"conditions", "containerStatuses", b"containerStatuses", "ephemeralContainerStatuses", b"ephemeralContainerStatuses", "hostIP", b"hostIP", "initContainerStatuses", b"initContainerStatuses", "message", b"message", "nominatedNodeName", b"nominatedNodeName", "phase", b"phase", "podIP", b"podIP", "podIPs", b"podIPs", "qosClass", b"qosClass", "reason", b"reason", "startTime", b"startTime"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["hostIP", b"hostIP", "message", b"message", "nominatedNodeName", b"nominatedNodeName", "phase", b"phase", "podIP", b"podIP", "qosClass", b"qosClass", "reason", b"reason", "startTime", b"startTime"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["conditions", b"conditions", "containerStatuses", b"containerStatuses", "ephemeralContainerStatuses", b"ephemeralContainerStatuses", "hostIP", b"hostIP", "initContainerStatuses", b"initContainerStatuses", "message", b"message", "nominatedNodeName", b"nominatedNodeName", "phase", b"phase", "podIP", b"podIP", "podIPs", b"podIPs", "qosClass", b"qosClass", "reason", b"reason", "startTime", b"startTime"]) -> None: ...
 
 global___PodStatus = PodStatus
 
-@typing_extensions.final
+@typing.final
 class PodStatusResult(google.protobuf.message.Message):
     """PodStatusResult is a wrapper for PodStatus returned by kubelet that can be encode/decoded"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     STATUS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def status(self) -> global___PodStatus:
         """Most recently observed status of the pod.
         This data may not be up to date.
         Populated by the system.
         Read-only.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         +optional
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         status: global___PodStatus | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "status", b"status"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "status", b"status"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata", "status", b"status"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["metadata", b"metadata", "status", b"status"]) -> None: ...
 
 global___PodStatusResult = PodStatusResult
 
-@typing_extensions.final
+@typing.final
 class PodTemplate(google.protobuf.message.Message):
     """PodTemplate describes a template for creating copies of a predefined pod."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     TEMPLATE_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def template(self) -> global___PodTemplateSpec:
         """Template defines the pods that will be created from this pod template.
         https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         +optional
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         template: global___PodTemplateSpec | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "template", b"template"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "template", b"template"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata", "template", b"template"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["metadata", b"metadata", "template", b"template"]) -> None: ...
 
 global___PodTemplate = PodTemplate
 
-@typing_extensions.final
+@typing.final
 class PodTemplateList(google.protobuf.message.Message):
     """PodTemplateList is a list of PodTemplates."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """Standard list metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PodTemplate]:
         """List of pod templates"""
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[global___PodTemplate] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___PodTemplateList = PodTemplateList
 
-@typing_extensions.final
+@typing.final
 class PodTemplateSpec(google.protobuf.message.Message):
     """PodTemplateSpec describes the data a pod should have when created from a template"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     SPEC_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def spec(self) -> global___PodSpec:
         """Specification of the desired behavior of the pod.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         +optional
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         spec: global___PodSpec | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec"]) -> None: ...
 
 global___PodTemplateSpec = PodTemplateSpec
 
-@typing_extensions.final
+@typing.final
 class PortStatus(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PORT_FIELD_NUMBER: builtins.int
     PROTOCOL_FIELD_NUMBER: builtins.int
     ERROR_FIELD_NUMBER: builtins.int
     port: builtins.int
@@ -7246,20 +7521,20 @@
     def __init__(
         self,
         *,
         port: builtins.int | None = ...,
         protocol: builtins.str | None = ...,
         error: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["error", b"error", "port", b"port", "protocol", b"protocol"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["error", b"error", "port", b"port", "protocol", b"protocol"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["error", b"error", "port", b"port", "protocol", b"protocol"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["error", b"error", "port", b"port", "protocol", b"protocol"]) -> None: ...
 
 global___PortStatus = PortStatus
 
-@typing_extensions.final
+@typing.final
 class PortworxVolumeSource(google.protobuf.message.Message):
     """PortworxVolumeSource represents a Portworx volume resource."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     VOLUMEID_FIELD_NUMBER: builtins.int
     FSTYPE_FIELD_NUMBER: builtins.int
@@ -7279,20 +7554,20 @@
     def __init__(
         self,
         *,
         volumeID: builtins.str | None = ...,
         fsType: builtins.str | None = ...,
         readOnly: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "readOnly", b"readOnly", "volumeID", b"volumeID"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "readOnly", b"readOnly", "volumeID", b"volumeID"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fsType", b"fsType", "readOnly", b"readOnly", "volumeID", b"volumeID"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["fsType", b"fsType", "readOnly", b"readOnly", "volumeID", b"volumeID"]) -> None: ...
 
 global___PortworxVolumeSource = PortworxVolumeSource
 
-@typing_extensions.final
+@typing.final
 class Preconditions(google.protobuf.message.Message):
     """Preconditions must be fulfilled before an operation (update, delete, etc.) is carried out.
     +k8s:openapi-gen=false
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -7302,102 +7577,102 @@
     +optional
     """
     def __init__(
         self,
         *,
         uid: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["uid", b"uid"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["uid", b"uid"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["uid", b"uid"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["uid", b"uid"]) -> None: ...
 
 global___Preconditions = Preconditions
 
-@typing_extensions.final
+@typing.final
 class PreferAvoidPodsEntry(google.protobuf.message.Message):
     """Describes a class of pods that should avoid this node."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PODSIGNATURE_FIELD_NUMBER: builtins.int
     EVICTIONTIME_FIELD_NUMBER: builtins.int
     REASON_FIELD_NUMBER: builtins.int
     MESSAGE_FIELD_NUMBER: builtins.int
-    @property
-    def podSignature(self) -> global___PodSignature:
-        """The class of pods."""
-    @property
-    def evictionTime(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
-        """Time at which this entry was added to the list.
-        +optional
-        """
     reason: builtins.str
     """(brief) reason why this entry was added to the list.
     +optional
     """
     message: builtins.str
     """Human readable message indicating why this entry was added to the list.
     +optional
     """
+    @property
+    def podSignature(self) -> global___PodSignature:
+        """The class of pods."""
+
+    @property
+    def evictionTime(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
+        """Time at which this entry was added to the list.
+        +optional
+        """
+
     def __init__(
         self,
         *,
         podSignature: global___PodSignature | None = ...,
         evictionTime: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time | None = ...,
         reason: builtins.str | None = ...,
         message: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["evictionTime", b"evictionTime", "message", b"message", "podSignature", b"podSignature", "reason", b"reason"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["evictionTime", b"evictionTime", "message", b"message", "podSignature", b"podSignature", "reason", b"reason"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["evictionTime", b"evictionTime", "message", b"message", "podSignature", b"podSignature", "reason", b"reason"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["evictionTime", b"evictionTime", "message", b"message", "podSignature", b"podSignature", "reason", b"reason"]) -> None: ...
 
 global___PreferAvoidPodsEntry = PreferAvoidPodsEntry
 
-@typing_extensions.final
+@typing.final
 class PreferredSchedulingTerm(google.protobuf.message.Message):
     """An empty preferred scheduling term matches all objects with implicit weight 0
     (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     WEIGHT_FIELD_NUMBER: builtins.int
     PREFERENCE_FIELD_NUMBER: builtins.int
     weight: builtins.int
     """Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100."""
     @property
     def preference(self) -> global___NodeSelectorTerm:
         """A node selector term, associated with the corresponding weight."""
+
     def __init__(
         self,
         *,
         weight: builtins.int | None = ...,
         preference: global___NodeSelectorTerm | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["preference", b"preference", "weight", b"weight"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["preference", b"preference", "weight", b"weight"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["preference", b"preference", "weight", b"weight"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["preference", b"preference", "weight", b"weight"]) -> None: ...
 
 global___PreferredSchedulingTerm = PreferredSchedulingTerm
 
-@typing_extensions.final
+@typing.final
 class Probe(google.protobuf.message.Message):
     """Probe describes a health check to be performed against a container to determine whether it is
     alive or ready to receive traffic.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     HANDLER_FIELD_NUMBER: builtins.int
     INITIALDELAYSECONDS_FIELD_NUMBER: builtins.int
     TIMEOUTSECONDS_FIELD_NUMBER: builtins.int
     PERIODSECONDS_FIELD_NUMBER: builtins.int
     SUCCESSTHRESHOLD_FIELD_NUMBER: builtins.int
     FAILURETHRESHOLD_FIELD_NUMBER: builtins.int
     TERMINATIONGRACEPERIODSECONDS_FIELD_NUMBER: builtins.int
-    @property
-    def handler(self) -> global___Handler:
-        """The action taken to determine the health of a container"""
     initialDelaySeconds: builtins.int
     """Number of seconds after the container has started before liveness probes are initiated.
     More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
     +optional
     """
     timeoutSeconds: builtins.int
     """Number of seconds after which the probe times out.
@@ -7429,64 +7704,69 @@
     value overrides the value provided by the pod spec.
     Value must be non-negative integer. The value zero indicates stop immediately via
     the kill signal (no opportunity to shut down).
     This is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.
     Minimum value is 1. spec.terminationGracePeriodSeconds is used if unset.
     +optional
     """
+    @property
+    def handler(self) -> global___Handler:
+        """The action taken to determine the health of a container"""
+
     def __init__(
         self,
         *,
         handler: global___Handler | None = ...,
         initialDelaySeconds: builtins.int | None = ...,
         timeoutSeconds: builtins.int | None = ...,
         periodSeconds: builtins.int | None = ...,
         successThreshold: builtins.int | None = ...,
         failureThreshold: builtins.int | None = ...,
         terminationGracePeriodSeconds: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["failureThreshold", b"failureThreshold", "handler", b"handler", "initialDelaySeconds", b"initialDelaySeconds", "periodSeconds", b"periodSeconds", "successThreshold", b"successThreshold", "terminationGracePeriodSeconds", b"terminationGracePeriodSeconds", "timeoutSeconds", b"timeoutSeconds"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["failureThreshold", b"failureThreshold", "handler", b"handler", "initialDelaySeconds", b"initialDelaySeconds", "periodSeconds", b"periodSeconds", "successThreshold", b"successThreshold", "terminationGracePeriodSeconds", b"terminationGracePeriodSeconds", "timeoutSeconds", b"timeoutSeconds"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["failureThreshold", b"failureThreshold", "handler", b"handler", "initialDelaySeconds", b"initialDelaySeconds", "periodSeconds", b"periodSeconds", "successThreshold", b"successThreshold", "terminationGracePeriodSeconds", b"terminationGracePeriodSeconds", "timeoutSeconds", b"timeoutSeconds"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["failureThreshold", b"failureThreshold", "handler", b"handler", "initialDelaySeconds", b"initialDelaySeconds", "periodSeconds", b"periodSeconds", "successThreshold", b"successThreshold", "terminationGracePeriodSeconds", b"terminationGracePeriodSeconds", "timeoutSeconds", b"timeoutSeconds"]) -> None: ...
 
 global___Probe = Probe
 
-@typing_extensions.final
+@typing.final
 class ProjectedVolumeSource(google.protobuf.message.Message):
     """Represents a projected volume source"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SOURCES_FIELD_NUMBER: builtins.int
     DEFAULTMODE_FIELD_NUMBER: builtins.int
-    @property
-    def sources(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___VolumeProjection]:
-        """list of volume projections
-        +optional
-        """
     defaultMode: builtins.int
     """Mode bits used to set permissions on created files by default.
     Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511.
     YAML accepts both octal and decimal values, JSON requires decimal values for mode bits.
     Directories within the path are not affected by this setting.
     This might be in conflict with other options that affect the file
     mode, like fsGroup, and the result can be other mode bits set.
     +optional
     """
+    @property
+    def sources(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___VolumeProjection]:
+        """list of volume projections
+        +optional
+        """
+
     def __init__(
         self,
         *,
         sources: collections.abc.Iterable[global___VolumeProjection] | None = ...,
         defaultMode: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["defaultMode", b"defaultMode"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["defaultMode", b"defaultMode", "sources", b"sources"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["defaultMode", b"defaultMode"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["defaultMode", b"defaultMode", "sources", b"sources"]) -> None: ...
 
 global___ProjectedVolumeSource = ProjectedVolumeSource
 
-@typing_extensions.final
+@typing.final
 class QuobyteVolumeSource(google.protobuf.message.Message):
     """Represents a Quobyte mount that lasts the lifetime of a pod.
     Quobyte volumes do not support ownership management or SELinux relabeling.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -7529,20 +7809,20 @@
         registry: builtins.str | None = ...,
         volume: builtins.str | None = ...,
         readOnly: builtins.bool | None = ...,
         user: builtins.str | None = ...,
         group: builtins.str | None = ...,
         tenant: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["group", b"group", "readOnly", b"readOnly", "registry", b"registry", "tenant", b"tenant", "user", b"user", "volume", b"volume"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["group", b"group", "readOnly", b"readOnly", "registry", b"registry", "tenant", b"tenant", "user", b"user", "volume", b"volume"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["group", b"group", "readOnly", b"readOnly", "registry", b"registry", "tenant", b"tenant", "user", b"user", "volume", b"volume"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["group", b"group", "readOnly", b"readOnly", "registry", b"registry", "tenant", b"tenant", "user", b"user", "volume", b"volume"]) -> None: ...
 
 global___QuobyteVolumeSource = QuobyteVolumeSource
 
-@typing_extensions.final
+@typing.final
 class RBDPersistentVolumeSource(google.protobuf.message.Message):
     """Represents a Rados Block Device mount that lasts the lifetime of a pod.
     RBD volumes support ownership management and SELinux relabeling.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -7550,19 +7830,14 @@
     IMAGE_FIELD_NUMBER: builtins.int
     FSTYPE_FIELD_NUMBER: builtins.int
     POOL_FIELD_NUMBER: builtins.int
     USER_FIELD_NUMBER: builtins.int
     KEYRING_FIELD_NUMBER: builtins.int
     SECRETREF_FIELD_NUMBER: builtins.int
     READONLY_FIELD_NUMBER: builtins.int
-    @property
-    def monitors(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
-        """A collection of Ceph monitors.
-        More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
-        """
     image: builtins.str
     """The rados image name.
     More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
     """
     fsType: builtins.str
     """Filesystem type of the volume that you want to mount.
     Tip: Ensure that the filesystem type is supported by the host operating system.
@@ -7585,46 +7860,53 @@
     """
     keyring: builtins.str
     """Keyring is the path to key ring for RBDUser.
     Default is /etc/ceph/keyring.
     More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
     +optional
     """
+    readOnly: builtins.bool
+    """ReadOnly here will force the ReadOnly setting in VolumeMounts.
+    Defaults to false.
+    More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
+    +optional
+    """
+    @property
+    def monitors(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
+        """A collection of Ceph monitors.
+        More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
+        """
+
     @property
     def secretRef(self) -> global___SecretReference:
         """SecretRef is name of the authentication secret for RBDUser. If provided
         overrides keyring.
         Default is nil.
         More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
         +optional
         """
-    readOnly: builtins.bool
-    """ReadOnly here will force the ReadOnly setting in VolumeMounts.
-    Defaults to false.
-    More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
-    +optional
-    """
+
     def __init__(
         self,
         *,
         monitors: collections.abc.Iterable[builtins.str] | None = ...,
         image: builtins.str | None = ...,
         fsType: builtins.str | None = ...,
         pool: builtins.str | None = ...,
         user: builtins.str | None = ...,
         keyring: builtins.str | None = ...,
         secretRef: global___SecretReference | None = ...,
         readOnly: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "image", b"image", "keyring", b"keyring", "pool", b"pool", "readOnly", b"readOnly", "secretRef", b"secretRef", "user", b"user"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "image", b"image", "keyring", b"keyring", "monitors", b"monitors", "pool", b"pool", "readOnly", b"readOnly", "secretRef", b"secretRef", "user", b"user"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fsType", b"fsType", "image", b"image", "keyring", b"keyring", "pool", b"pool", "readOnly", b"readOnly", "secretRef", b"secretRef", "user", b"user"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["fsType", b"fsType", "image", b"image", "keyring", b"keyring", "monitors", b"monitors", "pool", b"pool", "readOnly", b"readOnly", "secretRef", b"secretRef", "user", b"user"]) -> None: ...
 
 global___RBDPersistentVolumeSource = RBDPersistentVolumeSource
 
-@typing_extensions.final
+@typing.final
 class RBDVolumeSource(google.protobuf.message.Message):
     """Represents a Rados Block Device mount that lasts the lifetime of a pod.
     RBD volumes support ownership management and SELinux relabeling.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -7632,19 +7914,14 @@
     IMAGE_FIELD_NUMBER: builtins.int
     FSTYPE_FIELD_NUMBER: builtins.int
     POOL_FIELD_NUMBER: builtins.int
     USER_FIELD_NUMBER: builtins.int
     KEYRING_FIELD_NUMBER: builtins.int
     SECRETREF_FIELD_NUMBER: builtins.int
     READONLY_FIELD_NUMBER: builtins.int
-    @property
-    def monitors(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
-        """A collection of Ceph monitors.
-        More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
-        """
     image: builtins.str
     """The rados image name.
     More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
     """
     fsType: builtins.str
     """Filesystem type of the volume that you want to mount.
     Tip: Ensure that the filesystem type is supported by the host operating system.
@@ -7667,77 +7944,85 @@
     """
     keyring: builtins.str
     """Keyring is the path to key ring for RBDUser.
     Default is /etc/ceph/keyring.
     More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
     +optional
     """
+    readOnly: builtins.bool
+    """ReadOnly here will force the ReadOnly setting in VolumeMounts.
+    Defaults to false.
+    More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
+    +optional
+    """
+    @property
+    def monitors(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
+        """A collection of Ceph monitors.
+        More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
+        """
+
     @property
     def secretRef(self) -> global___LocalObjectReference:
         """SecretRef is name of the authentication secret for RBDUser. If provided
         overrides keyring.
         Default is nil.
         More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
         +optional
         """
-    readOnly: builtins.bool
-    """ReadOnly here will force the ReadOnly setting in VolumeMounts.
-    Defaults to false.
-    More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
-    +optional
-    """
+
     def __init__(
         self,
         *,
         monitors: collections.abc.Iterable[builtins.str] | None = ...,
         image: builtins.str | None = ...,
         fsType: builtins.str | None = ...,
         pool: builtins.str | None = ...,
         user: builtins.str | None = ...,
         keyring: builtins.str | None = ...,
         secretRef: global___LocalObjectReference | None = ...,
         readOnly: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "image", b"image", "keyring", b"keyring", "pool", b"pool", "readOnly", b"readOnly", "secretRef", b"secretRef", "user", b"user"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "image", b"image", "keyring", b"keyring", "monitors", b"monitors", "pool", b"pool", "readOnly", b"readOnly", "secretRef", b"secretRef", "user", b"user"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fsType", b"fsType", "image", b"image", "keyring", b"keyring", "pool", b"pool", "readOnly", b"readOnly", "secretRef", b"secretRef", "user", b"user"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["fsType", b"fsType", "image", b"image", "keyring", b"keyring", "monitors", b"monitors", "pool", b"pool", "readOnly", b"readOnly", "secretRef", b"secretRef", "user", b"user"]) -> None: ...
 
 global___RBDVolumeSource = RBDVolumeSource
 
-@typing_extensions.final
+@typing.final
 class RangeAllocation(google.protobuf.message.Message):
     """RangeAllocation is not a public type."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     RANGE_FIELD_NUMBER: builtins.int
     DATA_FIELD_NUMBER: builtins.int
+    range: builtins.str
+    """Range is string that identifies the range represented by 'data'."""
+    data: builtins.bytes
+    """Data is a bit array containing all allocated addresses in the previous segment."""
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
-    range: builtins.str
-    """Range is string that identifies the range represented by 'data'."""
-    data: builtins.bytes
-    """Data is a bit array containing all allocated addresses in the previous segment."""
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         range: builtins.str | None = ...,
         data: builtins.bytes | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["data", b"data", "metadata", b"metadata", "range", b"range"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["data", b"data", "metadata", b"metadata", "range", b"range"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["data", b"data", "metadata", b"metadata", "range", b"range"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["data", b"data", "metadata", b"metadata", "range", b"range"]) -> None: ...
 
 global___RangeAllocation = RangeAllocation
 
-@typing_extensions.final
+@typing.final
 class ReplicationController(google.protobuf.message.Message):
     """ReplicationController represents the configuration of a replication controller."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     SPEC_FIELD_NUMBER: builtins.int
@@ -7745,135 +8030,141 @@
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """If the Labels of a ReplicationController are empty, they are defaulted to
         be the same as the Pod(s) that the replication controller manages.
         Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def spec(self) -> global___ReplicationControllerSpec:
         """Spec defines the specification of the desired behavior of the replication controller.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         +optional
         """
+
     @property
     def status(self) -> global___ReplicationControllerStatus:
         """Status is the most recently observed status of the replication controller.
         This data may be out of date by some window of time.
         Populated by the system.
         Read-only.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         +optional
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         spec: global___ReplicationControllerSpec | None = ...,
         status: global___ReplicationControllerStatus | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> None: ...
 
 global___ReplicationController = ReplicationController
 
-@typing_extensions.final
+@typing.final
 class ReplicationControllerCondition(google.protobuf.message.Message):
     """ReplicationControllerCondition describes the state of a replication controller at a certain point."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     TYPE_FIELD_NUMBER: builtins.int
     STATUS_FIELD_NUMBER: builtins.int
     LASTTRANSITIONTIME_FIELD_NUMBER: builtins.int
     REASON_FIELD_NUMBER: builtins.int
     MESSAGE_FIELD_NUMBER: builtins.int
     type: builtins.str
     """Type of replication controller condition."""
     status: builtins.str
     """Status of the condition, one of True, False, Unknown."""
-    @property
-    def lastTransitionTime(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
-        """The last time the condition transitioned from one status to another.
-        +optional
-        """
     reason: builtins.str
     """The reason for the condition's last transition.
     +optional
     """
     message: builtins.str
     """A human readable message indicating details about the transition.
     +optional
     """
+    @property
+    def lastTransitionTime(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
+        """The last time the condition transitioned from one status to another.
+        +optional
+        """
+
     def __init__(
         self,
         *,
         type: builtins.str | None = ...,
         status: builtins.str | None = ...,
         lastTransitionTime: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time | None = ...,
         reason: builtins.str | None = ...,
         message: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["lastTransitionTime", b"lastTransitionTime", "message", b"message", "reason", b"reason", "status", b"status", "type", b"type"]) -> None: ...
 
 global___ReplicationControllerCondition = ReplicationControllerCondition
 
-@typing_extensions.final
+@typing.final
 class ReplicationControllerList(google.protobuf.message.Message):
     """ReplicationControllerList is a collection of replication controllers."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """Standard list metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ReplicationController]:
         """List of replication controllers.
         More info: https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[global___ReplicationController] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___ReplicationControllerList = ReplicationControllerList
 
-@typing_extensions.final
+@typing.final
 class ReplicationControllerSpec(google.protobuf.message.Message):
     """ReplicationControllerSpec is the specification of a replication controller."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class SelectorEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: builtins.str | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     REPLICAS_FIELD_NUMBER: builtins.int
     MINREADYSECONDS_FIELD_NUMBER: builtins.int
     SELECTOR_FIELD_NUMBER: builtins.int
     TEMPLATE_FIELD_NUMBER: builtins.int
     replicas: builtins.int
     """Replicas is the number of desired replicas.
@@ -7894,35 +8185,37 @@
         If Selector is empty, it is defaulted to the labels present on the Pod template.
         Label keys and values that must match in order to be controlled by this replication
         controller, if empty defaulted to labels on Pod template.
         More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors
         +optional
         +mapType=atomic
         """
+
     @property
     def template(self) -> global___PodTemplateSpec:
         """Template is the object that describes the pod that will be created if
         insufficient replicas are detected. This takes precedence over a TemplateRef.
         More info: https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller#pod-template
         +optional
         """
+
     def __init__(
         self,
         *,
         replicas: builtins.int | None = ...,
         minReadySeconds: builtins.int | None = ...,
         selector: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
         template: global___PodTemplateSpec | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["minReadySeconds", b"minReadySeconds", "replicas", b"replicas", "template", b"template"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["minReadySeconds", b"minReadySeconds", "replicas", b"replicas", "selector", b"selector", "template", b"template"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["minReadySeconds", b"minReadySeconds", "replicas", b"replicas", "template", b"template"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["minReadySeconds", b"minReadySeconds", "replicas", b"replicas", "selector", b"selector", "template", b"template"]) -> None: ...
 
 global___ReplicationControllerSpec = ReplicationControllerSpec
 
-@typing_extensions.final
+@typing.final
 class ReplicationControllerStatus(google.protobuf.message.Message):
     """ReplicationControllerStatus represents the current status of a replication
     controller.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -7955,30 +8248,31 @@
     @property
     def conditions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ReplicationControllerCondition]:
         """Represents the latest available observations of a replication controller's current state.
         +optional
         +patchMergeKey=type
         +patchStrategy=merge
         """
+
     def __init__(
         self,
         *,
         replicas: builtins.int | None = ...,
         fullyLabeledReplicas: builtins.int | None = ...,
         readyReplicas: builtins.int | None = ...,
         availableReplicas: builtins.int | None = ...,
         observedGeneration: builtins.int | None = ...,
         conditions: collections.abc.Iterable[global___ReplicationControllerCondition] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["availableReplicas", b"availableReplicas", "fullyLabeledReplicas", b"fullyLabeledReplicas", "observedGeneration", b"observedGeneration", "readyReplicas", b"readyReplicas", "replicas", b"replicas"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["availableReplicas", b"availableReplicas", "conditions", b"conditions", "fullyLabeledReplicas", b"fullyLabeledReplicas", "observedGeneration", b"observedGeneration", "readyReplicas", b"readyReplicas", "replicas", b"replicas"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["availableReplicas", b"availableReplicas", "fullyLabeledReplicas", b"fullyLabeledReplicas", "observedGeneration", b"observedGeneration", "readyReplicas", b"readyReplicas", "replicas", b"replicas"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["availableReplicas", b"availableReplicas", "conditions", b"conditions", "fullyLabeledReplicas", b"fullyLabeledReplicas", "observedGeneration", b"observedGeneration", "readyReplicas", b"readyReplicas", "replicas", b"replicas"]) -> None: ...
 
 global___ReplicationControllerStatus = ReplicationControllerStatus
 
-@typing_extensions.final
+@typing.final
 class ResourceFieldSelector(google.protobuf.message.Message):
     """ResourceFieldSelector represents container resources (cpu, memory) and their output format
     +structType=atomic
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -7992,287 +8286,300 @@
     resource: builtins.str
     """Required: resource to select"""
     @property
     def divisor(self) -> armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity:
         """Specifies the output format of the exposed resources, defaults to "1"
         +optional
         """
+
     def __init__(
         self,
         *,
         containerName: builtins.str | None = ...,
         resource: builtins.str | None = ...,
         divisor: armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["containerName", b"containerName", "divisor", b"divisor", "resource", b"resource"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["containerName", b"containerName", "divisor", b"divisor", "resource", b"resource"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["containerName", b"containerName", "divisor", b"divisor", "resource", b"resource"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["containerName", b"containerName", "divisor", b"divisor", "resource", b"resource"]) -> None: ...
 
 global___ResourceFieldSelector = ResourceFieldSelector
 
-@typing_extensions.final
+@typing.final
 class ResourceQuota(google.protobuf.message.Message):
     """ResourceQuota sets aggregate quota restrictions enforced per namespace"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     SPEC_FIELD_NUMBER: builtins.int
     STATUS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def spec(self) -> global___ResourceQuotaSpec:
         """Spec defines the desired quota.
         https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         +optional
         """
+
     @property
     def status(self) -> global___ResourceQuotaStatus:
         """Status defines the actual enforced quota and its current usage.
         https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         +optional
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         spec: global___ResourceQuotaSpec | None = ...,
         status: global___ResourceQuotaStatus | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> None: ...
 
 global___ResourceQuota = ResourceQuota
 
-@typing_extensions.final
+@typing.final
 class ResourceQuotaList(google.protobuf.message.Message):
     """ResourceQuotaList is a list of ResourceQuota items."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """Standard list metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ResourceQuota]:
         """Items is a list of ResourceQuota objects.
         More info: https://kubernetes.io/docs/concepts/policy/resource-quotas/
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[global___ResourceQuota] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___ResourceQuotaList = ResourceQuotaList
 
-@typing_extensions.final
+@typing.final
 class ResourceQuotaSpec(google.protobuf.message.Message):
     """ResourceQuotaSpec defines the desired hard limits to enforce for Quota."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class HardEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity: ...
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     HARD_FIELD_NUMBER: builtins.int
     SCOPES_FIELD_NUMBER: builtins.int
     SCOPESELECTOR_FIELD_NUMBER: builtins.int
     @property
     def hard(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity]:
         """hard is the set of desired hard limits for each named resource.
         More info: https://kubernetes.io/docs/concepts/policy/resource-quotas/
         +optional
         """
+
     @property
     def scopes(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """A collection of filters that must match each object tracked by a quota.
         If not specified, the quota matches all objects.
         +optional
         """
+
     @property
     def scopeSelector(self) -> global___ScopeSelector:
         """scopeSelector is also a collection of filters like scopes that must match each object tracked by a quota
         but expressed using ScopeSelectorOperator in combination with possible values.
         For a resource to match, both scopes AND scopeSelector (if specified in spec), must be matched.
         +optional
         """
+
     def __init__(
         self,
         *,
         hard: collections.abc.Mapping[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity] | None = ...,
         scopes: collections.abc.Iterable[builtins.str] | None = ...,
         scopeSelector: global___ScopeSelector | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["scopeSelector", b"scopeSelector"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["hard", b"hard", "scopeSelector", b"scopeSelector", "scopes", b"scopes"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["scopeSelector", b"scopeSelector"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["hard", b"hard", "scopeSelector", b"scopeSelector", "scopes", b"scopes"]) -> None: ...
 
 global___ResourceQuotaSpec = ResourceQuotaSpec
 
-@typing_extensions.final
+@typing.final
 class ResourceQuotaStatus(google.protobuf.message.Message):
     """ResourceQuotaStatus defines the enforced hard limits and observed use."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class HardEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity: ...
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
-    @typing_extensions.final
+    @typing.final
     class UsedEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity: ...
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     HARD_FIELD_NUMBER: builtins.int
     USED_FIELD_NUMBER: builtins.int
     @property
     def hard(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity]:
         """Hard is the set of enforced hard limits for each named resource.
         More info: https://kubernetes.io/docs/concepts/policy/resource-quotas/
         +optional
         """
+
     @property
     def used(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity]:
         """Used is the current observed total usage of the resource in the namespace.
         +optional
         """
+
     def __init__(
         self,
         *,
         hard: collections.abc.Mapping[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity] | None = ...,
         used: collections.abc.Mapping[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["hard", b"hard", "used", b"used"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["hard", b"hard", "used", b"used"]) -> None: ...
 
 global___ResourceQuotaStatus = ResourceQuotaStatus
 
-@typing_extensions.final
+@typing.final
 class ResourceRequirements(google.protobuf.message.Message):
     """ResourceRequirements describes the compute resource requirements."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class LimitsEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity: ...
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
-    @typing_extensions.final
+    @typing.final
     class RequestsEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         @property
         def value(self) -> armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity: ...
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     LIMITS_FIELD_NUMBER: builtins.int
     REQUESTS_FIELD_NUMBER: builtins.int
     @property
     def limits(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity]:
         """Limits describes the maximum amount of compute resources allowed.
         More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
         +optional
         """
+
     @property
     def requests(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity]:
         """Requests describes the minimum amount of compute resources required.
         If Requests is omitted for a container, it defaults to Limits if that is explicitly specified,
         otherwise to an implementation-defined value.
         More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
         +optional
         """
+
     def __init__(
         self,
         *,
         limits: collections.abc.Mapping[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity] | None = ...,
         requests: collections.abc.Mapping[builtins.str, armada_client.k8s.io.apimachinery.pkg.api.resource.generated_pb2.Quantity] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["limits", b"limits", "requests", b"requests"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["limits", b"limits", "requests", b"requests"]) -> None: ...
 
 global___ResourceRequirements = ResourceRequirements
 
-@typing_extensions.final
+@typing.final
 class SELinuxOptions(google.protobuf.message.Message):
     """SELinuxOptions are the labels to be applied to the container"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     USER_FIELD_NUMBER: builtins.int
     ROLE_FIELD_NUMBER: builtins.int
@@ -8298,20 +8605,20 @@
         self,
         *,
         user: builtins.str | None = ...,
         role: builtins.str | None = ...,
         type: builtins.str | None = ...,
         level: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["level", b"level", "role", b"role", "type", b"type", "user", b"user"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["level", b"level", "role", b"role", "type", b"type", "user", b"user"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["level", b"level", "role", b"role", "type", b"type", "user", b"user"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["level", b"level", "role", b"role", "type", b"type", "user", b"user"]) -> None: ...
 
 global___SELinuxOptions = SELinuxOptions
 
-@typing_extensions.final
+@typing.final
 class ScaleIOPersistentVolumeSource(google.protobuf.message.Message):
     """ScaleIOPersistentVolumeSource represents a persistent ScaleIO volume"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     GATEWAY_FIELD_NUMBER: builtins.int
     SYSTEM_FIELD_NUMBER: builtins.int
@@ -8323,19 +8630,14 @@
     VOLUMENAME_FIELD_NUMBER: builtins.int
     FSTYPE_FIELD_NUMBER: builtins.int
     READONLY_FIELD_NUMBER: builtins.int
     gateway: builtins.str
     """The host address of the ScaleIO API Gateway."""
     system: builtins.str
     """The name of the storage system as configured in ScaleIO."""
-    @property
-    def secretRef(self) -> global___SecretReference:
-        """SecretRef references to the secret for ScaleIO user and other
-        sensitive information. If this is not provided, Login operation will fail.
-        """
     sslEnabled: builtins.bool
     """Flag to enable/disable SSL communication with Gateway, default false
     +optional
     """
     protectionDomain: builtins.str
     """The name of the ScaleIO Protection Domain for the configured storage.
     +optional
@@ -8361,34 +8663,40 @@
     +optional
     """
     readOnly: builtins.bool
     """Defaults to false (read/write). ReadOnly here will force
     the ReadOnly setting in VolumeMounts.
     +optional
     """
+    @property
+    def secretRef(self) -> global___SecretReference:
+        """SecretRef references to the secret for ScaleIO user and other
+        sensitive information. If this is not provided, Login operation will fail.
+        """
+
     def __init__(
         self,
         *,
         gateway: builtins.str | None = ...,
         system: builtins.str | None = ...,
         secretRef: global___SecretReference | None = ...,
         sslEnabled: builtins.bool | None = ...,
         protectionDomain: builtins.str | None = ...,
         storagePool: builtins.str | None = ...,
         storageMode: builtins.str | None = ...,
         volumeName: builtins.str | None = ...,
         fsType: builtins.str | None = ...,
         readOnly: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "gateway", b"gateway", "protectionDomain", b"protectionDomain", "readOnly", b"readOnly", "secretRef", b"secretRef", "sslEnabled", b"sslEnabled", "storageMode", b"storageMode", "storagePool", b"storagePool", "system", b"system", "volumeName", b"volumeName"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "gateway", b"gateway", "protectionDomain", b"protectionDomain", "readOnly", b"readOnly", "secretRef", b"secretRef", "sslEnabled", b"sslEnabled", "storageMode", b"storageMode", "storagePool", b"storagePool", "system", b"system", "volumeName", b"volumeName"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fsType", b"fsType", "gateway", b"gateway", "protectionDomain", b"protectionDomain", "readOnly", b"readOnly", "secretRef", b"secretRef", "sslEnabled", b"sslEnabled", "storageMode", b"storageMode", "storagePool", b"storagePool", "system", b"system", "volumeName", b"volumeName"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["fsType", b"fsType", "gateway", b"gateway", "protectionDomain", b"protectionDomain", "readOnly", b"readOnly", "secretRef", b"secretRef", "sslEnabled", b"sslEnabled", "storageMode", b"storageMode", "storagePool", b"storagePool", "system", b"system", "volumeName", b"volumeName"]) -> None: ...
 
 global___ScaleIOPersistentVolumeSource = ScaleIOPersistentVolumeSource
 
-@typing_extensions.final
+@typing.final
 class ScaleIOVolumeSource(google.protobuf.message.Message):
     """ScaleIOVolumeSource represents a persistent ScaleIO volume"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     GATEWAY_FIELD_NUMBER: builtins.int
     SYSTEM_FIELD_NUMBER: builtins.int
@@ -8400,19 +8708,14 @@
     VOLUMENAME_FIELD_NUMBER: builtins.int
     FSTYPE_FIELD_NUMBER: builtins.int
     READONLY_FIELD_NUMBER: builtins.int
     gateway: builtins.str
     """The host address of the ScaleIO API Gateway."""
     system: builtins.str
     """The name of the storage system as configured in ScaleIO."""
-    @property
-    def secretRef(self) -> global___LocalObjectReference:
-        """SecretRef references to the secret for ScaleIO user and other
-        sensitive information. If this is not provided, Login operation will fail.
-        """
     sslEnabled: builtins.bool
     """Flag to enable/disable SSL communication with Gateway, default false
     +optional
     """
     protectionDomain: builtins.str
     """The name of the ScaleIO Protection Domain for the configured storage.
     +optional
@@ -8438,58 +8741,65 @@
     +optional
     """
     readOnly: builtins.bool
     """Defaults to false (read/write). ReadOnly here will force
     the ReadOnly setting in VolumeMounts.
     +optional
     """
+    @property
+    def secretRef(self) -> global___LocalObjectReference:
+        """SecretRef references to the secret for ScaleIO user and other
+        sensitive information. If this is not provided, Login operation will fail.
+        """
+
     def __init__(
         self,
         *,
         gateway: builtins.str | None = ...,
         system: builtins.str | None = ...,
         secretRef: global___LocalObjectReference | None = ...,
         sslEnabled: builtins.bool | None = ...,
         protectionDomain: builtins.str | None = ...,
         storagePool: builtins.str | None = ...,
         storageMode: builtins.str | None = ...,
         volumeName: builtins.str | None = ...,
         fsType: builtins.str | None = ...,
         readOnly: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "gateway", b"gateway", "protectionDomain", b"protectionDomain", "readOnly", b"readOnly", "secretRef", b"secretRef", "sslEnabled", b"sslEnabled", "storageMode", b"storageMode", "storagePool", b"storagePool", "system", b"system", "volumeName", b"volumeName"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "gateway", b"gateway", "protectionDomain", b"protectionDomain", "readOnly", b"readOnly", "secretRef", b"secretRef", "sslEnabled", b"sslEnabled", "storageMode", b"storageMode", "storagePool", b"storagePool", "system", b"system", "volumeName", b"volumeName"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fsType", b"fsType", "gateway", b"gateway", "protectionDomain", b"protectionDomain", "readOnly", b"readOnly", "secretRef", b"secretRef", "sslEnabled", b"sslEnabled", "storageMode", b"storageMode", "storagePool", b"storagePool", "system", b"system", "volumeName", b"volumeName"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["fsType", b"fsType", "gateway", b"gateway", "protectionDomain", b"protectionDomain", "readOnly", b"readOnly", "secretRef", b"secretRef", "sslEnabled", b"sslEnabled", "storageMode", b"storageMode", "storagePool", b"storagePool", "system", b"system", "volumeName", b"volumeName"]) -> None: ...
 
 global___ScaleIOVolumeSource = ScaleIOVolumeSource
 
-@typing_extensions.final
+@typing.final
 class ScopeSelector(google.protobuf.message.Message):
     """A scope selector represents the AND of the selectors represented
     by the scoped-resource selector requirements.
     +structType=atomic
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     MATCHEXPRESSIONS_FIELD_NUMBER: builtins.int
     @property
     def matchExpressions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ScopedResourceSelectorRequirement]:
         """A list of scope selector requirements by scope of the resources.
         +optional
         """
+
     def __init__(
         self,
         *,
         matchExpressions: collections.abc.Iterable[global___ScopedResourceSelectorRequirement] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["matchExpressions", b"matchExpressions"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["matchExpressions", b"matchExpressions"]) -> None: ...
 
 global___ScopeSelector = ScopeSelector
 
-@typing_extensions.final
+@typing.final
 class ScopedResourceSelectorRequirement(google.protobuf.message.Message):
     """A scoped-resource selector requirement is a selector that contains values, a scope name, and an operator
     that relates the scope name and values.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -8506,27 +8816,28 @@
     def values(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """An array of string values. If the operator is In or NotIn,
         the values array must be non-empty. If the operator is Exists or DoesNotExist,
         the values array must be empty.
         This array is replaced during a strategic merge patch.
         +optional
         """
+
     def __init__(
         self,
         *,
         scopeName: builtins.str | None = ...,
         operator: builtins.str | None = ...,
         values: collections.abc.Iterable[builtins.str] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["operator", b"operator", "scopeName", b"scopeName"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["operator", b"operator", "scopeName", b"scopeName", "values", b"values"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["operator", b"operator", "scopeName", b"scopeName"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["operator", b"operator", "scopeName", b"scopeName", "values", b"values"]) -> None: ...
 
 global___ScopedResourceSelectorRequirement = ScopedResourceSelectorRequirement
 
-@typing_extensions.final
+@typing.final
 class SeccompProfile(google.protobuf.message.Message):
     """SeccompProfile defines a pod/container's seccomp profile settings.
     Only one profile source may be set.
     +union
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -8551,252 +8862,260 @@
     """
     def __init__(
         self,
         *,
         type: builtins.str | None = ...,
         localhostProfile: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["localhostProfile", b"localhostProfile", "type", b"type"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["localhostProfile", b"localhostProfile", "type", b"type"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["localhostProfile", b"localhostProfile", "type", b"type"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["localhostProfile", b"localhostProfile", "type", b"type"]) -> None: ...
 
 global___SeccompProfile = SeccompProfile
 
-@typing_extensions.final
+@typing.final
 class Secret(google.protobuf.message.Message):
     """Secret holds secret data of a certain type. The total bytes of the values in
     the Data field must be less than MaxSecretSize bytes.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class DataEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.bytes
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: builtins.bytes | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
-    @typing_extensions.final
+    @typing.final
     class StringDataEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: builtins.str | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     METADATA_FIELD_NUMBER: builtins.int
     IMMUTABLE_FIELD_NUMBER: builtins.int
     DATA_FIELD_NUMBER: builtins.int
     STRINGDATA_FIELD_NUMBER: builtins.int
     TYPE_FIELD_NUMBER: builtins.int
-    @property
-    def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
-        """Standard object's metadata.
-        More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
-        +optional
-        """
     immutable: builtins.bool
     """Immutable, if set to true, ensures that data stored in the Secret cannot
     be updated (only object metadata can be modified).
     If not set to true, the field can be modified at any time.
     Defaulted to nil.
     +optional
     """
+    type: builtins.str
+    """Used to facilitate programmatic handling of secret data.
+    +optional
+    """
+    @property
+    def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
+        """Standard object's metadata.
+        More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
+        +optional
+        """
+
     @property
     def data(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.bytes]:
         """Data contains the secret data. Each key must consist of alphanumeric
         characters, '-', '_' or '.'. The serialized form of the secret data is a
         base64 encoded string, representing the arbitrary (possibly non-string)
         data value here. Described in https://tools.ietf.org/html/rfc4648#section-4
         +optional
         """
+
     @property
     def stringData(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]:
         """stringData allows specifying non-binary secret data in string form.
         It is provided as a write-only input field for convenience.
         All keys and values are merged into the data field on write, overwriting any existing values.
         The stringData field is never output when reading from the API.
         +k8s:conversion-gen=false
         +optional
         """
-    type: builtins.str
-    """Used to facilitate programmatic handling of secret data.
-    +optional
-    """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         immutable: builtins.bool | None = ...,
         data: collections.abc.Mapping[builtins.str, builtins.bytes] | None = ...,
         stringData: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
         type: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["immutable", b"immutable", "metadata", b"metadata", "type", b"type"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["data", b"data", "immutable", b"immutable", "metadata", b"metadata", "stringData", b"stringData", "type", b"type"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["immutable", b"immutable", "metadata", b"metadata", "type", b"type"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["data", b"data", "immutable", b"immutable", "metadata", b"metadata", "stringData", b"stringData", "type", b"type"]) -> None: ...
 
 global___Secret = Secret
 
-@typing_extensions.final
+@typing.final
 class SecretEnvSource(google.protobuf.message.Message):
     """SecretEnvSource selects a Secret to populate the environment
     variables with.
 
     The contents of the target Secret's Data field will represent the
     key-value pairs as environment variables.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     LOCALOBJECTREFERENCE_FIELD_NUMBER: builtins.int
     OPTIONAL_FIELD_NUMBER: builtins.int
-    @property
-    def localObjectReference(self) -> global___LocalObjectReference:
-        """The Secret to select from."""
     optional: builtins.bool
     """Specify whether the Secret must be defined
     +optional
     """
+    @property
+    def localObjectReference(self) -> global___LocalObjectReference:
+        """The Secret to select from."""
+
     def __init__(
         self,
         *,
         localObjectReference: global___LocalObjectReference | None = ...,
         optional: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["localObjectReference", b"localObjectReference", "optional", b"optional"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["localObjectReference", b"localObjectReference", "optional", b"optional"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["localObjectReference", b"localObjectReference", "optional", b"optional"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["localObjectReference", b"localObjectReference", "optional", b"optional"]) -> None: ...
 
 global___SecretEnvSource = SecretEnvSource
 
-@typing_extensions.final
+@typing.final
 class SecretKeySelector(google.protobuf.message.Message):
     """SecretKeySelector selects a key of a Secret.
     +structType=atomic
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     LOCALOBJECTREFERENCE_FIELD_NUMBER: builtins.int
     KEY_FIELD_NUMBER: builtins.int
     OPTIONAL_FIELD_NUMBER: builtins.int
-    @property
-    def localObjectReference(self) -> global___LocalObjectReference:
-        """The name of the secret in the pod's namespace to select from."""
     key: builtins.str
     """The key of the secret to select from.  Must be a valid secret key."""
     optional: builtins.bool
     """Specify whether the Secret or its key must be defined
     +optional
     """
+    @property
+    def localObjectReference(self) -> global___LocalObjectReference:
+        """The name of the secret in the pod's namespace to select from."""
+
     def __init__(
         self,
         *,
         localObjectReference: global___LocalObjectReference | None = ...,
         key: builtins.str | None = ...,
         optional: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["key", b"key", "localObjectReference", b"localObjectReference", "optional", b"optional"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "localObjectReference", b"localObjectReference", "optional", b"optional"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["key", b"key", "localObjectReference", b"localObjectReference", "optional", b"optional"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["key", b"key", "localObjectReference", b"localObjectReference", "optional", b"optional"]) -> None: ...
 
 global___SecretKeySelector = SecretKeySelector
 
-@typing_extensions.final
+@typing.final
 class SecretList(google.protobuf.message.Message):
     """SecretList is a list of Secret."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """Standard list metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Secret]:
         """Items is a list of secret objects.
         More info: https://kubernetes.io/docs/concepts/configuration/secret
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[global___Secret] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___SecretList = SecretList
 
-@typing_extensions.final
+@typing.final
 class SecretProjection(google.protobuf.message.Message):
     """Adapts a secret into a projected volume.
 
     The contents of the target Secret's Data field will be presented in a
     projected volume as files using the keys in the Data field as the file names.
     Note that this is identical to a secret volume source without the default
     mode.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     LOCALOBJECTREFERENCE_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     OPTIONAL_FIELD_NUMBER: builtins.int
+    optional: builtins.bool
+    """Specify whether the Secret or its key must be defined
+    +optional
+    """
     @property
     def localObjectReference(self) -> global___LocalObjectReference: ...
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___KeyToPath]:
         """If unspecified, each key-value pair in the Data field of the referenced
         Secret will be projected into the volume as a file whose name is the
         key and content is the value. If specified, the listed keys will be
         projected into the specified paths, and unlisted keys will not be
         present. If a key is specified which is not present in the Secret,
         the volume setup will error unless it is marked optional. Paths must be
         relative and may not contain the '..' path or start with '..'.
         +optional
         """
-    optional: builtins.bool
-    """Specify whether the Secret or its key must be defined
-    +optional
-    """
+
     def __init__(
         self,
         *,
         localObjectReference: global___LocalObjectReference | None = ...,
         items: collections.abc.Iterable[global___KeyToPath] | None = ...,
         optional: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["localObjectReference", b"localObjectReference", "optional", b"optional"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "localObjectReference", b"localObjectReference", "optional", b"optional"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["localObjectReference", b"localObjectReference", "optional", b"optional"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "localObjectReference", b"localObjectReference", "optional", b"optional"]) -> None: ...
 
 global___SecretProjection = SecretProjection
 
-@typing_extensions.final
+@typing.final
 class SecretReference(google.protobuf.message.Message):
     """SecretReference represents a Secret Reference. It has enough information to retrieve secret
     in any namespace
     +structType=atomic
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -8813,20 +9132,20 @@
     """
     def __init__(
         self,
         *,
         name: builtins.str | None = ...,
         namespace: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["name", b"name", "namespace", b"namespace"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["name", b"name", "namespace", b"namespace"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["name", b"name", "namespace", b"namespace"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["name", b"name", "namespace", b"namespace"]) -> None: ...
 
 global___SecretReference = SecretReference
 
-@typing_extensions.final
+@typing.final
 class SecretVolumeSource(google.protobuf.message.Message):
     """Adapts a Secret into a volume.
 
     The contents of the target Secret's Data field will be presented in a volume
     as files using the keys in the Data field as the file names.
     Secret volumes support ownership management and SELinux relabeling.
     """
@@ -8838,53 +9157,54 @@
     DEFAULTMODE_FIELD_NUMBER: builtins.int
     OPTIONAL_FIELD_NUMBER: builtins.int
     secretName: builtins.str
     """Name of the secret in the pod's namespace to use.
     More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
     +optional
     """
-    @property
-    def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___KeyToPath]:
-        """If unspecified, each key-value pair in the Data field of the referenced
-        Secret will be projected into the volume as a file whose name is the
-        key and content is the value. If specified, the listed keys will be
-        projected into the specified paths, and unlisted keys will not be
-        present. If a key is specified which is not present in the Secret,
-        the volume setup will error unless it is marked optional. Paths must be
-        relative and may not contain the '..' path or start with '..'.
-        +optional
-        """
     defaultMode: builtins.int
     """Optional: mode bits used to set permissions on created files by default.
     Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511.
     YAML accepts both octal and decimal values, JSON requires decimal values
     for mode bits. Defaults to 0644.
     Directories within the path are not affected by this setting.
     This might be in conflict with other options that affect the file
     mode, like fsGroup, and the result can be other mode bits set.
     +optional
     """
     optional: builtins.bool
     """Specify whether the Secret or its keys must be defined
     +optional
     """
+    @property
+    def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___KeyToPath]:
+        """If unspecified, each key-value pair in the Data field of the referenced
+        Secret will be projected into the volume as a file whose name is the
+        key and content is the value. If specified, the listed keys will be
+        projected into the specified paths, and unlisted keys will not be
+        present. If a key is specified which is not present in the Secret,
+        the volume setup will error unless it is marked optional. Paths must be
+        relative and may not contain the '..' path or start with '..'.
+        +optional
+        """
+
     def __init__(
         self,
         *,
         secretName: builtins.str | None = ...,
         items: collections.abc.Iterable[global___KeyToPath] | None = ...,
         defaultMode: builtins.int | None = ...,
         optional: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["defaultMode", b"defaultMode", "optional", b"optional", "secretName", b"secretName"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["defaultMode", b"defaultMode", "items", b"items", "optional", b"optional", "secretName", b"secretName"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["defaultMode", b"defaultMode", "optional", b"optional", "secretName", b"secretName"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["defaultMode", b"defaultMode", "items", b"items", "optional", b"optional", "secretName", b"secretName"]) -> None: ...
 
 global___SecretVolumeSource = SecretVolumeSource
 
-@typing_extensions.final
+@typing.final
 class SecurityContext(google.protobuf.message.Message):
     """SecurityContext holds security configuration that will be applied to a container.
     Some fields are present in both SecurityContext and PodSecurityContext.  When both
     are set, the values in SecurityContext take precedence.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -8896,41 +9216,20 @@
     RUNASUSER_FIELD_NUMBER: builtins.int
     RUNASGROUP_FIELD_NUMBER: builtins.int
     RUNASNONROOT_FIELD_NUMBER: builtins.int
     READONLYROOTFILESYSTEM_FIELD_NUMBER: builtins.int
     ALLOWPRIVILEGEESCALATION_FIELD_NUMBER: builtins.int
     PROCMOUNT_FIELD_NUMBER: builtins.int
     SECCOMPPROFILE_FIELD_NUMBER: builtins.int
-    @property
-    def capabilities(self) -> global___Capabilities:
-        """The capabilities to add/drop when running containers.
-        Defaults to the default set of capabilities granted by the container runtime.
-        +optional
-        """
     privileged: builtins.bool
     """Run container in privileged mode.
     Processes in privileged containers are essentially equivalent to root on the host.
     Defaults to false.
     +optional
     """
-    @property
-    def seLinuxOptions(self) -> global___SELinuxOptions:
-        """The SELinux context to be applied to the container.
-        If unspecified, the container runtime will allocate a random SELinux context for each
-        container.  May also be set in PodSecurityContext.  If set in both SecurityContext and
-        PodSecurityContext, the value specified in SecurityContext takes precedence.
-        +optional
-        """
-    @property
-    def windowsOptions(self) -> global___WindowsSecurityContextOptions:
-        """The Windows specific settings applied to all containers.
-        If unspecified, the options from the PodSecurityContext will be used.
-        If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
-        +optional
-        """
     runAsUser: builtins.int
     """The UID to run the entrypoint of the container process.
     Defaults to user specified in image metadata if unspecified.
     May also be set in PodSecurityContext.  If set in both SecurityContext and
     PodSecurityContext, the value specified in SecurityContext takes precedence.
     +optional
     """
@@ -8968,20 +9267,45 @@
     """procMount denotes the type of proc mount to use for the containers.
     The default is DefaultProcMount which uses the container runtime defaults for
     readonly paths and masked paths.
     This requires the ProcMountType feature flag to be enabled.
     +optional
     """
     @property
+    def capabilities(self) -> global___Capabilities:
+        """The capabilities to add/drop when running containers.
+        Defaults to the default set of capabilities granted by the container runtime.
+        +optional
+        """
+
+    @property
+    def seLinuxOptions(self) -> global___SELinuxOptions:
+        """The SELinux context to be applied to the container.
+        If unspecified, the container runtime will allocate a random SELinux context for each
+        container.  May also be set in PodSecurityContext.  If set in both SecurityContext and
+        PodSecurityContext, the value specified in SecurityContext takes precedence.
+        +optional
+        """
+
+    @property
+    def windowsOptions(self) -> global___WindowsSecurityContextOptions:
+        """The Windows specific settings applied to all containers.
+        If unspecified, the options from the PodSecurityContext will be used.
+        If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
+        +optional
+        """
+
+    @property
     def seccompProfile(self) -> global___SeccompProfile:
         """The seccomp options to use by this container. If seccomp options are
         provided at both the pod & container level, the container options
         override the pod options.
         +optional
         """
+
     def __init__(
         self,
         *,
         capabilities: global___Capabilities | None = ...,
         privileged: builtins.bool | None = ...,
         seLinuxOptions: global___SELinuxOptions | None = ...,
         windowsOptions: global___WindowsSecurityContextOptions | None = ...,
@@ -8989,42 +9313,43 @@
         runAsGroup: builtins.int | None = ...,
         runAsNonRoot: builtins.bool | None = ...,
         readOnlyRootFilesystem: builtins.bool | None = ...,
         allowPrivilegeEscalation: builtins.bool | None = ...,
         procMount: builtins.str | None = ...,
         seccompProfile: global___SeccompProfile | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["allowPrivilegeEscalation", b"allowPrivilegeEscalation", "capabilities", b"capabilities", "privileged", b"privileged", "procMount", b"procMount", "readOnlyRootFilesystem", b"readOnlyRootFilesystem", "runAsGroup", b"runAsGroup", "runAsNonRoot", b"runAsNonRoot", "runAsUser", b"runAsUser", "seLinuxOptions", b"seLinuxOptions", "seccompProfile", b"seccompProfile", "windowsOptions", b"windowsOptions"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["allowPrivilegeEscalation", b"allowPrivilegeEscalation", "capabilities", b"capabilities", "privileged", b"privileged", "procMount", b"procMount", "readOnlyRootFilesystem", b"readOnlyRootFilesystem", "runAsGroup", b"runAsGroup", "runAsNonRoot", b"runAsNonRoot", "runAsUser", b"runAsUser", "seLinuxOptions", b"seLinuxOptions", "seccompProfile", b"seccompProfile", "windowsOptions", b"windowsOptions"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["allowPrivilegeEscalation", b"allowPrivilegeEscalation", "capabilities", b"capabilities", "privileged", b"privileged", "procMount", b"procMount", "readOnlyRootFilesystem", b"readOnlyRootFilesystem", "runAsGroup", b"runAsGroup", "runAsNonRoot", b"runAsNonRoot", "runAsUser", b"runAsUser", "seLinuxOptions", b"seLinuxOptions", "seccompProfile", b"seccompProfile", "windowsOptions", b"windowsOptions"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["allowPrivilegeEscalation", b"allowPrivilegeEscalation", "capabilities", b"capabilities", "privileged", b"privileged", "procMount", b"procMount", "readOnlyRootFilesystem", b"readOnlyRootFilesystem", "runAsGroup", b"runAsGroup", "runAsNonRoot", b"runAsNonRoot", "runAsUser", b"runAsUser", "seLinuxOptions", b"seLinuxOptions", "seccompProfile", b"seccompProfile", "windowsOptions", b"windowsOptions"]) -> None: ...
 
 global___SecurityContext = SecurityContext
 
-@typing_extensions.final
+@typing.final
 class SerializedReference(google.protobuf.message.Message):
     """SerializedReference is a reference to serialized object."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     REFERENCE_FIELD_NUMBER: builtins.int
     @property
     def reference(self) -> global___ObjectReference:
         """The reference to an object in the system.
         +optional
         """
+
     def __init__(
         self,
         *,
         reference: global___ObjectReference | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["reference", b"reference"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["reference", b"reference"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["reference", b"reference"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["reference", b"reference"]) -> None: ...
 
 global___SerializedReference = SerializedReference
 
-@typing_extensions.final
+@typing.final
 class Service(google.protobuf.message.Message):
     """Service is a named abstraction of software service (for example, mysql) consisting of local port
     (for example 3306) that the proxy listens on, and the selector that determines which pods
     will answer requests sent through the proxy.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -9034,125 +9359,133 @@
     STATUS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def spec(self) -> global___ServiceSpec:
         """Spec defines the behavior of a service.
         https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         +optional
         """
+
     @property
     def status(self) -> global___ServiceStatus:
         """Most recently observed status of the service.
         Populated by the system.
         Read-only.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         +optional
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         spec: global___ServiceSpec | None = ...,
         status: global___ServiceStatus | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> None: ...
 
 global___Service = Service
 
-@typing_extensions.final
+@typing.final
 class ServiceAccount(google.protobuf.message.Message):
     """ServiceAccount binds together:
     * a name, understood by users, and perhaps by peripheral systems, for an identity
     * a principal that can be authenticated and authorized
     * a set of secrets
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     SECRETS_FIELD_NUMBER: builtins.int
     IMAGEPULLSECRETS_FIELD_NUMBER: builtins.int
     AUTOMOUNTSERVICEACCOUNTTOKEN_FIELD_NUMBER: builtins.int
+    automountServiceAccountToken: builtins.bool
+    """AutomountServiceAccountToken indicates whether pods running as this service account should have an API token automatically mounted.
+    Can be overridden at the pod level.
+    +optional
+    """
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def secrets(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ObjectReference]:
         """Secrets is the list of secrets allowed to be used by pods running using this ServiceAccount.
         More info: https://kubernetes.io/docs/concepts/configuration/secret
         +optional
         +patchMergeKey=name
         +patchStrategy=merge
         """
+
     @property
     def imagePullSecrets(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___LocalObjectReference]:
         """ImagePullSecrets is a list of references to secrets in the same namespace to use for pulling any images
         in pods that reference this ServiceAccount. ImagePullSecrets are distinct from Secrets because Secrets
         can be mounted in the pod, but ImagePullSecrets are only accessed by the kubelet.
         More info: https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
         +optional
         """
-    automountServiceAccountToken: builtins.bool
-    """AutomountServiceAccountToken indicates whether pods running as this service account should have an API token automatically mounted.
-    Can be overridden at the pod level.
-    +optional
-    """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         secrets: collections.abc.Iterable[global___ObjectReference] | None = ...,
         imagePullSecrets: collections.abc.Iterable[global___LocalObjectReference] | None = ...,
         automountServiceAccountToken: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["automountServiceAccountToken", b"automountServiceAccountToken", "metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["automountServiceAccountToken", b"automountServiceAccountToken", "imagePullSecrets", b"imagePullSecrets", "metadata", b"metadata", "secrets", b"secrets"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["automountServiceAccountToken", b"automountServiceAccountToken", "metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["automountServiceAccountToken", b"automountServiceAccountToken", "imagePullSecrets", b"imagePullSecrets", "metadata", b"metadata", "secrets", b"secrets"]) -> None: ...
 
 global___ServiceAccount = ServiceAccount
 
-@typing_extensions.final
+@typing.final
 class ServiceAccountList(google.protobuf.message.Message):
     """ServiceAccountList is a list of ServiceAccount objects"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """Standard list metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ServiceAccount]:
         """List of ServiceAccounts.
         More info: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[global___ServiceAccount] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___ServiceAccountList = ServiceAccountList
 
-@typing_extensions.final
+@typing.final
 class ServiceAccountTokenProjection(google.protobuf.message.Message):
     """ServiceAccountTokenProjection represents a projected service account token
     volume. This projection can be used to insert a service account token into
     the pods runtime filesystem for use against APIs (Kubernetes API Server or
     otherwise).
     """
 
@@ -9184,48 +9517,50 @@
     def __init__(
         self,
         *,
         audience: builtins.str | None = ...,
         expirationSeconds: builtins.int | None = ...,
         path: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["audience", b"audience", "expirationSeconds", b"expirationSeconds", "path", b"path"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["audience", b"audience", "expirationSeconds", b"expirationSeconds", "path", b"path"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["audience", b"audience", "expirationSeconds", b"expirationSeconds", "path", b"path"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["audience", b"audience", "expirationSeconds", b"expirationSeconds", "path", b"path"]) -> None: ...
 
 global___ServiceAccountTokenProjection = ServiceAccountTokenProjection
 
-@typing_extensions.final
+@typing.final
 class ServiceList(google.protobuf.message.Message):
     """ServiceList holds a list of services."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """Standard list metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Service]:
         """List of services"""
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[global___Service] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___ServiceList = ServiceList
 
-@typing_extensions.final
+@typing.final
 class ServicePort(google.protobuf.message.Message):
     """ServicePort contains information on service's port."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     PROTOCOL_FIELD_NUMBER: builtins.int
@@ -9254,54 +9589,55 @@
     RFC-6335 and http://www.iana.org/assignments/service-names).
     Non-standard protocols should use prefixed names such as
     mycompany.com/my-custom-protocol.
     +optional
     """
     port: builtins.int
     """The port that will be exposed by this service."""
-    @property
-    def targetPort(self) -> armada_client.k8s.io.apimachinery.pkg.util.intstr.generated_pb2.IntOrString:
-        """Number or name of the port to access on the pods targeted by the service.
-        Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
-        If this is a string, it will be looked up as a named port in the
-        target Pod's container ports. If this is not specified, the value
-        of the 'port' field is used (an identity map).
-        This field is ignored for services with clusterIP=None, and should be
-        omitted or set equal to the 'port' field.
-        More info: https://kubernetes.io/docs/concepts/services-networking/service/#defining-a-service
-        +optional
-        """
     nodePort: builtins.int
     """The port on each node on which this service is exposed when type is
     NodePort or LoadBalancer.  Usually assigned by the system. If a value is
     specified, in-range, and not in use it will be used, otherwise the
     operation will fail.  If not specified, a port will be allocated if this
     Service requires one.  If this field is specified when creating a
     Service which does not need it, creation will fail. This field will be
     wiped when updating a Service to no longer need it (e.g. changing type
     from NodePort to ClusterIP).
     More info: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport
     +optional
     """
+    @property
+    def targetPort(self) -> armada_client.k8s.io.apimachinery.pkg.util.intstr.generated_pb2.IntOrString:
+        """Number or name of the port to access on the pods targeted by the service.
+        Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
+        If this is a string, it will be looked up as a named port in the
+        target Pod's container ports. If this is not specified, the value
+        of the 'port' field is used (an identity map).
+        This field is ignored for services with clusterIP=None, and should be
+        omitted or set equal to the 'port' field.
+        More info: https://kubernetes.io/docs/concepts/services-networking/service/#defining-a-service
+        +optional
+        """
+
     def __init__(
         self,
         *,
         name: builtins.str | None = ...,
         protocol: builtins.str | None = ...,
         appProtocol: builtins.str | None = ...,
         port: builtins.int | None = ...,
         targetPort: armada_client.k8s.io.apimachinery.pkg.util.intstr.generated_pb2.IntOrString | None = ...,
         nodePort: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["appProtocol", b"appProtocol", "name", b"name", "nodePort", b"nodePort", "port", b"port", "protocol", b"protocol", "targetPort", b"targetPort"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["appProtocol", b"appProtocol", "name", b"name", "nodePort", b"nodePort", "port", b"port", "protocol", b"protocol", "targetPort", b"targetPort"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["appProtocol", b"appProtocol", "name", b"name", "nodePort", b"nodePort", "port", b"port", "protocol", b"protocol", "targetPort", b"targetPort"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["appProtocol", b"appProtocol", "name", b"name", "nodePort", b"nodePort", "port", b"port", "protocol", b"protocol", "targetPort", b"targetPort"]) -> None: ...
 
 global___ServicePort = ServicePort
 
-@typing_extensions.final
+@typing.final
 class ServiceProxyOptions(google.protobuf.message.Message):
     """ServiceProxyOptions is the query options to a Service's proxy call."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PATH_FIELD_NUMBER: builtins.int
     path: builtins.str
@@ -9313,41 +9649,41 @@
     +optional
     """
     def __init__(
         self,
         *,
         path: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["path", b"path"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["path", b"path"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["path", b"path"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["path", b"path"]) -> None: ...
 
 global___ServiceProxyOptions = ServiceProxyOptions
 
-@typing_extensions.final
+@typing.final
 class ServiceSpec(google.protobuf.message.Message):
     """ServiceSpec describes the attributes that a user creates on a service."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class SelectorEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: builtins.str | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     PORTS_FIELD_NUMBER: builtins.int
     SELECTOR_FIELD_NUMBER: builtins.int
     CLUSTERIP_FIELD_NUMBER: builtins.int
     CLUSTERIPS_FIELD_NUMBER: builtins.int
     TYPE_FIELD_NUMBER: builtins.int
     EXTERNALIPS_FIELD_NUMBER: builtins.int
@@ -9360,35 +9696,14 @@
     PUBLISHNOTREADYADDRESSES_FIELD_NUMBER: builtins.int
     SESSIONAFFINITYCONFIG_FIELD_NUMBER: builtins.int
     IPFAMILIES_FIELD_NUMBER: builtins.int
     IPFAMILYPOLICY_FIELD_NUMBER: builtins.int
     ALLOCATELOADBALANCERNODEPORTS_FIELD_NUMBER: builtins.int
     LOADBALANCERCLASS_FIELD_NUMBER: builtins.int
     INTERNALTRAFFICPOLICY_FIELD_NUMBER: builtins.int
-    @property
-    def ports(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ServicePort]:
-        """The list of ports that are exposed by this service.
-        More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies
-        +patchMergeKey=port
-        +patchStrategy=merge
-        +listType=map
-        +listMapKey=port
-        +listMapKey=protocol
-        """
-    @property
-    def selector(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]:
-        """Route service traffic to pods with label keys and values matching this
-        selector. If empty or not present, the service is assumed to have an
-        external process managing its endpoints, which Kubernetes will not
-        modify. Only applies to types ClusterIP, NodePort, and LoadBalancer.
-        Ignored if type is ExternalName.
-        More info: https://kubernetes.io/docs/concepts/services-networking/service/
-        +optional
-        +mapType=atomic
-        """
     clusterIP: builtins.str
     """clusterIP is the IP address of the service and is usually assigned
     randomly. If an address is specified manually, is in-range (as per
     system configuration), and is not in use, it will be allocated to the
     service; otherwise creation of the service will fail. This field may not
     be changed through updates unless the type field is also being changed
     to ExternalName (which requires this field to be blank) or the type
@@ -9399,45 +9714,14 @@
     connections are preferred and proxying is not required.  Only applies to
     types ClusterIP, NodePort, and LoadBalancer. If this field is specified
     when creating a Service of type ExternalName, creation will fail. This
     field will be wiped when updating a Service to type ExternalName.
     More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies
     +optional
     """
-    @property
-    def clusterIPs(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
-        """ClusterIPs is a list of IP addresses assigned to this service, and are
-        usually assigned randomly.  If an address is specified manually, is
-        in-range (as per system configuration), and is not in use, it will be
-        allocated to the service; otherwise creation of the service will fail.
-        This field may not be changed through updates unless the type field is
-        also being changed to ExternalName (which requires this field to be
-        empty) or the type field is being changed from ExternalName (in which
-        case this field may optionally be specified, as describe above).  Valid
-        values are "None", empty string (""), or a valid IP address.  Setting
-        this to "None" makes a "headless service" (no virtual IP), which is
-        useful when direct endpoint connections are preferred and proxying is
-        not required.  Only applies to types ClusterIP, NodePort, and
-        LoadBalancer. If this field is specified when creating a Service of type
-        ExternalName, creation will fail. This field will be wiped when updating
-        a Service to type ExternalName.  If this field is not specified, it will
-        be initialized from the clusterIP field.  If this field is specified,
-        clients must ensure that clusterIPs[0] and clusterIP have the same
-        value.
-
-        Unless the "IPv6DualStack" feature gate is enabled, this field is
-        limited to one value, which must be the same as the clusterIP field.  If
-        the feature gate is enabled, this field may hold a maximum of two
-        entries (dual-stack IPs, in either order).  These IPs must correspond to
-        the values of the ipFamilies field. Both clusterIPs and ipFamilies are
-        governed by the ipFamilyPolicy field.
-        More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies
-        +listType=atomic
-        +optional
-        """
     type: builtins.str
     """type determines how the Service is exposed. Defaults to ClusterIP. Valid
     options are ExternalName, ClusterIP, NodePort, and LoadBalancer.
     "ClusterIP" allocates a cluster-internal IP address for load-balancing
     to endpoints. Endpoints are determined by the selector or if that is not
     specified, by manual construction of an Endpoints object or
     EndpointSlice objects. If clusterIP is "None", no virtual IP is
@@ -9449,23 +9733,14 @@
     (if supported in the current cloud) which routes to the same endpoints
     as the clusterIP.
     "ExternalName" aliases this service to the specified externalName.
     Several other fields do not apply to ExternalName services.
     More info: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types
     +optional
     """
-    @property
-    def externalIPs(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
-        """externalIPs is a list of IP addresses for which nodes in the cluster
-        will also accept traffic for this service.  These IPs are not managed by
-        Kubernetes.  The user is responsible for ensuring that traffic arrives
-        at a node with this IP.  A common example is external load-balancers
-        that are not part of the Kubernetes system.
-        +optional
-        """
     sessionAffinity: builtins.str
     """Supports "ClientIP" and "None". Used to maintain session affinity.
     Enable client IP based session affinity.
     Must be ClientIP or None.
     Defaults to None.
     More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies
     +optional
@@ -9474,22 +9749,14 @@
     """Only applies to Service Type: LoadBalancer
     LoadBalancer will get created with the IP specified in this field.
     This feature depends on whether the underlying cloud-provider supports specifying
     the loadBalancerIP when a load balancer is created.
     This field will be ignored if the cloud-provider does not support the feature.
     +optional
     """
-    @property
-    def loadBalancerSourceRanges(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
-        """If specified and supported by the platform, this will restrict traffic through the cloud-provider
-        load-balancer will be restricted to the specified client IPs. This field will be ignored if the
-        cloud-provider does not support the feature."
-        More info: https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/
-        +optional
-        """
     externalName: builtins.str
     """externalName is the external reference that discovery mechanisms will
     return as an alias for this service (e.g. a DNS CNAME record). No
     proxying will be involved.  Must be a lowercase RFC-1123 hostname
     (https://tools.ietf.org/html/rfc1123) and requires `type` to be "ExternalName".
     +optional
     """
@@ -9521,41 +9788,14 @@
     propagate SRV DNS records for its Pods for the purpose of peer discovery.
     The Kubernetes controllers that generate Endpoints and EndpointSlice resources for
     Services interpret this to mean that all endpoints are considered "ready" even if the
     Pods themselves are not. Agents which consume only Kubernetes generated endpoints
     through the Endpoints or EndpointSlice resources can safely assume this behavior.
     +optional
     """
-    @property
-    def sessionAffinityConfig(self) -> global___SessionAffinityConfig:
-        """sessionAffinityConfig contains the configurations of session affinity.
-        +optional
-        """
-    @property
-    def ipFamilies(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
-        """IPFamilies is a list of IP families (e.g. IPv4, IPv6) assigned to this
-        service, and is gated by the "IPv6DualStack" feature gate.  This field
-        is usually assigned automatically based on cluster configuration and the
-        ipFamilyPolicy field. If this field is specified manually, the requested
-        family is available in the cluster, and ipFamilyPolicy allows it, it
-        will be used; otherwise creation of the service will fail.  This field
-        is conditionally mutable: it allows for adding or removing a secondary
-        IP family, but it does not allow changing the primary IP family of the
-        Service.  Valid values are "IPv4" and "IPv6".  This field only applies
-        to Services of types ClusterIP, NodePort, and LoadBalancer, and does
-        apply to "headless" services.  This field will be wiped when updating a
-        Service to type ExternalName.
-
-        This field may hold a maximum of two entries (dual-stack families, in
-        either order).  These families must correspond to the values of the
-        clusterIPs field, if specified. Both clusterIPs and ipFamilies are
-        governed by the ipFamilyPolicy field.
-        +listType=atomic
-        +optional
-        """
     ipFamilyPolicy: builtins.str
     """IPFamilyPolicy represents the dual-stack-ness requested or required by
     this Service, and is gated by the "IPv6DualStack" feature gate.  If
     there is no value provided, then this field will be set to SingleStack.
     Services can be "SingleStack" (a single IP family), "PreferDualStack"
     (two IP families on dual-stack configured clusters or a single IP family
     on single-stack clusters), or "RequireDualStack" (two IP families on
@@ -9596,14 +9836,117 @@
     "Cluster" routes internal traffic to a Service to all endpoints.
     "Local" routes traffic to node-local endpoints only, traffic is
     dropped if no node-local endpoints are ready.
     The default value is "Cluster".
     +featureGate=ServiceInternalTrafficPolicy
     +optional
     """
+    @property
+    def ports(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ServicePort]:
+        """The list of ports that are exposed by this service.
+        More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies
+        +patchMergeKey=port
+        +patchStrategy=merge
+        +listType=map
+        +listMapKey=port
+        +listMapKey=protocol
+        """
+
+    @property
+    def selector(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]:
+        """Route service traffic to pods with label keys and values matching this
+        selector. If empty or not present, the service is assumed to have an
+        external process managing its endpoints, which Kubernetes will not
+        modify. Only applies to types ClusterIP, NodePort, and LoadBalancer.
+        Ignored if type is ExternalName.
+        More info: https://kubernetes.io/docs/concepts/services-networking/service/
+        +optional
+        +mapType=atomic
+        """
+
+    @property
+    def clusterIPs(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
+        """ClusterIPs is a list of IP addresses assigned to this service, and are
+        usually assigned randomly.  If an address is specified manually, is
+        in-range (as per system configuration), and is not in use, it will be
+        allocated to the service; otherwise creation of the service will fail.
+        This field may not be changed through updates unless the type field is
+        also being changed to ExternalName (which requires this field to be
+        empty) or the type field is being changed from ExternalName (in which
+        case this field may optionally be specified, as describe above).  Valid
+        values are "None", empty string (""), or a valid IP address.  Setting
+        this to "None" makes a "headless service" (no virtual IP), which is
+        useful when direct endpoint connections are preferred and proxying is
+        not required.  Only applies to types ClusterIP, NodePort, and
+        LoadBalancer. If this field is specified when creating a Service of type
+        ExternalName, creation will fail. This field will be wiped when updating
+        a Service to type ExternalName.  If this field is not specified, it will
+        be initialized from the clusterIP field.  If this field is specified,
+        clients must ensure that clusterIPs[0] and clusterIP have the same
+        value.
+
+        Unless the "IPv6DualStack" feature gate is enabled, this field is
+        limited to one value, which must be the same as the clusterIP field.  If
+        the feature gate is enabled, this field may hold a maximum of two
+        entries (dual-stack IPs, in either order).  These IPs must correspond to
+        the values of the ipFamilies field. Both clusterIPs and ipFamilies are
+        governed by the ipFamilyPolicy field.
+        More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies
+        +listType=atomic
+        +optional
+        """
+
+    @property
+    def externalIPs(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
+        """externalIPs is a list of IP addresses for which nodes in the cluster
+        will also accept traffic for this service.  These IPs are not managed by
+        Kubernetes.  The user is responsible for ensuring that traffic arrives
+        at a node with this IP.  A common example is external load-balancers
+        that are not part of the Kubernetes system.
+        +optional
+        """
+
+    @property
+    def loadBalancerSourceRanges(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
+        """If specified and supported by the platform, this will restrict traffic through the cloud-provider
+        load-balancer will be restricted to the specified client IPs. This field will be ignored if the
+        cloud-provider does not support the feature."
+        More info: https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/
+        +optional
+        """
+
+    @property
+    def sessionAffinityConfig(self) -> global___SessionAffinityConfig:
+        """sessionAffinityConfig contains the configurations of session affinity.
+        +optional
+        """
+
+    @property
+    def ipFamilies(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
+        """IPFamilies is a list of IP families (e.g. IPv4, IPv6) assigned to this
+        service, and is gated by the "IPv6DualStack" feature gate.  This field
+        is usually assigned automatically based on cluster configuration and the
+        ipFamilyPolicy field. If this field is specified manually, the requested
+        family is available in the cluster, and ipFamilyPolicy allows it, it
+        will be used; otherwise creation of the service will fail.  This field
+        is conditionally mutable: it allows for adding or removing a secondary
+        IP family, but it does not allow changing the primary IP family of the
+        Service.  Valid values are "IPv4" and "IPv6".  This field only applies
+        to Services of types ClusterIP, NodePort, and LoadBalancer, and does
+        apply to "headless" services.  This field will be wiped when updating a
+        Service to type ExternalName.
+
+        This field may hold a maximum of two entries (dual-stack families, in
+        either order).  These families must correspond to the values of the
+        clusterIPs field, if specified. Both clusterIPs and ipFamilies are
+        governed by the ipFamilyPolicy field.
+        +listType=atomic
+        +optional
+        """
+
     def __init__(
         self,
         *,
         ports: collections.abc.Iterable[global___ServicePort] | None = ...,
         selector: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
         clusterIP: builtins.str | None = ...,
         clusterIPs: collections.abc.Iterable[builtins.str] | None = ...,
@@ -9619,76 +9962,79 @@
         sessionAffinityConfig: global___SessionAffinityConfig | None = ...,
         ipFamilies: collections.abc.Iterable[builtins.str] | None = ...,
         ipFamilyPolicy: builtins.str | None = ...,
         allocateLoadBalancerNodePorts: builtins.bool | None = ...,
         loadBalancerClass: builtins.str | None = ...,
         internalTrafficPolicy: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["allocateLoadBalancerNodePorts", b"allocateLoadBalancerNodePorts", "clusterIP", b"clusterIP", "externalName", b"externalName", "externalTrafficPolicy", b"externalTrafficPolicy", "healthCheckNodePort", b"healthCheckNodePort", "internalTrafficPolicy", b"internalTrafficPolicy", "ipFamilyPolicy", b"ipFamilyPolicy", "loadBalancerClass", b"loadBalancerClass", "loadBalancerIP", b"loadBalancerIP", "publishNotReadyAddresses", b"publishNotReadyAddresses", "sessionAffinity", b"sessionAffinity", "sessionAffinityConfig", b"sessionAffinityConfig", "type", b"type"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["allocateLoadBalancerNodePorts", b"allocateLoadBalancerNodePorts", "clusterIP", b"clusterIP", "clusterIPs", b"clusterIPs", "externalIPs", b"externalIPs", "externalName", b"externalName", "externalTrafficPolicy", b"externalTrafficPolicy", "healthCheckNodePort", b"healthCheckNodePort", "internalTrafficPolicy", b"internalTrafficPolicy", "ipFamilies", b"ipFamilies", "ipFamilyPolicy", b"ipFamilyPolicy", "loadBalancerClass", b"loadBalancerClass", "loadBalancerIP", b"loadBalancerIP", "loadBalancerSourceRanges", b"loadBalancerSourceRanges", "ports", b"ports", "publishNotReadyAddresses", b"publishNotReadyAddresses", "selector", b"selector", "sessionAffinity", b"sessionAffinity", "sessionAffinityConfig", b"sessionAffinityConfig", "type", b"type"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["allocateLoadBalancerNodePorts", b"allocateLoadBalancerNodePorts", "clusterIP", b"clusterIP", "externalName", b"externalName", "externalTrafficPolicy", b"externalTrafficPolicy", "healthCheckNodePort", b"healthCheckNodePort", "internalTrafficPolicy", b"internalTrafficPolicy", "ipFamilyPolicy", b"ipFamilyPolicy", "loadBalancerClass", b"loadBalancerClass", "loadBalancerIP", b"loadBalancerIP", "publishNotReadyAddresses", b"publishNotReadyAddresses", "sessionAffinity", b"sessionAffinity", "sessionAffinityConfig", b"sessionAffinityConfig", "type", b"type"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["allocateLoadBalancerNodePorts", b"allocateLoadBalancerNodePorts", "clusterIP", b"clusterIP", "clusterIPs", b"clusterIPs", "externalIPs", b"externalIPs", "externalName", b"externalName", "externalTrafficPolicy", b"externalTrafficPolicy", "healthCheckNodePort", b"healthCheckNodePort", "internalTrafficPolicy", b"internalTrafficPolicy", "ipFamilies", b"ipFamilies", "ipFamilyPolicy", b"ipFamilyPolicy", "loadBalancerClass", b"loadBalancerClass", "loadBalancerIP", b"loadBalancerIP", "loadBalancerSourceRanges", b"loadBalancerSourceRanges", "ports", b"ports", "publishNotReadyAddresses", b"publishNotReadyAddresses", "selector", b"selector", "sessionAffinity", b"sessionAffinity", "sessionAffinityConfig", b"sessionAffinityConfig", "type", b"type"]) -> None: ...
 
 global___ServiceSpec = ServiceSpec
 
-@typing_extensions.final
+@typing.final
 class ServiceStatus(google.protobuf.message.Message):
     """ServiceStatus represents the current status of a service."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     LOADBALANCER_FIELD_NUMBER: builtins.int
     CONDITIONS_FIELD_NUMBER: builtins.int
     @property
     def loadBalancer(self) -> global___LoadBalancerStatus:
         """LoadBalancer contains the current status of the load-balancer,
         if one is present.
         +optional
         """
+
     @property
     def conditions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Condition]:
         """Current service state
         +optional
         +patchMergeKey=type
         +patchStrategy=merge
         +listType=map
         +listMapKey=type
         """
+
     def __init__(
         self,
         *,
         loadBalancer: global___LoadBalancerStatus | None = ...,
         conditions: collections.abc.Iterable[armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Condition] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["loadBalancer", b"loadBalancer"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["conditions", b"conditions", "loadBalancer", b"loadBalancer"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["loadBalancer", b"loadBalancer"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["conditions", b"conditions", "loadBalancer", b"loadBalancer"]) -> None: ...
 
 global___ServiceStatus = ServiceStatus
 
-@typing_extensions.final
+@typing.final
 class SessionAffinityConfig(google.protobuf.message.Message):
     """SessionAffinityConfig represents the configurations of session affinity."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     CLIENTIP_FIELD_NUMBER: builtins.int
     @property
     def clientIP(self) -> global___ClientIPConfig:
         """clientIP contains the configurations of Client IP based session affinity.
         +optional
         """
+
     def __init__(
         self,
         *,
         clientIP: global___ClientIPConfig | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["clientIP", b"clientIP"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["clientIP", b"clientIP"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["clientIP", b"clientIP"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["clientIP", b"clientIP"]) -> None: ...
 
 global___SessionAffinityConfig = SessionAffinityConfig
 
-@typing_extensions.final
+@typing.final
 class StorageOSPersistentVolumeSource(google.protobuf.message.Message):
     """Represents a StorageOS persistent volume resource."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     VOLUMENAME_FIELD_NUMBER: builtins.int
     VOLUMENAMESPACE_FIELD_NUMBER: builtins.int
@@ -9721,29 +10067,30 @@
     """
     @property
     def secretRef(self) -> global___ObjectReference:
         """SecretRef specifies the secret to use for obtaining the StorageOS API
         credentials.  If not specified, default values will be attempted.
         +optional
         """
+
     def __init__(
         self,
         *,
         volumeName: builtins.str | None = ...,
         volumeNamespace: builtins.str | None = ...,
         fsType: builtins.str | None = ...,
         readOnly: builtins.bool | None = ...,
         secretRef: global___ObjectReference | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef", "volumeName", b"volumeName", "volumeNamespace", b"volumeNamespace"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef", "volumeName", b"volumeName", "volumeNamespace", b"volumeNamespace"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef", "volumeName", b"volumeName", "volumeNamespace", b"volumeNamespace"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef", "volumeName", b"volumeName", "volumeNamespace", b"volumeNamespace"]) -> None: ...
 
 global___StorageOSPersistentVolumeSource = StorageOSPersistentVolumeSource
 
-@typing_extensions.final
+@typing.final
 class StorageOSVolumeSource(google.protobuf.message.Message):
     """Represents a StorageOS persistent volume resource."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     VOLUMENAME_FIELD_NUMBER: builtins.int
     VOLUMENAMESPACE_FIELD_NUMBER: builtins.int
@@ -9776,29 +10123,30 @@
     """
     @property
     def secretRef(self) -> global___LocalObjectReference:
         """SecretRef specifies the secret to use for obtaining the StorageOS API
         credentials.  If not specified, default values will be attempted.
         +optional
         """
+
     def __init__(
         self,
         *,
         volumeName: builtins.str | None = ...,
         volumeNamespace: builtins.str | None = ...,
         fsType: builtins.str | None = ...,
         readOnly: builtins.bool | None = ...,
         secretRef: global___LocalObjectReference | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef", "volumeName", b"volumeName", "volumeNamespace", b"volumeNamespace"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef", "volumeName", b"volumeName", "volumeNamespace", b"volumeNamespace"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef", "volumeName", b"volumeName", "volumeNamespace", b"volumeNamespace"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["fsType", b"fsType", "readOnly", b"readOnly", "secretRef", b"secretRef", "volumeName", b"volumeName", "volumeNamespace", b"volumeNamespace"]) -> None: ...
 
 global___StorageOSVolumeSource = StorageOSVolumeSource
 
-@typing_extensions.final
+@typing.final
 class Sysctl(google.protobuf.message.Message):
     """Sysctl defines a kernel parameter to be set"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     VALUE_FIELD_NUMBER: builtins.int
@@ -9808,49 +10156,50 @@
     """Value of a property to set"""
     def __init__(
         self,
         *,
         name: builtins.str | None = ...,
         value: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["name", b"name", "value", b"value"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["name", b"name", "value", b"value"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["name", b"name", "value", b"value"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["name", b"name", "value", b"value"]) -> None: ...
 
 global___Sysctl = Sysctl
 
-@typing_extensions.final
+@typing.final
 class TCPSocketAction(google.protobuf.message.Message):
     """TCPSocketAction describes an action based on opening a socket"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PORT_FIELD_NUMBER: builtins.int
     HOST_FIELD_NUMBER: builtins.int
+    host: builtins.str
+    """Optional: Host name to connect to, defaults to the pod IP.
+    +optional
+    """
     @property
     def port(self) -> armada_client.k8s.io.apimachinery.pkg.util.intstr.generated_pb2.IntOrString:
         """Number or name of the port to access on the container.
         Number must be in the range 1 to 65535.
         Name must be an IANA_SVC_NAME.
         """
-    host: builtins.str
-    """Optional: Host name to connect to, defaults to the pod IP.
-    +optional
-    """
+
     def __init__(
         self,
         *,
         port: armada_client.k8s.io.apimachinery.pkg.util.intstr.generated_pb2.IntOrString | None = ...,
         host: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["host", b"host", "port", b"port"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["host", b"host", "port", b"port"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["host", b"host", "port", b"port"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["host", b"host", "port", b"port"]) -> None: ...
 
 global___TCPSocketAction = TCPSocketAction
 
-@typing_extensions.final
+@typing.final
 class Taint(google.protobuf.message.Message):
     """The node this Taint is attached to has the "effect" on
     any pod that does not tolerate the Taint.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -9871,28 +10220,29 @@
     """
     @property
     def timeAdded(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time:
         """TimeAdded represents the time at which the taint was added.
         It is only written for NoExecute taints.
         +optional
         """
+
     def __init__(
         self,
         *,
         key: builtins.str | None = ...,
         value: builtins.str | None = ...,
         effect: builtins.str | None = ...,
         timeAdded: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.Time | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["effect", b"effect", "key", b"key", "timeAdded", b"timeAdded", "value", b"value"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["effect", b"effect", "key", b"key", "timeAdded", b"timeAdded", "value", b"value"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["effect", b"effect", "key", b"key", "timeAdded", b"timeAdded", "value", b"value"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["effect", b"effect", "key", b"key", "timeAdded", b"timeAdded", "value", b"value"]) -> None: ...
 
 global___Taint = Taint
 
-@typing_extensions.final
+@typing.final
 class Toleration(google.protobuf.message.Message):
     """The pod this Toleration is attached to tolerates any taint that matches
     the triple <key,value,effect> using the matching operator <operator>.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -9935,20 +10285,20 @@
         *,
         key: builtins.str | None = ...,
         operator: builtins.str | None = ...,
         value: builtins.str | None = ...,
         effect: builtins.str | None = ...,
         tolerationSeconds: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["effect", b"effect", "key", b"key", "operator", b"operator", "tolerationSeconds", b"tolerationSeconds", "value", b"value"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["effect", b"effect", "key", b"key", "operator", b"operator", "tolerationSeconds", b"tolerationSeconds", "value", b"value"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["effect", b"effect", "key", b"key", "operator", b"operator", "tolerationSeconds", b"tolerationSeconds", "value", b"value"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["effect", b"effect", "key", b"key", "operator", b"operator", "tolerationSeconds", b"tolerationSeconds", "value", b"value"]) -> None: ...
 
 global___Toleration = Toleration
 
-@typing_extensions.final
+@typing.final
 class TopologySelectorLabelRequirement(google.protobuf.message.Message):
     """A topology selector requirement is a selector that matches given label.
     This is an alpha feature and may change in the future.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -9957,26 +10307,27 @@
     key: builtins.str
     """The label key that the selector applies to."""
     @property
     def values(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """An array of string values. One value must match the label to be selected.
         Each entry in Values is ORed.
         """
+
     def __init__(
         self,
         *,
         key: builtins.str | None = ...,
         values: collections.abc.Iterable[builtins.str] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["key", b"key"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "values", b"values"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["key", b"key"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["key", b"key", "values", b"values"]) -> None: ...
 
 global___TopologySelectorLabelRequirement = TopologySelectorLabelRequirement
 
-@typing_extensions.final
+@typing.final
 class TopologySelectorTerm(google.protobuf.message.Message):
     """A topology selector term represents the result of label queries.
     A null or empty topology selector term matches no objects.
     The requirements of them are ANDed.
     It provides a subset of functionality as NodeSelectorTerm.
     This is an alpha feature and may change in the future.
     +structType=atomic
@@ -9986,24 +10337,25 @@
 
     MATCHLABELEXPRESSIONS_FIELD_NUMBER: builtins.int
     @property
     def matchLabelExpressions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___TopologySelectorLabelRequirement]:
         """A list of topology selector requirements by labels.
         +optional
         """
+
     def __init__(
         self,
         *,
         matchLabelExpressions: collections.abc.Iterable[global___TopologySelectorLabelRequirement] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["matchLabelExpressions", b"matchLabelExpressions"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["matchLabelExpressions", b"matchLabelExpressions"]) -> None: ...
 
 global___TopologySelectorTerm = TopologySelectorTerm
 
-@typing_extensions.final
+@typing.final
 class TopologySpreadConstraint(google.protobuf.message.Message):
     """TopologySpreadConstraint specifies how to spread matching pods among the given topology."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     MAXSKEW_FIELD_NUMBER: builtins.int
     TOPOLOGYKEY_FIELD_NUMBER: builtins.int
@@ -10061,28 +10413,29 @@
     @property
     def labelSelector(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.LabelSelector:
         """LabelSelector is used to find matching pods.
         Pods that match this label selector are counted to determine the number of pods
         in their corresponding topology domain.
         +optional
         """
+
     def __init__(
         self,
         *,
         maxSkew: builtins.int | None = ...,
         topologyKey: builtins.str | None = ...,
         whenUnsatisfiable: builtins.str | None = ...,
         labelSelector: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.LabelSelector | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["labelSelector", b"labelSelector", "maxSkew", b"maxSkew", "topologyKey", b"topologyKey", "whenUnsatisfiable", b"whenUnsatisfiable"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["labelSelector", b"labelSelector", "maxSkew", b"maxSkew", "topologyKey", b"topologyKey", "whenUnsatisfiable", b"whenUnsatisfiable"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["labelSelector", b"labelSelector", "maxSkew", b"maxSkew", "topologyKey", b"topologyKey", "whenUnsatisfiable", b"whenUnsatisfiable"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["labelSelector", b"labelSelector", "maxSkew", b"maxSkew", "topologyKey", b"topologyKey", "whenUnsatisfiable", b"whenUnsatisfiable"]) -> None: ...
 
 global___TopologySpreadConstraint = TopologySpreadConstraint
 
-@typing_extensions.final
+@typing.final
 class TypedLocalObjectReference(google.protobuf.message.Message):
     """TypedLocalObjectReference contains enough information to let you locate the
     typed referenced object inside the same namespace.
     +structType=atomic
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -10103,20 +10456,20 @@
     def __init__(
         self,
         *,
         apiGroup: builtins.str | None = ...,
         kind: builtins.str | None = ...,
         name: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["apiGroup", b"apiGroup", "kind", b"kind", "name", b"name"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["apiGroup", b"apiGroup", "kind", b"kind", "name", b"name"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["apiGroup", b"apiGroup", "kind", b"kind", "name", b"name"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["apiGroup", b"apiGroup", "kind", b"kind", "name", b"name"]) -> None: ...
 
 global___TypedLocalObjectReference = TypedLocalObjectReference
 
-@typing_extensions.final
+@typing.final
 class Volume(google.protobuf.message.Message):
     """Volume represents a named volume in a pod that may be accessed by any container in the pod."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     VOLUMESOURCE_FIELD_NUMBER: builtins.int
@@ -10127,26 +10480,27 @@
     """
     @property
     def volumeSource(self) -> global___VolumeSource:
         """VolumeSource represents the location and type of the mounted volume.
         If not specified, the Volume is implied to be an EmptyDir.
         This implied behavior is deprecated and will be removed in a future version.
         """
+
     def __init__(
         self,
         *,
         name: builtins.str | None = ...,
         volumeSource: global___VolumeSource | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["name", b"name", "volumeSource", b"volumeSource"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["name", b"name", "volumeSource", b"volumeSource"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["name", b"name", "volumeSource", b"volumeSource"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["name", b"name", "volumeSource", b"volumeSource"]) -> None: ...
 
 global___Volume = Volume
 
-@typing_extensions.final
+@typing.final
 class VolumeDevice(google.protobuf.message.Message):
     """volumeDevice describes a mapping of a raw block device within a container."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     DEVICEPATH_FIELD_NUMBER: builtins.int
@@ -10156,20 +10510,20 @@
     """devicePath is the path inside of the container that the device will be mapped to."""
     def __init__(
         self,
         *,
         name: builtins.str | None = ...,
         devicePath: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["devicePath", b"devicePath", "name", b"name"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["devicePath", b"devicePath", "name", b"name"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["devicePath", b"devicePath", "name", b"name"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["devicePath", b"devicePath", "name", b"name"]) -> None: ...
 
 global___VolumeDevice = VolumeDevice
 
-@typing_extensions.final
+@typing.final
 class VolumeMount(google.protobuf.message.Message):
     """VolumeMount describes a mounting of a Volume within a container."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     READONLY_FIELD_NUMBER: builtins.int
@@ -10213,83 +10567,88 @@
         name: builtins.str | None = ...,
         readOnly: builtins.bool | None = ...,
         mountPath: builtins.str | None = ...,
         subPath: builtins.str | None = ...,
         mountPropagation: builtins.str | None = ...,
         subPathExpr: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["mountPath", b"mountPath", "mountPropagation", b"mountPropagation", "name", b"name", "readOnly", b"readOnly", "subPath", b"subPath", "subPathExpr", b"subPathExpr"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["mountPath", b"mountPath", "mountPropagation", b"mountPropagation", "name", b"name", "readOnly", b"readOnly", "subPath", b"subPath", "subPathExpr", b"subPathExpr"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["mountPath", b"mountPath", "mountPropagation", b"mountPropagation", "name", b"name", "readOnly", b"readOnly", "subPath", b"subPath", "subPathExpr", b"subPathExpr"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["mountPath", b"mountPath", "mountPropagation", b"mountPropagation", "name", b"name", "readOnly", b"readOnly", "subPath", b"subPath", "subPathExpr", b"subPathExpr"]) -> None: ...
 
 global___VolumeMount = VolumeMount
 
-@typing_extensions.final
+@typing.final
 class VolumeNodeAffinity(google.protobuf.message.Message):
     """VolumeNodeAffinity defines constraints that limit what nodes this volume can be accessed from."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     REQUIRED_FIELD_NUMBER: builtins.int
     @property
     def required(self) -> global___NodeSelector:
         """Required specifies hard node constraints that must be met."""
+
     def __init__(
         self,
         *,
         required: global___NodeSelector | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["required", b"required"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["required", b"required"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["required", b"required"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["required", b"required"]) -> None: ...
 
 global___VolumeNodeAffinity = VolumeNodeAffinity
 
-@typing_extensions.final
+@typing.final
 class VolumeProjection(google.protobuf.message.Message):
     """Projection that may be projected along with other supported volume types"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SECRET_FIELD_NUMBER: builtins.int
     DOWNWARDAPI_FIELD_NUMBER: builtins.int
     CONFIGMAP_FIELD_NUMBER: builtins.int
     SERVICEACCOUNTTOKEN_FIELD_NUMBER: builtins.int
     @property
     def secret(self) -> global___SecretProjection:
         """information about the secret data to project
         +optional
         """
+
     @property
     def downwardAPI(self) -> global___DownwardAPIProjection:
         """information about the downwardAPI data to project
         +optional
         """
+
     @property
     def configMap(self) -> global___ConfigMapProjection:
         """information about the configMap data to project
         +optional
         """
+
     @property
     def serviceAccountToken(self) -> global___ServiceAccountTokenProjection:
         """information about the serviceAccountToken data to project
         +optional
         """
+
     def __init__(
         self,
         *,
         secret: global___SecretProjection | None = ...,
         downwardAPI: global___DownwardAPIProjection | None = ...,
         configMap: global___ConfigMapProjection | None = ...,
         serviceAccountToken: global___ServiceAccountTokenProjection | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["configMap", b"configMap", "downwardAPI", b"downwardAPI", "secret", b"secret", "serviceAccountToken", b"serviceAccountToken"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["configMap", b"configMap", "downwardAPI", b"downwardAPI", "secret", b"secret", "serviceAccountToken", b"serviceAccountToken"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["configMap", b"configMap", "downwardAPI", b"downwardAPI", "secret", b"secret", "serviceAccountToken", b"serviceAccountToken"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["configMap", b"configMap", "downwardAPI", b"downwardAPI", "secret", b"secret", "serviceAccountToken", b"serviceAccountToken"]) -> None: ...
 
 global___VolumeProjection = VolumeProjection
 
-@typing_extensions.final
+@typing.final
 class VolumeSource(google.protobuf.message.Message):
     """Represents the source of a volume to mount.
     Only one of its members may be specified.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -10330,163 +10689,191 @@
         to see the host machine. Most containers will NOT need this.
         More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
         ---
         TODO(jonesdl) We need to restrict who can use host directory mounts and who can/can not
         mount host directories as read/write.
         +optional
         """
+
     @property
     def emptyDir(self) -> global___EmptyDirVolumeSource:
         """EmptyDir represents a temporary directory that shares a pod's lifetime.
         More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
         +optional
         """
+
     @property
     def gcePersistentDisk(self) -> global___GCEPersistentDiskVolumeSource:
         """GCEPersistentDisk represents a GCE Disk resource that is attached to a
         kubelet's host machine and then exposed to the pod.
         More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
         +optional
         """
+
     @property
     def awsElasticBlockStore(self) -> global___AWSElasticBlockStoreVolumeSource:
         """AWSElasticBlockStore represents an AWS Disk resource that is attached to a
         kubelet's host machine and then exposed to the pod.
         More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
         +optional
         """
+
     @property
     def gitRepo(self) -> global___GitRepoVolumeSource:
         """GitRepo represents a git repository at a particular revision.
         DEPRECATED: GitRepo is deprecated. To provision a container with a git repo, mount an
         EmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir
         into the Pod's container.
         +optional
         """
+
     @property
     def secret(self) -> global___SecretVolumeSource:
         """Secret represents a secret that should populate this volume.
         More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
         +optional
         """
+
     @property
     def nfs(self) -> global___NFSVolumeSource:
         """NFS represents an NFS mount on the host that shares a pod's lifetime
         More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
         +optional
         """
+
     @property
     def iscsi(self) -> global___ISCSIVolumeSource:
         """ISCSI represents an ISCSI Disk resource that is attached to a
         kubelet's host machine and then exposed to the pod.
         More info: https://examples.k8s.io/volumes/iscsi/README.md
         +optional
         """
+
     @property
     def glusterfs(self) -> global___GlusterfsVolumeSource:
         """Glusterfs represents a Glusterfs mount on the host that shares a pod's lifetime.
         More info: https://examples.k8s.io/volumes/glusterfs/README.md
         +optional
         """
+
     @property
     def persistentVolumeClaim(self) -> global___PersistentVolumeClaimVolumeSource:
         """PersistentVolumeClaimVolumeSource represents a reference to a
         PersistentVolumeClaim in the same namespace.
         More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         +optional
         """
+
     @property
     def rbd(self) -> global___RBDVolumeSource:
         """RBD represents a Rados Block Device mount on the host that shares a pod's lifetime.
         More info: https://examples.k8s.io/volumes/rbd/README.md
         +optional
         """
+
     @property
     def flexVolume(self) -> global___FlexVolumeSource:
         """FlexVolume represents a generic volume resource that is
         provisioned/attached using an exec based plugin.
         +optional
         """
+
     @property
     def cinder(self) -> global___CinderVolumeSource:
         """Cinder represents a cinder volume attached and mounted on kubelets host machine.
         More info: https://examples.k8s.io/mysql-cinder-pd/README.md
         +optional
         """
+
     @property
     def cephfs(self) -> global___CephFSVolumeSource:
         """CephFS represents a Ceph FS mount on the host that shares a pod's lifetime
         +optional
         """
+
     @property
     def flocker(self) -> global___FlockerVolumeSource:
         """Flocker represents a Flocker volume attached to a kubelet's host machine. This depends on the Flocker control service being running
         +optional
         """
+
     @property
     def downwardAPI(self) -> global___DownwardAPIVolumeSource:
         """DownwardAPI represents downward API about the pod that should populate this volume
         +optional
         """
+
     @property
     def fc(self) -> global___FCVolumeSource:
         """FC represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod.
         +optional
         """
+
     @property
     def azureFile(self) -> global___AzureFileVolumeSource:
         """AzureFile represents an Azure File Service mount on the host and bind mount to the pod.
         +optional
         """
+
     @property
     def configMap(self) -> global___ConfigMapVolumeSource:
         """ConfigMap represents a configMap that should populate this volume
         +optional
         """
+
     @property
     def vsphereVolume(self) -> global___VsphereVirtualDiskVolumeSource:
         """VsphereVolume represents a vSphere volume attached and mounted on kubelets host machine
         +optional
         """
+
     @property
     def quobyte(self) -> global___QuobyteVolumeSource:
         """Quobyte represents a Quobyte mount on the host that shares a pod's lifetime
         +optional
         """
+
     @property
     def azureDisk(self) -> global___AzureDiskVolumeSource:
         """AzureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
         +optional
         """
+
     @property
     def photonPersistentDisk(self) -> global___PhotonPersistentDiskVolumeSource:
         """PhotonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine"""
+
     @property
     def projected(self) -> global___ProjectedVolumeSource:
         """Items for all in one resources secrets, configmaps, and downward API"""
+
     @property
     def portworxVolume(self) -> global___PortworxVolumeSource:
         """PortworxVolume represents a portworx volume attached and mounted on kubelets host machine
         +optional
         """
+
     @property
     def scaleIO(self) -> global___ScaleIOVolumeSource:
         """ScaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.
         +optional
         """
+
     @property
     def storageos(self) -> global___StorageOSVolumeSource:
         """StorageOS represents a StorageOS volume attached and mounted on Kubernetes nodes.
         +optional
         """
+
     @property
     def csi(self) -> global___CSIVolumeSource:
         """CSI (Container Storage Interface) represents ephemeral storage that is handled by certain external CSI drivers (Beta feature).
         +optional
         """
+
     @property
     def ephemeral(self) -> global___EphemeralVolumeSource:
         """Ephemeral represents a volume that is handled by a cluster storage driver.
         The volume's lifecycle is tied to the pod that defines it - it will be created before the pod starts,
         and deleted when the pod is removed.
 
         Use this if:
@@ -10511,14 +10898,15 @@
         persistent volumes at the same time.
 
         This is a beta feature and only available when the GenericEphemeralVolume
         feature gate is enabled.
 
         +optional
         """
+
     def __init__(
         self,
         *,
         hostPath: global___HostPathVolumeSource | None = ...,
         emptyDir: global___EmptyDirVolumeSource | None = ...,
         gcePersistentDisk: global___GCEPersistentDiskVolumeSource | None = ...,
         awsElasticBlockStore: global___AWSElasticBlockStoreVolumeSource | None = ...,
@@ -10544,20 +10932,20 @@
         projected: global___ProjectedVolumeSource | None = ...,
         portworxVolume: global___PortworxVolumeSource | None = ...,
         scaleIO: global___ScaleIOVolumeSource | None = ...,
         storageos: global___StorageOSVolumeSource | None = ...,
         csi: global___CSIVolumeSource | None = ...,
         ephemeral: global___EphemeralVolumeSource | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["awsElasticBlockStore", b"awsElasticBlockStore", "azureDisk", b"azureDisk", "azureFile", b"azureFile", "cephfs", b"cephfs", "cinder", b"cinder", "configMap", b"configMap", "csi", b"csi", "downwardAPI", b"downwardAPI", "emptyDir", b"emptyDir", "ephemeral", b"ephemeral", "fc", b"fc", "flexVolume", b"flexVolume", "flocker", b"flocker", "gcePersistentDisk", b"gcePersistentDisk", "gitRepo", b"gitRepo", "glusterfs", b"glusterfs", "hostPath", b"hostPath", "iscsi", b"iscsi", "nfs", b"nfs", "persistentVolumeClaim", b"persistentVolumeClaim", "photonPersistentDisk", b"photonPersistentDisk", "portworxVolume", b"portworxVolume", "projected", b"projected", "quobyte", b"quobyte", "rbd", b"rbd", "scaleIO", b"scaleIO", "secret", b"secret", "storageos", b"storageos", "vsphereVolume", b"vsphereVolume"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["awsElasticBlockStore", b"awsElasticBlockStore", "azureDisk", b"azureDisk", "azureFile", b"azureFile", "cephfs", b"cephfs", "cinder", b"cinder", "configMap", b"configMap", "csi", b"csi", "downwardAPI", b"downwardAPI", "emptyDir", b"emptyDir", "ephemeral", b"ephemeral", "fc", b"fc", "flexVolume", b"flexVolume", "flocker", b"flocker", "gcePersistentDisk", b"gcePersistentDisk", "gitRepo", b"gitRepo", "glusterfs", b"glusterfs", "hostPath", b"hostPath", "iscsi", b"iscsi", "nfs", b"nfs", "persistentVolumeClaim", b"persistentVolumeClaim", "photonPersistentDisk", b"photonPersistentDisk", "portworxVolume", b"portworxVolume", "projected", b"projected", "quobyte", b"quobyte", "rbd", b"rbd", "scaleIO", b"scaleIO", "secret", b"secret", "storageos", b"storageos", "vsphereVolume", b"vsphereVolume"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["awsElasticBlockStore", b"awsElasticBlockStore", "azureDisk", b"azureDisk", "azureFile", b"azureFile", "cephfs", b"cephfs", "cinder", b"cinder", "configMap", b"configMap", "csi", b"csi", "downwardAPI", b"downwardAPI", "emptyDir", b"emptyDir", "ephemeral", b"ephemeral", "fc", b"fc", "flexVolume", b"flexVolume", "flocker", b"flocker", "gcePersistentDisk", b"gcePersistentDisk", "gitRepo", b"gitRepo", "glusterfs", b"glusterfs", "hostPath", b"hostPath", "iscsi", b"iscsi", "nfs", b"nfs", "persistentVolumeClaim", b"persistentVolumeClaim", "photonPersistentDisk", b"photonPersistentDisk", "portworxVolume", b"portworxVolume", "projected", b"projected", "quobyte", b"quobyte", "rbd", b"rbd", "scaleIO", b"scaleIO", "secret", b"secret", "storageos", b"storageos", "vsphereVolume", b"vsphereVolume"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["awsElasticBlockStore", b"awsElasticBlockStore", "azureDisk", b"azureDisk", "azureFile", b"azureFile", "cephfs", b"cephfs", "cinder", b"cinder", "configMap", b"configMap", "csi", b"csi", "downwardAPI", b"downwardAPI", "emptyDir", b"emptyDir", "ephemeral", b"ephemeral", "fc", b"fc", "flexVolume", b"flexVolume", "flocker", b"flocker", "gcePersistentDisk", b"gcePersistentDisk", "gitRepo", b"gitRepo", "glusterfs", b"glusterfs", "hostPath", b"hostPath", "iscsi", b"iscsi", "nfs", b"nfs", "persistentVolumeClaim", b"persistentVolumeClaim", "photonPersistentDisk", b"photonPersistentDisk", "portworxVolume", b"portworxVolume", "projected", b"projected", "quobyte", b"quobyte", "rbd", b"rbd", "scaleIO", b"scaleIO", "secret", b"secret", "storageos", b"storageos", "vsphereVolume", b"vsphereVolume"]) -> None: ...
 
 global___VolumeSource = VolumeSource
 
-@typing_extensions.final
+@typing.final
 class VsphereVirtualDiskVolumeSource(google.protobuf.message.Message):
     """Represents a vSphere volume resource."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     VOLUMEPATH_FIELD_NUMBER: builtins.int
     FSTYPE_FIELD_NUMBER: builtins.int
@@ -10583,46 +10971,47 @@
         self,
         *,
         volumePath: builtins.str | None = ...,
         fsType: builtins.str | None = ...,
         storagePolicyName: builtins.str | None = ...,
         storagePolicyID: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "storagePolicyID", b"storagePolicyID", "storagePolicyName", b"storagePolicyName", "volumePath", b"volumePath"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["fsType", b"fsType", "storagePolicyID", b"storagePolicyID", "storagePolicyName", b"storagePolicyName", "volumePath", b"volumePath"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fsType", b"fsType", "storagePolicyID", b"storagePolicyID", "storagePolicyName", b"storagePolicyName", "volumePath", b"volumePath"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["fsType", b"fsType", "storagePolicyID", b"storagePolicyID", "storagePolicyName", b"storagePolicyName", "volumePath", b"volumePath"]) -> None: ...
 
 global___VsphereVirtualDiskVolumeSource = VsphereVirtualDiskVolumeSource
 
-@typing_extensions.final
+@typing.final
 class WeightedPodAffinityTerm(google.protobuf.message.Message):
     """The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     WEIGHT_FIELD_NUMBER: builtins.int
     PODAFFINITYTERM_FIELD_NUMBER: builtins.int
     weight: builtins.int
     """weight associated with matching the corresponding podAffinityTerm,
     in the range 1-100.
     """
     @property
     def podAffinityTerm(self) -> global___PodAffinityTerm:
         """Required. A pod affinity term, associated with the corresponding weight."""
+
     def __init__(
         self,
         *,
         weight: builtins.int | None = ...,
         podAffinityTerm: global___PodAffinityTerm | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["podAffinityTerm", b"podAffinityTerm", "weight", b"weight"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["podAffinityTerm", b"podAffinityTerm", "weight", b"weight"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["podAffinityTerm", b"podAffinityTerm", "weight", b"weight"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["podAffinityTerm", b"podAffinityTerm", "weight", b"weight"]) -> None: ...
 
 global___WeightedPodAffinityTerm = WeightedPodAffinityTerm
 
-@typing_extensions.final
+@typing.final
 class WindowsSecurityContextOptions(google.protobuf.message.Message):
     """WindowsSecurityContextOptions contain Windows-specific options and credentials."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     GMSACREDENTIALSPECNAME_FIELD_NUMBER: builtins.int
     GMSACREDENTIALSPEC_FIELD_NUMBER: builtins.int
@@ -10659,11 +11048,11 @@
         self,
         *,
         gmsaCredentialSpecName: builtins.str | None = ...,
         gmsaCredentialSpec: builtins.str | None = ...,
         runAsUserName: builtins.str | None = ...,
         hostProcess: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["gmsaCredentialSpec", b"gmsaCredentialSpec", "gmsaCredentialSpecName", b"gmsaCredentialSpecName", "hostProcess", b"hostProcess", "runAsUserName", b"runAsUserName"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["gmsaCredentialSpec", b"gmsaCredentialSpec", "gmsaCredentialSpecName", b"gmsaCredentialSpecName", "hostProcess", b"hostProcess", "runAsUserName", b"runAsUserName"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["gmsaCredentialSpec", b"gmsaCredentialSpec", "gmsaCredentialSpecName", b"gmsaCredentialSpecName", "hostProcess", b"hostProcess", "runAsUserName", b"runAsUserName"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["gmsaCredentialSpec", b"gmsaCredentialSpec", "gmsaCredentialSpecName", b"gmsaCredentialSpecName", "hostProcess", b"hostProcess", "runAsUserName", b"runAsUserName"]) -> None: ...
 
 global___WindowsSecurityContextOptions = WindowsSecurityContextOptions
```

## armada_client/k8s/io/api/networking/v1/generated_pb2.py

```diff
@@ -1,11 +1,11 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: k8s.io/api/networking/v1/generated.proto
-# Protobuf Python Version: 4.25.1
+# Protobuf Python Version: 5.26.1
 """Generated protocol buffer code."""
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
 from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
@@ -20,16 +20,16 @@
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n(k8s.io/api/networking/v1/generated.proto\x12\x18k8s.io.api.networking.v1\x1a\"k8s.io/api/core/v1/generated.proto\x1a\x34k8s.io/apimachinery/pkg/apis/meta/v1/generated.proto\x1a/k8s.io/apimachinery/pkg/runtime/generated.proto\x1a\x36k8s.io/apimachinery/pkg/runtime/schema/generated.proto\x1a\x33k8s.io/apimachinery/pkg/util/intstr/generated.proto\"l\n\x0fHTTPIngressPath\x12\x0c\n\x04path\x18\x01 \x01(\t\x12\x10\n\x08pathType\x18\x03 \x01(\t\x12\x39\n\x07\x62\x61\x63kend\x18\x02 \x01(\x0b\x32(.k8s.io.api.networking.v1.IngressBackend\"P\n\x14HTTPIngressRuleValue\x12\x38\n\x05paths\x18\x01 \x03(\x0b\x32).k8s.io.api.networking.v1.HTTPIngressPath\"\'\n\x07IPBlock\x12\x0c\n\x04\x63idr\x18\x01 \x01(\t\x12\x0e\n\x06\x65xcept\x18\x02 \x03(\t\"\xbb\x01\n\x07Ingress\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12\x33\n\x04spec\x18\x02 \x01(\x0b\x32%.k8s.io.api.networking.v1.IngressSpec\x12\x37\n\x06status\x18\x03 \x01(\x0b\x32\'.k8s.io.api.networking.v1.IngressStatus\"\x93\x01\n\x0eIngressBackend\x12@\n\x07service\x18\x04 \x01(\x0b\x32/.k8s.io.api.networking.v1.IngressServiceBackend\x12?\n\x08resource\x18\x03 \x01(\x0b\x32-.k8s.io.api.core.v1.TypedLocalObjectReference\"\x8c\x01\n\x0cIngressClass\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12\x38\n\x04spec\x18\x02 \x01(\x0b\x32*.k8s.io.api.networking.v1.IngressClassSpec\"\x8b\x01\n\x10IngressClassList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12\x35\n\x05items\x18\x02 \x03(\x0b\x32&.k8s.io.api.networking.v1.IngressClass\"q\n\x1fIngressClassParametersReference\x12\x10\n\x08\x61PIGroup\x18\x01 \x01(\t\x12\x0c\n\x04kind\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\r\n\x05scope\x18\x04 \x01(\t\x12\x11\n\tnamespace\x18\x05 \x01(\t\"u\n\x10IngressClassSpec\x12\x12\n\ncontroller\x18\x01 \x01(\t\x12M\n\nparameters\x18\x02 \x01(\x0b\x32\x39.k8s.io.api.networking.v1.IngressClassParametersReference\"\x81\x01\n\x0bIngressList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12\x30\n\x05items\x18\x02 \x03(\x0b\x32!.k8s.io.api.networking.v1.Ingress\"a\n\x0bIngressRule\x12\x0c\n\x04host\x18\x01 \x01(\t\x12\x44\n\x10ingressRuleValue\x18\x02 \x01(\x0b\x32*.k8s.io.api.networking.v1.IngressRuleValue\"P\n\x10IngressRuleValue\x12<\n\x04http\x18\x01 \x01(\x0b\x32..k8s.io.api.networking.v1.HTTPIngressRuleValue\"a\n\x15IngressServiceBackend\x12\x0c\n\x04name\x18\x01 \x01(\t\x12:\n\x04port\x18\x02 \x01(\x0b\x32,.k8s.io.api.networking.v1.ServiceBackendPort\"\xd2\x01\n\x0bIngressSpec\x12\x18\n\x10ingressClassName\x18\x04 \x01(\t\x12@\n\x0e\x64\x65\x66\x61ultBackend\x18\x01 \x01(\x0b\x32(.k8s.io.api.networking.v1.IngressBackend\x12\x31\n\x03tls\x18\x02 \x03(\x0b\x32$.k8s.io.api.networking.v1.IngressTLS\x12\x34\n\x05rules\x18\x03 \x03(\x0b\x32%.k8s.io.api.networking.v1.IngressRule\"M\n\rIngressStatus\x12<\n\x0cloadBalancer\x18\x01 \x01(\x0b\x32&.k8s.io.api.core.v1.LoadBalancerStatus\"/\n\nIngressTLS\x12\r\n\x05hosts\x18\x01 \x03(\t\x12\x12\n\nsecretName\x18\x02 \x01(\t\"\x8e\x01\n\rNetworkPolicy\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\x12\x39\n\x04spec\x18\x02 \x01(\x0b\x32+.k8s.io.api.networking.v1.NetworkPolicySpec\"\x8e\x01\n\x17NetworkPolicyEgressRule\x12:\n\x05ports\x18\x01 \x03(\x0b\x32+.k8s.io.api.networking.v1.NetworkPolicyPort\x12\x37\n\x02to\x18\x02 \x03(\x0b\x32+.k8s.io.api.networking.v1.NetworkPolicyPeer\"\x91\x01\n\x18NetworkPolicyIngressRule\x12:\n\x05ports\x18\x01 \x03(\x0b\x32+.k8s.io.api.networking.v1.NetworkPolicyPort\x12\x39\n\x04\x66rom\x18\x02 \x03(\x0b\x32+.k8s.io.api.networking.v1.NetworkPolicyPeer\"\x8d\x01\n\x11NetworkPolicyList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12\x36\n\x05items\x18\x02 \x03(\x0b\x32\'.k8s.io.api.networking.v1.NetworkPolicy\"\xe1\x01\n\x11NetworkPolicyPeer\x12H\n\x0bpodSelector\x18\x01 \x01(\x0b\x32\x33.k8s.io.apimachinery.pkg.apis.meta.v1.LabelSelector\x12N\n\x11namespaceSelector\x18\x02 \x01(\x0b\x32\x33.k8s.io.apimachinery.pkg.apis.meta.v1.LabelSelector\x12\x32\n\x07ipBlock\x18\x03 \x01(\x0b\x32!.k8s.io.api.networking.v1.IPBlock\"v\n\x11NetworkPolicyPort\x12\x10\n\x08protocol\x18\x01 \x01(\t\x12>\n\x04port\x18\x02 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.util.intstr.IntOrString\x12\x0f\n\x07\x65ndPort\x18\x03 \x01(\x05\"\xfa\x01\n\x11NetworkPolicySpec\x12H\n\x0bpodSelector\x18\x01 \x01(\x0b\x32\x33.k8s.io.apimachinery.pkg.apis.meta.v1.LabelSelector\x12\x43\n\x07ingress\x18\x02 \x03(\x0b\x32\x32.k8s.io.api.networking.v1.NetworkPolicyIngressRule\x12\x41\n\x06\x65gress\x18\x03 \x03(\x0b\x32\x31.k8s.io.api.networking.v1.NetworkPolicyEgressRule\x12\x13\n\x0bpolicyTypes\x18\x04 \x03(\t\"2\n\x12ServiceBackendPort\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0e\n\x06number\x18\x02 \x01(\x05\x42\x04Z\x02v1')
 
 _globals = globals()
 _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
 _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'k8s.io.api.networking.v1.generated_pb2', _globals)
-if _descriptor._USE_C_DESCRIPTORS == False:
-  _globals['DESCRIPTOR']._options = None
+if not _descriptor._USE_C_DESCRIPTORS:
+  _globals['DESCRIPTOR']._loaded_options = None
   _globals['DESCRIPTOR']._serialized_options = b'Z\002v1'
   _globals['_HTTPINGRESSPATH']._serialized_start=318
   _globals['_HTTPINGRESSPATH']._serialized_end=426
   _globals['_HTTPINGRESSRULEVALUE']._serialized_start=428
   _globals['_HTTPINGRESSRULEVALUE']._serialized_end=508
   _globals['_IPBLOCK']._serialized_start=510
   _globals['_IPBLOCK']._serialized_end=549
```

## armada_client/k8s/io/api/networking/v1/generated_pb2.pyi

```diff
@@ -1,29 +1,25 @@
 """
 @generated by mypy-protobuf.  Do not edit manually!
 isort:skip_file
 This file was autogenerated by go-to-protobuf. Do not edit it manually!"""
+
 import builtins
 import collections.abc
 import google.protobuf.descriptor
 import google.protobuf.internal.containers
 import google.protobuf.message
 import armada_client.k8s.io.api.core.v1.generated_pb2
 import armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2
 import armada_client.k8s.io.apimachinery.pkg.util.intstr.generated_pb2
-import sys
-
-if sys.version_info >= (3, 8):
-    import typing as typing_extensions
-else:
-    import typing_extensions
+import typing
 
 DESCRIPTOR: google.protobuf.descriptor.FileDescriptor
 
-@typing_extensions.final
+@typing.final
 class HTTPIngressPath(google.protobuf.message.Message):
     """HTTPIngressPath associates a path with a backend. Incoming urls matching the
     path are forwarded to the backend.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -54,27 +50,28 @@
     Implementations are required to support all path types.
     """
     @property
     def backend(self) -> global___IngressBackend:
         """Backend defines the referenced service endpoint to which the traffic
         will be forwarded to.
         """
+
     def __init__(
         self,
         *,
         path: builtins.str | None = ...,
         pathType: builtins.str | None = ...,
         backend: global___IngressBackend | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["backend", b"backend", "path", b"path", "pathType", b"pathType"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["backend", b"backend", "path", b"path", "pathType", b"pathType"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["backend", b"backend", "path", b"path", "pathType", b"pathType"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["backend", b"backend", "path", b"path", "pathType", b"pathType"]) -> None: ...
 
 global___HTTPIngressPath = HTTPIngressPath
 
-@typing_extensions.final
+@typing.final
 class HTTPIngressRuleValue(google.protobuf.message.Message):
     """HTTPIngressRuleValue is a list of http selectors pointing to backends.
     In the example: http://<host>/<path>?<searchpart> -> backend where
     where parts of the url correspond to RFC 3986, this resource will be used
     to match against everything after the last '/' and before the first '?'
     or '#'.
     """
@@ -83,24 +80,25 @@
 
     PATHS_FIELD_NUMBER: builtins.int
     @property
     def paths(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___HTTPIngressPath]:
         """A collection of paths that map requests to backends.
         +listType=atomic
         """
+
     def __init__(
         self,
         *,
         paths: collections.abc.Iterable[global___HTTPIngressPath] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["paths", b"paths"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["paths", b"paths"]) -> None: ...
 
 global___HTTPIngressRuleValue = HTTPIngressRuleValue
 
-@typing_extensions.final
+@typing.final
 class IPBlock(google.protobuf.message.Message):
     """IPBlock describes a particular CIDR (Ex. "192.168.1.1/24","2001:db9::/64") that is allowed
     to the pods matched by a NetworkPolicySpec's podSelector. The except entry describes CIDRs
     that should not be included within this rule.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -112,20 +110,20 @@
     Valid examples are "192.168.1.1/24" or "2001:db9::/64"
     """
     def __init__(
         self,
         *,
         cidr: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["cidr", b"cidr"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["cidr", b"cidr", "except", b"except"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["cidr", b"cidr"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["cidr", b"cidr", "except", b"except"]) -> None: ...
 
 global___IPBlock = IPBlock
 
-@typing_extensions.final
+@typing.final
 class Ingress(google.protobuf.message.Message):
     """Ingress is a collection of rules that allow inbound connections to reach the
     endpoints defined by a backend. An Ingress can be configured to give services
     externally-reachable urls, load balance traffic, terminate SSL, offer name
     based virtual hosting etc.
     """
 
@@ -136,72 +134,77 @@
     STATUS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def spec(self) -> global___IngressSpec:
         """Spec is the desired state of the Ingress.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         +optional
         """
+
     @property
     def status(self) -> global___IngressStatus:
         """Status is the current state of the Ingress.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         +optional
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         spec: global___IngressSpec | None = ...,
         status: global___IngressStatus | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec", "status", b"status"]) -> None: ...
 
 global___Ingress = Ingress
 
-@typing_extensions.final
+@typing.final
 class IngressBackend(google.protobuf.message.Message):
     """IngressBackend describes all endpoints for a given service and port."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SERVICE_FIELD_NUMBER: builtins.int
     RESOURCE_FIELD_NUMBER: builtins.int
     @property
     def service(self) -> global___IngressServiceBackend:
         """Service references a Service as a Backend.
         This is a mutually exclusive setting with "Resource".
         +optional
         """
+
     @property
     def resource(self) -> armada_client.k8s.io.api.core.v1.generated_pb2.TypedLocalObjectReference:
         """Resource is an ObjectRef to another Kubernetes resource in the namespace
         of the Ingress object. If resource is specified, a service.Name and
         service.Port must not be specified.
         This is a mutually exclusive setting with "Service".
         +optional
         """
+
     def __init__(
         self,
         *,
         service: global___IngressServiceBackend | None = ...,
         resource: armada_client.k8s.io.api.core.v1.generated_pb2.TypedLocalObjectReference | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["resource", b"resource", "service", b"service"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["resource", b"resource", "service", b"service"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["resource", b"resource", "service", b"service"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["resource", b"resource", "service", b"service"]) -> None: ...
 
 global___IngressBackend = IngressBackend
 
-@typing_extensions.final
+@typing.final
 class IngressClass(google.protobuf.message.Message):
     """IngressClass represents the class of the Ingress, referenced by the Ingress
     Spec. The `ingressclass.kubernetes.io/is-default-class` annotation can be
     used to indicate that an IngressClass should be considered default. When a
     single IngressClass resource has this annotation set to true, new Ingress
     resources without a class specified will be assigned this default class.
     """
@@ -212,59 +215,63 @@
     SPEC_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def spec(self) -> global___IngressClassSpec:
         """Spec is the desired state of the IngressClass.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         +optional
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         spec: global___IngressClassSpec | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec"]) -> None: ...
 
 global___IngressClass = IngressClass
 
-@typing_extensions.final
+@typing.final
 class IngressClassList(google.protobuf.message.Message):
     """IngressClassList is a collection of IngressClasses."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """Standard list metadata.
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___IngressClass]:
         """Items is the list of IngressClasses."""
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[global___IngressClass] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___IngressClassList = IngressClassList
 
-@typing_extensions.final
+@typing.final
 class IngressClassParametersReference(google.protobuf.message.Message):
     """IngressClassParametersReference identifies an API object. This can be used
     to specify a cluster or namespace-scoped resource.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -302,20 +309,20 @@
         *,
         aPIGroup: builtins.str | None = ...,
         kind: builtins.str | None = ...,
         name: builtins.str | None = ...,
         scope: builtins.str | None = ...,
         namespace: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["aPIGroup", b"aPIGroup", "kind", b"kind", "name", b"name", "namespace", b"namespace", "scope", b"scope"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["aPIGroup", b"aPIGroup", "kind", b"kind", "name", b"name", "namespace", b"namespace", "scope", b"scope"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["aPIGroup", b"aPIGroup", "kind", b"kind", "name", b"name", "namespace", b"namespace", "scope", b"scope"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["aPIGroup", b"aPIGroup", "kind", b"kind", "name", b"name", "namespace", b"namespace", "scope", b"scope"]) -> None: ...
 
 global___IngressClassParametersReference = IngressClassParametersReference
 
-@typing_extensions.final
+@typing.final
 class IngressClassSpec(google.protobuf.message.Message):
     """IngressClassSpec provides information about the class of an Ingress."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     CONTROLLER_FIELD_NUMBER: builtins.int
     PARAMETERS_FIELD_NUMBER: builtins.int
@@ -330,54 +337,57 @@
     @property
     def parameters(self) -> global___IngressClassParametersReference:
         """Parameters is a link to a custom resource containing additional
         configuration for the controller. This is optional if the controller does
         not require extra parameters.
         +optional
         """
+
     def __init__(
         self,
         *,
         controller: builtins.str | None = ...,
         parameters: global___IngressClassParametersReference | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["controller", b"controller", "parameters", b"parameters"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["controller", b"controller", "parameters", b"parameters"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["controller", b"controller", "parameters", b"parameters"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["controller", b"controller", "parameters", b"parameters"]) -> None: ...
 
 global___IngressClassSpec = IngressClassSpec
 
-@typing_extensions.final
+@typing.final
 class IngressList(google.protobuf.message.Message):
     """IngressList is a collection of Ingress."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Ingress]:
         """Items is the list of Ingress."""
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[global___Ingress] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___IngressList = IngressList
 
-@typing_extensions.final
+@typing.final
 class IngressRule(google.protobuf.message.Message):
     """IngressRule represents the rules mapping the paths under a specified host to
     the related backend services. Incoming requests are first evaluated for a host
     match, then routed to the backend associated with the matching IngressRuleValue.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -414,50 +424,52 @@
         """IngressRuleValue represents a rule to route requests for this IngressRule.
         If unspecified, the rule defaults to a http catch-all. Whether that sends
         just traffic matching the host to the default backend or all traffic to the
         default backend, is left to the controller fulfilling the Ingress. Http is
         currently the only supported IngressRuleValue.
         +optional
         """
+
     def __init__(
         self,
         *,
         host: builtins.str | None = ...,
         ingressRuleValue: global___IngressRuleValue | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["host", b"host", "ingressRuleValue", b"ingressRuleValue"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["host", b"host", "ingressRuleValue", b"ingressRuleValue"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["host", b"host", "ingressRuleValue", b"ingressRuleValue"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["host", b"host", "ingressRuleValue", b"ingressRuleValue"]) -> None: ...
 
 global___IngressRule = IngressRule
 
-@typing_extensions.final
+@typing.final
 class IngressRuleValue(google.protobuf.message.Message):
     """IngressRuleValue represents a rule to apply against incoming requests. If the
     rule is satisfied, the request is routed to the specified backend. Currently
     mixing different types of rules in a single Ingress is disallowed, so exactly
     one of the following must be set.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     HTTP_FIELD_NUMBER: builtins.int
     @property
     def http(self) -> global___HTTPIngressRuleValue:
         """+optional"""
+
     def __init__(
         self,
         *,
         http: global___HTTPIngressRuleValue | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["http", b"http"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["http", b"http"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["http", b"http"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["http", b"http"]) -> None: ...
 
 global___IngressRuleValue = IngressRuleValue
 
-@typing_extensions.final
+@typing.final
 class IngressServiceBackend(google.protobuf.message.Message):
     """IngressServiceBackend references a Kubernetes Service as a Backend."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     PORT_FIELD_NUMBER: builtins.int
@@ -466,26 +478,27 @@
     the same namespace as the Ingress object.
     """
     @property
     def port(self) -> global___ServiceBackendPort:
         """Port of the referenced service. A port name or port number
         is required for a IngressServiceBackend.
         """
+
     def __init__(
         self,
         *,
         name: builtins.str | None = ...,
         port: global___ServiceBackendPort | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["name", b"name", "port", b"port"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["name", b"name", "port", b"port"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["name", b"name", "port", b"port"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["name", b"name", "port", b"port"]) -> None: ...
 
 global___IngressServiceBackend = IngressServiceBackend
 
-@typing_extensions.final
+@typing.final
 class IngressSpec(google.protobuf.message.Message):
     """IngressSpec describes the Ingress the user wishes to exist."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     INGRESSCLASSNAME_FIELD_NUMBER: builtins.int
     DEFAULTBACKEND_FIELD_NUMBER: builtins.int
@@ -508,133 +521,140 @@
     def defaultBackend(self) -> global___IngressBackend:
         """DefaultBackend is the backend that should handle requests that don't
         match any rule. If Rules are not specified, DefaultBackend must be specified.
         If DefaultBackend is not set, the handling of requests that do not match any
         of the rules will be up to the Ingress controller.
         +optional
         """
+
     @property
     def tls(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___IngressTLS]:
         """TLS configuration. Currently the Ingress only supports a single TLS
         port, 443. If multiple members of this list specify different hosts, they
         will be multiplexed on the same port according to the hostname specified
         through the SNI TLS extension, if the ingress controller fulfilling the
         ingress supports SNI.
         +listType=atomic
         +optional
         """
+
     @property
     def rules(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___IngressRule]:
         """A list of host rules used to configure the Ingress. If unspecified, or
         no rule matches, all traffic is sent to the default backend.
         +listType=atomic
         +optional
         """
+
     def __init__(
         self,
         *,
         ingressClassName: builtins.str | None = ...,
         defaultBackend: global___IngressBackend | None = ...,
         tls: collections.abc.Iterable[global___IngressTLS] | None = ...,
         rules: collections.abc.Iterable[global___IngressRule] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["defaultBackend", b"defaultBackend", "ingressClassName", b"ingressClassName"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["defaultBackend", b"defaultBackend", "ingressClassName", b"ingressClassName", "rules", b"rules", "tls", b"tls"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["defaultBackend", b"defaultBackend", "ingressClassName", b"ingressClassName"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["defaultBackend", b"defaultBackend", "ingressClassName", b"ingressClassName", "rules", b"rules", "tls", b"tls"]) -> None: ...
 
 global___IngressSpec = IngressSpec
 
-@typing_extensions.final
+@typing.final
 class IngressStatus(google.protobuf.message.Message):
     """IngressStatus describe the current state of the Ingress."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     LOADBALANCER_FIELD_NUMBER: builtins.int
     @property
     def loadBalancer(self) -> armada_client.k8s.io.api.core.v1.generated_pb2.LoadBalancerStatus:
         """LoadBalancer contains the current status of the load-balancer.
         +optional
         """
+
     def __init__(
         self,
         *,
         loadBalancer: armada_client.k8s.io.api.core.v1.generated_pb2.LoadBalancerStatus | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["loadBalancer", b"loadBalancer"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["loadBalancer", b"loadBalancer"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["loadBalancer", b"loadBalancer"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["loadBalancer", b"loadBalancer"]) -> None: ...
 
 global___IngressStatus = IngressStatus
 
-@typing_extensions.final
+@typing.final
 class IngressTLS(google.protobuf.message.Message):
     """IngressTLS describes the transport layer security associated with an Ingress."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     HOSTS_FIELD_NUMBER: builtins.int
     SECRETNAME_FIELD_NUMBER: builtins.int
+    secretName: builtins.str
+    """SecretName is the name of the secret used to terminate TLS traffic on
+    port 443. Field is left optional to allow TLS routing based on SNI
+    hostname alone. If the SNI host in a listener conflicts with the "Host"
+    header field used by an IngressRule, the SNI host is used for termination
+    and value of the Host header is used for routing.
+    +optional
+    """
     @property
     def hosts(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """Hosts are a list of hosts included in the TLS certificate. The values in
         this list must match the name/s used in the tlsSecret. Defaults to the
         wildcard host setting for the loadbalancer controller fulfilling this
         Ingress, if left unspecified.
         +listType=atomic
         +optional
         """
-    secretName: builtins.str
-    """SecretName is the name of the secret used to terminate TLS traffic on
-    port 443. Field is left optional to allow TLS routing based on SNI
-    hostname alone. If the SNI host in a listener conflicts with the "Host"
-    header field used by an IngressRule, the SNI host is used for termination
-    and value of the Host header is used for routing.
-    +optional
-    """
+
     def __init__(
         self,
         *,
         hosts: collections.abc.Iterable[builtins.str] | None = ...,
         secretName: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["secretName", b"secretName"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["hosts", b"hosts", "secretName", b"secretName"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["secretName", b"secretName"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["hosts", b"hosts", "secretName", b"secretName"]) -> None: ...
 
 global___IngressTLS = IngressTLS
 
-@typing_extensions.final
+@typing.final
 class NetworkPolicy(google.protobuf.message.Message):
     """NetworkPolicy describes what network traffic is allowed for a set of Pods"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     SPEC_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def spec(self) -> global___NetworkPolicySpec:
         """Specification of the desired behavior for this NetworkPolicy.
         +optional
         """
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ObjectMeta | None = ...,
         spec: global___NetworkPolicySpec | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["metadata", b"metadata", "spec", b"spec"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["metadata", b"metadata", "spec", b"spec"]) -> None: ...
 
 global___NetworkPolicy = NetworkPolicy
 
-@typing_extensions.final
+@typing.final
 class NetworkPolicyEgressRule(google.protobuf.message.Message):
     """NetworkPolicyEgressRule describes a particular set of traffic that is allowed out of pods
     matched by a NetworkPolicySpec's podSelector. The traffic must match both ports and to.
     This type is beta-level in 1.8
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -646,34 +666,36 @@
         """List of destination ports for outgoing traffic.
         Each item in this list is combined using a logical OR. If this field is
         empty or missing, this rule matches all ports (traffic not restricted by port).
         If this field is present and contains at least one item, then this rule allows
         traffic only if the traffic matches at least one port in the list.
         +optional
         """
+
     @property
     def to(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___NetworkPolicyPeer]:
         """List of destinations for outgoing traffic of pods selected for this rule.
         Items in this list are combined using a logical OR operation. If this field is
         empty or missing, this rule matches all destinations (traffic not restricted by
         destination). If this field is present and contains at least one item, this rule
         allows traffic only if the traffic matches at least one item in the to list.
         +optional
         """
+
     def __init__(
         self,
         *,
         ports: collections.abc.Iterable[global___NetworkPolicyPort] | None = ...,
         to: collections.abc.Iterable[global___NetworkPolicyPeer] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["ports", b"ports", "to", b"to"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["ports", b"ports", "to", b"to"]) -> None: ...
 
 global___NetworkPolicyEgressRule = NetworkPolicyEgressRule
 
-@typing_extensions.final
+@typing.final
 class NetworkPolicyIngressRule(google.protobuf.message.Message):
     """NetworkPolicyIngressRule describes a particular set of traffic that is allowed to the pods
     matched by a NetworkPolicySpec's podSelector. The traffic must match both ports and from.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -684,52 +706,55 @@
         """List of ports which should be made accessible on the pods selected for this
         rule. Each item in this list is combined using a logical OR. If this field is
         empty or missing, this rule matches all ports (traffic not restricted by port).
         If this field is present and contains at least one item, then this rule allows
         traffic only if the traffic matches at least one port in the list.
         +optional
         """
+
     def __init__(
         self,
         *,
         ports: collections.abc.Iterable[global___NetworkPolicyPort] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["from", b"from", "ports", b"ports"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["from", b"from", "ports", b"ports"]) -> None: ...
 
 global___NetworkPolicyIngressRule = NetworkPolicyIngressRule
 
-@typing_extensions.final
+@typing.final
 class NetworkPolicyList(google.protobuf.message.Message):
     """NetworkPolicyList is a list of NetworkPolicy objects."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta:
         """Standard list metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___NetworkPolicy]:
         """Items is a list of schema objects."""
+
     def __init__(
         self,
         *,
         metadata: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.ListMeta | None = ...,
         items: collections.abc.Iterable[global___NetworkPolicy] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___NetworkPolicyList = NetworkPolicyList
 
-@typing_extensions.final
+@typing.final
 class NetworkPolicyPeer(google.protobuf.message.Message):
     """NetworkPolicyPeer describes a peer to allow traffic to/from. Only certain combinations of
     fields are allowed
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -742,86 +767,90 @@
         selector semantics; if present but empty, it selects all pods.
 
         If NamespaceSelector is also set, then the NetworkPolicyPeer as a whole selects
         the Pods matching PodSelector in the Namespaces selected by NamespaceSelector.
         Otherwise it selects the Pods matching PodSelector in the policy's own Namespace.
         +optional
         """
+
     @property
     def namespaceSelector(self) -> armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.LabelSelector:
         """Selects Namespaces using cluster-scoped labels. This field follows standard label
         selector semantics; if present but empty, it selects all namespaces.
 
         If PodSelector is also set, then the NetworkPolicyPeer as a whole selects
         the Pods matching PodSelector in the Namespaces selected by NamespaceSelector.
         Otherwise it selects all Pods in the Namespaces selected by NamespaceSelector.
         +optional
         """
+
     @property
     def ipBlock(self) -> global___IPBlock:
         """IPBlock defines policy on a particular IPBlock. If this field is set then
         neither of the other fields can be.
         +optional
         """
+
     def __init__(
         self,
         *,
         podSelector: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.LabelSelector | None = ...,
         namespaceSelector: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.LabelSelector | None = ...,
         ipBlock: global___IPBlock | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["ipBlock", b"ipBlock", "namespaceSelector", b"namespaceSelector", "podSelector", b"podSelector"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["ipBlock", b"ipBlock", "namespaceSelector", b"namespaceSelector", "podSelector", b"podSelector"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["ipBlock", b"ipBlock", "namespaceSelector", b"namespaceSelector", "podSelector", b"podSelector"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["ipBlock", b"ipBlock", "namespaceSelector", b"namespaceSelector", "podSelector", b"podSelector"]) -> None: ...
 
 global___NetworkPolicyPeer = NetworkPolicyPeer
 
-@typing_extensions.final
+@typing.final
 class NetworkPolicyPort(google.protobuf.message.Message):
     """NetworkPolicyPort describes a port to allow traffic on"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PROTOCOL_FIELD_NUMBER: builtins.int
     PORT_FIELD_NUMBER: builtins.int
     ENDPORT_FIELD_NUMBER: builtins.int
     protocol: builtins.str
     """The protocol (TCP, UDP, or SCTP) which traffic must match. If not specified, this
     field defaults to TCP.
     +optional
     """
-    @property
-    def port(self) -> armada_client.k8s.io.apimachinery.pkg.util.intstr.generated_pb2.IntOrString:
-        """The port on the given protocol. This can either be a numerical or named
-        port on a pod. If this field is not provided, this matches all port names and
-        numbers.
-        If present, only traffic on the specified protocol AND port will be matched.
-        +optional
-        """
     endPort: builtins.int
     """If set, indicates that the range of ports from port to endPort, inclusive,
     should be allowed by the policy. This field cannot be defined if the port field
     is not defined or if the port field is defined as a named (string) port.
     The endPort must be equal or greater than port.
     This feature is in Beta state and is enabled by default.
     It can be disabled using the Feature Gate "NetworkPolicyEndPort".
     +optional
     """
+    @property
+    def port(self) -> armada_client.k8s.io.apimachinery.pkg.util.intstr.generated_pb2.IntOrString:
+        """The port on the given protocol. This can either be a numerical or named
+        port on a pod. If this field is not provided, this matches all port names and
+        numbers.
+        If present, only traffic on the specified protocol AND port will be matched.
+        +optional
+        """
+
     def __init__(
         self,
         *,
         protocol: builtins.str | None = ...,
         port: armada_client.k8s.io.apimachinery.pkg.util.intstr.generated_pb2.IntOrString | None = ...,
         endPort: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["endPort", b"endPort", "port", b"port", "protocol", b"protocol"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["endPort", b"endPort", "port", b"port", "protocol", b"protocol"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["endPort", b"endPort", "port", b"port", "protocol", b"protocol"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["endPort", b"endPort", "port", b"port", "protocol", b"protocol"]) -> None: ...
 
 global___NetworkPolicyPort = NetworkPolicyPort
 
-@typing_extensions.final
+@typing.final
 class NetworkPolicySpec(google.protobuf.message.Message):
     """NetworkPolicySpec provides the specification of a NetworkPolicy"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PODSELECTOR_FIELD_NUMBER: builtins.int
     INGRESS_FIELD_NUMBER: builtins.int
@@ -832,64 +861,68 @@
         """Selects the pods to which this NetworkPolicy object applies. The array of
         ingress rules is applied to any pods selected by this field. Multiple network
         policies can select the same set of pods. In this case, the ingress rules for
         each are combined additively. This field is NOT optional and follows standard
         label selector semantics. An empty podSelector matches all pods in this
         namespace.
         """
+
     @property
     def ingress(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___NetworkPolicyIngressRule]:
         """List of ingress rules to be applied to the selected pods. Traffic is allowed to
         a pod if there are no NetworkPolicies selecting the pod
         (and cluster policy otherwise allows the traffic), OR if the traffic source is
         the pod's local node, OR if the traffic matches at least one ingress rule
         across all of the NetworkPolicy objects whose podSelector matches the pod. If
         this field is empty then this NetworkPolicy does not allow any traffic (and serves
         solely to ensure that the pods it selects are isolated by default)
         +optional
         """
+
     @property
     def egress(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___NetworkPolicyEgressRule]:
         """List of egress rules to be applied to the selected pods. Outgoing traffic is
         allowed if there are no NetworkPolicies selecting the pod (and cluster policy
         otherwise allows the traffic), OR if the traffic matches at least one egress rule
         across all of the NetworkPolicy objects whose podSelector matches the pod. If
         this field is empty then this NetworkPolicy limits all outgoing traffic (and serves
         solely to ensure that the pods it selects are isolated by default).
         This field is beta-level in 1.8
         +optional
         """
+
     @property
     def policyTypes(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """List of rule types that the NetworkPolicy relates to.
         Valid options are ["Ingress"], ["Egress"], or ["Ingress", "Egress"].
         If this field is not specified, it will default based on the existence of Ingress or Egress rules;
         policies that contain an Egress section are assumed to affect Egress, and all policies
         (whether or not they contain an Ingress section) are assumed to affect Ingress.
         If you want to write an egress-only policy, you must explicitly specify policyTypes [ "Egress" ].
         Likewise, if you want to write a policy that specifies that no egress is allowed,
         you must specify a policyTypes value that include "Egress" (since such a policy would not include
         an Egress section and would otherwise default to just [ "Ingress" ]).
         This field is beta-level in 1.8
         +optional
         """
+
     def __init__(
         self,
         *,
         podSelector: armada_client.k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2.LabelSelector | None = ...,
         ingress: collections.abc.Iterable[global___NetworkPolicyIngressRule] | None = ...,
         egress: collections.abc.Iterable[global___NetworkPolicyEgressRule] | None = ...,
         policyTypes: collections.abc.Iterable[builtins.str] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["podSelector", b"podSelector"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["egress", b"egress", "ingress", b"ingress", "podSelector", b"podSelector", "policyTypes", b"policyTypes"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["podSelector", b"podSelector"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["egress", b"egress", "ingress", b"ingress", "podSelector", b"podSelector", "policyTypes", b"policyTypes"]) -> None: ...
 
 global___NetworkPolicySpec = NetworkPolicySpec
 
-@typing_extensions.final
+@typing.final
 class ServiceBackendPort(google.protobuf.message.Message):
     """ServiceBackendPort is the service port being referenced."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     NUMBER_FIELD_NUMBER: builtins.int
@@ -905,11 +938,11 @@
     """
     def __init__(
         self,
         *,
         name: builtins.str | None = ...,
         number: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["name", b"name", "number", b"number"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["name", b"name", "number", b"number"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["name", b"name", "number", b"number"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["name", b"name", "number", b"number"]) -> None: ...
 
 global___ServiceBackendPort = ServiceBackendPort
```

## armada_client/k8s/io/apimachinery/pkg/api/resource/generated_pb2.py

```diff
@@ -1,11 +1,11 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: k8s.io/apimachinery/pkg/api/resource/generated.proto
-# Protobuf Python Version: 4.25.1
+# Protobuf Python Version: 5.26.1
 """Generated protocol buffer code."""
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
 from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
@@ -15,13 +15,13 @@
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n4k8s.io/apimachinery/pkg/api/resource/generated.proto\x12$k8s.io.apimachinery.pkg.api.resource\"\x1a\n\x08Quantity\x12\x0e\n\x06string\x18\x01 \x01(\tB\nZ\x08resource')
 
 _globals = globals()
 _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
 _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'k8s.io.apimachinery.pkg.api.resource.generated_pb2', _globals)
-if _descriptor._USE_C_DESCRIPTORS == False:
-  _globals['DESCRIPTOR']._options = None
+if not _descriptor._USE_C_DESCRIPTORS:
+  _globals['DESCRIPTOR']._loaded_options = None
   _globals['DESCRIPTOR']._serialized_options = b'Z\010resource'
   _globals['_QUANTITY']._serialized_start=94
   _globals['_QUANTITY']._serialized_end=120
 # @@protoc_insertion_point(module_scope)
```

## armada_client/k8s/io/apimachinery/pkg/api/resource/generated_pb2.pyi

```diff
@@ -1,24 +1,20 @@
 """
 @generated by mypy-protobuf.  Do not edit manually!
 isort:skip_file
 This file was autogenerated by go-to-protobuf. Do not edit it manually!"""
+
 import builtins
 import google.protobuf.descriptor
 import google.protobuf.message
-import sys
-
-if sys.version_info >= (3, 8):
-    import typing as typing_extensions
-else:
-    import typing_extensions
+import typing
 
 DESCRIPTOR: google.protobuf.descriptor.FileDescriptor
 
-@typing_extensions.final
+@typing.final
 class Quantity(google.protobuf.message.Message):
     """Quantity is a fixed-point representation of a number.
     It provides convenient marshaling/unmarshaling in JSON and YAML,
     in addition to String() and AsInt64() accessors.
 
     The serialization format is:
 
@@ -81,11 +77,11 @@
     STRING_FIELD_NUMBER: builtins.int
     string: builtins.str
     def __init__(
         self,
         *,
         string: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["string", b"string"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["string", b"string"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["string", b"string"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["string", b"string"]) -> None: ...
 
 global___Quantity = Quantity
```

## armada_client/k8s/io/apimachinery/pkg/apis/meta/v1/generated_pb2.py

```diff
@@ -1,11 +1,11 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: k8s.io/apimachinery/pkg/apis/meta/v1/generated.proto
-# Protobuf Python Version: 4.25.1
+# Protobuf Python Version: 5.26.1
 """Generated protocol buffer code."""
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
 from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
@@ -17,22 +17,22 @@
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n4k8s.io/apimachinery/pkg/apis/meta/v1/generated.proto\x12$k8s.io.apimachinery.pkg.apis.meta.v1\x1a/k8s.io/apimachinery/pkg/runtime/generated.proto\x1a\x36k8s.io/apimachinery/pkg/runtime/schema/generated.proto\"\xa9\x02\n\x08\x41PIGroup\x12\x0c\n\x04name\x18\x01 \x01(\t\x12P\n\x08versions\x18\x02 \x03(\x0b\x32>.k8s.io.apimachinery.pkg.apis.meta.v1.GroupVersionForDiscovery\x12X\n\x10preferredVersion\x18\x03 \x01(\x0b\x32>.k8s.io.apimachinery.pkg.apis.meta.v1.GroupVersionForDiscovery\x12\x63\n\x1aserverAddressByClientCIDRs\x18\x04 \x03(\x0b\x32?.k8s.io.apimachinery.pkg.apis.meta.v1.ServerAddressByClientCIDR\"N\n\x0c\x41PIGroupList\x12>\n\x06groups\x18\x01 \x03(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.APIGroup\"\xf3\x01\n\x0b\x41PIResource\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x14\n\x0csingularName\x18\x06 \x01(\t\x12\x12\n\nnamespaced\x18\x02 \x01(\x08\x12\r\n\x05group\x18\x08 \x01(\t\x12\x0f\n\x07version\x18\t \x01(\t\x12\x0c\n\x04kind\x18\x03 \x01(\t\x12:\n\x05verbs\x18\x04 \x01(\x0b\x32+.k8s.io.apimachinery.pkg.apis.meta.v1.Verbs\x12\x12\n\nshortNames\x18\x05 \x03(\t\x12\x12\n\ncategories\x18\x07 \x03(\t\x12\x1a\n\x12storageVersionHash\x18\n \x01(\t\"m\n\x0f\x41PIResourceList\x12\x14\n\x0cgroupVersion\x18\x01 \x01(\t\x12\x44\n\tresources\x18\x02 \x03(\x0b\x32\x31.k8s.io.apimachinery.pkg.apis.meta.v1.APIResource\"\x84\x01\n\x0b\x41PIVersions\x12\x10\n\x08versions\x18\x01 \x03(\t\x12\x63\n\x1aserverAddressByClientCIDRs\x18\x02 \x03(\x0b\x32?.k8s.io.apimachinery.pkg.apis.meta.v1.ServerAddressByClientCIDR\"C\n\x0c\x41pplyOptions\x12\x0e\n\x06\x64ryRun\x18\x01 \x03(\t\x12\r\n\x05\x66orce\x18\x02 \x01(\x08\x12\x14\n\x0c\x66ieldManager\x18\x03 \x01(\t\"\xae\x01\n\tCondition\x12\x0c\n\x04type\x18\x01 \x01(\t\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x1a\n\x12observedGeneration\x18\x03 \x01(\x03\x12\x46\n\x12lastTransitionTime\x18\x04 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\x12\x0e\n\x06reason\x18\x05 \x01(\t\x12\x0f\n\x07message\x18\x06 \x01(\t\"5\n\rCreateOptions\x12\x0e\n\x06\x64ryRun\x18\x01 \x03(\t\x12\x14\n\x0c\x66ieldManager\x18\x03 \x01(\t\"\xbc\x01\n\rDeleteOptions\x12\x1a\n\x12gracePeriodSeconds\x18\x01 \x01(\x03\x12J\n\rpreconditions\x18\x02 \x01(\x0b\x32\x33.k8s.io.apimachinery.pkg.apis.meta.v1.Preconditions\x12\x18\n\x10orphanDependents\x18\x03 \x01(\x08\x12\x19\n\x11propagationPolicy\x18\x04 \x01(\t\x12\x0e\n\x06\x64ryRun\x18\x05 \x03(\t\"\x1c\n\x08\x44uration\x12\x10\n\x08\x64uration\x18\x01 \x01(\x03\"\x17\n\x08\x46ieldsV1\x12\x0b\n\x03Raw\x18\x01 \x01(\x0c\"%\n\nGetOptions\x12\x17\n\x0fresourceVersion\x18\x01 \x01(\t\"(\n\tGroupKind\x12\r\n\x05group\x18\x01 \x01(\t\x12\x0c\n\x04kind\x18\x02 \x01(\t\"0\n\rGroupResource\x12\r\n\x05group\x18\x01 \x01(\t\x12\x10\n\x08resource\x18\x02 \x01(\t\".\n\x0cGroupVersion\x12\r\n\x05group\x18\x01 \x01(\t\x12\x0f\n\x07version\x18\x02 \x01(\t\"A\n\x18GroupVersionForDiscovery\x12\x14\n\x0cgroupVersion\x18\x01 \x01(\t\x12\x0f\n\x07version\x18\x02 \x01(\t\"@\n\x10GroupVersionKind\x12\r\n\x05group\x18\x01 \x01(\t\x12\x0f\n\x07version\x18\x02 \x01(\t\x12\x0c\n\x04kind\x18\x03 \x01(\t\"H\n\x14GroupVersionResource\x12\r\n\x05group\x18\x01 \x01(\t\x12\x0f\n\x07version\x18\x02 \x01(\t\x12\x10\n\x08resource\x18\x03 \x01(\t\"\xf8\x01\n\rLabelSelector\x12Y\n\x0bmatchLabels\x18\x01 \x03(\x0b\x32\x44.k8s.io.apimachinery.pkg.apis.meta.v1.LabelSelector.MatchLabelsEntry\x12X\n\x10matchExpressions\x18\x02 \x03(\x0b\x32>.k8s.io.apimachinery.pkg.apis.meta.v1.LabelSelectorRequirement\x1a\x32\n\x10MatchLabelsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"I\n\x18LabelSelectorRequirement\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x10\n\x08operator\x18\x02 \x01(\t\x12\x0e\n\x06values\x18\x03 \x03(\t\"\x86\x01\n\x04List\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12<\n\x05items\x18\x02 \x03(\x0b\x32-.k8s.io.apimachinery.pkg.runtime.RawExtension\"c\n\x08ListMeta\x12\x10\n\x08selfLink\x18\x01 \x01(\t\x12\x17\n\x0fresourceVersion\x18\x02 \x01(\t\x12\x10\n\x08\x63ontinue\x18\x03 \x01(\t\x12\x1a\n\x12remainingItemCount\x18\x04 \x01(\x03\"\xd7\x01\n\x0bListOptions\x12\x15\n\rlabelSelector\x18\x01 \x01(\t\x12\x15\n\rfieldSelector\x18\x02 \x01(\t\x12\r\n\x05watch\x18\x03 \x01(\x08\x12\x1b\n\x13\x61llowWatchBookmarks\x18\t \x01(\x08\x12\x17\n\x0fresourceVersion\x18\x04 \x01(\t\x12\x1c\n\x14resourceVersionMatch\x18\n \x01(\t\x12\x16\n\x0etimeoutSeconds\x18\x05 \x01(\x03\x12\r\n\x05limit\x18\x07 \x01(\x03\x12\x10\n\x08\x63ontinue\x18\x08 \x01(\t\"\xf1\x01\n\x12ManagedFieldsEntry\x12\x0f\n\x07manager\x18\x01 \x01(\t\x12\x11\n\toperation\x18\x02 \x01(\t\x12\x12\n\napiVersion\x18\x03 \x01(\t\x12\x38\n\x04time\x18\x04 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\x12\x12\n\nfieldsType\x18\x06 \x01(\t\x12@\n\x08\x66ieldsV1\x18\x07 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.FieldsV1\x12\x13\n\x0bsubresource\x18\x08 \x01(\t\"+\n\tMicroTime\x12\x0f\n\x07seconds\x18\x01 \x01(\x03\x12\r\n\x05nanos\x18\x02 \x01(\x05\"\x93\x06\n\nObjectMeta\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x14\n\x0cgenerateName\x18\x02 \x01(\t\x12\x11\n\tnamespace\x18\x03 \x01(\t\x12\x10\n\x08selfLink\x18\x04 \x01(\t\x12\x0b\n\x03uid\x18\x05 \x01(\t\x12\x17\n\x0fresourceVersion\x18\x06 \x01(\t\x12\x12\n\ngeneration\x18\x07 \x01(\x03\x12\x45\n\x11\x63reationTimestamp\x18\x08 \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\x12\x45\n\x11\x64\x65letionTimestamp\x18\t \x01(\x0b\x32*.k8s.io.apimachinery.pkg.apis.meta.v1.Time\x12\"\n\x1a\x64\x65letionGracePeriodSeconds\x18\n \x01(\x03\x12L\n\x06labels\x18\x0b \x03(\x0b\x32<.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta.LabelsEntry\x12V\n\x0b\x61nnotations\x18\x0c \x03(\x0b\x32\x41.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta.AnnotationsEntry\x12M\n\x0fownerReferences\x18\r \x03(\x0b\x32\x34.k8s.io.apimachinery.pkg.apis.meta.v1.OwnerReference\x12\x12\n\nfinalizers\x18\x0e \x03(\t\x12\x13\n\x0b\x63lusterName\x18\x0f \x01(\t\x12O\n\rmanagedFields\x18\x11 \x03(\x0b\x32\x38.k8s.io.apimachinery.pkg.apis.meta.v1.ManagedFieldsEntry\x1a-\n\x0bLabelsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a\x32\n\x10\x41nnotationsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"}\n\x0eOwnerReference\x12\x12\n\napiVersion\x18\x05 \x01(\t\x12\x0c\n\x04kind\x18\x01 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x0b\n\x03uid\x18\x04 \x01(\t\x12\x12\n\ncontroller\x18\x06 \x01(\x08\x12\x1a\n\x12\x62lockOwnerDeletion\x18\x07 \x01(\x08\"[\n\x15PartialObjectMetadata\x12\x42\n\x08metadata\x18\x01 \x01(\x0b\x32\x30.k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta\"\xa9\x01\n\x19PartialObjectMetadataList\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12J\n\x05items\x18\x02 \x03(\x0b\x32;.k8s.io.apimachinery.pkg.apis.meta.v1.PartialObjectMetadata\"\x07\n\x05Patch\"C\n\x0cPatchOptions\x12\x0e\n\x06\x64ryRun\x18\x01 \x03(\t\x12\r\n\x05\x66orce\x18\x02 \x01(\x08\x12\x14\n\x0c\x66ieldManager\x18\x03 \x01(\t\"5\n\rPreconditions\x12\x0b\n\x03uid\x18\x01 \x01(\t\x12\x17\n\x0fresourceVersion\x18\x02 \x01(\t\"\x1a\n\tRootPaths\x12\r\n\x05paths\x18\x01 \x03(\t\"F\n\x19ServerAddressByClientCIDR\x12\x12\n\nclientCIDR\x18\x01 \x01(\t\x12\x15\n\rserverAddress\x18\x02 \x01(\t\"\xcf\x01\n\x06Status\x12@\n\x08metadata\x18\x01 \x01(\x0b\x32..k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x0f\n\x07message\x18\x03 \x01(\t\x12\x0e\n\x06reason\x18\x04 \x01(\t\x12\x44\n\x07\x64\x65tails\x18\x05 \x01(\x0b\x32\x33.k8s.io.apimachinery.pkg.apis.meta.v1.StatusDetails\x12\x0c\n\x04\x63ode\x18\x06 \x01(\x05\"=\n\x0bStatusCause\x12\x0e\n\x06reason\x18\x01 \x01(\t\x12\x0f\n\x07message\x18\x02 \x01(\t\x12\r\n\x05\x66ield\x18\x03 \x01(\t\"\xa5\x01\n\rStatusDetails\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\r\n\x05group\x18\x02 \x01(\t\x12\x0c\n\x04kind\x18\x03 \x01(\t\x12\x0b\n\x03uid\x18\x06 \x01(\t\x12\x41\n\x06\x63\x61uses\x18\x04 \x03(\x0b\x32\x31.k8s.io.apimachinery.pkg.apis.meta.v1.StatusCause\x12\x19\n\x11retryAfterSeconds\x18\x05 \x01(\x05\"%\n\x0cTableOptions\x12\x15\n\rincludeObject\x18\x01 \x01(\t\"&\n\x04Time\x12\x0f\n\x07seconds\x18\x01 \x01(\x03\x12\r\n\x05nanos\x18\x02 \x01(\x05\"+\n\tTimestamp\x12\x0f\n\x07seconds\x18\x01 \x01(\x03\x12\r\n\x05nanos\x18\x02 \x01(\x05\",\n\x08TypeMeta\x12\x0c\n\x04kind\x18\x01 \x01(\t\x12\x12\n\napiVersion\x18\x02 \x01(\t\"5\n\rUpdateOptions\x12\x0e\n\x06\x64ryRun\x18\x01 \x03(\t\x12\x14\n\x0c\x66ieldManager\x18\x02 \x01(\t\"\x16\n\x05Verbs\x12\r\n\x05items\x18\x01 \x03(\t\"Y\n\nWatchEvent\x12\x0c\n\x04type\x18\x01 \x01(\t\x12=\n\x06object\x18\x02 \x01(\x0b\x32-.k8s.io.apimachinery.pkg.runtime.RawExtensionB\x04Z\x02v1')
 
 _globals = globals()
 _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
 _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'k8s.io.apimachinery.pkg.apis.meta.v1.generated_pb2', _globals)
-if _descriptor._USE_C_DESCRIPTORS == False:
-  _globals['DESCRIPTOR']._options = None
+if not _descriptor._USE_C_DESCRIPTORS:
+  _globals['DESCRIPTOR']._loaded_options = None
   _globals['DESCRIPTOR']._serialized_options = b'Z\002v1'
-  _globals['_LABELSELECTOR_MATCHLABELSENTRY']._options = None
+  _globals['_LABELSELECTOR_MATCHLABELSENTRY']._loaded_options = None
   _globals['_LABELSELECTOR_MATCHLABELSENTRY']._serialized_options = b'8\001'
-  _globals['_OBJECTMETA_LABELSENTRY']._options = None
+  _globals['_OBJECTMETA_LABELSENTRY']._loaded_options = None
   _globals['_OBJECTMETA_LABELSENTRY']._serialized_options = b'8\001'
-  _globals['_OBJECTMETA_ANNOTATIONSENTRY']._options = None
+  _globals['_OBJECTMETA_ANNOTATIONSENTRY']._loaded_options = None
   _globals['_OBJECTMETA_ANNOTATIONSENTRY']._serialized_options = b'8\001'
   _globals['_APIGROUP']._serialized_start=200
   _globals['_APIGROUP']._serialized_end=497
   _globals['_APIGROUPLIST']._serialized_start=499
   _globals['_APIGROUPLIST']._serialized_end=577
   _globals['_APIRESOURCE']._serialized_start=580
   _globals['_APIRESOURCE']._serialized_end=823
```

## armada_client/k8s/io/apimachinery/pkg/apis/meta/v1/generated_pb2.pyi

```diff
@@ -1,27 +1,23 @@
 """
 @generated by mypy-protobuf.  Do not edit manually!
 isort:skip_file
 This file was autogenerated by go-to-protobuf. Do not edit it manually!"""
+
 import builtins
 import collections.abc
 import google.protobuf.descriptor
 import google.protobuf.internal.containers
 import google.protobuf.message
 import armada_client.k8s.io.apimachinery.pkg.runtime.generated_pb2
-import sys
-
-if sys.version_info >= (3, 8):
-    import typing as typing_extensions
-else:
-    import typing_extensions
+import typing
 
 DESCRIPTOR: google.protobuf.descriptor.FileDescriptor
 
-@typing_extensions.final
+@typing.final
 class APIGroup(google.protobuf.message.Message):
     """APIGroup contains the name, the supported versions, and the preferred version
     of a group.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -30,66 +26,70 @@
     PREFERREDVERSION_FIELD_NUMBER: builtins.int
     SERVERADDRESSBYCLIENTCIDRS_FIELD_NUMBER: builtins.int
     name: builtins.str
     """name is the name of the group."""
     @property
     def versions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___GroupVersionForDiscovery]:
         """versions are the versions supported in this group."""
+
     @property
     def preferredVersion(self) -> global___GroupVersionForDiscovery:
         """preferredVersion is the version preferred by the API server, which
         probably is the storage version.
         +optional
         """
+
     @property
     def serverAddressByClientCIDRs(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ServerAddressByClientCIDR]:
         """a map of client CIDR to server address that is serving this group.
         This is to help clients reach servers in the most network-efficient way possible.
         Clients can use the appropriate server address as per the CIDR that they match.
         In case of multiple matches, clients should use the longest matching CIDR.
         The server returns only those CIDRs that it thinks that the client can match.
         For example: the master will return an internal IP CIDR only, if the client reaches the server using an internal IP.
         Server looks at X-Forwarded-For header or X-Real-Ip header or request.RemoteAddr (in that order) to get the client IP.
         +optional
         """
+
     def __init__(
         self,
         *,
         name: builtins.str | None = ...,
         versions: collections.abc.Iterable[global___GroupVersionForDiscovery] | None = ...,
         preferredVersion: global___GroupVersionForDiscovery | None = ...,
         serverAddressByClientCIDRs: collections.abc.Iterable[global___ServerAddressByClientCIDR] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["name", b"name", "preferredVersion", b"preferredVersion"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["name", b"name", "preferredVersion", b"preferredVersion", "serverAddressByClientCIDRs", b"serverAddressByClientCIDRs", "versions", b"versions"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["name", b"name", "preferredVersion", b"preferredVersion"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["name", b"name", "preferredVersion", b"preferredVersion", "serverAddressByClientCIDRs", b"serverAddressByClientCIDRs", "versions", b"versions"]) -> None: ...
 
 global___APIGroup = APIGroup
 
-@typing_extensions.final
+@typing.final
 class APIGroupList(google.protobuf.message.Message):
     """APIGroupList is a list of APIGroup, to allow clients to discover the API at
     /apis.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     GROUPS_FIELD_NUMBER: builtins.int
     @property
     def groups(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___APIGroup]:
         """groups is a list of APIGroup."""
+
     def __init__(
         self,
         *,
         groups: collections.abc.Iterable[global___APIGroup] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["groups", b"groups"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["groups", b"groups"]) -> None: ...
 
 global___APIGroupList = APIGroupList
 
-@typing_extensions.final
+@typing.final
 class APIResource(google.protobuf.message.Message):
     """APIResource specifies the name of a resource and whether it is namespaced."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAME_FIELD_NUMBER: builtins.int
     SINGULARNAME_FIELD_NUMBER: builtins.int
@@ -116,55 +116,58 @@
     """
     version: builtins.str
     """version is the preferred version of the resource.  Empty implies the version of the containing resource list
     For subresources, this may have a different value, for example: v1 (while inside a v1beta1 version of the core resource's group)".
     """
     kind: builtins.str
     """kind is the kind for the resource (e.g. 'Foo' is the kind for a resource 'foo')"""
+    storageVersionHash: builtins.str
+    """The hash value of the storage version, the version this resource is
+    converted to when written to the data store. Value must be treated
+    as opaque by clients. Only equality comparison on the value is valid.
+    This is an alpha feature and may change or be removed in the future.
+    The field is populated by the apiserver only if the
+    StorageVersionHash feature gate is enabled.
+    This field will remain optional even if it graduates.
+    +optional
+    """
     @property
     def verbs(self) -> global___Verbs:
         """verbs is a list of supported kube verbs (this includes get, list, watch, create,
         update, patch, delete, deletecollection, and proxy)
         """
+
     @property
     def shortNames(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """shortNames is a list of suggested short names of the resource."""
+
     @property
     def categories(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """categories is a list of the grouped resources this resource belongs to (e.g. 'all')"""
-    storageVersionHash: builtins.str
-    """The hash value of the storage version, the version this resource is
-    converted to when written to the data store. Value must be treated
-    as opaque by clients. Only equality comparison on the value is valid.
-    This is an alpha feature and may change or be removed in the future.
-    The field is populated by the apiserver only if the
-    StorageVersionHash feature gate is enabled.
-    This field will remain optional even if it graduates.
-    +optional
-    """
+
     def __init__(
         self,
         *,
         name: builtins.str | None = ...,
         singularName: builtins.str | None = ...,
         namespaced: builtins.bool | None = ...,
         group: builtins.str | None = ...,
         version: builtins.str | None = ...,
         kind: builtins.str | None = ...,
         verbs: global___Verbs | None = ...,
         shortNames: collections.abc.Iterable[builtins.str] | None = ...,
         categories: collections.abc.Iterable[builtins.str] | None = ...,
         storageVersionHash: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["group", b"group", "kind", b"kind", "name", b"name", "namespaced", b"namespaced", "singularName", b"singularName", "storageVersionHash", b"storageVersionHash", "verbs", b"verbs", "version", b"version"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["categories", b"categories", "group", b"group", "kind", b"kind", "name", b"name", "namespaced", b"namespaced", "shortNames", b"shortNames", "singularName", b"singularName", "storageVersionHash", b"storageVersionHash", "verbs", b"verbs", "version", b"version"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["group", b"group", "kind", b"kind", "name", b"name", "namespaced", b"namespaced", "singularName", b"singularName", "storageVersionHash", b"storageVersionHash", "verbs", b"verbs", "version", b"version"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["categories", b"categories", "group", b"group", "kind", b"kind", "name", b"name", "namespaced", b"namespaced", "shortNames", b"shortNames", "singularName", b"singularName", "storageVersionHash", b"storageVersionHash", "verbs", b"verbs", "version", b"version"]) -> None: ...
 
 global___APIResource = APIResource
 
-@typing_extensions.final
+@typing.final
 class APIResourceList(google.protobuf.message.Message):
     """APIResourceList is a list of APIResource, it is used to expose the name of the
     resources supported in a specific group and version, and if the resource
     is namespaced.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -172,26 +175,27 @@
     GROUPVERSION_FIELD_NUMBER: builtins.int
     RESOURCES_FIELD_NUMBER: builtins.int
     groupVersion: builtins.str
     """groupVersion is the group and version this APIResourceList is for."""
     @property
     def resources(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___APIResource]:
         """resources contains the name of the resources and if they are namespaced."""
+
     def __init__(
         self,
         *,
         groupVersion: builtins.str | None = ...,
         resources: collections.abc.Iterable[global___APIResource] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["groupVersion", b"groupVersion"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["groupVersion", b"groupVersion", "resources", b"resources"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["groupVersion", b"groupVersion"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["groupVersion", b"groupVersion", "resources", b"resources"]) -> None: ...
 
 global___APIResourceList = APIResourceList
 
-@typing_extensions.final
+@typing.final
 class APIVersions(google.protobuf.message.Message):
     """APIVersions lists the versions that are available, to allow clients to
     discover the API at /api, which is the root path of the legacy v1 API.
 
     +protobuf.options.(gogoproto.goproto_stringer)=false
     +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object
     """
@@ -199,80 +203,83 @@
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     VERSIONS_FIELD_NUMBER: builtins.int
     SERVERADDRESSBYCLIENTCIDRS_FIELD_NUMBER: builtins.int
     @property
     def versions(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """versions are the api versions that are available."""
+
     @property
     def serverAddressByClientCIDRs(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ServerAddressByClientCIDR]:
         """a map of client CIDR to server address that is serving this group.
         This is to help clients reach servers in the most network-efficient way possible.
         Clients can use the appropriate server address as per the CIDR that they match.
         In case of multiple matches, clients should use the longest matching CIDR.
         The server returns only those CIDRs that it thinks that the client can match.
         For example: the master will return an internal IP CIDR only, if the client reaches the server using an internal IP.
         Server looks at X-Forwarded-For header or X-Real-Ip header or request.RemoteAddr (in that order) to get the client IP.
         """
+
     def __init__(
         self,
         *,
         versions: collections.abc.Iterable[builtins.str] | None = ...,
         serverAddressByClientCIDRs: collections.abc.Iterable[global___ServerAddressByClientCIDR] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["serverAddressByClientCIDRs", b"serverAddressByClientCIDRs", "versions", b"versions"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["serverAddressByClientCIDRs", b"serverAddressByClientCIDRs", "versions", b"versions"]) -> None: ...
 
 global___APIVersions = APIVersions
 
-@typing_extensions.final
+@typing.final
 class ApplyOptions(google.protobuf.message.Message):
     """ApplyOptions may be provided when applying an API object.
     FieldManager is required for apply requests.
     ApplyOptions is equivalent to PatchOptions. It is provided as a convenience with documentation
     that speaks specifically to how the options fields relate to apply.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     DRYRUN_FIELD_NUMBER: builtins.int
     FORCE_FIELD_NUMBER: builtins.int
     FIELDMANAGER_FIELD_NUMBER: builtins.int
-    @property
-    def dryRun(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
-        """When present, indicates that modifications should not be
-        persisted. An invalid or unrecognized dryRun directive will
-        result in an error response and no further processing of the
-        request. Valid values are:
-        - All: all dry run stages will be processed
-        +optional
-        """
     force: builtins.bool
     """Force is going to "force" Apply requests. It means user will
     re-acquire conflicting fields owned by other people.
     """
     fieldManager: builtins.str
     """fieldManager is a name associated with the actor or entity
     that is making these changes. The value must be less than or
     128 characters long, and only contain printable characters,
     as defined by https://golang.org/pkg/unicode/#IsPrint. This
     field is required.
     """
+    @property
+    def dryRun(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
+        """When present, indicates that modifications should not be
+        persisted. An invalid or unrecognized dryRun directive will
+        result in an error response and no further processing of the
+        request. Valid values are:
+        - All: all dry run stages will be processed
+        +optional
+        """
+
     def __init__(
         self,
         *,
         dryRun: collections.abc.Iterable[builtins.str] | None = ...,
         force: builtins.bool | None = ...,
         fieldManager: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fieldManager", b"fieldManager", "force", b"force"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["dryRun", b"dryRun", "fieldManager", b"fieldManager", "force", b"force"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fieldManager", b"fieldManager", "force", b"force"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["dryRun", b"dryRun", "fieldManager", b"fieldManager", "force", b"force"]) -> None: ...
 
 global___ApplyOptions = ApplyOptions
 
-@typing_extensions.final
+@typing.final
 class Condition(google.protobuf.message.Message):
     """Condition contains details for one aspect of the current state of this API Resource.
     ---
     This struct is intended for direct use as an array at the field path .status.conditions.  For example,
     type FooStatus struct{
         // Represents the observations of a foo's current state.
         // Known .status.conditions.type are: "Available", "Progressing", and "Degraded"
@@ -314,23 +321,14 @@
     observedGeneration: builtins.int
     """observedGeneration represents the .metadata.generation that the condition was set based upon.
     For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date
     with respect to the current state of the instance.
     +optional
     +kubebuilder:validation:Minimum=0
     """
-    @property
-    def lastTransitionTime(self) -> global___Time:
-        """lastTransitionTime is the last time the condition transitioned from one status to another.
-        This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.
-        +required
-        +kubebuilder:validation:Required
-        +kubebuilder:validation:Type=string
-        +kubebuilder:validation:Format=date-time
-        """
     reason: builtins.str
     """reason contains a programmatic identifier indicating the reason for the condition's last transition.
     Producers of specific condition types may define expected values and meanings for this field,
     and whether the values are considered a guaranteed API.
     The value should be a CamelCase string.
     This field may not be empty.
     +required
@@ -342,65 +340,76 @@
     message: builtins.str
     """message is a human readable message indicating details about the transition.
     This may be an empty string.
     +required
     +kubebuilder:validation:Required
     +kubebuilder:validation:MaxLength=32768
     """
+    @property
+    def lastTransitionTime(self) -> global___Time:
+        """lastTransitionTime is the last time the condition transitioned from one status to another.
+        This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.
+        +required
+        +kubebuilder:validation:Required
+        +kubebuilder:validation:Type=string
+        +kubebuilder:validation:Format=date-time
+        """
+
     def __init__(
         self,
         *,
         type: builtins.str | None = ...,
         status: builtins.str | None = ...,
         observedGeneration: builtins.int | None = ...,
         lastTransitionTime: global___Time | None = ...,
         reason: builtins.str | None = ...,
         message: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["lastTransitionTime", b"lastTransitionTime", "message", b"message", "observedGeneration", b"observedGeneration", "reason", b"reason", "status", b"status", "type", b"type"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["lastTransitionTime", b"lastTransitionTime", "message", b"message", "observedGeneration", b"observedGeneration", "reason", b"reason", "status", b"status", "type", b"type"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["lastTransitionTime", b"lastTransitionTime", "message", b"message", "observedGeneration", b"observedGeneration", "reason", b"reason", "status", b"status", "type", b"type"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["lastTransitionTime", b"lastTransitionTime", "message", b"message", "observedGeneration", b"observedGeneration", "reason", b"reason", "status", b"status", "type", b"type"]) -> None: ...
 
 global___Condition = Condition
 
-@typing_extensions.final
+@typing.final
 class CreateOptions(google.protobuf.message.Message):
     """CreateOptions may be provided when creating an API object."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     DRYRUN_FIELD_NUMBER: builtins.int
     FIELDMANAGER_FIELD_NUMBER: builtins.int
+    fieldManager: builtins.str
+    """fieldManager is a name associated with the actor or entity
+    that is making these changes. The value must be less than or
+    128 characters long, and only contain printable characters,
+    as defined by https://golang.org/pkg/unicode/#IsPrint.
+    +optional
+    """
     @property
     def dryRun(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """When present, indicates that modifications should not be
         persisted. An invalid or unrecognized dryRun directive will
         result in an error response and no further processing of the
         request. Valid values are:
         - All: all dry run stages will be processed
         +optional
         """
-    fieldManager: builtins.str
-    """fieldManager is a name associated with the actor or entity
-    that is making these changes. The value must be less than or
-    128 characters long, and only contain printable characters,
-    as defined by https://golang.org/pkg/unicode/#IsPrint.
-    +optional
-    """
+
     def __init__(
         self,
         *,
         dryRun: collections.abc.Iterable[builtins.str] | None = ...,
         fieldManager: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fieldManager", b"fieldManager"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["dryRun", b"dryRun", "fieldManager", b"fieldManager"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fieldManager", b"fieldManager"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["dryRun", b"dryRun", "fieldManager", b"fieldManager"]) -> None: ...
 
 global___CreateOptions = CreateOptions
 
-@typing_extensions.final
+@typing.final
 class DeleteOptions(google.protobuf.message.Message):
     """DeleteOptions may be provided when deleting an API object."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     GRACEPERIODSECONDS_FIELD_NUMBER: builtins.int
     PRECONDITIONS_FIELD_NUMBER: builtins.int
@@ -410,21 +419,14 @@
     gracePeriodSeconds: builtins.int
     """The duration in seconds before the object should be deleted. Value must be non-negative integer.
     The value zero indicates delete immediately. If this value is nil, the default grace period for the
     specified type will be used.
     Defaults to a per object value if not specified. zero means delete immediately.
     +optional
     """
-    @property
-    def preconditions(self) -> global___Preconditions:
-        """Must be fulfilled before a deletion is carried out. If not possible, a 409 Conflict status will be
-        returned.
-        +k8s:conversion-gen=false
-        +optional
-        """
     orphanDependents: builtins.bool
     """Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7.
     Should the dependent objects be orphaned. If true/false, the "orphan"
     finalizer will be added to/removed from the object's finalizers list.
     Either this field or PropagationPolicy may be set, but not both.
     +optional
     """
@@ -436,37 +438,46 @@
     Acceptable values are: 'Orphan' - orphan the dependents; 'Background' -
     allow the garbage collector to delete the dependents in the background;
     'Foreground' - a cascading policy that deletes all dependents in the
     foreground.
     +optional
     """
     @property
+    def preconditions(self) -> global___Preconditions:
+        """Must be fulfilled before a deletion is carried out. If not possible, a 409 Conflict status will be
+        returned.
+        +k8s:conversion-gen=false
+        +optional
+        """
+
+    @property
     def dryRun(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """When present, indicates that modifications should not be
         persisted. An invalid or unrecognized dryRun directive will
         result in an error response and no further processing of the
         request. Valid values are:
         - All: all dry run stages will be processed
         +optional
         """
+
     def __init__(
         self,
         *,
         gracePeriodSeconds: builtins.int | None = ...,
         preconditions: global___Preconditions | None = ...,
         orphanDependents: builtins.bool | None = ...,
         propagationPolicy: builtins.str | None = ...,
         dryRun: collections.abc.Iterable[builtins.str] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["gracePeriodSeconds", b"gracePeriodSeconds", "orphanDependents", b"orphanDependents", "preconditions", b"preconditions", "propagationPolicy", b"propagationPolicy"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["dryRun", b"dryRun", "gracePeriodSeconds", b"gracePeriodSeconds", "orphanDependents", b"orphanDependents", "preconditions", b"preconditions", "propagationPolicy", b"propagationPolicy"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["gracePeriodSeconds", b"gracePeriodSeconds", "orphanDependents", b"orphanDependents", "preconditions", b"preconditions", "propagationPolicy", b"propagationPolicy"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["dryRun", b"dryRun", "gracePeriodSeconds", b"gracePeriodSeconds", "orphanDependents", b"orphanDependents", "preconditions", b"preconditions", "propagationPolicy", b"propagationPolicy"]) -> None: ...
 
 global___DeleteOptions = DeleteOptions
 
-@typing_extensions.final
+@typing.final
 class Duration(google.protobuf.message.Message):
     """Duration is a wrapper around time.Duration which supports correct
     marshaling to YAML and JSON. In particular, it marshals into strings, which
     can be used as map keys in json.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -474,20 +485,20 @@
     DURATION_FIELD_NUMBER: builtins.int
     duration: builtins.int
     def __init__(
         self,
         *,
         duration: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["duration", b"duration"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["duration", b"duration"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["duration", b"duration"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["duration", b"duration"]) -> None: ...
 
 global___Duration = Duration
 
-@typing_extensions.final
+@typing.final
 class FieldsV1(google.protobuf.message.Message):
     """FieldsV1 stores a set of fields in a data structure like a Trie, in JSON format.
 
     Each key is either a '.' representing the field itself, and will always map to an empty set,
     or a string representing a sub-field or item. The string will follow one of these four formats:
     'f:<name>', where <name> is the name of a field in a struct, or key in a map
     'v:<value>', where <value> is the exact json formatted value of a list item
@@ -505,20 +516,20 @@
     Raw: builtins.bytes
     """Raw is the underlying serialization of this object."""
     def __init__(
         self,
         *,
         Raw: builtins.bytes | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["Raw", b"Raw"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["Raw", b"Raw"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["Raw", b"Raw"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["Raw", b"Raw"]) -> None: ...
 
 global___FieldsV1 = FieldsV1
 
-@typing_extensions.final
+@typing.final
 class GetOptions(google.protobuf.message.Message):
     """GetOptions is the standard query options to the standard REST get call."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     RESOURCEVERSION_FIELD_NUMBER: builtins.int
     resourceVersion: builtins.str
@@ -530,20 +541,20 @@
     +optional
     """
     def __init__(
         self,
         *,
         resourceVersion: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["resourceVersion", b"resourceVersion"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["resourceVersion", b"resourceVersion"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["resourceVersion", b"resourceVersion"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["resourceVersion", b"resourceVersion"]) -> None: ...
 
 global___GetOptions = GetOptions
 
-@typing_extensions.final
+@typing.final
 class GroupKind(google.protobuf.message.Message):
     """GroupKind specifies a Group and a Kind, but does not force a version.  This is useful for identifying
     concepts during lookup stages without having partially valid types
 
     +protobuf.options.(gogoproto.goproto_stringer)=false
     """
 
@@ -555,20 +566,20 @@
     kind: builtins.str
     def __init__(
         self,
         *,
         group: builtins.str | None = ...,
         kind: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["group", b"group", "kind", b"kind"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["group", b"group", "kind", b"kind"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["group", b"group", "kind", b"kind"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["group", b"group", "kind", b"kind"]) -> None: ...
 
 global___GroupKind = GroupKind
 
-@typing_extensions.final
+@typing.final
 class GroupResource(google.protobuf.message.Message):
     """GroupResource specifies a Group and a Resource, but does not force a version.  This is useful for identifying
     concepts during lookup stages without having partially valid types
 
     +protobuf.options.(gogoproto.goproto_stringer)=false
     """
 
@@ -580,20 +591,20 @@
     resource: builtins.str
     def __init__(
         self,
         *,
         group: builtins.str | None = ...,
         resource: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["group", b"group", "resource", b"resource"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["group", b"group", "resource", b"resource"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["group", b"group", "resource", b"resource"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["group", b"group", "resource", b"resource"]) -> None: ...
 
 global___GroupResource = GroupResource
 
-@typing_extensions.final
+@typing.final
 class GroupVersion(google.protobuf.message.Message):
     """GroupVersion contains the "group" and the "version", which uniquely identifies the API.
 
     +protobuf.options.(gogoproto.goproto_stringer)=false
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -604,20 +615,20 @@
     version: builtins.str
     def __init__(
         self,
         *,
         group: builtins.str | None = ...,
         version: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["group", b"group", "version", b"version"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["group", b"group", "version", b"version"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["group", b"group", "version", b"version"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["group", b"group", "version", b"version"]) -> None: ...
 
 global___GroupVersion = GroupVersion
 
-@typing_extensions.final
+@typing.final
 class GroupVersionForDiscovery(google.protobuf.message.Message):
     """GroupVersion contains the "group/version" and "version" string of a version.
     It is made a struct to keep extensibility.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -631,20 +642,20 @@
     """
     def __init__(
         self,
         *,
         groupVersion: builtins.str | None = ...,
         version: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["groupVersion", b"groupVersion", "version", b"version"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["groupVersion", b"groupVersion", "version", b"version"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["groupVersion", b"groupVersion", "version", b"version"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["groupVersion", b"groupVersion", "version", b"version"]) -> None: ...
 
 global___GroupVersionForDiscovery = GroupVersionForDiscovery
 
-@typing_extensions.final
+@typing.final
 class GroupVersionKind(google.protobuf.message.Message):
     """GroupVersionKind unambiguously identifies a kind.  It doesn't anonymously include GroupVersion
     to avoid automatic coersion.  It doesn't use a GroupVersion to avoid custom marshalling
 
     +protobuf.options.(gogoproto.goproto_stringer)=false
     """
 
@@ -659,20 +670,20 @@
     def __init__(
         self,
         *,
         group: builtins.str | None = ...,
         version: builtins.str | None = ...,
         kind: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["group", b"group", "kind", b"kind", "version", b"version"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["group", b"group", "kind", b"kind", "version", b"version"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["group", b"group", "kind", b"kind", "version", b"version"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["group", b"group", "kind", b"kind", "version", b"version"]) -> None: ...
 
 global___GroupVersionKind = GroupVersionKind
 
-@typing_extensions.final
+@typing.final
 class GroupVersionResource(google.protobuf.message.Message):
     """GroupVersionResource unambiguously identifies a resource.  It doesn't anonymously include GroupVersion
     to avoid automatic coersion.  It doesn't use a GroupVersion to avoid custom marshalling
 
     +protobuf.options.(gogoproto.goproto_stringer)=false
     """
 
@@ -687,71 +698,73 @@
     def __init__(
         self,
         *,
         group: builtins.str | None = ...,
         version: builtins.str | None = ...,
         resource: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["group", b"group", "resource", b"resource", "version", b"version"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["group", b"group", "resource", b"resource", "version", b"version"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["group", b"group", "resource", b"resource", "version", b"version"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["group", b"group", "resource", b"resource", "version", b"version"]) -> None: ...
 
 global___GroupVersionResource = GroupVersionResource
 
-@typing_extensions.final
+@typing.final
 class LabelSelector(google.protobuf.message.Message):
     """A label selector is a label query over a set of resources. The result of matchLabels and
     matchExpressions are ANDed. An empty label selector matches all objects. A null
     label selector matches no objects.
     +structType=atomic
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class MatchLabelsEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: builtins.str | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     MATCHLABELS_FIELD_NUMBER: builtins.int
     MATCHEXPRESSIONS_FIELD_NUMBER: builtins.int
     @property
     def matchLabels(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]:
         """matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
         map is equivalent to an element of matchExpressions, whose key field is "key", the
         operator is "In", and the values array contains only "value". The requirements are ANDed.
         +optional
         """
+
     @property
     def matchExpressions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___LabelSelectorRequirement]:
         """matchExpressions is a list of label selector requirements. The requirements are ANDed.
         +optional
         """
+
     def __init__(
         self,
         *,
         matchLabels: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
         matchExpressions: collections.abc.Iterable[global___LabelSelectorRequirement] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["matchExpressions", b"matchExpressions", "matchLabels", b"matchLabels"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["matchExpressions", b"matchExpressions", "matchLabels", b"matchLabels"]) -> None: ...
 
 global___LabelSelector = LabelSelector
 
-@typing_extensions.final
+@typing.final
 class LabelSelectorRequirement(google.protobuf.message.Message):
     """A label selector requirement is a selector that contains values, a key, and an operator that
     relates the key and values.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -771,55 +784,58 @@
     def values(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """values is an array of string values. If the operator is In or NotIn,
         the values array must be non-empty. If the operator is Exists or DoesNotExist,
         the values array must be empty. This array is replaced during a strategic
         merge patch.
         +optional
         """
+
     def __init__(
         self,
         *,
         key: builtins.str | None = ...,
         operator: builtins.str | None = ...,
         values: collections.abc.Iterable[builtins.str] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["key", b"key", "operator", b"operator"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "operator", b"operator", "values", b"values"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["key", b"key", "operator", b"operator"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["key", b"key", "operator", b"operator", "values", b"values"]) -> None: ...
 
 global___LabelSelectorRequirement = LabelSelectorRequirement
 
-@typing_extensions.final
+@typing.final
 class List(google.protobuf.message.Message):
     """List holds a list of objects, which may not be known by the server."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> global___ListMeta:
         """Standard list metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[armada_client.k8s.io.apimachinery.pkg.runtime.generated_pb2.RawExtension]:
         """List of objects"""
+
     def __init__(
         self,
         *,
         metadata: global___ListMeta | None = ...,
         items: collections.abc.Iterable[armada_client.k8s.io.apimachinery.pkg.runtime.generated_pb2.RawExtension] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___List = List
 
-@typing_extensions.final
+@typing.final
 class ListMeta(google.protobuf.message.Message):
     """ListMeta describes metadata that synthetic resources must have, including lists and
     various status objects. A resource may have only one of {ObjectMeta, ListMeta}.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -861,20 +877,20 @@
     def __init__(
         self,
         *,
         selfLink: builtins.str | None = ...,
         resourceVersion: builtins.str | None = ...,
         remainingItemCount: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["continue", b"continue", "remainingItemCount", b"remainingItemCount", "resourceVersion", b"resourceVersion", "selfLink", b"selfLink"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["continue", b"continue", "remainingItemCount", b"remainingItemCount", "resourceVersion", b"resourceVersion", "selfLink", b"selfLink"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["continue", b"continue", "remainingItemCount", b"remainingItemCount", "resourceVersion", b"resourceVersion", "selfLink", b"selfLink"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["continue", b"continue", "remainingItemCount", b"remainingItemCount", "resourceVersion", b"resourceVersion", "selfLink", b"selfLink"]) -> None: ...
 
 global___ListMeta = ListMeta
 
-@typing_extensions.final
+@typing.final
 class ListOptions(google.protobuf.message.Message):
     """ListOptions is the query options to a standard REST list call."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     LABELSELECTOR_FIELD_NUMBER: builtins.int
     FIELDSELECTOR_FIELD_NUMBER: builtins.int
@@ -958,20 +974,20 @@
         watch: builtins.bool | None = ...,
         allowWatchBookmarks: builtins.bool | None = ...,
         resourceVersion: builtins.str | None = ...,
         resourceVersionMatch: builtins.str | None = ...,
         timeoutSeconds: builtins.int | None = ...,
         limit: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["allowWatchBookmarks", b"allowWatchBookmarks", "continue", b"continue", "fieldSelector", b"fieldSelector", "labelSelector", b"labelSelector", "limit", b"limit", "resourceVersion", b"resourceVersion", "resourceVersionMatch", b"resourceVersionMatch", "timeoutSeconds", b"timeoutSeconds", "watch", b"watch"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["allowWatchBookmarks", b"allowWatchBookmarks", "continue", b"continue", "fieldSelector", b"fieldSelector", "labelSelector", b"labelSelector", "limit", b"limit", "resourceVersion", b"resourceVersion", "resourceVersionMatch", b"resourceVersionMatch", "timeoutSeconds", b"timeoutSeconds", "watch", b"watch"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["allowWatchBookmarks", b"allowWatchBookmarks", "continue", b"continue", "fieldSelector", b"fieldSelector", "labelSelector", b"labelSelector", "limit", b"limit", "resourceVersion", b"resourceVersion", "resourceVersionMatch", b"resourceVersionMatch", "timeoutSeconds", b"timeoutSeconds", "watch", b"watch"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["allowWatchBookmarks", b"allowWatchBookmarks", "continue", b"continue", "fieldSelector", b"fieldSelector", "labelSelector", b"labelSelector", "limit", b"limit", "resourceVersion", b"resourceVersion", "resourceVersionMatch", b"resourceVersionMatch", "timeoutSeconds", b"timeoutSeconds", "watch", b"watch"]) -> None: ...
 
 global___ListOptions = ListOptions
 
-@typing_extensions.final
+@typing.final
 class ManagedFieldsEntry(google.protobuf.message.Message):
     """ManagedFieldsEntry is a workflow-id, a FieldSet and the group version of the resource
     that the fieldset applies to.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -990,54 +1006,56 @@
     """
     apiVersion: builtins.str
     """APIVersion defines the version of this resource that this field set
     applies to. The format is "group/version" just like the top-level
     APIVersion field. It is necessary to track the version of a field
     set because it cannot be automatically converted.
     """
-    @property
-    def time(self) -> global___Time:
-        """Time is timestamp of when these fields were set. It should always be empty if Operation is 'Apply'
-        +optional
-        """
     fieldsType: builtins.str
     """FieldsType is the discriminator for the different fields format and version.
     There is currently only one possible value: "FieldsV1"
     """
-    @property
-    def fieldsV1(self) -> global___FieldsV1:
-        """FieldsV1 holds the first JSON version format as described in the "FieldsV1" type.
-        +optional
-        """
     subresource: builtins.str
     """Subresource is the name of the subresource used to update that object, or
     empty string if the object was updated through the main resource. The
     value of this field is used to distinguish between managers, even if they
     share the same name. For example, a status update will be distinct from a
     regular update using the same manager name.
     Note that the APIVersion field is not related to the Subresource field and
     it always corresponds to the version of the main resource.
     """
+    @property
+    def time(self) -> global___Time:
+        """Time is timestamp of when these fields were set. It should always be empty if Operation is 'Apply'
+        +optional
+        """
+
+    @property
+    def fieldsV1(self) -> global___FieldsV1:
+        """FieldsV1 holds the first JSON version format as described in the "FieldsV1" type.
+        +optional
+        """
+
     def __init__(
         self,
         *,
         manager: builtins.str | None = ...,
         operation: builtins.str | None = ...,
         apiVersion: builtins.str | None = ...,
         time: global___Time | None = ...,
         fieldsType: builtins.str | None = ...,
         fieldsV1: global___FieldsV1 | None = ...,
         subresource: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["apiVersion", b"apiVersion", "fieldsType", b"fieldsType", "fieldsV1", b"fieldsV1", "manager", b"manager", "operation", b"operation", "subresource", b"subresource", "time", b"time"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["apiVersion", b"apiVersion", "fieldsType", b"fieldsType", "fieldsV1", b"fieldsV1", "manager", b"manager", "operation", b"operation", "subresource", b"subresource", "time", b"time"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["apiVersion", b"apiVersion", "fieldsType", b"fieldsType", "fieldsV1", b"fieldsV1", "manager", b"manager", "operation", b"operation", "subresource", b"subresource", "time", b"time"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["apiVersion", b"apiVersion", "fieldsType", b"fieldsType", "fieldsV1", b"fieldsV1", "manager", b"manager", "operation", b"operation", "subresource", b"subresource", "time", b"time"]) -> None: ...
 
 global___ManagedFieldsEntry = ManagedFieldsEntry
 
-@typing_extensions.final
+@typing.final
 class MicroTime(google.protobuf.message.Message):
     """MicroTime is version of Time with microsecond level precision.
 
     +protobuf.options.marshal=false
     +protobuf.as=Timestamp
     +protobuf.options.(gogoproto.goproto_stringer)=false
     """
@@ -1059,60 +1077,60 @@
     """
     def __init__(
         self,
         *,
         seconds: builtins.int | None = ...,
         nanos: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["nanos", b"nanos", "seconds", b"seconds"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["nanos", b"nanos", "seconds", b"seconds"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["nanos", b"nanos", "seconds", b"seconds"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["nanos", b"nanos", "seconds", b"seconds"]) -> None: ...
 
 global___MicroTime = MicroTime
 
-@typing_extensions.final
+@typing.final
 class ObjectMeta(google.protobuf.message.Message):
     """ObjectMeta is metadata that all persisted resources must have, which includes all objects
     users must create.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    @typing_extensions.final
+    @typing.final
     class LabelsEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: builtins.str | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
-    @typing_extensions.final
+    @typing.final
     class AnnotationsEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
         VALUE_FIELD_NUMBER: builtins.int
         key: builtins.str
         value: builtins.str
         def __init__(
             self,
             *,
             key: builtins.str | None = ...,
             value: builtins.str | None = ...,
         ) -> None: ...
-        def HasField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
-        def ClearField(self, field_name: typing_extensions.Literal["key", b"key", "value", b"value"]) -> None: ...
+        def HasField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> builtins.bool: ...
+        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...
 
     NAME_FIELD_NUMBER: builtins.int
     GENERATENAME_FIELD_NUMBER: builtins.int
     NAMESPACE_FIELD_NUMBER: builtins.int
     SELFLINK_FIELD_NUMBER: builtins.int
     UID_FIELD_NUMBER: builtins.int
     RESOURCEVERSION_FIELD_NUMBER: builtins.int
@@ -1198,26 +1216,40 @@
     +optional
     """
     generation: builtins.int
     """A sequence number representing a specific generation of the desired state.
     Populated by the system. Read-only.
     +optional
     """
+    deletionGracePeriodSeconds: builtins.int
+    """Number of seconds allowed for this object to gracefully terminate before
+    it will be removed from the system. Only set when deletionTimestamp is also set.
+    May only be shortened.
+    Read-only.
+    +optional
+    """
+    clusterName: builtins.str
+    """The name of the cluster which the object belongs to.
+    This is used to distinguish resources with same name and namespace in different clusters.
+    This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request.
+    +optional
+    """
     @property
     def creationTimestamp(self) -> global___Time:
         """CreationTimestamp is a timestamp representing the server time when this object was
         created. It is not guaranteed to be set in happens-before order across separate operations.
         Clients may not set this value. It is represented in RFC3339 form and is in UTC.
 
         Populated by the system.
         Read-only.
         Null for lists.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     @property
     def deletionTimestamp(self) -> global___Time:
         """DeletionTimestamp is RFC 3339 date and time at which this resource will be deleted. This
         field is set by the server when a graceful deletion is requested by the user, and is not
         directly settable by a client. The resource is expected to be deleted (no longer visible
         from resource lists, and not reachable by name) after the time in this field, once the
         finalizers list is empty. As long as the finalizers list contains items, deletion is blocked.
@@ -1232,47 +1264,44 @@
         If not set, graceful deletion of the object has not been requested.
 
         Populated by the system when a graceful deletion is requested.
         Read-only.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
-    deletionGracePeriodSeconds: builtins.int
-    """Number of seconds allowed for this object to gracefully terminate before
-    it will be removed from the system. Only set when deletionTimestamp is also set.
-    May only be shortened.
-    Read-only.
-    +optional
-    """
+
     @property
     def labels(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]:
         """Map of string keys and values that can be used to organize and categorize
         (scope and select) objects. May match selectors of replication controllers
         and services.
         More info: http://kubernetes.io/docs/user-guide/labels
         +optional
         """
+
     @property
     def annotations(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]:
         """Annotations is an unstructured key value map stored with a resource that may be
         set by external tools to store and retrieve arbitrary metadata. They are not
         queryable and should be preserved when modifying objects.
         More info: http://kubernetes.io/docs/user-guide/annotations
         +optional
         """
+
     @property
     def ownerReferences(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___OwnerReference]:
         """List of objects depended by this object. If ALL objects in the list have
         been deleted, this object will be garbage collected. If this object is managed by a controller,
         then an entry in this list will point to this controller, with the controller field set to true.
         There cannot be more than one managing controller.
         +optional
         +patchMergeKey=uid
         +patchStrategy=merge
         """
+
     @property
     def finalizers(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """Must be empty before the object is deleted from the registry. Each entry
         is an identifier for the responsible component that will remove the entry
         from the list. If the deletionTimestamp of the object is non-nil, entries
         in this list can only be removed.
         Finalizers may be processed and removed in any order.  Order is NOT enforced
@@ -1283,32 +1312,28 @@
         waiting for a signal (field value, external system, or other) produced by a
         component responsible for a finalizer later in the list, resulting in a deadlock.
         Without enforced ordering finalizers are free to order amongst themselves and
         are not vulnerable to ordering changes in the list.
         +optional
         +patchStrategy=merge
         """
-    clusterName: builtins.str
-    """The name of the cluster which the object belongs to.
-    This is used to distinguish resources with same name and namespace in different clusters.
-    This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request.
-    +optional
-    """
+
     @property
     def managedFields(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ManagedFieldsEntry]:
         """ManagedFields maps workflow-id and version to the set of fields
         that are managed by that workflow. This is mostly for internal
         housekeeping, and users typically shouldn't need to set or
         understand this field. A workflow can be the user's name, a
         controller's name, or the name of a specific apply path like
         "ci-cd". The set of fields is always in the version that the
         workflow used when modifying the object.
 
         +optional
         """
+
     def __init__(
         self,
         *,
         name: builtins.str | None = ...,
         generateName: builtins.str | None = ...,
         namespace: builtins.str | None = ...,
         selfLink: builtins.str | None = ...,
@@ -1321,20 +1346,20 @@
         labels: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
         annotations: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
         ownerReferences: collections.abc.Iterable[global___OwnerReference] | None = ...,
         finalizers: collections.abc.Iterable[builtins.str] | None = ...,
         clusterName: builtins.str | None = ...,
         managedFields: collections.abc.Iterable[global___ManagedFieldsEntry] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["clusterName", b"clusterName", "creationTimestamp", b"creationTimestamp", "deletionGracePeriodSeconds", b"deletionGracePeriodSeconds", "deletionTimestamp", b"deletionTimestamp", "generateName", b"generateName", "generation", b"generation", "name", b"name", "namespace", b"namespace", "resourceVersion", b"resourceVersion", "selfLink", b"selfLink", "uid", b"uid"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["annotations", b"annotations", "clusterName", b"clusterName", "creationTimestamp", b"creationTimestamp", "deletionGracePeriodSeconds", b"deletionGracePeriodSeconds", "deletionTimestamp", b"deletionTimestamp", "finalizers", b"finalizers", "generateName", b"generateName", "generation", b"generation", "labels", b"labels", "managedFields", b"managedFields", "name", b"name", "namespace", b"namespace", "ownerReferences", b"ownerReferences", "resourceVersion", b"resourceVersion", "selfLink", b"selfLink", "uid", b"uid"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["clusterName", b"clusterName", "creationTimestamp", b"creationTimestamp", "deletionGracePeriodSeconds", b"deletionGracePeriodSeconds", "deletionTimestamp", b"deletionTimestamp", "generateName", b"generateName", "generation", b"generation", "name", b"name", "namespace", b"namespace", "resourceVersion", b"resourceVersion", "selfLink", b"selfLink", "uid", b"uid"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["annotations", b"annotations", "clusterName", b"clusterName", "creationTimestamp", b"creationTimestamp", "deletionGracePeriodSeconds", b"deletionGracePeriodSeconds", "deletionTimestamp", b"deletionTimestamp", "finalizers", b"finalizers", "generateName", b"generateName", "generation", b"generation", "labels", b"labels", "managedFields", b"managedFields", "name", b"name", "namespace", b"namespace", "ownerReferences", b"ownerReferences", "resourceVersion", b"resourceVersion", "selfLink", b"selfLink", "uid", b"uid"]) -> None: ...
 
 global___ObjectMeta = ObjectMeta
 
-@typing_extensions.final
+@typing.final
 class OwnerReference(google.protobuf.message.Message):
     """OwnerReference contains enough information to let you identify an owning
     object. An owning object must be in the same namespace as the dependent, or
     be cluster-scoped, so there is no namespace field.
     +structType=atomic
     """
 
@@ -1379,20 +1404,20 @@
         apiVersion: builtins.str | None = ...,
         kind: builtins.str | None = ...,
         name: builtins.str | None = ...,
         uid: builtins.str | None = ...,
         controller: builtins.bool | None = ...,
         blockOwnerDeletion: builtins.bool | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["apiVersion", b"apiVersion", "blockOwnerDeletion", b"blockOwnerDeletion", "controller", b"controller", "kind", b"kind", "name", b"name", "uid", b"uid"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["apiVersion", b"apiVersion", "blockOwnerDeletion", b"blockOwnerDeletion", "controller", b"controller", "kind", b"kind", "name", b"name", "uid", b"uid"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["apiVersion", b"apiVersion", "blockOwnerDeletion", b"blockOwnerDeletion", "controller", b"controller", "kind", b"kind", "name", b"name", "uid", b"uid"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["apiVersion", b"apiVersion", "blockOwnerDeletion", b"blockOwnerDeletion", "controller", b"controller", "kind", b"kind", "name", b"name", "uid", b"uid"]) -> None: ...
 
 global___OwnerReference = OwnerReference
 
-@typing_extensions.final
+@typing.final
 class PartialObjectMetadata(google.protobuf.message.Message):
     """PartialObjectMetadata is a generic representation of any object with ObjectMeta. It allows clients
     to get access to a particular ObjectMeta schema without knowing the details of the version.
     +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -1400,25 +1425,26 @@
     METADATA_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> global___ObjectMeta:
         """Standard object's metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         +optional
         """
+
     def __init__(
         self,
         *,
         metadata: global___ObjectMeta | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["metadata", b"metadata"]) -> None: ...
 
 global___PartialObjectMetadata = PartialObjectMetadata
 
-@typing_extensions.final
+@typing.final
 class PartialObjectMetadataList(google.protobuf.message.Message):
     """PartialObjectMetadataList contains a list of objects containing only their metadata
     +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -1426,60 +1452,53 @@
     ITEMS_FIELD_NUMBER: builtins.int
     @property
     def metadata(self) -> global___ListMeta:
         """Standard list metadata.
         More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
         +optional
         """
+
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PartialObjectMetadata]:
         """items contains each of the included items."""
+
     def __init__(
         self,
         *,
         metadata: global___ListMeta | None = ...,
         items: collections.abc.Iterable[global___PartialObjectMetadata] | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["metadata", b"metadata"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["metadata", b"metadata"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items", "metadata", b"metadata"]) -> None: ...
 
 global___PartialObjectMetadataList = PartialObjectMetadataList
 
-@typing_extensions.final
+@typing.final
 class Patch(google.protobuf.message.Message):
     """Patch is provided to give a concrete name and type to the Kubernetes PATCH request body."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     def __init__(
         self,
     ) -> None: ...
 
 global___Patch = Patch
 
-@typing_extensions.final
+@typing.final
 class PatchOptions(google.protobuf.message.Message):
     """PatchOptions may be provided when patching an API object.
     PatchOptions is meant to be a superset of UpdateOptions.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     DRYRUN_FIELD_NUMBER: builtins.int
     FORCE_FIELD_NUMBER: builtins.int
     FIELDMANAGER_FIELD_NUMBER: builtins.int
-    @property
-    def dryRun(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
-        """When present, indicates that modifications should not be
-        persisted. An invalid or unrecognized dryRun directive will
-        result in an error response and no further processing of the
-        request. Valid values are:
-        - All: all dry run stages will be processed
-        +optional
-        """
     force: builtins.bool
     """Force is going to "force" Apply requests. It means user will
     re-acquire conflicting fields owned by other people. Force
     flag must be unset for non-apply patch requests.
     +optional
     """
     fieldManager: builtins.str
@@ -1488,27 +1507,37 @@
     128 characters long, and only contain printable characters,
     as defined by https://golang.org/pkg/unicode/#IsPrint. This
     field is required for apply requests
     (application/apply-patch) but optional for non-apply patch
     types (JsonPatch, MergePatch, StrategicMergePatch).
     +optional
     """
+    @property
+    def dryRun(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
+        """When present, indicates that modifications should not be
+        persisted. An invalid or unrecognized dryRun directive will
+        result in an error response and no further processing of the
+        request. Valid values are:
+        - All: all dry run stages will be processed
+        +optional
+        """
+
     def __init__(
         self,
         *,
         dryRun: collections.abc.Iterable[builtins.str] | None = ...,
         force: builtins.bool | None = ...,
         fieldManager: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fieldManager", b"fieldManager", "force", b"force"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["dryRun", b"dryRun", "fieldManager", b"fieldManager", "force", b"force"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fieldManager", b"fieldManager", "force", b"force"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["dryRun", b"dryRun", "fieldManager", b"fieldManager", "force", b"force"]) -> None: ...
 
 global___PatchOptions = PatchOptions
 
-@typing_extensions.final
+@typing.final
 class Preconditions(google.protobuf.message.Message):
     """Preconditions must be fulfilled before an operation (update, delete, etc.) is carried out."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     UID_FIELD_NUMBER: builtins.int
     RESOURCEVERSION_FIELD_NUMBER: builtins.int
@@ -1522,41 +1551,42 @@
     """
     def __init__(
         self,
         *,
         uid: builtins.str | None = ...,
         resourceVersion: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["resourceVersion", b"resourceVersion", "uid", b"uid"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["resourceVersion", b"resourceVersion", "uid", b"uid"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["resourceVersion", b"resourceVersion", "uid", b"uid"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["resourceVersion", b"resourceVersion", "uid", b"uid"]) -> None: ...
 
 global___Preconditions = Preconditions
 
-@typing_extensions.final
+@typing.final
 class RootPaths(google.protobuf.message.Message):
     """RootPaths lists the paths available at root.
     For example: "/healthz", "/apis".
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PATHS_FIELD_NUMBER: builtins.int
     @property
     def paths(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """paths are the paths available at root."""
+
     def __init__(
         self,
         *,
         paths: collections.abc.Iterable[builtins.str] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["paths", b"paths"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["paths", b"paths"]) -> None: ...
 
 global___RootPaths = RootPaths
 
-@typing_extensions.final
+@typing.final
 class ServerAddressByClientCIDR(google.protobuf.message.Message):
     """ServerAddressByClientCIDR helps the client to determine the server address that they should use, depending on the clientCIDR that they match."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     CLIENTCIDR_FIELD_NUMBER: builtins.int
     SERVERADDRESS_FIELD_NUMBER: builtins.int
@@ -1568,37 +1598,31 @@
     """
     def __init__(
         self,
         *,
         clientCIDR: builtins.str | None = ...,
         serverAddress: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["clientCIDR", b"clientCIDR", "serverAddress", b"serverAddress"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["clientCIDR", b"clientCIDR", "serverAddress", b"serverAddress"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["clientCIDR", b"clientCIDR", "serverAddress", b"serverAddress"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["clientCIDR", b"clientCIDR", "serverAddress", b"serverAddress"]) -> None: ...
 
 global___ServerAddressByClientCIDR = ServerAddressByClientCIDR
 
-@typing_extensions.final
+@typing.final
 class Status(google.protobuf.message.Message):
     """Status is a return value for calls that don't return other objects."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     METADATA_FIELD_NUMBER: builtins.int
     STATUS_FIELD_NUMBER: builtins.int
     MESSAGE_FIELD_NUMBER: builtins.int
     REASON_FIELD_NUMBER: builtins.int
     DETAILS_FIELD_NUMBER: builtins.int
     CODE_FIELD_NUMBER: builtins.int
-    @property
-    def metadata(self) -> global___ListMeta:
-        """Standard list metadata.
-        More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
-        +optional
-        """
     status: builtins.str
     """Status of the operation.
     One of: "Success" or "Failure".
     More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
     +optional
     """
     message: builtins.str
@@ -1608,42 +1632,50 @@
     reason: builtins.str
     """A machine-readable description of why this operation is in the
     "Failure" status. If this value is empty there
     is no information available. A Reason clarifies an HTTP status
     code but does not override it.
     +optional
     """
+    code: builtins.int
+    """Suggested HTTP return code for this status, 0 if not set.
+    +optional
+    """
+    @property
+    def metadata(self) -> global___ListMeta:
+        """Standard list metadata.
+        More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
+        +optional
+        """
+
     @property
     def details(self) -> global___StatusDetails:
         """Extended data associated with the reason.  Each reason may define its
         own extended details. This field is optional and the data returned
         is not guaranteed to conform to any schema except that defined by
         the reason type.
         +optional
         """
-    code: builtins.int
-    """Suggested HTTP return code for this status, 0 if not set.
-    +optional
-    """
+
     def __init__(
         self,
         *,
         metadata: global___ListMeta | None = ...,
         status: builtins.str | None = ...,
         message: builtins.str | None = ...,
         reason: builtins.str | None = ...,
         details: global___StatusDetails | None = ...,
         code: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["code", b"code", "details", b"details", "message", b"message", "metadata", b"metadata", "reason", b"reason", "status", b"status"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["code", b"code", "details", b"details", "message", b"message", "metadata", b"metadata", "reason", b"reason", "status", b"status"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["code", b"code", "details", b"details", "message", b"message", "metadata", b"metadata", "reason", b"reason", "status", b"status"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["code", b"code", "details", b"details", "message", b"message", "metadata", b"metadata", "reason", b"reason", "status", b"status"]) -> None: ...
 
 global___Status = Status
 
-@typing_extensions.final
+@typing.final
 class StatusCause(google.protobuf.message.Message):
     """StatusCause provides more information about an api.Status failure, including
     cases when multiple errors are encountered.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -1675,20 +1707,20 @@
     def __init__(
         self,
         *,
         reason: builtins.str | None = ...,
         message: builtins.str | None = ...,
         field: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["field", b"field", "message", b"message", "reason", b"reason"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["field", b"field", "message", b"message", "reason", b"reason"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["field", b"field", "message", b"message", "reason", b"reason"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["field", b"field", "message", b"message", "reason", b"reason"]) -> None: ...
 
 global___StatusCause = StatusCause
 
-@typing_extensions.final
+@typing.final
 class StatusDetails(google.protobuf.message.Message):
     """StatusDetails is a set of additional properties that MAY be set by the
     server to provide additional information about a response. The Reason
     field of a Status object defines what attributes will be set. Clients
     must ignore fields that do not match the defined type of each attribute,
     and should assume that any attribute may be empty, invalid, or under
     defined.
@@ -1719,42 +1751,43 @@
     """
     uid: builtins.str
     """UID of the resource.
     (when there is a single resource which can be described).
     More info: http://kubernetes.io/docs/user-guide/identifiers#uids
     +optional
     """
-    @property
-    def causes(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___StatusCause]:
-        """The Causes array includes more details associated with the StatusReason
-        failure. Not all StatusReasons may provide detailed causes.
-        +optional
-        """
     retryAfterSeconds: builtins.int
     """If specified, the time in seconds before the operation should be retried. Some errors may indicate
     the client must take an alternate action - for those errors this field may indicate how long to wait
     before taking the alternate action.
     +optional
     """
+    @property
+    def causes(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___StatusCause]:
+        """The Causes array includes more details associated with the StatusReason
+        failure. Not all StatusReasons may provide detailed causes.
+        +optional
+        """
+
     def __init__(
         self,
         *,
         name: builtins.str | None = ...,
         group: builtins.str | None = ...,
         kind: builtins.str | None = ...,
         uid: builtins.str | None = ...,
         causes: collections.abc.Iterable[global___StatusCause] | None = ...,
         retryAfterSeconds: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["group", b"group", "kind", b"kind", "name", b"name", "retryAfterSeconds", b"retryAfterSeconds", "uid", b"uid"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["causes", b"causes", "group", b"group", "kind", b"kind", "name", b"name", "retryAfterSeconds", b"retryAfterSeconds", "uid", b"uid"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["group", b"group", "kind", b"kind", "name", b"name", "retryAfterSeconds", b"retryAfterSeconds", "uid", b"uid"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["causes", b"causes", "group", b"group", "kind", b"kind", "name", b"name", "retryAfterSeconds", b"retryAfterSeconds", "uid", b"uid"]) -> None: ...
 
 global___StatusDetails = StatusDetails
 
-@typing_extensions.final
+@typing.final
 class TableOptions(google.protobuf.message.Message):
     """TableOptions are used when a Table is requested by the caller.
     +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -1766,20 +1799,20 @@
     in version v1beta1 of the meta.k8s.io API group.
     """
     def __init__(
         self,
         *,
         includeObject: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["includeObject", b"includeObject"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["includeObject", b"includeObject"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["includeObject", b"includeObject"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["includeObject", b"includeObject"]) -> None: ...
 
 global___TableOptions = TableOptions
 
-@typing_extensions.final
+@typing.final
 class Time(google.protobuf.message.Message):
     """Time is a wrapper around time.Time which supports correct
     marshaling to YAML and JSON.  Wrappers are provided for many
     of the factory methods that the time package offers.
 
     +protobuf.options.marshal=false
     +protobuf.as=Timestamp
@@ -1803,20 +1836,20 @@
     """
     def __init__(
         self,
         *,
         seconds: builtins.int | None = ...,
         nanos: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["nanos", b"nanos", "seconds", b"seconds"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["nanos", b"nanos", "seconds", b"seconds"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["nanos", b"nanos", "seconds", b"seconds"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["nanos", b"nanos", "seconds", b"seconds"]) -> None: ...
 
 global___Time = Time
 
-@typing_extensions.final
+@typing.final
 class Timestamp(google.protobuf.message.Message):
     """Timestamp is a struct that is equivalent to Time, but intended for
     protobuf marshalling/unmarshalling. It is generated into a serialization
     that matches Time. Do not use in Go structs.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -1836,20 +1869,20 @@
     """
     def __init__(
         self,
         *,
         seconds: builtins.int | None = ...,
         nanos: builtins.int | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["nanos", b"nanos", "seconds", b"seconds"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["nanos", b"nanos", "seconds", b"seconds"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["nanos", b"nanos", "seconds", b"seconds"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["nanos", b"nanos", "seconds", b"seconds"]) -> None: ...
 
 global___Timestamp = Timestamp
 
-@typing_extensions.final
+@typing.final
 class TypeMeta(google.protobuf.message.Message):
     """TypeMeta describes an individual object in an API response or request
     with strings representing the type of the object and its API schema version.
     Structures that are versioned or persisted should inline TypeMeta.
 
     +k8s:deepcopy-gen=false
     """
@@ -1875,57 +1908,58 @@
     """
     def __init__(
         self,
         *,
         kind: builtins.str | None = ...,
         apiVersion: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["apiVersion", b"apiVersion", "kind", b"kind"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["apiVersion", b"apiVersion", "kind", b"kind"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["apiVersion", b"apiVersion", "kind", b"kind"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["apiVersion", b"apiVersion", "kind", b"kind"]) -> None: ...
 
 global___TypeMeta = TypeMeta
 
-@typing_extensions.final
+@typing.final
 class UpdateOptions(google.protobuf.message.Message):
     """UpdateOptions may be provided when updating an API object.
     All fields in UpdateOptions should also be present in PatchOptions.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     DRYRUN_FIELD_NUMBER: builtins.int
     FIELDMANAGER_FIELD_NUMBER: builtins.int
+    fieldManager: builtins.str
+    """fieldManager is a name associated with the actor or entity
+    that is making these changes. The value must be less than or
+    128 characters long, and only contain printable characters,
+    as defined by https://golang.org/pkg/unicode/#IsPrint.
+    +optional
+    """
     @property
     def dryRun(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """When present, indicates that modifications should not be
         persisted. An invalid or unrecognized dryRun directive will
         result in an error response and no further processing of the
         request. Valid values are:
         - All: all dry run stages will be processed
         +optional
         """
-    fieldManager: builtins.str
-    """fieldManager is a name associated with the actor or entity
-    that is making these changes. The value must be less than or
-    128 characters long, and only contain printable characters,
-    as defined by https://golang.org/pkg/unicode/#IsPrint.
-    +optional
-    """
+
     def __init__(
         self,
         *,
         dryRun: collections.abc.Iterable[builtins.str] | None = ...,
         fieldManager: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["fieldManager", b"fieldManager"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["dryRun", b"dryRun", "fieldManager", b"fieldManager"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["fieldManager", b"fieldManager"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["dryRun", b"dryRun", "fieldManager", b"fieldManager"]) -> None: ...
 
 global___UpdateOptions = UpdateOptions
 
-@typing_extensions.final
+@typing.final
 class Verbs(google.protobuf.message.Message):
     """Verbs masks the value so protobuf can generate
 
     +protobuf.nullable=true
     +protobuf.options.(gogoproto.goproto_stringer)=false
     items, if empty, will result in an empty slice
     """
@@ -1936,19 +1970,19 @@
     @property
     def items(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]: ...
     def __init__(
         self,
         *,
         items: collections.abc.Iterable[builtins.str] | None = ...,
     ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["items", b"items"]) -> None: ...
+    def ClearField(self, field_name: typing.Literal["items", b"items"]) -> None: ...
 
 global___Verbs = Verbs
 
-@typing_extensions.final
+@typing.final
 class WatchEvent(google.protobuf.message.Message):
     """Event represents a single event to a watched resource.
 
     +protobuf=true
     +k8s:deepcopy-gen=true
     +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object
     """
@@ -1962,17 +1996,18 @@
     def object(self) -> armada_client.k8s.io.apimachinery.pkg.runtime.generated_pb2.RawExtension:
         """Object is:
          * If Type is Added or Modified: the new state of the object.
          * If Type is Deleted: the state of the object immediately before deletion.
          * If Type is Error: *Status is recommended; other types may make sense
            depending on context.
         """
+
     def __init__(
         self,
         *,
         type: builtins.str | None = ...,
         object: armada_client.k8s.io.apimachinery.pkg.runtime.generated_pb2.RawExtension | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["object", b"object", "type", b"type"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["object", b"object", "type", b"type"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["object", b"object", "type", b"type"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["object", b"object", "type", b"type"]) -> None: ...
 
 global___WatchEvent = WatchEvent
```

## armada_client/k8s/io/apimachinery/pkg/runtime/generated_pb2.py

```diff
@@ -1,11 +1,11 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: k8s.io/apimachinery/pkg/runtime/generated.proto
-# Protobuf Python Version: 4.25.1
+# Protobuf Python Version: 5.26.1
 """Generated protocol buffer code."""
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
 from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
@@ -15,16 +15,16 @@
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n/k8s.io/apimachinery/pkg/runtime/generated.proto\x12\x1fk8s.io.apimachinery.pkg.runtime\"\x1b\n\x0cRawExtension\x12\x0b\n\x03raw\x18\x01 \x01(\x0c\",\n\x08TypeMeta\x12\x12\n\napiVersion\x18\x01 \x01(\t\x12\x0c\n\x04kind\x18\x02 \x01(\t\"\x81\x01\n\x07Unknown\x12;\n\x08typeMeta\x18\x01 \x01(\x0b\x32).k8s.io.apimachinery.pkg.runtime.TypeMeta\x12\x0b\n\x03raw\x18\x02 \x01(\x0c\x12\x17\n\x0f\x63ontentEncoding\x18\x03 \x01(\t\x12\x13\n\x0b\x63ontentType\x18\x04 \x01(\tB\tZ\x07runtime')
 
 _globals = globals()
 _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
 _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'k8s.io.apimachinery.pkg.runtime.generated_pb2', _globals)
-if _descriptor._USE_C_DESCRIPTORS == False:
-  _globals['DESCRIPTOR']._options = None
+if not _descriptor._USE_C_DESCRIPTORS:
+  _globals['DESCRIPTOR']._loaded_options = None
   _globals['DESCRIPTOR']._serialized_options = b'Z\007runtime'
   _globals['_RAWEXTENSION']._serialized_start=84
   _globals['_RAWEXTENSION']._serialized_end=111
   _globals['_TYPEMETA']._serialized_start=113
   _globals['_TYPEMETA']._serialized_end=157
   _globals['_UNKNOWN']._serialized_start=160
   _globals['_UNKNOWN']._serialized_end=289
```

## armada_client/k8s/io/apimachinery/pkg/runtime/generated_pb2.pyi

```diff
@@ -1,24 +1,20 @@
 """
 @generated by mypy-protobuf.  Do not edit manually!
 isort:skip_file
 This file was autogenerated by go-to-protobuf. Do not edit it manually!"""
+
 import builtins
 import google.protobuf.descriptor
 import google.protobuf.message
-import sys
-
-if sys.version_info >= (3, 8):
-    import typing as typing_extensions
-else:
-    import typing_extensions
+import typing
 
 DESCRIPTOR: google.protobuf.descriptor.FileDescriptor
 
-@typing_extensions.final
+@typing.final
 class RawExtension(google.protobuf.message.Message):
     """RawExtension is used to hold extensions in external versions.
 
     To use this, make a field which has RawExtension as its type in your external, versioned
     struct, and Object in your internal struct. You also need to register your
     various plugin types.
 
@@ -72,20 +68,20 @@
     TODO: Determine how to detect ContentType and ContentEncoding of 'Raw' data.
     """
     def __init__(
         self,
         *,
         raw: builtins.bytes | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["raw", b"raw"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["raw", b"raw"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["raw", b"raw"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["raw", b"raw"]) -> None: ...
 
 global___RawExtension = RawExtension
 
-@typing_extensions.final
+@typing.final
 class TypeMeta(google.protobuf.message.Message):
     """TypeMeta is shared by all top level objects. The proper way to use it is to inline it in your type,
     like this:
     type MyAwesomeAPIObject struct {
          runtime.TypeMeta    `json:",inline"`
          ... // other fields
     }
@@ -109,20 +105,20 @@
     """+optional"""
     def __init__(
         self,
         *,
         apiVersion: builtins.str | None = ...,
         kind: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["apiVersion", b"apiVersion", "kind", b"kind"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["apiVersion", b"apiVersion", "kind", b"kind"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["apiVersion", b"apiVersion", "kind", b"kind"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["apiVersion", b"apiVersion", "kind", b"kind"]) -> None: ...
 
 global___TypeMeta = TypeMeta
 
-@typing_extensions.final
+@typing.final
 class Unknown(google.protobuf.message.Message):
     """Unknown allows api objects with unknown types to be passed-through. This can be used
     to deal with the API objects from a plug-in. Unknown objects still have functioning
     TypeMeta features-- kind, version, etc.
     TODO: Make this object have easy access to field based accessors and settors for
     metadata and field mutatation.
 
@@ -134,34 +130,34 @@
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     TYPEMETA_FIELD_NUMBER: builtins.int
     RAW_FIELD_NUMBER: builtins.int
     CONTENTENCODING_FIELD_NUMBER: builtins.int
     CONTENTTYPE_FIELD_NUMBER: builtins.int
-    @property
-    def typeMeta(self) -> global___TypeMeta: ...
     raw: builtins.bytes
     """Raw will hold the complete serialized object which couldn't be matched
     with a registered type. Most likely, nothing should be done with this
     except for passing it through the system.
     """
     contentEncoding: builtins.str
     """ContentEncoding is encoding used to encode 'Raw' data.
     Unspecified means no encoding.
     """
     contentType: builtins.str
     """ContentType  is serialization method used to serialize 'Raw'.
     Unspecified means ContentTypeJSON.
     """
+    @property
+    def typeMeta(self) -> global___TypeMeta: ...
     def __init__(
         self,
         *,
         typeMeta: global___TypeMeta | None = ...,
         raw: builtins.bytes | None = ...,
         contentEncoding: builtins.str | None = ...,
         contentType: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["contentEncoding", b"contentEncoding", "contentType", b"contentType", "raw", b"raw", "typeMeta", b"typeMeta"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["contentEncoding", b"contentEncoding", "contentType", b"contentType", "raw", b"raw", "typeMeta", b"typeMeta"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["contentEncoding", b"contentEncoding", "contentType", b"contentType", "raw", b"raw", "typeMeta", b"typeMeta"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["contentEncoding", b"contentEncoding", "contentType", b"contentType", "raw", b"raw", "typeMeta", b"typeMeta"]) -> None: ...
 
 global___Unknown = Unknown
```

## armada_client/k8s/io/apimachinery/pkg/runtime/schema/generated_pb2.py

```diff
@@ -1,11 +1,11 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: k8s.io/apimachinery/pkg/runtime/schema/generated.proto
-# Protobuf Python Version: 4.25.1
+# Protobuf Python Version: 5.26.1
 """Generated protocol buffer code."""
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
 from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
@@ -15,11 +15,11 @@
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n6k8s.io/apimachinery/pkg/runtime/schema/generated.proto\x12&k8s.io.apimachinery.pkg.runtime.schemaB\x08Z\x06schema')
 
 _globals = globals()
 _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
 _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'k8s.io.apimachinery.pkg.runtime.schema.generated_pb2', _globals)
-if _descriptor._USE_C_DESCRIPTORS == False:
-  _globals['DESCRIPTOR']._options = None
+if not _descriptor._USE_C_DESCRIPTORS:
+  _globals['DESCRIPTOR']._loaded_options = None
   _globals['DESCRIPTOR']._serialized_options = b'Z\006schema'
 # @@protoc_insertion_point(module_scope)
```

## armada_client/k8s/io/apimachinery/pkg/runtime/schema/generated_pb2.pyi

```diff
@@ -1,7 +1,8 @@
 """
 @generated by mypy-protobuf.  Do not edit manually!
 isort:skip_file
 This file was autogenerated by go-to-protobuf. Do not edit it manually!"""
+
 import google.protobuf.descriptor
 
 DESCRIPTOR: google.protobuf.descriptor.FileDescriptor
```

## armada_client/k8s/io/apimachinery/pkg/util/intstr/generated_pb2.py

```diff
@@ -1,11 +1,11 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: k8s.io/apimachinery/pkg/util/intstr/generated.proto
-# Protobuf Python Version: 4.25.1
+# Protobuf Python Version: 5.26.1
 """Generated protocol buffer code."""
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
 from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
@@ -15,13 +15,13 @@
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n3k8s.io/apimachinery/pkg/util/intstr/generated.proto\x12#k8s.io.apimachinery.pkg.util.intstr\";\n\x0bIntOrString\x12\x0c\n\x04type\x18\x01 \x01(\x03\x12\x0e\n\x06intVal\x18\x02 \x01(\x05\x12\x0e\n\x06strVal\x18\x03 \x01(\tB\x08Z\x06intstr')
 
 _globals = globals()
 _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
 _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'k8s.io.apimachinery.pkg.util.intstr.generated_pb2', _globals)
-if _descriptor._USE_C_DESCRIPTORS == False:
-  _globals['DESCRIPTOR']._options = None
+if not _descriptor._USE_C_DESCRIPTORS:
+  _globals['DESCRIPTOR']._loaded_options = None
   _globals['DESCRIPTOR']._serialized_options = b'Z\006intstr'
   _globals['_INTORSTRING']._serialized_start=92
   _globals['_INTORSTRING']._serialized_end=151
 # @@protoc_insertion_point(module_scope)
```

## armada_client/k8s/io/apimachinery/pkg/util/intstr/generated_pb2.pyi

```diff
@@ -1,24 +1,20 @@
 """
 @generated by mypy-protobuf.  Do not edit manually!
 isort:skip_file
 This file was autogenerated by go-to-protobuf. Do not edit it manually!"""
+
 import builtins
 import google.protobuf.descriptor
 import google.protobuf.message
-import sys
-
-if sys.version_info >= (3, 8):
-    import typing as typing_extensions
-else:
-    import typing_extensions
+import typing
 
 DESCRIPTOR: google.protobuf.descriptor.FileDescriptor
 
-@typing_extensions.final
+@typing.final
 class IntOrString(google.protobuf.message.Message):
     """IntOrString is a type that can hold an int32 or a string.  When used in
     JSON or YAML marshalling and unmarshalling, it produces or consumes the
     inner type.  This allows you to have, for example, a JSON field that can
     accept a name or number.
     TODO: Rename to Int32OrString
 
@@ -38,11 +34,11 @@
     def __init__(
         self,
         *,
         type: builtins.int | None = ...,
         intVal: builtins.int | None = ...,
         strVal: builtins.str | None = ...,
     ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["intVal", b"intVal", "strVal", b"strVal", "type", b"type"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["intVal", b"intVal", "strVal", b"strVal", "type", b"type"]) -> None: ...
+    def HasField(self, field_name: typing.Literal["intVal", b"intVal", "strVal", b"strVal", "type", b"type"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing.Literal["intVal", b"intVal", "strVal", b"strVal", "type", b"type"]) -> None: ...
 
 global___IntOrString = IntOrString
```

## Comparing `armada_client-0.2.9.dist-info/METADATA` & `armada_client-0.3.0.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: armada_client
-Version: 0.2.9
+Version: 0.3.0
 Summary: Armada gRPC API python client
 Author-email: G-Research Open Source Software <armada@armadaproject.io>
 License: Apache Software License
 Requires-Python: >=3.7
 Description-Content-Type: text/markdown
 Requires-Dist: grpcio >=1.46.3
 Requires-Dist: grpcio-tools >=1.46.3
@@ -13,15 +13,15 @@
 Provides-Extra: docs
 Requires-Dist: sphinx ==7.1.2 ; extra == 'docs'
 Requires-Dist: sphinx-jekyll-builder ==0.3.0 ; extra == 'docs'
 Requires-Dist: sphinx-toolbox ==3.2.0b1 ; extra == 'docs'
 Requires-Dist: sphinx-markdown-builder ==0.5.5 ; extra == 'docs'
 Provides-Extra: format
 Requires-Dist: black ==23.7.0 ; extra == 'format'
-Requires-Dist: flake8 ==6.1.0 ; extra == 'format'
+Requires-Dist: flake8 ==7.0.0 ; extra == 'format'
 Requires-Dist: pylint ==2.17.5 ; extra == 'format'
 Provides-Extra: test
 Requires-Dist: pytest ==7.3.1 ; extra == 'test'
 Requires-Dist: coverage >=6.5.0 ; extra == 'test'
 Requires-Dist: pytest-asyncio ==0.21.1 ; extra == 'test'
 
 # Armada Python Client
```

## Comparing `armada_client-0.2.9.dist-info/RECORD` & `armada_client-0.3.0.dist-info/RECORD`

 * *Files 8% similar despite different names*

```diff
@@ -1,46 +1,47 @@
 armada_client/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-armada_client/asyncio_client.py,sha256=2T8IGkwe4fcw8nFGbeutYJ23S78BDg8w0LeNE-7TC4A,13315
-armada_client/client.py,sha256=f2XL5YWHWoGSlUm5FjaUKyYOZJF5lyYFvwoL9OoXOTk,12978
+armada_client/asyncio_client.py,sha256=7KwDW0HtG957KOrbgOW3kYFtgm2b6xCb9Tg2YwjnGLA,15237
+armada_client/client.py,sha256=YdwR_ogA955Ram1K77PyxphchLVnNCQBYhZGdz1Bpr0,14778
 armada_client/event.py,sha256=Jx_MOMRym1kaHxGzJPj0aNhBQ9bnqBTpymtXuVGbS0U,1092
+armada_client/iterators.py,sha256=55bb1W0d6kkDiS86zvUEKQLNCz7Cl_xcRaF58cpoJS0,5743
 armada_client/permissions.py,sha256=IwXNUkhYjeDLHWHDut5vRdeM9_sHMZPtqTAaco8nGJM,1110
 armada_client/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-armada_client/typings.py,sha256=la0YhlDSJgDhaEOgD_wY81W5uNcfr_VjjqFxxbvrqJM,2098
-armada_client/armada/event_pb2.py,sha256=WCbe6oHKUUGEngl0gp40nLGdBFCszuM2-RhuEr-w2qw,23778
-armada_client/armada/event_pb2.pyi,sha256=TUsg0hI5dYIwsrvTAbmxbGBdguEt88XmlRbGPQ2dyGQ,47203
-armada_client/armada/event_pb2_grpc.py,sha256=J4ebeLgRiFWI72I7rhOQ75xxQPnwojNZzp901ktZ9_U,5691
-armada_client/armada/health_pb2.py,sha256=QKcoSikL8DVZ48mJubRa3xrHBKDslQBun8WfF7lnG1c,1596
-armada_client/armada/health_pb2.pyi,sha256=KJBGhJa2yk-HXrXweBw5SznOSFLOkOxXMM7LnVoxYuY,1774
-armada_client/armada/health_pb2_grpc.py,sha256=1oboBPFxaTEXt9Aw7EAj8gXHDCNMhZD2VXqocC9l_gk,159
-armada_client/armada/job_pb2.py,sha256=oWgQ4CbqMy3caobYYtmTmk24lGrlBlL5IxiohHsl4FY,7766
-armada_client/armada/job_pb2.pyi,sha256=Y4jS4oPmU08cc1dzEFFflj6YzFn2tUg1RQAgKpP3OyY,12882
-armada_client/armada/job_pb2_grpc.py,sha256=A0kMExWaZw2wgiXiv-r-FwvxIVy5WuOei4vAFotvIMg,5623
-armada_client/armada/submit_pb2.py,sha256=J6WmhzpTUUt-ahgpI9gL1ELPEbGQ6DGGbqy0bM8G_Uo,20253
-armada_client/armada/submit_pb2.pyi,sha256=M3czGh91IWMQ7v6kDPfU2_ZjW1kWeL9YT5zWenfdug0,37354
-armada_client/armada/submit_pb2_grpc.py,sha256=A8W4MsgFHzwuSMUm5R8XDUJ54Ws6ZrGCmglbSq-ZyLw,19792
+armada_client/typings.py,sha256=70vxyEGpHMp6OIEzqqMRhE7i6EWBrmkiL-3jqfAU_Hc,2176
+armada_client/armada/event_pb2.py,sha256=MZVstlNupq6P-XJD00rpBSKh8eDbDisdsK3ZzVjMePI,24704
+armada_client/armada/event_pb2.pyi,sha256=uagL7sgaFMis2huq1ebTxfl8Slu-k1Iu7VyzeLcs-dM,47707
+armada_client/armada/event_pb2_grpc.py,sha256=ifc7g2bozR7iyPLOsfqxpG-1tUOKO8oYzoyevgNswUU,7244
+armada_client/armada/health_pb2.py,sha256=l6I5amG0a1vkfG2dfLiNOp5BLVXC0O8Li_WUl332cqQ,1598
+armada_client/armada/health_pb2.pyi,sha256=-vOfk9YRcxzoE9Q-XXVLokLhki9JxydRuUm8w0E2Syk,1753
+armada_client/armada/health_pb2_grpc.py,sha256=bMJikQ5ELV-xN9z2tZvynDPNWJ67RMgvklw_HCwWZdY,1130
+armada_client/armada/job_pb2.py,sha256=SWrVj6n0IV74-uSzvOHpumbWQEDH1WX_KAvxx3JH90A,8761
+armada_client/armada/job_pb2.pyi,sha256=KlLsNfbhqKuIkioA9eXZx22cU9g0TsJNkksD-T6yhWY,12599
+armada_client/armada/job_pb2_grpc.py,sha256=GYv6uO-o0L4elCQs_f4xZEih2cX72L4H_Hs1ZEaG2mc,7173
+armada_client/armada/submit_pb2.py,sha256=pQnhvXdIv-HnE9en0ooaqlOGdKjSa0gINwwImvOXsVI,25230
+armada_client/armada/submit_pb2.pyi,sha256=K0VTs5lkSG44-5-i94zORHpolD7sj97ozrwqHdGzFd4,42791
+armada_client/armada/submit_pb2_grpc.py,sha256=8a25w8rGOnVznqRewMB8IEtA1o3WvLKx1644QSSmlvw,24602
 armada_client/gen/event_typings.py,sha256=U5cOx_S4XzCWYMH0N0GZzPPBn4HO_vEGOtn47DMzL1s,2764
-armada_client/github/com/gogo/protobuf/gogoproto/gogo_pb2.py,sha256=MSrYw6kJkBnUEqX73aP6CtMJ0SYq5871Zr4PlFb8UTs,7770
-armada_client/github/com/gogo/protobuf/gogoproto/gogo_pb2.pyi,sha256=REOhvFR0Iw8ZLlI4yd6hRe3XePl3Z-EgC9tSVKyTekc,15509
-armada_client/google/api/annotations_pb2.py,sha256=ph-ePBjlZDj7TjqjkvFMkEV1CWapM-RS0KVBvKJj-JE,1590
-armada_client/google/api/annotations_pb2.pyi,sha256=qEDr7qQrlBnUlvaIT6M9Bx02Q2sXRzYHaj_pkVM7bos,1053
-armada_client/google/api/annotations_pb2_grpc.py,sha256=1oboBPFxaTEXt9Aw7EAj8gXHDCNMhZD2VXqocC9l_gk,159
-armada_client/google/api/http_pb2.py,sha256=19yKTNIrzIraNB-yXZ5eAStmDMWHLN3bteVBf9ZsOiw,2273
-armada_client/google/api/http_pb2.pyi,sha256=8b49oQJ34mZxinYCaXf9r3Dc2haymVtYDdopAde7AbY,15201
-armada_client/google/api/http_pb2_grpc.py,sha256=1oboBPFxaTEXt9Aw7EAj8gXHDCNMhZD2VXqocC9l_gk,159
-armada_client/k8s/io/api/core/v1/generated_pb2.py,sha256=0cifjW9YvERL6KHz1p9u1HNx8eK_iggHeX8812PjwCI,92958
-armada_client/k8s/io/api/core/v1/generated_pb2.pyi,sha256=znQVTsXpNuwTnmwE25v4i-WB0WQh54KApXZ0BLaKDJU,502797
-armada_client/k8s/io/api/networking/v1/generated_pb2.py,sha256=v7XBQWNaMzTFN4BR-chBycI7GgDP3FXZauKMY7N0cvA,9202
-armada_client/k8s/io/api/networking/v1/generated_pb2.pyi,sha256=HtX3pCChD4BuRapBhVYBmDMK4m8CMrfNxp5xgqv9OEE,42480
-armada_client/k8s/io/apimachinery/pkg/api/resource/generated_pb2.py,sha256=lpUTc_md_J5DhE8QcG-aB5cRhGfvWqpDVVK-KLWZxkI,1245
-armada_client/k8s/io/apimachinery/pkg/api/resource/generated_pb2.pyi,sha256=cV6t_I3H7i7U-WsEFruPiCMjvQMOjL023GIjoaKpCIY,3698
-armada_client/k8s/io/apimachinery/pkg/apis/meta/v1/generated_pb2.py,sha256=o3P_Lq-x3wOJ7lluAVVsCr4dfMoB-GQ4zNKJpHrKL7c,15227
-armada_client/k8s/io/apimachinery/pkg/apis/meta/v1/generated_pb2.pyi,sha256=RxxSDsk-1dvukAS0bflY38IYni2AMwceyYd7xy6wWqc,89806
-armada_client/k8s/io/apimachinery/pkg/runtime/generated_pb2.py,sha256=YRtSRBOJ07hQK1jx1hMjssidDAeCCGrRrk3Y4e1gq8o,1737
-armada_client/k8s/io/apimachinery/pkg/runtime/generated_pb2.pyi,sha256=tmRjh7pLgUeojiyaCXX5046Z63C-iXfeEd2EzbsAcys,6024
-armada_client/k8s/io/apimachinery/pkg/runtime/schema/generated_pb2.py,sha256=JtsHUFMTHrP3_1rd6ysu_1TJYCvnkzI0ege_5YXjqrk,1106
-armada_client/k8s/io/apimachinery/pkg/runtime/schema/generated_pb2.pyi,sha256=lHgT1RnziSypdBL8gaQ2UdD3Er2nXyTvKC1hsjpHbsI,236
-armada_client/k8s/io/apimachinery/pkg/util/intstr/generated_pb2.py,sha256=wNXDUZk6NBJM-Ll7Jk-hNOK6oGO0pUGkoH_MKloRlmI,1319
-armada_client/k8s/io/apimachinery/pkg/util/intstr/generated_pb2.pyi,sha256=hfL-8WHnZN78isx6i4rUEBGlV2SRJeLSYFqeW3qFuXE,1629
-armada_client-0.2.9.dist-info/METADATA,sha256=sHSADgqhZg3cY8yG4Kailk9-tMHd69Gc0eMTvq5H77g,2351
-armada_client-0.2.9.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
-armada_client-0.2.9.dist-info/top_level.txt,sha256=1a9lkrPHdUYkR_N9VH0hzg58inRXnDVJ-H2ZEH8Fu5c,14
-armada_client-0.2.9.dist-info/RECORD,,
+armada_client/github/com/gogo/protobuf/gogoproto/gogo_pb2.py,sha256=3uJqm8BvsEAIMxIuYYjhUHNpgkOwI38BYoHxKmqB5f8,7772
+armada_client/github/com/gogo/protobuf/gogoproto/gogo_pb2.pyi,sha256=T6xUckSwXWScT12XghxPq9OnU7g23ikaj3sPzY9dVBk,15510
+armada_client/google/api/annotations_pb2.py,sha256=0dbiMCxjLSTHW0fuF8Eks2re-KrtuR_t0BsHFNizpAE,1592
+armada_client/google/api/annotations_pb2.pyi,sha256=e2eW1Yu7fEOl1Z_eaX-6jkCTHbLndPNocgtOt8YH4Rc,1054
+armada_client/google/api/annotations_pb2_grpc.py,sha256=qtgZqYFd5VO8pAorgYGMr002rDUo60_55kDXsTOzwqE,1139
+armada_client/google/api/http_pb2.py,sha256=URG5RFdvvqrpsuI2rv2D2azEnuUBqke9ThSL7egQ6xE,2275
+armada_client/google/api/http_pb2.pyi,sha256=HCLakl6Hj1niXVvxkDvA_NFxnVbFlIEsy9XorkFUfq0,15003
+armada_client/google/api/http_pb2_grpc.py,sha256=6RH1sk21kGqLKF4yWkRlopgYQleNtOWYSmetb9LxIkw,1132
+armada_client/k8s/io/api/core/v1/generated_pb2.py,sha256=ZSXvYrgZtO2Uss37E-RdEL0tfCWe9erg8679u2nWHIA,93149
+armada_client/k8s/io/api/core/v1/generated_pb2.pyi,sha256=XPGiHvxg0Y6dDtv6NLMnkXAUg98gEOnNuZ-mzsb5pmE,495575
+armada_client/k8s/io/api/networking/v1/generated_pb2.py,sha256=vrC8_trGr3ivttC8KuCVCFNuY-A7V463tQaz7ZNDRP8,9204
+armada_client/k8s/io/api/networking/v1/generated_pb2.pyi,sha256=DYc6pk6gHm-yYt87Zd428dAJBapxt2JOr_4YR2QLnYY,41656
+armada_client/k8s/io/apimachinery/pkg/api/resource/generated_pb2.py,sha256=eupWZgnhwE3rOtT8HMj1eG8o9Sqqwa-ifye5U8weO4s,1247
+armada_client/k8s/io/apimachinery/pkg/api/resource/generated_pb2.pyi,sha256=SWTQwYyGYDOTaoz4-xYi5pIwi1xVvCLn02Z0PP48GUI,3563
+armada_client/k8s/io/apimachinery/pkg/apis/meta/v1/generated_pb2.py,sha256=HtF2A7aJGt1BqRCWoxWlVthyRWdOFX81HnvO8FEN7p4,15250
+armada_client/k8s/io/apimachinery/pkg/apis/meta/v1/generated_pb2.pyi,sha256=Yoz0R8KEL1r7l6PvAkq6MtCrczDXeOzCu1U2us6UBno,88269
+armada_client/k8s/io/apimachinery/pkg/runtime/generated_pb2.py,sha256=ClGGbp6pa9eYGxtOjAFb2KfVaQCcPUuyPNAnKUUrQQU,1739
+armada_client/k8s/io/apimachinery/pkg/runtime/generated_pb2.pyi,sha256=If2xvVdUS-KibQzE7xCLDvTLZQwZLFsGpH-bWKnJw3U,5823
+armada_client/k8s/io/apimachinery/pkg/runtime/schema/generated_pb2.py,sha256=DWosOCR_VBG4XsZsAbdA0pmZ4MZmPAvXNKbHaKzh_gg,1108
+armada_client/k8s/io/apimachinery/pkg/runtime/schema/generated_pb2.pyi,sha256=fyNwa-AAQTeJ9lKrrbv14AJYghesBKFU6hcFQkGugYc,237
+armada_client/k8s/io/apimachinery/pkg/util/intstr/generated_pb2.py,sha256=MT8zVjhzrSOwySHuMNOjxdM8J1DfxWV5mMHNepb5TQ8,1321
+armada_client/k8s/io/apimachinery/pkg/util/intstr/generated_pb2.pyi,sha256=ncV3KnuoXQ4ZZtGR4HM4uU-GnwJQ-iZTmmk70AeFcAQ,1494
+armada_client-0.3.0.dist-info/METADATA,sha256=BsmpOM-0EdPllCOjBDHnhwgBSdf8jNrsmJvJMOn4MTM,2351
+armada_client-0.3.0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+armada_client-0.3.0.dist-info/top_level.txt,sha256=1a9lkrPHdUYkR_N9VH0hzg58inRXnDVJ-H2ZEH8Fu5c,14
+armada_client-0.3.0.dist-info/RECORD,,
```

