# Comparing `tmp/rqdatac-3.0.6-cp39-cp39-win_amd64.whl.zip` & `tmp/rqdatac-3.0.7.1-cp39-cp39-macosx_10_9_x86_64.whl.zip`

## zipinfo {}

```diff
@@ -1,54 +1,54 @@
-Zip file size: 302131 bytes, number of entries: 52
--rw-rw-rw-  2.0 fat      967 b- defN 23-Dec-01 07:07 rqdatac/__init__.py
--rw-rw-rw-  2.0 fat    10668 b- defN 24-Mar-29 02:50 rqdatac/__init__.pyi
--rw-rw-rw-  2.0 fat      934 b- defN 23-Dec-01 07:07 rqdatac/_internal.py
--rw-rw-rw-  2.0 fat      518 b- defN 24-May-16 10:00 rqdatac/_version.py
--rw-rw-rw-  2.0 fat    10387 b- defN 23-Dec-22 06:50 rqdatac/client.py
--rw-rw-rw-  2.0 fat   139776 b- defN 24-May-16 10:00 rqdatac/connection.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat   768200 b- defN 24-May-16 10:00 rqdatac/connection.cpp
--rw-rw-rw-  2.0 fat     2239 b- defN 23-Dec-01 07:07 rqdatac/connection_pool.py
--rw-rw-rw-  2.0 fat     4447 b- defN 23-Dec-01 07:07 rqdatac/decorators.py
--rw-rw-rw-  2.0 fat     3072 b- defN 23-Dec-01 07:07 rqdatac/rqdatah_helper.py
--rw-rw-rw-  2.0 fat     2140 b- defN 23-Dec-01 07:07 rqdatac/thread_local.py
--rw-rw-rw-  2.0 fat    10929 b- defN 24-Apr-29 06:08 rqdatac/utils.py
--rw-rw-rw-  2.0 fat     9265 b- defN 24-Jan-12 06:37 rqdatac/validators.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Dec-01 07:07 rqdatac/services/__init__.py
--rw-rw-rw-  2.0 fat     6792 b- defN 23-Dec-01 07:07 rqdatac/services/async_live_md_client.py
--rw-rw-rw-  2.0 fat    74860 b- defN 24-Mar-26 06:33 rqdatac/services/basic.py
--rw-rw-rw-  2.0 fat     6202 b- defN 23-Dec-01 07:07 rqdatac/services/calendar.py
--rw-rw-rw-  2.0 fat     2470 b- defN 23-Dec-01 07:07 rqdatac/services/concept.py
--rw-rw-rw-  2.0 fat    47501 b- defN 24-Apr-16 06:15 rqdatac/services/consensus.py
--rw-rw-rw-  2.0 fat    10141 b- defN 23-Dec-01 07:07 rqdatac/services/constant.py
--rw-rw-rw-  2.0 fat    29339 b- defN 24-Mar-29 02:50 rqdatac/services/convertible.py
--rw-rw-rw-  2.0 fat     2405 b- defN 23-Dec-01 07:07 rqdatac/services/extra.py
--rw-rw-rw-  2.0 fat    33958 b- defN 24-Mar-29 02:50 rqdatac/services/factor.py
--rw-rw-rw-  2.0 fat    12561 b- defN 24-Apr-29 06:08 rqdatac/services/financial.py
--rw-rw-rw-  2.0 fat    33768 b- defN 24-Apr-16 06:15 rqdatac/services/future.py
--rw-rw-rw-  2.0 fat    13532 b- defN 24-Apr-29 06:08 rqdatac/services/get_capital_flow.py
--rw-rw-rw-  2.0 fat    29756 b- defN 24-Mar-15 05:59 rqdatac/services/get_price.py
--rw-rw-rw-  2.0 fat     8880 b- defN 24-Mar-15 05:59 rqdatac/services/index.py
--rw-rw-rw-  2.0 fat     6473 b- defN 24-Apr-29 06:08 rqdatac/services/ksh_auction_info.py
--rw-rw-rw-  2.0 fat    15816 b- defN 23-Dec-01 07:07 rqdatac/services/live.py
--rw-rw-rw-  2.0 fat    17180 b- defN 23-Dec-01 07:07 rqdatac/services/live_md_client.py
--rw-rw-rw-  2.0 fat    20995 b- defN 24-May-16 09:39 rqdatac/services/market_data.py
--rw-rw-rw-  2.0 fat    12650 b- defN 24-Apr-29 06:08 rqdatac/services/options.py
--rw-rw-rw-  2.0 fat     9995 b- defN 23-Dec-01 07:07 rqdatac/services/shenwan.py
--rw-rw-rw-  2.0 fat    29976 b- defN 24-Feb-23 09:49 rqdatac/services/stock_status.py
--rw-rw-rw-  2.0 fat     2310 b- defN 23-Dec-01 07:07 rqdatac/services/structured_fund.py
--rw-rw-rw-  2.0 fat     2268 b- defN 23-Dec-01 07:07 rqdatac/services/tmall.py
--rw-rw-rw-  2.0 fat     3649 b- defN 23-Dec-01 07:07 rqdatac/services/xueqiu.py
--rw-rw-rw-  2.0 fat       61 b- defN 23-Dec-01 07:07 rqdatac/services/detail/__init__.py
--rw-rw-rw-  2.0 fat     5733 b- defN 23-Dec-01 07:07 rqdatac/services/detail/adjust_price.py
--rw-rw-rw-  2.0 fat    14077 b- defN 24-Apr-29 06:08 rqdatac/services/detail/get_price_df.py
--rw-rw-rw-  2.0 fat     1833 b- defN 23-Dec-01 07:07 rqdatac/services/detail/resample_helper.py
--rw-rw-rw-  2.0 fat       16 b- defN 23-Dec-01 07:07 rqdatac/services/orm/__init__.py
--rw-rw-rw-  2.0 fat    12814 b- defN 23-Dec-01 07:07 rqdatac/services/orm/pit_financials_ex.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Dec-01 07:07 rqdatac/share/__init__.py
--rw-rw-rw-  2.0 fat     5289 b- defN 23-Dec-01 07:07 rqdatac/share/codec.py
--rw-rw-rw-  2.0 fat     1728 b- defN 23-Dec-01 07:07 rqdatac/share/errors.py
--rw-rw-rw-  2.0 fat     1817 b- defN 23-Dec-01 07:07 rqdatac/share/protocol.py
--rw-rw-rw-  2.0 fat     2517 b- defN 24-May-16 10:00 rqdatac-3.0.6.dist-info/METADATA
--rw-rw-rw-  2.0 fat      100 b- defN 24-May-16 10:00 rqdatac-3.0.6.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        8 b- defN 24-May-16 10:00 rqdatac-3.0.6.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     4382 b- defN 24-May-16 10:00 rqdatac-3.0.6.dist-info/RECORD
-52 files, 1447394 bytes uncompressed, 295225 bytes compressed:  79.6%
+Zip file size: 308318 bytes, number of entries: 52
+-rw-r--r--  2.0 unx      934 b- defN 23-Dec-01 07:08 rqdatac/__init__.py
+-rw-r--r--  2.0 unx     8402 b- defN 24-May-21 09:50 rqdatac/__init__.pyi
+-rw-r--r--  2.0 unx      895 b- defN 23-Dec-01 07:08 rqdatac/_internal.py
+-rw-r--r--  2.0 unx      499 b- defN 24-May-21 09:50 rqdatac/_version.py
+-rw-r--r--  2.0 unx    10102 b- defN 23-Dec-22 06:51 rqdatac/client.py
+-rw-r--r--  2.0 unx   768538 b- defN 24-May-16 09:51 rqdatac/connection.cpp
+-rwxr-xr-x  2.0 unx   185696 b- defN 24-May-21 09:50 rqdatac/connection.cpython-39-darwin.so
+-rw-r--r--  2.0 unx     2173 b- defN 23-Dec-01 07:08 rqdatac/connection_pool.py
+-rw-r--r--  2.0 unx     4299 b- defN 23-Dec-01 07:08 rqdatac/decorators.py
+-rw-r--r--  2.0 unx     2967 b- defN 23-Dec-01 07:08 rqdatac/rqdatah_helper.py
+-rw-r--r--  2.0 unx     2082 b- defN 23-Dec-01 07:08 rqdatac/thread_local.py
+-rw-r--r--  2.0 unx    10573 b- defN 24-Apr-29 06:08 rqdatac/utils.py
+-rw-r--r--  2.0 unx     9015 b- defN 24-Jan-15 03:08 rqdatac/validators.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Dec-01 07:08 rqdatac/services/__init__.py
+-rw-r--r--  2.0 unx     6605 b- defN 23-Dec-01 07:08 rqdatac/services/async_live_md_client.py
+-rw-r--r--  2.0 unx    72801 b- defN 24-Mar-26 06:33 rqdatac/services/basic.py
+-rw-r--r--  2.0 unx     6005 b- defN 23-Dec-01 07:08 rqdatac/services/calendar.py
+-rw-r--r--  2.0 unx     2406 b- defN 23-Dec-01 07:08 rqdatac/services/concept.py
+-rw-r--r--  2.0 unx    46256 b- defN 24-Apr-16 06:15 rqdatac/services/consensus.py
+-rw-r--r--  2.0 unx     9902 b- defN 23-Dec-01 07:08 rqdatac/services/constant.py
+-rw-r--r--  2.0 unx    28626 b- defN 24-Mar-29 02:50 rqdatac/services/convertible.py
+-rw-r--r--  2.0 unx     2337 b- defN 23-Dec-01 07:08 rqdatac/services/extra.py
+-rw-r--r--  2.0 unx    33046 b- defN 24-Mar-29 02:50 rqdatac/services/factor.py
+-rw-r--r--  2.0 unx    12232 b- defN 24-Apr-29 06:08 rqdatac/services/financial.py
+-rw-r--r--  2.0 unx    32997 b- defN 24-Apr-16 06:15 rqdatac/services/future.py
+-rw-r--r--  2.0 unx    13146 b- defN 24-Apr-29 06:08 rqdatac/services/get_capital_flow.py
+-rw-r--r--  2.0 unx    29061 b- defN 24-Mar-15 05:59 rqdatac/services/get_price.py
+-rw-r--r--  2.0 unx     8664 b- defN 24-Mar-15 05:59 rqdatac/services/index.py
+-rw-r--r--  2.0 unx     6306 b- defN 24-Apr-29 06:08 rqdatac/services/ksh_auction_info.py
+-rw-r--r--  2.0 unx    15323 b- defN 23-Dec-01 07:08 rqdatac/services/live.py
+-rw-r--r--  2.0 unx    16723 b- defN 23-Dec-01 07:08 rqdatac/services/live_md_client.py
+-rw-r--r--  2.0 unx    20431 b- defN 24-May-16 09:39 rqdatac/services/market_data.py
+-rw-r--r--  2.0 unx    13814 b- defN 24-May-21 09:49 rqdatac/services/options.py
+-rw-r--r--  2.0 unx     9711 b- defN 23-Dec-01 07:08 rqdatac/services/shenwan.py
+-rw-r--r--  2.0 unx    29233 b- defN 24-Feb-23 09:49 rqdatac/services/stock_status.py
+-rw-r--r--  2.0 unx     2234 b- defN 23-Dec-01 07:08 rqdatac/services/structured_fund.py
+-rw-r--r--  2.0 unx     2198 b- defN 23-Dec-01 07:08 rqdatac/services/tmall.py
+-rw-r--r--  2.0 unx     3547 b- defN 23-Dec-01 07:08 rqdatac/services/xueqiu.py
+-rw-r--r--  2.0 unx       58 b- defN 23-Dec-01 07:08 rqdatac/services/detail/__init__.py
+-rw-r--r--  2.0 unx     5569 b- defN 23-Dec-01 07:08 rqdatac/services/detail/adjust_price.py
+-rw-r--r--  2.0 unx    13707 b- defN 24-Apr-29 06:08 rqdatac/services/detail/get_price_df.py
+-rw-r--r--  2.0 unx     1768 b- defN 23-Dec-01 07:08 rqdatac/services/detail/resample_helper.py
+-rw-r--r--  2.0 unx       15 b- defN 23-Dec-01 07:08 rqdatac/services/orm/__init__.py
+-rw-r--r--  2.0 unx    12408 b- defN 23-Dec-01 07:08 rqdatac/services/orm/pit_financials_ex.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Dec-01 07:08 rqdatac/share/__init__.py
+-rw-r--r--  2.0 unx     5113 b- defN 23-Dec-01 07:08 rqdatac/share/codec.py
+-rw-r--r--  2.0 unx     1644 b- defN 23-Dec-01 07:08 rqdatac/share/errors.py
+-rw-r--r--  2.0 unx     1741 b- defN 23-Dec-01 07:08 rqdatac/share/protocol.py
+-rw-r--r--  2.0 unx     2482 b- defN 24-May-21 09:50 rqdatac-3.0.7.1.dist-info/METADATA
+-rw-r--r--  2.0 unx      109 b- defN 24-May-21 09:50 rqdatac-3.0.7.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx        8 b- defN 24-May-21 09:50 rqdatac-3.0.7.1.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     4390 b- defN 24-May-21 09:50 rqdatac-3.0.7.1.dist-info/RECORD
+52 files, 1478791 bytes uncompressed, 301392 bytes compressed:  79.6%
```

## zipnote {}

```diff
@@ -9,18 +9,18 @@
 
 Filename: rqdatac/_version.py
 Comment: 
 
 Filename: rqdatac/client.py
 Comment: 
 
-Filename: rqdatac/connection.cp39-win_amd64.pyd
+Filename: rqdatac/connection.cpp
 Comment: 
 
-Filename: rqdatac/connection.cpp
+Filename: rqdatac/connection.cpython-39-darwin.so
 Comment: 
 
 Filename: rqdatac/connection_pool.py
 Comment: 
 
 Filename: rqdatac/decorators.py
 Comment: 
@@ -138,20 +138,20 @@
 
 Filename: rqdatac/share/errors.py
 Comment: 
 
 Filename: rqdatac/share/protocol.py
 Comment: 
 
-Filename: rqdatac-3.0.6.dist-info/METADATA
+Filename: rqdatac-3.0.7.1.dist-info/METADATA
 Comment: 
 
-Filename: rqdatac-3.0.6.dist-info/WHEEL
+Filename: rqdatac-3.0.7.1.dist-info/WHEEL
 Comment: 
 
-Filename: rqdatac-3.0.6.dist-info/top_level.txt
+Filename: rqdatac-3.0.7.1.dist-info/top_level.txt
 Comment: 
 
-Filename: rqdatac-3.0.6.dist-info/RECORD
+Filename: rqdatac-3.0.7.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## rqdatac/__init__.py

 * *Ordering differences only*

```diff
@@ -1,33 +1,33 @@
-# -*- coding: utf-8 -*-
-import warnings
-
-warnings.filterwarnings("ignore", message="[.\n]*Pandas[.\n]*")
-warnings.simplefilter(action="ignore", category=FutureWarning)
-from .client import init, reset, initialized  # noqa
-
-
-__all__ = ["__version__", "init", "reset", "initialized"]
-
-
-def __go():
-    import sys
-    import importlib
-    import pkgutil
-
-    # 3.4 引入 asyncio，3.5 引入 async/await 语法，3.6 引入 async generator
-    async_syntax_supported = sys.version_info[:2] >= (3, 6)
-
-    for loader, module_name, is_pkg in pkgutil.walk_packages(__path__, "rqdatac."):
-        if module_name == "rqdatac.services.async_live_md_client" and not async_syntax_supported:
-            continue
-        elif module_name.startswith("rqdatac.services") and not is_pkg:
-            importlib.import_module(module_name)
-
-
-__go()
-
-del __go
-
-from ._version import get_versions
-__version__ = get_versions()['version']
-del get_versions
+# -*- coding: utf-8 -*-
+import warnings
+
+warnings.filterwarnings("ignore", message="[.\n]*Pandas[.\n]*")
+warnings.simplefilter(action="ignore", category=FutureWarning)
+from .client import init, reset, initialized  # noqa
+
+
+__all__ = ["__version__", "init", "reset", "initialized"]
+
+
+def __go():
+    import sys
+    import importlib
+    import pkgutil
+
+    # 3.4 引入 asyncio，3.5 引入 async/await 语法，3.6 引入 async generator
+    async_syntax_supported = sys.version_info[:2] >= (3, 6)
+
+    for loader, module_name, is_pkg in pkgutil.walk_packages(__path__, "rqdatac."):
+        if module_name == "rqdatac.services.async_live_md_client" and not async_syntax_supported:
+            continue
+        elif module_name.startswith("rqdatac.services") and not is_pkg:
+            importlib.import_module(module_name)
+
+
+__go()
+
+del __go
+
+from ._version import get_versions
+__version__ = get_versions()['version']
+del get_versions
```

## rqdatac/__init__.pyi

```diff
@@ -1,211 +1,147 @@
-import rqdatac.services.financial
-import rqdatac.services.market_data
-import rqdatac.services.live_md_client
-import rqdatac.services.basic
-import rqdatac.services.get_capital_flow
-import rqdatac.services.constant
-import rqdatac.services.calendar
-import rqdatac.services.factor
-import rqdatac.services.concept
-import rqdatac.services.xueqiu
-import rqdatac.services.index
-import rqdatac.services.ksh_auction_info
-import rqdatac.services.future
-import rqdatac.services.structured_fund
-import rqdatac.services.convertible
-import rqdatac.services.tmall
-import rqdatac.services.options
-import rqdatac.services.shenwan
-import rqdatac.services.stock_status
-import rqdatac.services.live
-import rqdatac.client
-import rqdatac.services.get_price
-import rqdatac.services.extra
-import rqdatac.services.consensus
-
-__version__: str = ...
-init = rqdatac.client.init
-reset = rqdatac.client.reset
-initialized = rqdatac.client.initialized
-concept_list = rqdatac.services.concept.concept_list
-concept = rqdatac.services.concept.concept
-concept_names = rqdatac.services.concept.concept_names
-shenwan_industry = rqdatac.services.shenwan.shenwan_industry
-shenwan_instrument_industry = rqdatac.services.shenwan.shenwan_instrument_industry
-zx_industry = rqdatac.services.shenwan.zx_industry
-zx_instrument_industry = rqdatac.services.shenwan.zx_instrument_industry
-get_industry = rqdatac.services.shenwan.get_industry
-get_instrument_industry = rqdatac.services.shenwan.get_instrument_industry
-get_industry_mapping = rqdatac.services.shenwan.get_industry_mapping
-industry_code = rqdatac.services.constant.IndustryCode
-IndustryCode = rqdatac.services.constant.IndustryCode
-sector_code = rqdatac.services.constant.SectorCode
-SectorCode = rqdatac.services.constant.SectorCode
-get_trading_dates = rqdatac.services.calendar.get_trading_dates
-get_next_trading_date = rqdatac.services.calendar.get_next_trading_date
-get_previous_trading_date = rqdatac.services.calendar.get_previous_trading_date
-get_latest_trading_date = rqdatac.services.calendar.get_latest_trading_date
-trading_date_offset = rqdatac.services.calendar.trading_date_offset
-is_trading_date = rqdatac.services.calendar.is_trading_date
-has_night_trading = rqdatac.services.calendar.has_night_trading
-current_trading_date = rqdatac.services.calendar.current_trading_date
-id_convert = rqdatac.services.basic.id_convert
-instruments = rqdatac.services.basic.instruments
-all_instruments = rqdatac.services.basic.all_instruments
-sector = rqdatac.services.basic.sector
-industry = rqdatac.services.basic.industry
-get_future_contracts = rqdatac.services.basic.get_future_contracts
-get_spot_benchmark_price = rqdatac.services.basic.get_spot_benchmark_price
-get_stock_connect_holding_details = rqdatac.services.get_price.get_stock_connect_holding_details
-
-
-class futures:
-    get_commission_margin = rqdatac.services.future.get_commission_margin
-    get_contracts = rqdatac.services.basic.get_contracts
-    get_dominant = rqdatac.services.future.get_dominant
-    get_dominant_price = rqdatac.services.future.get_dominant_price
-    get_member_rank = rqdatac.services.future.get_member_rank
-    get_warehouse_stocks = rqdatac.services.future.get_warehouse_stocks
-    get_contract_multiplier = rqdatac.services.future.get_contract_multiplier
-    get_ex_factor = rqdatac.services.future.get_ex_factor
-    get_current_basis = rqdatac.services.future.get_current_basis
-
-
-jy_instrument_industry = rqdatac.services.basic.jy_instrument_industry
-
-
-class econ:
-    get_factors = rqdatac.services.basic.get_factors
-    get_money_supply = rqdatac.services.basic.get_money_supply
-    get_reserve_ratio = rqdatac.services.basic.get_reserve_ratio
-
-
-get_main_shareholder = rqdatac.services.basic.get_main_shareholder
-get_current_news = rqdatac.services.basic.get_current_news
-get_trading_hours = rqdatac.services.basic.get_trading_hours
-get_private_placement = rqdatac.services.basic.get_private_placement
-get_share_transformation = rqdatac.services.basic.get_share_transformation
-
-
-class user:
-    get_quota = rqdatac.services.basic.get_quota
-
-
-get_update_status = rqdatac.services.basic.get_update_status
-info = rqdatac.services.basic.info
-get_basic_info = rqdatac.services.basic.get_basic_info
-
-
-class convertible:
-    all_instruments = rqdatac.services.convertible.all_instruments
-    get_call_info = rqdatac.services.convertible.get_call_info
-    get_cash_flow = rqdatac.services.convertible.get_cash_flow
-    get_conversion_info = rqdatac.services.convertible.get_conversion_info
-    get_conversion_price = rqdatac.services.convertible.get_conversion_price
-    get_credit_rating = rqdatac.services.convertible.get_credit_rating
-    get_indicators = rqdatac.services.convertible.get_indicators
-    get_industry = rqdatac.services.convertible.get_industry
-    get_instrument_industry = rqdatac.services.convertible.get_instrument_industry
-    get_latest_rating = rqdatac.services.convertible.get_latest_rating
-    get_put_info = rqdatac.services.convertible.get_put_info
-    instruments = rqdatac.services.convertible.instruments
-    is_suspended = rqdatac.services.convertible.is_suspended
-    rating = rqdatac.services.convertible.rating
-
-
-get_dominant_future = rqdatac.services.future.get_dominant_future
-future_commission_margin = rqdatac.services.future.future_commission_margin
-get_future_member_rank = rqdatac.services.future.get_future_member_rank
-current_stock_connect_quota = rqdatac.services.stock_status.current_stock_connect_quota
-get_stock_connect_quota = rqdatac.services.stock_status.get_stock_connect_quota
-is_st_stock = rqdatac.services.stock_status.is_st_stock
-_is_st_stock = rqdatac.services.stock_status._is_st_stock
-is_suspended = rqdatac.services.stock_status.is_suspended
-get_stock_connect = rqdatac.services.stock_status.get_stock_connect
-get_securities_margin = rqdatac.services.stock_status.get_securities_margin
-get_investor_ra = rqdatac.services.stock_status.get_investor_ra
-get_margin_stocks = rqdatac.services.stock_status.get_margin_stocks
-get_shares = rqdatac.services.stock_status.get_shares
-get_allotment = rqdatac.services.stock_status.get_allotment
-get_symbol_change_info = rqdatac.services.stock_status.get_symbol_change_info
-get_special_treatment_info = rqdatac.services.stock_status.get_special_treatment_info
-
-current_snapshot = rqdatac.services.live.current_snapshot
-get_ticks = rqdatac.services.live.get_ticks
-current_minute = rqdatac.services.live.current_minute
-get_live_ticks = rqdatac.services.live.get_live_ticks
-get_price = rqdatac.services.get_price.get_price
-LiveMarketDataClient = rqdatac.services.live_md_client.LiveMarketDataClient
-AsyncLiveMarketDataClient = rqdatac.services.async_live_md_client.AsyncLiveMarketDataClient
-get_all_factor_names = rqdatac.services.factor.get_all_factor_names
-get_factor = rqdatac.services.factor.get_factor
-get_factor_return = rqdatac.services.factor.get_factor_return
-get_factor_exposure = rqdatac.services.factor.get_factor_exposure
-get_style_factor_exposure = rqdatac.services.factor.get_style_factor_exposure
-get_descriptor_exposure = rqdatac.services.factor.get_descriptor_exposure
-get_stock_beta = rqdatac.services.factor.get_stock_beta
-get_factor_covariance = rqdatac.services.factor.get_factor_covariance
-get_specific_return = rqdatac.services.factor.get_specific_return
-get_specific_risk = rqdatac.services.factor.get_specific_risk
-get_index_factor_exposure = rqdatac.services.factor.get_index_factor_exposure
-get_pit_financials_ex = rqdatac.services.financial.get_pit_financials_ex
-current_performance = rqdatac.services.financial.current_performance
-performance_forecast = rqdatac.services.financial.performance_forecast
-get_capital_flow = rqdatac.services.get_capital_flow.get_capital_flow
-get_open_auction_info = rqdatac.services.get_capital_flow.get_open_auction_info
-get_close_auction_info = rqdatac.services.get_capital_flow.get_close_auction_info
-index_components = rqdatac.services.index.index_components
-index_weights = rqdatac.services.index.index_weights
-index_indicator = rqdatac.services.index.index_indicator
-index_weights_ex = rqdatac.services.index.index_weights_ex
-get_ksh_auction_info = rqdatac.services.ksh_auction_info.get_ksh_auction_info
-get_split = rqdatac.services.market_data.get_split
-get_dividend = rqdatac.services.market_data.get_dividend
-get_dividend_info = rqdatac.services.market_data.get_dividend_info
-get_ex_factor = rqdatac.services.market_data.get_ex_factor
-get_turnover_rate = rqdatac.services.market_data.get_turnover_rate
-get_price_change_rate = rqdatac.services.market_data.get_price_change_rate
-get_yield_curve = rqdatac.services.market_data.get_yield_curve
-get_block_trade = rqdatac.services.market_data.get_block_trade
-get_exchange_rate = rqdatac.services.market_data.get_exchange_rate
-get_temporary_code = rqdatac.services.market_data.get_temporary_code
-get_interbank_offered_rate = rqdatac.services.market_data.get_interbank_offered_rate
-
-
-class options:
-    get_contract_property = rqdatac.services.options.get_contract_property
-    get_contracts = rqdatac.services.options.get_contracts
-    get_greeks = rqdatac.services.options.get_greeks
-
-
-class fenji:
-    get = rqdatac.services.structured_fund.get
-    get_a_by_interest_rule = rqdatac.services.structured_fund.get_a_by_interest_rule
-    get_a_by_yield = rqdatac.services.structured_fund.get_a_by_yield
-    get_all = rqdatac.services.structured_fund.get_all
-
-
-ecommerce = rqdatac.services.tmall.ecommerce
-
-
-class xueqiu:
-    history = rqdatac.services.xueqiu.history
-    top_stocks = rqdatac.services.xueqiu.top_stocks
-
-
-class consensus:
-    get_indicator = rqdatac.services.consensus.get_indicator
-    get_price = rqdatac.services.consensus.get_price
-    get_comp_indicators = rqdatac.services.consensus.get_comp_indicators
-    all_industries = rqdatac.services.consensus.all_industries
-    get_industry_rating = rqdatac.services.consensus.get_industry_rating
-    get_market_estimate = rqdatac.services.consensus.get_market_estimate
-    get_security_change = rqdatac.services.consensus.get_security_change
-    get_expect_appr_exceed = rqdatac.services.consensus.get_expect_appr_exceed
-    get_expect_prob = rqdatac.services.consensus.get_expect_prob
-    get_factor = rqdatac.services.consensus.get_factor
-    get_analyst_momentum = rqdatac.services.consensus.get_analyst_momentum
-
-
-current_freefloat_turnover = rqdatac.services.extra.current_freefloat_turnover
-get_live_minute_price_change_rate = rqdatac.services.extra.get_live_minute_price_change_rate
+import rqdatac.services.basic
+import rqdatac.services.get_price
+import rqdatac.services.consensus
+import rqdatac.services.calendar
+import rqdatac.services.financial
+import rqdatac.services.concept
+import rqdatac.services.get_capital_flow
+import rqdatac.services.async_live_md_client
+import rqdatac.services.market_data
+import rqdatac.services.extra
+import rqdatac.services.tmall
+import rqdatac.services.stock_status
+import rqdatac.services.ksh_auction_info
+import rqdatac.services.constant
+import rqdatac.services.shenwan
+import rqdatac.services.factor
+import rqdatac.services.live
+import rqdatac.services.live_md_client
+import rqdatac.client
+import rqdatac.services.index
+import rqdatac.services.future
+
+__version__: str = ...
+init = rqdatac.client.init
+reset = rqdatac.client.reset
+initialized = rqdatac.client.initialized
+concept_list = rqdatac.services.concept.concept_list
+concept = rqdatac.services.concept.concept
+concept_names = rqdatac.services.concept.concept_names
+shenwan_industry = rqdatac.services.shenwan.shenwan_industry
+shenwan_instrument_industry = rqdatac.services.shenwan.shenwan_instrument_industry
+zx_industry = rqdatac.services.shenwan.zx_industry
+zx_instrument_industry = rqdatac.services.shenwan.zx_instrument_industry
+get_industry = rqdatac.services.shenwan.get_industry
+get_instrument_industry = rqdatac.services.shenwan.get_instrument_industry
+get_industry_mapping = rqdatac.services.shenwan.get_industry_mapping
+industry_code = rqdatac.services.constant.IndustryCode
+IndustryCode = rqdatac.services.constant.IndustryCode
+sector_code = rqdatac.services.constant.SectorCode
+SectorCode = rqdatac.services.constant.SectorCode
+get_trading_dates = rqdatac.services.calendar.get_trading_dates
+get_next_trading_date = rqdatac.services.calendar.get_next_trading_date
+get_previous_trading_date = rqdatac.services.calendar.get_previous_trading_date
+get_latest_trading_date = rqdatac.services.calendar.get_latest_trading_date
+get_future_latest_trading_date = rqdatac.services.calendar.get_future_latest_trading_date
+trading_date_offset = rqdatac.services.calendar.trading_date_offset
+is_trading_date = rqdatac.services.calendar.is_trading_date
+has_night_trading = rqdatac.services.calendar.has_night_trading
+id_convert = rqdatac.services.basic.id_convert
+instruments = rqdatac.services.basic.instruments
+all_instruments = rqdatac.services.basic.all_instruments
+sector = rqdatac.services.basic.sector
+industry = rqdatac.services.basic.industry
+get_future_contracts = rqdatac.services.basic.get_future_contracts
+futures: str = ...
+jy_instrument_industry = rqdatac.services.basic.jy_instrument_industry
+econ: str = ...
+get_main_shareholder = rqdatac.services.basic.get_main_shareholder
+get_current_news = rqdatac.services.basic.get_current_news
+get_trading_hours = rqdatac.services.basic.get_trading_hours
+get_private_placement = rqdatac.services.basic.get_private_placement
+get_share_transformation = rqdatac.services.basic.get_share_transformation
+user: str = ...
+get_update_status = rqdatac.services.basic.get_update_status
+info = rqdatac.services.basic.info
+get_basic_info = rqdatac.services.basic.get_basic_info
+get_spot_benchmark_price = rqdatac.services.basic.get_spot_benchmark_price
+LiveMarketDataClient = rqdatac.services.live_md_client.LiveMarketDataClient
+AsyncLiveMarketDataClient = rqdatac.services.async_live_md_client.AsyncLiveMarketDataClient
+consensus: str = ...
+get_consensus_indicator = rqdatac.services.consensus.get_indicator
+get_consensus_price = rqdatac.services.consensus.get_price
+get_consensus_comp_indicators = rqdatac.services.consensus.get_comp_indicators
+all_consensus_industries = rqdatac.services.consensus.all_industries
+get_consensus_industry_rating = rqdatac.services.consensus.get_industry_rating
+get_consensus_market_estimate = rqdatac.services.consensus.get_market_estimate
+convertible: str = ...
+get_dominant_future = rqdatac.services.future.get_dominant_future
+future_commission_margin = rqdatac.services.future.future_commission_margin
+get_future_member_rank = rqdatac.services.future.get_future_member_rank
+current_stock_connect_quota = rqdatac.services.stock_status.current_stock_connect_quota
+get_stock_connect_quota = rqdatac.services.stock_status.get_stock_connect_quota
+is_st_stock = rqdatac.services.stock_status.is_st_stock
+_is_st_stock = rqdatac.services.stock_status._is_st_stock
+is_suspended = rqdatac.services.stock_status.is_suspended
+get_stock_connect = rqdatac.services.stock_status.get_stock_connect
+get_securities_margin = rqdatac.services.stock_status.get_securities_margin
+get_margin_stocks = rqdatac.services.stock_status.get_margin_stocks
+get_shares = rqdatac.services.stock_status.get_shares
+get_allotment = rqdatac.services.stock_status.get_allotment
+get_symbol_change_info = rqdatac.services.stock_status.get_symbol_change_info
+get_special_treatment_info = rqdatac.services.stock_status.get_special_treatment_info
+get_incentive_plan = rqdatac.services.stock_status.get_incentive_plan
+get_investor_ra = rqdatac.services.stock_status.get_investor_ra
+get_announcement = rqdatac.services.stock_status.get_announcement
+get_holder_number = rqdatac.services.stock_status.get_holder_number
+get_audit_opinion = rqdatac.services.stock_status.get_audit_opinion
+current_snapshot = rqdatac.services.live.current_snapshot
+get_ticks = rqdatac.services.live.get_ticks
+current_minute = rqdatac.services.live.current_minute
+get_live_ticks = rqdatac.services.live.get_live_ticks
+get_price = rqdatac.services.get_price.get_price
+get_stock_connect_holding_details = rqdatac.services.get_price.get_stock_connect_holding_details
+get_vwap = rqdatac.services.get_price.get_vwap
+current_freefloat_turnover = rqdatac.services.extra.current_freefloat_turnover
+get_live_minute_price_change_rate = rqdatac.services.extra.get_live_minute_price_change_rate
+get_all_factor_names = rqdatac.services.factor.get_all_factor_names
+get_factor = rqdatac.services.factor.get_factor
+get_factor_return = rqdatac.services.factor.get_factor_return
+get_factor_exposure = rqdatac.services.factor.get_factor_exposure
+get_style_factor_exposure = rqdatac.services.factor.get_style_factor_exposure
+get_descriptor_exposure = rqdatac.services.factor.get_descriptor_exposure
+get_stock_beta = rqdatac.services.factor.get_stock_beta
+get_factor_covariance = rqdatac.services.factor.get_factor_covariance
+get_specific_return = rqdatac.services.factor.get_specific_return
+get_specific_risk = rqdatac.services.factor.get_specific_risk
+get_index_factor_exposure = rqdatac.services.factor.get_index_factor_exposure
+get_pit_financials_ex = rqdatac.services.financial.get_pit_financials_ex
+current_performance = rqdatac.services.financial.current_performance
+performance_forecast = rqdatac.services.financial.performance_forecast
+get_capital_flow = rqdatac.services.get_capital_flow.get_capital_flow
+get_open_auction_info = rqdatac.services.get_capital_flow.get_open_auction_info
+get_close_auction_info = rqdatac.services.get_capital_flow.get_close_auction_info
+index_components = rqdatac.services.index.index_components
+index_weights = rqdatac.services.index.index_weights
+index_indicator = rqdatac.services.index.index_indicator
+index_weights_ex = rqdatac.services.index.index_weights_ex
+get_ksh_auction_info = rqdatac.services.ksh_auction_info.get_ksh_auction_info
+get_auction_info = rqdatac.services.ksh_auction_info.get_auction_info
+get_split = rqdatac.services.market_data.get_split
+get_dividend = rqdatac.services.market_data.get_dividend
+get_dividend_info = rqdatac.services.market_data.get_dividend_info
+get_dividend_amount = rqdatac.services.market_data.get_dividend_amount
+get_ex_factor = rqdatac.services.market_data.get_ex_factor
+get_turnover_rate = rqdatac.services.market_data.get_turnover_rate
+get_price_change_rate = rqdatac.services.market_data.get_price_change_rate
+get_yield_curve = rqdatac.services.market_data.get_yield_curve
+get_block_trade = rqdatac.services.market_data.get_block_trade
+get_exchange_rate = rqdatac.services.market_data.get_exchange_rate
+get_temporary_code = rqdatac.services.market_data.get_temporary_code
+get_interbank_offered_rate = rqdatac.services.market_data.get_interbank_offered_rate
+get_abnormal_stocks = rqdatac.services.market_data.get_abnormal_stocks
+get_abnormal_stocks_detail = rqdatac.services.market_data.get_abnormal_stocks_detail
+options: str = ...
+fenji: str = ...
+ecommerce = rqdatac.services.tmall.ecommerce
+xueqiu: str = ...
```

## rqdatac/_internal.py

 * *Ordering differences only*

```diff
@@ -1,39 +1,39 @@
-# -*- coding: utf-8 -*-
-#
-# Copyright 2018 Ricequant, Inc
-import os
-import logging
-
-from . import client
-
-
-class _RQDataClient:
-    def __init__(self):
-        import rqdatad.core.app
-        import rqdatad.__main__
-        import rqdatad.database
-
-        app = rqdatad.core.app.app
-        app.config = rqdatad.__main__.default_config_file()
-        app.init()
-        rqdatad.database.set_database_config(app.config)
-
-        self.app = app
-        self.PID = os.getpid()
-
-    def execute(self, api_name, *args, **kwargs):
-        return self.app.debug_api(api_name, *args, **kwargs)
-
-    def close(self):
-        import asyncio
-
-        loop = self.app.get_event_loop()
-        loop.stop()
-        for task in asyncio.Task.all_tasks():
-            task.cancel()
-        loop.close()
-
-
-def as_rqdata():
-    logging.info('RQDATAC: behave like RQDATA now')
-    client._CLIENT = _RQDataClient()
+# -*- coding: utf-8 -*-
+#
+# Copyright 2018 Ricequant, Inc
+import os
+import logging
+
+from . import client
+
+
+class _RQDataClient:
+    def __init__(self):
+        import rqdatad.core.app
+        import rqdatad.__main__
+        import rqdatad.database
+
+        app = rqdatad.core.app.app
+        app.config = rqdatad.__main__.default_config_file()
+        app.init()
+        rqdatad.database.set_database_config(app.config)
+
+        self.app = app
+        self.PID = os.getpid()
+
+    def execute(self, api_name, *args, **kwargs):
+        return self.app.debug_api(api_name, *args, **kwargs)
+
+    def close(self):
+        import asyncio
+
+        loop = self.app.get_event_loop()
+        loop.stop()
+        for task in asyncio.Task.all_tasks():
+            task.cancel()
+        loop.close()
+
+
+def as_rqdata():
+    logging.info('RQDATAC: behave like RQDATA now')
+    client._CLIENT = _RQDataClient()
```

## rqdatac/_version.py

```diff
@@ -1,21 +1,21 @@
-
-# This file was generated by 'versioneer.py' (0.28) from
-# revision-control system data, or from the parent directory name of an
-# unpacked source archive. Distribution tarballs contain a pre-generated copy
-# of this file.
-
-import json
-
-version_json = '''
-{
- "date": "2024-05-16T15:56:32+0800",
- "dirty": false,
- "error": null,
- "full-revisionid": "47aba1f2d9a9dad27c9c9d70651772520382c204",
- "version": "3.0.6"
-}
-'''  # END VERSION_JSON
-
-
-def get_versions():
-    return json.loads(version_json)
+
+# This file was generated by 'versioneer.py' (0.28) from
+# revision-control system data, or from the parent directory name of an
+# unpacked source archive. Distribution tarballs contain a pre-generated copy
+# of this file.
+
+import json
+
+version_json = '''
+{
+ "date": "2024-05-21T17:47:38+0800",
+ "dirty": false,
+ "error": null,
+ "full-revisionid": "d7fb4192e172f25e72d55a5dcc1fd974cfe2e1ae",
+ "version": "3.0.7.1"
+}
+'''  # END VERSION_JSON
+
+
+def get_versions():
+    return json.loads(version_json)
```

## rqdatac/client.py

 * *Ordering differences only*

```diff
@@ -1,285 +1,285 @@
-# -*- coding: utf-8 -*-
-import os
-import re
-import socket
-import warnings
-import logging
-from functools import partial, wraps
-
-from six.moves.urllib.parse import urlparse
-from six import string_types
-from sys import platform
-import rqdatac
-
-URI_PATTERN = r"^(?P<schema>tcp|rqdatac?)://(?P<username>\S+?):(?P<password>\S+)@(?P<hostname>\S+):(?P<port>\d+$)"
-URI_PATTERN = re.compile(URI_PATTERN)
-
-if getattr(os, "register_at_fork", None):
-    def _close_after_fork():
-        global _CLIENT
-        if _CLIENT is not _DUMMY and _CLIENT.PID != os.getpid():
-            reset()
-
-
-    os.register_at_fork(after_in_child=_close_after_fork)
-
-
-class DummyClient:
-    PID = -1
-
-    def execute(self, *args, **kwargs):
-        raise RuntimeError("rqdatac is not initialized")
-
-    def reset(self):
-        pass
-
-    def info(self):
-        print('rqdatac is not initialized')
-
-    def close(self):
-        pass
-
-    execute_with_timeout = execute
-
-
-_DUMMY = DummyClient()
-
-_CLIENT = _DUMMY
-
-_PLUGINS_IMPORTED = False
-
-
-def reset(flush_cache=False):
-    """
-    reset all connections. this function is helpful when you fork from an connected client.
-
-    :params flush_cache: boolean, flush all ttl cache, default False
-    """
-    _CLIENT.reset()
-    _CLIENT.PID = os.getpid()
-    if flush_cache:
-        from rqdatac.decorators import ttl_cache_clear
-        ttl_cache_clear()
-
-
-def initialized():
-    """
-    is rqdatac already initialized ?
-
-    :return: Bool
-    """
-    global _CLIENT, _DUMMY
-    return _CLIENT is not _DUMMY
-
-
-def set_sock_opts(func):
-    @wraps(func)
-    def wrap(*args, **kwargs):
-        s = func(*args, **kwargs)
-        s.setsockopt(socket.SOL_TCP, socket.TCP_NODELAY, 1)
-        s.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)
-        try:
-            if platform.startswith('linux'):
-                # (unit:s)
-                s.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPINTVL, 60)
-                s.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPIDLE, 5 * 60)
-            elif platform.startswith('darwin'):  # macos
-                s.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPINTVL, 60)
-            elif platform.startswith('win'):  # windows
-                # (unit:ms) since windows2000
-                s.ioctl(socket.SIO_KEEPALIVE_VALS, (1, 5 * 60 * 1000, 60 * 1000))
-            s.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPCNT, 20)
-        except:
-            pass
-        return s
-
-    return wrap
-
-
-def _parse_proxy_url(proxy_url):
-    if not proxy_url:
-        return
-
-    proxy = urlparse(proxy_url)
-    return proxy.scheme, proxy.hostname or proxy.path, proxy.port, proxy.username, proxy.password
-
-
-def _set_sock_factory(proxy_info):
-    from rqdatac.connection import Connection
-    if proxy_info is None:
-        conn = socket.create_connection
-    else:
-        try:
-            import socks
-        except ImportError:
-            raise RuntimeError("PySocks is required when use proxy. You can install it using `pip install PySocks` or "
-                               "`pip install rqdatac[proxy]`")
-
-        if not isinstance(proxy_info, tuple) or len(proxy_info) != 5:
-            raise ValueError("expected a tuple like (proxy_type, host, port, user, password)")
-
-        proxy_type, host, port, user, password = proxy_info
-        if proxy_type.upper() == "HTTP":
-            proxy_type = socks.PROXY_TYPE_HTTP
-        elif proxy_type.upper() == "SOCKS4":
-            proxy_type = socks.PROXY_TYPE_SOCKS4
-        elif proxy_type.upper() == "SOCKS5":
-            proxy_type = socks.PROXY_TYPE_SOCKS5
-        else:
-            raise ValueError("proxy type {} not supported yet. http, socks4 and socks5 proxy are supported".format(proxy_type))
-        conn = partial(socks.create_connection, proxy_type=proxy_type, proxy_addr=host, proxy_port=port,
-                       proxy_username=user, proxy_password=password)
-
-    Connection.set_sock_factory(set_sock_opts(conn))
-
-
-def init(username=None, password=None, addr=("rqdatad-pro.ricequant.com", 16011), *_, **kwargs):
-    """initialize rqdatac.
-
-    rqdatac connection is thread safe but not fork safe. Every thread have their own connection by
-    default. you can set param 'use_pool' to True to use a connection pool instead.
-
-    NOTE: if you are using rqdatac with python < 3.7 in a multi-process program, remember to call
-    reset in child process.
-
-    Environment Variable:
-    RQDATAC_CONF / RQDATAC2_CONF: When init called with no argument, the value in RQDATAC2_CONF is used as uri, then RQDATAC_CONF.
-    RQDATAC_PROXY: proxy info, e.g. http://username:password@host:port
-
-    :param username: string
-    :param password: string
-    :param addr: ('127.0.0.1', 80) or '127.0.0.1:80'
-
-    :keyword uri: keyword only. a uri like rqdata://username:password@host:port or tcp://username:password@host:port
-    :keyword connect_timeout: socket connect connect timeout, default is 5 sec.
-    :keyword timeout: socket time out, default is 60 sec.
-    :keyword lazy: True by default, means "do not connect to server immediately".
-    :keyword use_pool: use connection pool. default is False
-    :keyword max_pool_size: max pool size, default is 8
-    :keyword proxy_info: a tuple like (proxy_type, host, port, user, password) if use proxy, default is None
-    :keyword auto_load_plugins: boolean, enable or disable auto load plugin, default to True.
-    :keyword use_zstd: using zstd compression method to transfer data, default to False.
-    """
-    extra_args = {k: kwargs.pop(k) for k in ('timeout', 'connect_timeout') if k in kwargs}
-    proxy_info = kwargs.pop('proxy_info', None) or _parse_proxy_url(os.environ.get('RQDATAC_PROXY'))
-    _set_sock_factory(proxy_info)
-
-    logging.getLogger("rqdatac").disabled = not kwargs.pop('debug', False)
-
-    if kwargs.pop("use_zstd", False):
-        try:
-            import zstandard
-        except ImportError:
-            raise RuntimeError("zstandard is not installed, you can try `pip install zstandard`, or making `use_zstd = False`")
-        from rqdatac import connection
-        from rqdatac.share.protocol import COMPRESSION_METHOD
-        connection.DEFAULT_COMPRESSION_METHOD = COMPRESSION_METHOD.ZSTD
-    uri = kwargs.pop("uri", None)
-    if not (username or password or uri):
-        uri = os.environ.get("RQDATAC2_CONF") or os.environ.get("RQDATAC_CONF")
-    if username and password and addr:
-        addr = parse_address(addr)
-    elif uri:
-        r = URI_PATTERN.match(uri)
-        if r is not None:
-            username = username or r.group('username')
-            password = password or r.group('password')
-            addr = parse_address((r.group("hostname"), r.group("port")))
-        else:
-            raise ValueError("uri invalid")
-    else:
-        err = ValueError("username/password/addr or uri expected")
-        if not username:
-            raise err
-        r = URI_PATTERN.match(username)
-        # pass uri as first argument.
-        if not r:
-            raise err
-        username = r.group('username')
-        password = r.group('password')
-        addr = parse_address((r.group("hostname"), r.group("port")))
-        if not (username and password):
-            raise err
-
-    global _CLIENT
-    if _CLIENT is not _DUMMY:
-        warnings.warn("rqdatac is already inited. Settings will be changed.", stacklevel=0)
-        reset()
-
-    global _PLUGINS_IMPORTED
-    if not _PLUGINS_IMPORTED:
-        if kwargs.get("auto_load_plugins", True):
-            _auto_import_plugin()
-            _PLUGINS_IMPORTED = True
-
-    auth_info = {'username': username, 'password': password, 'ver': rqdatac.__version__}
-    if kwargs.pop("use_pool", False):
-        from .connection_pool import ConnectionPool
-        max_pool_size = kwargs.pop("max_pool_size", 8)
-        _CLIENT = ConnectionPool(addr, auth=auth_info, max_pool_size=max_pool_size, **extra_args)
-    else:
-        from .thread_local import ThreadLocalConnection
-        _CLIENT = ThreadLocalConnection(addr, auth=auth_info, **extra_args)
-
-    _CLIENT.PID = os.getpid()
-
-    def show_info():
-        print('rqdatac version:', rqdatac.__version__)
-        print('server address: {}:{}'.format(addr[0], addr[1]))
-        if username == 'license':
-            print('You are using license:\r\n{}'.format(password))
-        elif username.startswith('rqpro.'):
-            print('You are using a RQPro account: {}'.format(username.split('.', 1)[1]))
-        elif username == 'sid':
-            print('You are using your RQPro account')
-        else:
-            print('You are using account: {}'.format(username))
-
-    _CLIENT.info = show_info
-
-    if username == "license":
-        quota = get_client().execute("user.get_quota")
-        remaining_days = quota["remaining_days"]
-        is_trial = quota["license_type"] == "TRIAL"
-        if is_trial or 0 <= remaining_days <= 14:
-            warnings.warn("Your account will be expired after  {} days. "
-                          "Please call us at 0755-22676337 to upgrade or purchase or "
-                          "renew your contract.".format(remaining_days))
-    elif not kwargs.get("lazy", True):
-        get_client().execute("get_all_trading_dates")
-
-
-def get_client():
-    if _CLIENT.PID != os.getpid():
-        reset()
-    return _CLIENT
-
-
-def parse_address(address):
-    if isinstance(address, tuple):
-        host, port = address
-        return host, int(port)
-    elif isinstance(address, string_types):
-        if ":" not in address:
-            return address
-        host, port = address.rsplit(":", 1)
-        return host, int(port)
-    else:
-        raise ValueError("address must be a str or tuple")
-
-
-def _auto_import_plugin():
-    from pkgutil import iter_modules
-    from importlib import import_module
-    plugin_module_names = []
-    for m in iter_modules():
-        _, name, is_pkg = m
-        if not is_pkg:
-            continue
-        if name.startswith('rqdatac_'):
-            plugin_module_names.append(name)
-
-    plugin_module_names.sort()
-    for name in plugin_module_names:
-        logging.getLogger("rqdatac").info("loading plugin {}".format(name))
-        import_module(name)
+# -*- coding: utf-8 -*-
+import os
+import re
+import socket
+import warnings
+import logging
+from functools import partial, wraps
+
+from six.moves.urllib.parse import urlparse
+from six import string_types
+from sys import platform
+import rqdatac
+
+URI_PATTERN = r"^(?P<schema>tcp|rqdatac?)://(?P<username>\S+?):(?P<password>\S+)@(?P<hostname>\S+):(?P<port>\d+$)"
+URI_PATTERN = re.compile(URI_PATTERN)
+
+if getattr(os, "register_at_fork", None):
+    def _close_after_fork():
+        global _CLIENT
+        if _CLIENT is not _DUMMY and _CLIENT.PID != os.getpid():
+            reset()
+
+
+    os.register_at_fork(after_in_child=_close_after_fork)
+
+
+class DummyClient:
+    PID = -1
+
+    def execute(self, *args, **kwargs):
+        raise RuntimeError("rqdatac is not initialized")
+
+    def reset(self):
+        pass
+
+    def info(self):
+        print('rqdatac is not initialized')
+
+    def close(self):
+        pass
+
+    execute_with_timeout = execute
+
+
+_DUMMY = DummyClient()
+
+_CLIENT = _DUMMY
+
+_PLUGINS_IMPORTED = False
+
+
+def reset(flush_cache=False):
+    """
+    reset all connections. this function is helpful when you fork from an connected client.
+
+    :params flush_cache: boolean, flush all ttl cache, default False
+    """
+    _CLIENT.reset()
+    _CLIENT.PID = os.getpid()
+    if flush_cache:
+        from rqdatac.decorators import ttl_cache_clear
+        ttl_cache_clear()
+
+
+def initialized():
+    """
+    is rqdatac already initialized ?
+
+    :return: Bool
+    """
+    global _CLIENT, _DUMMY
+    return _CLIENT is not _DUMMY
+
+
+def set_sock_opts(func):
+    @wraps(func)
+    def wrap(*args, **kwargs):
+        s = func(*args, **kwargs)
+        s.setsockopt(socket.SOL_TCP, socket.TCP_NODELAY, 1)
+        s.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)
+        try:
+            if platform.startswith('linux'):
+                # (unit:s)
+                s.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPINTVL, 60)
+                s.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPIDLE, 5 * 60)
+            elif platform.startswith('darwin'):  # macos
+                s.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPINTVL, 60)
+            elif platform.startswith('win'):  # windows
+                # (unit:ms) since windows2000
+                s.ioctl(socket.SIO_KEEPALIVE_VALS, (1, 5 * 60 * 1000, 60 * 1000))
+            s.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPCNT, 20)
+        except:
+            pass
+        return s
+
+    return wrap
+
+
+def _parse_proxy_url(proxy_url):
+    if not proxy_url:
+        return
+
+    proxy = urlparse(proxy_url)
+    return proxy.scheme, proxy.hostname or proxy.path, proxy.port, proxy.username, proxy.password
+
+
+def _set_sock_factory(proxy_info):
+    from rqdatac.connection import Connection
+    if proxy_info is None:
+        conn = socket.create_connection
+    else:
+        try:
+            import socks
+        except ImportError:
+            raise RuntimeError("PySocks is required when use proxy. You can install it using `pip install PySocks` or "
+                               "`pip install rqdatac[proxy]`")
+
+        if not isinstance(proxy_info, tuple) or len(proxy_info) != 5:
+            raise ValueError("expected a tuple like (proxy_type, host, port, user, password)")
+
+        proxy_type, host, port, user, password = proxy_info
+        if proxy_type.upper() == "HTTP":
+            proxy_type = socks.PROXY_TYPE_HTTP
+        elif proxy_type.upper() == "SOCKS4":
+            proxy_type = socks.PROXY_TYPE_SOCKS4
+        elif proxy_type.upper() == "SOCKS5":
+            proxy_type = socks.PROXY_TYPE_SOCKS5
+        else:
+            raise ValueError("proxy type {} not supported yet. http, socks4 and socks5 proxy are supported".format(proxy_type))
+        conn = partial(socks.create_connection, proxy_type=proxy_type, proxy_addr=host, proxy_port=port,
+                       proxy_username=user, proxy_password=password)
+
+    Connection.set_sock_factory(set_sock_opts(conn))
+
+
+def init(username=None, password=None, addr=("rqdatad-pro.ricequant.com", 16011), *_, **kwargs):
+    """initialize rqdatac.
+
+    rqdatac connection is thread safe but not fork safe. Every thread have their own connection by
+    default. you can set param 'use_pool' to True to use a connection pool instead.
+
+    NOTE: if you are using rqdatac with python < 3.7 in a multi-process program, remember to call
+    reset in child process.
+
+    Environment Variable:
+    RQDATAC_CONF / RQDATAC2_CONF: When init called with no argument, the value in RQDATAC2_CONF is used as uri, then RQDATAC_CONF.
+    RQDATAC_PROXY: proxy info, e.g. http://username:password@host:port
+
+    :param username: string
+    :param password: string
+    :param addr: ('127.0.0.1', 80) or '127.0.0.1:80'
+
+    :keyword uri: keyword only. a uri like rqdata://username:password@host:port or tcp://username:password@host:port
+    :keyword connect_timeout: socket connect connect timeout, default is 5 sec.
+    :keyword timeout: socket time out, default is 60 sec.
+    :keyword lazy: True by default, means "do not connect to server immediately".
+    :keyword use_pool: use connection pool. default is False
+    :keyword max_pool_size: max pool size, default is 8
+    :keyword proxy_info: a tuple like (proxy_type, host, port, user, password) if use proxy, default is None
+    :keyword auto_load_plugins: boolean, enable or disable auto load plugin, default to True.
+    :keyword use_zstd: using zstd compression method to transfer data, default to False.
+    """
+    extra_args = {k: kwargs.pop(k) for k in ('timeout', 'connect_timeout') if k in kwargs}
+    proxy_info = kwargs.pop('proxy_info', None) or _parse_proxy_url(os.environ.get('RQDATAC_PROXY'))
+    _set_sock_factory(proxy_info)
+
+    logging.getLogger("rqdatac").disabled = not kwargs.pop('debug', False)
+
+    if kwargs.pop("use_zstd", False):
+        try:
+            import zstandard
+        except ImportError:
+            raise RuntimeError("zstandard is not installed, you can try `pip install zstandard`, or making `use_zstd = False`")
+        from rqdatac import connection
+        from rqdatac.share.protocol import COMPRESSION_METHOD
+        connection.DEFAULT_COMPRESSION_METHOD = COMPRESSION_METHOD.ZSTD
+    uri = kwargs.pop("uri", None)
+    if not (username or password or uri):
+        uri = os.environ.get("RQDATAC2_CONF") or os.environ.get("RQDATAC_CONF")
+    if username and password and addr:
+        addr = parse_address(addr)
+    elif uri:
+        r = URI_PATTERN.match(uri)
+        if r is not None:
+            username = username or r.group('username')
+            password = password or r.group('password')
+            addr = parse_address((r.group("hostname"), r.group("port")))
+        else:
+            raise ValueError("uri invalid")
+    else:
+        err = ValueError("username/password/addr or uri expected")
+        if not username:
+            raise err
+        r = URI_PATTERN.match(username)
+        # pass uri as first argument.
+        if not r:
+            raise err
+        username = r.group('username')
+        password = r.group('password')
+        addr = parse_address((r.group("hostname"), r.group("port")))
+        if not (username and password):
+            raise err
+
+    global _CLIENT
+    if _CLIENT is not _DUMMY:
+        warnings.warn("rqdatac is already inited. Settings will be changed.", stacklevel=0)
+        reset()
+
+    global _PLUGINS_IMPORTED
+    if not _PLUGINS_IMPORTED:
+        if kwargs.get("auto_load_plugins", True):
+            _auto_import_plugin()
+            _PLUGINS_IMPORTED = True
+
+    auth_info = {'username': username, 'password': password, 'ver': rqdatac.__version__}
+    if kwargs.pop("use_pool", False):
+        from .connection_pool import ConnectionPool
+        max_pool_size = kwargs.pop("max_pool_size", 8)
+        _CLIENT = ConnectionPool(addr, auth=auth_info, max_pool_size=max_pool_size, **extra_args)
+    else:
+        from .thread_local import ThreadLocalConnection
+        _CLIENT = ThreadLocalConnection(addr, auth=auth_info, **extra_args)
+
+    _CLIENT.PID = os.getpid()
+
+    def show_info():
+        print('rqdatac version:', rqdatac.__version__)
+        print('server address: {}:{}'.format(addr[0], addr[1]))
+        if username == 'license':
+            print('You are using license:\r\n{}'.format(password))
+        elif username.startswith('rqpro.'):
+            print('You are using a RQPro account: {}'.format(username.split('.', 1)[1]))
+        elif username == 'sid':
+            print('You are using your RQPro account')
+        else:
+            print('You are using account: {}'.format(username))
+
+    _CLIENT.info = show_info
+
+    if username == "license":
+        quota = get_client().execute("user.get_quota")
+        remaining_days = quota["remaining_days"]
+        is_trial = quota["license_type"] == "TRIAL"
+        if is_trial or 0 <= remaining_days <= 14:
+            warnings.warn("Your account will be expired after  {} days. "
+                          "Please call us at 0755-22676337 to upgrade or purchase or "
+                          "renew your contract.".format(remaining_days))
+    elif not kwargs.get("lazy", True):
+        get_client().execute("get_all_trading_dates")
+
+
+def get_client():
+    if _CLIENT.PID != os.getpid():
+        reset()
+    return _CLIENT
+
+
+def parse_address(address):
+    if isinstance(address, tuple):
+        host, port = address
+        return host, int(port)
+    elif isinstance(address, string_types):
+        if ":" not in address:
+            return address
+        host, port = address.rsplit(":", 1)
+        return host, int(port)
+    else:
+        raise ValueError("address must be a str or tuple")
+
+
+def _auto_import_plugin():
+    from pkgutil import iter_modules
+    from importlib import import_module
+    plugin_module_names = []
+    for m in iter_modules():
+        _, name, is_pkg = m
+        if not is_pkg:
+            continue
+        if name.startswith('rqdatac_'):
+            plugin_module_names.append(name)
+
+    plugin_module_names.sort()
+    for name in plugin_module_names:
+        logging.getLogger("rqdatac").info("loading plugin {}".format(name))
+        import_module(name)
```

## rqdatac/connection.cpp

```diff
@@ -1,8 +1,8 @@
-/* Generated by Cython 3.0.5 */
+/* Generated by Cython 3.0.10 */
 
 /* BEGIN: Cython Metadata
 {
     "distutils": {
         "language": "c++",
         "name": "rqdatac.connection",
         "sources": [
@@ -33,18 +33,18 @@
     #error Cython requires Python 2.7+ or Python 3.3+.
 #else
 #if defined(CYTHON_LIMITED_API) && CYTHON_LIMITED_API
 #define __PYX_EXTRA_ABI_MODULE_NAME "limited"
 #else
 #define __PYX_EXTRA_ABI_MODULE_NAME ""
 #endif
-#define CYTHON_ABI "3_0_5" __PYX_EXTRA_ABI_MODULE_NAME
+#define CYTHON_ABI "3_0_10" __PYX_EXTRA_ABI_MODULE_NAME
 #define __PYX_ABI_MODULE_NAME "_cython_" CYTHON_ABI
 #define __PYX_TYPE_MODULE_PREFIX __PYX_ABI_MODULE_NAME "."
-#define CYTHON_HEX_VERSION 0x030005F0
+#define CYTHON_HEX_VERSION 0x03000AF0
 #define CYTHON_FUTURE_DIVISION 1
 #include <stddef.h>
 #ifndef offsetof
   #define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
 #endif
 #if !defined(_WIN32) && !defined(WIN32) && !defined(MS_WINDOWS)
   #ifndef __stdcall
@@ -128,14 +128,16 @@
   #undef CYTHON_USE_DICT_VERSIONS
   #define CYTHON_USE_DICT_VERSIONS 0
   #undef CYTHON_USE_EXC_INFO_STACK
   #define CYTHON_USE_EXC_INFO_STACK 0
   #ifndef CYTHON_UPDATE_DESCRIPTOR_DOC
     #define CYTHON_UPDATE_DESCRIPTOR_DOC 0
   #endif
+  #undef CYTHON_USE_FREELISTS
+  #define CYTHON_USE_FREELISTS 0
 #elif defined(PYPY_VERSION)
   #define CYTHON_COMPILING_IN_PYPY 1
   #define CYTHON_COMPILING_IN_CPYTHON 0
   #define CYTHON_COMPILING_IN_LIMITED_API 0
   #define CYTHON_COMPILING_IN_GRAAL 0
   #define CYTHON_COMPILING_IN_NOGIL 0
   #undef CYTHON_USE_TYPE_SLOTS
@@ -189,14 +191,16 @@
   #undef CYTHON_USE_DICT_VERSIONS
   #define CYTHON_USE_DICT_VERSIONS 0
   #undef CYTHON_USE_EXC_INFO_STACK
   #define CYTHON_USE_EXC_INFO_STACK 0
   #ifndef CYTHON_UPDATE_DESCRIPTOR_DOC
     #define CYTHON_UPDATE_DESCRIPTOR_DOC 0
   #endif
+  #undef CYTHON_USE_FREELISTS
+  #define CYTHON_USE_FREELISTS 0
 #elif defined(CYTHON_LIMITED_API)
   #ifdef Py_LIMITED_API
     #undef __PYX_LIMITED_VERSION_HEX
     #define __PYX_LIMITED_VERSION_HEX Py_LIMITED_API
   #endif
   #define CYTHON_COMPILING_IN_PYPY 0
   #define CYTHON_COMPILING_IN_CPYTHON 0
@@ -250,60 +254,83 @@
   #undef CYTHON_USE_DICT_VERSIONS
   #define CYTHON_USE_DICT_VERSIONS 0
   #undef CYTHON_USE_EXC_INFO_STACK
   #define CYTHON_USE_EXC_INFO_STACK 0
   #ifndef CYTHON_UPDATE_DESCRIPTOR_DOC
     #define CYTHON_UPDATE_DESCRIPTOR_DOC 0
   #endif
-#elif defined(PY_NOGIL)
+  #undef CYTHON_USE_FREELISTS
+  #define CYTHON_USE_FREELISTS 0
+#elif defined(Py_GIL_DISABLED) || defined(Py_NOGIL)
   #define CYTHON_COMPILING_IN_PYPY 0
   #define CYTHON_COMPILING_IN_CPYTHON 0
   #define CYTHON_COMPILING_IN_LIMITED_API 0
   #define CYTHON_COMPILING_IN_GRAAL 0
   #define CYTHON_COMPILING_IN_NOGIL 1
   #ifndef CYTHON_USE_TYPE_SLOTS
     #define CYTHON_USE_TYPE_SLOTS 1
   #endif
+  #ifndef CYTHON_USE_TYPE_SPECS
+    #define CYTHON_USE_TYPE_SPECS 0
+  #endif
   #undef CYTHON_USE_PYTYPE_LOOKUP
   #define CYTHON_USE_PYTYPE_LOOKUP 0
   #ifndef CYTHON_USE_ASYNC_SLOTS
     #define CYTHON_USE_ASYNC_SLOTS 1
   #endif
+  #ifndef CYTHON_USE_PYLONG_INTERNALS
+    #define CYTHON_USE_PYLONG_INTERNALS 0
+  #endif
   #undef CYTHON_USE_PYLIST_INTERNALS
   #define CYTHON_USE_PYLIST_INTERNALS 0
   #ifndef CYTHON_USE_UNICODE_INTERNALS
     #define CYTHON_USE_UNICODE_INTERNALS 1
   #endif
   #undef CYTHON_USE_UNICODE_WRITER
   #define CYTHON_USE_UNICODE_WRITER 0
-  #undef CYTHON_USE_PYLONG_INTERNALS
-  #define CYTHON_USE_PYLONG_INTERNALS 0
   #ifndef CYTHON_AVOID_BORROWED_REFS
     #define CYTHON_AVOID_BORROWED_REFS 0
   #endif
   #ifndef CYTHON_ASSUME_SAFE_MACROS
     #define CYTHON_ASSUME_SAFE_MACROS 1
   #endif
   #ifndef CYTHON_UNPACK_METHODS
     #define CYTHON_UNPACK_METHODS 1
   #endif
   #undef CYTHON_FAST_THREAD_STATE
   #define CYTHON_FAST_THREAD_STATE 0
+  #undef CYTHON_FAST_GIL
+  #define CYTHON_FAST_GIL 0
+  #ifndef CYTHON_METH_FASTCALL
+    #define CYTHON_METH_FASTCALL 1
+  #endif
   #undef CYTHON_FAST_PYCALL
   #define CYTHON_FAST_PYCALL 0
+  #ifndef CYTHON_PEP487_INIT_SUBCLASS
+    #define CYTHON_PEP487_INIT_SUBCLASS 1
+  #endif
   #ifndef CYTHON_PEP489_MULTI_PHASE_INIT
     #define CYTHON_PEP489_MULTI_PHASE_INIT 1
   #endif
+  #ifndef CYTHON_USE_MODULE_STATE
+    #define CYTHON_USE_MODULE_STATE 0
+  #endif
   #ifndef CYTHON_USE_TP_FINALIZE
     #define CYTHON_USE_TP_FINALIZE 1
   #endif
   #undef CYTHON_USE_DICT_VERSIONS
   #define CYTHON_USE_DICT_VERSIONS 0
   #undef CYTHON_USE_EXC_INFO_STACK
   #define CYTHON_USE_EXC_INFO_STACK 0
+  #ifndef CYTHON_UPDATE_DESCRIPTOR_DOC
+    #define CYTHON_UPDATE_DESCRIPTOR_DOC 1
+  #endif
+  #ifndef CYTHON_USE_FREELISTS
+    #define CYTHON_USE_FREELISTS 0
+  #endif
 #else
   #define CYTHON_COMPILING_IN_PYPY 0
   #define CYTHON_COMPILING_IN_CPYTHON 1
   #define CYTHON_COMPILING_IN_LIMITED_API 0
   #define CYTHON_COMPILING_IN_GRAAL 0
   #define CYTHON_COMPILING_IN_NOGIL 0
   #ifndef CYTHON_USE_TYPE_SLOTS
@@ -386,14 +413,17 @@
     #define CYTHON_USE_EXC_INFO_STACK 0
   #elif !defined(CYTHON_USE_EXC_INFO_STACK)
     #define CYTHON_USE_EXC_INFO_STACK 1
   #endif
   #ifndef CYTHON_UPDATE_DESCRIPTOR_DOC
     #define CYTHON_UPDATE_DESCRIPTOR_DOC 1
   #endif
+  #ifndef CYTHON_USE_FREELISTS
+    #define CYTHON_USE_FREELISTS 1
+  #endif
 #endif
 #if !defined(CYTHON_FAST_PYCCALL)
 #define CYTHON_FAST_PYCCALL  (CYTHON_FAST_PYCALL && PY_VERSION_HEX >= 0x030600B1)
 #endif
 #if !defined(CYTHON_VECTORCALL)
 #define CYTHON_VECTORCALL  (CYTHON_FAST_PYCCALL && PY_VERSION_HEX >= 0x030800B1)
 #endif
@@ -594,26 +624,27 @@
     static CYTHON_INLINE PyObject* __Pyx_PyCode_New(int a, int p, int k, int l, int s, int f,
                                                     PyObject *code, PyObject *c, PyObject* n, PyObject *v,
                                                     PyObject *fv, PyObject *cell, PyObject* fn,
                                                     PyObject *name, int fline, PyObject *lnos) {
         PyObject *exception_table = NULL;
         PyObject *types_module=NULL, *code_type=NULL, *result=NULL;
         #if __PYX_LIMITED_VERSION_HEX < 0x030B0000
-        PyObject *version_info; // borrowed
-        #endif
+        PyObject *version_info;
         PyObject *py_minor_version = NULL;
+        #endif
         long minor_version = 0;
         PyObject *type, *value, *traceback;
         PyErr_Fetch(&type, &value, &traceback);
         #if __PYX_LIMITED_VERSION_HEX >= 0x030B0000
-        minor_version = 11; // we don't yet need to distinguish between versions > 11
+        minor_version = 11;
         #else
         if (!(version_info = PySys_GetObject("version_info"))) goto end;
         if (!(py_minor_version = PySequence_GetItem(version_info, 1))) goto end;
         minor_version = PyLong_AsLong(py_minor_version);
+        Py_DECREF(py_minor_version);
         if (minor_version == -1 && PyErr_Occurred()) goto end;
         #endif
         if (!(types_module = PyImport_ImportModule("types"))) goto end;
         if (!(code_type = PyObject_GetAttrString(types_module, "CodeType"))) goto end;
         if (minor_version <= 7) {
             (void)p;
             result = PyObject_CallFunction(code_type, "iiiiiOOOOOOiOO", a, k, l, s, f, code,
@@ -626,15 +657,14 @@
             result = PyObject_CallFunction(code_type, "iiiiiiOOOOOOOiOO", a,p, k, l, s, f, code,
                           c, n, v, fn, name, name, fline, lnos, exception_table, fv, cell);
         }
     end:
         Py_XDECREF(code_type);
         Py_XDECREF(exception_table);
         Py_XDECREF(types_module);
-        Py_XDECREF(py_minor_version);
         if (type) {
             PyErr_Restore(type, value, traceback);
         }
         return result;
     }
     #ifndef CO_OPTIMIZED
     #define CO_OPTIMIZED 0x0001
@@ -659,15 +689,15 @@
     #endif
 #elif PY_VERSION_HEX >= 0x030B0000
   static CYTHON_INLINE PyCodeObject* __Pyx_PyCode_New(int a, int p, int k, int l, int s, int f,
                                                     PyObject *code, PyObject *c, PyObject* n, PyObject *v,
                                                     PyObject *fv, PyObject *cell, PyObject* fn,
                                                     PyObject *name, int fline, PyObject *lnos) {
     PyCodeObject *result;
-    PyObject *empty_bytes = PyBytes_FromStringAndSize("", 0);  // we don't have access to __pyx_empty_bytes here
+    PyObject *empty_bytes = PyBytes_FromStringAndSize("", 0);
     if (!empty_bytes) return NULL;
     result =
       #if PY_VERSION_HEX >= 0x030C0000
         PyUnstable_Code_NewWithPosOnlyArgs
       #else
         PyCode_NewWithPosOnlyArgs
       #endif
@@ -745,16 +775,21 @@
   #ifndef METH_FASTCALL
      #define METH_FASTCALL 0x80
   #endif
   typedef PyObject *(*__Pyx_PyCFunctionFast) (PyObject *self, PyObject *const *args, Py_ssize_t nargs);
   typedef PyObject *(*__Pyx_PyCFunctionFastWithKeywords) (PyObject *self, PyObject *const *args,
                                                           Py_ssize_t nargs, PyObject *kwnames);
 #else
-  #define __Pyx_PyCFunctionFast _PyCFunctionFast
-  #define __Pyx_PyCFunctionFastWithKeywords _PyCFunctionFastWithKeywords
+  #if PY_VERSION_HEX >= 0x030d00A4
+  #  define __Pyx_PyCFunctionFast PyCFunctionFast
+  #  define __Pyx_PyCFunctionFastWithKeywords PyCFunctionFastWithKeywords
+  #else
+  #  define __Pyx_PyCFunctionFast _PyCFunctionFast
+  #  define __Pyx_PyCFunctionFastWithKeywords _PyCFunctionFastWithKeywords
+  #endif
 #endif
 #if CYTHON_METH_FASTCALL
   #define __Pyx_METH_FASTCALL METH_FASTCALL
   #define __Pyx_PyCFunction_FastCall __Pyx_PyCFunctionFast
   #define __Pyx_PyCFunction_FastCallWithKeywords __Pyx_PyCFunctionFastWithKeywords
 #else
   #define __Pyx_METH_FASTCALL METH_VARARGS
@@ -954,15 +989,15 @@
 #if CYTHON_COMPILING_IN_LIMITED_API
   #define __Pyx_SetItemOnTypeDict(tp, k, v) PyObject_GenericSetAttr((PyObject*)tp, k, v)
 #else
   #define __Pyx_SetItemOnTypeDict(tp, k, v) PyDict_SetItem(tp->tp_dict, k, v)
 #endif
 #if CYTHON_USE_TYPE_SPECS && PY_VERSION_HEX >= 0x03080000
 #define __Pyx_PyHeapTypeObject_GC_Del(obj)  {\
-    PyTypeObject *type = Py_TYPE(obj);\
+    PyTypeObject *type = Py_TYPE((PyObject*)obj);\
     assert(__Pyx_PyType_HasFeature(type, Py_TPFLAGS_HEAPTYPE));\
     PyObject_GC_Del(obj);\
     Py_DECREF(type);\
 }
 #else
 #define __Pyx_PyHeapTypeObject_GC_Del(obj)  PyObject_GC_Del(obj)
 #endif
@@ -1098,15 +1133,15 @@
   #define __Pyx_PyList_SET_ITEM(o, i, v) PyList_SetItem(o, i, v)
   #define __Pyx_PyTuple_GET_SIZE(o) PyTuple_Size(o)
   #define __Pyx_PyList_GET_SIZE(o) PyList_Size(o)
   #define __Pyx_PySet_GET_SIZE(o) PySet_Size(o)
   #define __Pyx_PyBytes_GET_SIZE(o) PyBytes_Size(o)
   #define __Pyx_PyByteArray_GET_SIZE(o) PyByteArray_Size(o)
 #endif
-#if PY_VERSION_HEX >= 0x030d00A1
+#if __PYX_LIMITED_VERSION_HEX >= 0x030d00A1
   #define __Pyx_PyImport_AddModuleRef(name) PyImport_AddModuleRef(name)
 #else
   static CYTHON_INLINE PyObject *__Pyx_PyImport_AddModuleRef(const char *name) {
       PyObject *module = PyImport_AddModule(name);
       Py_XINCREF(module);
       return module;
   }
@@ -1185,15 +1220,15 @@
 #if defined(__CYGWIN__) && defined(_LDBL_EQ_DBL)
 #define __Pyx_truncl trunc
 #else
 #define __Pyx_truncl truncl
 #endif
 
 #define __PYX_MARK_ERR_POS(f_index, lineno) \
-    { __pyx_filename = __pyx_f[f_index]; (void)__pyx_filename; __pyx_lineno = lineno; (void)__pyx_lineno; __pyx_clineno = __LINE__; (void)__pyx_clineno; }
+    { __pyx_filename = __pyx_f[f_index]; (void)__pyx_filename; __pyx_lineno = lineno; (void)__pyx_lineno; __pyx_clineno = __LINE__;  (void)__pyx_clineno; }
 #define __PYX_ERR(f_index, lineno, Ln_error) \
     { __PYX_MARK_ERR_POS(f_index, lineno) goto Ln_error; }
 
 #ifdef CYTHON_EXTERN_C
     #undef __PYX_EXTERN_C
     #define __PYX_EXTERN_C CYTHON_EXTERN_C
 #elif defined(__PYX_EXTERN_C)
@@ -1284,32 +1319,15 @@
 #define __Pyx_PyObject_AsSString(s)    ((const signed char*) __Pyx_PyObject_AsString(s))
 #define __Pyx_PyObject_AsUString(s)    ((const unsigned char*) __Pyx_PyObject_AsString(s))
 #define __Pyx_PyObject_FromCString(s)  __Pyx_PyObject_FromString((const char*)s)
 #define __Pyx_PyBytes_FromCString(s)   __Pyx_PyBytes_FromString((const char*)s)
 #define __Pyx_PyByteArray_FromCString(s)   __Pyx_PyByteArray_FromString((const char*)s)
 #define __Pyx_PyStr_FromCString(s)     __Pyx_PyStr_FromString((const char*)s)
 #define __Pyx_PyUnicode_FromCString(s) __Pyx_PyUnicode_FromString((const char*)s)
-#if CYTHON_COMPILING_IN_LIMITED_API
-static CYTHON_INLINE size_t __Pyx_Py_UNICODE_strlen(const wchar_t *u)
-{
-    const wchar_t *u_end = u;
-    while (*u_end++) ;
-    return (size_t)(u_end - u - 1);
-}
-#else
-static CYTHON_INLINE size_t __Pyx_Py_UNICODE_strlen(const Py_UNICODE *u)
-{
-    const Py_UNICODE *u_end = u;
-    while (*u_end++) ;
-    return (size_t)(u_end - u - 1);
-}
-#endif
 #define __Pyx_PyUnicode_FromOrdinal(o)       PyUnicode_FromOrdinal((int)o)
-#define __Pyx_PyUnicode_FromUnicode(u)       PyUnicode_FromUnicode(u, __Pyx_Py_UNICODE_strlen(u))
-#define __Pyx_PyUnicode_FromUnicodeAndLength PyUnicode_FromUnicode
 #define __Pyx_PyUnicode_AsUnicode            PyUnicode_AsUnicode
 #define __Pyx_NewRef(obj) (Py_INCREF(obj), obj)
 #define __Pyx_Owned_Py_None(b) __Pyx_NewRef(Py_None)
 static CYTHON_INLINE PyObject * __Pyx_PyBool_FromLong(long b);
 static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject*);
 static CYTHON_INLINE int __Pyx_PyObject_IsTrueAndDecref(PyObject*);
 static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x);
@@ -1351,15 +1369,15 @@
     #define __Pyx_PyLong_CompactValue(x)  PyUnstable_Long_CompactValue((PyLongObject*) x)
   #else
     #define __Pyx_PyLong_IsCompact(x)     (((PyLongObject*)x)->long_value.lv_tag < (2 << _PyLong_NON_SIZE_BITS))
     #define __Pyx_PyLong_CompactValue(x)  ((1 - (Py_ssize_t) __Pyx_PyLong_Sign(x)) * (Py_ssize_t) __Pyx_PyLong_Digits(x)[0])
   #endif
   typedef Py_ssize_t  __Pyx_compact_pylong;
   typedef size_t  __Pyx_compact_upylong;
-  #else  // Py < 3.12
+  #else
   #define __Pyx_PyLong_IsNeg(x)  (Py_SIZE(x) < 0)
   #define __Pyx_PyLong_IsNonNeg(x)  (Py_SIZE(x) >= 0)
   #define __Pyx_PyLong_IsZero(x)  (Py_SIZE(x) == 0)
   #define __Pyx_PyLong_IsPos(x)  (Py_SIZE(x) > 0)
   #define __Pyx_PyLong_CompactValueUnsigned(x)  ((Py_SIZE(x) == 0) ? 0 : __Pyx_PyLong_Digits(x)[0])
   #define __Pyx_PyLong_DigitCount(x)  __Pyx_sst_abs(Py_SIZE(x))
   #define __Pyx_PyLong_SignedDigitCount(x)  Py_SIZE(x)
@@ -1470,15 +1488,15 @@
 static int __pyx_clineno = 0;
 static const char * __pyx_cfilenm = __FILE__;
 static const char *__pyx_filename;
 
 /* #### Code section: filename_table ### */
 
 static const char *__pyx_f[] = {
-  "rqdatac\\\\connection.py",
+  "rqdatac/connection.py",
 };
 /* #### Code section: utility_code_proto_before_types ### */
 /* ForceInitThreads.proto */
 #ifndef __PYX_FORCE_INIT_THREADS
   #define __PYX_FORCE_INIT_THREADS 0
 #endif
 
@@ -1744,33 +1762,34 @@
 #else
     #define __Pyx_Arg_VARARGS(args, i) PyTuple_GetItem(args, i)
 #endif
 #if CYTHON_AVOID_BORROWED_REFS
     #define __Pyx_Arg_NewRef_VARARGS(arg) __Pyx_NewRef(arg)
     #define __Pyx_Arg_XDECREF_VARARGS(arg) Py_XDECREF(arg)
 #else
-    #define __Pyx_Arg_NewRef_VARARGS(arg) arg // no-op
-    #define __Pyx_Arg_XDECREF_VARARGS(arg) // no-op - arg is borrowed
+    #define __Pyx_Arg_NewRef_VARARGS(arg) arg
+    #define __Pyx_Arg_XDECREF_VARARGS(arg)
 #endif
 #define __Pyx_NumKwargs_VARARGS(kwds) PyDict_Size(kwds)
 #define __Pyx_KwValues_VARARGS(args, nargs) NULL
 #define __Pyx_GetKwValue_VARARGS(kw, kwvalues, s) __Pyx_PyDict_GetItemStrWithError(kw, s)
 #define __Pyx_KwargsAsDict_VARARGS(kw, kwvalues) PyDict_Copy(kw)
 #if CYTHON_METH_FASTCALL
     #define __Pyx_Arg_FASTCALL(args, i) args[i]
     #define __Pyx_NumKwargs_FASTCALL(kwds) PyTuple_GET_SIZE(kwds)
     #define __Pyx_KwValues_FASTCALL(args, nargs) ((args) + (nargs))
     static CYTHON_INLINE PyObject * __Pyx_GetKwValue_FASTCALL(PyObject *kwnames, PyObject *const *kwvalues, PyObject *s);
 #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030d0000
-    static CYTHON_UNUSED PyObject *__Pyx_KwargsAsDict_FASTCALL(PyObject *kwnames, PyObject *const *kwvalues);
+    CYTHON_UNUSED static PyObject *__Pyx_KwargsAsDict_FASTCALL(PyObject *kwnames, PyObject *const *kwvalues);
   #else
     #define __Pyx_KwargsAsDict_FASTCALL(kw, kwvalues) _PyStack_AsDict(kwvalues, kw)
   #endif
-    #define __Pyx_Arg_NewRef_FASTCALL(arg) arg // no-op, __Pyx_Arg_FASTCALL is direct and this needs
-    #define __Pyx_Arg_XDECREF_FASTCALL(arg)  // no-op - arg was returned from array
+    #define __Pyx_Arg_NewRef_FASTCALL(arg) arg  /* no-op, __Pyx_Arg_FASTCALL is direct and this needs
+                                                   to have the same reference counting */
+    #define __Pyx_Arg_XDECREF_FASTCALL(arg)
 #else
     #define __Pyx_Arg_FASTCALL __Pyx_Arg_VARARGS
     #define __Pyx_NumKwargs_FASTCALL __Pyx_NumKwargs_VARARGS
     #define __Pyx_KwValues_FASTCALL __Pyx_KwValues_VARARGS
     #define __Pyx_GetKwValue_FASTCALL __Pyx_GetKwValue_VARARGS
     #define __Pyx_KwargsAsDict_FASTCALL __Pyx_KwargsAsDict_VARARGS
     #define __Pyx_Arg_NewRef_FASTCALL(arg) __Pyx_Arg_NewRef_VARARGS(arg)
@@ -2160,15 +2179,15 @@
     PyObject *func_code;
     PyObject *func_closure;
 #if PY_VERSION_HEX < 0x030900B1 || CYTHON_COMPILING_IN_LIMITED_API
     PyObject *func_classobj;
 #endif
     void *defaults;
     int defaults_pyobjects;
-    size_t defaults_size;  // used by FusedFunction for copying defaults
+    size_t defaults_size;
     int flags;
     PyObject *defaults_tuple;
     PyObject *defaults_kwdict;
     PyObject *(*defaults_getter)(PyObject *);
     PyObject *func_annotations;
     PyObject *func_is_coroutine;
 } __pyx_CyFunctionObject;
@@ -2560,15 +2579,15 @@
 static const char __pyx_k_Connection__do_auth[] = "Connection._do_auth";
 static const char __pyx_k_incomplete_header_r[] = "incomplete header, %r";
 static const char __pyx_k_rqdatac_share_codec[] = "rqdatac.share.codec";
 static const char __pyx_k_Connection_is_normal[] = "Connection.is_normal";
 static const char __pyx_k_invalid_message_type[] = "invalid message type: {}";
 static const char __pyx_k_is_connection_normal[] = "_is_connection_normal";
 static const char __pyx_k_rqdatac_share_errors[] = "rqdatac.share.errors";
-static const char __pyx_k_rqdatac_connection_py[] = "rqdatac\\connection.py";
+static const char __pyx_k_rqdatac_connection_py[] = "rqdatac/connection.py";
 static const char __pyx_k_Connection_feed_unpack[] = "Connection.feed_unpack";
 static const char __pyx_k_Connection_set_timeout[] = "Connection.set_timeout";
 static const char __pyx_k_rqdatac_share_protocol[] = "rqdatac.share.protocol";
 static const char __pyx_k_Connection_table_unpack[] = "Connection.table_unpack";
 static const char __pyx_k_DEFAULT_SERIALIZER_TYPE[] = "DEFAULT_SERIALIZER_TYPE";
 static const char __pyx_k_invalid_serializer_type[] = "invalid serializer type: {}";
 static const char __pyx_k_Connection_table2_unpack[] = "Connection.table2_unpack";
@@ -9994,24 +10013,26 @@
   __Pyx_XDECREF(__pyx_gb_7rqdatac_10connection_10Connection_13table2_unpack_2generator2);
   __Pyx_XDECREF(__pyx_gb_7rqdatac_10connection_10Connection_13table2_unpack_5generator3);
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
+#if CYTHON_USE_FREELISTS
 static struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct__table_unpack *__pyx_freelist_7rqdatac_10connection___pyx_scope_struct__table_unpack[8];
 static int __pyx_freecount_7rqdatac_10connection___pyx_scope_struct__table_unpack = 0;
+#endif
 
 static PyObject *__pyx_tp_new_7rqdatac_10connection___pyx_scope_struct__table_unpack(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
   PyObject *o;
   #if CYTHON_COMPILING_IN_LIMITED_API
   allocfunc alloc_func = (allocfunc)PyType_GetSlot(t, Py_tp_alloc);
   o = alloc_func(t, 0);
   #else
-  #if CYTHON_COMPILING_IN_CPYTHON
+  #if CYTHON_USE_FREELISTS
   if (likely((int)(__pyx_freecount_7rqdatac_10connection___pyx_scope_struct__table_unpack > 0) & (int)(t->tp_basicsize == sizeof(struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct__table_unpack)))) {
     o = (PyObject*)__pyx_freelist_7rqdatac_10connection___pyx_scope_struct__table_unpack[--__pyx_freecount_7rqdatac_10connection___pyx_scope_struct__table_unpack];
     memset(o, 0, sizeof(struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct__table_unpack));
     (void) PyObject_INIT(o, t);
     PyObject_GC_Track(o);
   } else
   #endif
@@ -10030,15 +10051,15 @@
     if (__Pyx_PyObject_GetSlot(o, tp_dealloc, destructor) == __pyx_tp_dealloc_7rqdatac_10connection___pyx_scope_struct__table_unpack) {
       if (PyObject_CallFinalizerFromDealloc(o)) return;
     }
   }
   #endif
   PyObject_GC_UnTrack(o);
   Py_CLEAR(p->__pyx_v_keys);
-  #if CYTHON_COMPILING_IN_CPYTHON
+  #if CYTHON_USE_FREELISTS
   if (((int)(__pyx_freecount_7rqdatac_10connection___pyx_scope_struct__table_unpack < 8) & (int)(Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct__table_unpack)))) {
     __pyx_freelist_7rqdatac_10connection___pyx_scope_struct__table_unpack[__pyx_freecount_7rqdatac_10connection___pyx_scope_struct__table_unpack++] = ((struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct__table_unpack *)o);
   } else
   #endif
   {
     #if CYTHON_USE_TYPE_SLOTS || CYTHON_COMPILING_IN_PYPY
     (*Py_TYPE(o)->tp_free)(o);
@@ -10163,24 +10184,26 @@
   #endif
   #if CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX >= 0x03090000 && PY_VERSION_HEX < 0x030a0000
   0, /*tp_pypy_flags*/
   #endif
 };
 #endif
 
+#if CYTHON_USE_FREELISTS
 static struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_1_genexpr *__pyx_freelist_7rqdatac_10connection___pyx_scope_struct_1_genexpr[8];
 static int __pyx_freecount_7rqdatac_10connection___pyx_scope_struct_1_genexpr = 0;
+#endif
 
 static PyObject *__pyx_tp_new_7rqdatac_10connection___pyx_scope_struct_1_genexpr(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
   PyObject *o;
   #if CYTHON_COMPILING_IN_LIMITED_API
   allocfunc alloc_func = (allocfunc)PyType_GetSlot(t, Py_tp_alloc);
   o = alloc_func(t, 0);
   #else
-  #if CYTHON_COMPILING_IN_CPYTHON
+  #if CYTHON_USE_FREELISTS
   if (likely((int)(__pyx_freecount_7rqdatac_10connection___pyx_scope_struct_1_genexpr > 0) & (int)(t->tp_basicsize == sizeof(struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_1_genexpr)))) {
     o = (PyObject*)__pyx_freelist_7rqdatac_10connection___pyx_scope_struct_1_genexpr[--__pyx_freecount_7rqdatac_10connection___pyx_scope_struct_1_genexpr];
     memset(o, 0, sizeof(struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_1_genexpr));
     (void) PyObject_INIT(o, t);
     PyObject_GC_Track(o);
   } else
   #endif
@@ -10202,15 +10225,15 @@
   }
   #endif
   PyObject_GC_UnTrack(o);
   Py_CLEAR(p->__pyx_outer_scope);
   Py_CLEAR(p->__pyx_genexpr_arg_0);
   Py_CLEAR(p->__pyx_v_row);
   Py_CLEAR(p->__pyx_t_0);
-  #if CYTHON_COMPILING_IN_CPYTHON
+  #if CYTHON_USE_FREELISTS
   if (((int)(__pyx_freecount_7rqdatac_10connection___pyx_scope_struct_1_genexpr < 8) & (int)(Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_1_genexpr)))) {
     __pyx_freelist_7rqdatac_10connection___pyx_scope_struct_1_genexpr[__pyx_freecount_7rqdatac_10connection___pyx_scope_struct_1_genexpr++] = ((struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_1_genexpr *)o);
   } else
   #endif
   {
     #if CYTHON_USE_TYPE_SLOTS || CYTHON_COMPILING_IN_PYPY
     (*Py_TYPE(o)->tp_free)(o);
@@ -10334,24 +10357,26 @@
   #endif
   #if CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX >= 0x03090000 && PY_VERSION_HEX < 0x030a0000
   0, /*tp_pypy_flags*/
   #endif
 };
 #endif
 
+#if CYTHON_USE_FREELISTS
 static struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_2_genexpr *__pyx_freelist_7rqdatac_10connection___pyx_scope_struct_2_genexpr[8];
 static int __pyx_freecount_7rqdatac_10connection___pyx_scope_struct_2_genexpr = 0;
+#endif
 
 static PyObject *__pyx_tp_new_7rqdatac_10connection___pyx_scope_struct_2_genexpr(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
   PyObject *o;
   #if CYTHON_COMPILING_IN_LIMITED_API
   allocfunc alloc_func = (allocfunc)PyType_GetSlot(t, Py_tp_alloc);
   o = alloc_func(t, 0);
   #else
-  #if CYTHON_COMPILING_IN_CPYTHON
+  #if CYTHON_USE_FREELISTS
   if (likely((int)(__pyx_freecount_7rqdatac_10connection___pyx_scope_struct_2_genexpr > 0) & (int)(t->tp_basicsize == sizeof(struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_2_genexpr)))) {
     o = (PyObject*)__pyx_freelist_7rqdatac_10connection___pyx_scope_struct_2_genexpr[--__pyx_freecount_7rqdatac_10connection___pyx_scope_struct_2_genexpr];
     memset(o, 0, sizeof(struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_2_genexpr));
     (void) PyObject_INIT(o, t);
     PyObject_GC_Track(o);
   } else
   #endif
@@ -10373,15 +10398,15 @@
   }
   #endif
   PyObject_GC_UnTrack(o);
   Py_CLEAR(p->__pyx_outer_scope);
   Py_CLEAR(p->__pyx_genexpr_arg_0);
   Py_CLEAR(p->__pyx_v_row);
   Py_CLEAR(p->__pyx_t_0);
-  #if CYTHON_COMPILING_IN_CPYTHON
+  #if CYTHON_USE_FREELISTS
   if (((int)(__pyx_freecount_7rqdatac_10connection___pyx_scope_struct_2_genexpr < 8) & (int)(Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_2_genexpr)))) {
     __pyx_freelist_7rqdatac_10connection___pyx_scope_struct_2_genexpr[__pyx_freecount_7rqdatac_10connection___pyx_scope_struct_2_genexpr++] = ((struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_2_genexpr *)o);
   } else
   #endif
   {
     #if CYTHON_USE_TYPE_SLOTS || CYTHON_COMPILING_IN_PYPY
     (*Py_TYPE(o)->tp_free)(o);
@@ -10505,24 +10530,26 @@
   #endif
   #if CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX >= 0x03090000 && PY_VERSION_HEX < 0x030a0000
   0, /*tp_pypy_flags*/
   #endif
 };
 #endif
 
+#if CYTHON_USE_FREELISTS
 static struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_3_genexpr *__pyx_freelist_7rqdatac_10connection___pyx_scope_struct_3_genexpr[8];
 static int __pyx_freecount_7rqdatac_10connection___pyx_scope_struct_3_genexpr = 0;
+#endif
 
 static PyObject *__pyx_tp_new_7rqdatac_10connection___pyx_scope_struct_3_genexpr(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
   PyObject *o;
   #if CYTHON_COMPILING_IN_LIMITED_API
   allocfunc alloc_func = (allocfunc)PyType_GetSlot(t, Py_tp_alloc);
   o = alloc_func(t, 0);
   #else
-  #if CYTHON_COMPILING_IN_CPYTHON
+  #if CYTHON_USE_FREELISTS
   if (likely((int)(__pyx_freecount_7rqdatac_10connection___pyx_scope_struct_3_genexpr > 0) & (int)(t->tp_basicsize == sizeof(struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_3_genexpr)))) {
     o = (PyObject*)__pyx_freelist_7rqdatac_10connection___pyx_scope_struct_3_genexpr[--__pyx_freecount_7rqdatac_10connection___pyx_scope_struct_3_genexpr];
     memset(o, 0, sizeof(struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_3_genexpr));
     (void) PyObject_INIT(o, t);
     PyObject_GC_Track(o);
   } else
   #endif
@@ -10543,15 +10570,15 @@
     }
   }
   #endif
   PyObject_GC_UnTrack(o);
   Py_CLEAR(p->__pyx_genexpr_arg_0);
   Py_CLEAR(p->__pyx_v_row);
   Py_CLEAR(p->__pyx_t_0);
-  #if CYTHON_COMPILING_IN_CPYTHON
+  #if CYTHON_USE_FREELISTS
   if (((int)(__pyx_freecount_7rqdatac_10connection___pyx_scope_struct_3_genexpr < 8) & (int)(Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_3_genexpr)))) {
     __pyx_freelist_7rqdatac_10connection___pyx_scope_struct_3_genexpr[__pyx_freecount_7rqdatac_10connection___pyx_scope_struct_3_genexpr++] = ((struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_3_genexpr *)o);
   } else
   #endif
   {
     #if CYTHON_USE_TYPE_SLOTS || CYTHON_COMPILING_IN_PYPY
     (*Py_TYPE(o)->tp_free)(o);
@@ -10672,24 +10699,26 @@
   #endif
   #if CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX >= 0x03090000 && PY_VERSION_HEX < 0x030a0000
   0, /*tp_pypy_flags*/
   #endif
 };
 #endif
 
+#if CYTHON_USE_FREELISTS
 static struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_4_genexpr *__pyx_freelist_7rqdatac_10connection___pyx_scope_struct_4_genexpr[8];
 static int __pyx_freecount_7rqdatac_10connection___pyx_scope_struct_4_genexpr = 0;
+#endif
 
 static PyObject *__pyx_tp_new_7rqdatac_10connection___pyx_scope_struct_4_genexpr(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
   PyObject *o;
   #if CYTHON_COMPILING_IN_LIMITED_API
   allocfunc alloc_func = (allocfunc)PyType_GetSlot(t, Py_tp_alloc);
   o = alloc_func(t, 0);
   #else
-  #if CYTHON_COMPILING_IN_CPYTHON
+  #if CYTHON_USE_FREELISTS
   if (likely((int)(__pyx_freecount_7rqdatac_10connection___pyx_scope_struct_4_genexpr > 0) & (int)(t->tp_basicsize == sizeof(struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_4_genexpr)))) {
     o = (PyObject*)__pyx_freelist_7rqdatac_10connection___pyx_scope_struct_4_genexpr[--__pyx_freecount_7rqdatac_10connection___pyx_scope_struct_4_genexpr];
     memset(o, 0, sizeof(struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_4_genexpr));
     (void) PyObject_INIT(o, t);
     PyObject_GC_Track(o);
   } else
   #endif
@@ -10710,15 +10739,15 @@
     }
   }
   #endif
   PyObject_GC_UnTrack(o);
   Py_CLEAR(p->__pyx_genexpr_arg_0);
   Py_CLEAR(p->__pyx_v_row);
   Py_CLEAR(p->__pyx_t_0);
-  #if CYTHON_COMPILING_IN_CPYTHON
+  #if CYTHON_USE_FREELISTS
   if (((int)(__pyx_freecount_7rqdatac_10connection___pyx_scope_struct_4_genexpr < 8) & (int)(Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_4_genexpr)))) {
     __pyx_freelist_7rqdatac_10connection___pyx_scope_struct_4_genexpr[__pyx_freecount_7rqdatac_10connection___pyx_scope_struct_4_genexpr++] = ((struct __pyx_obj_7rqdatac_10connection___pyx_scope_struct_4_genexpr *)o);
   } else
   #endif
   {
     #if CYTHON_USE_TYPE_SLOTS || CYTHON_COMPILING_IN_PYPY
     (*Py_TYPE(o)->tp_free)(o);
@@ -11592,15 +11621,15 @@
   #if PY_MAJOR_VERSION < 3
   __pyx_m = Py_InitModule4("connection", __pyx_methods, 0, 0, PYTHON_API_VERSION); Py_XINCREF(__pyx_m);
   if (unlikely(!__pyx_m)) __PYX_ERR(0, 1, __pyx_L1_error)
   #elif CYTHON_USE_MODULE_STATE
   __pyx_t_1 = PyModule_Create(&__pyx_moduledef); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1, __pyx_L1_error)
   {
     int add_module_result = PyState_AddModule(__pyx_t_1, &__pyx_moduledef);
-    __pyx_t_1 = 0; /* transfer ownership from __pyx_t_1 to connection pseudovariable */
+    __pyx_t_1 = 0; /* transfer ownership from __pyx_t_1 to "connection" pseudovariable */
     if (unlikely((add_module_result < 0))) __PYX_ERR(0, 1, __pyx_L1_error)
     pystate_addmodule_run = 1;
   }
   #else
   __pyx_m = PyModule_Create(&__pyx_moduledef);
   if (unlikely(!__pyx_m)) __PYX_ERR(0, 1, __pyx_L1_error)
   #endif
@@ -12749,22 +12778,22 @@
     {
         if (s == PyTuple_GET_ITEM(kwnames, i)) return kwvalues[i];
     }
     for (i = 0; i < n; i++)
     {
         int eq = __Pyx_PyUnicode_Equals(s, PyTuple_GET_ITEM(kwnames, i), Py_EQ);
         if (unlikely(eq != 0)) {
-            if (unlikely(eq < 0)) return NULL;  // error
+            if (unlikely(eq < 0)) return NULL;
             return kwvalues[i];
         }
     }
-    return NULL;  // not found (no exception set)
+    return NULL;
 }
 #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030d0000
-static CYTHON_UNUSED PyObject *__Pyx_KwargsAsDict_FASTCALL(PyObject *kwnames, PyObject *const *kwvalues) {
+CYTHON_UNUSED static PyObject *__Pyx_KwargsAsDict_FASTCALL(PyObject *kwnames, PyObject *const *kwvalues) {
     Py_ssize_t i, nkwargs = PyTuple_GET_SIZE(kwnames);
     PyObject *dict;
     dict = PyDict_New();
     if (unlikely(!dict))
         return NULL;
     for (i=0; i<nkwargs; i++) {
         PyObject *key = PyTuple_GET_ITEM(kwnames, i);
@@ -12840,15 +12869,15 @@
 #endif
         }
         name = first_kw_arg;
         while (*name && (**name != key)) name++;
         if (*name) {
             values[name-argnames] = value;
 #if CYTHON_AVOID_BORROWED_REFS
-            Py_INCREF(value); // transfer ownership of value to values
+            Py_INCREF(value);
             Py_DECREF(key);
 #endif
             key = NULL;
             value = NULL;
             continue;
         }
 #if !CYTHON_AVOID_BORROWED_REFS
@@ -12859,15 +12888,15 @@
         #if PY_MAJOR_VERSION < 3
         if (likely(PyString_Check(key))) {
             while (*name) {
                 if ((CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**name) == PyString_GET_SIZE(key))
                         && _PyString_Eq(**name, key)) {
                     values[name-argnames] = value;
 #if CYTHON_AVOID_BORROWED_REFS
-                    value = NULL;  // ownership transferred to values
+                    value = NULL;
 #endif
                     break;
                 }
                 name++;
             }
             if (*name) continue;
             else {
@@ -12891,15 +12920,15 @@
                 #endif
                     PyUnicode_Compare(**name, key)
                 );
                 if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                 if (cmp == 0) {
                     values[name-argnames] = value;
 #if CYTHON_AVOID_BORROWED_REFS
-                    value = NULL; // ownership transferred to values
+                    value = NULL;
 #endif
                     break;
                 }
                 name++;
             }
             if (*name) continue;
             else {
@@ -13378,17 +13407,18 @@
     PyErr_Format(PyExc_ValueError,
                  "need more than %" CYTHON_FORMAT_SSIZE_T "d value%.1s to unpack",
                  index, (index == 1) ? "" : "s");
 }
 
 /* IterFinish */
 static CYTHON_INLINE int __Pyx_IterFinish(void) {
+    PyObject* exc_type;
     __Pyx_PyThreadState_declare
     __Pyx_PyThreadState_assign
-    PyObject* exc_type = __Pyx_PyErr_CurrentExceptionType();
+    exc_type = __Pyx_PyErr_CurrentExceptionType();
     if (unlikely(exc_type)) {
         if (unlikely(!__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration)))
             return -1;
         __Pyx_PyErr_Clear();
         return 0;
     }
     return 0;
@@ -13508,15 +13538,15 @@
                     PyErr_Clear();
                 }
             }
             return sm->sq_item(o, i);
         }
     }
 #else
-    if (is_list || PySequence_Check(o)) {
+    if (is_list || !PyMapping_Check(o)) {
         return PySequence_GetItem(o, i);
     }
 #endif
     return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
 }
 
 /* RaiseException */
@@ -14342,46 +14372,46 @@
                 "base class '" __Pyx_FMT_TYPENAME "' is not a heap type", b_name);
             __Pyx_DECREF_TypeName(b_name);
 #if CYTHON_AVOID_BORROWED_REFS
             Py_DECREF(b0);
 #endif
             return -1;
         }
-#if !CYTHON_USE_TYPE_SLOTS
-        if (dictoffset == 0) {
-            PyErr_Format(PyExc_TypeError,
-                "extension type '%s.200s': "
-                "unable to validate whether bases have a __dict__ "
-                "when CYTHON_USE_TYPE_SLOTS is off "
-                "(likely because you are building in the limited API). "
-                "Therefore, all extension types with multiple bases "
-                "must add 'cdef dict __dict__' in this compilation mode",
-                type_name);
-#if CYTHON_AVOID_BORROWED_REFS
-            Py_DECREF(b0);
-#endif
-            return -1;
-        }
-#else
-        if (dictoffset == 0 && b->tp_dictoffset)
+        if (dictoffset == 0)
         {
-            __Pyx_TypeName b_name = __Pyx_PyType_GetName(b);
-            PyErr_Format(PyExc_TypeError,
-                "extension type '%.200s' has no __dict__ slot, "
-                "but base type '" __Pyx_FMT_TYPENAME "' has: "
-                "either add 'cdef dict __dict__' to the extension type "
-                "or add '__slots__ = [...]' to the base type",
-                type_name, b_name);
-            __Pyx_DECREF_TypeName(b_name);
+            Py_ssize_t b_dictoffset = 0;
+#if CYTHON_USE_TYPE_SLOTS || CYTHON_COMPILING_IN_PYPY
+            b_dictoffset = b->tp_dictoffset;
+#else
+            PyObject *py_b_dictoffset = PyObject_GetAttrString((PyObject*)b, "__dictoffset__");
+            if (!py_b_dictoffset) goto dictoffset_return;
+            b_dictoffset = PyLong_AsSsize_t(py_b_dictoffset);
+            Py_DECREF(py_b_dictoffset);
+            if (b_dictoffset == -1 && PyErr_Occurred()) goto dictoffset_return;
+#endif
+            if (b_dictoffset) {
+                {
+                    __Pyx_TypeName b_name = __Pyx_PyType_GetName(b);
+                    PyErr_Format(PyExc_TypeError,
+                        "extension type '%.200s' has no __dict__ slot, "
+                        "but base type '" __Pyx_FMT_TYPENAME "' has: "
+                        "either add 'cdef dict __dict__' to the extension type "
+                        "or add '__slots__ = [...]' to the base type",
+                        type_name, b_name);
+                    __Pyx_DECREF_TypeName(b_name);
+                }
+#if !(CYTHON_USE_TYPE_SLOTS || CYTHON_COMPILING_IN_PYPY)
+              dictoffset_return:
+#endif
 #if CYTHON_AVOID_BORROWED_REFS
-            Py_DECREF(b0);
+                Py_DECREF(b0);
 #endif
-            return -1;
+                return -1;
+            }
         }
-#endif
 #if CYTHON_AVOID_BORROWED_REFS
         Py_DECREF(b0);
 #endif
     }
     return 0;
 }
 #endif
@@ -15754,15 +15784,15 @@
         break;
     case 0:
         self = ((PyCFunctionObject*)cyfunc)->m_self;
         break;
     default:
         return NULL;
     }
-    return ((_PyCFunctionFastWithKeywords)(void(*)(void))def->ml_meth)(self, args, nargs, kwnames);
+    return ((__Pyx_PyCFunctionFastWithKeywords)(void(*)(void))def->ml_meth)(self, args, nargs, kwnames);
 }
 static PyObject * __Pyx_CyFunction_Vectorcall_FASTCALL_KEYWORDS_METHOD(PyObject *func, PyObject *const *args, size_t nargsf, PyObject *kwnames)
 {
     __pyx_CyFunctionObject *cyfunc = (__pyx_CyFunctionObject *)func;
     PyMethodDef* def = ((PyCFunctionObject*)cyfunc)->m_ml;
     PyTypeObject *cls = (PyTypeObject *) __Pyx_CyFunction_GetClassObj(cyfunc);
 #if CYTHON_BACKPORT_VECTORCALL
@@ -16568,15 +16598,15 @@
         py_line,
         __pyx_empty_bytes  /*PyObject *lnotab*/
     );
     Py_DECREF(py_srcfile);
     #else
     py_code = PyCode_NewEmpty(filename, funcname, py_line);
     #endif
-    Py_XDECREF(py_funcname);  // XDECREF since it's only set on Py3 if cline
+    Py_XDECREF(py_funcname);
     return py_code;
 bad:
     Py_XDECREF(py_funcname);
     #if PY_MAJOR_VERSION < 3
     Py_XDECREF(py_srcfile);
     #endif
     return NULL;
```

## rqdatac/connection_pool.py

 * *Ordering differences only*

```diff
@@ -1,66 +1,66 @@
-# -*- coding: utf-8 -*-
-import socket
-from collections import deque
-from threading import Lock, Semaphore
-from contextlib import contextmanager
-
-from rqdatac.share.errors import ErrorFromBackend, GatewayError
-from rqdatac.decorators import retry
-from rqdatac.connection import Connection
-from rqdatac.utils import connection_error, timeout_error
-
-
-class ConnectionPool:
-    def __init__(self, addr, auth=None, max_pool_size=8, connect_timeout=3.0, timeout=5 * 60):
-        self._addr = addr
-        self._auth = auth if auth is not None else {}
-        self._connect_timeout = connect_timeout
-        self._timeout = timeout
-        self._lock = Lock()
-        self._free_connections = deque()
-        self._semaphore = Semaphore(max_pool_size)
-
-    @retry(10, suppress_exceptions=connection_error)
-    def execute(self, method, *args, **kwargs):
-        with self._semaphore:
-            with self._get_connection() as conn:
-                return conn.execute(method, *args, **kwargs)
-
-    def reset(self):
-        with self._lock:
-            for conn in self._free_connections:
-                conn.close()
-            self._free_connections.clear()
-
-    @contextmanager
-    def _get_connection(self):
-        conn = self._ensure_connection()
-        try:
-            yield conn
-        except (KeyboardInterrupt, Exception) as e:
-            if not isinstance(e, (ErrorFromBackend, GatewayError)):
-                conn.close()
-            raise e
-        else:
-            with self._lock:
-                self._free_connections.append(conn)
-
-    def _ensure_connection(self):
-        with self._lock:
-            while self._free_connections:
-                # round-robin to distribute load
-                conn = self._free_connections.popleft()
-                if conn.is_normal():
-                    return conn
-                else:
-                    conn.close()
-
-        return self._new_connection()
-
-    @retry(3, suppress_exceptions=timeout_error)
-    def _new_connection(self):
-        s = Connection.sock_factory(self._addr, timeout=self._connect_timeout)
-        s.settimeout(self._timeout)
-        return Connection(s, self._auth)
-
-    close = reset
+# -*- coding: utf-8 -*-
+import socket
+from collections import deque
+from threading import Lock, Semaphore
+from contextlib import contextmanager
+
+from rqdatac.share.errors import ErrorFromBackend, GatewayError
+from rqdatac.decorators import retry
+from rqdatac.connection import Connection
+from rqdatac.utils import connection_error, timeout_error
+
+
+class ConnectionPool:
+    def __init__(self, addr, auth=None, max_pool_size=8, connect_timeout=3.0, timeout=5 * 60):
+        self._addr = addr
+        self._auth = auth if auth is not None else {}
+        self._connect_timeout = connect_timeout
+        self._timeout = timeout
+        self._lock = Lock()
+        self._free_connections = deque()
+        self._semaphore = Semaphore(max_pool_size)
+
+    @retry(10, suppress_exceptions=connection_error)
+    def execute(self, method, *args, **kwargs):
+        with self._semaphore:
+            with self._get_connection() as conn:
+                return conn.execute(method, *args, **kwargs)
+
+    def reset(self):
+        with self._lock:
+            for conn in self._free_connections:
+                conn.close()
+            self._free_connections.clear()
+
+    @contextmanager
+    def _get_connection(self):
+        conn = self._ensure_connection()
+        try:
+            yield conn
+        except (KeyboardInterrupt, Exception) as e:
+            if not isinstance(e, (ErrorFromBackend, GatewayError)):
+                conn.close()
+            raise e
+        else:
+            with self._lock:
+                self._free_connections.append(conn)
+
+    def _ensure_connection(self):
+        with self._lock:
+            while self._free_connections:
+                # round-robin to distribute load
+                conn = self._free_connections.popleft()
+                if conn.is_normal():
+                    return conn
+                else:
+                    conn.close()
+
+        return self._new_connection()
+
+    @retry(3, suppress_exceptions=timeout_error)
+    def _new_connection(self):
+        s = Connection.sock_factory(self._addr, timeout=self._connect_timeout)
+        s.settimeout(self._timeout)
+        return Connection(s, self._auth)
+
+    close = reset
```

## rqdatac/decorators.py

 * *Ordering differences only*

```diff
@@ -1,148 +1,148 @@
-# -*- coding: utf-8 -*-
-import time
-import types
-import warnings
-from functools import wraps, partial, update_wrapper
-
-import rqdatac
-from rqdatac.share.errors import OverwriteWarning
-
-
-def deprecated(func=None, msg=None):
-    if func is None:
-        return partial(deprecated, msg=msg)
-
-    if msg is None:
-        msg = func.__name__ + " is deprecated, and will be removed in future."
-
-    @wraps(func)
-    def wrap(*args, **kwargs):
-        warnings.warn(msg, category=DeprecationWarning, stacklevel=0)
-        return func(*args, **kwargs)
-
-    return wrap
-
-
-def export_as_api(f=None, name=None, namespace=None, priority=0):
-    if f is None:
-        return partial(export_as_api, name=name, namespace=namespace)
-    name = name if name else f.__name__
-    if namespace:
-        if hasattr(rqdatac, namespace):
-            namespace = getattr(rqdatac, namespace)
-        else:
-            namespace_name = namespace
-            namespace = types.ModuleType(namespace_name)
-            namespace.__file__ = 'rqdatac plugin'
-            namespace.__module__ = "rqdatac"
-            setattr(rqdatac, namespace_name, namespace)
-            rqdatac.__all__.append(namespace_name)
-    else:
-        namespace = rqdatac
-        rqdatac.__all__.append(name)
-
-    old_f = getattr(namespace, name, None)
-    if old_f is not None:
-        if old_f.__priority > priority:
-            warnings.warn("!!!! CAN'T OVERWRITE API {} WITH {} BECAUSE OLD PRIPORITY {} > {} !!!!".format(name, f, old_f.__priority, priority), category=OverwriteWarning)
-            return f
-        warnings.warn("!!!! OVERWRITE API {} WITH {} !!!!".format(name, f), category=OverwriteWarning)
-
-    f.__priority = priority
-    setattr(namespace, name, f)
-
-    return f
-
-
-def retry(count, suppress_exceptions, delay=1.0):
-    def decorate(func):
-        @wraps(func)
-        def wrap(*args, **kwargs):
-            c = count
-            while c > 0:
-                try:
-                    return func(*args, **kwargs)
-                except suppress_exceptions as e:
-                    c -= 1
-                    if c == 0:
-                        raise e
-                    if delay:
-                        time.sleep(delay)
-
-        return wrap
-
-    return decorate
-
-
-def coroutine(func):
-    @wraps(func)
-    def primer(*args, **kwargs):
-        gen = func(*args, **kwargs)
-        next(gen)
-        return gen
-
-    return primer
-
-
-_ttl_cached_functions = set()
-
-
-def ttl_cache(ttl):
-    if not isinstance(ttl, int) or not ttl > 0:
-        raise TypeError("Expected ttl to be a positive integer")
-
-    def decorating_function(user_function):
-        wrapper = _ttl_cache_wrapper(user_function, ttl)
-        _ttl_cached_functions.add(wrapper)
-        return update_wrapper(wrapper, user_function)
-
-    return decorating_function
-
-
-def ttl_cache_clear():
-    for f in _ttl_cached_functions:
-        f.clear()
-
-
-def _ttl_cache_wrapper(user_function, ttl):
-    sentinel = object()
-    cache = {}
-    cache_get = cache.get  # bound method to lookup a key or return None
-    cache_clear = cache.clear
-
-    def wrapper(*args, **kwargs):
-        if kwargs:
-            key = args + (repr(sorted(kwargs.items())),)
-        else:
-            key = args
-
-        # in cpython, dict.get is thread-safe
-        result = cache_get(key, sentinel)
-        if result is not sentinel:
-            expire_at, value = result
-            if expire_at > time.time():
-                return value
-        value = user_function(*args, **kwargs)
-        cache[key] = (time.time() + ttl, value)
-        return value
-
-    setattr(wrapper, 'clear', cache_clear)
-    return wrapper
-
-
-def compatible_with_parm(func=None, name=None, value=None, replace=None):
-    if func is None:
-        return partial(compatible_with_parm, name=name, value=value, replace=replace)
-
-    @wraps(func)
-    def wrap(*args, **kwargs):
-        if name:
-            if name in kwargs:
-                msg = "'{}' is no longer used, please use '{}' instead ".format(name, replace)
-                warnings.warn(msg, category=DeprecationWarning, stacklevel=2)
-                item = kwargs.pop(name)
-                if item != value:
-                    raise ValueError("'{}': except '{}', got '{}'".format(name, value, item))
-        return func(*args, **kwargs)
-
-    return wrap
+# -*- coding: utf-8 -*-
+import time
+import types
+import warnings
+from functools import wraps, partial, update_wrapper
+
+import rqdatac
+from rqdatac.share.errors import OverwriteWarning
+
+
+def deprecated(func=None, msg=None):
+    if func is None:
+        return partial(deprecated, msg=msg)
+
+    if msg is None:
+        msg = func.__name__ + " is deprecated, and will be removed in future."
+
+    @wraps(func)
+    def wrap(*args, **kwargs):
+        warnings.warn(msg, category=DeprecationWarning, stacklevel=0)
+        return func(*args, **kwargs)
+
+    return wrap
+
+
+def export_as_api(f=None, name=None, namespace=None, priority=0):
+    if f is None:
+        return partial(export_as_api, name=name, namespace=namespace)
+    name = name if name else f.__name__
+    if namespace:
+        if hasattr(rqdatac, namespace):
+            namespace = getattr(rqdatac, namespace)
+        else:
+            namespace_name = namespace
+            namespace = types.ModuleType(namespace_name)
+            namespace.__file__ = 'rqdatac plugin'
+            namespace.__module__ = "rqdatac"
+            setattr(rqdatac, namespace_name, namespace)
+            rqdatac.__all__.append(namespace_name)
+    else:
+        namespace = rqdatac
+        rqdatac.__all__.append(name)
+
+    old_f = getattr(namespace, name, None)
+    if old_f is not None:
+        if old_f.__priority > priority:
+            warnings.warn("!!!! CAN'T OVERWRITE API {} WITH {} BECAUSE OLD PRIPORITY {} > {} !!!!".format(name, f, old_f.__priority, priority), category=OverwriteWarning)
+            return f
+        warnings.warn("!!!! OVERWRITE API {} WITH {} !!!!".format(name, f), category=OverwriteWarning)
+
+    f.__priority = priority
+    setattr(namespace, name, f)
+
+    return f
+
+
+def retry(count, suppress_exceptions, delay=1.0):
+    def decorate(func):
+        @wraps(func)
+        def wrap(*args, **kwargs):
+            c = count
+            while c > 0:
+                try:
+                    return func(*args, **kwargs)
+                except suppress_exceptions as e:
+                    c -= 1
+                    if c == 0:
+                        raise e
+                    if delay:
+                        time.sleep(delay)
+
+        return wrap
+
+    return decorate
+
+
+def coroutine(func):
+    @wraps(func)
+    def primer(*args, **kwargs):
+        gen = func(*args, **kwargs)
+        next(gen)
+        return gen
+
+    return primer
+
+
+_ttl_cached_functions = set()
+
+
+def ttl_cache(ttl):
+    if not isinstance(ttl, int) or not ttl > 0:
+        raise TypeError("Expected ttl to be a positive integer")
+
+    def decorating_function(user_function):
+        wrapper = _ttl_cache_wrapper(user_function, ttl)
+        _ttl_cached_functions.add(wrapper)
+        return update_wrapper(wrapper, user_function)
+
+    return decorating_function
+
+
+def ttl_cache_clear():
+    for f in _ttl_cached_functions:
+        f.clear()
+
+
+def _ttl_cache_wrapper(user_function, ttl):
+    sentinel = object()
+    cache = {}
+    cache_get = cache.get  # bound method to lookup a key or return None
+    cache_clear = cache.clear
+
+    def wrapper(*args, **kwargs):
+        if kwargs:
+            key = args + (repr(sorted(kwargs.items())),)
+        else:
+            key = args
+
+        # in cpython, dict.get is thread-safe
+        result = cache_get(key, sentinel)
+        if result is not sentinel:
+            expire_at, value = result
+            if expire_at > time.time():
+                return value
+        value = user_function(*args, **kwargs)
+        cache[key] = (time.time() + ttl, value)
+        return value
+
+    setattr(wrapper, 'clear', cache_clear)
+    return wrapper
+
+
+def compatible_with_parm(func=None, name=None, value=None, replace=None):
+    if func is None:
+        return partial(compatible_with_parm, name=name, value=value, replace=replace)
+
+    @wraps(func)
+    def wrap(*args, **kwargs):
+        if name:
+            if name in kwargs:
+                msg = "'{}' is no longer used, please use '{}' instead ".format(name, replace)
+                warnings.warn(msg, category=DeprecationWarning, stacklevel=2)
+                item = kwargs.pop(name)
+                if item != value:
+                    raise ValueError("'{}': except '{}', got '{}'".format(name, value, item))
+        return func(*args, **kwargs)
+
+    return wrap
```

## rqdatac/rqdatah_helper.py

 * *Ordering differences only*

```diff
@@ -1,105 +1,105 @@
-# -*- coding: utf-8 -*-
-
-from functools import partial
-try:
-    from collections.abc import Iterable
-except ImportError:
-    from collections import Iterable
-import pandas as pd
-
-
-def rqdatah_serialize(f=None, converter=None, **kwargs):
-    """
-    为api添加结果转化函数，方便rqdatah将api返回结果转为文本格式。
-
-    params f: api函数
-    params converter: 函数类型，负责将api返回结果转化成为字符串
-    params kwargs: 传入converter的额外参数
-    """
-    if f is None:
-        return partial(rqdatah_serialize, converter=converter, **kwargs)
-    f.http_converter = partial(converter, **kwargs)
-    return f
-
-
-# rqdatah converters，负责将api返回结果转化成为字符串
-
-
-def http_conv_list_to_csv(data, **kwargs):
-    """ list 转化成csv """
-    if not isinstance(data, list):
-        data = [data]
-    name = kwargs.get('name', 'Unknown')
-    return name + '\n' + '\n'.join(str(d) for d in data)
-
-
-def http_conv_trading_hours(hours):
-    header = 'start_at,end_at\n'
-    if isinstance(hours, str):
-        return header + hours
-
-    return header + '\n'.join('{},{}'.format(str(s), str(e)) for (s, e) in hours)
-
-
-def http_conv_instruments(instruments):
-    """ instruments 转换成csv """
-    if not instruments:
-        return None
-    if not isinstance(instruments, list):
-        instruments = [instruments]
-
-    df = pd.DataFrame([i.__dict__ for i in instruments])
-    df.set_index('order_book_id', inplace=True)
-    return df.to_csv()
-
-
-def tick_to_dict(t):
-    d = {n: getattr(t, n) for n in dir(t) if not n.startswith('_')}
-
-    asks = d.pop('asks')
-    if isinstance(asks, Iterable):
-        d.update(('ask{}'.format(i), v) for i, v in enumerate(asks))
-
-    ask_vols = d.pop('ask_vols')
-    if isinstance(ask_vols, Iterable):
-        d.update(('ask_vol{}'.format(i), v) for i, v in enumerate(ask_vols))
-
-    bids = d.pop('bids')
-    if isinstance(bids, Iterable):
-        d.update(('bid{}'.format(i), v) for i, v in enumerate(bids))
-
-    bid_vols = d.pop('bid_vols')
-    if isinstance(bids, Iterable):
-        d.update(('bid_vol{}'.format(i), v) for i, v in enumerate(bid_vols))
-
-    return d
-
-
-def http_conv_ticks(ticks):
-    """ ticks 转换成csv """
-    if not isinstance(ticks, list):
-        ticks = [ticks]
-
-    df = pd.DataFrame([tick_to_dict(t) for t in ticks])
-    df.set_index('order_book_id', inplace=True)
-    return df.to_csv()
-
-
-def http_conv_dict_to_csv(d):
-    """ dict 转换成csv """
-    header = 'name,value\n'
-    body = '\n'.join('{},{}'.format(k, v) for k, v in d.items())
-    return header + body
-
-
-def http_conv_index_compoents(data, **kwargs):
-    if isinstance(data, list):
-        return http_conv_list_to_csv(data, **kwargs)
-    # expect dict
-    if isinstance(data, dict):
-        body = "date,order_book_id"
-        for dt, obs in data.items():
-            for oid in obs:
-                body += "\n{},{}".format(dt, oid)
-        return body
-    return str(data)
+# -*- coding: utf-8 -*-
+
+from functools import partial
+try:
+    from collections.abc import Iterable
+except ImportError:
+    from collections import Iterable
+import pandas as pd
+
+
+def rqdatah_serialize(f=None, converter=None, **kwargs):
+    """
+    为api添加结果转化函数，方便rqdatah将api返回结果转为文本格式。
+
+    params f: api函数
+    params converter: 函数类型，负责将api返回结果转化成为字符串
+    params kwargs: 传入converter的额外参数
+    """
+    if f is None:
+        return partial(rqdatah_serialize, converter=converter, **kwargs)
+    f.http_converter = partial(converter, **kwargs)
+    return f
+
+
+# rqdatah converters，负责将api返回结果转化成为字符串
+
+
+def http_conv_list_to_csv(data, **kwargs):
+    """ list 转化成csv """
+    if not isinstance(data, list):
+        data = [data]
+    name = kwargs.get('name', 'Unknown')
+    return name + '\n' + '\n'.join(str(d) for d in data)
+
+
+def http_conv_trading_hours(hours):
+    header = 'start_at,end_at\n'
+    if isinstance(hours, str):
+        return header + hours
+
+    return header + '\n'.join('{},{}'.format(str(s), str(e)) for (s, e) in hours)
+
+
+def http_conv_instruments(instruments):
+    """ instruments 转换成csv """
+    if not instruments:
+        return None
+    if not isinstance(instruments, list):
+        instruments = [instruments]
+
+    df = pd.DataFrame([i.__dict__ for i in instruments])
+    df.set_index('order_book_id', inplace=True)
+    return df.to_csv()
+
+
+def tick_to_dict(t):
+    d = {n: getattr(t, n) for n in dir(t) if not n.startswith('_')}
+
+    asks = d.pop('asks')
+    if isinstance(asks, Iterable):
+        d.update(('ask{}'.format(i), v) for i, v in enumerate(asks))
+
+    ask_vols = d.pop('ask_vols')
+    if isinstance(ask_vols, Iterable):
+        d.update(('ask_vol{}'.format(i), v) for i, v in enumerate(ask_vols))
+
+    bids = d.pop('bids')
+    if isinstance(bids, Iterable):
+        d.update(('bid{}'.format(i), v) for i, v in enumerate(bids))
+
+    bid_vols = d.pop('bid_vols')
+    if isinstance(bids, Iterable):
+        d.update(('bid_vol{}'.format(i), v) for i, v in enumerate(bid_vols))
+
+    return d
+
+
+def http_conv_ticks(ticks):
+    """ ticks 转换成csv """
+    if not isinstance(ticks, list):
+        ticks = [ticks]
+
+    df = pd.DataFrame([tick_to_dict(t) for t in ticks])
+    df.set_index('order_book_id', inplace=True)
+    return df.to_csv()
+
+
+def http_conv_dict_to_csv(d):
+    """ dict 转换成csv """
+    header = 'name,value\n'
+    body = '\n'.join('{},{}'.format(k, v) for k, v in d.items())
+    return header + body
+
+
+def http_conv_index_compoents(data, **kwargs):
+    if isinstance(data, list):
+        return http_conv_list_to_csv(data, **kwargs)
+    # expect dict
+    if isinstance(data, dict):
+        body = "date,order_book_id"
+        for dt, obs in data.items():
+            for oid in obs:
+                body += "\n{},{}".format(dt, oid)
+        return body
+    return str(data)
```

## rqdatac/thread_local.py

 * *Ordering differences only*

```diff
@@ -1,58 +1,58 @@
-# -*- coding: utf-8 -*-
-import threading
-import socket
-
-from rqdatac.share.errors import ErrorFromBackend, GatewayError
-from rqdatac.connection import Connection
-from rqdatac.decorators import retry
-from rqdatac.utils import connection_error, timeout_error
-
-
-class ThreadLocalConnection:
-    def __init__(self, addr, auth=None, connect_timeout=5, timeout=60):
-        self._local = threading.local()
-        self._addr = addr
-        self._auth = auth
-        self._connect_timeout = connect_timeout
-        self._timeout = timeout
-
-    def _get_connection(self):
-        conn = getattr(self._local, "connection", None)
-        if conn is not None:
-            if conn.is_normal():
-                return conn
-            else:
-                self.close()
-        s = Connection.sock_factory(self._addr, timeout=self._connect_timeout)
-        s.settimeout(self._timeout)
-        self._local.connection = Connection(s, self._auth)
-        return self._local.connection
-
-    def _execute(self, conn, method, args, kwargs):
-        try:
-            return conn.execute(method, *args, **kwargs)
-        except (KeyboardInterrupt, Exception) as e:
-            if not isinstance(e, (ErrorFromBackend, GatewayError)):
-                self.reset()
-                conn.close()
-            raise e
-
-    @retry(3, suppress_exceptions=(connection_error, GatewayError, timeout_error, socket.timeout))
-    def execute(self, method, *args, **kwargs):
-        return self._execute(self._get_connection(), method, args, kwargs)
-
-    @retry(3, suppress_exceptions=(connection_error, GatewayError))
-    def execute_with_timeout(self, timeout, method, *args, **kwargs):
-        assert isinstance(timeout, int) and timeout > 0
-        conn = self._get_connection()
-        conn.set_timeout(timeout)
-        r = self._execute(conn, method, args, kwargs)
-        conn.set_timeout(self._timeout)
-        return r
-
-    def close(self):
-        if getattr(self._local, "connection", None) is not None:
-            self._local.connection.close()
-            self._local.connection = None
-
-    reset = close
+# -*- coding: utf-8 -*-
+import threading
+import socket
+
+from rqdatac.share.errors import ErrorFromBackend, GatewayError
+from rqdatac.connection import Connection
+from rqdatac.decorators import retry
+from rqdatac.utils import connection_error, timeout_error
+
+
+class ThreadLocalConnection:
+    def __init__(self, addr, auth=None, connect_timeout=5, timeout=60):
+        self._local = threading.local()
+        self._addr = addr
+        self._auth = auth
+        self._connect_timeout = connect_timeout
+        self._timeout = timeout
+
+    def _get_connection(self):
+        conn = getattr(self._local, "connection", None)
+        if conn is not None:
+            if conn.is_normal():
+                return conn
+            else:
+                self.close()
+        s = Connection.sock_factory(self._addr, timeout=self._connect_timeout)
+        s.settimeout(self._timeout)
+        self._local.connection = Connection(s, self._auth)
+        return self._local.connection
+
+    def _execute(self, conn, method, args, kwargs):
+        try:
+            return conn.execute(method, *args, **kwargs)
+        except (KeyboardInterrupt, Exception) as e:
+            if not isinstance(e, (ErrorFromBackend, GatewayError)):
+                self.reset()
+                conn.close()
+            raise e
+
+    @retry(3, suppress_exceptions=(connection_error, GatewayError, timeout_error, socket.timeout))
+    def execute(self, method, *args, **kwargs):
+        return self._execute(self._get_connection(), method, args, kwargs)
+
+    @retry(3, suppress_exceptions=(connection_error, GatewayError))
+    def execute_with_timeout(self, timeout, method, *args, **kwargs):
+        assert isinstance(timeout, int) and timeout > 0
+        conn = self._get_connection()
+        conn.set_timeout(timeout)
+        r = self._execute(conn, method, args, kwargs)
+        conn.set_timeout(self._timeout)
+        return r
+
+    def close(self):
+        if getattr(self._local, "connection", None) is not None:
+            self._local.connection.close()
+            self._local.connection = None
+
+    reset = close
```

## rqdatac/utils.py

 * *Ordering differences only*

```diff
@@ -1,356 +1,356 @@
-# -*- coding: utf-8 -*-
-import datetime
-import socket
-
-import dateutil.parser
-import pandas as pd
-import numpy as np
-
-from dateutil.parser import parse as parse_datetime
-from dateutil.relativedelta import relativedelta
-
-from six import string_types, integer_types, PY2, binary_type
-
-
-def iterable(it):
-    return hasattr(it, "__next__") or hasattr(it, "__iter__")
-
-
-pd_version = pd.__version__
-if pd_version >= "0.25":
-    is_panel_removed = True
-else:
-    is_panel_removed = False
-
-_str_like = string_types + (bytes,)
-
-
-if PY2:
-    connection_error = socket.error
-    timeout_error = socket.timeout
-else:
-    timeout_error = TimeoutError
-    connection_error = ConnectionError
-
-
-def listify(it):
-    if isinstance(it, _str_like):
-        return [it]
-    elif iterable(it):
-        return list(it)
-    else:
-        return [it]
-
-
-def to_datetime(dt):
-    if isinstance(dt, datetime.datetime):
-        return dt
-    elif isinstance(dt, datetime.date):
-        return datetime.datetime(dt.year, dt.month, dt.day)
-    elif isinstance(dt, string_types):
-        return parse_datetime(dt, ignoretz=True)
-    elif isinstance(dt, integer_types):
-        return int_to_datetime(dt)
-    elif hasattr(dt, "to_pydatetime"):
-        return dt.to_pydatetime()
-    elif hasattr(dt, "dtype") and dt.dtype.char == "M":
-        return parse_datetime(str(dt))
-    raise ValueError("expect a datetime like object, got %r(%r)" % (type(dt), dt))
-
-
-def to_date(dt):
-    if isinstance(dt, datetime.datetime):
-        return dt.date()
-    elif isinstance(dt, datetime.date):
-        return dt
-    elif isinstance(dt, string_types):
-        return parse_datetime(dt).date()
-    elif isinstance(dt, integer_types):
-        return int8_to_date(dt)
-    elif hasattr(dt, "to_pydatetime"):
-        return dt.to_pydatetime()
-    elif hasattr(dt, "dtype") and dt.dtype.char == "M":
-        return parse_datetime(str(dt)).date()
-    raise ValueError("expect a datetime like object, got %r(%r)" % (type(dt), dt))
-
-
-def to_datetime_str(dt):
-    if not isinstance(dt, datetime.datetime):
-        dt = to_datetime(dt)
-    return "%04d-%02d-%02d %02d:%02d:%02d" % (
-        dt.year,
-        dt.month,
-        dt.day,
-        dt.hour,
-        dt.minute,
-        dt.second,
-    )
-
-
-def to_date_str(dt):
-    if not isinstance(dt, datetime.date):
-        dt = to_date(dt)
-    return "%04d-%02d-%02d" % (dt.year, dt.month, dt.day)
-
-
-def delay_today(years=0, months=0, days=0, leapdays=0, weeks=0):
-    # type: (int, int, int, int, int) -> datetime.datetime
-    return to_datetime(
-        datetime.date.today()
-        + relativedelta(years=years, months=months, days=days, leapdays=leapdays, weeks=weeks)
-    )
-
-
-def int_to_datetime(dt):
-    # type: (int) -> datetime.datetime
-    if 9999999 < dt < 99999999:  # 8位日期
-        return int8_to_datetime(dt)
-    if 9999999999999 < dt < 99999999999999:  # 14位日期时间
-        return int14_to_datetime(dt)
-    if 9999999999999999 < dt < 99999999999999999:  # 17位日期时间
-        return int17_to_datetime(dt)
-    raise ValueError("a datetime int should be 8, 14 or 17 length int, now is {}".format(dt))
-
-
-def int8_to_datetime(dt):
-    # type: (int) -> datetime.datetime
-    year, dt = dt // 10000, dt % 10000
-    month, day = dt // 100, dt % 100
-    return datetime.datetime(year, month, day)
-
-
-_int8_vectorize = np.vectorize(lambda y, m, d: datetime.datetime(y, m, d))
-
-
-def int8_to_datetime_v(dtarr):
-    if not isinstance(dtarr, np.ndarray):
-        dtarr = np.array(dtarr)
-    years, dt = dtarr // 10000, dtarr % 10000
-    months, days = dt // 100, dt % 100
-    return _int8_vectorize(years, months, days)
-
-
-def int9_to_time(tm):
-    hour, tm = tm // 10000000, tm % 10000000
-    minute, tm = tm // 100000, tm % 100000
-    second, ms = tm // 1000, tm % 1000
-    return datetime.time(hour, minute, second, ms * 1000)
-
-
-def int14_to_datetime(dt):
-    # type: (int) -> datetime.datetime
-    year, dt = dt // 10000000000, dt % 10000000000
-    month, dt = dt // 100000000, dt % 100000000
-    day, dt = dt // 1000000, dt % 1000000
-    hour, dt = dt // 10000, dt % 10000
-    minute, second = dt // 100, dt % 100
-    return datetime.datetime(year, month, day, hour, minute, second)
-
-
-_int14_vectorize = np.vectorize(lambda y, m, d, h, mm, s: datetime.datetime(y, m, d, h, mm, s))
-
-
-def int14_to_datetime_v(dtarr):
-    if not isinstance(dtarr, np.ndarray):
-        dtarr = np.array(dtarr)
-    years, dt = dtarr // 10000000000, dtarr % 10000000000
-    months = dt // 100000000
-    dt %= 100000000
-    days = dt // 1000000
-    dt %= 1000000
-    hours = dt // 10000
-    dt %= 10000
-    minutes, seconds = dt // 100, dt % 100
-    return _int14_vectorize(years, months, days, hours, minutes, seconds)
-
-
-def int17_to_datetime(dt):
-    # type: (int) -> datetime.datetime
-    year, dt = dt // 10000000000000, dt % 10000000000000
-    month, dt = dt // 100000000000, dt % 100000000000
-    day, dt = dt // 1000000000, dt % 1000000000
-    hour, dt = dt // 10000000, dt % 10000000
-    minute, dt = dt // 100000, dt % 100000
-    second, ms = dt // 1000, dt % 1000
-    return datetime.datetime(year, month, day, hour, minute, second, ms * 1000)
-
-
-_int17_vectorize = np.vectorize(lambda y, m, d, h, mm, s, ms: datetime.datetime(y, m, d, h, mm, s, ms))
-
-
-def int17_to_datetime_v(dtarr):
-    if not isinstance(dtarr, np.ndarray):
-        dtarr = np.array(dtarr)
-    years, dt = dtarr // 10000000000000, dtarr % 10000000000000
-    months = dt // 100000000000
-    dt %= 100000000000
-    days = dt // 1000000000
-    dt %= 1000000000
-    hours = dt // 10000000
-    dt %= 10000000
-    minutes = dt // 100000
-    dt %= 100000
-    seconds, ms = dt // 1000, dt % 1000
-    return _int17_vectorize(years, months, days, hours, minutes, seconds, ms*1000)
-
-
-def int8_to_date(dt):
-    # type: (int) -> datetime.date
-    year, dt = dt // 10000, dt % 10000
-    month, day = dt // 100, dt % 100
-    return datetime.date(year, month, day)
-
-
-def date_to_int8(dt):
-    return dt.year * 10000 + dt.month * 100 + dt.day
-
-
-def datetime_to_int14(dt):
-    return (
-        dt.year * 10000000000
-        + dt.month * 100000000
-        + dt.day * 1000000
-        + dt.hour * 10000
-        + dt.minute * 100
-        + dt.second
-    )
-
-
-def datetime_to_int17(dt):
-    return (
-        dt.year * 10000000000000
-        + dt.month * 100000000000
-        + dt.day * 1000000000
-        + dt.hour * 10000000
-        + dt.minute * 100000
-        + dt.second * 1000
-        + int(dt.microsecond / 1000)  # ms have six digits
-    )
-
-
-def to_date_int(ds):
-    # type: (...) -> int
-    if isinstance(ds, int):
-        return ds
-    elif not isinstance(ds, (datetime.date, datetime.datetime)):
-        ds = to_date(ds)
-    year, month, day = ds.year, ds.month, ds.day
-    return year * 10000 + month * 100 + day
-
-
-def today_int():
-    today = datetime.date.today()
-    return today.year * 10000 + today.month * 100 + today.day
-
-
-def _int_to_time(s):
-    if s < 10000:
-        return datetime.time(s // 100, s % 100)
-    if s < 10000000:
-        return datetime.time(s // 10000, (s % 10000) // 100, s % 100)
-    return datetime.time(s // 10000000000, (s % 10000000000) // 100000000, (s % 100000000) // 1000000,  s % 1000000)
-
-
-def to_time(s):
-    """convert object to datetime.time something like hh:mm:ss.* or hh:mm:ss or hh:mm"""
-    if isinstance(s, datetime.time):
-        return s
-    if isinstance(s, integer_types):
-        return _int_to_time(s)
-    if isinstance(s, string_types):
-        return parse_datetime(s).time()
-    if isinstance(s, datetime.datetime):
-        return s.time()
-    raise TypeError('unknown type: {}'.format(s))
-
-
-def safe_string_equal(s1, s2):
-    if PY2:
-        if isinstance(s1, binary_type):
-            s1 = s1.decode("utf8")
-        if isinstance(s2, binary_type):
-            s2 = s2.decode("utf8")
-    return s1 == s2
-
-
-def pf_fill_nan(pf, order_book_ids):
-    pf = pf.transpose(2, 0, 1)
-    for order_book_id in order_book_ids:
-        if order_book_id not in pf:
-            pf[order_book_id] = np.NAN
-    return pf.transpose(1, 2, 0)
-
-
-def get_tick_value(tick, field, default=0):
-    key_map = {"a": "ask", "b": "bid"}
-    if field.startswith("a") or field.startswith("b"):
-        key = key_map[field[0]]
-        if field.endswith("v"):
-            key += "_vol"
-        t = tick.get(key)
-        if t:
-            return t[int(field[1]) - 1]
-        else:
-            return default
-    else:
-        return tick.get(field, default)
-
-
-def convert_bar_to_multi_df(data, dt_name, fields, convert_dt, default=np.nan, return_slice_map=False):
-    line_no = 0
-    dt_set = set()
-    obid_level = []
-    obid_slice_map = {}
-    for obid, d in data:
-        dts = d[dt_name]
-        dts_len = len(dts)
-        if dts_len == 0:
-            continue
-        obid_slice_map[obid] = slice(line_no, line_no + dts_len, None)
-        dt_set.update(dts)
-        line_no += dts_len
-
-        obid_level.append(obid)
-
-    if line_no == 0:
-        return (None, obid_slice_map) if return_slice_map else None
-
-    obid_idx_map = {o: i for i, o in enumerate(obid_level)}
-    obid_label = np.empty(line_no, dtype=object)
-    dt_label = np.empty(line_no, dtype=object)
-    arr = np.full((line_no, len(fields)), default)
-    r_map_fields = {f: i for i, f in enumerate(fields)}
-
-    dt_arr_sorted = np.array(sorted(dt_set))
-    dt_level = convert_dt(dt_arr_sorted)
-
-    for obid, d in data:
-        dts = d[dt_name]
-        if len(dts) == 0:
-            continue
-        slice_ = obid_slice_map[obid]
-        for f, value in d.items():
-            if f == dt_name:
-                dt_label[slice_] = dt_arr_sorted.searchsorted(dts, side='left')
-            else:
-                arr[slice_, r_map_fields[f]] = value
-        obid_label[slice_] = [obid_idx_map[obid]] * len(dts)
-    try:
-        # func 'is_datetime_with_singletz_array'  is the most time consuming part in multi_index constructing
-        # it is useless for our situation. skip it.
-        func_is_singletz = getattr(pd._libs.lib, 'is_datetime_with_singletz_array')
-        setattr(pd._libs.lib, 'is_datetime_with_singletz_array', lambda *args: True)
-    except AttributeError:
-        func_is_singletz = None
-
-    multi_idx = pd.MultiIndex([obid_level, dt_level], [obid_label, dt_label],
-                              names=('order_book_id', dt_name))
-
-    if func_is_singletz is not None:
-        # recovery
-        setattr(pd._libs.lib, 'is_datetime_with_singletz_array', func_is_singletz)
-
-    df = pd.DataFrame(data=arr, index=multi_idx, columns=fields)
-    if return_slice_map:
-        return df, obid_slice_map
-    return df
+# -*- coding: utf-8 -*-
+import datetime
+import socket
+
+import dateutil.parser
+import pandas as pd
+import numpy as np
+
+from dateutil.parser import parse as parse_datetime
+from dateutil.relativedelta import relativedelta
+
+from six import string_types, integer_types, PY2, binary_type
+
+
+def iterable(it):
+    return hasattr(it, "__next__") or hasattr(it, "__iter__")
+
+
+pd_version = pd.__version__
+if pd_version >= "0.25":
+    is_panel_removed = True
+else:
+    is_panel_removed = False
+
+_str_like = string_types + (bytes,)
+
+
+if PY2:
+    connection_error = socket.error
+    timeout_error = socket.timeout
+else:
+    timeout_error = TimeoutError
+    connection_error = ConnectionError
+
+
+def listify(it):
+    if isinstance(it, _str_like):
+        return [it]
+    elif iterable(it):
+        return list(it)
+    else:
+        return [it]
+
+
+def to_datetime(dt):
+    if isinstance(dt, datetime.datetime):
+        return dt
+    elif isinstance(dt, datetime.date):
+        return datetime.datetime(dt.year, dt.month, dt.day)
+    elif isinstance(dt, string_types):
+        return parse_datetime(dt, ignoretz=True)
+    elif isinstance(dt, integer_types):
+        return int_to_datetime(dt)
+    elif hasattr(dt, "to_pydatetime"):
+        return dt.to_pydatetime()
+    elif hasattr(dt, "dtype") and dt.dtype.char == "M":
+        return parse_datetime(str(dt))
+    raise ValueError("expect a datetime like object, got %r(%r)" % (type(dt), dt))
+
+
+def to_date(dt):
+    if isinstance(dt, datetime.datetime):
+        return dt.date()
+    elif isinstance(dt, datetime.date):
+        return dt
+    elif isinstance(dt, string_types):
+        return parse_datetime(dt).date()
+    elif isinstance(dt, integer_types):
+        return int8_to_date(dt)
+    elif hasattr(dt, "to_pydatetime"):
+        return dt.to_pydatetime()
+    elif hasattr(dt, "dtype") and dt.dtype.char == "M":
+        return parse_datetime(str(dt)).date()
+    raise ValueError("expect a datetime like object, got %r(%r)" % (type(dt), dt))
+
+
+def to_datetime_str(dt):
+    if not isinstance(dt, datetime.datetime):
+        dt = to_datetime(dt)
+    return "%04d-%02d-%02d %02d:%02d:%02d" % (
+        dt.year,
+        dt.month,
+        dt.day,
+        dt.hour,
+        dt.minute,
+        dt.second,
+    )
+
+
+def to_date_str(dt):
+    if not isinstance(dt, datetime.date):
+        dt = to_date(dt)
+    return "%04d-%02d-%02d" % (dt.year, dt.month, dt.day)
+
+
+def delay_today(years=0, months=0, days=0, leapdays=0, weeks=0):
+    # type: (int, int, int, int, int) -> datetime.datetime
+    return to_datetime(
+        datetime.date.today()
+        + relativedelta(years=years, months=months, days=days, leapdays=leapdays, weeks=weeks)
+    )
+
+
+def int_to_datetime(dt):
+    # type: (int) -> datetime.datetime
+    if 9999999 < dt < 99999999:  # 8位日期
+        return int8_to_datetime(dt)
+    if 9999999999999 < dt < 99999999999999:  # 14位日期时间
+        return int14_to_datetime(dt)
+    if 9999999999999999 < dt < 99999999999999999:  # 17位日期时间
+        return int17_to_datetime(dt)
+    raise ValueError("a datetime int should be 8, 14 or 17 length int, now is {}".format(dt))
+
+
+def int8_to_datetime(dt):
+    # type: (int) -> datetime.datetime
+    year, dt = dt // 10000, dt % 10000
+    month, day = dt // 100, dt % 100
+    return datetime.datetime(year, month, day)
+
+
+_int8_vectorize = np.vectorize(lambda y, m, d: datetime.datetime(y, m, d))
+
+
+def int8_to_datetime_v(dtarr):
+    if not isinstance(dtarr, np.ndarray):
+        dtarr = np.array(dtarr)
+    years, dt = dtarr // 10000, dtarr % 10000
+    months, days = dt // 100, dt % 100
+    return _int8_vectorize(years, months, days)
+
+
+def int9_to_time(tm):
+    hour, tm = tm // 10000000, tm % 10000000
+    minute, tm = tm // 100000, tm % 100000
+    second, ms = tm // 1000, tm % 1000
+    return datetime.time(hour, minute, second, ms * 1000)
+
+
+def int14_to_datetime(dt):
+    # type: (int) -> datetime.datetime
+    year, dt = dt // 10000000000, dt % 10000000000
+    month, dt = dt // 100000000, dt % 100000000
+    day, dt = dt // 1000000, dt % 1000000
+    hour, dt = dt // 10000, dt % 10000
+    minute, second = dt // 100, dt % 100
+    return datetime.datetime(year, month, day, hour, minute, second)
+
+
+_int14_vectorize = np.vectorize(lambda y, m, d, h, mm, s: datetime.datetime(y, m, d, h, mm, s))
+
+
+def int14_to_datetime_v(dtarr):
+    if not isinstance(dtarr, np.ndarray):
+        dtarr = np.array(dtarr)
+    years, dt = dtarr // 10000000000, dtarr % 10000000000
+    months = dt // 100000000
+    dt %= 100000000
+    days = dt // 1000000
+    dt %= 1000000
+    hours = dt // 10000
+    dt %= 10000
+    minutes, seconds = dt // 100, dt % 100
+    return _int14_vectorize(years, months, days, hours, minutes, seconds)
+
+
+def int17_to_datetime(dt):
+    # type: (int) -> datetime.datetime
+    year, dt = dt // 10000000000000, dt % 10000000000000
+    month, dt = dt // 100000000000, dt % 100000000000
+    day, dt = dt // 1000000000, dt % 1000000000
+    hour, dt = dt // 10000000, dt % 10000000
+    minute, dt = dt // 100000, dt % 100000
+    second, ms = dt // 1000, dt % 1000
+    return datetime.datetime(year, month, day, hour, minute, second, ms * 1000)
+
+
+_int17_vectorize = np.vectorize(lambda y, m, d, h, mm, s, ms: datetime.datetime(y, m, d, h, mm, s, ms))
+
+
+def int17_to_datetime_v(dtarr):
+    if not isinstance(dtarr, np.ndarray):
+        dtarr = np.array(dtarr)
+    years, dt = dtarr // 10000000000000, dtarr % 10000000000000
+    months = dt // 100000000000
+    dt %= 100000000000
+    days = dt // 1000000000
+    dt %= 1000000000
+    hours = dt // 10000000
+    dt %= 10000000
+    minutes = dt // 100000
+    dt %= 100000
+    seconds, ms = dt // 1000, dt % 1000
+    return _int17_vectorize(years, months, days, hours, minutes, seconds, ms*1000)
+
+
+def int8_to_date(dt):
+    # type: (int) -> datetime.date
+    year, dt = dt // 10000, dt % 10000
+    month, day = dt // 100, dt % 100
+    return datetime.date(year, month, day)
+
+
+def date_to_int8(dt):
+    return dt.year * 10000 + dt.month * 100 + dt.day
+
+
+def datetime_to_int14(dt):
+    return (
+        dt.year * 10000000000
+        + dt.month * 100000000
+        + dt.day * 1000000
+        + dt.hour * 10000
+        + dt.minute * 100
+        + dt.second
+    )
+
+
+def datetime_to_int17(dt):
+    return (
+        dt.year * 10000000000000
+        + dt.month * 100000000000
+        + dt.day * 1000000000
+        + dt.hour * 10000000
+        + dt.minute * 100000
+        + dt.second * 1000
+        + int(dt.microsecond / 1000)  # ms have six digits
+    )
+
+
+def to_date_int(ds):
+    # type: (...) -> int
+    if isinstance(ds, int):
+        return ds
+    elif not isinstance(ds, (datetime.date, datetime.datetime)):
+        ds = to_date(ds)
+    year, month, day = ds.year, ds.month, ds.day
+    return year * 10000 + month * 100 + day
+
+
+def today_int():
+    today = datetime.date.today()
+    return today.year * 10000 + today.month * 100 + today.day
+
+
+def _int_to_time(s):
+    if s < 10000:
+        return datetime.time(s // 100, s % 100)
+    if s < 10000000:
+        return datetime.time(s // 10000, (s % 10000) // 100, s % 100)
+    return datetime.time(s // 10000000000, (s % 10000000000) // 100000000, (s % 100000000) // 1000000,  s % 1000000)
+
+
+def to_time(s):
+    """convert object to datetime.time something like hh:mm:ss.* or hh:mm:ss or hh:mm"""
+    if isinstance(s, datetime.time):
+        return s
+    if isinstance(s, integer_types):
+        return _int_to_time(s)
+    if isinstance(s, string_types):
+        return parse_datetime(s).time()
+    if isinstance(s, datetime.datetime):
+        return s.time()
+    raise TypeError('unknown type: {}'.format(s))
+
+
+def safe_string_equal(s1, s2):
+    if PY2:
+        if isinstance(s1, binary_type):
+            s1 = s1.decode("utf8")
+        if isinstance(s2, binary_type):
+            s2 = s2.decode("utf8")
+    return s1 == s2
+
+
+def pf_fill_nan(pf, order_book_ids):
+    pf = pf.transpose(2, 0, 1)
+    for order_book_id in order_book_ids:
+        if order_book_id not in pf:
+            pf[order_book_id] = np.NAN
+    return pf.transpose(1, 2, 0)
+
+
+def get_tick_value(tick, field, default=0):
+    key_map = {"a": "ask", "b": "bid"}
+    if field.startswith("a") or field.startswith("b"):
+        key = key_map[field[0]]
+        if field.endswith("v"):
+            key += "_vol"
+        t = tick.get(key)
+        if t:
+            return t[int(field[1]) - 1]
+        else:
+            return default
+    else:
+        return tick.get(field, default)
+
+
+def convert_bar_to_multi_df(data, dt_name, fields, convert_dt, default=np.nan, return_slice_map=False):
+    line_no = 0
+    dt_set = set()
+    obid_level = []
+    obid_slice_map = {}
+    for obid, d in data:
+        dts = d[dt_name]
+        dts_len = len(dts)
+        if dts_len == 0:
+            continue
+        obid_slice_map[obid] = slice(line_no, line_no + dts_len, None)
+        dt_set.update(dts)
+        line_no += dts_len
+
+        obid_level.append(obid)
+
+    if line_no == 0:
+        return (None, obid_slice_map) if return_slice_map else None
+
+    obid_idx_map = {o: i for i, o in enumerate(obid_level)}
+    obid_label = np.empty(line_no, dtype=object)
+    dt_label = np.empty(line_no, dtype=object)
+    arr = np.full((line_no, len(fields)), default)
+    r_map_fields = {f: i for i, f in enumerate(fields)}
+
+    dt_arr_sorted = np.array(sorted(dt_set))
+    dt_level = convert_dt(dt_arr_sorted)
+
+    for obid, d in data:
+        dts = d[dt_name]
+        if len(dts) == 0:
+            continue
+        slice_ = obid_slice_map[obid]
+        for f, value in d.items():
+            if f == dt_name:
+                dt_label[slice_] = dt_arr_sorted.searchsorted(dts, side='left')
+            else:
+                arr[slice_, r_map_fields[f]] = value
+        obid_label[slice_] = [obid_idx_map[obid]] * len(dts)
+    try:
+        # func 'is_datetime_with_singletz_array'  is the most time consuming part in multi_index constructing
+        # it is useless for our situation. skip it.
+        func_is_singletz = getattr(pd._libs.lib, 'is_datetime_with_singletz_array')
+        setattr(pd._libs.lib, 'is_datetime_with_singletz_array', lambda *args: True)
+    except AttributeError:
+        func_is_singletz = None
+
+    multi_idx = pd.MultiIndex([obid_level, dt_level], [obid_label, dt_label],
+                              names=('order_book_id', dt_name))
+
+    if func_is_singletz is not None:
+        # recovery
+        setattr(pd._libs.lib, 'is_datetime_with_singletz_array', func_is_singletz)
+
+    df = pd.DataFrame(data=arr, index=multi_idx, columns=fields)
+    if return_slice_map:
+        return df, obid_slice_map
+    return df
```

## rqdatac/validators.py

 * *Ordering differences only*

```diff
@@ -1,250 +1,250 @@
-# -*- coding: utf-8 -*-
-import warnings
-import datetime
-
-from dateutil.relativedelta import relativedelta
-from six import string_types, binary_type, text_type
-
-from rqdatac.utils import listify, to_date, is_panel_removed
-
-
-def check_quarter(quarter, name=""):
-    if not isinstance(quarter, string_types):
-        raise ValueError("{}: expect string, got{!r}".format(name, quarter))
-    quarter_elm = quarter.lower().split("q")
-    if len(quarter_elm) != 2:
-        raise ValueError("{}: invalid quarter param, got{!r} please use format like '2016q1'".format(name, quarter))
-    if len(quarter_elm[0]) != 4 or len(quarter_elm[1]) != 1:
-        raise ValueError("{}: invalid param, got{!r} please use format like '2016q1'".format(name, quarter))
-    ensure_int(quarter_elm[1], name)
-    ensure_int(quarter_elm[0], name)
-    if not (1 <= int(quarter_elm[1]) <= 4 or 1900 <= int(quarter_elm[0]) <= 3000):
-        raise ValueError(
-            "{}: invalid year/quarter param, got{!r} please use format like '2016q1'".format(name, quarter))
-
-
-def quarter_string_to_date(quarter_string):
-    mappings = {
-        "1": "03-31",
-        "2": "06-30",
-        "3": "09-30",
-        "4": "12-31"
-    }
-    year, quarter = quarter_string.lower().split("q")
-    return "{}-{}".format(year, mappings[quarter])
-
-
-def ensure_list_of_string(s, name=""):
-    if isinstance(s, string_types):
-        return [s]
-
-    result = list(s)
-    for v in result:
-        if not isinstance(v, string_types):
-            raise ValueError("{}: expect string or list of string, got {!r}".format(name, v))
-    return result
-
-
-def ensure_list(s, expect_type, name=""):
-    if isinstance(s, expect_type):
-        return [s]    
-    result = list(s)
-    for v in result:
-        if not isinstance(v, expect_type):
-            raise ValueError("{}: expect {!r}, got {!r}".format(name, expect_type, v))
-    return result
-
-
-def ensure_string(s, name="", decoding="utf-8"):
-    if isinstance(s, binary_type):
-        return s.decode(decoding)
-    if not isinstance(s, text_type):
-        raise ValueError("{}: expect a string, got {!r}".format(name, s))
-    return s
-
-
-def ensure_string_in(s, should_in, name="", decoding="utf-8"):
-    s = ensure_string(s, name, decoding)
-    if s not in should_in:
-        raise TypeError("{}: expect value in {!r}".format(name, should_in))
-    return s
-
-
-def check_type(s, t, name=""):
-    if not isinstance(s, t):
-        raise ValueError("{}: expect value in type {}, got {!r}.".format(name, t, s))
-
-
-def ensure_int(s, name=""):
-    try:
-        return int(s)
-    except TypeError:
-        raise ValueError("{}: expect int value, got {!r}.".format(name, s))
-
-
-def check_items_in_container(items, should_in, name):
-    items = listify(items)
-    for item in items:
-        if item not in should_in:
-            raise ValueError(
-                "{}: got invalided value {}, choose any in {}".format(name, item, should_in)
-            )
-
-
-def ensure_order(items, ordered):
-    # type: (list, iter) -> list
-    items = set(items)
-    return [i for i in ordered if i in items]
-
-
-def ensure_date_str(date):
-    # type: (...) -> str
-    date = to_date(date)
-    return "%04d-%02d-%02d" % (date.year, date.month, date.day)
-
-
-def ensure_date_int(date):
-    date = to_date(date)
-    return date.year * 10000 + date.month * 100 + date.day
-
-
-def ensure_date_or_today_int(date):
-    if date:
-        return ensure_date_int(date)
-    return _to_date_int(datetime.datetime.today())
-
-
-def _to_date_int(date):
-    # type: (datetime.datetime or datetime.date) -> int
-    return date.year * 10000 + date.month * 100 + date.day
-
-
-def ensure_date_range(start_date, end_date, delta=relativedelta(months=3)):
-    if start_date is None and end_date is None:
-        return _to_date_int(datetime.date.today() - delta), _to_date_int(datetime.date.today())
-
-    if start_date is None:
-        end_date = to_date(end_date)
-        return _to_date_int(end_date - delta), _to_date_int(end_date)
-
-    if end_date is None:
-        start_date = to_date(start_date)
-        return _to_date_int(start_date), _to_date_int(start_date + delta)
-
-    s, e = ensure_date_int(start_date), ensure_date_int(end_date)
-    if s > e:
-        raise ValueError("invalid date range: [{!r}, {!r}]".format(start_date, end_date))
-    return s, e
-
-
-def ensure_dates_base_on_listed_date(instrument, start_date, end_date, market):
-    from rqdatac.services.calendar import get_previous_trading_date, get_latest_trading_date
-    if to_date(instrument.listed_date) > datetime.date.today():
-        raise ValueError("instrument {} is not listed yet".format(instrument.order_book_id))
-
-    if start_date is None:
-        start_date = instrument.listed_date
-    elif to_date(start_date) < to_date(instrument.listed_date):
-        start_date = to_date(instrument.listed_date)
-    elif instrument.de_listed_date != "0000-00-00" and to_date(start_date) >= to_date(instrument.de_listed_date):
-        warnings.warn("{} has been delisted on {}".format(instrument.order_book_id, instrument.de_listed_date))
-        return None, None
-
-    if end_date is None:
-        if instrument.de_listed_date != "0000-00-00":
-            end_date = get_previous_trading_date(instrument.de_listed_date, market=market)
-        else:
-            end_date = get_latest_trading_date(market=market)
-    elif instrument.de_listed_date != "0000-00-00" and to_date(end_date) >= to_date(instrument.de_listed_date):
-        warnings.warn("{} has been delisted on {}".format(instrument.order_book_id, instrument.de_listed_date))
-        end_date = get_previous_trading_date(instrument.de_listed_date, market=market)
-    return start_date, end_date
-
-
-def ensure_instruments(order_book_ids, type=None, market="cn"):
-    order_book_ids = ensure_list_of_string(order_book_ids)
-    from rqdatac.services.basic import _all_obid_to_type, _get_instrument
-
-    obid_to_type = _all_obid_to_type(market)
-    result = []
-    obid_set = set()
-    for ob in order_book_ids:
-        if ob not in obid_to_type:
-            warnings.warn("invalid order_book_id: {}".format(ob), stacklevel=0)
-            continue
-        ob_type, ob = obid_to_type[ob]
-        if ob in obid_set:
-            continue
-        obid_set.add(ob)
-        if type is not None and ob_type != type:
-            warnings.warn(
-                "expect {} instrument, got {}({}), ignored".format(type, ob_type, ob), stacklevel=0
-            )
-            continue
-        instrument = _get_instrument(ob_type, ob, market)
-        result.append(instrument)
-    if not result:
-        raise ValueError("order_book_ids: at least one valid instrument expected, got none")
-    return result
-
-
-def ensure_order_book_ids(order_book_ids, type=None, market="cn"):
-    order_book_ids = ensure_list_of_string(order_book_ids)
-    from rqdatac.services.basic import _all_obid_to_type
-
-    obid_to_type = _all_obid_to_type(market)
-    result = []
-
-    if type is not None:
-        type = tuple(type) if isinstance(type, (list, tuple, set)) else (type, )
-
-    for ob in set(order_book_ids):
-        if ob not in obid_to_type:
-            warnings.warn("invalid order_book_id: {}".format(ob))
-            continue
-        ob_type, ob = obid_to_type[ob]
-        if type is not None and ob_type not in type:
-            warnings.warn("expect {} instrument, got {}({}), ignored".format(type, ob_type, ob))
-            continue
-        result.append(ob)
-    if not result:
-        raise ValueError("order_book_ids: at least one valid instrument expected, got none")
-    return result
-
-
-def ensure_order_book_id(ob, type=None, market="cn"):
-    ob = ensure_string(ob, "order_book_id")
-    from rqdatac.services.basic import _all_obid_to_type
-
-    obid_to_type = _all_obid_to_type(market)
-    if ob not in obid_to_type:
-        raise ValueError("invalid order_book_id: {}".format(ob))
-    ob_type, ob = obid_to_type[ob]
-    if type is not None and ob_type != type:
-        raise ValueError(
-            "expect {} instrument, got {}({}), ignored".format(type, obid_to_type[ob], ob)
-        )
-    return ob
-
-
-def ensure_trading_date(date):
-    from rqdatac.services.calendar import get_trading_dates, get_previous_trading_date, get_next_trading_date
-
-    trading_dates = get_trading_dates(get_previous_trading_date(date), get_next_trading_date(date))
-    if date not in trading_dates:
-        raise ValueError(
-            "expect a trading date, got {}, for reference {}".format(date.strftime("%Y%m%d"), trading_dates)
-        )
-    return date
-
-
-def raise_for_no_panel(expect_df=False):
-    if not expect_df and is_panel_removed:
-        raise RuntimeError("Panel has been removed since pandas's version >= 0.25, "
-                           "you could set 'expect_df=True' and then get a MultiIndex DataFrame")
-
-
-def ensure_expect_df(expect_df):
-    if not expect_df and is_panel_removed:
-        raise RuntimeError("Panel has been removed since pandas's version >= 0.25, "
-                           "you could set 'expect_df=True' and then get a MultiIndex DataFrame")
+# -*- coding: utf-8 -*-
+import warnings
+import datetime
+
+from dateutil.relativedelta import relativedelta
+from six import string_types, binary_type, text_type
+
+from rqdatac.utils import listify, to_date, is_panel_removed
+
+
+def check_quarter(quarter, name=""):
+    if not isinstance(quarter, string_types):
+        raise ValueError("{}: expect string, got{!r}".format(name, quarter))
+    quarter_elm = quarter.lower().split("q")
+    if len(quarter_elm) != 2:
+        raise ValueError("{}: invalid quarter param, got{!r} please use format like '2016q1'".format(name, quarter))
+    if len(quarter_elm[0]) != 4 or len(quarter_elm[1]) != 1:
+        raise ValueError("{}: invalid param, got{!r} please use format like '2016q1'".format(name, quarter))
+    ensure_int(quarter_elm[1], name)
+    ensure_int(quarter_elm[0], name)
+    if not (1 <= int(quarter_elm[1]) <= 4 or 1900 <= int(quarter_elm[0]) <= 3000):
+        raise ValueError(
+            "{}: invalid year/quarter param, got{!r} please use format like '2016q1'".format(name, quarter))
+
+
+def quarter_string_to_date(quarter_string):
+    mappings = {
+        "1": "03-31",
+        "2": "06-30",
+        "3": "09-30",
+        "4": "12-31"
+    }
+    year, quarter = quarter_string.lower().split("q")
+    return "{}-{}".format(year, mappings[quarter])
+
+
+def ensure_list_of_string(s, name=""):
+    if isinstance(s, string_types):
+        return [s]
+
+    result = list(s)
+    for v in result:
+        if not isinstance(v, string_types):
+            raise ValueError("{}: expect string or list of string, got {!r}".format(name, v))
+    return result
+
+
+def ensure_list(s, expect_type, name=""):
+    if isinstance(s, expect_type):
+        return [s]    
+    result = list(s)
+    for v in result:
+        if not isinstance(v, expect_type):
+            raise ValueError("{}: expect {!r}, got {!r}".format(name, expect_type, v))
+    return result
+
+
+def ensure_string(s, name="", decoding="utf-8"):
+    if isinstance(s, binary_type):
+        return s.decode(decoding)
+    if not isinstance(s, text_type):
+        raise ValueError("{}: expect a string, got {!r}".format(name, s))
+    return s
+
+
+def ensure_string_in(s, should_in, name="", decoding="utf-8"):
+    s = ensure_string(s, name, decoding)
+    if s not in should_in:
+        raise TypeError("{}: expect value in {!r}".format(name, should_in))
+    return s
+
+
+def check_type(s, t, name=""):
+    if not isinstance(s, t):
+        raise ValueError("{}: expect value in type {}, got {!r}.".format(name, t, s))
+
+
+def ensure_int(s, name=""):
+    try:
+        return int(s)
+    except TypeError:
+        raise ValueError("{}: expect int value, got {!r}.".format(name, s))
+
+
+def check_items_in_container(items, should_in, name):
+    items = listify(items)
+    for item in items:
+        if item not in should_in:
+            raise ValueError(
+                "{}: got invalided value {}, choose any in {}".format(name, item, should_in)
+            )
+
+
+def ensure_order(items, ordered):
+    # type: (list, iter) -> list
+    items = set(items)
+    return [i for i in ordered if i in items]
+
+
+def ensure_date_str(date):
+    # type: (...) -> str
+    date = to_date(date)
+    return "%04d-%02d-%02d" % (date.year, date.month, date.day)
+
+
+def ensure_date_int(date):
+    date = to_date(date)
+    return date.year * 10000 + date.month * 100 + date.day
+
+
+def ensure_date_or_today_int(date):
+    if date:
+        return ensure_date_int(date)
+    return _to_date_int(datetime.datetime.today())
+
+
+def _to_date_int(date):
+    # type: (datetime.datetime or datetime.date) -> int
+    return date.year * 10000 + date.month * 100 + date.day
+
+
+def ensure_date_range(start_date, end_date, delta=relativedelta(months=3)):
+    if start_date is None and end_date is None:
+        return _to_date_int(datetime.date.today() - delta), _to_date_int(datetime.date.today())
+
+    if start_date is None:
+        end_date = to_date(end_date)
+        return _to_date_int(end_date - delta), _to_date_int(end_date)
+
+    if end_date is None:
+        start_date = to_date(start_date)
+        return _to_date_int(start_date), _to_date_int(start_date + delta)
+
+    s, e = ensure_date_int(start_date), ensure_date_int(end_date)
+    if s > e:
+        raise ValueError("invalid date range: [{!r}, {!r}]".format(start_date, end_date))
+    return s, e
+
+
+def ensure_dates_base_on_listed_date(instrument, start_date, end_date, market):
+    from rqdatac.services.calendar import get_previous_trading_date, get_latest_trading_date
+    if to_date(instrument.listed_date) > datetime.date.today():
+        raise ValueError("instrument {} is not listed yet".format(instrument.order_book_id))
+
+    if start_date is None:
+        start_date = instrument.listed_date
+    elif to_date(start_date) < to_date(instrument.listed_date):
+        start_date = to_date(instrument.listed_date)
+    elif instrument.de_listed_date != "0000-00-00" and to_date(start_date) >= to_date(instrument.de_listed_date):
+        warnings.warn("{} has been delisted on {}".format(instrument.order_book_id, instrument.de_listed_date))
+        return None, None
+
+    if end_date is None:
+        if instrument.de_listed_date != "0000-00-00":
+            end_date = get_previous_trading_date(instrument.de_listed_date, market=market)
+        else:
+            end_date = get_latest_trading_date(market=market)
+    elif instrument.de_listed_date != "0000-00-00" and to_date(end_date) >= to_date(instrument.de_listed_date):
+        warnings.warn("{} has been delisted on {}".format(instrument.order_book_id, instrument.de_listed_date))
+        end_date = get_previous_trading_date(instrument.de_listed_date, market=market)
+    return start_date, end_date
+
+
+def ensure_instruments(order_book_ids, type=None, market="cn"):
+    order_book_ids = ensure_list_of_string(order_book_ids)
+    from rqdatac.services.basic import _all_obid_to_type, _get_instrument
+
+    obid_to_type = _all_obid_to_type(market)
+    result = []
+    obid_set = set()
+    for ob in order_book_ids:
+        if ob not in obid_to_type:
+            warnings.warn("invalid order_book_id: {}".format(ob), stacklevel=0)
+            continue
+        ob_type, ob = obid_to_type[ob]
+        if ob in obid_set:
+            continue
+        obid_set.add(ob)
+        if type is not None and ob_type != type:
+            warnings.warn(
+                "expect {} instrument, got {}({}), ignored".format(type, ob_type, ob), stacklevel=0
+            )
+            continue
+        instrument = _get_instrument(ob_type, ob, market)
+        result.append(instrument)
+    if not result:
+        raise ValueError("order_book_ids: at least one valid instrument expected, got none")
+    return result
+
+
+def ensure_order_book_ids(order_book_ids, type=None, market="cn"):
+    order_book_ids = ensure_list_of_string(order_book_ids)
+    from rqdatac.services.basic import _all_obid_to_type
+
+    obid_to_type = _all_obid_to_type(market)
+    result = []
+
+    if type is not None:
+        type = tuple(type) if isinstance(type, (list, tuple, set)) else (type, )
+
+    for ob in set(order_book_ids):
+        if ob not in obid_to_type:
+            warnings.warn("invalid order_book_id: {}".format(ob))
+            continue
+        ob_type, ob = obid_to_type[ob]
+        if type is not None and ob_type not in type:
+            warnings.warn("expect {} instrument, got {}({}), ignored".format(type, ob_type, ob))
+            continue
+        result.append(ob)
+    if not result:
+        raise ValueError("order_book_ids: at least one valid instrument expected, got none")
+    return result
+
+
+def ensure_order_book_id(ob, type=None, market="cn"):
+    ob = ensure_string(ob, "order_book_id")
+    from rqdatac.services.basic import _all_obid_to_type
+
+    obid_to_type = _all_obid_to_type(market)
+    if ob not in obid_to_type:
+        raise ValueError("invalid order_book_id: {}".format(ob))
+    ob_type, ob = obid_to_type[ob]
+    if type is not None and ob_type != type:
+        raise ValueError(
+            "expect {} instrument, got {}({}), ignored".format(type, obid_to_type[ob], ob)
+        )
+    return ob
+
+
+def ensure_trading_date(date):
+    from rqdatac.services.calendar import get_trading_dates, get_previous_trading_date, get_next_trading_date
+
+    trading_dates = get_trading_dates(get_previous_trading_date(date), get_next_trading_date(date))
+    if date not in trading_dates:
+        raise ValueError(
+            "expect a trading date, got {}, for reference {}".format(date.strftime("%Y%m%d"), trading_dates)
+        )
+    return date
+
+
+def raise_for_no_panel(expect_df=False):
+    if not expect_df and is_panel_removed:
+        raise RuntimeError("Panel has been removed since pandas's version >= 0.25, "
+                           "you could set 'expect_df=True' and then get a MultiIndex DataFrame")
+
+
+def ensure_expect_df(expect_df):
+    if not expect_df and is_panel_removed:
+        raise RuntimeError("Panel has been removed since pandas's version >= 0.25, "
+                           "you could set 'expect_df=True' and then get a MultiIndex DataFrame")
```

## rqdatac/services/async_live_md_client.py

 * *Ordering differences only*

```diff
@@ -1,187 +1,187 @@
-import asyncio
-import warnings
-from collections import defaultdict
-
-from rqdatac.decorators import export_as_api
-from rqdatac.services.live_md_client import (
-    ensure_list_of_string,
-    instruments,
-    MinbarResampler,
-    json_dumps,
-    get_client,
-    json_loads,
-)
-
-
-@export_as_api
-class AsyncLiveMarketDataClient:
-    def __init__(self, ws_server_uri="wss://rqdata.ricequant.com/live_md"):
-        self._ws_server_url = ws_server_uri
-        self._lock = asyncio.Lock()
-
-        self._subscribed = set()
-        self._subscribed_by_user = set()
-        self._resamplers = defaultdict(dict)
-        self._info = None
-
-        self._ws_connection = None
-        self._closed = False
-
-    async def _connect(self):
-        try:
-            import websockets
-        except ImportError:
-            raise ImportError(
-                "AsyncLiveMarketData requires websockets: run 'pip install websockets' first"
-            )
-
-        # 这是一个阻塞的操作
-        _token = get_client().execute(
-            "user.get_live_md_auth_token",
-        )
-
-        login_data = {"action": "auth_by_token", "token": _token}
-        count = 3
-        while count > 0:
-            try:
-                self._ws_connection = await websockets.connect(self._ws_server_url)
-                await self._ws_connection.send(json_dumps(login_data))
-                res = await self._ws_connection.recv()
-                self._info = json_loads(res)
-            except websockets.WebSocketException as e:
-                count -= 1
-                if count == 0:
-                    raise e
-                warnings.warn(f"Login failed: {e}, Retrying...")
-                await asyncio.sleep(1)
-            else:
-                break
-
-    async def _get_connection(self):
-        async with self._lock:
-            if not self._ws_connection:
-                await self._connect()
-        return self._ws_connection
-
-    @property
-    def info(self):
-        return self._info
-
-    def close(self):
-        self._closed = True
-        asyncio.create_task(self._ws_connection.close())
-
-    async def subscribe(self, channels):
-        """订阅实时行情
-
-        :param channels: 订阅的标的列表 分钟和tick分别以 bar_ 和tick_开头 以平安银行为例，
-            subscribe('bar_000001.XSHE')  # 订阅分钟线的实时行情
-            subscribe('bar_AU2112_15m')   # 订阅15分钟线的实时行情
-            subscribe('tick_000001.XSHE')  # 订阅tick的实时行情
-            可以同时订阅多支标的 subscribe(['bar_000001.XSHE'， 'bar_000002.XSHE')
-        """
-        if self._closed:
-            raise RuntimeError("this connection is closed.")
-
-        channels = ensure_list_of_string(channels)
-        to_subscribe = []
-        for ch in channels:
-            ob = ch.split("_")[1]
-            if not instruments(ob):
-                warnings.warn(
-                    "invalid order_book_id: {}, channel {} ignored".format(ob, ch), stacklevel=0
-                )
-                continue
-
-            self._subscribed_by_user.add(ch)
-
-            if ch.startswith("bar_") and ch.endswith("m"):
-                _, order_book_id, freq = ch.split("_")
-                to_subscribe.append("bar_" + order_book_id)
-                resampler = MinbarResampler(order_book_id, int(freq[:-1]))
-                if resampler.channel not in self._resamplers["bar_" + order_book_id]:
-                    self._resamplers["bar_" + order_book_id][resampler.channel] = resampler
-            else:
-                to_subscribe.append(ch)
-
-        data = {
-            "action": "subscribe",
-            "channels": to_subscribe,
-        }
-
-        connection = await self._get_connection()
-        await connection.send(json_dumps(data))
-
-    async def unsubscribe(self, channels):
-        """取消订阅实时行情
-
-        :param channels: 取消订阅的标的列表 分钟和tick分别以 bar_ 和tick_开头 以平安银行为例，
-            unsubscribe('bar_000001.XSHE')  # 订阅分钟线的实时行情
-            unsubscribe('tick_000001.XSHE')  # 订阅tick的实时行情
-        """
-
-        if self._closed:
-            raise RuntimeError("this connection is closed.")
-
-        channels = ensure_list_of_string(channels)
-        for ch in channels:
-            self._subscribed_by_user.discard(ch)
-            if ch.startswith("bar_") and ch.endswith("m"):
-                _, order_book_id, freq = ch.split("_")
-                self._resamplers["bar_" + order_book_id].pop(ch, None)
-
-        channels = [
-            ch
-            for ch in channels
-            if ch not in self._subscribed_by_user
-            and (ch not in self._resamplers or not self._resamplers[ch])
-        ]
-
-        data = {
-            "action": "unsubscribe",
-            "channels": channels,
-        }
-
-        connection = await self._get_connection()
-        await connection.send(json_dumps(data))
-
-    async def listen(self):
-        """获取实时行情。
-        返回一个 AsyncGenerator，用法如下：
-
-            async for msg in client.listen():
-                print(msg)
-        """
-        try:
-            import websockets
-        except ImportError:
-            raise ImportError(
-                "AsyncLiveMarketData requires websockets: run 'pip install websockets' first"
-            )
-
-        if self._closed:
-            raise RuntimeError("this connection is closed.")
-        await self._get_connection()
-        while not self._closed:
-            try:
-                res = await self._ws_connection.recv()  # noqa
-            except websockets.ConnectionClosed:
-                warnings.warn("Connectio closed, reconnecting...")
-                self._ws_connection = None
-                await self._get_connection()
-            else:
-                if res:
-                    data = json_loads(res)
-                    if data["action"] == "feed":
-                        ch = data["channel"]
-                        if ch in self._resamplers:
-                            for resampler in self._resamplers[ch].values():
-                                bar = resampler.enqueue(data)
-                                if bar is not None:
-                                    yield bar
-                        if ch in self._subscribed_by_user:
-                            yield data
-                    elif data["action"] == "subscribe_reply":
-                        self._subscribed.update(data["subscribed"])
-                    elif data["action"] == "unsubscribe_reply":
-                        self._subscribed -= set(data["unsubscribed"])
+import asyncio
+import warnings
+from collections import defaultdict
+
+from rqdatac.decorators import export_as_api
+from rqdatac.services.live_md_client import (
+    ensure_list_of_string,
+    instruments,
+    MinbarResampler,
+    json_dumps,
+    get_client,
+    json_loads,
+)
+
+
+@export_as_api
+class AsyncLiveMarketDataClient:
+    def __init__(self, ws_server_uri="wss://rqdata.ricequant.com/live_md"):
+        self._ws_server_url = ws_server_uri
+        self._lock = asyncio.Lock()
+
+        self._subscribed = set()
+        self._subscribed_by_user = set()
+        self._resamplers = defaultdict(dict)
+        self._info = None
+
+        self._ws_connection = None
+        self._closed = False
+
+    async def _connect(self):
+        try:
+            import websockets
+        except ImportError:
+            raise ImportError(
+                "AsyncLiveMarketData requires websockets: run 'pip install websockets' first"
+            )
+
+        # 这是一个阻塞的操作
+        _token = get_client().execute(
+            "user.get_live_md_auth_token",
+        )
+
+        login_data = {"action": "auth_by_token", "token": _token}
+        count = 3
+        while count > 0:
+            try:
+                self._ws_connection = await websockets.connect(self._ws_server_url)
+                await self._ws_connection.send(json_dumps(login_data))
+                res = await self._ws_connection.recv()
+                self._info = json_loads(res)
+            except websockets.WebSocketException as e:
+                count -= 1
+                if count == 0:
+                    raise e
+                warnings.warn(f"Login failed: {e}, Retrying...")
+                await asyncio.sleep(1)
+            else:
+                break
+
+    async def _get_connection(self):
+        async with self._lock:
+            if not self._ws_connection:
+                await self._connect()
+        return self._ws_connection
+
+    @property
+    def info(self):
+        return self._info
+
+    def close(self):
+        self._closed = True
+        asyncio.create_task(self._ws_connection.close())
+
+    async def subscribe(self, channels):
+        """订阅实时行情
+
+        :param channels: 订阅的标的列表 分钟和tick分别以 bar_ 和tick_开头 以平安银行为例，
+            subscribe('bar_000001.XSHE')  # 订阅分钟线的实时行情
+            subscribe('bar_AU2112_15m')   # 订阅15分钟线的实时行情
+            subscribe('tick_000001.XSHE')  # 订阅tick的实时行情
+            可以同时订阅多支标的 subscribe(['bar_000001.XSHE'， 'bar_000002.XSHE')
+        """
+        if self._closed:
+            raise RuntimeError("this connection is closed.")
+
+        channels = ensure_list_of_string(channels)
+        to_subscribe = []
+        for ch in channels:
+            ob = ch.split("_")[1]
+            if not instruments(ob):
+                warnings.warn(
+                    "invalid order_book_id: {}, channel {} ignored".format(ob, ch), stacklevel=0
+                )
+                continue
+
+            self._subscribed_by_user.add(ch)
+
+            if ch.startswith("bar_") and ch.endswith("m"):
+                _, order_book_id, freq = ch.split("_")
+                to_subscribe.append("bar_" + order_book_id)
+                resampler = MinbarResampler(order_book_id, int(freq[:-1]))
+                if resampler.channel not in self._resamplers["bar_" + order_book_id]:
+                    self._resamplers["bar_" + order_book_id][resampler.channel] = resampler
+            else:
+                to_subscribe.append(ch)
+
+        data = {
+            "action": "subscribe",
+            "channels": to_subscribe,
+        }
+
+        connection = await self._get_connection()
+        await connection.send(json_dumps(data))
+
+    async def unsubscribe(self, channels):
+        """取消订阅实时行情
+
+        :param channels: 取消订阅的标的列表 分钟和tick分别以 bar_ 和tick_开头 以平安银行为例，
+            unsubscribe('bar_000001.XSHE')  # 订阅分钟线的实时行情
+            unsubscribe('tick_000001.XSHE')  # 订阅tick的实时行情
+        """
+
+        if self._closed:
+            raise RuntimeError("this connection is closed.")
+
+        channels = ensure_list_of_string(channels)
+        for ch in channels:
+            self._subscribed_by_user.discard(ch)
+            if ch.startswith("bar_") and ch.endswith("m"):
+                _, order_book_id, freq = ch.split("_")
+                self._resamplers["bar_" + order_book_id].pop(ch, None)
+
+        channels = [
+            ch
+            for ch in channels
+            if ch not in self._subscribed_by_user
+            and (ch not in self._resamplers or not self._resamplers[ch])
+        ]
+
+        data = {
+            "action": "unsubscribe",
+            "channels": channels,
+        }
+
+        connection = await self._get_connection()
+        await connection.send(json_dumps(data))
+
+    async def listen(self):
+        """获取实时行情。
+        返回一个 AsyncGenerator，用法如下：
+
+            async for msg in client.listen():
+                print(msg)
+        """
+        try:
+            import websockets
+        except ImportError:
+            raise ImportError(
+                "AsyncLiveMarketData requires websockets: run 'pip install websockets' first"
+            )
+
+        if self._closed:
+            raise RuntimeError("this connection is closed.")
+        await self._get_connection()
+        while not self._closed:
+            try:
+                res = await self._ws_connection.recv()  # noqa
+            except websockets.ConnectionClosed:
+                warnings.warn("Connectio closed, reconnecting...")
+                self._ws_connection = None
+                await self._get_connection()
+            else:
+                if res:
+                    data = json_loads(res)
+                    if data["action"] == "feed":
+                        ch = data["channel"]
+                        if ch in self._resamplers:
+                            for resampler in self._resamplers[ch].values():
+                                bar = resampler.enqueue(data)
+                                if bar is not None:
+                                    yield bar
+                        if ch in self._subscribed_by_user:
+                            yield data
+                    elif data["action"] == "subscribe_reply":
+                        self._subscribed.update(data["subscribed"])
+                    elif data["action"] == "unsubscribe_reply":
+                        self._subscribed -= set(data["unsubscribed"])
```

## rqdatac/services/basic.py

 * *Ordering differences only*

```diff
@@ -1,2059 +1,2059 @@
-# -*- coding: utf-8 -*-
-import datetime
-import bisect
-import re
-import warnings
-from copy import deepcopy
-
-import six
-import pandas as pd
-
-from rqdatac.client import get_client
-from rqdatac.utils import to_date, datetime_to_int14, to_date_str, to_time, int8_to_date
-from rqdatac.validators import (
-    ensure_list_of_string,
-    ensure_date_int,
-    check_type,
-    ensure_date_str,
-    ensure_order_book_id,
-    ensure_order_book_ids,
-    check_items_in_container,
-    ensure_date_range,
-    ensure_int,
-    ensure_string,
-    ensure_date_or_today_int,
-    ensure_string_in,
-)
-from rqdatac.services.concept import concept_names as get_concept_names
-from rqdatac.services.shenwan import get_instrument_industry
-from rqdatac.services.constant import SectorCode, SectorCodeItem, IndustryCode, IndustryCodeItem
-from rqdatac.services.calendar import get_previous_trading_date, is_trading_date, has_night_trading
-from rqdatac.decorators import export_as_api, ttl_cache, compatible_with_parm
-from dateutil.relativedelta import relativedelta
-from rqdatac.rqdatah_helper import (
-    rqdatah_serialize, http_conv_list_to_csv, http_conv_trading_hours, http_conv_dict_to_csv, http_conv_instruments
-)
-
-_wind_exchange_map = {
-    'CFFEX': 'CFE',
-    'SHFE': 'SHF',
-    'INE': 'INE',
-    'DCE': 'DCE',
-    'CZCE': 'CZC',
-    'GFEX': 'GFE',
-}
-
-
-_wind_index_map = {
-    '000902.CSI': '000902.XSHG',
-    '000904.CSI': '000904.XSHG',
-    '000907.CSI': '000907.XSHG',
-    '000980.CSI': '000980.XSHG',
-    '000985.CSI': '000985.XSHG',
-    'h30455.CSI': 'H30455.XSHG',
-    '921395.CSI': '921395.INDX',
-    '921396.CSI': '921396.INDX',
-    '921459.SH': '921459.INDX',
-    '921460.SH': '921460.INDX',
-    'h00300.CSI': 'H00300.INDX',
-    'h00902.CSI': 'H00902.INDX',
-    'h00903.CSI': 'H00903.INDX',
-    'h00904.CSI': 'H00904.INDX',
-    'h00905.CSI': 'H00905.INDX',
-    'h00906.CSI': 'H00906.INDX',
-    'h00907.CSI': 'H00907.INDX',
-    'h00980.CSI': 'H00980.INDX',
-    'h00985.CSI': 'H00985.INDX',
-    'h20748.CSI': 'H20748.INDX',
-    'h20749.CSI': 'H20749.INDX',
-    'h20750.CSI': 'H20750.INDX',
-    'h20751.CSI': 'H20751.INDX',
-    'h20752.CSI': 'H20752.INDX',
-    'h20753.CSI': 'H20753.INDX',
-    'h20903.CSI': 'H20903.INDX',
-    'h30310.CSI': 'H30310.XSHG',
-    '000908.CSI': '000908.XSHG',
-    '000909.CSI': '000909.XSHG',
-    '000910.CSI': '000910.XSHG',
-    '000911.CSI': '000911.XSHG',
-    '000912.CSI': '000912.XSHG',
-    '000913.CSI': '000913.XSHG',
-    '000915.CSI': '000915.XSHG',
-    '000916.CSI': '000916.XSHG',
-    '000917.CSI': '000917.XSHG',
-    '000951.CSI': '000951.XSHG',
-    '000952.CSI': '000952.XSHG',
-    '000957.CSI': '000957.XSHG',
-    'h00908.CSI': 'H00908.INDX',
-    'h00909.CSI': 'H00909.INDX',
-    'h00910.CSI': 'H00910.INDX',
-    'h00911.CSI': 'H00911.INDX',
-    'h00912.CSI': 'H00912.INDX',
-    'h00913.CSI': 'H00913.INDX',
-    'h00915.CSI': 'H00915.INDX',
-    'h00916.CSI': 'H00916.INDX',
-    'h00917.CSI': 'H00917.INDX',
-    'h00952.CSI': 'H00952.INDX',
-    'h30034.CSI': 'H30034.XSHG',
-    'h00951.CSI': 'H00951.INDX',
-    'h00957.CSI': 'H00957.INDX',
-    'h20034.CSI': 'H20034.INDX',
-    'h30250.CSI': 'H30250.XSHG',
-    'h30253.CSI': 'H30253.XSHG',
-    'h30254.CSI': 'H30254.XSHG',
-    'h30255.CSI': 'H30255.XSHG',
-    'h30258.CSI': 'H30258.XSHG',
-    'h30259.CSI': 'H30259.XSHG',
-    'h20250.CSI': 'H20250.INDX',
-    'h20251.CSI': 'H20251.INDX',
-    'h20252.CSI': 'H20252.INDX',
-    'h20253.CSI': 'H20253.INDX',
-    'h20254.CSI': 'H20254.INDX',
-    'h20255.CSI': 'H20255.INDX',
-    'h20257.CSI': 'H20257.INDX',
-    'h20258.CSI': 'H20258.INDX',
-    'h20259.CSI': 'H20259.INDX',
-    'h20673.CSI': 'H20673.INDX',
-    'h20670.CSI': 'H20670.INDX',
-    'h20671.CSI': 'H20671.INDX',
-    'h20674.CSI': 'H20674.INDX',
-    'h20675.CSI': 'H20675.INDX',
-    'h20676.CSI': 'H20676.INDX',
-    'h20677.CSI': 'H20677.INDX',
-    'h20679.CSI': 'H20679.INDX',
-    'h20680.CSI': 'H20680.INDX',
-    'h20681.CSI': 'H20681.INDX',
-    'h20682.CSI': 'H20682.INDX',
-    'h20683.CSI': 'H20683.INDX',
-    'h20684.CSI': 'H20684.INDX',
-    'h20685.CSI': 'H20685.INDX',
-    'h20694.CSI': 'H20694.INDX',
-    'h20695.CSI': 'H20695.INDX',
-    'h20686.CSI': 'H20686.INDX',
-    'h20687.CSI': 'H20687.INDX',
-    'h20688.CSI': 'H20688.INDX',
-    'h20689.CSI': 'H20689.INDX',
-    'h20690.CSI': 'H20690.INDX',
-    'h20691.CSI': 'H20691.INDX',
-    'h20692.CSI': 'H20692.INDX',
-    'h20693.CSI': 'H20693.INDX',
-    '000929.CSI': '000929.XSHG',
-    '000930.CSI': '000930.XSHG',
-    '000931.CSI': '000931.XSHG',
-    '000936.CSI': '000936.XSHG',
-    '000937.CSI': '000937.XSHG',
-    'h30086.CSI': 'H30086.XSHG',
-    'h00928.CSI': 'H00928.INDX',
-    'h00929.CSI': 'H00929.INDX',
-    'h00930.CSI': 'H00930.INDX',
-    'h00931.CSI': 'H00931.INDX',
-    'h00932.CSI': 'H00932.INDX',
-    'h00933.CSI': 'H00933.INDX',
-    'h00935.CSI': 'H00935.INDX',
-    'h00936.CSI': 'H00936.INDX',
-    'h00937.CSI': 'H00937.INDX',
-    'h20025.CSI': 'H20025.INDX',
-    'h20086.CSI': 'H20086.INDX',
-    '000841.CSI': '000841.XSHG',
-    'h30010.CSI': 'H30010.XSHG',
-    'h30013.CSI': 'H30013.XSHG',
-    'h30014.CSI': 'H30014.XSHG',
-    'h30016.CSI': 'H30016.XSHG',
-    'h30017.CSI': 'H30017.XSHG',
-    'h30018.CSI': 'H30018.XSHG',
-    'h30019.CSI': 'H30019.XSHG',
-    'h30020.CSI': 'H30020.XSHG',
-    'h30022.CSI': 'H30022.XSHG',
-    'h30023.CSI': 'H30023.XSHG',
-    'h30024.CSI': 'H30024.XSHG',
-    'h30026.CSI': 'H30026.XSHG',
-    'h30028.CSI': 'H30028.XSHG',
-    'h30029.CSI': 'H30029.XSHG',
-    'h30031.CSI': 'H30031.XSHG',
-    'h00841.CSI': 'H00841.INDX',
-    'h20010.CSI': 'H20010.INDX',
-    'h20013.CSI': 'H20013.INDX',
-    'h20014.CSI': 'H20014.INDX',
-    'h20016.CSI': 'H20016.INDX',
-    'h20017.CSI': 'H20017.INDX',
-    'h20018.CSI': 'H20018.INDX',
-    'h20019.CSI': 'H20019.INDX',
-    'h20020.CSI': 'H20020.INDX',
-    'h20022.CSI': 'H20022.INDX',
-    'h20023.CSI': 'H20023.INDX',
-    'h20024.CSI': 'H20024.INDX',
-    'h20026.CSI': 'H20026.INDX',
-    'h20028.CSI': 'H20028.INDX',
-    'h20029.CSI': 'H20029.INDX',
-    'h20031.CSI': 'H20031.INDX',
-    '931775.CSI': '931775.INDX',
-    'h00986.CSI': 'H00986.INDX',
-    'h00987.CSI': 'H00987.INDX',
-    'h00988.CSI': 'H00988.INDX',
-    'h00989.CSI': 'H00989.INDX',
-    'h00990.CSI': 'H00990.INDX',
-    'h00991.CSI': 'H00991.INDX',
-    'h00993.CSI': 'H00993.INDX',
-    'h00994.CSI': 'H00994.INDX',
-    'h00995.CSI': 'H00995.INDX',
-    'h30166.CSI': 'H30166.XSHG',
-    'h30170.CSI': 'H30170.XSHG',
-    'h30171.CSI': 'H30171.XSHG',
-    'h30173.CSI': 'H30173.XSHG',
-    'h30174.CSI': 'H30174.XSHG',
-    'h30175.CSI': 'H30175.XSHG',
-    'h30177.CSI': 'H30177.XSHG',
-    'h30179.CSI': 'H30179.XSHG',
-    'h30182.CSI': 'H30182.XSHG',
-    'h30183.CSI': 'H30183.XSHG',
-    'h30184.CSI': 'H30184.XSHG',
-    'h30186.CSI': 'H30186.XSHG',
-    'h30187.CSI': 'H30187.XSHG',
-    'h30196.CSI': 'H30196.XSHG',
-    'h30211.CSI': 'H30211.XSHG',
-    'h20164.CSI': 'H20164.INDX',
-    'h20166.CSI': 'H20166.INDX',
-    'h20170.CSI': 'H20170.INDX',
-    'h20171.CSI': 'H20171.INDX',
-    'h20173.CSI': 'H20173.INDX',
-    'h20174.CSI': 'H20174.INDX',
-    'h20175.CSI': 'H20175.INDX',
-    'h20177.CSI': 'H20177.INDX',
-    'h20179.CSI': 'H20179.INDX',
-    'h20180.CSI': 'H20180.INDX',
-    'h20182.CSI': 'H20182.INDX',
-    'h20183.CSI': 'H20183.INDX',
-    'h20184.CSI': 'H20184.INDX',
-    'h20186.CSI': 'H20186.INDX',
-    'h20187.CSI': 'H20187.INDX',
-    'h20196.CSI': 'H20196.INDX',
-    'h20211.CSI': 'H20211.INDX',
-    'h20910.CSI': 'H20910.INDX',
-    '930697.CSI': '930697.INDX',
-    'h30192.CSI': 'H30192.XSHG',
-    'h30193.CSI': 'H30193.XSHG',
-    'h30194.CSI': 'H30194.XSHG',
-    'h30195.CSI': 'H30195.XSHG',
-    'h30197.CSI': 'H30197.XSHG',
-    'h30199.CSI': 'H30199.XSHG',
-    'h30200.CSI': 'H30200.XSHG',
-    'h30203.CSI': 'H30203.XSHG',
-    'h30204.CSI': 'H30204.XSHG',
-    'h30206.CSI': 'H30206.XSHG',
-    'h30208.CSI': 'H30208.XSHG',
-    'h30209.CSI': 'H30209.XSHG',
-    'h30214.CSI': 'H30214.XSHG',
-    'h30215.CSI': 'H30215.XSHG',
-    'h30217.CSI': 'H30217.XSHG',
-    'h30218.CSI': 'H30218.XSHG',
-    'h30219.CSI': 'H30219.XSHG',
-    'h30220.CSI': 'H30220.XSHG',
-    'h30221.CSI': 'H30221.XSHG',
-    'h30222.CSI': 'H30222.XSHG',
-    'h20192.CSI': 'H20192.INDX',
-    'h20193.CSI': 'H20193.INDX',
-    'h20194.CSI': 'H20194.INDX',
-    'h20195.CSI': 'H20195.INDX',
-    'h20197.CSI': 'H20197.INDX',
-    'h20199.CSI': 'H20199.INDX',
-    'h20200.CSI': 'H20200.INDX',
-    'h20203.CSI': 'H20203.INDX',
-    'h20204.CSI': 'H20204.INDX',
-    'h20206.CSI': 'H20206.INDX',
-    'h20208.CSI': 'H20208.INDX',
-    'h20209.CSI': 'H20209.INDX',
-    'h20214.CSI': 'H20214.INDX',
-    'h20215.CSI': 'H20215.INDX',
-    'h20217.CSI': 'H20217.INDX',
-    'h20218.CSI': 'H20218.INDX',
-    'h20219.CSI': 'H20219.INDX',
-    'h20220.CSI': 'H20220.INDX',
-    'h20221.CSI': 'H20221.INDX',
-    'h20222.CSI': 'H20222.INDX',
-    'h20697.CSI': 'H20697.INDX',
-    'h20911.CSI': 'H20911.INDX',
-    'h30201.CSI': 'H30201.XSHG',
-    'h30207.CSI': 'H30207.XSHG',
-    'h30216.CSI': 'H30216.XSHG',
-    'h30223.CSI': 'H30223.XSHG',
-    'h20168.CSI': 'H20168.INDX',
-    'h20201.CSI': 'H20201.INDX',
-    'h20207.CSI': 'H20207.INDX',
-    'h20216.CSI': 'H20216.INDX',
-    'h20223.CSI': 'H20223.INDX',
-    'h11030.CSI': 'H11030.XSHG',
-    'h11031.CSI': 'H11031.XSHG',
-    'h11041.CSI': 'H11041.XSHG',
-    'h11042.CSI': 'H11042.XSHG',
-    'h11043.CSI': 'H11043.XSHG',
-    'h11044.CSI': 'H11044.XSHG',
-    'h11045.CSI': 'H11045.XSHG',
-    'h11046.CSI': 'H11046.XSHG',
-    'h11047.CSI': 'H11047.XSHG',
-    'h11049.CSI': 'H11049.XSHG',
-    'h11050.CSI': 'H11050.XSHG',
-    'h30036.CSI': 'H30036.XSHG',
-    'h30037.CSI': 'H30037.XSHG',
-    'h30038.CSI': 'H30038.XSHG',
-    'h30039.CSI': 'H30039.XSHG',
-    'h30040.CSI': 'H30040.XSHG',
-    'h30041.CSI': 'H30041.XSHG',
-    'h30042.CSI': 'H30042.XSHG',
-    'h30043.CSI': 'H30043.XSHG',
-    'h30044.CSI': 'H30044.XSHG',
-    'h30045.CSI': 'H30045.XSHG',
-    'h30046.CSI': 'H30046.XSHG',
-    'h30047.CSI': 'H30047.XSHG',
-    'h30048.CSI': 'H30048.XSHG',
-    'h30049.CSI': 'H30049.XSHG',
-    'h30050.CSI': 'H30050.XSHG',
-    'h30051.CSI': 'H30051.XSHG',
-    'h30052.CSI': 'H30052.XSHG',
-    'h30053.CSI': 'H30053.XSHG',
-    'h30054.CSI': 'H30054.XSHG',
-    'h30055.CSI': 'H30055.XSHG',
-    'h30056.CSI': 'H30056.XSHG',
-    'h30057.CSI': 'H30057.XSHG',
-    'h30058.CSI': 'H30058.XSHG',
-    'h30059.CSI': 'H30059.XSHG',
-    'h30060.CSI': 'H30060.XSHG',
-    'h30061.CSI': 'H30061.XSHG',
-    'h30062.CSI': 'H30062.XSHG',
-    'h30063.CSI': 'H30063.XSHG',
-    'h30064.CSI': 'H30064.XSHG',
-    'h30065.CSI': 'H30065.XSHG',
-    'h30066.CSI': 'H30066.XSHG',
-    'h30067.CSI': 'H30067.XSHG',
-    '000925.CSI': '000925.XSHG',
-    '000965.CSI': '000965.XSHG',
-    '000966.CSI': '000966.XSHG',
-    '000967.CSI': '000967.XSHG',
-    '930723.CSI': '930723.INDX',
-    'h11111.CSI': 'H11111.XSHG',
-    'h30362.CSI': 'H30362.XSHG',
-    'h30363.CSI': 'H30363.XSHG',
-    'h00925.CSI': 'H00925.INDX',
-    'h00965.CSI': 'H00965.INDX',
-    'h00966.CSI': 'H00966.INDX',
-    'h00967.CSI': 'H00967.INDX',
-    '000842.CSI': '000842.XSHG',
-    '000971.CSI': '000971.XSHG',
-    '000981.CSI': '000981.XSHG',
-    '000982.CSI': '000982.XSHG',
-    '000984.CSI': '000984.XSHG',
-    'h30238.CSI': 'H30238.XSHG',
-    'h30239.CSI': 'H30239.XSHG',
-    'h30248.CSI': 'H30248.XSHG',
-    'h30249.CSI': 'H30249.XSHG',
-    'h30422.CSI': 'H30422.XSHG',
-    'h30438.CSI': 'H30438.XSHG',
-    'h00842.CSI': 'H00842.INDX',
-    'h00971.CSI': 'H00971.INDX',
-    'h00981.CSI': 'H00981.INDX',
-    'h00982.CSI': 'H00982.INDX',
-    'h00984.CSI': 'H00984.INDX',
-    '000843.CSI': '000843.XSHG',
-    '000844.CSI': '000844.XSHG',
-    'h30087.CSI': 'H30087.XSHG',
-    'h30088.CSI': 'H30088.XSHG',
-    'h00843.CSI': 'H00843.INDX',
-    'h00844.CSI': 'H00844.INDX',
-    'h20087.CSI': 'H20087.INDX',
-    'h20088.CSI': 'H20088.INDX',
-    '000828.CSI': '000828.XSHG',
-    '000829.CSI': '000829.XSHG',
-    '000830.CSI': '000830.XSHG',
-    '000831.CSI': '000831.XSHG',
-    'h00828.CSI': 'H00828.INDX',
-    'h00829.CSI': 'H00829.INDX',
-    'h00830.CSI': 'H00830.INDX',
-    'h00831.CSI': 'H00831.INDX',
-    '000803.CSI': '000803.XSHG',
-    '000804.CSI': '000804.XSHG',
-    'h00803.CSI': 'H00803.INDX',
-    'h00804.CSI': 'H00804.INDX',
-    'h30082.CSI': 'H30082.XSHG',
-    'h30083.CSI': 'H30083.XSHG',
-    'h30084.CSI': 'H30084.XSHG',
-    'h11180.CSI': 'H11180.XSHG',
-    '000920.CSI': '000920.XSHG',
-    '000921.CSI': '000921.XSHG',
-    'h30090.CSI': 'H30090.XSHG',
-    'h30091.CSI': 'H30091.XSHG',
-    'h30092.CSI': 'H30092.XSHG',
-    'h30093.CSI': 'H30093.XSHG',
-    'h30094.CSI': 'H30094.XSHG',
-    'h30095.CSI': 'H30095.XSHG',
-    'h30096.CSI': 'H30096.XSHG',
-    'h30097.CSI': 'H30097.XSHG',
-    'h30098.CSI': 'H30098.XSHG',
-    'h30099.CSI': 'H30099.XSHG',
-    'h20090.CSI': 'H20090.INDX',
-    'h20091.CSI': 'H20091.INDX',
-    'h20092.CSI': 'H20092.INDX',
-    'h20093.CSI': 'H20093.INDX',
-    'h20094.CSI': 'H20094.INDX',
-    'h20095.CSI': 'H20095.INDX',
-    'h20096.CSI': 'H20096.INDX',
-    'h20097.CSI': 'H20097.INDX',
-    'h20098.CSI': 'H20098.INDX',
-    'h20099.CSI': 'H20099.INDX',
-    '000810.CSI': '000810.XSHG',
-    '000811.CSI': '000811.XSHG',
-    '000812.CSI': '000812.XSHG',
-    '000813.CSI': '000813.XSHG',
-    '000814.CSI': '000814.XSHG',
-    '000815.CSI': '000815.XSHG',
-    '000818.CSI': '000818.XSHG',
-    'h00810.CSI': 'H00810.INDX',
-    'h00811.CSI': 'H00811.INDX',
-    'h00812.CSI': 'H00812.INDX',
-    'h00813.CSI': 'H00813.INDX',
-    'h00814.CSI': 'H00814.INDX',
-    'h00815.CSI': 'H00815.INDX',
-    'h00816.CSI': 'H00816.INDX',
-    'h00818.CSI': 'H00818.INDX',
-    'h30001.CSI': 'H30001.XSHG',
-    'h30002.CSI': 'H30002.XSHG',
-    'h30004.CSI': 'H30004.XSHG',
-    'h30005.CSI': 'H30005.XSHG',
-    'h30006.CSI': 'H30006.XSHG',
-    'h20001.CSI': 'H20001.INDX',
-    'h20002.CSI': 'H20002.INDX',
-    'h20004.CSI': 'H20004.INDX',
-    'h20005.CSI': 'H20005.INDX',
-    'h20006.CSI': 'H20006.INDX',
-    'h11051.CSI': 'H11051.XSHG',
-    'h11052.CSI': 'H11052.XSHG',
-    'h11053.CSI': 'H11053.XSHG',
-    'h11054.CSI': 'H11054.XSHG',
-    'h11055.CSI': 'H11055.XSHG',
-    'h11057.CSI': 'H11057.XSHG',
-    'h11058.CSI': 'H11058.XSHG',
-    'h11059.CSI': 'H11059.XSHG',
-    'h11060.CSI': 'H11060.XSHG',
-    'h01051.CSI': 'H01051.INDX',
-    'h01052.CSI': 'H01052.INDX',
-    'h01053.CSI': 'H01053.INDX',
-    'h01054.CSI': 'H01054.INDX',
-    'h01055.CSI': 'H01055.INDX',
-    'h01057.CSI': 'H01057.INDX',
-    'h01058.CSI': 'H01058.INDX',
-    'h01059.CSI': 'H01059.INDX',
-    'h01060.CSI': 'H01060.INDX',
-    'h01113.CSI': 'H01113.INDX',
-    'h30137.CSI': 'H30137.XSHG',
-    'h30138.CSI': 'H30138.XSHG',
-    'h30139.CSI': 'H30139.XSHG',
-    'h30140.CSI': 'H30140.XSHG',
-    'h30141.CSI': 'H30141.XSHG',
-    'h30142.CSI': 'H30142.XSHG',
-    'h30143.CSI': 'H30143.XSHG',
-    'h20137.CSI': 'H20137.INDX',
-    'h20138.CSI': 'H20138.INDX',
-    'h20139.CSI': 'H20139.INDX',
-    'h20140.CSI': 'H20140.INDX',
-    'h20141.CSI': 'H20141.INDX',
-    'h20142.CSI': 'H20142.INDX',
-    'h20143.CSI': 'H20143.INDX',
-    '000942.CSI': '000942.XSHG',
-    '000943.CSI': '000943.XSHG',
-    '000945.CSI': '000945.XSHG',
-    '000947.CSI': '000947.XSHG',
-    '000948.CSI': '000948.XSHG',
-    '000949.CSI': '000949.XSHG',
-    'h00942.CSI': 'H00942.INDX',
-    'h00943.CSI': 'H00943.INDX',
-    'h00944.CSI': 'H00944.INDX',
-    'h00945.CSI': 'H00945.INDX',
-    'h00947.CSI': 'H00947.INDX',
-    'h00948.CSI': 'H00948.INDX',
-    'h00949.CSI': 'H00949.INDX',
-    '000821.CSI': '000821.XSHG',
-    '000822.CSI': '000822.XSHG',
-    '000824.CSI': '000824.XSHG',
-    '000825.CSI': '000825.XSHG',
-    '000826.CSI': '000826.XSHG',
-    'h30073.CSI': 'H30073.XSHG',
-    'h30089.CSI': 'H30089.XSHG',
-    'h00821.CSI': 'H00821.INDX',
-    'h00822.CSI': 'H00822.INDX',
-    'h00824.CSI': 'H00824.INDX',
-    'h00825.CSI': 'H00825.INDX',
-    'h00826.CSI': 'H00826.INDX',
-    'h00922.CSI': 'H00922.INDX',
-    '000839.CSI': '000839.XSHG',
-    '000840.CSI': '000840.XSHG',
-    '000926.CSI': '000926.XSHG',
-    '000927.CSI': '000927.XSHG',
-    '000938.CSI': '000938.XSHG',
-    '000953.CSI': '000953.XSHG',
-    '000954.CSI': '000954.XSHG',
-    '000955.CSI': '000955.XSHG',
-    '000956.CSI': '000956.XSHG',
-    '930746.CSI': '930746.INDX',
-    'h11154.CSI': 'H11154.XSHG',
-    'h11155.CSI': 'H11155.XSHG',
-    'h30368.CSI': 'H30368.XSHG',
-    'h50052.CSI': 'H50052.XSHG',
-    'h00839.CSI': 'H00839.INDX',
-    'h00840.CSI': 'H00840.INDX',
-    'h00926.CSI': 'H00926.INDX',
-    'h00927.CSI': 'H00927.INDX',
-    'h00938.CSI': 'H00938.INDX',
-    'h00939.CSI': 'H00939.INDX',
-    'h00953.CSI': 'H00953.INDX',
-    'h00954.CSI': 'H00954.INDX',
-    'h00955.CSI': 'H00955.INDX',
-    'h00956.CSI': 'H00956.INDX',
-    'h00958.CSI': 'H00958.INDX',
-    '000838.CSI': '000838.XSHG',
-    '000846.CSI': '000846.XSHG',
-    '000850.CSI': '000850.XSHG',
-    '000859.CSI': '000859.XSHG',
-    '000860.CSI': '000860.XSHG',
-    '000861.CSI': '000861.XSHG',
-    '000891.CSI': '000891.XSHG',
-    '000922.CSI': '000922.XSHG',
-    '000939.CSI': '000939.XSHG',
-    '000941.CSI': '000941.XSHG',
-    '000950.CSI': '000950.XSHG',
-    '000958.CSI': '000958.XSHG',
-    '000959.CSI': '000959.XSHG',
-    '000961.CSI': '000961.XSHG',
-    '000962.CSI': '000962.XSHG',
-    '000963.CSI': '000963.XSHG',
-    '000964.CSI': '000964.XSHG',
-    '000968.CSI': '000968.XSHG',
-    '000969.CSI': '000969.XSHG',
-    '000970.CSI': '000970.XSHG',
-    '000972.CSI': '000972.XSHG',
-    '000975.CSI': '000975.XSHG',
-    '000977.CSI': '000977.XSHG',
-    '000978.CSI': '000978.XSHG',
-    '000979.CSI': '000979.XSHG',
-    '000998.CSI': '000998.XSHG',
-    '930599.CSI': '930599.INDX',
-    '930629.CSI': '930629.INDX',
-    '930641.CSI': '930641.INDX',
-    '930648.CSI': '930648.INDX',
-    '930651.CSI': '930651.INDX',
-    '930652.CSI': '930652.INDX',
-    '930654.CSI': '930654.INDX',
-    '930700.CSI': '930700.INDX',
-    '930701.CSI': '930701.INDX',
-    '930709.CSI': '930709.INDX',
-    '930713.CSI': '930713.INDX',
-    '930719.CSI': '930719.INDX',
-    '930720.CSI': '930720.INDX',
-    '930721.CSI': '930721.INDX',
-    '930726.CSI': '930726.INDX',
-    '930734.CSI': '930734.INDX',
-    '930738.CSI': '930738.INDX',
-    '930743.CSI': '930743.INDX',
-    '930792.CSI': '930792.INDX',
-    '930838.CSI': '930838.INDX',
-    '930875.CSI': '930875.INDX',
-    '930915.CSI': '930915.INDX',
-    '930917.CSI': '930917.INDX',
-    '930997.CSI': '930997.INDX',
-    '930999.CSI': '930999.INDX',
-    '931000.CSI': '931000.INDX',
-    '931008.CSI': '931008.INDX',
-    '931009.CSI': '931009.INDX',
-    '931023.CSI': '931023.INDX',
-    '931029.CSI': '931029.INDX',
-    '931030.CSI': '931030.INDX',
-    '931031.CSI': '931031.INDX',
-    '931032.CSI': '931032.INDX',
-    '931033.CSI': '931033.INDX',
-    '931068.CSI': '931068.INDX',
-    '931071.CSI': '931071.INDX',
-    '931079.CSI': '931079.INDX',
-    '931087.CSI': '931087.INDX',
-    '931136.CSI': '931136.INDX',
-    '931139.CSI': '931139.INDX',
-    '931140.CSI': '931140.INDX',
-    '931141.CSI': '931141.INDX',
-    '931144.CSI': '931144.INDX',
-    '931152.CSI': '931152.INDX',
-    '931159.CSI': '931159.INDX',
-    '931160.CSI': '931160.INDX',
-    '931186.CSI': '931186.INDX',
-    '931187.CSI': '931187.INDX',
-    '931268.CSI': '931268.INDX',
-    '931357.CSI': '931357.INDX',
-    '931373.CSI': '931373.INDX',
-    '931380.CSI': '931380.INDX',
-    '931406.CSI': '931406.INDX',
-    '950082.CSI': '950082.INDX',
-    '950096.CSI': '950096.INDX',
-    'h11102.CSI': 'H11102.XSHG',
-    'h11103.CSI': 'H11103.XSHG',
-    'h11104.CSI': 'H11104.XSHG',
-    'h11105.CSI': 'H11105.XSHG',
-    'h11106.CSI': 'H11106.XSHG',
-    'h11112.CSI': 'H11112.XSHG',
-    'h11113.CSI': 'H11113.XSHG',
-    'h11114.CSI': 'H11114.XSHG',
-    'h11115.CSI': 'H11115.XSHG',
-    'h11116.CSI': 'H11116.XSHG',
-    'h11121.CSI': 'H11121.XSHG',
-    'h11125.CSI': 'H11125.XSHG',
-    'h11126.CSI': 'H11126.XSHG',
-    'h11136.CSI': 'H11136.XSHG',
-    'h11137.CSI': 'H11137.XSHG',
-    'h11141.CSI': 'H11141.XSHG',
-    'h11142.CSI': 'H11142.XSHG',
-    'h11145.CSI': 'H11145.XSHG',
-    'h11146.CSI': 'H11146.XSHG',
-    'h11147.CSI': 'H11147.XSHG',
-    'h11148.CSI': 'H11148.XSHG',
-    'h11149.CSI': 'H11149.XSHG',
-    'h11150.CSI': 'H11150.XSHG',
-    'h11151.CSI': 'H11151.XSHG',
-    'h11160.CSI': 'H11160.XSHG',
-    'h11161.CSI': 'H11161.XSHG',
-    'h11162.CSI': 'H11162.XSHG',
-    'h11163.CSI': 'H11163.XSHG',
-    'h11166.CSI': 'H11166.XSHG',
-    'h11167.CSI': 'H11167.XSHG',
-    'h11170.CSI': 'H11170.XSHG',
-    'h11171.CSI': 'H11171.XSHG',
-    'h11183.CSI': 'H11183.XSHG',
-    'h11184.CSI': 'H11184.XSHG',
-    'h30007.CSI': 'H30007.XSHG',
-    'h30011.CSI': 'H30011.XSHG',
-    'h30012.CSI': 'H30012.XSHG',
-    'h30015.CSI': 'H30015.XSHG',
-    'h30035.CSI': 'H30035.XSHG',
-    'h30068.CSI': 'H30068.XSHG',
-    'h30074.CSI': 'H30074.XSHG',
-    'h30079.CSI': 'H30079.XSHG',
-    'h30080.CSI': 'H30080.XSHG',
-    'h30081.CSI': 'H30081.XSHG',
-    'h30085.CSI': 'H30085.XSHG',
-    'h30100.CSI': 'H30100.XSHG',
-    'h30101.CSI': 'H30101.XSHG',
-    'h30102.CSI': 'H30102.XSHG',
-    'h30103.CSI': 'H30103.XSHG',
-    'h30104.CSI': 'H30104.XSHG',
-    'h30105.CSI': 'H30105.XSHG',
-    'h30106.CSI': 'H30106.XSHG',
-    'h30107.CSI': 'H30107.XSHG',
-    'h30109.CSI': 'H30109.XSHG',
-    'h30110.CSI': 'H30110.XSHG',
-    'h30111.CSI': 'H30111.XSHG',
-    'h30112.CSI': 'H30112.XSHG',
-    'h30113.CSI': 'H30113.XSHG',
-    'h30114.CSI': 'H30114.XSHG',
-    'h30115.CSI': 'H30115.XSHG',
-    'h30116.CSI': 'H30116.XSHG',
-    'h30117.CSI': 'H30117.XSHG',
-    'h30119.CSI': 'H30119.XSHG',
-    'h30131.CSI': 'H30131.XSHG',
-    'h30132.CSI': 'H30132.XSHG',
-    'h30169.CSI': 'H30169.XSHG',
-    'h30172.CSI': 'H30172.XSHG',
-    'h30176.CSI': 'H30176.XSHG',
-    'h30178.CSI': 'H30178.XSHG',
-    'h30188.CSI': 'H30188.XSHG',
-    'h30190.CSI': 'H30190.XSHG',
-    'h30202.CSI': 'H30202.XSHG',
-    'h30213.CSI': 'H30213.XSHG',
-    'h30256.CSI': 'H30256.XSHG',
-    'h30275.CSI': 'H30275.XSHG',
-    'h30276.CSI': 'H30276.XSHG',
-    'h30277.CSI': 'H30277.XSHG',
-    'h30334.CSI': 'H30334.XSHG',
-    'h30335.CSI': 'H30335.XSHG',
-    'h30336.CSI': 'H30336.XSHG',
-    'h30337.CSI': 'H30337.XSHG',
-    'h30338.CSI': 'H30338.XSHG',
-    'h30339.CSI': 'H30339.XSHG',
-    'h30340.CSI': 'H30340.XSHG',
-    'h30341.CSI': 'H30341.XSHG',
-    'h30342.CSI': 'H30342.XSHG',
-    'h30344.CSI': 'H30344.XSHG',
-    'h30350.CSI': 'H30350.XSHG',
-    'h30360.CSI': 'H30360.XSHG',
-    'h30361.CSI': 'H30361.XSHG',
-    'h30365.CSI': 'H30365.XSHG',
-    'h30366.CSI': 'H30366.XSHG',
-    'h30372.CSI': 'H30372.XSHG',
-    'h30401.CSI': 'H30401.XSHG',
-    'h30402.CSI': 'H30402.XSHG',
-    'h30456.CSI': 'H30456.XSHG',
-    'h30457.CSI': 'H30457.XSHG',
-    'h30458.CSI': 'H30458.XSHG',
-    'h30459.CSI': 'H30459.XSHG',
-    'h30460.CSI': 'H30460.XSHG',
-    'h30461.CSI': 'H30461.XSHG',
-    'h30462.CSI': 'H30462.XSHG',
-    'h30463.CSI': 'H30463.XSHG',
-    'h30464.CSI': 'H30464.XSHG',
-    'h30465.CSI': 'H30465.XSHG',
-    'h30466.CSI': 'H30466.XSHG',
-    'h30467.CSI': 'H30467.XSHG',
-    'h30468.CSI': 'H30468.XSHG',
-    'h30469.CSI': 'H30469.XSHG',
-    'h30470.CSI': 'H30470.XSHG',
-    'h30471.CSI': 'H30471.XSHG',
-    'h30472.CSI': 'H30472.XSHG',
-    'h30473.CSI': 'H30473.XSHG',
-    'h30474.CSI': 'H30474.XSHG',
-    'h30475.CSI': 'H30475.XSHG',
-    'h30476.CSI': 'H30476.XSHG',
-    'h30477.CSI': 'H30477.XSHG',
-    'h30478.CSI': 'H30478.XSHG',
-    'h30479.CSI': 'H30479.XSHG',
-    'h30480.CSI': 'H30480.XSHG',
-    'h30481.CSI': 'H30481.XSHG',
-    'h30482.CSI': 'H30482.XSHG',
-    'h30483.CSI': 'H30483.XSHG',
-    'h30484.CSI': 'H30484.XSHG',
-    'h30485.CSI': 'H30485.XSHG',
-    'h30486.CSI': 'H30486.XSHG',
-    'h30487.CSI': 'H30487.XSHG',
-    'h30488.CSI': 'H30488.XSHG',
-    'h30489.CSI': 'H30489.XSHG',
-    'h30490.CSI': 'H30490.XSHG',
-    'h30491.CSI': 'H30491.XSHG',
-    'h30492.CSI': 'H30492.XSHG',
-    'h30493.CSI': 'H30493.XSHG',
-    'h30494.CSI': 'H30494.XSHG',
-    'h30495.CSI': 'H30495.XSHG',
-    'h30496.CSI': 'H30496.XSHG',
-    'h30497.CSI': 'H30497.XSHG',
-    'h30498.CSI': 'H30498.XSHG',
-    'h30499.CSI': 'H30499.XSHG',
-    'h30500.CSI': 'H30500.XSHG',
-    'h30501.CSI': 'H30501.XSHG',
-    'h30502.CSI': 'H30502.XSHG',
-    'h30503.CSI': 'H30503.XSHG',
-    'h30504.CSI': 'H30504.XSHG',
-    'h30505.CSI': 'H30505.XSHG',
-    'h30506.CSI': 'H30506.XSHG',
-    'h30507.CSI': 'H30507.XSHG',
-    'h30508.CSI': 'H30508.XSHG',
-    'h30509.CSI': 'H30509.XSHG',
-    'h30510.CSI': 'H30510.XSHG',
-    'h30511.CSI': 'H30511.XSHG',
-    'h30512.CSI': 'H30512.XSHG',
-    'h30513.CSI': 'H30513.XSHG',
-    'h30514.CSI': 'H30514.XSHG',
-    'h30515.CSI': 'H30515.XSHG',
-    'h30516.CSI': 'H30516.XSHG',
-    'h30517.CSI': 'H30517.XSHG',
-    'h30518.CSI': 'H30518.XSHG',
-    'h30519.CSI': 'H30519.XSHG',
-    'h30520.CSI': 'H30520.XSHG',
-    'h30531.CSI': 'H30531.XSHG',
-    'h30532.CSI': 'H30532.XSHG',
-    'h30533.CSI': 'H30533.XSHG',
-    'h30534.CSI': 'H30534.XSHG',
-    'h30535.CSI': 'H30535.XSHG',
-    'h30537.CSI': 'H30537.XSHG',
-    'h30544.CSI': 'H30544.XSHG',
-    'h30545.CSI': 'H30545.XSHG',
-    'h30546.CSI': 'H30546.XSHG',
-    'h30547.CSI': 'H30547.XSHG',
-    'h30548.CSI': 'H30548.XSHG',
-    'h30550.CSI': 'H30550.XSHG',
-    'h30551.CSI': 'H30551.XSHG',
-    'h30552.CSI': 'H30552.XSHG',
-    'h30554.CSI': 'H30554.XSHG',
-    'h30555.CSI': 'H30555.XSHG',
-    'h30556.CSI': 'H30556.XSHG',
-    'h30557.CSI': 'H30557.XSHG',
-    'h30558.CSI': 'H30558.XSHG',
-    'h30559.CSI': 'H30559.XSHG',
-    'h30560.CSI': 'H30560.XSHG',
-    'h30561.CSI': 'H30561.XSHG',
-    'h30562.CSI': 'H30562.XSHG',
-    'h30563.CSI': 'H30563.XSHG',
-    'h30564.CSI': 'H30564.XSHG',
-    'h30565.CSI': 'H30565.XSHG',
-    'h30566.CSI': 'H30566.XSHG',
-    'h30567.CSI': 'H30567.XSHG',
-    'h30568.CSI': 'H30568.XSHG',
-    'h30569.CSI': 'H30569.XSHG',
-    'h30570.CSI': 'H30570.XSHG',
-    'h30572.CSI': 'H30572.XSHG',
-    'h30573.CSI': 'H30573.XSHG',
-    'h30574.CSI': 'H30574.XSHG',
-    'h30576.CSI': 'H30576.XSHG',
-    'h30577.CSI': 'H30577.XSHG',
-    'h30578.CSI': 'H30578.XSHG',
-    'h30579.CSI': 'H30579.XSHG',
-    'h30580.CSI': 'H30580.XSHG',
-    'h30581.CSI': 'H30581.XSHG',
-    'h30582.CSI': 'H30582.XSHG',
-    'h30583.CSI': 'H30583.XSHG',
-    'h30584.CSI': 'H30584.XSHG',
-    'h30585.CSI': 'H30585.XSHG',
-    'h30586.CSI': 'H30586.XSHG',
-    'h30587.CSI': 'H30587.XSHG',
-    'h30588.CSI': 'H30588.XSHG',
-    'h30590.CSI': 'H30590.XSHG',
-    'h30597.CSI': 'H30597.XSHG',
-    'h50036.CSI': 'H50036.XSHG',
-    'h50043.CSI': 'H50043.XSHG',
-    'h50044.CSI': 'H50044.XSHG',
-    'h50053.CSI': 'H50053.XSHG',
-    'h50054.CSI': 'H50054.XSHG',
-    'h50055.CSI': 'H50055.XSHG',
-    'h50056.CSI': 'H50056.XSHG',
-    'h50059.CSI': 'H50059.XSHG',
-    'h50060.CSI': 'H50060.XSHG',
-    'h50066.CSI': 'H50066.XSHG',
-    'h50069.CSI': 'H50069.XSHG',
-    'h00801.CSI': 'H00801.INDX',
-    'h00802.CSI': 'H00802.INDX',
-    'h00805.CSI': 'H00805.INDX',
-    'h00806.CSI': 'H00806.INDX',
-    'h00827.CSI': 'H00827.INDX',
-    'h00838.CSI': 'H00838.INDX',
-    'h00941.CSI': 'H00941.INDX',
-    'h00950.CSI': 'H00950.INDX',
-    'h00961.CSI': 'H00961.INDX',
-    'h00962.CSI': 'H00962.INDX',
-    'h00963.CSI': 'H00963.INDX',
-    'h00964.CSI': 'H00964.INDX',
-    'h00968.CSI': 'H00968.INDX',
-    'h00969.CSI': 'H00969.INDX',
-    'h00970.CSI': 'H00970.INDX',
-    'h00972.CSI': 'H00972.INDX',
-    'h00977.CSI': 'H00977.INDX',
-    'h00978.CSI': 'H00978.INDX',
-    'h00979.CSI': 'H00979.INDX',
-    'h00998.CSI': 'H00998.INDX',
-    'h20007.CSI': 'H20007.INDX',
-    'h20033.CSI': 'H20033.INDX',
-    'h20035.CSI': 'H20035.INDX',
-    'h20068.CSI': 'H20068.INDX',
-    'h20073.CSI': 'H20073.INDX',
-    'h20074.CSI': 'H20074.INDX',
-    'h20079.CSI': 'H20079.INDX',
-    'h20080.CSI': 'H20080.INDX',
-    'h20081.CSI': 'H20081.INDX',
-    'h20089.CSI': 'H20089.INDX',
-    'h30230.CSI': 'H30230.XSHG',
-    'h30231.CSI': 'H30231.XSHG',
-    'h30232.CSI': 'H30232.XSHG',
-    'h30233.CSI': 'H30233.XSHG',
-    'h30234.CSI': 'H30234.XSHG',
-    'h30235.CSI': 'H30235.XSHG',
-    'h30236.CSI': 'H30236.XSHG',
-    'h30237.CSI': 'H30237.XSHG',
-    'h30240.CSI': 'H30240.XSHG',
-    'h30241.CSI': 'H30241.XSHG',
-    'h30242.CSI': 'H30242.XSHG',
-    'h30243.CSI': 'H30243.XSHG',
-    'h30244.CSI': 'H30244.XSHG',
-    'h30245.CSI': 'H30245.XSHG',
-    'h30246.CSI': 'H30246.XSHG',
-    'h30247.CSI': 'H30247.XSHG',
-    'h11172.CSI': 'H11172.XSHG',
-    'h11173.CSI': 'H11173.XSHG',
-    'h11174.CSI': 'H11174.XSHG',
-    'h11175.CSI': 'H11175.XSHG',
-    'h11176.CSI': 'H11176.XSHG',
-    'h11177.CSI': 'H11177.XSHG',
-    'h11178.CSI': 'H11178.XSHG',
-    'h11179.CSI': 'H11179.XSHG',
-    'h01172.CSI': 'H01172.INDX',
-    'h01173.CSI': 'H01173.INDX',
-    'h01174.CSI': 'H01174.INDX',
-    'h01175.CSI': 'H01175.INDX',
-    'h01176.CSI': 'H01176.INDX',
-    'h01177.CSI': 'H01177.INDX',
-    'h01178.CSI': 'H01178.INDX',
-    'h01179.CSI': 'H01179.INDX',
-    'h20100.CSI': 'H20100.INDX',
-    'h20101.CSI': 'H20101.INDX',
-    'h20102.CSI': 'H20102.INDX',
-    'h20103.CSI': 'H20103.INDX',
-    'h20104.CSI': 'H20104.INDX',
-    'h20105.CSI': 'H20105.INDX',
-    'h20106.CSI': 'H20106.INDX',
-    'h20107.CSI': 'H20107.INDX',
-    'h20109.CSI': 'H20109.INDX',
-    'h20110.CSI': 'H20110.INDX',
-    'h20111.CSI': 'H20111.INDX',
-    'h20112.CSI': 'H20112.INDX',
-    'h20113.CSI': 'H20113.INDX',
-    'h20114.CSI': 'H20114.INDX',
-    'h20115.CSI': 'H20115.INDX',
-    'h20116.CSI': 'H20116.INDX',
-    'h20117.CSI': 'H20117.INDX',
-    'h20119.CSI': 'H20119.INDX',
-    'h01142.CSI': 'H01142.INDX',
-    'h01143.CSI': 'H01143.INDX',
-    'h01144.CSI': 'H01144.INDX',
-    'h01145.CSI': 'H01145.INDX',
-    'h01146.CSI': 'H01146.INDX',
-    'h01147.CSI': 'H01147.INDX',
-    'h01148.CSI': 'H01148.INDX',
-    'h01149.CSI': 'H01149.INDX',
-    'h01150.CSI': 'H01150.INDX',
-    'h01151.CSI': 'H01151.INDX',
-    'h01102.CSI': 'H01102.INDX',
-    'h01103.CSI': 'H01103.INDX',
-    'h01104.CSI': 'H01104.INDX',
-    'h01105.CSI': 'H01105.INDX',
-    'h01106.CSI': 'H01106.INDX',
-    'h01112.CSI': 'H01112.INDX',
-    'h01114.CSI': 'H01114.INDX',
-    'h01115.CSI': 'H01115.INDX',
-    'h01116.CSI': 'H01116.INDX',
-    'h01138.CS': 'H01138.INDX',
-    'h11101.CSI': 'H11101.XSHG',
-    'h11108.CSI': 'H11108.XSHG',
-    'h11118.CSI': 'H11118.XSHG',
-    'h11128.CSI': 'H11128.XSHG',
-    'h11138.CSI': 'H11138.XSHG',
-    'h11164.CSI': 'H11164.XSHG',
-    'h11165.CSI': 'H11165.XSHG',
-    'h11168.CSI': 'H11168.XSHG',
-    'h11169.CSI': 'H11169.XSHG',
-    'h01108.CSI': 'H01108.INDX',
-    'h01118.CSI': 'H01118.INDX',
-    'h01120.CSI': 'H01120.INDX',
-    'h01123.CSI': 'H01123.INDX',
-    'h01124.CSI': 'H01124.INDX',
-    'h01125.CSI': 'H01125.INDX',
-    'h01126.CSI': 'H01126.INDX',
-    'h01128.CSI': 'H01128.INDX',
-    'h01164.CSI': 'H01164.INDX',
-    'h01165.CSI': 'H01165.INDX',
-    'h01166.CSI': 'H01166.INDX',
-    'h01167.CSI': 'H01167.INDX',
-    'h01168.CSI': 'H01168.INDX',
-    'h01169.CSI': 'H01169.INDX',
-    'h01110.CSI': 'H01110.INDX',
-    'h01111.CSI': 'H01111.INDX',
-    'h11156.CSI': 'H11156.XSHG',
-    'h11157.CSI': 'H11157.XSHG',
-    'h11158.CSI': 'H11158.XSHG',
-    'h11159.CSI': 'H11159.XSHG',
-    'h01134.CSI': 'H01134.INDX',
-    'h01135.CSI': 'H01135.INDX',
-    'h01136.CSI': 'H01136.INDX',
-    'h01137.CSI': 'H01137.INDX',
-    'h01140.CSI': 'H01140.INDX',
-    'h01141.CSI': 'H01141.INDX',
-    'h01152.CSI': 'H01152.INDX',
-    'h01153.CSI': 'H01153.INDX',
-    'h01154.CSI': 'H01154.INDX',
-    'h01155.CSI': 'H01155.INDX',
-    'h01156.CSI': 'H01156.INDX',
-    'h01157.CSI': 'H01157.INDX',
-    'h01158.CSI': 'H01158.INDX',
-    'h01159.CSI': 'H01159.INDX',
-    'h01160.CSI': 'H01160.INDX',
-    'h01161.CSI': 'H01161.INDX',
-    'h01162.CSI': 'H01162.INDX',
-    'h01163.CSI': 'H01163.INDX',
-    'h20131.CSI': 'H20131.INDX',
-    'h20132.CSI': 'H20132.INDX',
-    'h11134.CSI': 'H11134.XSHG',
-    'h11135.CSI': 'H11135.XSHG',
-    'h01181.CSI': 'H01181.INDX',
-    'h01182.CSI': 'H01182.INDX',
-    'h01183.CSI': 'H01183.INDX',
-    'h01184.CSI': 'H01184.INDX',
-    'h20133.CSI': 'H20133.INDX',
-    'h20134.CSI': 'H20134.INDX',
-    'h20135.CSI': 'H20135.INDX',
-    'h20136.CSI': 'H20136.INDX',
-    'h11181.CSI': 'H11181.XSHG',
-    'h11182.CSI': 'H11182.XSHG',
-    'h30133.CSI': 'H30133.XSHG',
-    'h30134.CSI': 'H30134.XSHG',
-    'h30135.CSI': 'H30135.XSHG',
-    'h30136.CSI': 'H30136.XSHG',
-    'h11020.CSI': 'H11020.XSHG',
-    'h11021.CSI': 'H11021.XSHG',
-    'h11022.CSI': 'H11022.XSHG',
-    'h11023.CSI': 'H11023.XSHG',
-    'h11024.CSI': 'H11024.XSHG',
-    'h11025.CSI': 'H11025.XSHG',
-    'h11026.CSI': 'H11026.XSHG',
-    'h11027.CSI': 'H11027.XSHG',
-    'h11028.CSI': 'H11028.XSHG',
-    'h20267.CSI': 'H20267.INDX',
-    'h20268.CSI': 'H20268.INDX',
-    'h30267.CSI': 'H30267.XSHG',
-    'h30268.CSI': 'H30268.XSHG',
-    '921374.CSI': '921374.INDX',
-    '921496.CSI': '921496.INDX',
-    '921496HKD.CSI': '921496HKD.INDX',
-    'h11001.CSI': 'H11001.XSHG',
-    'h11002.CSI': 'H11002.XSHG',
-    'h11003.CSI': 'H11003.XSHG',
-    'h11004.CSI': 'H11004.XSHG',
-    'h11005.CSI': 'H11005.XSHG',
-    'h11009.CSI': 'H11009.XSHG',
-    'h11010.CSI': 'H11010.XSHG',
-    'h11015.CSI': 'H11015.XSHG',
-    'h11016.CSI': 'H11016.XSHG',
-    'h11076.CSI': 'H11076.XSHG',
-    '930871.CSI': '930871.INDX',
-    '930872.CSI': '930872.INDX',
-    '930873.CSI': '930873.INDX',
-    '930874.CSI': '930874.INDX',
-    'h11006.CSI': 'H11006.XSHG',
-    'h11017.CSI': 'H11017.XSHG',
-    'h11071.CSI': 'H11071.XSHG',
-    'h11075.CSI': 'H11075.XSHG',
-    'h11099.CSI': 'H11099.XSHG',
-    '000833.CSI': '000833.XSHG',
-    '000845.CSI': '000845.XSHG',
-    '930780.CSI': '930780.INDX',
-    'h11007.CSI': 'H11007.XSHG',
-    'h11008.CSI': 'H11008.XSHG',
-    'h11014.CSI': 'H11014.XSHG',
-    'h11018.CSI': 'H11018.XSHG',
-    'h11019.CSI': 'H11019.XSHG',
-    'h11070.CSI': 'H11070.XSHG',
-    'h11072.CSI': 'H11072.XSHG',
-    'h11073.CSI': 'H11073.XSHG',
-    'h11074.CSI': 'H11074.XSHG',
-    'h11078.CSI': 'H11078.XSHG',
-    'h11079.CSI': 'H11079.XSHG',
-    'h11087.CSI': 'H11087.XSHG',
-    'h11088.CSI': 'H11088.XSHG',
-    'h11089.CSI': 'H11089.XSHG',
-    'h11090.CSI': 'H11090.XSHG',
-    'h11091.CSI': 'H11091.XSHG',
-    'h11092.CSI': 'H11092.XSHG',
-    'h11093.CSI': 'H11093.XSHG',
-    'h11094.CSI': 'H11094.XSHG',
-    'h11096.CSI': 'H11096.XSHG',
-    'h11097.CSI': 'H11097.XSHG',
-    'h11185.CSI': 'H11185.XSHG',
-    'h30396.CSI': 'H30396.XSHG',
-    'h30521.CSI': 'H30521.XSHG',
-    '000832.CSI': '000832.XSHG',
-    '000923.CSI': '000923.XSHG',
-    '930849.CSI': '930849.INDX',
-    '930865.CSI': '930865.INDX',
-    '930866.CSI': '930866.INDX',
-    '930916.CSI': '930916.INDX',
-    '930954.CSI': '930954.INDX',
-    '931018.CSI': '931018.INDX',
-    '931078.CSI': '931078.INDX',
-    '931162.CSI': '931162.INDX',
-    '931172.CSI': '931172.INDX',
-    '931175.CSI': '931175.INDX',
-    '950045.CSI': '950045.INDX',
-}
-
-
-_to_wind_index_map = {j: i for i, j in _wind_index_map.items()}
-
-
-@ttl_cache(8 * 3600)
-def _all_futures():
-    # cache futures
-    df = all_instruments('Future')
-    r = {i.upper(): i for i in df['order_book_id'].tolist()}
-    s = df.set_index('order_book_id')['trading_code']
-    s = s[~s.index.str.endswith(('88', '99', '888', '889', '88A2', '88A3'))]
-    s = s.sort_index().drop_duplicates(keep='last').str.upper()
-    r.update({v: k for k, v in s.items()})
-    # cache commodity options
-    df = all_instruments('Option')
-    df = df[~df.exchange.isin(('XSHG', 'XSHE'))]
-    r.update({i.upper(): i for i in df['order_book_id'].tolist()})
-    s = df.set_index('order_book_id')['trading_code']
-    s = s.sort_index().drop_duplicates(keep='last').str.upper()
-    r.update({v: k for k, v in s.items()})
-    return r
-
-
-def _convert_to_wind(order_book_id):
-    if order_book_id.endswith(".XSHE"):
-        return order_book_id[:-4] + "SZ"
-    elif order_book_id.endswith(".XSHG"):
-        return order_book_id[:-4] + "SH"
-    elif order_book_id.endswith(".XHKG"):
-        return order_book_id[:-4] + "HK"
-
-    inst = instruments(order_book_id)
-    inst_type, exchange = inst.type, inst.exchange
-    if inst_type == 'Future':
-        if exchange != 'CZCE' or order_book_id.endswith(('88', '99', '888', '889')):
-            return order_book_id + '.' + _wind_exchange_map[exchange]
-        return order_book_id[:-4] + order_book_id[-3:] + '.CZC'
-    if inst_type == 'Spot':
-        return order_book_id[:-1]
-    if inst_type == 'Option':
-        if exchange == 'XSHE':
-            return order_book_id + '.SZ'
-        if exchange == 'XSHG':
-            return order_book_id + '.SH'
-        return inst.trading_code.upper() + '.' + _wind_exchange_map[exchange]
-
-    if inst_type == 'INDX':
-        if order_book_id[0] == 'C':
-            return order_book_id[:-4] + 'WI'
-        if order_book_id[0] == '8':
-            return order_book_id[:-4] + 'SI'
-        if order_book_id in _to_wind_index_map:
-            return _to_wind_index_map[order_book_id]
-        if exchange == 'XSHE':
-            return order_book_id[:-4].lower() + 'SZ'
-        return order_book_id[:-4].lower() + 'SH'
-    return order_book_id
-
-
-_wind_reg = re.compile(r'((?P<future>[A-Z]+\d{3,4})|((?P<option_id>((\d{8})|((?P<option>[A-Z]{1,2})(?P<option_suffix>\d{3,4}\-?(P|C)\-?\d{3,}))))))\.?(?P<ex>(CFE|SHF|INE|DCE|CZC|SH|SZ))')
-_future_re = re.compile(r'^([A-Z]+\d+([PC]\w+)?)')
-_current_year = str((datetime.date.today().year % 100) // 10)
-
-
-def _id_convert_one(order_book_id):  # noqa: C901
-    # hard code
-    if order_book_id in {"T00018", "T00018.SH", "T00018.XSHG", "SH.T00018"}:
-        return "990018.XSHG"
-    if order_book_id.endswith(".XHKG"):
-        return order_book_id
-    inst = instruments(order_book_id)
-    if inst is not None:
-        return inst.order_book_id
-
-    # WIND Future & Option
-    r = _wind_reg.match(order_book_id)
-    if r:
-        d = r.groupdict()
-        if d['future']:
-            return _all_futures().get(d['future'].upper(), d['future'])
-        if not d['option']:
-            return d['option_id']
-
-        if d['ex'] != 'CZC':
-            return r['option_id'].replace('-', '')
-        return d['option'] + _current_year + d['option_suffix'].replace('-', '')
-
-    # WIND ZZ INDX
-    if order_book_id in _wind_index_map:
-        return _wind_index_map[order_book_id]
-
-    # WIND SH INDX
-    if order_book_id[-3:] == '.SH':
-        if order_book_id[:2] in ('h0', 'h4'):
-            return order_book_id[:-2].upper() + 'INDX'
-
-    # WIND SW, ZX INDEX
-    if (order_book_id[-3:] == '.WI' and order_book_id[0] == 'C') or (
-            order_book_id[0] == '8' and order_book_id[-3:] == '.SI'):
-        return order_book_id[:-2] + 'INDX'
-
-    # WIND Spot
-    if order_book_id[-4:] == '.SGE':
-        return order_book_id + 'X'
-
-    if order_book_id.isdigit():
-        if order_book_id.startswith(("0", "3", "15")):
-            return order_book_id + ".XSHE"
-        elif order_book_id.startswith(("5", "6", "9")):
-            return order_book_id + ".XSHG"
-        else:
-            raise ValueError("order_book_ids should be str like 000001, 600000")
-
-    order_book_id = order_book_id.upper()
-    if order_book_id.endswith(".XSHG") or order_book_id.endswith(".XSHE"):
-        return order_book_id
-
-    if order_book_id.startswith(("SZ", "SH")):
-        suffix = order_book_id.replace(".", "")[2:]
-        prefix = order_book_id[:2]   # it's SZ or SH
-        # maybe CS order_book_id
-        if len(suffix) == 6 and suffix.isdigit():
-            return suffix + (".XSHG" if prefix == "SH" else ".XSHE")
-    elif order_book_id.endswith("SZ"):
-        return order_book_id.replace(".", "")[:-2] + ".XSHE"
-    elif order_book_id.endswith("SH"):
-        return order_book_id.replace(".", "")[:-2] + ".XSHG"
-
-    # 期货 & 商品期权
-    order_book_id = order_book_id.replace('-', '').split(".")[0]
-    m = _future_re.match(order_book_id)
-    if m:
-        i = m.groups()[0]
-        return _all_futures().get(i, order_book_id)
-
-    raise ValueError("unknown order_book_id: {}".format(order_book_id))
-
-
-@export_as_api
-@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
-def id_convert(order_book_ids, to=None):
-    """合约格式转换
-
-    :param order_book_ids: str 或 str list, 如'000001', 'SZ000001', '000001SZ',
-        '000001.SZ', 纯数字str默认为股票类型
-    :param to: str, 转换为指定类型目标代码，默认为米筐代码， 其他: normal， ricequant
-    :returns: str 或 str list, 米筐格式的合约
-
-    """
-    if to == 'normal' or to == 'wind':
-        _convert_one = lambda o: _convert_to_wind(_id_convert_one(o))
-    elif to is None or to == 'ricequant':
-        _convert_one = _id_convert_one
-    else:
-        raise ValueError('Unsupported destination: {}'.format(to))
-    with warnings.catch_warnings():
-        warnings.simplefilter("ignore")
-        if isinstance(order_book_ids, six.string_types):
-            return _convert_one(order_book_ids)
-        elif isinstance(order_book_ids, list):
-            return [_convert_one(o) for o in order_book_ids]
-        else:
-            raise ValueError("order_book_ids should be str or list")
-
-
-def _id_compatible(order_book_id):
-    if order_book_id.endswith("XSHE"):
-        return order_book_id[:-4] + "SZ"
-    elif order_book_id.endswith("XSHG"):
-        return order_book_id[:-4] + "SH"
-    else:
-        return order_book_id
-
-
-def _all_instruments_list(type_, market):
-    ins = [
-        Instrument(i)
-        for i in get_client().execute(
-            "all_instruments_by_type", instrument_type=type_, market=market
-        )
-    ]
-    ins.sort(key=lambda i: i.order_book_id)
-
-    extra_hk_instruments = []
-    if market == 'hk':  # 对港股需要根据 stock_connect 字段做拆分并替换该字段
-        suffix_map = {'sz': 'XSEC', 'sh': 'XSSC'}
-        for i in ins:
-            if not i.stock_connect:  # 港股中 stcok_connect 字段为空则设置该字段为 ''
-                setattr(i, 'stock_connect', '')
-                continue
-            for stock_connect in i.stock_connect:
-                _temp_instruments = deepcopy(i)
-                _temp_instruments.unique_id = _temp_instruments.unique_id[:-4] + suffix_map.get(stock_connect)
-                _temp_instruments.stock_connect = stock_connect + '_connect'
-                extra_hk_instruments.append(_temp_instruments)
-            i.stock_connect = i.stock_connect[0] if len(i.stock_connect) == 1 else '_and_'.join(i.stock_connect)
-
-    ins += extra_hk_instruments
-    return ins
-
-
-@ttl_cache(3 * 3600)
-def _all_cached_instruments_list(type_, market):
-    return _all_instruments_list(type_, market)
-
-
-@ttl_cache(3 * 3600)
-def _all_obid_to_type(market):
-    simple_insts = get_client().execute("all_obid_type_list", market)
-    result = {}
-    for inst in simple_insts:
-        # 统一一下值的类型, 后面使用起来简单点
-        result[inst["order_book_id"]] = (inst["type"], inst["order_book_id"])
-        result[inst["symbol"]] = (inst["type"], inst["order_book_id"])
-    return result
-
-
-@ttl_cache(3 * 3600)
-def _all_instruments_dict(type_, market):
-    ins = _all_cached_instruments_list(type_, market)
-    result = dict()
-    for i in ins:
-        if i.type == "Convertible":
-            result[_id_compatible(i.order_book_id)] = i
-
-        if getattr(i, "unique_id", None):  # 对港股 unique_id 作为 key 添加到 result dict
-            result[i.unique_id] = i
-
-        if i.order_book_id in result:  # 对港股存在退市后 order_book_id 复用的情况只存上市日期最晚的信息
-            if i.listed_date > result[i.order_book_id].listed_date:
-                result[i.order_book_id] = i
-        else:
-            result[i.order_book_id] = i
-
-    try:
-        result["沪深300"] = result["000300.XSHG"]
-        result["中证500"] = result["000905.XSHG"]
-        result[result["SSE180.INDX"].symbol] = result["000010.XSHG"]
-    except KeyError:
-        pass
-
-    return result
-
-
-def get_underlying_listed_date(underlying_symbol, ins_type, market="cn"):
-    """ 获取期货或者期权的某个品种的上市日期"""
-    ins_list = _all_cached_instruments_list(ins_type, market)
-    listed_dates = [i.listed_date for i in ins_list
-                    if (getattr(i, "underlying_symbol", "") == underlying_symbol
-                        and i.type == ins_type and i.listed_date != "0000-00-00")]
-
-    return min(listed_dates)
-
-
-def get_tick_size(order_book_id, market="cn"):
-    """获取合约价格最小变动单位
-
-    :param order_book_id: 如: FU1703
-    :param market: 如：'cn' (Default value = "cn")
-    :returns: float
-
-    """
-    return get_client().execute("get_tick_size", order_book_id, market=market)
-
-
-HK_STOCK_PRICE_SECTIONS = [0.25, 0.5, 10, 20, 100, 200, 500, 1000, 2000, 5000]
-HK_STOCK_TICK_SIZES = [0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 2, 5]
-
-
-# noinspection All
-class Instrument(object):
-    def __init__(self, d):
-        self.__dict__ = d
-
-    def __repr__(self):
-        if self.has_citics_info() and not hasattr(self, "_citics_industry_code"):
-            self.citics_industry()
-
-        return "{}({})".format(
-            type(self).__name__,
-            ", ".join(
-                [
-                    "{}={!r}".format(k.lstrip("_"), v)
-                    for k, v in self.__dict__.items()
-                    if v is not None
-                ]
-            ),
-        )
-
-    @property
-    def concept_names(self):
-        return get_concept_names(self.order_book_id)
-
-    def days_from_listed(self, date=None):
-        if self.listed_date == "0000-00-00":
-            return -1
-
-        date = to_date(date) if date else datetime.date.today()
-        if self.de_listed_date != "0000-00-00" and date > to_date(self.de_listed_date):
-            # 晚于退市日期
-            return -1
-
-        listed_date = to_date(self.listed_date)
-        ipo_days = (date - listed_date).days
-        return ipo_days if ipo_days >= 0 else -1
-
-    def days_to_expire(self, date=None):
-        if getattr(self, 'maturity_date', '0000-00-00') == '0000-00-00':
-            return -1
-
-        date = to_date(date) if date else datetime.date.today()
-
-        maturity_date = to_date(self.maturity_date)
-        days = (maturity_date - date).days
-        return days if days >= 0 else -1
-
-    def tick_size(self, price=None):
-        if self.exchange == "XHKG":
-            check_type(price, (int, float), "price")
-            index = bisect.bisect_left(HK_STOCK_PRICE_SECTIONS, price)
-            return HK_STOCK_TICK_SIZES[index]
-        elif self.type in ["CS", "INDX"]:
-            return 0.01
-        elif self.type in ["ETF", "LOF", "FUND", "FenjiB", "FenjiA", "FenjiMu", "PublicFund"]:
-            return 0.001
-        elif self.type == "Convertible":
-            return 0.001
-        elif self.type not in ["Future", "Option", "Spot"]:
-            return -1
-        return get_tick_size(self.order_book_id)
-
-    def has_citics_info(self):
-        return self.type == "CS" and self.exchange in {"XSHE", "XSHG"}
-
-    def citics_industry(self, date=None):
-        if self.has_citics_info():
-            if date is None:
-                if hasattr(self, "_citics_industry_code"):
-                    return (self._citics_industry_code, self._citics_industry_name)
-
-            if self.de_listed_date != '0000-00-00':
-                date = get_previous_trading_date(self.de_listed_date)
-
-            result = get_instrument_industry(self.order_book_id, date=date, level=1, source='citics_2019')
-            if result is None:
-                self._citics_industry_code, self._citics_industry_name = (None, None)
-                return None
-
-            self._citics_industry_code = result['first_industry_code'][0]
-            self._citics_industry_name = result['first_industry_name'][0]
-
-            return {"code": result.iloc[0, 0], "name": result.iloc[0, 1]}
-
-    @property
-    def citics_industry_code(self):
-        if not self.has_citics_info():
-            return None
-
-        if not hasattr(self, "_citics_industry_code"):
-            self.citics_industry()
-        return self._citics_industry_code
-
-    @property
-    def citics_industry_name(self):
-        if not self.has_citics_info():
-            return None
-
-        if not hasattr(self, "_citics_industry_name"):
-            self.citics_industry()
-        return self._citics_industry_name
-
-
-def _get_instrument(type_, order_book_id, market="cn"):
-    all_dict = _all_instruments_dict(type_, market)
-    return all_dict[order_book_id]
-
-
-@export_as_api
-@compatible_with_parm(name="country", value="cn", replace="market")
-@rqdatah_serialize(converter=http_conv_instruments)
-def instruments(order_book_ids, market="cn"):
-    """获取证券详细信息
-
-    :param order_book_ids: 证券ID列表, 如'000001.XSHE', 'AAPL.US'. 注意, 所有列表中的证券需要属于同一个国家。
-    :param market: 证券所属国家, 如 cn, us, hk (Default value = "cn")
-    :returns: 对应证券的列表
-
-    """
-    obid_to_type = _all_obid_to_type(market)
-    if isinstance(order_book_ids, six.string_types):
-        if order_book_ids not in obid_to_type:
-            warnings.warn('unknown order_book_id: {}'.format(order_book_ids))
-            return
-        ob_type, ob = obid_to_type[order_book_ids]
-        return _get_instrument(ob_type, ob, market)
-    result = []
-    for ob in order_book_ids:
-        if ob not in obid_to_type:
-            continue
-        ob_type, ob = obid_to_type[ob]
-        result.append(_get_instrument(ob_type, ob, market))
-    return result
-
-
-VALID_TYPES = {"CS", "ETF", "LOF", "INDX", "Future", "Spot", "Option", "Convertible", "Repo", "FUND"}
-
-
-@export_as_api
-@compatible_with_parm(name="country", value="cn", replace="market")
-def all_instruments(type=None, date=None, market="cn", **kwargs):
-    """获得某个国家的全部证券信息
-
-    :param type:  (Default value = None)
-    :param date:  (Default value = None)
-    :param market: cn, hk (Default value = "cn")
-    :kwargs
-        trading_market: [hk, all] (Default value = "hk")
-            hk: 港交所可购买的股票。对应返回stock_connect = null、sh、sz 的记录
-            all: 包括港交所、上交所、深交所可购买的港股。（对沪深港通支持股票均展示一条独立的unique_id捆绑的信息）,对应返回全部列表，即stock_connect = null、sz_and_sh、sh、sz、sz_connect、sh_connect
-    """
-
-    if type is not None:
-        type = ensure_list_of_string(type)
-        itype = set()
-        for t in type:
-            if t.upper() == "STOCK":
-                itype.add("CS")
-            elif t.upper() == "FUND":
-                itype = itype.union({"ETF", "LOF", "FUND"})
-            elif t.upper() == "INDEX":
-                itype.add("INDX")
-            elif t not in VALID_TYPES:
-                raise ValueError("invalid type: {}, chose any in {}".format(type, VALID_TYPES))
-            else:
-                itype.add(t)
-    else:
-        itype = VALID_TYPES
-
-    if date:
-        date = ensure_date_str(date)
-        cond = lambda x: (  # noqa: E731
-                (itype is None or x.type in itype)
-                and (x.listed_date <= date or x.listed_date == "0000-00-00")
-                and (
-                        x.de_listed_date == "0000-00-00"
-                        or (
-                                x.de_listed_date >= date
-                                and x.type in ("Future", "Option")
-                                or (x.de_listed_date > date and x.type not in ("Future", "Option"))
-                        )
-                )
-        )
-    else:
-        cond = lambda x: itype is None or x.type in itype  # noqa: E731
-
-    cached = kwargs.pop("cached", True)
-    trading_market = kwargs.pop("trading_market", 'hk')
-    if kwargs:
-        raise ValueError("Unknown kwargs: {}".format(kwargs))
-
-    if cached:
-        get_instrument_list = _all_cached_instruments_list
-    else:
-        get_instrument_list = _all_instruments_list
-
-    ins_ret = []
-    for t in itype:
-        ins_ret.extend(filter(cond, get_instrument_list(t, market)))
-
-    if market == 'hk' and trading_market == 'hk':
-        ins_ret = filter(lambda x: x.unique_id.endswith('.XHKG'), ins_ret)
-
-    if itype is not None and len(itype) == 1:
-        df = pd.DataFrame([v.__dict__ for v in ins_ret])
-        internal_fields = [f for f in df.columns if f.startswith('_')]
-        for f in internal_fields:
-            del df[f]
-    else:
-        df = pd.DataFrame(
-            [
-                (
-                    v.order_book_id,
-                    v.symbol,
-                    getattr(v, "abbrev_symbol", None),
-                    v.type,
-                    v.listed_date,
-                    v.de_listed_date,
-                )
-                for v in ins_ret
-            ],
-            columns=[
-                "order_book_id",
-                "symbol",
-                "abbrev_symbol",
-                "type",
-                "listed_date",
-                "de_listed_date",
-            ],
-        )
-    return df
-
-
-def to_sector_name(s):
-    for _, v in SectorCode.__dict__.items():
-        if isinstance(v, SectorCodeItem):
-            if v.cn == s or v.en == s or v.name == s:
-                return v.name
-    return s
-
-
-@export_as_api
-@compatible_with_parm(name="country", value="cn", replace="market")
-@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
-def sector(code, market="cn"):
-    """获取某个板块的股票列表。目前支持的板块分类具体可以查询以下网址:
-    https://www.ricequant.com/api/research/chn#research-API-sector
-
-    :param code: 可以使用板块英文名字如'Energy', 或者 sector_code.Energy
-    :param market: 地区代码, 如'cn' (Default value = "cn")
-    :returns: 板块全部股票列表
-
-    """
-    check_type(code, (SectorCodeItem, six.string_types), "code")
-    if isinstance(code, SectorCodeItem):
-        code = code.name
-    else:
-        code = to_sector_name(code)
-    return [
-        v.order_book_id
-        for v in _all_cached_instruments_list("CS", market)
-        if v.sector_code == code
-    ]
-
-
-def to_industry_code(s):
-    for _, v in IndustryCode.__dict__.items():
-        if isinstance(v, IndustryCodeItem):
-            if v.name == s:
-                return v.code
-    return s
-
-
-@export_as_api
-@compatible_with_parm(name="country", value="cn", replace="market")
-@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
-def industry(code, market="cn"):
-    """获取某个行业的股票列表。目前支持的行业列表具体可以查询以下网址:
-    https://www.ricequant.com/api/research/chn#research-API-industry
-
-    :param code: 行业代码,如 A01, 或者 industry_code.A01
-    :param market: 地区代码, 如'cn' (Default value = "cn")
-    :returns: 行业全部股票列表
-
-    """
-    if not isinstance(code, six.string_types):
-        code = code.code
-    else:
-        code = to_industry_code(code)
-    return [
-        v.order_book_id
-        for v in _all_cached_instruments_list("CS", market)
-        if v.industry_code == code
-    ]
-
-
-@export_as_api
-@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
-def get_future_contracts(underlying_symbol, date=None, market="cn"):
-    import rqdatac
-    import warnings
-
-    msg = "'get_future_contracts' is deprecated, please use 'futures.get_contracts' instead"
-    warnings.warn(msg, category=DeprecationWarning, stacklevel=2)
-    return rqdatac.futures.get_contracts(underlying_symbol, date, market)
-
-
-@export_as_api(namespace='futures')
-@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
-def get_contracts(underlying_symbol, date=None, market="cn"):
-    """获得中国市场某个时间某个期货品种正在交易的合约列表
-
-    :param underlying_symbol: 期货品种
-    :param date: 日期，可以为str，datetime，date，pd.Timestamp 等类型
-    :param market:  (Default value = "cn")
-    :returns: list of order book id
-
-    """
-    if date is None:
-        date = datetime.date.today()
-    date = ensure_date_str(date)
-
-    return sorted(
-        v.order_book_id
-        for v in _all_cached_instruments_list("Future", market)
-        if v.underlying_symbol == underlying_symbol
-        and v.listed_date != "0000-00-00"
-        and v.listed_date <= date <= v.de_listed_date
-    )
-
-
-@export_as_api
-def jy_instrument_industry(order_book_ids, date=None, level=1, expect_df=True, market="cn"):
-    """获取股票对应的聚源行业
-
-    :param order_book_ids: 股票列表，如['000001.XSHE', '000002.XSHE']
-    :param date: 如 '2015-01-07' (Default value = None)
-    :param level: 聚源等级，0, 1, 2, 3, 'customized' (Default value = 1)
-    :param expect_df: 返回 MultiIndex DataFrame (Default value = True)
-    :param market:  (Default value = "cn")
-    :returns: code, name
-        返回输入日期最近交易日的股票对应聚源行业以及对应的聚源等级
-
-    """
-    if level not in (0, 1, 2, 3, "customized"):
-        raise ValueError("level should in 0, 1, 2, 3, 'customized'")
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-    if not date:
-        date = ensure_date_int(get_previous_trading_date(datetime.date.today(), market=market))
-    else:
-        date = ensure_date_int(date)
-
-    df = get_client().execute("jy_instrument_industry", order_book_ids, date, level, market=market)
-    if not df:
-        return
-    if len(order_book_ids) == 1 and not expect_df:
-        r = df[0]
-        if level == 0:
-            return r["first_industry_name"], r["second_industry_name"], r["third_industry_name"]
-        return r["industry_name"]
-    return pd.DataFrame(df).set_index("order_book_id")
-
-
-@export_as_api(namespace="econ")
-def get_reserve_ratio(reserve_type="all", start_date=None, end_date=None, market="cn"):
-    """获取存款准备金率
-
-    :param reserve_type: 存款准备金详细类别，默认为'all'，目前仅支持'all'、'major'、'other'类别的查询
-    :param start_date: 开始查找时间，如'20180501'，默认为上一年的当天
-    :param end_date: 截止查找时间，如'20180501'，默认为当天
-    :param market:  (Default value = "cn")
-    :return: pd.DataFrame
-
-    """
-    check_items_in_container(reserve_type, ["all", "major", "other"], "reserve_type")
-
-    start_date, end_date = ensure_date_range(start_date, end_date, delta=relativedelta(years=1))
-
-    ret = get_client().execute(
-        "econ.get_reserve_ratio", reserve_type, start_date, end_date, market
-    )
-    if not ret:
-        return
-    columns = ["info_date", "effective_date", "reserve_type", "ratio_floor", "ratio_ceiling"]
-    df = pd.DataFrame(ret, columns=columns).set_index("info_date").sort_index(ascending=True)
-    return df
-
-
-@export_as_api(namespace="econ")
-def get_money_supply(start_date=None, end_date=None, market="cn"):
-    """获取货币供应量信息
-
-    :param start_date: 开始日期，默认为一年前
-    :param end_date: 结束日期，默认为今天
-    :param market:  (Default value = "cn")
-
-    """
-    check_items_in_container("info_date", ["info_date", "effective_date"], "date_type")
-    start_date, end_date = ensure_date_range(start_date, end_date, delta=relativedelta(years=1))
-
-    data = get_client().execute("econ.get_money_supply", start_date, end_date, market=market)
-    if not data:
-        return
-    columns = [
-        "info_date",
-        "effective_date",
-        "m2",
-        "m1",
-        "m0",
-        "m2_growth_yoy",
-        "m1_growth_yoy",
-        "m0_growth_yoy",
-    ]
-    df = pd.DataFrame(data, columns=columns).set_index("info_date").sort_index(ascending=True)
-    return df
-
-
-@export_as_api
-def get_main_shareholder(
-        order_book_ids, start_date=None, end_date=None, is_total=False, start_rank=None, end_rank=None, market="cn"
-):
-    """获取十大股东信息
-
-    :param order_book_ids: 股票代码
-    :param start_date: 开始日期，默认为一年前
-    :param end_date: 结束日期，默认为今天
-    :param is_total: 默认为 False, 即基于持有 A 股流通股。若为 True 则基于所有发行出的 A 股。
-    :param start_rank: 开始排名, int, 默认为最小排名
-    :param end_rank: 结束排名, int, 默认为最大排名
-    :param market:  (Default value = "cn")
-
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    check_items_in_container(is_total, [True, False], "is_total")
-    start_date, end_date = ensure_date_range(start_date, end_date, delta=relativedelta(years=1))
-
-    ret = get_client().execute(
-        "get_main_shareholder", order_book_ids, start_date, end_date, is_total,
-        start_rank=start_rank, end_rank=end_rank, market=market
-    )
-    if not ret:
-        return
-    columns = ['info_date', 'end_date', 'rank', 'shareholder_name', 'shareholder_attr', 'shareholder_kind',
-               'shareholder_type', 'hold_percent_total', 'hold_percent_float', 'share_pledge', 'share_freeze',
-               'order_book_id']
-    df = pd.DataFrame(ret, columns=columns).sort_values(by=['info_date', 'rank']).\
-        set_index(['order_book_id', 'info_date'])
-    return df
-
-
-@export_as_api
-def get_current_news(n=None, start_time=None, end_time=None, channels=None):
-    """获取新闻
-    :param n: 新闻条数, n 和 start_time/end_time 只能指定其一
-    :param start_time: 开始日期，默认为None,格式为%Y-%m-%d %H:%M:%S，如"2018-10-20 09:10:20"
-    :param end_time: 结束日期，默认为None,格式为%Y-%m-%d %H:%M:%S，如"2018-10-20 19:10:20"
-    :param channels: 新闻大类, 默认为None,返回每个大类n条新闻, 如 "global"，"forex", "commodity", "a-stock"
-    """
-
-    if start_time is not None or end_time is not None:
-        try:
-            start_time = datetime.datetime.strptime(start_time, "%Y-%m-%d %H:%M:%S")
-        except Exception:
-            raise ValueError('start_time should be str format like "%Y-%m-%d %H:%M:%S"')
-        try:
-            end_time = datetime.datetime.strptime(end_time, "%Y-%m-%d %H:%M:%S")
-        except Exception:
-            raise ValueError('end_time should be str format like "%Y-%m-%d %H:%M:%S"')
-        start_time = datetime_to_int14(start_time)
-        end_time = datetime_to_int14(end_time)
-        if n is not None:
-            raise ValueError(
-                "please either specify parameter n, or specify both start_time and end_time"
-            )
-        n = 1200
-    elif n is None:
-        n = 1
-    else:
-        n = ensure_int(n, "n")
-        if n < 1 or n > 1200:
-            raise ValueError("n should be in [0, 1200]")
-
-    if channels is not None:
-        channels = ensure_list_of_string(channels)
-        check_items_in_container(channels, ["global", "forex", "a-stock", "commodity"], "channels")
-    else:
-        channels = ["global", "forex", "a-stock", "commodity"]
-
-    data = get_client().execute("get_current_news", n, start_time, end_time, channels)
-    if not data:
-        return
-    df = pd.DataFrame(data, columns=["channel", "datetime", "content"])
-    return df.set_index("channel")
-
-
-@export_as_api(namespace="econ")
-def get_factors(factors, start_date, end_date, market="cn"):
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    factors = ensure_list_of_string(factors, "factors")
-    data = get_client().execute("econ.get_factors", factors, start_date, end_date, market=market)
-    if not data:
-        return
-    df = pd.DataFrame(data)
-    columns = ["factor", "info_date", "start_date", "end_date", "value"]
-    if "rice_create_tm" in df.columns:
-        df["rice_create_tm"] = pd.to_datetime(df["rice_create_tm"] + 3600 * 8, unit="s")
-        columns.append("rice_create_tm")
-    df = df.reindex(columns=columns)
-    df.set_index(["factor", "info_date"], inplace=True)
-    return df
-
-
-@export_as_api
-@rqdatah_serialize(converter=http_conv_trading_hours)
-def get_trading_hours(order_book_id, date=None, expected_fmt="str", frequency="1m", market="cn"):
-    """获取合约指定日期交易时间
-      :param order_book_id: 合约代码
-      :param date: 日期，默认为今天
-      :param expected_fmt: 返回格式，默认为str, 也支持datetime.time和datetime.datetime格式
-      :param frequency: 频率，默认为1m, 对应米筐分钟线时间段的起始, tick和1m相比区别在于每个交易时间段开盘往前移一分钟
-      :param market:  (Default value = "cn")
-
-      :return: trading_hours str or list of datetime.time/datetime.datetime list or None
-      """
-    date = ensure_date_or_today_int(date)
-    if not is_trading_date(date, market):
-        warnings.warn(" %d is not a trading date" % date)
-        return
-
-    ensure_string(order_book_id, "order_book_id")
-    ins = instruments(order_book_id)
-    if ins is None:
-        return
-
-    ensure_string_in(expected_fmt, ("str", "time", "datetime"), "expected_fmt")
-    ensure_string_in(frequency, ("1m", "tick"), "frequency")
-    date_str = to_date_str(date)
-
-    if ins.listed_date > date_str:
-        return
-
-    if ins.type in ("Future", "Option") and ins.de_listed_date < date_str and ins.de_listed_date != "0000-00-00":
-        return
-
-    if ins.type not in ("Future", "Option") and ins.de_listed_date <= date_str and ins.de_listed_date != "0000-00-00":
-        return
-    if ins.type == "Repo":
-        trading_hours = "09:31-11:30,13:01-15:30"
-    elif ins.type == "Spot":
-        if has_night_trading(date, market):
-            trading_hours = "20:01-02:30,09:01-15:30"
-        else:
-            trading_hours = "09:01-15:30"
-    elif ins.type not in ("Future", "Option") or (ins.type == "Option" and ins.exchange in ("XSHG", "XSHE")):
-        trading_hours = "09:31-11:30,13:01-15:00"
-    else:
-        trading_hours = get_client().execute("get_trading_hours", ins.underlying_symbol, date, market=market)
-        if trading_hours is None:
-            return
-        # 前一天放假或者该品种上市首日没有夜盘
-        no_night_trading = (not has_night_trading(date, market) or
-                            get_underlying_listed_date(ins.underlying_symbol, ins.type) == date_str)
-
-        if no_night_trading and not trading_hours.startswith("09"):
-            trading_hours = trading_hours.split(",", 1)[-1]
-
-    if frequency == "tick":
-        trading_hours = ",".join([s[:4] + str(int(s[4]) - 1) + s[5:] for s in trading_hours.split(",")])
-
-    if expected_fmt != "str":
-        trading_hours = [t.split("-", 1) for t in trading_hours.split(",")]
-        for i, (start, end) in enumerate(trading_hours):
-            trading_hours[i][0] = to_time(start)
-            trading_hours[i][1] = to_time(end)
-
-        if expected_fmt == "datetime":
-            td = int8_to_date(date)
-            prev_td = get_previous_trading_date(date)
-            prev_td_next = prev_td + datetime.timedelta(days=1)
-
-            for i, (start, end) in enumerate(trading_hours):
-                if start.hour > 16:
-                    start_dt = prev_td
-                    end_dt = start_dt if end.hour > 16 else prev_td_next
-                else:
-                    start_dt = end_dt = td
-                trading_hours[i][0] = datetime.datetime.combine(start_dt, start)
-                trading_hours[i][1] = datetime.datetime.combine(end_dt, end)
-
-    return trading_hours
-
-
-@export_as_api
-def get_private_placement(order_book_ids, start_date=None, end_date=None, progress="complete", issue_type="private", market="cn"):
-    """获取定增数据
-    :param order_book_ids: 合约代码
-    :param start_date: 开始日期，默认为None
-    :param end_date: 结束日期，默认为None
-    :param progress: 是否已完成定增，默认为complete。可选参数["complete", "incomplete", "all"]
-    :param issue_type: 默认为all。可选参数["private", "public", "all"]
-    :param market: (Default value = "cn")
-    :return:
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-    if start_date and end_date:
-        start_date, end_date = ensure_date_range(start_date, end_date)
-    elif start_date:
-        start_date = ensure_date_int(start_date)
-    elif end_date:
-        end_date = ensure_date_int(end_date)
-    ensure_string_in(progress, ["complete", "incomplete", "all"], "progress")
-    ensure_string_in(issue_type, ["private", "public", "all"], "issue_type")
-    issue_type_change = {"private": (21, 23), "public": (22,), "all": (21, 22, 23)}
-    issue_type = issue_type_change[issue_type]
-    data = get_client().execute(
-        "get_private_placement", order_book_ids, start_date, end_date, progress, issue_type=issue_type, market=market
-    )
-    if not data:
-        return
-    progress_map = {
-        10: "董事会预案", 20: "股东大会通过", 21: "国资委通过", 22: "发审委通过", 23: "证监会通过",
-        29: "实施中", 30: "实施完成", 40: "国资委否决", 41: "股东大会否决", 42: "证监会否决",
-        43: "发审委否决", 50: "延期实施", 60: "停止实施", 70: "暂缓发行"}
-    issue_type_map = {21: "非公开发行", 22: "公开发行", 23: "非公开发行配套融资"}
-    df = pd.DataFrame(data)
-    df["progress"] = df["progress"].map(progress_map)
-    df["issue_type"] = df["issue_type"].map(issue_type_map)
-    df.set_index(["order_book_id", "initial_info_date"], inplace=True)
-    return df
-
-
-@export_as_api
-def get_share_transformation(predecessor=None, market="cn"):
-    """
-    获取转股信息
-    :param predecessor: 换股前的股票代码。默认为空，返回所有转股信息
-    :param market:  (Default value = "cn")
-    :return pd.DataFrame
-    """
-    if predecessor:
-        predecessor = ensure_order_book_id(predecessor)
-    data = get_client().execute("get_share_transformation", predecessor, market=market)
-    if not data:
-        return
-    columns = [
-        "predecessor", "successor", "effective_date", "share_conversion_ratio", "predecessor_delisted",
-        "discretionary_execution", "predecessor_delisted_date", "event"
-    ]
-    df = pd.DataFrame(data, columns=columns)
-    df = df.sort_values('predecessor').reset_index(drop=True)
-    return df
-
-
-@export_as_api(namespace="user")
-@rqdatah_serialize(converter=http_conv_dict_to_csv)
-def get_quota():
-    """
-    获取用户配额信息
-    :return dict
-        bytes_limit：每日流量使用上限（单位为字节），如为0则表示不受限
-        bytes_used：当日已用流量（单位为字节）
-        remaining_days：账号剩余有效天数, 如为0则表示不受限
-        license_type：账户类型(FULL: 付费类型，TRIAL: 试用类型， EDU: 教育网类型, OTHER: 其他类型)
-    """
-    data = get_client().execute("user.get_quota")
-    if data['bytes_limit'] > 0 and data["bytes_used"] >= data["bytes_limit"]:
-        warnings.warn("Traffic usage has been exceeded quota,"
-                      "Please call us at 0755-22676337 to upgrade"
-                      "your contract.")
-    return data
-
-
-_CHECK_CATEGORIES = ("stock_1d", "stock_1m", "future_1d", "future_1m", "index_1d", "index_1m")
-
-
-@export_as_api()
-def get_update_status(categories):
-    """
-    获取数据最新日期
-    :param categories: str or list or str, 数据类型，支持类型有:
-        stock_1d: 股票日线
-        stock_1m: 股票分钟线
-        future_1d: 期货日线
-        future_1m: 期货分钟线
-        index_1d：指数日线
-        index_1m：指数分钟线
-
-    :return datetime.datetime or dict(category=datetime.datetime)
-    """
-    categories = ensure_list_of_string(categories, "categories")
-    check_items_in_container(categories, _CHECK_CATEGORIES, "categories")
-    ret = get_client().execute("get_update_status", categories)
-    if len(categories) == 1:
-        return ret[0]["date"]
-    return {r["category"]: r["date"] for r in ret}
-
-
-@export_as_api()
-def info():
-    """
-    打印账户信息
-    :return None
-    """
-    get_client().info()
-
-
-@export_as_api()
-def get_basic_info(order_book_ids=None, fields=("order_book_id", "symbol"), market='cn'):
-    if order_book_ids is not None:
-        order_book_ids = ensure_list_of_string(order_book_ids, "order_book_ids")
-    if fields is not None:
-        fields = ensure_list_of_string(fields, "fields")
-
-    ret = get_client().execute("get_basic_info", order_book_ids, fields, market=market)
-    if not ret:
-        return
-    columns, data = ret
-    return pd.DataFrame(data, columns=columns)
-
-
-@export_as_api()
-def get_spot_benchmark_price(order_book_ids, start_date=None, end_date=None):
-    """
-        获取上海黄金交易所基准价数据: 有早盘价和午盘价
-    :param order_book_ids: 现货标的
-    :param start_date: 开始日期，默认为None
-    :param end_date: 结束日期，默认为None
-    :return: pd.DataFrame
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, type="Spot", market="cn")
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    data = get_client().execute("get_spot_benchmark_price", order_book_ids, start_date=start_date, end_date=end_date)
-    if not data:
-        return
-    df = pd.DataFrame(data)
-    df.sort_values(by=["order_book_id", "date"], inplace=True)
-    df.set_index(keys=["order_book_id", "date"], inplace=True)
-    return df
+# -*- coding: utf-8 -*-
+import datetime
+import bisect
+import re
+import warnings
+from copy import deepcopy
+
+import six
+import pandas as pd
+
+from rqdatac.client import get_client
+from rqdatac.utils import to_date, datetime_to_int14, to_date_str, to_time, int8_to_date
+from rqdatac.validators import (
+    ensure_list_of_string,
+    ensure_date_int,
+    check_type,
+    ensure_date_str,
+    ensure_order_book_id,
+    ensure_order_book_ids,
+    check_items_in_container,
+    ensure_date_range,
+    ensure_int,
+    ensure_string,
+    ensure_date_or_today_int,
+    ensure_string_in,
+)
+from rqdatac.services.concept import concept_names as get_concept_names
+from rqdatac.services.shenwan import get_instrument_industry
+from rqdatac.services.constant import SectorCode, SectorCodeItem, IndustryCode, IndustryCodeItem
+from rqdatac.services.calendar import get_previous_trading_date, is_trading_date, has_night_trading
+from rqdatac.decorators import export_as_api, ttl_cache, compatible_with_parm
+from dateutil.relativedelta import relativedelta
+from rqdatac.rqdatah_helper import (
+    rqdatah_serialize, http_conv_list_to_csv, http_conv_trading_hours, http_conv_dict_to_csv, http_conv_instruments
+)
+
+_wind_exchange_map = {
+    'CFFEX': 'CFE',
+    'SHFE': 'SHF',
+    'INE': 'INE',
+    'DCE': 'DCE',
+    'CZCE': 'CZC',
+    'GFEX': 'GFE',
+}
+
+
+_wind_index_map = {
+    '000902.CSI': '000902.XSHG',
+    '000904.CSI': '000904.XSHG',
+    '000907.CSI': '000907.XSHG',
+    '000980.CSI': '000980.XSHG',
+    '000985.CSI': '000985.XSHG',
+    'h30455.CSI': 'H30455.XSHG',
+    '921395.CSI': '921395.INDX',
+    '921396.CSI': '921396.INDX',
+    '921459.SH': '921459.INDX',
+    '921460.SH': '921460.INDX',
+    'h00300.CSI': 'H00300.INDX',
+    'h00902.CSI': 'H00902.INDX',
+    'h00903.CSI': 'H00903.INDX',
+    'h00904.CSI': 'H00904.INDX',
+    'h00905.CSI': 'H00905.INDX',
+    'h00906.CSI': 'H00906.INDX',
+    'h00907.CSI': 'H00907.INDX',
+    'h00980.CSI': 'H00980.INDX',
+    'h00985.CSI': 'H00985.INDX',
+    'h20748.CSI': 'H20748.INDX',
+    'h20749.CSI': 'H20749.INDX',
+    'h20750.CSI': 'H20750.INDX',
+    'h20751.CSI': 'H20751.INDX',
+    'h20752.CSI': 'H20752.INDX',
+    'h20753.CSI': 'H20753.INDX',
+    'h20903.CSI': 'H20903.INDX',
+    'h30310.CSI': 'H30310.XSHG',
+    '000908.CSI': '000908.XSHG',
+    '000909.CSI': '000909.XSHG',
+    '000910.CSI': '000910.XSHG',
+    '000911.CSI': '000911.XSHG',
+    '000912.CSI': '000912.XSHG',
+    '000913.CSI': '000913.XSHG',
+    '000915.CSI': '000915.XSHG',
+    '000916.CSI': '000916.XSHG',
+    '000917.CSI': '000917.XSHG',
+    '000951.CSI': '000951.XSHG',
+    '000952.CSI': '000952.XSHG',
+    '000957.CSI': '000957.XSHG',
+    'h00908.CSI': 'H00908.INDX',
+    'h00909.CSI': 'H00909.INDX',
+    'h00910.CSI': 'H00910.INDX',
+    'h00911.CSI': 'H00911.INDX',
+    'h00912.CSI': 'H00912.INDX',
+    'h00913.CSI': 'H00913.INDX',
+    'h00915.CSI': 'H00915.INDX',
+    'h00916.CSI': 'H00916.INDX',
+    'h00917.CSI': 'H00917.INDX',
+    'h00952.CSI': 'H00952.INDX',
+    'h30034.CSI': 'H30034.XSHG',
+    'h00951.CSI': 'H00951.INDX',
+    'h00957.CSI': 'H00957.INDX',
+    'h20034.CSI': 'H20034.INDX',
+    'h30250.CSI': 'H30250.XSHG',
+    'h30253.CSI': 'H30253.XSHG',
+    'h30254.CSI': 'H30254.XSHG',
+    'h30255.CSI': 'H30255.XSHG',
+    'h30258.CSI': 'H30258.XSHG',
+    'h30259.CSI': 'H30259.XSHG',
+    'h20250.CSI': 'H20250.INDX',
+    'h20251.CSI': 'H20251.INDX',
+    'h20252.CSI': 'H20252.INDX',
+    'h20253.CSI': 'H20253.INDX',
+    'h20254.CSI': 'H20254.INDX',
+    'h20255.CSI': 'H20255.INDX',
+    'h20257.CSI': 'H20257.INDX',
+    'h20258.CSI': 'H20258.INDX',
+    'h20259.CSI': 'H20259.INDX',
+    'h20673.CSI': 'H20673.INDX',
+    'h20670.CSI': 'H20670.INDX',
+    'h20671.CSI': 'H20671.INDX',
+    'h20674.CSI': 'H20674.INDX',
+    'h20675.CSI': 'H20675.INDX',
+    'h20676.CSI': 'H20676.INDX',
+    'h20677.CSI': 'H20677.INDX',
+    'h20679.CSI': 'H20679.INDX',
+    'h20680.CSI': 'H20680.INDX',
+    'h20681.CSI': 'H20681.INDX',
+    'h20682.CSI': 'H20682.INDX',
+    'h20683.CSI': 'H20683.INDX',
+    'h20684.CSI': 'H20684.INDX',
+    'h20685.CSI': 'H20685.INDX',
+    'h20694.CSI': 'H20694.INDX',
+    'h20695.CSI': 'H20695.INDX',
+    'h20686.CSI': 'H20686.INDX',
+    'h20687.CSI': 'H20687.INDX',
+    'h20688.CSI': 'H20688.INDX',
+    'h20689.CSI': 'H20689.INDX',
+    'h20690.CSI': 'H20690.INDX',
+    'h20691.CSI': 'H20691.INDX',
+    'h20692.CSI': 'H20692.INDX',
+    'h20693.CSI': 'H20693.INDX',
+    '000929.CSI': '000929.XSHG',
+    '000930.CSI': '000930.XSHG',
+    '000931.CSI': '000931.XSHG',
+    '000936.CSI': '000936.XSHG',
+    '000937.CSI': '000937.XSHG',
+    'h30086.CSI': 'H30086.XSHG',
+    'h00928.CSI': 'H00928.INDX',
+    'h00929.CSI': 'H00929.INDX',
+    'h00930.CSI': 'H00930.INDX',
+    'h00931.CSI': 'H00931.INDX',
+    'h00932.CSI': 'H00932.INDX',
+    'h00933.CSI': 'H00933.INDX',
+    'h00935.CSI': 'H00935.INDX',
+    'h00936.CSI': 'H00936.INDX',
+    'h00937.CSI': 'H00937.INDX',
+    'h20025.CSI': 'H20025.INDX',
+    'h20086.CSI': 'H20086.INDX',
+    '000841.CSI': '000841.XSHG',
+    'h30010.CSI': 'H30010.XSHG',
+    'h30013.CSI': 'H30013.XSHG',
+    'h30014.CSI': 'H30014.XSHG',
+    'h30016.CSI': 'H30016.XSHG',
+    'h30017.CSI': 'H30017.XSHG',
+    'h30018.CSI': 'H30018.XSHG',
+    'h30019.CSI': 'H30019.XSHG',
+    'h30020.CSI': 'H30020.XSHG',
+    'h30022.CSI': 'H30022.XSHG',
+    'h30023.CSI': 'H30023.XSHG',
+    'h30024.CSI': 'H30024.XSHG',
+    'h30026.CSI': 'H30026.XSHG',
+    'h30028.CSI': 'H30028.XSHG',
+    'h30029.CSI': 'H30029.XSHG',
+    'h30031.CSI': 'H30031.XSHG',
+    'h00841.CSI': 'H00841.INDX',
+    'h20010.CSI': 'H20010.INDX',
+    'h20013.CSI': 'H20013.INDX',
+    'h20014.CSI': 'H20014.INDX',
+    'h20016.CSI': 'H20016.INDX',
+    'h20017.CSI': 'H20017.INDX',
+    'h20018.CSI': 'H20018.INDX',
+    'h20019.CSI': 'H20019.INDX',
+    'h20020.CSI': 'H20020.INDX',
+    'h20022.CSI': 'H20022.INDX',
+    'h20023.CSI': 'H20023.INDX',
+    'h20024.CSI': 'H20024.INDX',
+    'h20026.CSI': 'H20026.INDX',
+    'h20028.CSI': 'H20028.INDX',
+    'h20029.CSI': 'H20029.INDX',
+    'h20031.CSI': 'H20031.INDX',
+    '931775.CSI': '931775.INDX',
+    'h00986.CSI': 'H00986.INDX',
+    'h00987.CSI': 'H00987.INDX',
+    'h00988.CSI': 'H00988.INDX',
+    'h00989.CSI': 'H00989.INDX',
+    'h00990.CSI': 'H00990.INDX',
+    'h00991.CSI': 'H00991.INDX',
+    'h00993.CSI': 'H00993.INDX',
+    'h00994.CSI': 'H00994.INDX',
+    'h00995.CSI': 'H00995.INDX',
+    'h30166.CSI': 'H30166.XSHG',
+    'h30170.CSI': 'H30170.XSHG',
+    'h30171.CSI': 'H30171.XSHG',
+    'h30173.CSI': 'H30173.XSHG',
+    'h30174.CSI': 'H30174.XSHG',
+    'h30175.CSI': 'H30175.XSHG',
+    'h30177.CSI': 'H30177.XSHG',
+    'h30179.CSI': 'H30179.XSHG',
+    'h30182.CSI': 'H30182.XSHG',
+    'h30183.CSI': 'H30183.XSHG',
+    'h30184.CSI': 'H30184.XSHG',
+    'h30186.CSI': 'H30186.XSHG',
+    'h30187.CSI': 'H30187.XSHG',
+    'h30196.CSI': 'H30196.XSHG',
+    'h30211.CSI': 'H30211.XSHG',
+    'h20164.CSI': 'H20164.INDX',
+    'h20166.CSI': 'H20166.INDX',
+    'h20170.CSI': 'H20170.INDX',
+    'h20171.CSI': 'H20171.INDX',
+    'h20173.CSI': 'H20173.INDX',
+    'h20174.CSI': 'H20174.INDX',
+    'h20175.CSI': 'H20175.INDX',
+    'h20177.CSI': 'H20177.INDX',
+    'h20179.CSI': 'H20179.INDX',
+    'h20180.CSI': 'H20180.INDX',
+    'h20182.CSI': 'H20182.INDX',
+    'h20183.CSI': 'H20183.INDX',
+    'h20184.CSI': 'H20184.INDX',
+    'h20186.CSI': 'H20186.INDX',
+    'h20187.CSI': 'H20187.INDX',
+    'h20196.CSI': 'H20196.INDX',
+    'h20211.CSI': 'H20211.INDX',
+    'h20910.CSI': 'H20910.INDX',
+    '930697.CSI': '930697.INDX',
+    'h30192.CSI': 'H30192.XSHG',
+    'h30193.CSI': 'H30193.XSHG',
+    'h30194.CSI': 'H30194.XSHG',
+    'h30195.CSI': 'H30195.XSHG',
+    'h30197.CSI': 'H30197.XSHG',
+    'h30199.CSI': 'H30199.XSHG',
+    'h30200.CSI': 'H30200.XSHG',
+    'h30203.CSI': 'H30203.XSHG',
+    'h30204.CSI': 'H30204.XSHG',
+    'h30206.CSI': 'H30206.XSHG',
+    'h30208.CSI': 'H30208.XSHG',
+    'h30209.CSI': 'H30209.XSHG',
+    'h30214.CSI': 'H30214.XSHG',
+    'h30215.CSI': 'H30215.XSHG',
+    'h30217.CSI': 'H30217.XSHG',
+    'h30218.CSI': 'H30218.XSHG',
+    'h30219.CSI': 'H30219.XSHG',
+    'h30220.CSI': 'H30220.XSHG',
+    'h30221.CSI': 'H30221.XSHG',
+    'h30222.CSI': 'H30222.XSHG',
+    'h20192.CSI': 'H20192.INDX',
+    'h20193.CSI': 'H20193.INDX',
+    'h20194.CSI': 'H20194.INDX',
+    'h20195.CSI': 'H20195.INDX',
+    'h20197.CSI': 'H20197.INDX',
+    'h20199.CSI': 'H20199.INDX',
+    'h20200.CSI': 'H20200.INDX',
+    'h20203.CSI': 'H20203.INDX',
+    'h20204.CSI': 'H20204.INDX',
+    'h20206.CSI': 'H20206.INDX',
+    'h20208.CSI': 'H20208.INDX',
+    'h20209.CSI': 'H20209.INDX',
+    'h20214.CSI': 'H20214.INDX',
+    'h20215.CSI': 'H20215.INDX',
+    'h20217.CSI': 'H20217.INDX',
+    'h20218.CSI': 'H20218.INDX',
+    'h20219.CSI': 'H20219.INDX',
+    'h20220.CSI': 'H20220.INDX',
+    'h20221.CSI': 'H20221.INDX',
+    'h20222.CSI': 'H20222.INDX',
+    'h20697.CSI': 'H20697.INDX',
+    'h20911.CSI': 'H20911.INDX',
+    'h30201.CSI': 'H30201.XSHG',
+    'h30207.CSI': 'H30207.XSHG',
+    'h30216.CSI': 'H30216.XSHG',
+    'h30223.CSI': 'H30223.XSHG',
+    'h20168.CSI': 'H20168.INDX',
+    'h20201.CSI': 'H20201.INDX',
+    'h20207.CSI': 'H20207.INDX',
+    'h20216.CSI': 'H20216.INDX',
+    'h20223.CSI': 'H20223.INDX',
+    'h11030.CSI': 'H11030.XSHG',
+    'h11031.CSI': 'H11031.XSHG',
+    'h11041.CSI': 'H11041.XSHG',
+    'h11042.CSI': 'H11042.XSHG',
+    'h11043.CSI': 'H11043.XSHG',
+    'h11044.CSI': 'H11044.XSHG',
+    'h11045.CSI': 'H11045.XSHG',
+    'h11046.CSI': 'H11046.XSHG',
+    'h11047.CSI': 'H11047.XSHG',
+    'h11049.CSI': 'H11049.XSHG',
+    'h11050.CSI': 'H11050.XSHG',
+    'h30036.CSI': 'H30036.XSHG',
+    'h30037.CSI': 'H30037.XSHG',
+    'h30038.CSI': 'H30038.XSHG',
+    'h30039.CSI': 'H30039.XSHG',
+    'h30040.CSI': 'H30040.XSHG',
+    'h30041.CSI': 'H30041.XSHG',
+    'h30042.CSI': 'H30042.XSHG',
+    'h30043.CSI': 'H30043.XSHG',
+    'h30044.CSI': 'H30044.XSHG',
+    'h30045.CSI': 'H30045.XSHG',
+    'h30046.CSI': 'H30046.XSHG',
+    'h30047.CSI': 'H30047.XSHG',
+    'h30048.CSI': 'H30048.XSHG',
+    'h30049.CSI': 'H30049.XSHG',
+    'h30050.CSI': 'H30050.XSHG',
+    'h30051.CSI': 'H30051.XSHG',
+    'h30052.CSI': 'H30052.XSHG',
+    'h30053.CSI': 'H30053.XSHG',
+    'h30054.CSI': 'H30054.XSHG',
+    'h30055.CSI': 'H30055.XSHG',
+    'h30056.CSI': 'H30056.XSHG',
+    'h30057.CSI': 'H30057.XSHG',
+    'h30058.CSI': 'H30058.XSHG',
+    'h30059.CSI': 'H30059.XSHG',
+    'h30060.CSI': 'H30060.XSHG',
+    'h30061.CSI': 'H30061.XSHG',
+    'h30062.CSI': 'H30062.XSHG',
+    'h30063.CSI': 'H30063.XSHG',
+    'h30064.CSI': 'H30064.XSHG',
+    'h30065.CSI': 'H30065.XSHG',
+    'h30066.CSI': 'H30066.XSHG',
+    'h30067.CSI': 'H30067.XSHG',
+    '000925.CSI': '000925.XSHG',
+    '000965.CSI': '000965.XSHG',
+    '000966.CSI': '000966.XSHG',
+    '000967.CSI': '000967.XSHG',
+    '930723.CSI': '930723.INDX',
+    'h11111.CSI': 'H11111.XSHG',
+    'h30362.CSI': 'H30362.XSHG',
+    'h30363.CSI': 'H30363.XSHG',
+    'h00925.CSI': 'H00925.INDX',
+    'h00965.CSI': 'H00965.INDX',
+    'h00966.CSI': 'H00966.INDX',
+    'h00967.CSI': 'H00967.INDX',
+    '000842.CSI': '000842.XSHG',
+    '000971.CSI': '000971.XSHG',
+    '000981.CSI': '000981.XSHG',
+    '000982.CSI': '000982.XSHG',
+    '000984.CSI': '000984.XSHG',
+    'h30238.CSI': 'H30238.XSHG',
+    'h30239.CSI': 'H30239.XSHG',
+    'h30248.CSI': 'H30248.XSHG',
+    'h30249.CSI': 'H30249.XSHG',
+    'h30422.CSI': 'H30422.XSHG',
+    'h30438.CSI': 'H30438.XSHG',
+    'h00842.CSI': 'H00842.INDX',
+    'h00971.CSI': 'H00971.INDX',
+    'h00981.CSI': 'H00981.INDX',
+    'h00982.CSI': 'H00982.INDX',
+    'h00984.CSI': 'H00984.INDX',
+    '000843.CSI': '000843.XSHG',
+    '000844.CSI': '000844.XSHG',
+    'h30087.CSI': 'H30087.XSHG',
+    'h30088.CSI': 'H30088.XSHG',
+    'h00843.CSI': 'H00843.INDX',
+    'h00844.CSI': 'H00844.INDX',
+    'h20087.CSI': 'H20087.INDX',
+    'h20088.CSI': 'H20088.INDX',
+    '000828.CSI': '000828.XSHG',
+    '000829.CSI': '000829.XSHG',
+    '000830.CSI': '000830.XSHG',
+    '000831.CSI': '000831.XSHG',
+    'h00828.CSI': 'H00828.INDX',
+    'h00829.CSI': 'H00829.INDX',
+    'h00830.CSI': 'H00830.INDX',
+    'h00831.CSI': 'H00831.INDX',
+    '000803.CSI': '000803.XSHG',
+    '000804.CSI': '000804.XSHG',
+    'h00803.CSI': 'H00803.INDX',
+    'h00804.CSI': 'H00804.INDX',
+    'h30082.CSI': 'H30082.XSHG',
+    'h30083.CSI': 'H30083.XSHG',
+    'h30084.CSI': 'H30084.XSHG',
+    'h11180.CSI': 'H11180.XSHG',
+    '000920.CSI': '000920.XSHG',
+    '000921.CSI': '000921.XSHG',
+    'h30090.CSI': 'H30090.XSHG',
+    'h30091.CSI': 'H30091.XSHG',
+    'h30092.CSI': 'H30092.XSHG',
+    'h30093.CSI': 'H30093.XSHG',
+    'h30094.CSI': 'H30094.XSHG',
+    'h30095.CSI': 'H30095.XSHG',
+    'h30096.CSI': 'H30096.XSHG',
+    'h30097.CSI': 'H30097.XSHG',
+    'h30098.CSI': 'H30098.XSHG',
+    'h30099.CSI': 'H30099.XSHG',
+    'h20090.CSI': 'H20090.INDX',
+    'h20091.CSI': 'H20091.INDX',
+    'h20092.CSI': 'H20092.INDX',
+    'h20093.CSI': 'H20093.INDX',
+    'h20094.CSI': 'H20094.INDX',
+    'h20095.CSI': 'H20095.INDX',
+    'h20096.CSI': 'H20096.INDX',
+    'h20097.CSI': 'H20097.INDX',
+    'h20098.CSI': 'H20098.INDX',
+    'h20099.CSI': 'H20099.INDX',
+    '000810.CSI': '000810.XSHG',
+    '000811.CSI': '000811.XSHG',
+    '000812.CSI': '000812.XSHG',
+    '000813.CSI': '000813.XSHG',
+    '000814.CSI': '000814.XSHG',
+    '000815.CSI': '000815.XSHG',
+    '000818.CSI': '000818.XSHG',
+    'h00810.CSI': 'H00810.INDX',
+    'h00811.CSI': 'H00811.INDX',
+    'h00812.CSI': 'H00812.INDX',
+    'h00813.CSI': 'H00813.INDX',
+    'h00814.CSI': 'H00814.INDX',
+    'h00815.CSI': 'H00815.INDX',
+    'h00816.CSI': 'H00816.INDX',
+    'h00818.CSI': 'H00818.INDX',
+    'h30001.CSI': 'H30001.XSHG',
+    'h30002.CSI': 'H30002.XSHG',
+    'h30004.CSI': 'H30004.XSHG',
+    'h30005.CSI': 'H30005.XSHG',
+    'h30006.CSI': 'H30006.XSHG',
+    'h20001.CSI': 'H20001.INDX',
+    'h20002.CSI': 'H20002.INDX',
+    'h20004.CSI': 'H20004.INDX',
+    'h20005.CSI': 'H20005.INDX',
+    'h20006.CSI': 'H20006.INDX',
+    'h11051.CSI': 'H11051.XSHG',
+    'h11052.CSI': 'H11052.XSHG',
+    'h11053.CSI': 'H11053.XSHG',
+    'h11054.CSI': 'H11054.XSHG',
+    'h11055.CSI': 'H11055.XSHG',
+    'h11057.CSI': 'H11057.XSHG',
+    'h11058.CSI': 'H11058.XSHG',
+    'h11059.CSI': 'H11059.XSHG',
+    'h11060.CSI': 'H11060.XSHG',
+    'h01051.CSI': 'H01051.INDX',
+    'h01052.CSI': 'H01052.INDX',
+    'h01053.CSI': 'H01053.INDX',
+    'h01054.CSI': 'H01054.INDX',
+    'h01055.CSI': 'H01055.INDX',
+    'h01057.CSI': 'H01057.INDX',
+    'h01058.CSI': 'H01058.INDX',
+    'h01059.CSI': 'H01059.INDX',
+    'h01060.CSI': 'H01060.INDX',
+    'h01113.CSI': 'H01113.INDX',
+    'h30137.CSI': 'H30137.XSHG',
+    'h30138.CSI': 'H30138.XSHG',
+    'h30139.CSI': 'H30139.XSHG',
+    'h30140.CSI': 'H30140.XSHG',
+    'h30141.CSI': 'H30141.XSHG',
+    'h30142.CSI': 'H30142.XSHG',
+    'h30143.CSI': 'H30143.XSHG',
+    'h20137.CSI': 'H20137.INDX',
+    'h20138.CSI': 'H20138.INDX',
+    'h20139.CSI': 'H20139.INDX',
+    'h20140.CSI': 'H20140.INDX',
+    'h20141.CSI': 'H20141.INDX',
+    'h20142.CSI': 'H20142.INDX',
+    'h20143.CSI': 'H20143.INDX',
+    '000942.CSI': '000942.XSHG',
+    '000943.CSI': '000943.XSHG',
+    '000945.CSI': '000945.XSHG',
+    '000947.CSI': '000947.XSHG',
+    '000948.CSI': '000948.XSHG',
+    '000949.CSI': '000949.XSHG',
+    'h00942.CSI': 'H00942.INDX',
+    'h00943.CSI': 'H00943.INDX',
+    'h00944.CSI': 'H00944.INDX',
+    'h00945.CSI': 'H00945.INDX',
+    'h00947.CSI': 'H00947.INDX',
+    'h00948.CSI': 'H00948.INDX',
+    'h00949.CSI': 'H00949.INDX',
+    '000821.CSI': '000821.XSHG',
+    '000822.CSI': '000822.XSHG',
+    '000824.CSI': '000824.XSHG',
+    '000825.CSI': '000825.XSHG',
+    '000826.CSI': '000826.XSHG',
+    'h30073.CSI': 'H30073.XSHG',
+    'h30089.CSI': 'H30089.XSHG',
+    'h00821.CSI': 'H00821.INDX',
+    'h00822.CSI': 'H00822.INDX',
+    'h00824.CSI': 'H00824.INDX',
+    'h00825.CSI': 'H00825.INDX',
+    'h00826.CSI': 'H00826.INDX',
+    'h00922.CSI': 'H00922.INDX',
+    '000839.CSI': '000839.XSHG',
+    '000840.CSI': '000840.XSHG',
+    '000926.CSI': '000926.XSHG',
+    '000927.CSI': '000927.XSHG',
+    '000938.CSI': '000938.XSHG',
+    '000953.CSI': '000953.XSHG',
+    '000954.CSI': '000954.XSHG',
+    '000955.CSI': '000955.XSHG',
+    '000956.CSI': '000956.XSHG',
+    '930746.CSI': '930746.INDX',
+    'h11154.CSI': 'H11154.XSHG',
+    'h11155.CSI': 'H11155.XSHG',
+    'h30368.CSI': 'H30368.XSHG',
+    'h50052.CSI': 'H50052.XSHG',
+    'h00839.CSI': 'H00839.INDX',
+    'h00840.CSI': 'H00840.INDX',
+    'h00926.CSI': 'H00926.INDX',
+    'h00927.CSI': 'H00927.INDX',
+    'h00938.CSI': 'H00938.INDX',
+    'h00939.CSI': 'H00939.INDX',
+    'h00953.CSI': 'H00953.INDX',
+    'h00954.CSI': 'H00954.INDX',
+    'h00955.CSI': 'H00955.INDX',
+    'h00956.CSI': 'H00956.INDX',
+    'h00958.CSI': 'H00958.INDX',
+    '000838.CSI': '000838.XSHG',
+    '000846.CSI': '000846.XSHG',
+    '000850.CSI': '000850.XSHG',
+    '000859.CSI': '000859.XSHG',
+    '000860.CSI': '000860.XSHG',
+    '000861.CSI': '000861.XSHG',
+    '000891.CSI': '000891.XSHG',
+    '000922.CSI': '000922.XSHG',
+    '000939.CSI': '000939.XSHG',
+    '000941.CSI': '000941.XSHG',
+    '000950.CSI': '000950.XSHG',
+    '000958.CSI': '000958.XSHG',
+    '000959.CSI': '000959.XSHG',
+    '000961.CSI': '000961.XSHG',
+    '000962.CSI': '000962.XSHG',
+    '000963.CSI': '000963.XSHG',
+    '000964.CSI': '000964.XSHG',
+    '000968.CSI': '000968.XSHG',
+    '000969.CSI': '000969.XSHG',
+    '000970.CSI': '000970.XSHG',
+    '000972.CSI': '000972.XSHG',
+    '000975.CSI': '000975.XSHG',
+    '000977.CSI': '000977.XSHG',
+    '000978.CSI': '000978.XSHG',
+    '000979.CSI': '000979.XSHG',
+    '000998.CSI': '000998.XSHG',
+    '930599.CSI': '930599.INDX',
+    '930629.CSI': '930629.INDX',
+    '930641.CSI': '930641.INDX',
+    '930648.CSI': '930648.INDX',
+    '930651.CSI': '930651.INDX',
+    '930652.CSI': '930652.INDX',
+    '930654.CSI': '930654.INDX',
+    '930700.CSI': '930700.INDX',
+    '930701.CSI': '930701.INDX',
+    '930709.CSI': '930709.INDX',
+    '930713.CSI': '930713.INDX',
+    '930719.CSI': '930719.INDX',
+    '930720.CSI': '930720.INDX',
+    '930721.CSI': '930721.INDX',
+    '930726.CSI': '930726.INDX',
+    '930734.CSI': '930734.INDX',
+    '930738.CSI': '930738.INDX',
+    '930743.CSI': '930743.INDX',
+    '930792.CSI': '930792.INDX',
+    '930838.CSI': '930838.INDX',
+    '930875.CSI': '930875.INDX',
+    '930915.CSI': '930915.INDX',
+    '930917.CSI': '930917.INDX',
+    '930997.CSI': '930997.INDX',
+    '930999.CSI': '930999.INDX',
+    '931000.CSI': '931000.INDX',
+    '931008.CSI': '931008.INDX',
+    '931009.CSI': '931009.INDX',
+    '931023.CSI': '931023.INDX',
+    '931029.CSI': '931029.INDX',
+    '931030.CSI': '931030.INDX',
+    '931031.CSI': '931031.INDX',
+    '931032.CSI': '931032.INDX',
+    '931033.CSI': '931033.INDX',
+    '931068.CSI': '931068.INDX',
+    '931071.CSI': '931071.INDX',
+    '931079.CSI': '931079.INDX',
+    '931087.CSI': '931087.INDX',
+    '931136.CSI': '931136.INDX',
+    '931139.CSI': '931139.INDX',
+    '931140.CSI': '931140.INDX',
+    '931141.CSI': '931141.INDX',
+    '931144.CSI': '931144.INDX',
+    '931152.CSI': '931152.INDX',
+    '931159.CSI': '931159.INDX',
+    '931160.CSI': '931160.INDX',
+    '931186.CSI': '931186.INDX',
+    '931187.CSI': '931187.INDX',
+    '931268.CSI': '931268.INDX',
+    '931357.CSI': '931357.INDX',
+    '931373.CSI': '931373.INDX',
+    '931380.CSI': '931380.INDX',
+    '931406.CSI': '931406.INDX',
+    '950082.CSI': '950082.INDX',
+    '950096.CSI': '950096.INDX',
+    'h11102.CSI': 'H11102.XSHG',
+    'h11103.CSI': 'H11103.XSHG',
+    'h11104.CSI': 'H11104.XSHG',
+    'h11105.CSI': 'H11105.XSHG',
+    'h11106.CSI': 'H11106.XSHG',
+    'h11112.CSI': 'H11112.XSHG',
+    'h11113.CSI': 'H11113.XSHG',
+    'h11114.CSI': 'H11114.XSHG',
+    'h11115.CSI': 'H11115.XSHG',
+    'h11116.CSI': 'H11116.XSHG',
+    'h11121.CSI': 'H11121.XSHG',
+    'h11125.CSI': 'H11125.XSHG',
+    'h11126.CSI': 'H11126.XSHG',
+    'h11136.CSI': 'H11136.XSHG',
+    'h11137.CSI': 'H11137.XSHG',
+    'h11141.CSI': 'H11141.XSHG',
+    'h11142.CSI': 'H11142.XSHG',
+    'h11145.CSI': 'H11145.XSHG',
+    'h11146.CSI': 'H11146.XSHG',
+    'h11147.CSI': 'H11147.XSHG',
+    'h11148.CSI': 'H11148.XSHG',
+    'h11149.CSI': 'H11149.XSHG',
+    'h11150.CSI': 'H11150.XSHG',
+    'h11151.CSI': 'H11151.XSHG',
+    'h11160.CSI': 'H11160.XSHG',
+    'h11161.CSI': 'H11161.XSHG',
+    'h11162.CSI': 'H11162.XSHG',
+    'h11163.CSI': 'H11163.XSHG',
+    'h11166.CSI': 'H11166.XSHG',
+    'h11167.CSI': 'H11167.XSHG',
+    'h11170.CSI': 'H11170.XSHG',
+    'h11171.CSI': 'H11171.XSHG',
+    'h11183.CSI': 'H11183.XSHG',
+    'h11184.CSI': 'H11184.XSHG',
+    'h30007.CSI': 'H30007.XSHG',
+    'h30011.CSI': 'H30011.XSHG',
+    'h30012.CSI': 'H30012.XSHG',
+    'h30015.CSI': 'H30015.XSHG',
+    'h30035.CSI': 'H30035.XSHG',
+    'h30068.CSI': 'H30068.XSHG',
+    'h30074.CSI': 'H30074.XSHG',
+    'h30079.CSI': 'H30079.XSHG',
+    'h30080.CSI': 'H30080.XSHG',
+    'h30081.CSI': 'H30081.XSHG',
+    'h30085.CSI': 'H30085.XSHG',
+    'h30100.CSI': 'H30100.XSHG',
+    'h30101.CSI': 'H30101.XSHG',
+    'h30102.CSI': 'H30102.XSHG',
+    'h30103.CSI': 'H30103.XSHG',
+    'h30104.CSI': 'H30104.XSHG',
+    'h30105.CSI': 'H30105.XSHG',
+    'h30106.CSI': 'H30106.XSHG',
+    'h30107.CSI': 'H30107.XSHG',
+    'h30109.CSI': 'H30109.XSHG',
+    'h30110.CSI': 'H30110.XSHG',
+    'h30111.CSI': 'H30111.XSHG',
+    'h30112.CSI': 'H30112.XSHG',
+    'h30113.CSI': 'H30113.XSHG',
+    'h30114.CSI': 'H30114.XSHG',
+    'h30115.CSI': 'H30115.XSHG',
+    'h30116.CSI': 'H30116.XSHG',
+    'h30117.CSI': 'H30117.XSHG',
+    'h30119.CSI': 'H30119.XSHG',
+    'h30131.CSI': 'H30131.XSHG',
+    'h30132.CSI': 'H30132.XSHG',
+    'h30169.CSI': 'H30169.XSHG',
+    'h30172.CSI': 'H30172.XSHG',
+    'h30176.CSI': 'H30176.XSHG',
+    'h30178.CSI': 'H30178.XSHG',
+    'h30188.CSI': 'H30188.XSHG',
+    'h30190.CSI': 'H30190.XSHG',
+    'h30202.CSI': 'H30202.XSHG',
+    'h30213.CSI': 'H30213.XSHG',
+    'h30256.CSI': 'H30256.XSHG',
+    'h30275.CSI': 'H30275.XSHG',
+    'h30276.CSI': 'H30276.XSHG',
+    'h30277.CSI': 'H30277.XSHG',
+    'h30334.CSI': 'H30334.XSHG',
+    'h30335.CSI': 'H30335.XSHG',
+    'h30336.CSI': 'H30336.XSHG',
+    'h30337.CSI': 'H30337.XSHG',
+    'h30338.CSI': 'H30338.XSHG',
+    'h30339.CSI': 'H30339.XSHG',
+    'h30340.CSI': 'H30340.XSHG',
+    'h30341.CSI': 'H30341.XSHG',
+    'h30342.CSI': 'H30342.XSHG',
+    'h30344.CSI': 'H30344.XSHG',
+    'h30350.CSI': 'H30350.XSHG',
+    'h30360.CSI': 'H30360.XSHG',
+    'h30361.CSI': 'H30361.XSHG',
+    'h30365.CSI': 'H30365.XSHG',
+    'h30366.CSI': 'H30366.XSHG',
+    'h30372.CSI': 'H30372.XSHG',
+    'h30401.CSI': 'H30401.XSHG',
+    'h30402.CSI': 'H30402.XSHG',
+    'h30456.CSI': 'H30456.XSHG',
+    'h30457.CSI': 'H30457.XSHG',
+    'h30458.CSI': 'H30458.XSHG',
+    'h30459.CSI': 'H30459.XSHG',
+    'h30460.CSI': 'H30460.XSHG',
+    'h30461.CSI': 'H30461.XSHG',
+    'h30462.CSI': 'H30462.XSHG',
+    'h30463.CSI': 'H30463.XSHG',
+    'h30464.CSI': 'H30464.XSHG',
+    'h30465.CSI': 'H30465.XSHG',
+    'h30466.CSI': 'H30466.XSHG',
+    'h30467.CSI': 'H30467.XSHG',
+    'h30468.CSI': 'H30468.XSHG',
+    'h30469.CSI': 'H30469.XSHG',
+    'h30470.CSI': 'H30470.XSHG',
+    'h30471.CSI': 'H30471.XSHG',
+    'h30472.CSI': 'H30472.XSHG',
+    'h30473.CSI': 'H30473.XSHG',
+    'h30474.CSI': 'H30474.XSHG',
+    'h30475.CSI': 'H30475.XSHG',
+    'h30476.CSI': 'H30476.XSHG',
+    'h30477.CSI': 'H30477.XSHG',
+    'h30478.CSI': 'H30478.XSHG',
+    'h30479.CSI': 'H30479.XSHG',
+    'h30480.CSI': 'H30480.XSHG',
+    'h30481.CSI': 'H30481.XSHG',
+    'h30482.CSI': 'H30482.XSHG',
+    'h30483.CSI': 'H30483.XSHG',
+    'h30484.CSI': 'H30484.XSHG',
+    'h30485.CSI': 'H30485.XSHG',
+    'h30486.CSI': 'H30486.XSHG',
+    'h30487.CSI': 'H30487.XSHG',
+    'h30488.CSI': 'H30488.XSHG',
+    'h30489.CSI': 'H30489.XSHG',
+    'h30490.CSI': 'H30490.XSHG',
+    'h30491.CSI': 'H30491.XSHG',
+    'h30492.CSI': 'H30492.XSHG',
+    'h30493.CSI': 'H30493.XSHG',
+    'h30494.CSI': 'H30494.XSHG',
+    'h30495.CSI': 'H30495.XSHG',
+    'h30496.CSI': 'H30496.XSHG',
+    'h30497.CSI': 'H30497.XSHG',
+    'h30498.CSI': 'H30498.XSHG',
+    'h30499.CSI': 'H30499.XSHG',
+    'h30500.CSI': 'H30500.XSHG',
+    'h30501.CSI': 'H30501.XSHG',
+    'h30502.CSI': 'H30502.XSHG',
+    'h30503.CSI': 'H30503.XSHG',
+    'h30504.CSI': 'H30504.XSHG',
+    'h30505.CSI': 'H30505.XSHG',
+    'h30506.CSI': 'H30506.XSHG',
+    'h30507.CSI': 'H30507.XSHG',
+    'h30508.CSI': 'H30508.XSHG',
+    'h30509.CSI': 'H30509.XSHG',
+    'h30510.CSI': 'H30510.XSHG',
+    'h30511.CSI': 'H30511.XSHG',
+    'h30512.CSI': 'H30512.XSHG',
+    'h30513.CSI': 'H30513.XSHG',
+    'h30514.CSI': 'H30514.XSHG',
+    'h30515.CSI': 'H30515.XSHG',
+    'h30516.CSI': 'H30516.XSHG',
+    'h30517.CSI': 'H30517.XSHG',
+    'h30518.CSI': 'H30518.XSHG',
+    'h30519.CSI': 'H30519.XSHG',
+    'h30520.CSI': 'H30520.XSHG',
+    'h30531.CSI': 'H30531.XSHG',
+    'h30532.CSI': 'H30532.XSHG',
+    'h30533.CSI': 'H30533.XSHG',
+    'h30534.CSI': 'H30534.XSHG',
+    'h30535.CSI': 'H30535.XSHG',
+    'h30537.CSI': 'H30537.XSHG',
+    'h30544.CSI': 'H30544.XSHG',
+    'h30545.CSI': 'H30545.XSHG',
+    'h30546.CSI': 'H30546.XSHG',
+    'h30547.CSI': 'H30547.XSHG',
+    'h30548.CSI': 'H30548.XSHG',
+    'h30550.CSI': 'H30550.XSHG',
+    'h30551.CSI': 'H30551.XSHG',
+    'h30552.CSI': 'H30552.XSHG',
+    'h30554.CSI': 'H30554.XSHG',
+    'h30555.CSI': 'H30555.XSHG',
+    'h30556.CSI': 'H30556.XSHG',
+    'h30557.CSI': 'H30557.XSHG',
+    'h30558.CSI': 'H30558.XSHG',
+    'h30559.CSI': 'H30559.XSHG',
+    'h30560.CSI': 'H30560.XSHG',
+    'h30561.CSI': 'H30561.XSHG',
+    'h30562.CSI': 'H30562.XSHG',
+    'h30563.CSI': 'H30563.XSHG',
+    'h30564.CSI': 'H30564.XSHG',
+    'h30565.CSI': 'H30565.XSHG',
+    'h30566.CSI': 'H30566.XSHG',
+    'h30567.CSI': 'H30567.XSHG',
+    'h30568.CSI': 'H30568.XSHG',
+    'h30569.CSI': 'H30569.XSHG',
+    'h30570.CSI': 'H30570.XSHG',
+    'h30572.CSI': 'H30572.XSHG',
+    'h30573.CSI': 'H30573.XSHG',
+    'h30574.CSI': 'H30574.XSHG',
+    'h30576.CSI': 'H30576.XSHG',
+    'h30577.CSI': 'H30577.XSHG',
+    'h30578.CSI': 'H30578.XSHG',
+    'h30579.CSI': 'H30579.XSHG',
+    'h30580.CSI': 'H30580.XSHG',
+    'h30581.CSI': 'H30581.XSHG',
+    'h30582.CSI': 'H30582.XSHG',
+    'h30583.CSI': 'H30583.XSHG',
+    'h30584.CSI': 'H30584.XSHG',
+    'h30585.CSI': 'H30585.XSHG',
+    'h30586.CSI': 'H30586.XSHG',
+    'h30587.CSI': 'H30587.XSHG',
+    'h30588.CSI': 'H30588.XSHG',
+    'h30590.CSI': 'H30590.XSHG',
+    'h30597.CSI': 'H30597.XSHG',
+    'h50036.CSI': 'H50036.XSHG',
+    'h50043.CSI': 'H50043.XSHG',
+    'h50044.CSI': 'H50044.XSHG',
+    'h50053.CSI': 'H50053.XSHG',
+    'h50054.CSI': 'H50054.XSHG',
+    'h50055.CSI': 'H50055.XSHG',
+    'h50056.CSI': 'H50056.XSHG',
+    'h50059.CSI': 'H50059.XSHG',
+    'h50060.CSI': 'H50060.XSHG',
+    'h50066.CSI': 'H50066.XSHG',
+    'h50069.CSI': 'H50069.XSHG',
+    'h00801.CSI': 'H00801.INDX',
+    'h00802.CSI': 'H00802.INDX',
+    'h00805.CSI': 'H00805.INDX',
+    'h00806.CSI': 'H00806.INDX',
+    'h00827.CSI': 'H00827.INDX',
+    'h00838.CSI': 'H00838.INDX',
+    'h00941.CSI': 'H00941.INDX',
+    'h00950.CSI': 'H00950.INDX',
+    'h00961.CSI': 'H00961.INDX',
+    'h00962.CSI': 'H00962.INDX',
+    'h00963.CSI': 'H00963.INDX',
+    'h00964.CSI': 'H00964.INDX',
+    'h00968.CSI': 'H00968.INDX',
+    'h00969.CSI': 'H00969.INDX',
+    'h00970.CSI': 'H00970.INDX',
+    'h00972.CSI': 'H00972.INDX',
+    'h00977.CSI': 'H00977.INDX',
+    'h00978.CSI': 'H00978.INDX',
+    'h00979.CSI': 'H00979.INDX',
+    'h00998.CSI': 'H00998.INDX',
+    'h20007.CSI': 'H20007.INDX',
+    'h20033.CSI': 'H20033.INDX',
+    'h20035.CSI': 'H20035.INDX',
+    'h20068.CSI': 'H20068.INDX',
+    'h20073.CSI': 'H20073.INDX',
+    'h20074.CSI': 'H20074.INDX',
+    'h20079.CSI': 'H20079.INDX',
+    'h20080.CSI': 'H20080.INDX',
+    'h20081.CSI': 'H20081.INDX',
+    'h20089.CSI': 'H20089.INDX',
+    'h30230.CSI': 'H30230.XSHG',
+    'h30231.CSI': 'H30231.XSHG',
+    'h30232.CSI': 'H30232.XSHG',
+    'h30233.CSI': 'H30233.XSHG',
+    'h30234.CSI': 'H30234.XSHG',
+    'h30235.CSI': 'H30235.XSHG',
+    'h30236.CSI': 'H30236.XSHG',
+    'h30237.CSI': 'H30237.XSHG',
+    'h30240.CSI': 'H30240.XSHG',
+    'h30241.CSI': 'H30241.XSHG',
+    'h30242.CSI': 'H30242.XSHG',
+    'h30243.CSI': 'H30243.XSHG',
+    'h30244.CSI': 'H30244.XSHG',
+    'h30245.CSI': 'H30245.XSHG',
+    'h30246.CSI': 'H30246.XSHG',
+    'h30247.CSI': 'H30247.XSHG',
+    'h11172.CSI': 'H11172.XSHG',
+    'h11173.CSI': 'H11173.XSHG',
+    'h11174.CSI': 'H11174.XSHG',
+    'h11175.CSI': 'H11175.XSHG',
+    'h11176.CSI': 'H11176.XSHG',
+    'h11177.CSI': 'H11177.XSHG',
+    'h11178.CSI': 'H11178.XSHG',
+    'h11179.CSI': 'H11179.XSHG',
+    'h01172.CSI': 'H01172.INDX',
+    'h01173.CSI': 'H01173.INDX',
+    'h01174.CSI': 'H01174.INDX',
+    'h01175.CSI': 'H01175.INDX',
+    'h01176.CSI': 'H01176.INDX',
+    'h01177.CSI': 'H01177.INDX',
+    'h01178.CSI': 'H01178.INDX',
+    'h01179.CSI': 'H01179.INDX',
+    'h20100.CSI': 'H20100.INDX',
+    'h20101.CSI': 'H20101.INDX',
+    'h20102.CSI': 'H20102.INDX',
+    'h20103.CSI': 'H20103.INDX',
+    'h20104.CSI': 'H20104.INDX',
+    'h20105.CSI': 'H20105.INDX',
+    'h20106.CSI': 'H20106.INDX',
+    'h20107.CSI': 'H20107.INDX',
+    'h20109.CSI': 'H20109.INDX',
+    'h20110.CSI': 'H20110.INDX',
+    'h20111.CSI': 'H20111.INDX',
+    'h20112.CSI': 'H20112.INDX',
+    'h20113.CSI': 'H20113.INDX',
+    'h20114.CSI': 'H20114.INDX',
+    'h20115.CSI': 'H20115.INDX',
+    'h20116.CSI': 'H20116.INDX',
+    'h20117.CSI': 'H20117.INDX',
+    'h20119.CSI': 'H20119.INDX',
+    'h01142.CSI': 'H01142.INDX',
+    'h01143.CSI': 'H01143.INDX',
+    'h01144.CSI': 'H01144.INDX',
+    'h01145.CSI': 'H01145.INDX',
+    'h01146.CSI': 'H01146.INDX',
+    'h01147.CSI': 'H01147.INDX',
+    'h01148.CSI': 'H01148.INDX',
+    'h01149.CSI': 'H01149.INDX',
+    'h01150.CSI': 'H01150.INDX',
+    'h01151.CSI': 'H01151.INDX',
+    'h01102.CSI': 'H01102.INDX',
+    'h01103.CSI': 'H01103.INDX',
+    'h01104.CSI': 'H01104.INDX',
+    'h01105.CSI': 'H01105.INDX',
+    'h01106.CSI': 'H01106.INDX',
+    'h01112.CSI': 'H01112.INDX',
+    'h01114.CSI': 'H01114.INDX',
+    'h01115.CSI': 'H01115.INDX',
+    'h01116.CSI': 'H01116.INDX',
+    'h01138.CS': 'H01138.INDX',
+    'h11101.CSI': 'H11101.XSHG',
+    'h11108.CSI': 'H11108.XSHG',
+    'h11118.CSI': 'H11118.XSHG',
+    'h11128.CSI': 'H11128.XSHG',
+    'h11138.CSI': 'H11138.XSHG',
+    'h11164.CSI': 'H11164.XSHG',
+    'h11165.CSI': 'H11165.XSHG',
+    'h11168.CSI': 'H11168.XSHG',
+    'h11169.CSI': 'H11169.XSHG',
+    'h01108.CSI': 'H01108.INDX',
+    'h01118.CSI': 'H01118.INDX',
+    'h01120.CSI': 'H01120.INDX',
+    'h01123.CSI': 'H01123.INDX',
+    'h01124.CSI': 'H01124.INDX',
+    'h01125.CSI': 'H01125.INDX',
+    'h01126.CSI': 'H01126.INDX',
+    'h01128.CSI': 'H01128.INDX',
+    'h01164.CSI': 'H01164.INDX',
+    'h01165.CSI': 'H01165.INDX',
+    'h01166.CSI': 'H01166.INDX',
+    'h01167.CSI': 'H01167.INDX',
+    'h01168.CSI': 'H01168.INDX',
+    'h01169.CSI': 'H01169.INDX',
+    'h01110.CSI': 'H01110.INDX',
+    'h01111.CSI': 'H01111.INDX',
+    'h11156.CSI': 'H11156.XSHG',
+    'h11157.CSI': 'H11157.XSHG',
+    'h11158.CSI': 'H11158.XSHG',
+    'h11159.CSI': 'H11159.XSHG',
+    'h01134.CSI': 'H01134.INDX',
+    'h01135.CSI': 'H01135.INDX',
+    'h01136.CSI': 'H01136.INDX',
+    'h01137.CSI': 'H01137.INDX',
+    'h01140.CSI': 'H01140.INDX',
+    'h01141.CSI': 'H01141.INDX',
+    'h01152.CSI': 'H01152.INDX',
+    'h01153.CSI': 'H01153.INDX',
+    'h01154.CSI': 'H01154.INDX',
+    'h01155.CSI': 'H01155.INDX',
+    'h01156.CSI': 'H01156.INDX',
+    'h01157.CSI': 'H01157.INDX',
+    'h01158.CSI': 'H01158.INDX',
+    'h01159.CSI': 'H01159.INDX',
+    'h01160.CSI': 'H01160.INDX',
+    'h01161.CSI': 'H01161.INDX',
+    'h01162.CSI': 'H01162.INDX',
+    'h01163.CSI': 'H01163.INDX',
+    'h20131.CSI': 'H20131.INDX',
+    'h20132.CSI': 'H20132.INDX',
+    'h11134.CSI': 'H11134.XSHG',
+    'h11135.CSI': 'H11135.XSHG',
+    'h01181.CSI': 'H01181.INDX',
+    'h01182.CSI': 'H01182.INDX',
+    'h01183.CSI': 'H01183.INDX',
+    'h01184.CSI': 'H01184.INDX',
+    'h20133.CSI': 'H20133.INDX',
+    'h20134.CSI': 'H20134.INDX',
+    'h20135.CSI': 'H20135.INDX',
+    'h20136.CSI': 'H20136.INDX',
+    'h11181.CSI': 'H11181.XSHG',
+    'h11182.CSI': 'H11182.XSHG',
+    'h30133.CSI': 'H30133.XSHG',
+    'h30134.CSI': 'H30134.XSHG',
+    'h30135.CSI': 'H30135.XSHG',
+    'h30136.CSI': 'H30136.XSHG',
+    'h11020.CSI': 'H11020.XSHG',
+    'h11021.CSI': 'H11021.XSHG',
+    'h11022.CSI': 'H11022.XSHG',
+    'h11023.CSI': 'H11023.XSHG',
+    'h11024.CSI': 'H11024.XSHG',
+    'h11025.CSI': 'H11025.XSHG',
+    'h11026.CSI': 'H11026.XSHG',
+    'h11027.CSI': 'H11027.XSHG',
+    'h11028.CSI': 'H11028.XSHG',
+    'h20267.CSI': 'H20267.INDX',
+    'h20268.CSI': 'H20268.INDX',
+    'h30267.CSI': 'H30267.XSHG',
+    'h30268.CSI': 'H30268.XSHG',
+    '921374.CSI': '921374.INDX',
+    '921496.CSI': '921496.INDX',
+    '921496HKD.CSI': '921496HKD.INDX',
+    'h11001.CSI': 'H11001.XSHG',
+    'h11002.CSI': 'H11002.XSHG',
+    'h11003.CSI': 'H11003.XSHG',
+    'h11004.CSI': 'H11004.XSHG',
+    'h11005.CSI': 'H11005.XSHG',
+    'h11009.CSI': 'H11009.XSHG',
+    'h11010.CSI': 'H11010.XSHG',
+    'h11015.CSI': 'H11015.XSHG',
+    'h11016.CSI': 'H11016.XSHG',
+    'h11076.CSI': 'H11076.XSHG',
+    '930871.CSI': '930871.INDX',
+    '930872.CSI': '930872.INDX',
+    '930873.CSI': '930873.INDX',
+    '930874.CSI': '930874.INDX',
+    'h11006.CSI': 'H11006.XSHG',
+    'h11017.CSI': 'H11017.XSHG',
+    'h11071.CSI': 'H11071.XSHG',
+    'h11075.CSI': 'H11075.XSHG',
+    'h11099.CSI': 'H11099.XSHG',
+    '000833.CSI': '000833.XSHG',
+    '000845.CSI': '000845.XSHG',
+    '930780.CSI': '930780.INDX',
+    'h11007.CSI': 'H11007.XSHG',
+    'h11008.CSI': 'H11008.XSHG',
+    'h11014.CSI': 'H11014.XSHG',
+    'h11018.CSI': 'H11018.XSHG',
+    'h11019.CSI': 'H11019.XSHG',
+    'h11070.CSI': 'H11070.XSHG',
+    'h11072.CSI': 'H11072.XSHG',
+    'h11073.CSI': 'H11073.XSHG',
+    'h11074.CSI': 'H11074.XSHG',
+    'h11078.CSI': 'H11078.XSHG',
+    'h11079.CSI': 'H11079.XSHG',
+    'h11087.CSI': 'H11087.XSHG',
+    'h11088.CSI': 'H11088.XSHG',
+    'h11089.CSI': 'H11089.XSHG',
+    'h11090.CSI': 'H11090.XSHG',
+    'h11091.CSI': 'H11091.XSHG',
+    'h11092.CSI': 'H11092.XSHG',
+    'h11093.CSI': 'H11093.XSHG',
+    'h11094.CSI': 'H11094.XSHG',
+    'h11096.CSI': 'H11096.XSHG',
+    'h11097.CSI': 'H11097.XSHG',
+    'h11185.CSI': 'H11185.XSHG',
+    'h30396.CSI': 'H30396.XSHG',
+    'h30521.CSI': 'H30521.XSHG',
+    '000832.CSI': '000832.XSHG',
+    '000923.CSI': '000923.XSHG',
+    '930849.CSI': '930849.INDX',
+    '930865.CSI': '930865.INDX',
+    '930866.CSI': '930866.INDX',
+    '930916.CSI': '930916.INDX',
+    '930954.CSI': '930954.INDX',
+    '931018.CSI': '931018.INDX',
+    '931078.CSI': '931078.INDX',
+    '931162.CSI': '931162.INDX',
+    '931172.CSI': '931172.INDX',
+    '931175.CSI': '931175.INDX',
+    '950045.CSI': '950045.INDX',
+}
+
+
+_to_wind_index_map = {j: i for i, j in _wind_index_map.items()}
+
+
+@ttl_cache(8 * 3600)
+def _all_futures():
+    # cache futures
+    df = all_instruments('Future')
+    r = {i.upper(): i for i in df['order_book_id'].tolist()}
+    s = df.set_index('order_book_id')['trading_code']
+    s = s[~s.index.str.endswith(('88', '99', '888', '889', '88A2', '88A3'))]
+    s = s.sort_index().drop_duplicates(keep='last').str.upper()
+    r.update({v: k for k, v in s.items()})
+    # cache commodity options
+    df = all_instruments('Option')
+    df = df[~df.exchange.isin(('XSHG', 'XSHE'))]
+    r.update({i.upper(): i for i in df['order_book_id'].tolist()})
+    s = df.set_index('order_book_id')['trading_code']
+    s = s.sort_index().drop_duplicates(keep='last').str.upper()
+    r.update({v: k for k, v in s.items()})
+    return r
+
+
+def _convert_to_wind(order_book_id):
+    if order_book_id.endswith(".XSHE"):
+        return order_book_id[:-4] + "SZ"
+    elif order_book_id.endswith(".XSHG"):
+        return order_book_id[:-4] + "SH"
+    elif order_book_id.endswith(".XHKG"):
+        return order_book_id[:-4] + "HK"
+
+    inst = instruments(order_book_id)
+    inst_type, exchange = inst.type, inst.exchange
+    if inst_type == 'Future':
+        if exchange != 'CZCE' or order_book_id.endswith(('88', '99', '888', '889')):
+            return order_book_id + '.' + _wind_exchange_map[exchange]
+        return order_book_id[:-4] + order_book_id[-3:] + '.CZC'
+    if inst_type == 'Spot':
+        return order_book_id[:-1]
+    if inst_type == 'Option':
+        if exchange == 'XSHE':
+            return order_book_id + '.SZ'
+        if exchange == 'XSHG':
+            return order_book_id + '.SH'
+        return inst.trading_code.upper() + '.' + _wind_exchange_map[exchange]
+
+    if inst_type == 'INDX':
+        if order_book_id[0] == 'C':
+            return order_book_id[:-4] + 'WI'
+        if order_book_id[0] == '8':
+            return order_book_id[:-4] + 'SI'
+        if order_book_id in _to_wind_index_map:
+            return _to_wind_index_map[order_book_id]
+        if exchange == 'XSHE':
+            return order_book_id[:-4].lower() + 'SZ'
+        return order_book_id[:-4].lower() + 'SH'
+    return order_book_id
+
+
+_wind_reg = re.compile(r'((?P<future>[A-Z]+\d{3,4})|((?P<option_id>((\d{8})|((?P<option>[A-Z]{1,2})(?P<option_suffix>\d{3,4}\-?(P|C)\-?\d{3,}))))))\.?(?P<ex>(CFE|SHF|INE|DCE|CZC|SH|SZ))')
+_future_re = re.compile(r'^([A-Z]+\d+([PC]\w+)?)')
+_current_year = str((datetime.date.today().year % 100) // 10)
+
+
+def _id_convert_one(order_book_id):  # noqa: C901
+    # hard code
+    if order_book_id in {"T00018", "T00018.SH", "T00018.XSHG", "SH.T00018"}:
+        return "990018.XSHG"
+    if order_book_id.endswith(".XHKG"):
+        return order_book_id
+    inst = instruments(order_book_id)
+    if inst is not None:
+        return inst.order_book_id
+
+    # WIND Future & Option
+    r = _wind_reg.match(order_book_id)
+    if r:
+        d = r.groupdict()
+        if d['future']:
+            return _all_futures().get(d['future'].upper(), d['future'])
+        if not d['option']:
+            return d['option_id']
+
+        if d['ex'] != 'CZC':
+            return r['option_id'].replace('-', '')
+        return d['option'] + _current_year + d['option_suffix'].replace('-', '')
+
+    # WIND ZZ INDX
+    if order_book_id in _wind_index_map:
+        return _wind_index_map[order_book_id]
+
+    # WIND SH INDX
+    if order_book_id[-3:] == '.SH':
+        if order_book_id[:2] in ('h0', 'h4'):
+            return order_book_id[:-2].upper() + 'INDX'
+
+    # WIND SW, ZX INDEX
+    if (order_book_id[-3:] == '.WI' and order_book_id[0] == 'C') or (
+            order_book_id[0] == '8' and order_book_id[-3:] == '.SI'):
+        return order_book_id[:-2] + 'INDX'
+
+    # WIND Spot
+    if order_book_id[-4:] == '.SGE':
+        return order_book_id + 'X'
+
+    if order_book_id.isdigit():
+        if order_book_id.startswith(("0", "3", "15")):
+            return order_book_id + ".XSHE"
+        elif order_book_id.startswith(("5", "6", "9")):
+            return order_book_id + ".XSHG"
+        else:
+            raise ValueError("order_book_ids should be str like 000001, 600000")
+
+    order_book_id = order_book_id.upper()
+    if order_book_id.endswith(".XSHG") or order_book_id.endswith(".XSHE"):
+        return order_book_id
+
+    if order_book_id.startswith(("SZ", "SH")):
+        suffix = order_book_id.replace(".", "")[2:]
+        prefix = order_book_id[:2]   # it's SZ or SH
+        # maybe CS order_book_id
+        if len(suffix) == 6 and suffix.isdigit():
+            return suffix + (".XSHG" if prefix == "SH" else ".XSHE")
+    elif order_book_id.endswith("SZ"):
+        return order_book_id.replace(".", "")[:-2] + ".XSHE"
+    elif order_book_id.endswith("SH"):
+        return order_book_id.replace(".", "")[:-2] + ".XSHG"
+
+    # 期货 & 商品期权
+    order_book_id = order_book_id.replace('-', '').split(".")[0]
+    m = _future_re.match(order_book_id)
+    if m:
+        i = m.groups()[0]
+        return _all_futures().get(i, order_book_id)
+
+    raise ValueError("unknown order_book_id: {}".format(order_book_id))
+
+
+@export_as_api
+@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
+def id_convert(order_book_ids, to=None):
+    """合约格式转换
+
+    :param order_book_ids: str 或 str list, 如'000001', 'SZ000001', '000001SZ',
+        '000001.SZ', 纯数字str默认为股票类型
+    :param to: str, 转换为指定类型目标代码，默认为米筐代码， 其他: normal， ricequant
+    :returns: str 或 str list, 米筐格式的合约
+
+    """
+    if to == 'normal' or to == 'wind':
+        _convert_one = lambda o: _convert_to_wind(_id_convert_one(o))
+    elif to is None or to == 'ricequant':
+        _convert_one = _id_convert_one
+    else:
+        raise ValueError('Unsupported destination: {}'.format(to))
+    with warnings.catch_warnings():
+        warnings.simplefilter("ignore")
+        if isinstance(order_book_ids, six.string_types):
+            return _convert_one(order_book_ids)
+        elif isinstance(order_book_ids, list):
+            return [_convert_one(o) for o in order_book_ids]
+        else:
+            raise ValueError("order_book_ids should be str or list")
+
+
+def _id_compatible(order_book_id):
+    if order_book_id.endswith("XSHE"):
+        return order_book_id[:-4] + "SZ"
+    elif order_book_id.endswith("XSHG"):
+        return order_book_id[:-4] + "SH"
+    else:
+        return order_book_id
+
+
+def _all_instruments_list(type_, market):
+    ins = [
+        Instrument(i)
+        for i in get_client().execute(
+            "all_instruments_by_type", instrument_type=type_, market=market
+        )
+    ]
+    ins.sort(key=lambda i: i.order_book_id)
+
+    extra_hk_instruments = []
+    if market == 'hk':  # 对港股需要根据 stock_connect 字段做拆分并替换该字段
+        suffix_map = {'sz': 'XSEC', 'sh': 'XSSC'}
+        for i in ins:
+            if not i.stock_connect:  # 港股中 stcok_connect 字段为空则设置该字段为 ''
+                setattr(i, 'stock_connect', '')
+                continue
+            for stock_connect in i.stock_connect:
+                _temp_instruments = deepcopy(i)
+                _temp_instruments.unique_id = _temp_instruments.unique_id[:-4] + suffix_map.get(stock_connect)
+                _temp_instruments.stock_connect = stock_connect + '_connect'
+                extra_hk_instruments.append(_temp_instruments)
+            i.stock_connect = i.stock_connect[0] if len(i.stock_connect) == 1 else '_and_'.join(i.stock_connect)
+
+    ins += extra_hk_instruments
+    return ins
+
+
+@ttl_cache(3 * 3600)
+def _all_cached_instruments_list(type_, market):
+    return _all_instruments_list(type_, market)
+
+
+@ttl_cache(3 * 3600)
+def _all_obid_to_type(market):
+    simple_insts = get_client().execute("all_obid_type_list", market)
+    result = {}
+    for inst in simple_insts:
+        # 统一一下值的类型, 后面使用起来简单点
+        result[inst["order_book_id"]] = (inst["type"], inst["order_book_id"])
+        result[inst["symbol"]] = (inst["type"], inst["order_book_id"])
+    return result
+
+
+@ttl_cache(3 * 3600)
+def _all_instruments_dict(type_, market):
+    ins = _all_cached_instruments_list(type_, market)
+    result = dict()
+    for i in ins:
+        if i.type == "Convertible":
+            result[_id_compatible(i.order_book_id)] = i
+
+        if getattr(i, "unique_id", None):  # 对港股 unique_id 作为 key 添加到 result dict
+            result[i.unique_id] = i
+
+        if i.order_book_id in result:  # 对港股存在退市后 order_book_id 复用的情况只存上市日期最晚的信息
+            if i.listed_date > result[i.order_book_id].listed_date:
+                result[i.order_book_id] = i
+        else:
+            result[i.order_book_id] = i
+
+    try:
+        result["沪深300"] = result["000300.XSHG"]
+        result["中证500"] = result["000905.XSHG"]
+        result[result["SSE180.INDX"].symbol] = result["000010.XSHG"]
+    except KeyError:
+        pass
+
+    return result
+
+
+def get_underlying_listed_date(underlying_symbol, ins_type, market="cn"):
+    """ 获取期货或者期权的某个品种的上市日期"""
+    ins_list = _all_cached_instruments_list(ins_type, market)
+    listed_dates = [i.listed_date for i in ins_list
+                    if (getattr(i, "underlying_symbol", "") == underlying_symbol
+                        and i.type == ins_type and i.listed_date != "0000-00-00")]
+
+    return min(listed_dates)
+
+
+def get_tick_size(order_book_id, market="cn"):
+    """获取合约价格最小变动单位
+
+    :param order_book_id: 如: FU1703
+    :param market: 如：'cn' (Default value = "cn")
+    :returns: float
+
+    """
+    return get_client().execute("get_tick_size", order_book_id, market=market)
+
+
+HK_STOCK_PRICE_SECTIONS = [0.25, 0.5, 10, 20, 100, 200, 500, 1000, 2000, 5000]
+HK_STOCK_TICK_SIZES = [0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 2, 5]
+
+
+# noinspection All
+class Instrument(object):
+    def __init__(self, d):
+        self.__dict__ = d
+
+    def __repr__(self):
+        if self.has_citics_info() and not hasattr(self, "_citics_industry_code"):
+            self.citics_industry()
+
+        return "{}({})".format(
+            type(self).__name__,
+            ", ".join(
+                [
+                    "{}={!r}".format(k.lstrip("_"), v)
+                    for k, v in self.__dict__.items()
+                    if v is not None
+                ]
+            ),
+        )
+
+    @property
+    def concept_names(self):
+        return get_concept_names(self.order_book_id)
+
+    def days_from_listed(self, date=None):
+        if self.listed_date == "0000-00-00":
+            return -1
+
+        date = to_date(date) if date else datetime.date.today()
+        if self.de_listed_date != "0000-00-00" and date > to_date(self.de_listed_date):
+            # 晚于退市日期
+            return -1
+
+        listed_date = to_date(self.listed_date)
+        ipo_days = (date - listed_date).days
+        return ipo_days if ipo_days >= 0 else -1
+
+    def days_to_expire(self, date=None):
+        if getattr(self, 'maturity_date', '0000-00-00') == '0000-00-00':
+            return -1
+
+        date = to_date(date) if date else datetime.date.today()
+
+        maturity_date = to_date(self.maturity_date)
+        days = (maturity_date - date).days
+        return days if days >= 0 else -1
+
+    def tick_size(self, price=None):
+        if self.exchange == "XHKG":
+            check_type(price, (int, float), "price")
+            index = bisect.bisect_left(HK_STOCK_PRICE_SECTIONS, price)
+            return HK_STOCK_TICK_SIZES[index]
+        elif self.type in ["CS", "INDX"]:
+            return 0.01
+        elif self.type in ["ETF", "LOF", "FUND", "FenjiB", "FenjiA", "FenjiMu", "PublicFund"]:
+            return 0.001
+        elif self.type == "Convertible":
+            return 0.001
+        elif self.type not in ["Future", "Option", "Spot"]:
+            return -1
+        return get_tick_size(self.order_book_id)
+
+    def has_citics_info(self):
+        return self.type == "CS" and self.exchange in {"XSHE", "XSHG"}
+
+    def citics_industry(self, date=None):
+        if self.has_citics_info():
+            if date is None:
+                if hasattr(self, "_citics_industry_code"):
+                    return (self._citics_industry_code, self._citics_industry_name)
+
+            if self.de_listed_date != '0000-00-00':
+                date = get_previous_trading_date(self.de_listed_date)
+
+            result = get_instrument_industry(self.order_book_id, date=date, level=1, source='citics_2019')
+            if result is None:
+                self._citics_industry_code, self._citics_industry_name = (None, None)
+                return None
+
+            self._citics_industry_code = result['first_industry_code'][0]
+            self._citics_industry_name = result['first_industry_name'][0]
+
+            return {"code": result.iloc[0, 0], "name": result.iloc[0, 1]}
+
+    @property
+    def citics_industry_code(self):
+        if not self.has_citics_info():
+            return None
+
+        if not hasattr(self, "_citics_industry_code"):
+            self.citics_industry()
+        return self._citics_industry_code
+
+    @property
+    def citics_industry_name(self):
+        if not self.has_citics_info():
+            return None
+
+        if not hasattr(self, "_citics_industry_name"):
+            self.citics_industry()
+        return self._citics_industry_name
+
+
+def _get_instrument(type_, order_book_id, market="cn"):
+    all_dict = _all_instruments_dict(type_, market)
+    return all_dict[order_book_id]
+
+
+@export_as_api
+@compatible_with_parm(name="country", value="cn", replace="market")
+@rqdatah_serialize(converter=http_conv_instruments)
+def instruments(order_book_ids, market="cn"):
+    """获取证券详细信息
+
+    :param order_book_ids: 证券ID列表, 如'000001.XSHE', 'AAPL.US'. 注意, 所有列表中的证券需要属于同一个国家。
+    :param market: 证券所属国家, 如 cn, us, hk (Default value = "cn")
+    :returns: 对应证券的列表
+
+    """
+    obid_to_type = _all_obid_to_type(market)
+    if isinstance(order_book_ids, six.string_types):
+        if order_book_ids not in obid_to_type:
+            warnings.warn('unknown order_book_id: {}'.format(order_book_ids))
+            return
+        ob_type, ob = obid_to_type[order_book_ids]
+        return _get_instrument(ob_type, ob, market)
+    result = []
+    for ob in order_book_ids:
+        if ob not in obid_to_type:
+            continue
+        ob_type, ob = obid_to_type[ob]
+        result.append(_get_instrument(ob_type, ob, market))
+    return result
+
+
+VALID_TYPES = {"CS", "ETF", "LOF", "INDX", "Future", "Spot", "Option", "Convertible", "Repo", "FUND"}
+
+
+@export_as_api
+@compatible_with_parm(name="country", value="cn", replace="market")
+def all_instruments(type=None, date=None, market="cn", **kwargs):
+    """获得某个国家的全部证券信息
+
+    :param type:  (Default value = None)
+    :param date:  (Default value = None)
+    :param market: cn, hk (Default value = "cn")
+    :kwargs
+        trading_market: [hk, all] (Default value = "hk")
+            hk: 港交所可购买的股票。对应返回stock_connect = null、sh、sz 的记录
+            all: 包括港交所、上交所、深交所可购买的港股。（对沪深港通支持股票均展示一条独立的unique_id捆绑的信息）,对应返回全部列表，即stock_connect = null、sz_and_sh、sh、sz、sz_connect、sh_connect
+    """
+
+    if type is not None:
+        type = ensure_list_of_string(type)
+        itype = set()
+        for t in type:
+            if t.upper() == "STOCK":
+                itype.add("CS")
+            elif t.upper() == "FUND":
+                itype = itype.union({"ETF", "LOF", "FUND"})
+            elif t.upper() == "INDEX":
+                itype.add("INDX")
+            elif t not in VALID_TYPES:
+                raise ValueError("invalid type: {}, chose any in {}".format(type, VALID_TYPES))
+            else:
+                itype.add(t)
+    else:
+        itype = VALID_TYPES
+
+    if date:
+        date = ensure_date_str(date)
+        cond = lambda x: (  # noqa: E731
+                (itype is None or x.type in itype)
+                and (x.listed_date <= date or x.listed_date == "0000-00-00")
+                and (
+                        x.de_listed_date == "0000-00-00"
+                        or (
+                                x.de_listed_date >= date
+                                and x.type in ("Future", "Option")
+                                or (x.de_listed_date > date and x.type not in ("Future", "Option"))
+                        )
+                )
+        )
+    else:
+        cond = lambda x: itype is None or x.type in itype  # noqa: E731
+
+    cached = kwargs.pop("cached", True)
+    trading_market = kwargs.pop("trading_market", 'hk')
+    if kwargs:
+        raise ValueError("Unknown kwargs: {}".format(kwargs))
+
+    if cached:
+        get_instrument_list = _all_cached_instruments_list
+    else:
+        get_instrument_list = _all_instruments_list
+
+    ins_ret = []
+    for t in itype:
+        ins_ret.extend(filter(cond, get_instrument_list(t, market)))
+
+    if market == 'hk' and trading_market == 'hk':
+        ins_ret = filter(lambda x: x.unique_id.endswith('.XHKG'), ins_ret)
+
+    if itype is not None and len(itype) == 1:
+        df = pd.DataFrame([v.__dict__ for v in ins_ret])
+        internal_fields = [f for f in df.columns if f.startswith('_')]
+        for f in internal_fields:
+            del df[f]
+    else:
+        df = pd.DataFrame(
+            [
+                (
+                    v.order_book_id,
+                    v.symbol,
+                    getattr(v, "abbrev_symbol", None),
+                    v.type,
+                    v.listed_date,
+                    v.de_listed_date,
+                )
+                for v in ins_ret
+            ],
+            columns=[
+                "order_book_id",
+                "symbol",
+                "abbrev_symbol",
+                "type",
+                "listed_date",
+                "de_listed_date",
+            ],
+        )
+    return df
+
+
+def to_sector_name(s):
+    for _, v in SectorCode.__dict__.items():
+        if isinstance(v, SectorCodeItem):
+            if v.cn == s or v.en == s or v.name == s:
+                return v.name
+    return s
+
+
+@export_as_api
+@compatible_with_parm(name="country", value="cn", replace="market")
+@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
+def sector(code, market="cn"):
+    """获取某个板块的股票列表。目前支持的板块分类具体可以查询以下网址:
+    https://www.ricequant.com/api/research/chn#research-API-sector
+
+    :param code: 可以使用板块英文名字如'Energy', 或者 sector_code.Energy
+    :param market: 地区代码, 如'cn' (Default value = "cn")
+    :returns: 板块全部股票列表
+
+    """
+    check_type(code, (SectorCodeItem, six.string_types), "code")
+    if isinstance(code, SectorCodeItem):
+        code = code.name
+    else:
+        code = to_sector_name(code)
+    return [
+        v.order_book_id
+        for v in _all_cached_instruments_list("CS", market)
+        if v.sector_code == code
+    ]
+
+
+def to_industry_code(s):
+    for _, v in IndustryCode.__dict__.items():
+        if isinstance(v, IndustryCodeItem):
+            if v.name == s:
+                return v.code
+    return s
+
+
+@export_as_api
+@compatible_with_parm(name="country", value="cn", replace="market")
+@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
+def industry(code, market="cn"):
+    """获取某个行业的股票列表。目前支持的行业列表具体可以查询以下网址:
+    https://www.ricequant.com/api/research/chn#research-API-industry
+
+    :param code: 行业代码,如 A01, 或者 industry_code.A01
+    :param market: 地区代码, 如'cn' (Default value = "cn")
+    :returns: 行业全部股票列表
+
+    """
+    if not isinstance(code, six.string_types):
+        code = code.code
+    else:
+        code = to_industry_code(code)
+    return [
+        v.order_book_id
+        for v in _all_cached_instruments_list("CS", market)
+        if v.industry_code == code
+    ]
+
+
+@export_as_api
+@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
+def get_future_contracts(underlying_symbol, date=None, market="cn"):
+    import rqdatac
+    import warnings
+
+    msg = "'get_future_contracts' is deprecated, please use 'futures.get_contracts' instead"
+    warnings.warn(msg, category=DeprecationWarning, stacklevel=2)
+    return rqdatac.futures.get_contracts(underlying_symbol, date, market)
+
+
+@export_as_api(namespace='futures')
+@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
+def get_contracts(underlying_symbol, date=None, market="cn"):
+    """获得中国市场某个时间某个期货品种正在交易的合约列表
+
+    :param underlying_symbol: 期货品种
+    :param date: 日期，可以为str，datetime，date，pd.Timestamp 等类型
+    :param market:  (Default value = "cn")
+    :returns: list of order book id
+
+    """
+    if date is None:
+        date = datetime.date.today()
+    date = ensure_date_str(date)
+
+    return sorted(
+        v.order_book_id
+        for v in _all_cached_instruments_list("Future", market)
+        if v.underlying_symbol == underlying_symbol
+        and v.listed_date != "0000-00-00"
+        and v.listed_date <= date <= v.de_listed_date
+    )
+
+
+@export_as_api
+def jy_instrument_industry(order_book_ids, date=None, level=1, expect_df=True, market="cn"):
+    """获取股票对应的聚源行业
+
+    :param order_book_ids: 股票列表，如['000001.XSHE', '000002.XSHE']
+    :param date: 如 '2015-01-07' (Default value = None)
+    :param level: 聚源等级，0, 1, 2, 3, 'customized' (Default value = 1)
+    :param expect_df: 返回 MultiIndex DataFrame (Default value = True)
+    :param market:  (Default value = "cn")
+    :returns: code, name
+        返回输入日期最近交易日的股票对应聚源行业以及对应的聚源等级
+
+    """
+    if level not in (0, 1, 2, 3, "customized"):
+        raise ValueError("level should in 0, 1, 2, 3, 'customized'")
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+    if not date:
+        date = ensure_date_int(get_previous_trading_date(datetime.date.today(), market=market))
+    else:
+        date = ensure_date_int(date)
+
+    df = get_client().execute("jy_instrument_industry", order_book_ids, date, level, market=market)
+    if not df:
+        return
+    if len(order_book_ids) == 1 and not expect_df:
+        r = df[0]
+        if level == 0:
+            return r["first_industry_name"], r["second_industry_name"], r["third_industry_name"]
+        return r["industry_name"]
+    return pd.DataFrame(df).set_index("order_book_id")
+
+
+@export_as_api(namespace="econ")
+def get_reserve_ratio(reserve_type="all", start_date=None, end_date=None, market="cn"):
+    """获取存款准备金率
+
+    :param reserve_type: 存款准备金详细类别，默认为'all'，目前仅支持'all'、'major'、'other'类别的查询
+    :param start_date: 开始查找时间，如'20180501'，默认为上一年的当天
+    :param end_date: 截止查找时间，如'20180501'，默认为当天
+    :param market:  (Default value = "cn")
+    :return: pd.DataFrame
+
+    """
+    check_items_in_container(reserve_type, ["all", "major", "other"], "reserve_type")
+
+    start_date, end_date = ensure_date_range(start_date, end_date, delta=relativedelta(years=1))
+
+    ret = get_client().execute(
+        "econ.get_reserve_ratio", reserve_type, start_date, end_date, market
+    )
+    if not ret:
+        return
+    columns = ["info_date", "effective_date", "reserve_type", "ratio_floor", "ratio_ceiling"]
+    df = pd.DataFrame(ret, columns=columns).set_index("info_date").sort_index(ascending=True)
+    return df
+
+
+@export_as_api(namespace="econ")
+def get_money_supply(start_date=None, end_date=None, market="cn"):
+    """获取货币供应量信息
+
+    :param start_date: 开始日期，默认为一年前
+    :param end_date: 结束日期，默认为今天
+    :param market:  (Default value = "cn")
+
+    """
+    check_items_in_container("info_date", ["info_date", "effective_date"], "date_type")
+    start_date, end_date = ensure_date_range(start_date, end_date, delta=relativedelta(years=1))
+
+    data = get_client().execute("econ.get_money_supply", start_date, end_date, market=market)
+    if not data:
+        return
+    columns = [
+        "info_date",
+        "effective_date",
+        "m2",
+        "m1",
+        "m0",
+        "m2_growth_yoy",
+        "m1_growth_yoy",
+        "m0_growth_yoy",
+    ]
+    df = pd.DataFrame(data, columns=columns).set_index("info_date").sort_index(ascending=True)
+    return df
+
+
+@export_as_api
+def get_main_shareholder(
+        order_book_ids, start_date=None, end_date=None, is_total=False, start_rank=None, end_rank=None, market="cn"
+):
+    """获取十大股东信息
+
+    :param order_book_ids: 股票代码
+    :param start_date: 开始日期，默认为一年前
+    :param end_date: 结束日期，默认为今天
+    :param is_total: 默认为 False, 即基于持有 A 股流通股。若为 True 则基于所有发行出的 A 股。
+    :param start_rank: 开始排名, int, 默认为最小排名
+    :param end_rank: 结束排名, int, 默认为最大排名
+    :param market:  (Default value = "cn")
+
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    check_items_in_container(is_total, [True, False], "is_total")
+    start_date, end_date = ensure_date_range(start_date, end_date, delta=relativedelta(years=1))
+
+    ret = get_client().execute(
+        "get_main_shareholder", order_book_ids, start_date, end_date, is_total,
+        start_rank=start_rank, end_rank=end_rank, market=market
+    )
+    if not ret:
+        return
+    columns = ['info_date', 'end_date', 'rank', 'shareholder_name', 'shareholder_attr', 'shareholder_kind',
+               'shareholder_type', 'hold_percent_total', 'hold_percent_float', 'share_pledge', 'share_freeze',
+               'order_book_id']
+    df = pd.DataFrame(ret, columns=columns).sort_values(by=['info_date', 'rank']).\
+        set_index(['order_book_id', 'info_date'])
+    return df
+
+
+@export_as_api
+def get_current_news(n=None, start_time=None, end_time=None, channels=None):
+    """获取新闻
+    :param n: 新闻条数, n 和 start_time/end_time 只能指定其一
+    :param start_time: 开始日期，默认为None,格式为%Y-%m-%d %H:%M:%S，如"2018-10-20 09:10:20"
+    :param end_time: 结束日期，默认为None,格式为%Y-%m-%d %H:%M:%S，如"2018-10-20 19:10:20"
+    :param channels: 新闻大类, 默认为None,返回每个大类n条新闻, 如 "global"，"forex", "commodity", "a-stock"
+    """
+
+    if start_time is not None or end_time is not None:
+        try:
+            start_time = datetime.datetime.strptime(start_time, "%Y-%m-%d %H:%M:%S")
+        except Exception:
+            raise ValueError('start_time should be str format like "%Y-%m-%d %H:%M:%S"')
+        try:
+            end_time = datetime.datetime.strptime(end_time, "%Y-%m-%d %H:%M:%S")
+        except Exception:
+            raise ValueError('end_time should be str format like "%Y-%m-%d %H:%M:%S"')
+        start_time = datetime_to_int14(start_time)
+        end_time = datetime_to_int14(end_time)
+        if n is not None:
+            raise ValueError(
+                "please either specify parameter n, or specify both start_time and end_time"
+            )
+        n = 1200
+    elif n is None:
+        n = 1
+    else:
+        n = ensure_int(n, "n")
+        if n < 1 or n > 1200:
+            raise ValueError("n should be in [0, 1200]")
+
+    if channels is not None:
+        channels = ensure_list_of_string(channels)
+        check_items_in_container(channels, ["global", "forex", "a-stock", "commodity"], "channels")
+    else:
+        channels = ["global", "forex", "a-stock", "commodity"]
+
+    data = get_client().execute("get_current_news", n, start_time, end_time, channels)
+    if not data:
+        return
+    df = pd.DataFrame(data, columns=["channel", "datetime", "content"])
+    return df.set_index("channel")
+
+
+@export_as_api(namespace="econ")
+def get_factors(factors, start_date, end_date, market="cn"):
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    factors = ensure_list_of_string(factors, "factors")
+    data = get_client().execute("econ.get_factors", factors, start_date, end_date, market=market)
+    if not data:
+        return
+    df = pd.DataFrame(data)
+    columns = ["factor", "info_date", "start_date", "end_date", "value"]
+    if "rice_create_tm" in df.columns:
+        df["rice_create_tm"] = pd.to_datetime(df["rice_create_tm"] + 3600 * 8, unit="s")
+        columns.append("rice_create_tm")
+    df = df.reindex(columns=columns)
+    df.set_index(["factor", "info_date"], inplace=True)
+    return df
+
+
+@export_as_api
+@rqdatah_serialize(converter=http_conv_trading_hours)
+def get_trading_hours(order_book_id, date=None, expected_fmt="str", frequency="1m", market="cn"):
+    """获取合约指定日期交易时间
+      :param order_book_id: 合约代码
+      :param date: 日期，默认为今天
+      :param expected_fmt: 返回格式，默认为str, 也支持datetime.time和datetime.datetime格式
+      :param frequency: 频率，默认为1m, 对应米筐分钟线时间段的起始, tick和1m相比区别在于每个交易时间段开盘往前移一分钟
+      :param market:  (Default value = "cn")
+
+      :return: trading_hours str or list of datetime.time/datetime.datetime list or None
+      """
+    date = ensure_date_or_today_int(date)
+    if not is_trading_date(date, market):
+        warnings.warn(" %d is not a trading date" % date)
+        return
+
+    ensure_string(order_book_id, "order_book_id")
+    ins = instruments(order_book_id)
+    if ins is None:
+        return
+
+    ensure_string_in(expected_fmt, ("str", "time", "datetime"), "expected_fmt")
+    ensure_string_in(frequency, ("1m", "tick"), "frequency")
+    date_str = to_date_str(date)
+
+    if ins.listed_date > date_str:
+        return
+
+    if ins.type in ("Future", "Option") and ins.de_listed_date < date_str and ins.de_listed_date != "0000-00-00":
+        return
+
+    if ins.type not in ("Future", "Option") and ins.de_listed_date <= date_str and ins.de_listed_date != "0000-00-00":
+        return
+    if ins.type == "Repo":
+        trading_hours = "09:31-11:30,13:01-15:30"
+    elif ins.type == "Spot":
+        if has_night_trading(date, market):
+            trading_hours = "20:01-02:30,09:01-15:30"
+        else:
+            trading_hours = "09:01-15:30"
+    elif ins.type not in ("Future", "Option") or (ins.type == "Option" and ins.exchange in ("XSHG", "XSHE")):
+        trading_hours = "09:31-11:30,13:01-15:00"
+    else:
+        trading_hours = get_client().execute("get_trading_hours", ins.underlying_symbol, date, market=market)
+        if trading_hours is None:
+            return
+        # 前一天放假或者该品种上市首日没有夜盘
+        no_night_trading = (not has_night_trading(date, market) or
+                            get_underlying_listed_date(ins.underlying_symbol, ins.type) == date_str)
+
+        if no_night_trading and not trading_hours.startswith("09"):
+            trading_hours = trading_hours.split(",", 1)[-1]
+
+    if frequency == "tick":
+        trading_hours = ",".join([s[:4] + str(int(s[4]) - 1) + s[5:] for s in trading_hours.split(",")])
+
+    if expected_fmt != "str":
+        trading_hours = [t.split("-", 1) for t in trading_hours.split(",")]
+        for i, (start, end) in enumerate(trading_hours):
+            trading_hours[i][0] = to_time(start)
+            trading_hours[i][1] = to_time(end)
+
+        if expected_fmt == "datetime":
+            td = int8_to_date(date)
+            prev_td = get_previous_trading_date(date)
+            prev_td_next = prev_td + datetime.timedelta(days=1)
+
+            for i, (start, end) in enumerate(trading_hours):
+                if start.hour > 16:
+                    start_dt = prev_td
+                    end_dt = start_dt if end.hour > 16 else prev_td_next
+                else:
+                    start_dt = end_dt = td
+                trading_hours[i][0] = datetime.datetime.combine(start_dt, start)
+                trading_hours[i][1] = datetime.datetime.combine(end_dt, end)
+
+    return trading_hours
+
+
+@export_as_api
+def get_private_placement(order_book_ids, start_date=None, end_date=None, progress="complete", issue_type="private", market="cn"):
+    """获取定增数据
+    :param order_book_ids: 合约代码
+    :param start_date: 开始日期，默认为None
+    :param end_date: 结束日期，默认为None
+    :param progress: 是否已完成定增，默认为complete。可选参数["complete", "incomplete", "all"]
+    :param issue_type: 默认为all。可选参数["private", "public", "all"]
+    :param market: (Default value = "cn")
+    :return:
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+    if start_date and end_date:
+        start_date, end_date = ensure_date_range(start_date, end_date)
+    elif start_date:
+        start_date = ensure_date_int(start_date)
+    elif end_date:
+        end_date = ensure_date_int(end_date)
+    ensure_string_in(progress, ["complete", "incomplete", "all"], "progress")
+    ensure_string_in(issue_type, ["private", "public", "all"], "issue_type")
+    issue_type_change = {"private": (21, 23), "public": (22,), "all": (21, 22, 23)}
+    issue_type = issue_type_change[issue_type]
+    data = get_client().execute(
+        "get_private_placement", order_book_ids, start_date, end_date, progress, issue_type=issue_type, market=market
+    )
+    if not data:
+        return
+    progress_map = {
+        10: "董事会预案", 20: "股东大会通过", 21: "国资委通过", 22: "发审委通过", 23: "证监会通过",
+        29: "实施中", 30: "实施完成", 40: "国资委否决", 41: "股东大会否决", 42: "证监会否决",
+        43: "发审委否决", 50: "延期实施", 60: "停止实施", 70: "暂缓发行"}
+    issue_type_map = {21: "非公开发行", 22: "公开发行", 23: "非公开发行配套融资"}
+    df = pd.DataFrame(data)
+    df["progress"] = df["progress"].map(progress_map)
+    df["issue_type"] = df["issue_type"].map(issue_type_map)
+    df.set_index(["order_book_id", "initial_info_date"], inplace=True)
+    return df
+
+
+@export_as_api
+def get_share_transformation(predecessor=None, market="cn"):
+    """
+    获取转股信息
+    :param predecessor: 换股前的股票代码。默认为空，返回所有转股信息
+    :param market:  (Default value = "cn")
+    :return pd.DataFrame
+    """
+    if predecessor:
+        predecessor = ensure_order_book_id(predecessor)
+    data = get_client().execute("get_share_transformation", predecessor, market=market)
+    if not data:
+        return
+    columns = [
+        "predecessor", "successor", "effective_date", "share_conversion_ratio", "predecessor_delisted",
+        "discretionary_execution", "predecessor_delisted_date", "event"
+    ]
+    df = pd.DataFrame(data, columns=columns)
+    df = df.sort_values('predecessor').reset_index(drop=True)
+    return df
+
+
+@export_as_api(namespace="user")
+@rqdatah_serialize(converter=http_conv_dict_to_csv)
+def get_quota():
+    """
+    获取用户配额信息
+    :return dict
+        bytes_limit：每日流量使用上限（单位为字节），如为0则表示不受限
+        bytes_used：当日已用流量（单位为字节）
+        remaining_days：账号剩余有效天数, 如为0则表示不受限
+        license_type：账户类型(FULL: 付费类型，TRIAL: 试用类型， EDU: 教育网类型, OTHER: 其他类型)
+    """
+    data = get_client().execute("user.get_quota")
+    if data['bytes_limit'] > 0 and data["bytes_used"] >= data["bytes_limit"]:
+        warnings.warn("Traffic usage has been exceeded quota,"
+                      "Please call us at 0755-22676337 to upgrade"
+                      "your contract.")
+    return data
+
+
+_CHECK_CATEGORIES = ("stock_1d", "stock_1m", "future_1d", "future_1m", "index_1d", "index_1m")
+
+
+@export_as_api()
+def get_update_status(categories):
+    """
+    获取数据最新日期
+    :param categories: str or list or str, 数据类型，支持类型有:
+        stock_1d: 股票日线
+        stock_1m: 股票分钟线
+        future_1d: 期货日线
+        future_1m: 期货分钟线
+        index_1d：指数日线
+        index_1m：指数分钟线
+
+    :return datetime.datetime or dict(category=datetime.datetime)
+    """
+    categories = ensure_list_of_string(categories, "categories")
+    check_items_in_container(categories, _CHECK_CATEGORIES, "categories")
+    ret = get_client().execute("get_update_status", categories)
+    if len(categories) == 1:
+        return ret[0]["date"]
+    return {r["category"]: r["date"] for r in ret}
+
+
+@export_as_api()
+def info():
+    """
+    打印账户信息
+    :return None
+    """
+    get_client().info()
+
+
+@export_as_api()
+def get_basic_info(order_book_ids=None, fields=("order_book_id", "symbol"), market='cn'):
+    if order_book_ids is not None:
+        order_book_ids = ensure_list_of_string(order_book_ids, "order_book_ids")
+    if fields is not None:
+        fields = ensure_list_of_string(fields, "fields")
+
+    ret = get_client().execute("get_basic_info", order_book_ids, fields, market=market)
+    if not ret:
+        return
+    columns, data = ret
+    return pd.DataFrame(data, columns=columns)
+
+
+@export_as_api()
+def get_spot_benchmark_price(order_book_ids, start_date=None, end_date=None):
+    """
+        获取上海黄金交易所基准价数据: 有早盘价和午盘价
+    :param order_book_ids: 现货标的
+    :param start_date: 开始日期，默认为None
+    :param end_date: 结束日期，默认为None
+    :return: pd.DataFrame
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, type="Spot", market="cn")
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    data = get_client().execute("get_spot_benchmark_price", order_book_ids, start_date=start_date, end_date=end_date)
+    if not data:
+        return
+    df = pd.DataFrame(data)
+    df.sort_values(by=["order_book_id", "date"], inplace=True)
+    df.set_index(keys=["order_book_id", "date"], inplace=True)
+    return df
```

## rqdatac/services/calendar.py

 * *Ordering differences only*

```diff
@@ -1,197 +1,197 @@
-# -*- coding: utf-8 -*-
-import bisect
-import datetime
-from rqdatac.client import get_client
-from rqdatac.utils import int8_to_date, int_to_datetime
-from rqdatac.validators import ensure_date_int
-from rqdatac.decorators import export_as_api, ttl_cache, compatible_with_parm
-from rqdatac.rqdatah_helper import rqdatah_serialize, http_conv_list_to_csv
-
-
-@ttl_cache(24 * 3600)
-def _get_all_trading_dates(market):
-    return get_client().execute("get_all_trading_dates", market=market)
-
-
-def _map_expect_type(ty, fmt, dates):
-    if ty == "int":
-        return dates
-    if ty == "datetime":
-        return [int_to_datetime(dt) for dt in dates]
-    if ty == "date":
-        return [int8_to_date(dt) for dt in dates]
-    if ty == "str":
-        return [int_to_datetime(dt).strftime(fmt) for dt in dates]
-    raise TypeError(ty)
-
-
-def _expect_type(ty, fmt, date):
-    return _map_expect_type(ty, fmt, [date])[0]
-
-
-def get_trading_dates_in_type(start_date, end_date, expect_type="datetime", fmt=None, market="cn"):
-    """获取两个日期之间的交易日列表
-
-    :param start_date: 开始日期
-    :param end_date: 结束日期
-    :param expect_type:  (Default value = "datetime")
-    :param fmt:  (Default value = None)
-    :param market:  (Default value = "cn")
-
-    """
-    start_date = ensure_date_int(start_date)
-    end_date = ensure_date_int(end_date)
-    dates = _get_all_trading_dates(market)
-    start_pos = bisect.bisect_left(dates, start_date)
-    end_pos = bisect.bisect_right(dates, end_date)
-    return _map_expect_type(expect_type, fmt, dates[start_pos:end_pos])
-
-
-@export_as_api
-@compatible_with_parm(name="country", value="cn", replace="market")
-@rqdatah_serialize(converter=http_conv_list_to_csv, name='trading_date')
-def get_trading_dates(start_date, end_date, market="cn"):
-    """获取两个日期之间的交易日列表
-
-    :param start_date: 如 '2013-01-04'
-    :param end_date: 如 '2013-01-04'
-    :param market: 地区代码, 如 'cn' (Default value = "cn")
-    :returns: 日期列表
-
-    """
-    start_date = ensure_date_int(start_date)
-    end_date = ensure_date_int(end_date)
-    dates = _get_all_trading_dates(market)
-    start_pos = bisect.bisect_left(dates, start_date)
-    end_pos = bisect.bisect_right(dates, end_date)
-    return [int8_to_date(i) for i in dates[start_pos:end_pos]]
-
-
-@export_as_api
-@compatible_with_parm(name="country", value="cn", replace="market")
-@rqdatah_serialize(converter=http_conv_list_to_csv, name='trading_date')
-def get_next_trading_date(date, n=1, market="cn"):
-    """获取后一交易日
-
-    :param date: 日期
-    :parm n: 日期间隔
-    :param market:  (Default value = "cn")
-
-    """
-    if n < 1:
-        raise ValueError("n: except a positive value, got {}".format(n))
-    date = ensure_date_int(date)
-    dates = _get_all_trading_dates(market)
-    pos = bisect.bisect_right(dates, date)
-    if pos + n - 1 < len(dates):
-        return int8_to_date(dates[pos + n - 1])
-    return int8_to_date(dates[-1])
-
-
-@export_as_api
-@compatible_with_parm(name="country", value="cn", replace="market")
-@rqdatah_serialize(converter=http_conv_list_to_csv, name='trading_date')
-def get_previous_trading_date(date, n=1, market="cn"):
-    """获取前一交易日
-
-    :param date: 日期
-    :parm n: 日期间隔
-    :param market:  (Default value = "cn")
-
-    """
-    if n < 1:
-        raise ValueError("n: except a positive value, got {}".format(n))
-    date = ensure_date_int(date)
-    dates = _get_all_trading_dates(market)
-    pos = bisect.bisect_left(dates, date)
-    if pos > n:
-        return int8_to_date(dates[pos - n])
-    return int8_to_date(dates[0])
-
-
-@export_as_api
-def get_latest_trading_date(market="cn"):
-    """获取最近的一个交易日
-
-    :param market:  (Default value = "cn")
-
-    """
-    tomorrow = datetime.date.today() + datetime.timedelta(days=1)
-    return get_previous_trading_date(tomorrow, market=market)
-
-
-@export_as_api
-def get_future_latest_trading_date(market="cn"):
-    """获取期货市场最近的一个交易日
-
-    :param market:  (Default value = "cn")
-
-    """
-    now = datetime.datetime.now()
-    latest_trading_date = get_latest_trading_date(market)
-    if now < datetime.datetime.combine(latest_trading_date, datetime.time(20, 55)):
-        return latest_trading_date
-    return get_next_trading_date(latest_trading_date, market=market)
-
-
-@export_as_api
-def trading_date_offset(date, offset, market="cn"):
-    """获取当前日期之前（或之后）的一个交易日
-
-    :param date: 日期
-    :param offset: 日期间隔
-    :param market:  (Default value = "cn")
-
-    """
-    date = ensure_date_int(date)
-    dates = _get_all_trading_dates(market)
-    if offset < 0:
-        pos = bisect.bisect_left(dates, date) + offset
-    else:
-        pos = bisect.bisect_right(dates, date) + offset
-
-    return int8_to_date(dates[pos])
-
-
-@export_as_api
-def is_trading_date(date, market="cn"):
-    """判断日期是否为交易日
-    :param date: 日期 如20190401
-    :param market:  (Default value = "cn")
-    :returns: bool
-    """
-    date = ensure_date_int(date)
-    dates = _get_all_trading_dates(market)
-    return date in dates
-
-
-def get_prev_weekday(date):
-    """获取上一个工作日，周二到周四返回昨天，周一返回上周五
-    :param date : date_int 如 如20190411
-    :returns: date_int 如20190413
-    """
-    date = int8_to_date(date)
-    weekday = date.weekday()
-    if weekday == 0:
-        days = 3
-    else:
-        days = 1
-    return date - datetime.timedelta(days=days)
-
-
-@export_as_api
-def has_night_trading(date, market="cn"):
-    """判断交易日是否有夜盘
-    :param date: 日期 如20190401
-    :param market:  (Default value = "cn")
-    :returns: bool
-    """
-    date = ensure_date_int(date)
-    if not is_trading_date(date, market):
-        return False
-    return is_trading_date(get_prev_weekday(date))
-
-
-@ttl_cache(3)
-def current_trading_date(market='cn'):
-    return get_client().execute('current_trading_date', market=market)
+# -*- coding: utf-8 -*-
+import bisect
+import datetime
+from rqdatac.client import get_client
+from rqdatac.utils import int8_to_date, int_to_datetime
+from rqdatac.validators import ensure_date_int
+from rqdatac.decorators import export_as_api, ttl_cache, compatible_with_parm
+from rqdatac.rqdatah_helper import rqdatah_serialize, http_conv_list_to_csv
+
+
+@ttl_cache(24 * 3600)
+def _get_all_trading_dates(market):
+    return get_client().execute("get_all_trading_dates", market=market)
+
+
+def _map_expect_type(ty, fmt, dates):
+    if ty == "int":
+        return dates
+    if ty == "datetime":
+        return [int_to_datetime(dt) for dt in dates]
+    if ty == "date":
+        return [int8_to_date(dt) for dt in dates]
+    if ty == "str":
+        return [int_to_datetime(dt).strftime(fmt) for dt in dates]
+    raise TypeError(ty)
+
+
+def _expect_type(ty, fmt, date):
+    return _map_expect_type(ty, fmt, [date])[0]
+
+
+def get_trading_dates_in_type(start_date, end_date, expect_type="datetime", fmt=None, market="cn"):
+    """获取两个日期之间的交易日列表
+
+    :param start_date: 开始日期
+    :param end_date: 结束日期
+    :param expect_type:  (Default value = "datetime")
+    :param fmt:  (Default value = None)
+    :param market:  (Default value = "cn")
+
+    """
+    start_date = ensure_date_int(start_date)
+    end_date = ensure_date_int(end_date)
+    dates = _get_all_trading_dates(market)
+    start_pos = bisect.bisect_left(dates, start_date)
+    end_pos = bisect.bisect_right(dates, end_date)
+    return _map_expect_type(expect_type, fmt, dates[start_pos:end_pos])
+
+
+@export_as_api
+@compatible_with_parm(name="country", value="cn", replace="market")
+@rqdatah_serialize(converter=http_conv_list_to_csv, name='trading_date')
+def get_trading_dates(start_date, end_date, market="cn"):
+    """获取两个日期之间的交易日列表
+
+    :param start_date: 如 '2013-01-04'
+    :param end_date: 如 '2013-01-04'
+    :param market: 地区代码, 如 'cn' (Default value = "cn")
+    :returns: 日期列表
+
+    """
+    start_date = ensure_date_int(start_date)
+    end_date = ensure_date_int(end_date)
+    dates = _get_all_trading_dates(market)
+    start_pos = bisect.bisect_left(dates, start_date)
+    end_pos = bisect.bisect_right(dates, end_date)
+    return [int8_to_date(i) for i in dates[start_pos:end_pos]]
+
+
+@export_as_api
+@compatible_with_parm(name="country", value="cn", replace="market")
+@rqdatah_serialize(converter=http_conv_list_to_csv, name='trading_date')
+def get_next_trading_date(date, n=1, market="cn"):
+    """获取后一交易日
+
+    :param date: 日期
+    :parm n: 日期间隔
+    :param market:  (Default value = "cn")
+
+    """
+    if n < 1:
+        raise ValueError("n: except a positive value, got {}".format(n))
+    date = ensure_date_int(date)
+    dates = _get_all_trading_dates(market)
+    pos = bisect.bisect_right(dates, date)
+    if pos + n - 1 < len(dates):
+        return int8_to_date(dates[pos + n - 1])
+    return int8_to_date(dates[-1])
+
+
+@export_as_api
+@compatible_with_parm(name="country", value="cn", replace="market")
+@rqdatah_serialize(converter=http_conv_list_to_csv, name='trading_date')
+def get_previous_trading_date(date, n=1, market="cn"):
+    """获取前一交易日
+
+    :param date: 日期
+    :parm n: 日期间隔
+    :param market:  (Default value = "cn")
+
+    """
+    if n < 1:
+        raise ValueError("n: except a positive value, got {}".format(n))
+    date = ensure_date_int(date)
+    dates = _get_all_trading_dates(market)
+    pos = bisect.bisect_left(dates, date)
+    if pos > n:
+        return int8_to_date(dates[pos - n])
+    return int8_to_date(dates[0])
+
+
+@export_as_api
+def get_latest_trading_date(market="cn"):
+    """获取最近的一个交易日
+
+    :param market:  (Default value = "cn")
+
+    """
+    tomorrow = datetime.date.today() + datetime.timedelta(days=1)
+    return get_previous_trading_date(tomorrow, market=market)
+
+
+@export_as_api
+def get_future_latest_trading_date(market="cn"):
+    """获取期货市场最近的一个交易日
+
+    :param market:  (Default value = "cn")
+
+    """
+    now = datetime.datetime.now()
+    latest_trading_date = get_latest_trading_date(market)
+    if now < datetime.datetime.combine(latest_trading_date, datetime.time(20, 55)):
+        return latest_trading_date
+    return get_next_trading_date(latest_trading_date, market=market)
+
+
+@export_as_api
+def trading_date_offset(date, offset, market="cn"):
+    """获取当前日期之前（或之后）的一个交易日
+
+    :param date: 日期
+    :param offset: 日期间隔
+    :param market:  (Default value = "cn")
+
+    """
+    date = ensure_date_int(date)
+    dates = _get_all_trading_dates(market)
+    if offset < 0:
+        pos = bisect.bisect_left(dates, date) + offset
+    else:
+        pos = bisect.bisect_right(dates, date) + offset
+
+    return int8_to_date(dates[pos])
+
+
+@export_as_api
+def is_trading_date(date, market="cn"):
+    """判断日期是否为交易日
+    :param date: 日期 如20190401
+    :param market:  (Default value = "cn")
+    :returns: bool
+    """
+    date = ensure_date_int(date)
+    dates = _get_all_trading_dates(market)
+    return date in dates
+
+
+def get_prev_weekday(date):
+    """获取上一个工作日，周二到周四返回昨天，周一返回上周五
+    :param date : date_int 如 如20190411
+    :returns: date_int 如20190413
+    """
+    date = int8_to_date(date)
+    weekday = date.weekday()
+    if weekday == 0:
+        days = 3
+    else:
+        days = 1
+    return date - datetime.timedelta(days=days)
+
+
+@export_as_api
+def has_night_trading(date, market="cn"):
+    """判断交易日是否有夜盘
+    :param date: 日期 如20190401
+    :param market:  (Default value = "cn")
+    :returns: bool
+    """
+    date = ensure_date_int(date)
+    if not is_trading_date(date, market):
+        return False
+    return is_trading_date(get_prev_weekday(date))
+
+
+@ttl_cache(3)
+def current_trading_date(market='cn'):
+    return get_client().execute('current_trading_date', market=market)
```

## rqdatac/services/concept.py

 * *Ordering differences only*

```diff
@@ -1,64 +1,64 @@
-# -*- coding: utf-8 -*-
-from rqdatac.validators import ensure_date_or_today_int
-from rqdatac.client import get_client
-from rqdatac.decorators import export_as_api
-from rqdatac.rqdatah_helper import rqdatah_serialize, http_conv_list_to_csv
-
-
-@export_as_api
-@rqdatah_serialize(converter=http_conv_list_to_csv, name='concept')
-def concept_list(date=None, market="cn"):
-    """获取所有股票概念.
-
-    :param date: 可指定日期，默认按当前日期返回.
-    :param market: 地区代码, 如 'cn' (Default value = "cn")
-    :returns: 符合指定日期内出现过的所有概念列表
-
-    """
-    date = ensure_date_or_today_int(date)
-    return get_client().execute("concept_list", date, market=market)
-
-
-@export_as_api
-@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
-def concept(*concepts, **kwargs):
-    """获取对应某个概念的股票列表。
-
-    可指定日期，默认按当前日期返回。目前支持的概念列表可以查询以下网址:
-    https://www.ricequant.com/api/research/chn#concept-API-industry
-
-    :param concepts: 概念字符串,如 '民营医院'
-    :param date: 可指定日期，默认按当前日期返回.
-    :param market: 地区代码, 如 'cn'
-    :returns: 符合对应概念的股票列表
-
-    """
-    date = kwargs.pop("date", None)
-    market = kwargs.pop("market", "cn")
-    date = ensure_date_or_today_int(date)
-    if kwargs:
-        raise ValueError('unknown kwargs: {}'.format(kwargs))
-    return get_client().execute("concept", concepts, date, market=market)
-
-
-@export_as_api
-@rqdatah_serialize(converter=http_conv_list_to_csv, name='concept')
-def concept_names(order_book_id, date=None, expect_type="str", market="cn"):
-    """获取证券所属的概念列表。
-
-    :param order_book_id: 证券ID
-    :param date: 可指定日期，默认按当前日期返回。
-    :param expect_type: 期望返回结果类型，可选址为："str"：返回字符串，"list"：返回列表，默认为str。
-    :param market: 地区代码, 如 "cn" (Default value = "cn")
-    :returns: 概念列表
-
-    """
-
-    date = ensure_date_or_today_int(date)
-    data = get_client().execute("concept_names", order_book_id, date, market=market)
-    if expect_type == "str":
-        return data
-    elif expect_type == "list":
-        return data.split("|")
-    raise ValueError("expect_type should be str like 'str' or 'list'")
-
+# -*- coding: utf-8 -*-
+from rqdatac.validators import ensure_date_or_today_int
+from rqdatac.client import get_client
+from rqdatac.decorators import export_as_api
+from rqdatac.rqdatah_helper import rqdatah_serialize, http_conv_list_to_csv
+
+
+@export_as_api
+@rqdatah_serialize(converter=http_conv_list_to_csv, name='concept')
+def concept_list(date=None, market="cn"):
+    """获取所有股票概念.
+
+    :param date: 可指定日期，默认按当前日期返回.
+    :param market: 地区代码, 如 'cn' (Default value = "cn")
+    :returns: 符合指定日期内出现过的所有概念列表
+
+    """
+    date = ensure_date_or_today_int(date)
+    return get_client().execute("concept_list", date, market=market)
+
+
+@export_as_api
+@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
+def concept(*concepts, **kwargs):
+    """获取对应某个概念的股票列表。
+
+    可指定日期，默认按当前日期返回。目前支持的概念列表可以查询以下网址:
+    https://www.ricequant.com/api/research/chn#concept-API-industry
+
+    :param concepts: 概念字符串,如 '民营医院'
+    :param date: 可指定日期，默认按当前日期返回.
+    :param market: 地区代码, 如 'cn'
+    :returns: 符合对应概念的股票列表
+
+    """
+    date = kwargs.pop("date", None)
+    market = kwargs.pop("market", "cn")
+    date = ensure_date_or_today_int(date)
+    if kwargs:
+        raise ValueError('unknown kwargs: {}'.format(kwargs))
+    return get_client().execute("concept", concepts, date, market=market)
+
+
+@export_as_api
+@rqdatah_serialize(converter=http_conv_list_to_csv, name='concept')
+def concept_names(order_book_id, date=None, expect_type="str", market="cn"):
+    """获取证券所属的概念列表。
+
+    :param order_book_id: 证券ID
+    :param date: 可指定日期，默认按当前日期返回。
+    :param expect_type: 期望返回结果类型，可选址为："str"：返回字符串，"list"：返回列表，默认为str。
+    :param market: 地区代码, 如 "cn" (Default value = "cn")
+    :returns: 概念列表
+
+    """
+
+    date = ensure_date_or_today_int(date)
+    data = get_client().execute("concept_names", order_book_id, date, market=market)
+    if expect_type == "str":
+        return data
+    elif expect_type == "list":
+        return data.split("|")
+    raise ValueError("expect_type should be str like 'str' or 'list'")
+
```

## rqdatac/services/consensus.py

 * *Ordering differences only*

```diff
@@ -1,1245 +1,1245 @@
-# -*- coding: utf-8 -*-
-import datetime
-import warnings
-from collections import defaultdict
-
-import pandas as pd
-import numpy as np
-from rqdatac.utils import today_int
-
-from rqdatac.validators import (
-    ensure_list_of_string,
-    ensure_order_book_ids,
-    check_items_in_container,
-    ensure_date_range,
-    ensure_date_int,
-    ensure_string_in,
-)
-
-from rqdatac.client import get_client
-from rqdatac.decorators import export_as_api, ttl_cache, deprecated
-
-
-CONSENSUS_INDICATOR_FIELDS = [
-    'net_profit_t',
-    'net_profit_t1',
-    'net_profit_t2',
-    'revenue_t',
-    'revenue_t1',
-    'revenue_t2',
-    'net_asset_t',
-    'net_asset_t1',
-    'net_asset_t2',
-    'cash_from_operating_activities_t',
-    'cash_from_operating_activities_t1',
-    'cash_from_operating_activities_t2',
-    'profit_from_operation_t',
-    'profit_from_operation_t1',
-    'profit_from_operation_t2',
-    'cost_of_goods_sold_t',
-    'cost_of_goods_sold_t1',
-    'cost_of_goods_sold_t2',
-    'profit_before_tax_t',
-    'profit_before_tax_t1',
-    'profit_before_tax_t2',
-    'ebit_t',
-    'ebit_t1',
-    'ebit_t2',
-    'operating_revenue_per_share_t',
-    'operating_revenue_per_share_t1',
-    'operating_revenue_per_share_t2',
-    'eps_t',
-    'eps_t1',
-    'eps_t2',
-    'bps_t',
-    'bps_t1',
-    'bps_t2',
-    'share_cap_chg_date',
-    'report_main_id',
-    'grade_coef',
-    'targ_price',
-    'ebitda_t',
-    'ebitda_t1',
-    'ebitda_t2',
-    'profit_res_t',
-    'profit_res_t1',
-    'profit_res_t2',
-    'operate_cash_flow_per_share_t',
-    'operate_cash_flow_per_share_t1',
-    'operate_cash_flow_per_share_t2',
-    'profit_chg_t',
-    'profit_chg_t1',
-    'profit_chg_t2',
-    'grade_chg_t',
-    'grade_chg_t1',
-    'grade_chg_t2',
-    'targ_price_chg_t',
-    'targ_price_chg_t1',
-    'targ_price_chg_t2',
-    'chg_reason_t',
-    'chg_reason_t1',
-    'chg_reason_t2',
-    'create_time',
-    'summary',
-]
-
-NON_NUMERIC_FIELDS = [
-    'share_cap_chg_date',
-    'report_main_id',
-    'chg_reason_t',
-    'chg_reason_t1',
-    'chg_reason_t2',
-    'create_time',
-    'summary',
-]
-
-
-DTYPES = {k: '<f8' for k in CONSENSUS_INDICATOR_FIELDS if k not in NON_NUMERIC_FIELDS}
-DTYPES['fiscal_year'] = '<u4'
-DTYPES['data_source'] = '<f2'
-
-
-CONSENSUS_PRICE_FIELDS = [
-    'half_year_target_price',
-    'one_year_target_price',
-    'quarter_recommendation',
-    'half_year_recommendation',
-    'one_year_recommendation',
-]
-
-CONSENSUS_PRICE_FIELDS_MAP = {
-    'half_year_target_price': ('price_raw', 'price_prd', 'M06'),
-    'one_year_target_price': ('price_raw', 'price_prd', 'Y01'),
-    'quarter_recommendation': ('grd_coef', 'grd_prd', '1'),
-    'half_year_recommendation': ('grd_coef', 'grd_prd', '2'),
-    'one_year_recommendation': ('grd_coef', 'grd_prd', '3'),
-}
-
-PRICE_DTYPES = {
-    'half_year_target_price': '<f8',
-    'one_year_target_price': '<f8',
-    'quarter_recommendation': '<f8',
-    'half_year_recommendation': '<f8',
-    'one_year_recommendation': '<f8',
-    'price_raw': '<f8',
-}
-
-
-@export_as_api(namespace='consensus')
-def get_indicator(order_book_ids, fiscal_year, fields=None, start_date=None, end_date=None, date_rule=None, market='cn'):
-    """
-    获取一致预期数据
-
-    :param order_book_ids: 股票名称
-    :param fiscal_year: int/str, 查询年份
-    :param fields: list,  一致预期字段
-    :param start_date: date-like object, 开始日期, 默认为None
-    :param end_date: date-like object, 结束日期, 默认为None
-    :param date_rule: str 日期截取规则，和start_date/end_date一起使用，默认为None不生效
-        'rpt_dt'，根据研报发布日期RPT_DT截取返回的数据
-        'create_tm',根据今日投资入库时间截取返回的数据
-        'rice_create_tm',根据米筐入库时间截取返回的数据
-    :param market: (Default value = 'cn')
-    :returns: pandas  MultiIndex DataFrame
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-    if fields is None:
-        fields = CONSENSUS_INDICATOR_FIELDS
-    else:
-        fields = ensure_list_of_string(fields, 'consensus_indicator')
-        check_items_in_container(fields, CONSENSUS_INDICATOR_FIELDS, 'consensus_indicator')
-
-    if start_date is not None:
-        start_date = ensure_date_int(start_date)
-    if end_date is not None:
-        end_date = ensure_date_int(end_date)
-    if date_rule is not None:
-        ensure_string_in(date_rule, ('rpt_dt', 'create_tm', 'rice_create_tm'), 'date_rule')
-    elif start_date is not None or end_date is not None:
-        raise ValueError('Ambiguous: date_rule should be specific!')
-    if fiscal_year is not None:
-        fiscal_year = int(fiscal_year)
-    elif start_date is None and end_date is None:
-        raise ValueError('at least one of (start_date/end_date, fiscal_year) should be non-none value.')
-
-    data = get_client().execute('consensus.get_indicator_v2', order_book_ids, fiscal_year, fields, start_date, end_date, date_rule, market=market)
-    if not data:
-        return None
-    df = pd.DataFrame(data)
-    df.set_index(['order_book_id', 'date'], inplace=True)
-    df.sort_index(inplace=True)
-    dtypes = {f: DTYPES[f] for f in df.columns if f in DTYPES}
-    df = df.astype(dtypes)
-    return df
-
-
-@export_as_api(namespace='consensus')
-def get_price(order_book_ids, start_date=None, end_date=None, fields=None, adjust_type='none', market='cn'):
-    """
-    获取一致预期股价预测数据
-
-    :param order_book_ids: 股票名称
-    :param start_date: 开始日期， date-like object, 默认三月前那天
-    :param end_date: 结束日期， date-like object， 默认当天
-    :param fields: list,  一致预期字段
-    :param adjust_type: 可选参数,默认为‘none', 返回原始数据
-            'pre' 返回前复权数据
-            'post' 返回后复权数据
-    :param market: (Default value = 'cn')
-    :returns: pandas MultiIndex DataFrame
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-
-    if fields is None:
-        fields = CONSENSUS_PRICE_FIELDS
-    else:
-        fields = ensure_list_of_string(fields, 'consensus_price')
-        check_items_in_container(fields, CONSENSUS_PRICE_FIELDS, 'consensus_price')
-
-    start_date, end_date = ensure_date_range(start_date, end_date)
-
-    data = get_client().execute('consensus.get_price', order_book_ids, start_date, end_date, market=market)
-    if not data:
-        return None
-
-    records = defaultdict(dict)
-    for r in data:
-        key = (r['order_book_id'], r['institute'], r['date'])
-        if key not in records:
-            records[key].update(r)
-        for field in fields:
-            name, f, value = CONSENSUS_PRICE_FIELDS_MAP[field]
-            if r[f] == value:
-                records[key][field] = r[name]
-    df = pd.DataFrame(list(records.values()))
-    df.set_index(['order_book_id', 'date'], inplace=True)
-    df.sort_index(inplace=True)
-    for f in fields:
-        if f not in df.columns:
-            df[f] = None
-    df = df.astype({f: PRICE_DTYPES[f] for f in fields if f in PRICE_DTYPES})
-
-    if adjust_type != 'none':
-        adjust_fields = list(set(CONSENSUS_PRICE_FIELDS[:2]) & set(fields))
-        if not adjust_fields:
-            return df
-
-        from rqdatac.services.detail.adjust_price import get_ex_factor_for
-        ex_factors = get_ex_factor_for(order_book_ids, market)
-        pre = adjust_type == 'pre'
-
-        def adjust(sub):
-            factors = ex_factors.get(sub.name)
-            if factors is None:
-                return sub
-            factor = np.take(factors.values, factors.index.searchsorted(sub.index.get_level_values(1), side='right') - 1)
-            if pre:
-                factor /= factors.iloc[-1]
-
-            sub[adjust_fields] = (sub[adjust_fields].values.T * factor).T
-            return sub
-
-        df = df.groupby(level=0).apply(adjust)
-        df[adjust_fields] = np.round(df[adjust_fields], 4)
-
-    return df
-
-
-CONSENSUS_COMP_INDICATOR_FIELDS = [
-    'comp_operating_revenue_t',
-    'comp_con_operating_revenue_t1',
-    'comp_con_operating_revenue_t2',
-    'comp_con_operating_revenue_t3',
-    'comp_con_operating_revenue_ftm',
-    'comp_net_profit_t',
-    'comp_con_net_profit_t1',
-    'comp_con_net_profit_t2',
-    'comp_con_net_profit_t3',
-    'comp_con_net_profit_ftm',
-    'comp_eps_t',
-    'comp_con_eps_t1',
-    'comp_con_eps_t2',
-    'comp_con_eps_t3',
-    'comp_net_asset_t',
-    'comp_con_net_asset_t1',
-    'comp_con_net_asset_t2',
-    'comp_con_net_asset_t3',
-    'comp_con_net_asset_ftm',
-    'comp_cash_flow_t',
-    'comp_con_cash_flow_t1',
-    'comp_con_cash_flow_t2',
-    'comp_con_cash_flow_t3',
-    'comp_con_cash_flow_ftm',
-    'comp_roe_t',
-    'comp_con_roe_t1',
-    'comp_con_roe_t2',
-    'comp_con_roe_t3',
-    'comp_con_roe_ftm',
-    'comp_pe_t',
-    'comp_con_pe_t1',
-    'comp_con_pe_t2',
-    'comp_con_pe_t3',
-    'comp_con_pe_ftm',
-    'comp_ps_t',
-    'comp_con_ps_t1',
-    'comp_con_ps_t2',
-    'comp_con_ps_t3',
-    'comp_con_ps_ftm',
-    'comp_pb_t',
-    'comp_con_pb_t1',
-    'comp_con_pb_t2',
-    'comp_con_pb_t3',
-    'comp_con_pb_ftm',
-    'comp_peg',
-    'comp_operating_revenue_growth_ratio_t',
-    'comp_con_operating_revenue_growth_ratio_t1',
-    'comp_con_operating_revenue_growth_ratio_t2',
-    'comp_con_operating_revenue_growth_ratio_t3',
-    'comp_con_operating_revenue_growth_ratio_ftm',
-    'comp_net_profit_growth_ratio_t',
-    'comp_con_net_profit_growth_ratio_t1',
-    'comp_con_net_profit_growth_ratio_t2',
-    'comp_con_net_profit_growth_ratio_t3',
-    'comp_con_net_profit_growth_ratio_ftm',
-    'con_grd_coef',
-    'con_targ_price',
-    'comp_con_eps_ftm',
-    'ty_profit_t1',
-    'ty_profit_t2',
-    'ty_profit_t3',
-    'ty_profit_ftm',
-    'ty_eps_t1',
-    'ty_eps_t2',
-    'ty_eps_t3',
-    'ty_eps_ftm',
-]
-
-CONSENSUS_COMP_INDICATOR_FIELDS_V = [
-    'comp_con_net_profit_t1',
-    'comp_con_net_profit_t2',
-    'comp_con_net_profit_t3',
-    'comp_con_operating_revenue_t1',
-    'comp_con_operating_revenue_t2',
-    'comp_con_operating_revenue_t3',
-    'comp_con_cash_flow_t1',
-    'comp_con_cash_flow_t2',
-    'comp_con_cash_flow_t3',
-    'comp_con_eps_t1',
-    'comp_con_eps_t2',
-    'comp_con_eps_t3',
-    'comp_con_eps_ftm',
-]
-
-CONSENSUS_COMP_INDICATORS_FIELDS_GRD_HIST = ['con_targ_price']
-
-COMP_INDICATORS_DTYPES = {
-    field: '<f8' for field in
-    CONSENSUS_COMP_INDICATOR_FIELDS + CONSENSUS_COMP_INDICATOR_FIELDS_V + CONSENSUS_COMP_INDICATORS_FIELDS_GRD_HIST
-}
-
-
-@export_as_api(namespace='consensus')
-def get_comp_indicators(order_book_ids, start_date=None, end_date=None, fields=None, report_range=0, market='cn'):
-    """
-    获取个股一致预期表
-
-    :param order_book_ids: 股票名称
-    :param start_date: date-like object, 默认当日
-    :param end_date: date-like object, 默认为当日
-    :param fields: list,  一致预期字段
-    :param report_range: int, 研报范围
-        0-不考虑补录入&包括所有报告数据（历史值修复会存在数值变动，需要不变的话传入3）
-        1-考虑补录入&包括所有报告数据
-        2-考虑补录入&仅包括公司报告数据
-        3-不考虑补录入&包括所有报告数据
-        4-不考虑补录入&仅包括公司报告数据
-    :param market: (Default value = 'cn')
-
-    :returns: pandas MultiIndex DataFrame
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-    today = today_int()
-    start_date = ensure_date_int(start_date) if start_date else today
-    end_date = ensure_date_int(end_date) if end_date else today
-
-    assert report_range in (0, 1, 2, 3, 4), 'invalid report_range {}. should in (0,1,2,3,4)!'.format(report_range)
-    fields_pool = CONSENSUS_COMP_INDICATOR_FIELDS if report_range == 0 else CONSENSUS_COMP_INDICATOR_FIELDS_V
-    if report_range in (1, 3):
-        fields_pool += CONSENSUS_COMP_INDICATORS_FIELDS_GRD_HIST
-    if fields is None:
-        fields = fields_pool
-    else:
-        fields = ensure_list_of_string(fields, 'consensus_comp_indicator')
-        check_items_in_container(fields, fields_pool, 'consensus_comp_indicator')
-
-    data = get_client().execute(
-        'consensus.get_comp_indicators',
-        order_book_ids, start_date, end_date, fields, report_range=report_range,
-        market=market
-    )
-    if not data:
-        return None
-    if report_range in (1, 3) and len(fields) > 1 and (
-            set(fields) & set(CONSENSUS_COMP_INDICATORS_FIELDS_GRD_HIST)
-    ):
-        new_data = defaultdict(dict)
-        for d in data:
-            pkey = (d['order_book_id'], d['date'])
-            if pkey not in new_data:
-                new_data[pkey] = d
-                continue
-            for k, v in d.items():
-                if k not in new_data[pkey]:
-                    new_data[pkey][k] = v
-        df = pd.DataFrame(list(new_data.values()))
-    else:
-        df = pd.DataFrame(data)
-    df.set_index(['order_book_id', 'date'], inplace=True)
-    df.sort_index(inplace=True)
-    dtypes = {f: COMP_INDICATORS_DTYPES[f] for f in df.columns if f in COMP_INDICATORS_DTYPES}
-    df = df.astype(dtypes)
-    return df
-
-
-@ttl_cache(3600)
-def _all_industries(market='cn'):
-    return get_client().execute('consensus.all_industries', market=market)
-
-
-@ttl_cache(3600)
-def _all_industry_dict(market='cn'):
-    result = defaultdict(list)
-    for v in _all_industries(market):
-        result[v['industry_code']].append(v['industry_code'])
-        result[v['industry_name']].append(v['industry_code'])
-    return result
-
-
-def ensure_industries(industries):
-    industries = ensure_list_of_string(industries)
-    code_mapping = _all_industry_dict()
-    industry_codes = set()
-    for i in industries:
-        if i in code_mapping:
-            industry_codes.update(code_mapping[i])
-    return list(industry_codes)
-
-
-@export_as_api(namespace='consensus')
-def all_industries(market='cn'):
-    data = _all_industries(market)
-    return pd.DataFrame(data).set_index('industry_code')
-
-
-@export_as_api(namespace='consensus')
-def get_industry_rating(industries, start_date, end_date, market='cn'):
-    """
-    获取行业评级数据
-
-    :param industries: str or list, 行业code是今日投资行业分类代码, 可通过all_consensus_industries()获取全部
-    :param start_date: date-like object， 结束日期
-    :param end_date: date-like object, 结束日期
-    :param market: str, 默认'cn'
-    :return: pandas.DataFrame
-    """
-    industries = ensure_industries(industries)
-    if not industries:
-        warnings.warn('No valid industry found')
-        return None
-
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    data = get_client().execute('consensus.get_industry_rating', industries, start_date, end_date, market=market)
-    if not data:
-        return None
-
-    df = pd.DataFrame(data)
-    df.set_index(['industry_name', 'info_date'], inplace=True)
-    return df
-
-
-@export_as_api(namespace='consensus')
-def get_market_estimate(indexes, fiscal_year, market='cn'):
-    """
-    获取今日投资的机构预测大势表
-
-    :param indexes: str or list, 指数列表
-    :param fiscal_year: int, 年份
-    :param market: str, default 'cn'
-    :return: pandas MultiIndex DataFrame
-
-    :example:
-    >>> rqdatac.consensus.get_market_estimate('000001.XSHG', 2021)
-                                fiscal_year    institute start_date  ...  period  value
-    order_book_id info_date                        ...
-    000001.XSHG   2020-10-13        2021    财信证券 2021-01-01  ...  策略年度报告     中性
-                  2020-10-16        2021    华融证券 2021-01-01  ...  策略年度报告     中性
-                  2020-10-23        2021    东北证券 2021-01-01  ...  策略年度报告     中性
-                  2020-11-01        2021    方正证券 2021-01-01  ...  策略年度报告     中性
-                  2020-11-02        2021    西南证券 2021-01-01  ...  策略年度报告     中性
-                                    ...      ...      ...       ...     ...        ...
-                  2021-12-31        2021    山西证券 2022-01-01  ...  策略月度报告     中性
-                  2021-12-31        2021    方正证券 2021-12-31  ...   策略日报等     中性
-                  2021-12-31      2021    东亚前海证券 2022-01-01  ...  策略月度报告     中性
-                  2021-12-31        2021    粤开证券 2022-01-01  ...  策略月度报告     乐观
-                  2021-12-31        2021    渤海证券 2022-01-01  ...  策略月度报告     中性
-
-    返回字段:
-    fiscal_year: 预测年份
-    institue: 机构名称
-    start_date: 预测开始日期
-    end_date: 预测结束日期
-    high: 预测高点
-    low: 预测低点
-    period: 预测时段
-    value: 预测值
-    """
-
-    indexes = ensure_list_of_string(indexes)
-    indexes = ensure_order_book_ids(indexes, type='INDX')
-    fiscal_year = int(fiscal_year)
-    data = get_client().execute('consensus.get_market_estimate', indexes, fiscal_year, market=market)
-    if not data:
-        return None
-    df = pd.DataFrame(data)
-    df.set_index(['order_book_id', 'info_date'], inplace=True)
-    df.sort_index(inplace=True)
-    return df
-
-
-export_as_api(deprecated(
-    func=get_indicator,
-    msg='get_consensus_indicator will be deprecated in future. use consensus.get_indicator instead.'
-), name='get_consensus_indicator')
-export_as_api(deprecated(
-    func=get_price,
-    msg='get_consensus_price will be deprecated in future. use consensus.get_price instead.'
-), name='get_consensus_price')
-export_as_api(deprecated(
-    func=get_comp_indicators,
-    msg='get_consensus_comp_indicators will be deprecated in future. use consensus.get_comp_indicators instead.'
-), name='get_consensus_comp_indicators')
-export_as_api(deprecated(
-    func=all_industries,
-    msg='all_consensus_industries will be deprecated in future. use consensus.all_industries instead.'
-), name='all_consensus_industries')
-export_as_api(deprecated(
-    func=get_industry_rating,
-    msg='get_consensus_industry_rating will be deprecated in future. use consensus.get_industry_rating instead.'
-), name='get_consensus_industry_rating')
-export_as_api(deprecated(
-    func=get_market_estimate,
-    msg='get_consensus_market_estimate will be deprecated in future. use consensus.get_market_estimate instead.'
-), name='get_consensus_market_estimate')
-
-
-VALID_STAT_PERIODS = ['WEEK1', 'MON1', 'MON3', 'MON6', 'YEAR1']
-
-
-@export_as_api(namespace='consensus')
-def get_security_change(order_book_ids, start_date=None, end_date=None, stat_periods=None):
-    """
-    获取机构报告统计周期内个股调整明细表
-
-    :param order_book_ids: 股票名称
-    :param start_date: 开始日期， date-like object, 默认三月前那天
-    :param end_date: 结束日期， date-like object， 默认当天
-    :param stat_periods: 统计周期，str/list, 默认全部, 可选值 {'WEEK1', 'MON1', 'MON3', 'MON6', 'YEAR1'}
-
-    :return: pandas MultiIndex DataFrame
-
-    返回字段：
-    order_book_id
-    date
-    stat_period
-    institute
-    adjust_classification: 调整类别
-        1 盈利预测调高;
-        2 盈利预测调低;
-        3 投资评级调高;
-        4 投资评级调低;
-        5 盈利预测维持;
-        6 投资评级维持;
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-
-    if stat_periods is None:
-        stat_periods = VALID_STAT_PERIODS
-    else:
-        stat_periods = ensure_list_of_string(stat_periods)
-        check_items_in_container(stat_periods, VALID_STAT_PERIODS, 'stat_periods')
-
-    data = get_client().execute('consensus.get_security_change', order_book_ids, start_date, end_date, stat_periods)
-    if not data:
-        return None
-    df = pd.DataFrame(data)
-    df.set_index(['order_book_id', 'date'], inplace=True)
-    df.sort_index(inplace=True)
-    return df
-
-
-REPORT_PERIODS = {'q1': 103, 'q2': 106, 'q3': 109, 'q4': 112}
-REPORT_TYPES = {'financial_reports': 0, 'performance_forecast': 1, 'current_performance': 2}
-APPRAISAL_RESULTS = {'exceed': 1, 'below': 2}
-VALID_REPORT_PERIODS = list(REPORT_PERIODS)
-VALID_REPORT_TYPES = list(REPORT_TYPES)
-VALID_APPRAISAL_RESULTS = list(APPRAISAL_RESULTS)
-REVERSED_REPORT_PERIODS = {103: 'q1', 106: 'q2', 109: 'q3', 112: 'q4'}
-REVERSED_REPORT_TYPES = {0: 'financial_reports', 1: 'performance_forecast', 2: 'current_performance'}
-REVERSED_APPRAISAL_RESULTS = {1: 'exceed', 2: 'below'}
-
-
-@export_as_api(namespace='consensus')
-def get_expect_appr_exceed(
-        order_book_ids,
-        start_date=None,
-        end_date=None,
-        report_year=None,
-        report_periods=None,
-        report_types=None,
-        appraisal_results=None
-):
-    """
-    获取超预期鉴定数据
-
-    :param order_book_ids: 股票名称
-    :param start_date: 开始日期， date-like object, 默认三月前那天
-    :param end_date: 结束日期， date-like object， 默认当天
-    :param report_year: int, 报告年度，默认全部
-    :param report_periods: str/list, 报告时段， 默认全部
-        q1  一季度
-        q2  半年度
-        q3  三季度
-        q4  年度
-    :param report_types: str/list, 业绩报告类型, 默认全部
-        financial_reports 财务定期报告
-        performance_forecast 业绩预告
-        current_performance 业绩快报
-    :param appraisal_results: str/list, 鉴定结果,默认全部
-        exceed 超预期
-        below 低于预期
-
-    :return: pandas MultiIndex DataFrame
-    
-    返回字段:
-    report_year: int，报告年度
-    report_period: str，报告时段
-    report_type: str, 业绩报告类型
-    appraisal_result: str，鉴定结果
-        exceed 超预期
-        below 低于预期
-    info_date: datetime.datetime
-    forecast_profit_max: float 业绩预告净利润上限，报告为年报时，对应的披露数据
-    forecast_profit_min: float 业绩预告净利润下限，报告为年报时，对应的披露数据
-    forecast_profit: float 业绩预告净利润，报告为年报时，对应的披露数据，包括定期报告和业绩快报数据
-    adjust_con_profit: float，调整后一致预期净利润，报告为季报时，对应季报发布日之后第5个交易日的一致预期（T+1年）仅计算5日内的预测明细数据（简单平均）
-    appraisal_date: datetime.datetime, 鉴定日
-    appraisal_standard: int, 鉴定标准
-        1 报表发布日鉴定
-        2 报表发布周期鉴定
-    con_cal_date: datetime.datetime, 一致预期计算日
-    con_profit: float, 一致预期净利润
-        鉴定标准为1时，为财报或者预告、快报发布日前一交易日的一致预期净利润；
-        鉴定标准为2时，为对应财报期最后一个交易日的一致预期净利润
-    profit_ex_rate: float, 业绩超预期幅度
-        超预期幅度=(报告净利润或调整后一致预期净利润 - 一致预期净利润) / ABS(一致预期净利润)
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-
-    if report_periods is None:
-        report_periods = VALID_REPORT_PERIODS
-    else:
-        report_periods = ensure_list_of_string(report_periods)
-        check_items_in_container(report_periods, VALID_REPORT_PERIODS, 'report_periods')
-
-    if report_types is None:
-        report_types = VALID_REPORT_TYPES
-    else:
-        report_types = ensure_list_of_string(report_types)
-        check_items_in_container(report_types, VALID_REPORT_TYPES, 'report_types')
-
-    if appraisal_results is None:
-        appraisal_results = VALID_APPRAISAL_RESULTS
-    else:
-        appraisal_results = ensure_list_of_string(appraisal_results)
-        check_items_in_container(appraisal_results, VALID_APPRAISAL_RESULTS, 'appraisal_results')
-
-    data = get_client().execute(
-        'consensus.get_expect_appr_exceed', order_book_ids, start_date, end_date, report_year,
-        [REPORT_PERIODS[_] for _ in report_periods],
-        [REPORT_TYPES[_] for _ in report_types],
-        [APPRAISAL_RESULTS[_] for _ in appraisal_results]
-    )
-    if not data:
-        return None
-    df = pd.DataFrame(data)
-    df['report_period'] = df['report_period'].map(REVERSED_REPORT_PERIODS)
-    df['report_type'] = df['report_type'].map(REVERSED_REPORT_TYPES)
-    df['appraisal_result'] = df['appraisal_result'].map(REVERSED_APPRAISAL_RESULTS)
-    df.set_index(['order_book_id', 'date'], inplace=True)
-    df.sort_index(inplace=True)
-    return df
-
-
-@export_as_api(namespace='consensus')
-def get_expect_prob(order_book_ids, expect_prob, start_date=None, end_date=None):
-    """
-    获取超/低于预期数据
-
-    :param order_book_ids: str or list, 股票列表
-    :param expect_prob: str, 'below': 低于预期， 'exceed': 超预期
-    :param start_date: 开始日期， date-like object, 默认三月前那天
-    :param end_date: 结束日期， date-like object， 默认当天
-
-    :return: pandas.DataFrame
-    
-    返回字段:
-    order_book_id
-    date
-    report_year: 报告年度
-    report_period: 报告时段
-        103  一季度 q1
-        106  半年度 q2
-        109  三季度 q3
-        112  年度 q4
-    info_classification: 预期类别代码
-        exceed:
-            1101 分析师上调（剔除明星分析师）
-            1102 明星分析师上调
-            1103 业绩公告后分析师全部上调
-            1201 业绩公告后一致预期净利润大幅上调
-            1301 研报标题超预期
-            1302 研报摘要超预期
-            1401 业绩预告/快报超上次预期
-            1403 业绩预告/快报超一致预期
-            1405 本期财报净利润超一致预期净利润（单季度）
-            1501 本期财报净利润同比增速超年度一致预期净利润同比增速
-            1502 本次预告/快报净利润同比增速超年度一致预期净利润同比增速
-            1503 本期财报净利润同比增速超一致预期净利润同比增速（单季度）
-            1504 本次预告/快报净利润同比增速超一致预期净利润同比增速（单季度）
-        below:
-            2101 分析师下调;
-            2102 明星分析师下调（名字待定）
-            2103 业绩公告后分析师全部下调
-            2201 一致预期净利润大幅下调
-            2301 研报标题低于预期
-            2302 研报摘要低于预期
-            2401 业绩预告/快报低于上次预期
-            2403 业绩预告/快报低于一致预期
-            2405 本期财报净利润低于一致预期净利润（单季度）
-            2501 本期财报净利润同比增速低于年度一致预期净利润同比增速
-            2502 本次预告/快报净利润同比增速低于年度一致预期净利润同比增速
-            2503 本期财报净利润同比增速低于一致预期净利润同比增速（单季度）
-            2504 本次预告/快报净利润同比增速低于一致预期净利润同比增速（单季度）
-    institute: 研究机构简称
-    info_summary: 超预期信息简述
-    report_date: 本次研究报告撰写日
-    title: 本次研报标题
-    author: 本次研报作者
-    est_profit: 本次研报预测净利润
-    report_date_last: 上次研究报告撰写日
-    title_last: 上次研报标题
-    est_profit_last: 上次研报预测净利润
-    info_date: 本次业绩报告日
-    report_type: 本次业绩报告类型
-        0 财务定期报告 financial_reports
-        1 业绩预告 performance_forecast
-        2 业绩快报 current_performance
-    forecast_profit_max: 本次业绩预告上限净利润 适用类型：1 业绩预告
-    forecast_profit_min: 本次业绩预告下限净利润 适用类型：1 业绩预告
-    profit: 本次业绩报告净利润	适用类型：0 财务定期报告； 2 业绩快报
-    profit_q: 本次业绩报告净利润（单季度） 适用类型：0 财务定期报告； 2 业绩快报
-    forecast_profit_growth_limit: 本次业绩预告净利润同比增速上下限
-        exceed: 下限
-        below:  上限
-        适用类型：0 财务定期报告； 2 业绩快报
-    profit_growth: 本次业绩报告净利润同比增速 适用类型：1 业绩预告
-    forecast_profit_growth_limit_q: 本次业绩预告净利润同比增速上下限（单季度）
-        exceed: 下限
-        below:  上限
-        适用类型：0 财务定期报告； 2 业绩快报
-    profit_growth_q: 本次业绩报告净利润同比增速（单季度） 适用类型：1 业绩预告 2 业绩快报
-    fin_report_date_last: 上次业绩报告公告日 适用类型：1 业绩预告； 2 业绩快报
-    fin_report_type_last: 上次业绩报告类型 1 业绩预告； 2 业绩快报
-    forecast_profit_max_last: 上次业绩预告上限净利润 适用类型：1 业绩预告；
-    forecast_profit_min_last: 上次业绩预告下限净利润 适用类型：1 业绩预告；
-    profit_last: 上次业绩快报净利润 	适用类型：2 业绩快报
-    con_calc_date: 本次一致预期计算日
-    con_profit: 本次一致预期净利润
-    con_calc_date_last: 上次一致预期计算日
-    con_profit_last: 上次一致预期净利润
-    con_profit_q_last: 上次一致预期净利润（单季度）
-    con_profit_growth_last: 上次一致预期净利润同比增速（年度）
-    con_profit_growth_q_last: 上次一致预期净利润同比增速（单季度）
-    expect_rate: 业绩上下调幅度或低于预期幅度
-    """
-
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-
-    ensure_string_in(expect_prob, ('exceed', 'below'))
-    if expect_prob not in ('exceed', 'below'):
-        raise ValueError('invalid expect_prob: {}'.format(expect_prob))
-
-    data = get_client().execute('consensus.get_expect_prob', order_book_ids, expect_prob, start_date, end_date)
-    if not data:
-        return None
-    df = pd.DataFrame(data)
-    df['report_period'] = df['report_period'].map(REVERSED_REPORT_PERIODS)
-    df['report_type'] = df['report_type'].map(REVERSED_REPORT_TYPES)
-    df.set_index(['order_book_id', 'date'], inplace=True)
-    df.sort_index(inplace=True)
-    return df
-
-
-FACTOR_EMOTIONS = [
-    'MTK_CONF',
-    'OPTIM_CONF',
-    'PESSIM_CONF',
-    'TY_PROFIT_T1_DEV',
-    'TY_PROFIT_T2_DEV',
-    'TY_PROFIT_T3_DEV',
-    'TY_EPS_T1_DEV',
-    'TY_EPS_T2_DEV',
-    'TY_EPS_T3_DEV',
-    'EPS_T1_DEV',
-    'EPS_T2_DEV',
-    'EPS_T3_DEV',
-    'PROFIT_T1_DEV',
-    'PROFIT_T2_DEV',
-    'PROFIT_T3_DEV',
-    'OP_REVEN_T1_DEV',
-    'OP_REVEN_T2_DEV',
-    'OP_REVEN_T3_DEV',
-    'OP_COST_T1_DEV',
-    'OP_COST_T2_DEV',
-    'OP_COST_T3_DEV',
-    'OP_PROFIT_T1_DEV',
-    'OP_PROFIT_T2_DEV',
-    'OP_PROFIT_T3_DEV',
-    'OP_CASH_FLOW_T1_DEV',
-    'OP_CASH_FLOW_T2_DEV',
-    'OP_CASH_FLOW_T3_DEV',
-    'ROE_T1_DEV',
-    'ROE_T2_DEV',
-    'ROE_T3_DEV',
-    'PEG_1Y_DEV',
-    'PEG_3Y_DEV',
-    'PB_T1_DEV',
-    'PB_T2_DEV',
-    'PB_T3_DEV',
-    'PE_T1_DEV',
-    'PE_T2_DEV',
-    'PE_T3_DEV',
-    'PS_T1_DEV',
-    'PS_T2_DEV',
-    'PS_T3_DEV',
-    'PCF_T1_DEV',
-    'PCF_T2_DEV',
-    'PCF_T3_DEV',
-]
-FACTOR_EMOTIONS = ['{}_{}D'.format(f, d) for d in [7, 14, 30, 60, 90] for f in FACTOR_EMOTIONS]
-
-FACTOR_VALUATIONS = [
-    'PEG_1Y',
-    'PEG_1Y_SCO',
-    'PEG_3Y',
-    'PEG_3Y_SCO',
-    'RV_VALUT_EM',
-    'RV_VALUT_EM_SCO',
-    'PB_T',
-    'PE_T',
-    'PS_T',
-    'PCF_T',
-    'PB_T_SCO',
-    'PE_T_SCO',
-    'PS_T_SCO',
-    'PCF_T_SCO',
-    'PB_T1',
-    'PE_T1',
-    'PS_T1',
-    'PCF_T1',
-    'PB_T1_SCO',
-    'PE_T1_SCO',
-    'PS_T1_SCO',
-    'PCF_T1_SCO',
-    'PB_T2',
-    'PE_T2',
-    'PS_T2',
-    'PCF_T2',
-    'PB_T2_SCO',
-    'PE_T2_SCO',
-    'PS_T2_SCO',
-    'PCF_T2_SCO',
-    'PB_T3',
-    'PE_T3',
-    'PS_T3',
-    'PCF_T3',
-    'PB_T3_SCO',
-    'PE_T3_SCO',
-    'PS_T3_SCO',
-    'PCF_T3_SCO',
-    'PB_FTM',
-    'PE_FTM',
-    'PS_FTM',
-    'PCF_FTM',
-    'PB_FTM_SCO',
-    'PE_FTM_SCO',
-    'PS_FTM_SCO',
-    'PCF_FTM_SCO',
-]
-
-FACTOR_GROWTHS = [
-    'TY_PROFIT_T1_CHG',
-    'TY_PROFIT_T2_CHG',
-    'TY_PROFIT_T3_CHG',
-    'TY_EPS_T1_CHG',
-    'TY_EPS_T2_CHG',
-    'TY_EPS_T3_CHG',
-    'PROFIT_T1_CHG',
-    'PROFIT_T2_CHG',
-    'PROFIT_T3_CHG',
-    'EPS_T1_CHG',
-    'EPS_T2_CHG',
-    'EPS_T3_CHG',
-    'OP_REVEN_T1_CHG',
-    'OP_REVEN_T2_CHG',
-    'OP_REVEN_T3_CHG',
-    'OP_COST_T1_CHG',
-    'OP_COST_T2_CHG',
-    'OP_COST_T3_CHG',
-    'OP_PROFIT_T1_CHG',
-    'OP_PROFIT_T2_CHG',
-    'OP_PROFIT_T3_CHG',
-    'OP_CASH_FLOW_T1_CHG',
-    'OP_CASH_FLOW_T2_CHG',
-    'OP_CASH_FLOW_T3_CHG',
-    'ASSET_T1_CHG',
-    'ASSET_T2_CHG',
-    'ASSET_T3_CHG',
-    'ROE_T1_CHG',
-    'ROE_T2_CHG',
-    'ROE_T3_CHG',
-]
-FACTOR_GROWTHS = ['{}_{}D'.format(f, d) for d in [7, 14, 30, 60, 90] for f in FACTOR_GROWTHS]
-
-FACTOR_FINS = [
-    'RPT_YR_T',
-    'ANN_RPT_DT_LAST',
-    'PROFIT_T',
-    'PROFIT_T1',
-    'PROFIT_T2',
-    'PROFIT_T3',
-    'PROFIT_FTM',
-    'PROFIT_YOY_T',
-    'PROFIT_YOY_T1',
-    'PROFIT_YOY_T2',
-    'PROFIT_YOY_T3',
-    'PROFIT_YOY_FTM',
-    'PROFIT_CAGR_2Y',
-    'PROFIT_CAGR_3Y',
-    'TY_PROFIT_T1',
-    'TY_PROFIT_T2',
-    'TY_PROFIT_T3',
-    'TY_PROFIT_FTM',
-    'TY_PROFIT_YOY_T1',
-    'TY_PROFIT_YOY_T2',
-    'TY_PROFIT_YOY_T3',
-    'TY_PROFIT_YOY_FTM',
-    'EPS_T',
-    'EPS_T1',
-    'EPS_T2',
-    'EPS_T3',
-    'EPS_FTM',
-    'EPS_YOY_T',
-    'EPS_YOY_T1',
-    'EPS_YOY_T2',
-    'EPS_YOY_T3',
-    'EPS_YOY_FTM',
-    'TY_EPS_T1',
-    'TY_EPS_T2',
-    'TY_EPS_T3',
-    'TY_EPS_FTM',
-    'TY_EPS_YOY_T1',
-    'TY_EPS_YOY_T2',
-    'TY_EPS_YOY_T3',
-    'TY_EPS_YOY_FTM',
-    'OP_REVEN_T',
-    'OP_REVEN_T1',
-    'OP_REVEN_T2',
-    'OP_REVEN_T3',
-    'OP_REVEN_FTM',
-    'OP_REVEN_YOY_T',
-    'OP_REVEN_YOY_T1',
-    'OP_REVEN_YOY_T2',
-    'OP_REVEN_YOY_T3',
-    'OP_REVEN_YOY_FTM',
-    'OP_REVEN_CAGR_2Y',
-    'OP_REVEN_CAGR_3Y',
-    'OP_COST_T',
-    'OP_COST_T1',
-    'OP_COST_T2',
-    'OP_COST_T3',
-    'OP_COST_FTM',
-    'OP_COST_YOY_T',
-    'OP_COST_YOY_T1',
-    'OP_COST_YOY_T2',
-    'OP_COST_YOY_T3',
-    'OP_COST_YOY_FTM',
-    'OP_PROFIT_T',
-    'OP_PROFIT_T1',
-    'OP_PROFIT_T2',
-    'OP_PROFIT_T3',
-    'OP_PROFIT_FTM',
-    'OP_PROFIT_YOY_T',
-    'OP_PROFIT_YOY_T1',
-    'OP_PROFIT_YOY_T2',
-    'OP_PROFIT_YOY_T3',
-    'OP_PROFIT_YOY_FTM',
-    'ROE_T',
-    'ROE_T1',
-    'ROE_T2',
-    'ROE_T3',
-    'ROE_FTM',
-    'ROE_YOY_T',
-    'ROE_YOY_T1',
-    'ROE_YOY_T2',
-    'ROE_YOY_T3',
-    'ROE_YOY_FTM',
-    'OP_CASH_FLOW_T',
-    'OP_CASH_FLOW_T1',
-    'OP_CASH_FLOW_T2',
-    'OP_CASH_FLOW_T3',
-    'OP_CASH_FLOW_FTM',
-    'OP_CASH_FLOW_YOY_T',
-    'OP_CASH_FLOW_YOY_T1',
-    'OP_CASH_FLOW_YOY_T2',
-    'OP_CASH_FLOW_YOY_T3',
-    'OP_CASH_FLOW_YOY_FTM',
-    'ASSET_T',
-    'ASSET_T1',
-    'ASSET_T2',
-    'ASSET_T3',
-    'ASSET_FTM',
-    'ASSET_YOY_T',
-    'ASSET_YOY_T1',
-    'ASSET_YOY_T2',
-    'ASSET_YOY_T3',
-    'ASSET_YOY_FTM',
-    'EARN_QUAL',
-]
-
-VALID_FACTOR_FIELDS = FACTOR_EMOTIONS + FACTOR_GROWTHS + FACTOR_VALUATIONS + FACTOR_FINS
-
-
-@export_as_api(namespace='consensus')
-def get_factor(order_book_ids, factors, start_date=None, end_date=None):
-    """
-    获取一致预期因子库数据
-
-    :param order_book_ids: str or list, 股票列表
-    :param factors: str or list, 因子列表
-    :param start_date: 开始日期， date-like object, 默认三月前那天
-    :param end_date: 结束日期， date-like object， 默认当天
-
-    :return: pandas.DataFrame
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-
-    factors = ensure_list_of_string(factors)
-    check_items_in_container(factors, VALID_FACTOR_FIELDS, 'factors')
-
-    data = get_client().execute('consensus.get_factor', order_book_ids, factors, start_date, end_date)
-    if not data:
-        return
-
-    result = defaultdict(dict)
-    for r in data:
-        key = (r['order_book_id'], r['date'])
-        result[key].update(r)
-
-    df = pd.DataFrame(result.values())
-    df.set_index(['order_book_id', 'date'], inplace=True)
-    fields = [f for f in df.columns if f != 'ANN_RPT_DT_LAST']
-    df[fields] = df[fields].astype(float)
-    df.sort_index(inplace=True)
-    return df
-
-
-ANALYST_MOMEMTUM_FIELDS = [
-    'profit_chg_1w',
-    'profit_chg_1w_rank',
-    'profit_chg_1w_sco',
-    'profit_chg_2w',
-    'profit_chg_2w_rank',
-    'profit_chg_2w_sco',
-    'profit_chg_1m',
-    'profit_chg_1m_rank',
-    'profit_chg_1m_sco',
-    'profit_chg_2m',
-    'profit_chg_2m_rank',
-    'profit_chg_2m_sco',
-    'profit_chg_3m',
-    'profit_chg_3m_rank',
-    'profit_chg_3m_sco',
-    'op_reven_chg_1w',
-    'op_reven_chg_1w_rank',
-    'op_reven_chg_1w_sco',
-    'op_reven_chg_2w',
-    'op_reven_chg_2w_rank',
-    'op_reven_chg_2w_sco',
-    'op_reven_chg_1m',
-    'op_reven_chg_1m_rank',
-    'op_reven_chg_1m_sco',
-    'op_reven_chg_2m',
-    'op_reven_chg_2m_rank',
-    'op_reven_chg_2m_sco',
-    'op_reven_chg_3m',
-    'op_reven_chg_3m_rank',
-    'op_reven_chg_3m_sco',
-    'ty_est_dev',
-    'ty_est_dev_rank',
-    'ty_est_dev_sco',
-    'est_em_bic_sco',
-    'est_em_non_bic_sco',
-    'grd_em_1m',
-    'grd_em_1m_rank',
-    'grd_em_1m_sco',
-    'grd_em_2m',
-    'grd_em_2m_rank',
-    'grd_em_2m_sco',
-    'grd_em_3m',
-    'grd_em_3m_rank',
-    'grd_em_3m_sco',
-    'targ_price_space',
-    'targ_price_space_rank',
-    'targ_price_space_sco',
-    'grd_em_sco',
-    'ana_em_bic_sco',
-    'ana_em_non_bic_sco',
-]
-
-OBJECT_DTYPE = np.dtype('O')
-
-
-@export_as_api(namespace='consensus')
-def get_analyst_momentum(
-        order_book_ids,
-        fiscal_year=None,
-        start_date=None,
-        end_date=None,
-        fields=None,
-        report_periods=None,
-        report_range=None,
-        market='cn'
-):
-    """
-    获取一致预期分析师动能数据
-
-    :param order_book_ids: 股票名称
-    :param fiscal_year: int/str, 查询年份, 默认返回全部
-    :param start_date: date-like object, 开始日期, 默认三月前那天
-    :param end_date: date-like object, 结束日期, 默认当天
-    :param fields: stor/list, 数据字段, 默认返回全部
-    :param report_periods: str/list, 报告时段， 默认全部
-        q1  一季度
-        q2  半年度
-        q3  三季度
-        q4  年度
-    :param report_range: int, 默认全部
-        1-考虑补录入&包括所有报告数据
-        3-不考虑补录入&包括所有报告数据
-    :param market: Default('cn')
-    :returns: pandas  MultiIndex DataFrame
-    
-    返回字段说明:
-    profit_chg_1w	        净利润1周变化率        [一致预期净利润（当前）-一致预期净利润（1周前）]/ [︱一致预期净利润（1周前）︱+0.5*总股本]
-    profit_chg_1w_rank	    净利润1周变化率排名      全市场排名
-    profit_chg_1w_sco	    净利润1周变化率得分      百分制打分，排名最靠前的1%为100分。
-    profit_chg_2w   	    净利润2周变化率        [一致预期净利润（当前）-一致预期净利润（2周前）]/ [︱一致预期净利润（2周前）︱+0.5*总股本]
-    profit_chg_2w_rank	    净利润2周变化率排名      全市场排名
-    profit_chg_2w_sco	    净利润2周变化率得分      百分制打分，排名最靠前的1%为100分。
-    profit_chg_1m	        净利润1月变化率        [一致预期净利润（当前）-一致预期净利润（1月前）]/ [︱一致预期净利润（1月前）︱+0.5*总股本]
-    profit_chg_1m_rank	    净利润1月变化率排名      全市场排名
-    profit_chg_1m_sco	    净利润1月变化率得分      百分制打分，排名最靠前的1%为100分。
-    profit_chg_2m   	    净利润2月变化率        [一致预期净利润（当前）-一致预期净利润（2月前）]/ [︱一致预期净利润（2月前）︱+0.5*总股本]
-    profit_chg_2m_rank	    净利润2月变化率排名      全市场排名
-    profit_chg_2m_sco	    净利润2月变化率得分      百分制打分，排名最靠前的1%为100分。
-    profit_chg_3m	        净利润3月变化率        [一致预期净利润（当前）-一致预期净利润（3月前）]/ [︱一致预期净利润（3月前）︱+0.5*总股本]
-    profit_chg_3m_rank	    净利润3月变化率排名      全市场排名
-    profit_chg_3m_sco	    净利润3月变化率得分      百分制打分，排名最靠前的1%为100分。
-    op_reven_chg_1w	        业务收入1周变化率       [一致预期业务收入（当前）-一致预期业务收入（1周前）]/ 一致预期业务收入（1周前）
-    op_reven_chg_1w_rank	业务收入1周变化率排名     全市场排名
-    op_reven_chg_1w_sco	    业务收入1周变化率得分     百分制打分，排名最靠前的1%为100分。
-    op_reven_chg_2w	        业务收入2周变化率       [一致预期业务收入（当前）-一致预期业务收入（2周前）]/ 一致预期业务收入（2周前）
-    op_reven_chg_2w_rank	业务收入2周变化率排名     全市场排名
-    op_reven_chg_2w_sco	    业务收入2周变化率得分     百分制打分，排名最靠前的1%为100分。
-    op_reven_chg_1m	        业务收入1月变化率       [一致预期业务收入（当前）-一致预期业务收入（1月前）]/ 一致预期业务收入（1月前）
-    op_reven_chg_1m_rank	业务收入1月变化率排名     全市场排名
-    op_reven_chg_1m_sco	    业务收入1月变化率得分     百分制打分，排名最靠前的1%为100分。
-    op_reven_chg_2m	        业务收入2月变化率       [一致预期业务收入（当前）-一致预期业务收入（2月前）]/ 一致预期业务收入（2月前）
-    op_reven_chg_2m_rank	业务收入2月变化率排名     全市场排名
-    op_reven_chg_2m_sco	    业务收入2月变化率得分     百分制打分，排名最靠前的1%为100分。
-    op_reven_chg_3m	        业务收入3月变化率       [一致预期业务收入（当前）-一致预期业务收入（3月前）]/ 一致预期业务收入（3月前）
-    op_reven_chg_3m_rank	业务收入3月变化率排名     全市场排名
-    op_reven_chg_3m_sco	    业务收入3月变化率得分     百分制打分，排名最靠前的1%为100分。
-    ty_est_dev	            天眼预期偏离度	        （天眼预期-一致预期）/(｜一致预期｜+0.5*总股本）
-    ty_est_dev_rank	        天眼预期偏离度排名       全市场排名
-    ty_est_dev_sco	        天眼预期偏离度得分       百分制打分，排名最靠前的1%为100分。
-    est_em_bic_sco	        预期动能得分(考虑业务收入变化率)   考虑了收入的变化率
-    est_em_non_bic_sco	    预期动能得分(不考虑业务收入变化率)  未考虑了收入的变化率
-    grd_em_1m           	评级动能1月            1个月前评级系数-现在评级系数；对于单个评级，强力买入1.00；买入2.00；观望3.00；适度减持4.00；卖出5.00。评级系数为60天内所有给出评级机构最新评级的简单平均。
-    grd_em_1m_rank	        评级动能1月排名         全市场排名
-    grd_em_1m_sco	        评级动能1月得分         百分制打分，排名最靠前的1%为100分。
-    grd_em_2m	            评级动能2月            2个月前评级系数-现在评级系数；对于单个评级，强力买入1.00；买入2.00；观望3.00；适度减持4.00；卖出5.00。评级系数为60天内所有给出评级机构最新评级的简单平均。
-    grd_em_2m_rank	        评级动能2月排名         全市场排名
-    grd_em_2m_sco	        评级动能2月得分         百分制打分，排名最靠前的1%为100分。
-    grd_em_3m	            评级动能3月            3个月前评级系数-现在评级系数；对于单个评级，强力买入1.00；买入2.00；观望3.00；适度减持4.00；卖出5.00。评级系数为60天内所有给出评级机构最新评级的简单平均。
-    grd_em_3m_rank	        评级动能3月排名         全市场排名
-    grd_em_3m_sco	        评级动能3月得分         百分制打分，排名最靠前的1%为100分。
-    targ_price_space	    目标价涨升空间
-    targ_price_space_rank	目标价涨升空间排名       全市场排名
-    targ_price_space_sco	目标价涨升空间得分       百分制打分，排名最靠前的1%为100分。
-    grd_em_sco	            评级动能得分            百分制打分，排名最靠前的1%为100分。
-    ana_em_bic_sco	        分析师动能得分(考虑业务收入变化率)      0.3*天眼预期得分+0.2*预期业绩动能得分+0.3*目标价涨升空间得分+0.2*评级动能得分（考虑业务收入变动情况）
-    ana_em_non_bic_sco	    分析师动能得分(不考虑业务收入变化率)     0.3*天眼预期得分+0.2*预期业绩动能得分2+0.3*目标价涨升空间得分+0.2*评级动能得分（不考虑业务收入变动）
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-
-    if fiscal_year is not None:
-        fiscal_year = int(fiscal_year)
-
-    if fields is None:
-        fields = ANALYST_MOMEMTUM_FIELDS
-    else:
-        fields = ensure_list_of_string(fields, 'analyst_momentum')
-        check_items_in_container(fields, ANALYST_MOMEMTUM_FIELDS, 'analyst_momentum')
-
-    if report_periods is not None:
-        report_periods = ensure_list_of_string(report_periods)
-        check_items_in_container(report_periods, VALID_REPORT_PERIODS, 'report_periods')
-        report_periods = [REPORT_PERIODS[_] for _ in report_periods]
-
-    if report_range is not None:
-        assert report_range in (1, 3), 'invalid report_range {}. should in (1,3)!'.format(report_range)
-
-    data = get_client().execute(
-        'consensus.get_analyst_momentum',
-        order_book_ids, fiscal_year, start_date, end_date, fields,
-        report_periods,
-        report_range,
-        market=market
-    )
-
-    if not data:
-        return None
-
-    df = pd.DataFrame(data)
-    dtypes = {f: (dtype if dtype != OBJECT_DTYPE else '<f8') for f, dtype in df[fields].dtypes.items()}
-    df = df.astype(dtypes)
-    df['report_period'] = df['report_period'].map(REVERSED_REPORT_PERIODS)
-    df.set_index(['order_book_id', 'date'], inplace=True)
-    return df
+# -*- coding: utf-8 -*-
+import datetime
+import warnings
+from collections import defaultdict
+
+import pandas as pd
+import numpy as np
+from rqdatac.utils import today_int
+
+from rqdatac.validators import (
+    ensure_list_of_string,
+    ensure_order_book_ids,
+    check_items_in_container,
+    ensure_date_range,
+    ensure_date_int,
+    ensure_string_in,
+)
+
+from rqdatac.client import get_client
+from rqdatac.decorators import export_as_api, ttl_cache, deprecated
+
+
+CONSENSUS_INDICATOR_FIELDS = [
+    'net_profit_t',
+    'net_profit_t1',
+    'net_profit_t2',
+    'revenue_t',
+    'revenue_t1',
+    'revenue_t2',
+    'net_asset_t',
+    'net_asset_t1',
+    'net_asset_t2',
+    'cash_from_operating_activities_t',
+    'cash_from_operating_activities_t1',
+    'cash_from_operating_activities_t2',
+    'profit_from_operation_t',
+    'profit_from_operation_t1',
+    'profit_from_operation_t2',
+    'cost_of_goods_sold_t',
+    'cost_of_goods_sold_t1',
+    'cost_of_goods_sold_t2',
+    'profit_before_tax_t',
+    'profit_before_tax_t1',
+    'profit_before_tax_t2',
+    'ebit_t',
+    'ebit_t1',
+    'ebit_t2',
+    'operating_revenue_per_share_t',
+    'operating_revenue_per_share_t1',
+    'operating_revenue_per_share_t2',
+    'eps_t',
+    'eps_t1',
+    'eps_t2',
+    'bps_t',
+    'bps_t1',
+    'bps_t2',
+    'share_cap_chg_date',
+    'report_main_id',
+    'grade_coef',
+    'targ_price',
+    'ebitda_t',
+    'ebitda_t1',
+    'ebitda_t2',
+    'profit_res_t',
+    'profit_res_t1',
+    'profit_res_t2',
+    'operate_cash_flow_per_share_t',
+    'operate_cash_flow_per_share_t1',
+    'operate_cash_flow_per_share_t2',
+    'profit_chg_t',
+    'profit_chg_t1',
+    'profit_chg_t2',
+    'grade_chg_t',
+    'grade_chg_t1',
+    'grade_chg_t2',
+    'targ_price_chg_t',
+    'targ_price_chg_t1',
+    'targ_price_chg_t2',
+    'chg_reason_t',
+    'chg_reason_t1',
+    'chg_reason_t2',
+    'create_time',
+    'summary',
+]
+
+NON_NUMERIC_FIELDS = [
+    'share_cap_chg_date',
+    'report_main_id',
+    'chg_reason_t',
+    'chg_reason_t1',
+    'chg_reason_t2',
+    'create_time',
+    'summary',
+]
+
+
+DTYPES = {k: '<f8' for k in CONSENSUS_INDICATOR_FIELDS if k not in NON_NUMERIC_FIELDS}
+DTYPES['fiscal_year'] = '<u4'
+DTYPES['data_source'] = '<f2'
+
+
+CONSENSUS_PRICE_FIELDS = [
+    'half_year_target_price',
+    'one_year_target_price',
+    'quarter_recommendation',
+    'half_year_recommendation',
+    'one_year_recommendation',
+]
+
+CONSENSUS_PRICE_FIELDS_MAP = {
+    'half_year_target_price': ('price_raw', 'price_prd', 'M06'),
+    'one_year_target_price': ('price_raw', 'price_prd', 'Y01'),
+    'quarter_recommendation': ('grd_coef', 'grd_prd', '1'),
+    'half_year_recommendation': ('grd_coef', 'grd_prd', '2'),
+    'one_year_recommendation': ('grd_coef', 'grd_prd', '3'),
+}
+
+PRICE_DTYPES = {
+    'half_year_target_price': '<f8',
+    'one_year_target_price': '<f8',
+    'quarter_recommendation': '<f8',
+    'half_year_recommendation': '<f8',
+    'one_year_recommendation': '<f8',
+    'price_raw': '<f8',
+}
+
+
+@export_as_api(namespace='consensus')
+def get_indicator(order_book_ids, fiscal_year, fields=None, start_date=None, end_date=None, date_rule=None, market='cn'):
+    """
+    获取一致预期数据
+
+    :param order_book_ids: 股票名称
+    :param fiscal_year: int/str, 查询年份
+    :param fields: list,  一致预期字段
+    :param start_date: date-like object, 开始日期, 默认为None
+    :param end_date: date-like object, 结束日期, 默认为None
+    :param date_rule: str 日期截取规则，和start_date/end_date一起使用，默认为None不生效
+        'rpt_dt'，根据研报发布日期RPT_DT截取返回的数据
+        'create_tm',根据今日投资入库时间截取返回的数据
+        'rice_create_tm',根据米筐入库时间截取返回的数据
+    :param market: (Default value = 'cn')
+    :returns: pandas  MultiIndex DataFrame
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+    if fields is None:
+        fields = CONSENSUS_INDICATOR_FIELDS
+    else:
+        fields = ensure_list_of_string(fields, 'consensus_indicator')
+        check_items_in_container(fields, CONSENSUS_INDICATOR_FIELDS, 'consensus_indicator')
+
+    if start_date is not None:
+        start_date = ensure_date_int(start_date)
+    if end_date is not None:
+        end_date = ensure_date_int(end_date)
+    if date_rule is not None:
+        ensure_string_in(date_rule, ('rpt_dt', 'create_tm', 'rice_create_tm'), 'date_rule')
+    elif start_date is not None or end_date is not None:
+        raise ValueError('Ambiguous: date_rule should be specific!')
+    if fiscal_year is not None:
+        fiscal_year = int(fiscal_year)
+    elif start_date is None and end_date is None:
+        raise ValueError('at least one of (start_date/end_date, fiscal_year) should be non-none value.')
+
+    data = get_client().execute('consensus.get_indicator_v2', order_book_ids, fiscal_year, fields, start_date, end_date, date_rule, market=market)
+    if not data:
+        return None
+    df = pd.DataFrame(data)
+    df.set_index(['order_book_id', 'date'], inplace=True)
+    df.sort_index(inplace=True)
+    dtypes = {f: DTYPES[f] for f in df.columns if f in DTYPES}
+    df = df.astype(dtypes)
+    return df
+
+
+@export_as_api(namespace='consensus')
+def get_price(order_book_ids, start_date=None, end_date=None, fields=None, adjust_type='none', market='cn'):
+    """
+    获取一致预期股价预测数据
+
+    :param order_book_ids: 股票名称
+    :param start_date: 开始日期， date-like object, 默认三月前那天
+    :param end_date: 结束日期， date-like object， 默认当天
+    :param fields: list,  一致预期字段
+    :param adjust_type: 可选参数,默认为‘none', 返回原始数据
+            'pre' 返回前复权数据
+            'post' 返回后复权数据
+    :param market: (Default value = 'cn')
+    :returns: pandas MultiIndex DataFrame
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+
+    if fields is None:
+        fields = CONSENSUS_PRICE_FIELDS
+    else:
+        fields = ensure_list_of_string(fields, 'consensus_price')
+        check_items_in_container(fields, CONSENSUS_PRICE_FIELDS, 'consensus_price')
+
+    start_date, end_date = ensure_date_range(start_date, end_date)
+
+    data = get_client().execute('consensus.get_price', order_book_ids, start_date, end_date, market=market)
+    if not data:
+        return None
+
+    records = defaultdict(dict)
+    for r in data:
+        key = (r['order_book_id'], r['institute'], r['date'])
+        if key not in records:
+            records[key].update(r)
+        for field in fields:
+            name, f, value = CONSENSUS_PRICE_FIELDS_MAP[field]
+            if r[f] == value:
+                records[key][field] = r[name]
+    df = pd.DataFrame(list(records.values()))
+    df.set_index(['order_book_id', 'date'], inplace=True)
+    df.sort_index(inplace=True)
+    for f in fields:
+        if f not in df.columns:
+            df[f] = None
+    df = df.astype({f: PRICE_DTYPES[f] for f in fields if f in PRICE_DTYPES})
+
+    if adjust_type != 'none':
+        adjust_fields = list(set(CONSENSUS_PRICE_FIELDS[:2]) & set(fields))
+        if not adjust_fields:
+            return df
+
+        from rqdatac.services.detail.adjust_price import get_ex_factor_for
+        ex_factors = get_ex_factor_for(order_book_ids, market)
+        pre = adjust_type == 'pre'
+
+        def adjust(sub):
+            factors = ex_factors.get(sub.name)
+            if factors is None:
+                return sub
+            factor = np.take(factors.values, factors.index.searchsorted(sub.index.get_level_values(1), side='right') - 1)
+            if pre:
+                factor /= factors.iloc[-1]
+
+            sub[adjust_fields] = (sub[adjust_fields].values.T * factor).T
+            return sub
+
+        df = df.groupby(level=0).apply(adjust)
+        df[adjust_fields] = np.round(df[adjust_fields], 4)
+
+    return df
+
+
+CONSENSUS_COMP_INDICATOR_FIELDS = [
+    'comp_operating_revenue_t',
+    'comp_con_operating_revenue_t1',
+    'comp_con_operating_revenue_t2',
+    'comp_con_operating_revenue_t3',
+    'comp_con_operating_revenue_ftm',
+    'comp_net_profit_t',
+    'comp_con_net_profit_t1',
+    'comp_con_net_profit_t2',
+    'comp_con_net_profit_t3',
+    'comp_con_net_profit_ftm',
+    'comp_eps_t',
+    'comp_con_eps_t1',
+    'comp_con_eps_t2',
+    'comp_con_eps_t3',
+    'comp_net_asset_t',
+    'comp_con_net_asset_t1',
+    'comp_con_net_asset_t2',
+    'comp_con_net_asset_t3',
+    'comp_con_net_asset_ftm',
+    'comp_cash_flow_t',
+    'comp_con_cash_flow_t1',
+    'comp_con_cash_flow_t2',
+    'comp_con_cash_flow_t3',
+    'comp_con_cash_flow_ftm',
+    'comp_roe_t',
+    'comp_con_roe_t1',
+    'comp_con_roe_t2',
+    'comp_con_roe_t3',
+    'comp_con_roe_ftm',
+    'comp_pe_t',
+    'comp_con_pe_t1',
+    'comp_con_pe_t2',
+    'comp_con_pe_t3',
+    'comp_con_pe_ftm',
+    'comp_ps_t',
+    'comp_con_ps_t1',
+    'comp_con_ps_t2',
+    'comp_con_ps_t3',
+    'comp_con_ps_ftm',
+    'comp_pb_t',
+    'comp_con_pb_t1',
+    'comp_con_pb_t2',
+    'comp_con_pb_t3',
+    'comp_con_pb_ftm',
+    'comp_peg',
+    'comp_operating_revenue_growth_ratio_t',
+    'comp_con_operating_revenue_growth_ratio_t1',
+    'comp_con_operating_revenue_growth_ratio_t2',
+    'comp_con_operating_revenue_growth_ratio_t3',
+    'comp_con_operating_revenue_growth_ratio_ftm',
+    'comp_net_profit_growth_ratio_t',
+    'comp_con_net_profit_growth_ratio_t1',
+    'comp_con_net_profit_growth_ratio_t2',
+    'comp_con_net_profit_growth_ratio_t3',
+    'comp_con_net_profit_growth_ratio_ftm',
+    'con_grd_coef',
+    'con_targ_price',
+    'comp_con_eps_ftm',
+    'ty_profit_t1',
+    'ty_profit_t2',
+    'ty_profit_t3',
+    'ty_profit_ftm',
+    'ty_eps_t1',
+    'ty_eps_t2',
+    'ty_eps_t3',
+    'ty_eps_ftm',
+]
+
+CONSENSUS_COMP_INDICATOR_FIELDS_V = [
+    'comp_con_net_profit_t1',
+    'comp_con_net_profit_t2',
+    'comp_con_net_profit_t3',
+    'comp_con_operating_revenue_t1',
+    'comp_con_operating_revenue_t2',
+    'comp_con_operating_revenue_t3',
+    'comp_con_cash_flow_t1',
+    'comp_con_cash_flow_t2',
+    'comp_con_cash_flow_t3',
+    'comp_con_eps_t1',
+    'comp_con_eps_t2',
+    'comp_con_eps_t3',
+    'comp_con_eps_ftm',
+]
+
+CONSENSUS_COMP_INDICATORS_FIELDS_GRD_HIST = ['con_targ_price']
+
+COMP_INDICATORS_DTYPES = {
+    field: '<f8' for field in
+    CONSENSUS_COMP_INDICATOR_FIELDS + CONSENSUS_COMP_INDICATOR_FIELDS_V + CONSENSUS_COMP_INDICATORS_FIELDS_GRD_HIST
+}
+
+
+@export_as_api(namespace='consensus')
+def get_comp_indicators(order_book_ids, start_date=None, end_date=None, fields=None, report_range=0, market='cn'):
+    """
+    获取个股一致预期表
+
+    :param order_book_ids: 股票名称
+    :param start_date: date-like object, 默认当日
+    :param end_date: date-like object, 默认为当日
+    :param fields: list,  一致预期字段
+    :param report_range: int, 研报范围
+        0-不考虑补录入&包括所有报告数据（历史值修复会存在数值变动，需要不变的话传入3）
+        1-考虑补录入&包括所有报告数据
+        2-考虑补录入&仅包括公司报告数据
+        3-不考虑补录入&包括所有报告数据
+        4-不考虑补录入&仅包括公司报告数据
+    :param market: (Default value = 'cn')
+
+    :returns: pandas MultiIndex DataFrame
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+    today = today_int()
+    start_date = ensure_date_int(start_date) if start_date else today
+    end_date = ensure_date_int(end_date) if end_date else today
+
+    assert report_range in (0, 1, 2, 3, 4), 'invalid report_range {}. should in (0,1,2,3,4)!'.format(report_range)
+    fields_pool = CONSENSUS_COMP_INDICATOR_FIELDS if report_range == 0 else CONSENSUS_COMP_INDICATOR_FIELDS_V
+    if report_range in (1, 3):
+        fields_pool += CONSENSUS_COMP_INDICATORS_FIELDS_GRD_HIST
+    if fields is None:
+        fields = fields_pool
+    else:
+        fields = ensure_list_of_string(fields, 'consensus_comp_indicator')
+        check_items_in_container(fields, fields_pool, 'consensus_comp_indicator')
+
+    data = get_client().execute(
+        'consensus.get_comp_indicators',
+        order_book_ids, start_date, end_date, fields, report_range=report_range,
+        market=market
+    )
+    if not data:
+        return None
+    if report_range in (1, 3) and len(fields) > 1 and (
+            set(fields) & set(CONSENSUS_COMP_INDICATORS_FIELDS_GRD_HIST)
+    ):
+        new_data = defaultdict(dict)
+        for d in data:
+            pkey = (d['order_book_id'], d['date'])
+            if pkey not in new_data:
+                new_data[pkey] = d
+                continue
+            for k, v in d.items():
+                if k not in new_data[pkey]:
+                    new_data[pkey][k] = v
+        df = pd.DataFrame(list(new_data.values()))
+    else:
+        df = pd.DataFrame(data)
+    df.set_index(['order_book_id', 'date'], inplace=True)
+    df.sort_index(inplace=True)
+    dtypes = {f: COMP_INDICATORS_DTYPES[f] for f in df.columns if f in COMP_INDICATORS_DTYPES}
+    df = df.astype(dtypes)
+    return df
+
+
+@ttl_cache(3600)
+def _all_industries(market='cn'):
+    return get_client().execute('consensus.all_industries', market=market)
+
+
+@ttl_cache(3600)
+def _all_industry_dict(market='cn'):
+    result = defaultdict(list)
+    for v in _all_industries(market):
+        result[v['industry_code']].append(v['industry_code'])
+        result[v['industry_name']].append(v['industry_code'])
+    return result
+
+
+def ensure_industries(industries):
+    industries = ensure_list_of_string(industries)
+    code_mapping = _all_industry_dict()
+    industry_codes = set()
+    for i in industries:
+        if i in code_mapping:
+            industry_codes.update(code_mapping[i])
+    return list(industry_codes)
+
+
+@export_as_api(namespace='consensus')
+def all_industries(market='cn'):
+    data = _all_industries(market)
+    return pd.DataFrame(data).set_index('industry_code')
+
+
+@export_as_api(namespace='consensus')
+def get_industry_rating(industries, start_date, end_date, market='cn'):
+    """
+    获取行业评级数据
+
+    :param industries: str or list, 行业code是今日投资行业分类代码, 可通过all_consensus_industries()获取全部
+    :param start_date: date-like object， 结束日期
+    :param end_date: date-like object, 结束日期
+    :param market: str, 默认'cn'
+    :return: pandas.DataFrame
+    """
+    industries = ensure_industries(industries)
+    if not industries:
+        warnings.warn('No valid industry found')
+        return None
+
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    data = get_client().execute('consensus.get_industry_rating', industries, start_date, end_date, market=market)
+    if not data:
+        return None
+
+    df = pd.DataFrame(data)
+    df.set_index(['industry_name', 'info_date'], inplace=True)
+    return df
+
+
+@export_as_api(namespace='consensus')
+def get_market_estimate(indexes, fiscal_year, market='cn'):
+    """
+    获取今日投资的机构预测大势表
+
+    :param indexes: str or list, 指数列表
+    :param fiscal_year: int, 年份
+    :param market: str, default 'cn'
+    :return: pandas MultiIndex DataFrame
+
+    :example:
+    >>> rqdatac.consensus.get_market_estimate('000001.XSHG', 2021)
+                                fiscal_year    institute start_date  ...  period  value
+    order_book_id info_date                        ...
+    000001.XSHG   2020-10-13        2021    财信证券 2021-01-01  ...  策略年度报告     中性
+                  2020-10-16        2021    华融证券 2021-01-01  ...  策略年度报告     中性
+                  2020-10-23        2021    东北证券 2021-01-01  ...  策略年度报告     中性
+                  2020-11-01        2021    方正证券 2021-01-01  ...  策略年度报告     中性
+                  2020-11-02        2021    西南证券 2021-01-01  ...  策略年度报告     中性
+                                    ...      ...      ...       ...     ...        ...
+                  2021-12-31        2021    山西证券 2022-01-01  ...  策略月度报告     中性
+                  2021-12-31        2021    方正证券 2021-12-31  ...   策略日报等     中性
+                  2021-12-31      2021    东亚前海证券 2022-01-01  ...  策略月度报告     中性
+                  2021-12-31        2021    粤开证券 2022-01-01  ...  策略月度报告     乐观
+                  2021-12-31        2021    渤海证券 2022-01-01  ...  策略月度报告     中性
+
+    返回字段:
+    fiscal_year: 预测年份
+    institue: 机构名称
+    start_date: 预测开始日期
+    end_date: 预测结束日期
+    high: 预测高点
+    low: 预测低点
+    period: 预测时段
+    value: 预测值
+    """
+
+    indexes = ensure_list_of_string(indexes)
+    indexes = ensure_order_book_ids(indexes, type='INDX')
+    fiscal_year = int(fiscal_year)
+    data = get_client().execute('consensus.get_market_estimate', indexes, fiscal_year, market=market)
+    if not data:
+        return None
+    df = pd.DataFrame(data)
+    df.set_index(['order_book_id', 'info_date'], inplace=True)
+    df.sort_index(inplace=True)
+    return df
+
+
+export_as_api(deprecated(
+    func=get_indicator,
+    msg='get_consensus_indicator will be deprecated in future. use consensus.get_indicator instead.'
+), name='get_consensus_indicator')
+export_as_api(deprecated(
+    func=get_price,
+    msg='get_consensus_price will be deprecated in future. use consensus.get_price instead.'
+), name='get_consensus_price')
+export_as_api(deprecated(
+    func=get_comp_indicators,
+    msg='get_consensus_comp_indicators will be deprecated in future. use consensus.get_comp_indicators instead.'
+), name='get_consensus_comp_indicators')
+export_as_api(deprecated(
+    func=all_industries,
+    msg='all_consensus_industries will be deprecated in future. use consensus.all_industries instead.'
+), name='all_consensus_industries')
+export_as_api(deprecated(
+    func=get_industry_rating,
+    msg='get_consensus_industry_rating will be deprecated in future. use consensus.get_industry_rating instead.'
+), name='get_consensus_industry_rating')
+export_as_api(deprecated(
+    func=get_market_estimate,
+    msg='get_consensus_market_estimate will be deprecated in future. use consensus.get_market_estimate instead.'
+), name='get_consensus_market_estimate')
+
+
+VALID_STAT_PERIODS = ['WEEK1', 'MON1', 'MON3', 'MON6', 'YEAR1']
+
+
+@export_as_api(namespace='consensus')
+def get_security_change(order_book_ids, start_date=None, end_date=None, stat_periods=None):
+    """
+    获取机构报告统计周期内个股调整明细表
+
+    :param order_book_ids: 股票名称
+    :param start_date: 开始日期， date-like object, 默认三月前那天
+    :param end_date: 结束日期， date-like object， 默认当天
+    :param stat_periods: 统计周期，str/list, 默认全部, 可选值 {'WEEK1', 'MON1', 'MON3', 'MON6', 'YEAR1'}
+
+    :return: pandas MultiIndex DataFrame
+
+    返回字段：
+    order_book_id
+    date
+    stat_period
+    institute
+    adjust_classification: 调整类别
+        1 盈利预测调高;
+        2 盈利预测调低;
+        3 投资评级调高;
+        4 投资评级调低;
+        5 盈利预测维持;
+        6 投资评级维持;
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+
+    if stat_periods is None:
+        stat_periods = VALID_STAT_PERIODS
+    else:
+        stat_periods = ensure_list_of_string(stat_periods)
+        check_items_in_container(stat_periods, VALID_STAT_PERIODS, 'stat_periods')
+
+    data = get_client().execute('consensus.get_security_change', order_book_ids, start_date, end_date, stat_periods)
+    if not data:
+        return None
+    df = pd.DataFrame(data)
+    df.set_index(['order_book_id', 'date'], inplace=True)
+    df.sort_index(inplace=True)
+    return df
+
+
+REPORT_PERIODS = {'q1': 103, 'q2': 106, 'q3': 109, 'q4': 112}
+REPORT_TYPES = {'financial_reports': 0, 'performance_forecast': 1, 'current_performance': 2}
+APPRAISAL_RESULTS = {'exceed': 1, 'below': 2}
+VALID_REPORT_PERIODS = list(REPORT_PERIODS)
+VALID_REPORT_TYPES = list(REPORT_TYPES)
+VALID_APPRAISAL_RESULTS = list(APPRAISAL_RESULTS)
+REVERSED_REPORT_PERIODS = {103: 'q1', 106: 'q2', 109: 'q3', 112: 'q4'}
+REVERSED_REPORT_TYPES = {0: 'financial_reports', 1: 'performance_forecast', 2: 'current_performance'}
+REVERSED_APPRAISAL_RESULTS = {1: 'exceed', 2: 'below'}
+
+
+@export_as_api(namespace='consensus')
+def get_expect_appr_exceed(
+        order_book_ids,
+        start_date=None,
+        end_date=None,
+        report_year=None,
+        report_periods=None,
+        report_types=None,
+        appraisal_results=None
+):
+    """
+    获取超预期鉴定数据
+
+    :param order_book_ids: 股票名称
+    :param start_date: 开始日期， date-like object, 默认三月前那天
+    :param end_date: 结束日期， date-like object， 默认当天
+    :param report_year: int, 报告年度，默认全部
+    :param report_periods: str/list, 报告时段， 默认全部
+        q1  一季度
+        q2  半年度
+        q3  三季度
+        q4  年度
+    :param report_types: str/list, 业绩报告类型, 默认全部
+        financial_reports 财务定期报告
+        performance_forecast 业绩预告
+        current_performance 业绩快报
+    :param appraisal_results: str/list, 鉴定结果,默认全部
+        exceed 超预期
+        below 低于预期
+
+    :return: pandas MultiIndex DataFrame
+    
+    返回字段:
+    report_year: int，报告年度
+    report_period: str，报告时段
+    report_type: str, 业绩报告类型
+    appraisal_result: str，鉴定结果
+        exceed 超预期
+        below 低于预期
+    info_date: datetime.datetime
+    forecast_profit_max: float 业绩预告净利润上限，报告为年报时，对应的披露数据
+    forecast_profit_min: float 业绩预告净利润下限，报告为年报时，对应的披露数据
+    forecast_profit: float 业绩预告净利润，报告为年报时，对应的披露数据，包括定期报告和业绩快报数据
+    adjust_con_profit: float，调整后一致预期净利润，报告为季报时，对应季报发布日之后第5个交易日的一致预期（T+1年）仅计算5日内的预测明细数据（简单平均）
+    appraisal_date: datetime.datetime, 鉴定日
+    appraisal_standard: int, 鉴定标准
+        1 报表发布日鉴定
+        2 报表发布周期鉴定
+    con_cal_date: datetime.datetime, 一致预期计算日
+    con_profit: float, 一致预期净利润
+        鉴定标准为1时，为财报或者预告、快报发布日前一交易日的一致预期净利润；
+        鉴定标准为2时，为对应财报期最后一个交易日的一致预期净利润
+    profit_ex_rate: float, 业绩超预期幅度
+        超预期幅度=(报告净利润或调整后一致预期净利润 - 一致预期净利润) / ABS(一致预期净利润)
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+
+    if report_periods is None:
+        report_periods = VALID_REPORT_PERIODS
+    else:
+        report_periods = ensure_list_of_string(report_periods)
+        check_items_in_container(report_periods, VALID_REPORT_PERIODS, 'report_periods')
+
+    if report_types is None:
+        report_types = VALID_REPORT_TYPES
+    else:
+        report_types = ensure_list_of_string(report_types)
+        check_items_in_container(report_types, VALID_REPORT_TYPES, 'report_types')
+
+    if appraisal_results is None:
+        appraisal_results = VALID_APPRAISAL_RESULTS
+    else:
+        appraisal_results = ensure_list_of_string(appraisal_results)
+        check_items_in_container(appraisal_results, VALID_APPRAISAL_RESULTS, 'appraisal_results')
+
+    data = get_client().execute(
+        'consensus.get_expect_appr_exceed', order_book_ids, start_date, end_date, report_year,
+        [REPORT_PERIODS[_] for _ in report_periods],
+        [REPORT_TYPES[_] for _ in report_types],
+        [APPRAISAL_RESULTS[_] for _ in appraisal_results]
+    )
+    if not data:
+        return None
+    df = pd.DataFrame(data)
+    df['report_period'] = df['report_period'].map(REVERSED_REPORT_PERIODS)
+    df['report_type'] = df['report_type'].map(REVERSED_REPORT_TYPES)
+    df['appraisal_result'] = df['appraisal_result'].map(REVERSED_APPRAISAL_RESULTS)
+    df.set_index(['order_book_id', 'date'], inplace=True)
+    df.sort_index(inplace=True)
+    return df
+
+
+@export_as_api(namespace='consensus')
+def get_expect_prob(order_book_ids, expect_prob, start_date=None, end_date=None):
+    """
+    获取超/低于预期数据
+
+    :param order_book_ids: str or list, 股票列表
+    :param expect_prob: str, 'below': 低于预期， 'exceed': 超预期
+    :param start_date: 开始日期， date-like object, 默认三月前那天
+    :param end_date: 结束日期， date-like object， 默认当天
+
+    :return: pandas.DataFrame
+    
+    返回字段:
+    order_book_id
+    date
+    report_year: 报告年度
+    report_period: 报告时段
+        103  一季度 q1
+        106  半年度 q2
+        109  三季度 q3
+        112  年度 q4
+    info_classification: 预期类别代码
+        exceed:
+            1101 分析师上调（剔除明星分析师）
+            1102 明星分析师上调
+            1103 业绩公告后分析师全部上调
+            1201 业绩公告后一致预期净利润大幅上调
+            1301 研报标题超预期
+            1302 研报摘要超预期
+            1401 业绩预告/快报超上次预期
+            1403 业绩预告/快报超一致预期
+            1405 本期财报净利润超一致预期净利润（单季度）
+            1501 本期财报净利润同比增速超年度一致预期净利润同比增速
+            1502 本次预告/快报净利润同比增速超年度一致预期净利润同比增速
+            1503 本期财报净利润同比增速超一致预期净利润同比增速（单季度）
+            1504 本次预告/快报净利润同比增速超一致预期净利润同比增速（单季度）
+        below:
+            2101 分析师下调;
+            2102 明星分析师下调（名字待定）
+            2103 业绩公告后分析师全部下调
+            2201 一致预期净利润大幅下调
+            2301 研报标题低于预期
+            2302 研报摘要低于预期
+            2401 业绩预告/快报低于上次预期
+            2403 业绩预告/快报低于一致预期
+            2405 本期财报净利润低于一致预期净利润（单季度）
+            2501 本期财报净利润同比增速低于年度一致预期净利润同比增速
+            2502 本次预告/快报净利润同比增速低于年度一致预期净利润同比增速
+            2503 本期财报净利润同比增速低于一致预期净利润同比增速（单季度）
+            2504 本次预告/快报净利润同比增速低于一致预期净利润同比增速（单季度）
+    institute: 研究机构简称
+    info_summary: 超预期信息简述
+    report_date: 本次研究报告撰写日
+    title: 本次研报标题
+    author: 本次研报作者
+    est_profit: 本次研报预测净利润
+    report_date_last: 上次研究报告撰写日
+    title_last: 上次研报标题
+    est_profit_last: 上次研报预测净利润
+    info_date: 本次业绩报告日
+    report_type: 本次业绩报告类型
+        0 财务定期报告 financial_reports
+        1 业绩预告 performance_forecast
+        2 业绩快报 current_performance
+    forecast_profit_max: 本次业绩预告上限净利润 适用类型：1 业绩预告
+    forecast_profit_min: 本次业绩预告下限净利润 适用类型：1 业绩预告
+    profit: 本次业绩报告净利润	适用类型：0 财务定期报告； 2 业绩快报
+    profit_q: 本次业绩报告净利润（单季度） 适用类型：0 财务定期报告； 2 业绩快报
+    forecast_profit_growth_limit: 本次业绩预告净利润同比增速上下限
+        exceed: 下限
+        below:  上限
+        适用类型：0 财务定期报告； 2 业绩快报
+    profit_growth: 本次业绩报告净利润同比增速 适用类型：1 业绩预告
+    forecast_profit_growth_limit_q: 本次业绩预告净利润同比增速上下限（单季度）
+        exceed: 下限
+        below:  上限
+        适用类型：0 财务定期报告； 2 业绩快报
+    profit_growth_q: 本次业绩报告净利润同比增速（单季度） 适用类型：1 业绩预告 2 业绩快报
+    fin_report_date_last: 上次业绩报告公告日 适用类型：1 业绩预告； 2 业绩快报
+    fin_report_type_last: 上次业绩报告类型 1 业绩预告； 2 业绩快报
+    forecast_profit_max_last: 上次业绩预告上限净利润 适用类型：1 业绩预告；
+    forecast_profit_min_last: 上次业绩预告下限净利润 适用类型：1 业绩预告；
+    profit_last: 上次业绩快报净利润 	适用类型：2 业绩快报
+    con_calc_date: 本次一致预期计算日
+    con_profit: 本次一致预期净利润
+    con_calc_date_last: 上次一致预期计算日
+    con_profit_last: 上次一致预期净利润
+    con_profit_q_last: 上次一致预期净利润（单季度）
+    con_profit_growth_last: 上次一致预期净利润同比增速（年度）
+    con_profit_growth_q_last: 上次一致预期净利润同比增速（单季度）
+    expect_rate: 业绩上下调幅度或低于预期幅度
+    """
+
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+
+    ensure_string_in(expect_prob, ('exceed', 'below'))
+    if expect_prob not in ('exceed', 'below'):
+        raise ValueError('invalid expect_prob: {}'.format(expect_prob))
+
+    data = get_client().execute('consensus.get_expect_prob', order_book_ids, expect_prob, start_date, end_date)
+    if not data:
+        return None
+    df = pd.DataFrame(data)
+    df['report_period'] = df['report_period'].map(REVERSED_REPORT_PERIODS)
+    df['report_type'] = df['report_type'].map(REVERSED_REPORT_TYPES)
+    df.set_index(['order_book_id', 'date'], inplace=True)
+    df.sort_index(inplace=True)
+    return df
+
+
+FACTOR_EMOTIONS = [
+    'MTK_CONF',
+    'OPTIM_CONF',
+    'PESSIM_CONF',
+    'TY_PROFIT_T1_DEV',
+    'TY_PROFIT_T2_DEV',
+    'TY_PROFIT_T3_DEV',
+    'TY_EPS_T1_DEV',
+    'TY_EPS_T2_DEV',
+    'TY_EPS_T3_DEV',
+    'EPS_T1_DEV',
+    'EPS_T2_DEV',
+    'EPS_T3_DEV',
+    'PROFIT_T1_DEV',
+    'PROFIT_T2_DEV',
+    'PROFIT_T3_DEV',
+    'OP_REVEN_T1_DEV',
+    'OP_REVEN_T2_DEV',
+    'OP_REVEN_T3_DEV',
+    'OP_COST_T1_DEV',
+    'OP_COST_T2_DEV',
+    'OP_COST_T3_DEV',
+    'OP_PROFIT_T1_DEV',
+    'OP_PROFIT_T2_DEV',
+    'OP_PROFIT_T3_DEV',
+    'OP_CASH_FLOW_T1_DEV',
+    'OP_CASH_FLOW_T2_DEV',
+    'OP_CASH_FLOW_T3_DEV',
+    'ROE_T1_DEV',
+    'ROE_T2_DEV',
+    'ROE_T3_DEV',
+    'PEG_1Y_DEV',
+    'PEG_3Y_DEV',
+    'PB_T1_DEV',
+    'PB_T2_DEV',
+    'PB_T3_DEV',
+    'PE_T1_DEV',
+    'PE_T2_DEV',
+    'PE_T3_DEV',
+    'PS_T1_DEV',
+    'PS_T2_DEV',
+    'PS_T3_DEV',
+    'PCF_T1_DEV',
+    'PCF_T2_DEV',
+    'PCF_T3_DEV',
+]
+FACTOR_EMOTIONS = ['{}_{}D'.format(f, d) for d in [7, 14, 30, 60, 90] for f in FACTOR_EMOTIONS]
+
+FACTOR_VALUATIONS = [
+    'PEG_1Y',
+    'PEG_1Y_SCO',
+    'PEG_3Y',
+    'PEG_3Y_SCO',
+    'RV_VALUT_EM',
+    'RV_VALUT_EM_SCO',
+    'PB_T',
+    'PE_T',
+    'PS_T',
+    'PCF_T',
+    'PB_T_SCO',
+    'PE_T_SCO',
+    'PS_T_SCO',
+    'PCF_T_SCO',
+    'PB_T1',
+    'PE_T1',
+    'PS_T1',
+    'PCF_T1',
+    'PB_T1_SCO',
+    'PE_T1_SCO',
+    'PS_T1_SCO',
+    'PCF_T1_SCO',
+    'PB_T2',
+    'PE_T2',
+    'PS_T2',
+    'PCF_T2',
+    'PB_T2_SCO',
+    'PE_T2_SCO',
+    'PS_T2_SCO',
+    'PCF_T2_SCO',
+    'PB_T3',
+    'PE_T3',
+    'PS_T3',
+    'PCF_T3',
+    'PB_T3_SCO',
+    'PE_T3_SCO',
+    'PS_T3_SCO',
+    'PCF_T3_SCO',
+    'PB_FTM',
+    'PE_FTM',
+    'PS_FTM',
+    'PCF_FTM',
+    'PB_FTM_SCO',
+    'PE_FTM_SCO',
+    'PS_FTM_SCO',
+    'PCF_FTM_SCO',
+]
+
+FACTOR_GROWTHS = [
+    'TY_PROFIT_T1_CHG',
+    'TY_PROFIT_T2_CHG',
+    'TY_PROFIT_T3_CHG',
+    'TY_EPS_T1_CHG',
+    'TY_EPS_T2_CHG',
+    'TY_EPS_T3_CHG',
+    'PROFIT_T1_CHG',
+    'PROFIT_T2_CHG',
+    'PROFIT_T3_CHG',
+    'EPS_T1_CHG',
+    'EPS_T2_CHG',
+    'EPS_T3_CHG',
+    'OP_REVEN_T1_CHG',
+    'OP_REVEN_T2_CHG',
+    'OP_REVEN_T3_CHG',
+    'OP_COST_T1_CHG',
+    'OP_COST_T2_CHG',
+    'OP_COST_T3_CHG',
+    'OP_PROFIT_T1_CHG',
+    'OP_PROFIT_T2_CHG',
+    'OP_PROFIT_T3_CHG',
+    'OP_CASH_FLOW_T1_CHG',
+    'OP_CASH_FLOW_T2_CHG',
+    'OP_CASH_FLOW_T3_CHG',
+    'ASSET_T1_CHG',
+    'ASSET_T2_CHG',
+    'ASSET_T3_CHG',
+    'ROE_T1_CHG',
+    'ROE_T2_CHG',
+    'ROE_T3_CHG',
+]
+FACTOR_GROWTHS = ['{}_{}D'.format(f, d) for d in [7, 14, 30, 60, 90] for f in FACTOR_GROWTHS]
+
+FACTOR_FINS = [
+    'RPT_YR_T',
+    'ANN_RPT_DT_LAST',
+    'PROFIT_T',
+    'PROFIT_T1',
+    'PROFIT_T2',
+    'PROFIT_T3',
+    'PROFIT_FTM',
+    'PROFIT_YOY_T',
+    'PROFIT_YOY_T1',
+    'PROFIT_YOY_T2',
+    'PROFIT_YOY_T3',
+    'PROFIT_YOY_FTM',
+    'PROFIT_CAGR_2Y',
+    'PROFIT_CAGR_3Y',
+    'TY_PROFIT_T1',
+    'TY_PROFIT_T2',
+    'TY_PROFIT_T3',
+    'TY_PROFIT_FTM',
+    'TY_PROFIT_YOY_T1',
+    'TY_PROFIT_YOY_T2',
+    'TY_PROFIT_YOY_T3',
+    'TY_PROFIT_YOY_FTM',
+    'EPS_T',
+    'EPS_T1',
+    'EPS_T2',
+    'EPS_T3',
+    'EPS_FTM',
+    'EPS_YOY_T',
+    'EPS_YOY_T1',
+    'EPS_YOY_T2',
+    'EPS_YOY_T3',
+    'EPS_YOY_FTM',
+    'TY_EPS_T1',
+    'TY_EPS_T2',
+    'TY_EPS_T3',
+    'TY_EPS_FTM',
+    'TY_EPS_YOY_T1',
+    'TY_EPS_YOY_T2',
+    'TY_EPS_YOY_T3',
+    'TY_EPS_YOY_FTM',
+    'OP_REVEN_T',
+    'OP_REVEN_T1',
+    'OP_REVEN_T2',
+    'OP_REVEN_T3',
+    'OP_REVEN_FTM',
+    'OP_REVEN_YOY_T',
+    'OP_REVEN_YOY_T1',
+    'OP_REVEN_YOY_T2',
+    'OP_REVEN_YOY_T3',
+    'OP_REVEN_YOY_FTM',
+    'OP_REVEN_CAGR_2Y',
+    'OP_REVEN_CAGR_3Y',
+    'OP_COST_T',
+    'OP_COST_T1',
+    'OP_COST_T2',
+    'OP_COST_T3',
+    'OP_COST_FTM',
+    'OP_COST_YOY_T',
+    'OP_COST_YOY_T1',
+    'OP_COST_YOY_T2',
+    'OP_COST_YOY_T3',
+    'OP_COST_YOY_FTM',
+    'OP_PROFIT_T',
+    'OP_PROFIT_T1',
+    'OP_PROFIT_T2',
+    'OP_PROFIT_T3',
+    'OP_PROFIT_FTM',
+    'OP_PROFIT_YOY_T',
+    'OP_PROFIT_YOY_T1',
+    'OP_PROFIT_YOY_T2',
+    'OP_PROFIT_YOY_T3',
+    'OP_PROFIT_YOY_FTM',
+    'ROE_T',
+    'ROE_T1',
+    'ROE_T2',
+    'ROE_T3',
+    'ROE_FTM',
+    'ROE_YOY_T',
+    'ROE_YOY_T1',
+    'ROE_YOY_T2',
+    'ROE_YOY_T3',
+    'ROE_YOY_FTM',
+    'OP_CASH_FLOW_T',
+    'OP_CASH_FLOW_T1',
+    'OP_CASH_FLOW_T2',
+    'OP_CASH_FLOW_T3',
+    'OP_CASH_FLOW_FTM',
+    'OP_CASH_FLOW_YOY_T',
+    'OP_CASH_FLOW_YOY_T1',
+    'OP_CASH_FLOW_YOY_T2',
+    'OP_CASH_FLOW_YOY_T3',
+    'OP_CASH_FLOW_YOY_FTM',
+    'ASSET_T',
+    'ASSET_T1',
+    'ASSET_T2',
+    'ASSET_T3',
+    'ASSET_FTM',
+    'ASSET_YOY_T',
+    'ASSET_YOY_T1',
+    'ASSET_YOY_T2',
+    'ASSET_YOY_T3',
+    'ASSET_YOY_FTM',
+    'EARN_QUAL',
+]
+
+VALID_FACTOR_FIELDS = FACTOR_EMOTIONS + FACTOR_GROWTHS + FACTOR_VALUATIONS + FACTOR_FINS
+
+
+@export_as_api(namespace='consensus')
+def get_factor(order_book_ids, factors, start_date=None, end_date=None):
+    """
+    获取一致预期因子库数据
+
+    :param order_book_ids: str or list, 股票列表
+    :param factors: str or list, 因子列表
+    :param start_date: 开始日期， date-like object, 默认三月前那天
+    :param end_date: 结束日期， date-like object， 默认当天
+
+    :return: pandas.DataFrame
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+
+    factors = ensure_list_of_string(factors)
+    check_items_in_container(factors, VALID_FACTOR_FIELDS, 'factors')
+
+    data = get_client().execute('consensus.get_factor', order_book_ids, factors, start_date, end_date)
+    if not data:
+        return
+
+    result = defaultdict(dict)
+    for r in data:
+        key = (r['order_book_id'], r['date'])
+        result[key].update(r)
+
+    df = pd.DataFrame(result.values())
+    df.set_index(['order_book_id', 'date'], inplace=True)
+    fields = [f for f in df.columns if f != 'ANN_RPT_DT_LAST']
+    df[fields] = df[fields].astype(float)
+    df.sort_index(inplace=True)
+    return df
+
+
+ANALYST_MOMEMTUM_FIELDS = [
+    'profit_chg_1w',
+    'profit_chg_1w_rank',
+    'profit_chg_1w_sco',
+    'profit_chg_2w',
+    'profit_chg_2w_rank',
+    'profit_chg_2w_sco',
+    'profit_chg_1m',
+    'profit_chg_1m_rank',
+    'profit_chg_1m_sco',
+    'profit_chg_2m',
+    'profit_chg_2m_rank',
+    'profit_chg_2m_sco',
+    'profit_chg_3m',
+    'profit_chg_3m_rank',
+    'profit_chg_3m_sco',
+    'op_reven_chg_1w',
+    'op_reven_chg_1w_rank',
+    'op_reven_chg_1w_sco',
+    'op_reven_chg_2w',
+    'op_reven_chg_2w_rank',
+    'op_reven_chg_2w_sco',
+    'op_reven_chg_1m',
+    'op_reven_chg_1m_rank',
+    'op_reven_chg_1m_sco',
+    'op_reven_chg_2m',
+    'op_reven_chg_2m_rank',
+    'op_reven_chg_2m_sco',
+    'op_reven_chg_3m',
+    'op_reven_chg_3m_rank',
+    'op_reven_chg_3m_sco',
+    'ty_est_dev',
+    'ty_est_dev_rank',
+    'ty_est_dev_sco',
+    'est_em_bic_sco',
+    'est_em_non_bic_sco',
+    'grd_em_1m',
+    'grd_em_1m_rank',
+    'grd_em_1m_sco',
+    'grd_em_2m',
+    'grd_em_2m_rank',
+    'grd_em_2m_sco',
+    'grd_em_3m',
+    'grd_em_3m_rank',
+    'grd_em_3m_sco',
+    'targ_price_space',
+    'targ_price_space_rank',
+    'targ_price_space_sco',
+    'grd_em_sco',
+    'ana_em_bic_sco',
+    'ana_em_non_bic_sco',
+]
+
+OBJECT_DTYPE = np.dtype('O')
+
+
+@export_as_api(namespace='consensus')
+def get_analyst_momentum(
+        order_book_ids,
+        fiscal_year=None,
+        start_date=None,
+        end_date=None,
+        fields=None,
+        report_periods=None,
+        report_range=None,
+        market='cn'
+):
+    """
+    获取一致预期分析师动能数据
+
+    :param order_book_ids: 股票名称
+    :param fiscal_year: int/str, 查询年份, 默认返回全部
+    :param start_date: date-like object, 开始日期, 默认三月前那天
+    :param end_date: date-like object, 结束日期, 默认当天
+    :param fields: stor/list, 数据字段, 默认返回全部
+    :param report_periods: str/list, 报告时段， 默认全部
+        q1  一季度
+        q2  半年度
+        q3  三季度
+        q4  年度
+    :param report_range: int, 默认全部
+        1-考虑补录入&包括所有报告数据
+        3-不考虑补录入&包括所有报告数据
+    :param market: Default('cn')
+    :returns: pandas  MultiIndex DataFrame
+    
+    返回字段说明:
+    profit_chg_1w	        净利润1周变化率        [一致预期净利润（当前）-一致预期净利润（1周前）]/ [︱一致预期净利润（1周前）︱+0.5*总股本]
+    profit_chg_1w_rank	    净利润1周变化率排名      全市场排名
+    profit_chg_1w_sco	    净利润1周变化率得分      百分制打分，排名最靠前的1%为100分。
+    profit_chg_2w   	    净利润2周变化率        [一致预期净利润（当前）-一致预期净利润（2周前）]/ [︱一致预期净利润（2周前）︱+0.5*总股本]
+    profit_chg_2w_rank	    净利润2周变化率排名      全市场排名
+    profit_chg_2w_sco	    净利润2周变化率得分      百分制打分，排名最靠前的1%为100分。
+    profit_chg_1m	        净利润1月变化率        [一致预期净利润（当前）-一致预期净利润（1月前）]/ [︱一致预期净利润（1月前）︱+0.5*总股本]
+    profit_chg_1m_rank	    净利润1月变化率排名      全市场排名
+    profit_chg_1m_sco	    净利润1月变化率得分      百分制打分，排名最靠前的1%为100分。
+    profit_chg_2m   	    净利润2月变化率        [一致预期净利润（当前）-一致预期净利润（2月前）]/ [︱一致预期净利润（2月前）︱+0.5*总股本]
+    profit_chg_2m_rank	    净利润2月变化率排名      全市场排名
+    profit_chg_2m_sco	    净利润2月变化率得分      百分制打分，排名最靠前的1%为100分。
+    profit_chg_3m	        净利润3月变化率        [一致预期净利润（当前）-一致预期净利润（3月前）]/ [︱一致预期净利润（3月前）︱+0.5*总股本]
+    profit_chg_3m_rank	    净利润3月变化率排名      全市场排名
+    profit_chg_3m_sco	    净利润3月变化率得分      百分制打分，排名最靠前的1%为100分。
+    op_reven_chg_1w	        业务收入1周变化率       [一致预期业务收入（当前）-一致预期业务收入（1周前）]/ 一致预期业务收入（1周前）
+    op_reven_chg_1w_rank	业务收入1周变化率排名     全市场排名
+    op_reven_chg_1w_sco	    业务收入1周变化率得分     百分制打分，排名最靠前的1%为100分。
+    op_reven_chg_2w	        业务收入2周变化率       [一致预期业务收入（当前）-一致预期业务收入（2周前）]/ 一致预期业务收入（2周前）
+    op_reven_chg_2w_rank	业务收入2周变化率排名     全市场排名
+    op_reven_chg_2w_sco	    业务收入2周变化率得分     百分制打分，排名最靠前的1%为100分。
+    op_reven_chg_1m	        业务收入1月变化率       [一致预期业务收入（当前）-一致预期业务收入（1月前）]/ 一致预期业务收入（1月前）
+    op_reven_chg_1m_rank	业务收入1月变化率排名     全市场排名
+    op_reven_chg_1m_sco	    业务收入1月变化率得分     百分制打分，排名最靠前的1%为100分。
+    op_reven_chg_2m	        业务收入2月变化率       [一致预期业务收入（当前）-一致预期业务收入（2月前）]/ 一致预期业务收入（2月前）
+    op_reven_chg_2m_rank	业务收入2月变化率排名     全市场排名
+    op_reven_chg_2m_sco	    业务收入2月变化率得分     百分制打分，排名最靠前的1%为100分。
+    op_reven_chg_3m	        业务收入3月变化率       [一致预期业务收入（当前）-一致预期业务收入（3月前）]/ 一致预期业务收入（3月前）
+    op_reven_chg_3m_rank	业务收入3月变化率排名     全市场排名
+    op_reven_chg_3m_sco	    业务收入3月变化率得分     百分制打分，排名最靠前的1%为100分。
+    ty_est_dev	            天眼预期偏离度	        （天眼预期-一致预期）/(｜一致预期｜+0.5*总股本）
+    ty_est_dev_rank	        天眼预期偏离度排名       全市场排名
+    ty_est_dev_sco	        天眼预期偏离度得分       百分制打分，排名最靠前的1%为100分。
+    est_em_bic_sco	        预期动能得分(考虑业务收入变化率)   考虑了收入的变化率
+    est_em_non_bic_sco	    预期动能得分(不考虑业务收入变化率)  未考虑了收入的变化率
+    grd_em_1m           	评级动能1月            1个月前评级系数-现在评级系数；对于单个评级，强力买入1.00；买入2.00；观望3.00；适度减持4.00；卖出5.00。评级系数为60天内所有给出评级机构最新评级的简单平均。
+    grd_em_1m_rank	        评级动能1月排名         全市场排名
+    grd_em_1m_sco	        评级动能1月得分         百分制打分，排名最靠前的1%为100分。
+    grd_em_2m	            评级动能2月            2个月前评级系数-现在评级系数；对于单个评级，强力买入1.00；买入2.00；观望3.00；适度减持4.00；卖出5.00。评级系数为60天内所有给出评级机构最新评级的简单平均。
+    grd_em_2m_rank	        评级动能2月排名         全市场排名
+    grd_em_2m_sco	        评级动能2月得分         百分制打分，排名最靠前的1%为100分。
+    grd_em_3m	            评级动能3月            3个月前评级系数-现在评级系数；对于单个评级，强力买入1.00；买入2.00；观望3.00；适度减持4.00；卖出5.00。评级系数为60天内所有给出评级机构最新评级的简单平均。
+    grd_em_3m_rank	        评级动能3月排名         全市场排名
+    grd_em_3m_sco	        评级动能3月得分         百分制打分，排名最靠前的1%为100分。
+    targ_price_space	    目标价涨升空间
+    targ_price_space_rank	目标价涨升空间排名       全市场排名
+    targ_price_space_sco	目标价涨升空间得分       百分制打分，排名最靠前的1%为100分。
+    grd_em_sco	            评级动能得分            百分制打分，排名最靠前的1%为100分。
+    ana_em_bic_sco	        分析师动能得分(考虑业务收入变化率)      0.3*天眼预期得分+0.2*预期业绩动能得分+0.3*目标价涨升空间得分+0.2*评级动能得分（考虑业务收入变动情况）
+    ana_em_non_bic_sco	    分析师动能得分(不考虑业务收入变化率)     0.3*天眼预期得分+0.2*预期业绩动能得分2+0.3*目标价涨升空间得分+0.2*评级动能得分（不考虑业务收入变动）
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+
+    if fiscal_year is not None:
+        fiscal_year = int(fiscal_year)
+
+    if fields is None:
+        fields = ANALYST_MOMEMTUM_FIELDS
+    else:
+        fields = ensure_list_of_string(fields, 'analyst_momentum')
+        check_items_in_container(fields, ANALYST_MOMEMTUM_FIELDS, 'analyst_momentum')
+
+    if report_periods is not None:
+        report_periods = ensure_list_of_string(report_periods)
+        check_items_in_container(report_periods, VALID_REPORT_PERIODS, 'report_periods')
+        report_periods = [REPORT_PERIODS[_] for _ in report_periods]
+
+    if report_range is not None:
+        assert report_range in (1, 3), 'invalid report_range {}. should in (1,3)!'.format(report_range)
+
+    data = get_client().execute(
+        'consensus.get_analyst_momentum',
+        order_book_ids, fiscal_year, start_date, end_date, fields,
+        report_periods,
+        report_range,
+        market=market
+    )
+
+    if not data:
+        return None
+
+    df = pd.DataFrame(data)
+    dtypes = {f: (dtype if dtype != OBJECT_DTYPE else '<f8') for f, dtype in df[fields].dtypes.items()}
+    df = df.astype(dtypes)
+    df['report_period'] = df['report_period'].map(REVERSED_REPORT_PERIODS)
+    df.set_index(['order_book_id', 'date'], inplace=True)
+    return df
```

## rqdatac/services/constant.py

 * *Ordering differences only*

```diff
@@ -1,239 +1,239 @@
-# -*- coding: utf-8 -*-
-from rqdatac.decorators import export_as_api
-
-
-class IndustryCodeItem:
-    def __init__(self, code, name):
-        self.__code = code
-        self.__name = name
-
-    @property
-    def code(self):
-        return self.__code
-
-    @property
-    def name(self):
-        return self.__name
-
-    def __repr__(self):
-        return "{0}:{1}".format(self.__code, self.__name)
-
-
-@export_as_api
-@export_as_api(name="industry_code")
-class IndustryCode:
-    """Industry code constant"""
-
-    A01 = IndustryCodeItem("A01", "农业")
-    A02 = IndustryCodeItem("A02", "林业")
-    A03 = IndustryCodeItem("A03", "畜牧业")
-    A04 = IndustryCodeItem("A04", "渔业")
-    A05 = IndustryCodeItem("A05", "农、林、牧、渔服务业")
-    B06 = IndustryCodeItem("B06", "煤炭开采和洗选业")
-    B07 = IndustryCodeItem("B07", "石油和天然气开采业")
-    B08 = IndustryCodeItem("B08", "黑色金属矿采选业")
-    B09 = IndustryCodeItem("B09", "有色金属矿采选业")
-    B10 = IndustryCodeItem("B10", "非金属矿采选业")
-    B11 = IndustryCodeItem("B11", "开采辅助活动")
-    B12 = IndustryCodeItem("B12", "其他采矿业")
-    C13 = IndustryCodeItem("C13", "农副食品加工业")
-    C14 = IndustryCodeItem("C14", "食品制造业")
-    C15 = IndustryCodeItem("C15", "酒、饮料和精制茶制造业")
-    C16 = IndustryCodeItem("C16", "烟草制品业")
-    C17 = IndustryCodeItem("C17", "纺织业")
-    C18 = IndustryCodeItem("C18", "纺织服装、服饰业")
-    C19 = IndustryCodeItem("C19", "皮革、毛皮、羽毛及其制品和制鞋业")
-    C20 = IndustryCodeItem("C20", "木材加工及木、竹、藤、棕、草制品业")
-    C21 = IndustryCodeItem("C21", "家具制造业")
-    C22 = IndustryCodeItem("C22", "造纸及纸制品业")
-    C23 = IndustryCodeItem("C23", "印刷和记录媒介复制业")
-    C24 = IndustryCodeItem("C24", "文教、工美、体育和娱乐用品制造业")
-    C25 = IndustryCodeItem("C25", "石油加工、炼焦及核燃料加工业")
-    C26 = IndustryCodeItem("C26", "化学原料及化学制品制造业")
-    C27 = IndustryCodeItem("C27", "医药制造业")
-    C28 = IndustryCodeItem("C28", "化学纤维制造业")
-    C29 = IndustryCodeItem("C29", "橡胶和塑料制品业")
-    C30 = IndustryCodeItem("C30", "非金属矿物制品业")
-    C31 = IndustryCodeItem("C31", "黑色金属冶炼及压延加工业")
-    C32 = IndustryCodeItem("C32", "有色金属冶炼和压延加工业")
-    C33 = IndustryCodeItem("C33", "金属制品业")
-    C34 = IndustryCodeItem("C34", "通用设备制造业")
-    C35 = IndustryCodeItem("C35", "专用设备制造业")
-    C36 = IndustryCodeItem("C36", "汽车制造业")
-    C37 = IndustryCodeItem("C37", "铁路、船舶、航空航天和其它运输设备制造业")
-    C38 = IndustryCodeItem("C38", "电气机械和器材制造业")
-    C39 = IndustryCodeItem("C39", "计算机、通信和其他电子设备制造业")
-    C40 = IndustryCodeItem("C40", "仪器仪表制造业")
-    C41 = IndustryCodeItem("C41", "其他制造业")
-    C42 = IndustryCodeItem("C42", "废弃资源综合利用业")
-    C43 = IndustryCodeItem("C43", "金属制品、机械和设备修理业")
-    D44 = IndustryCodeItem("D44", "电力、热力生产和供应业")
-    D45 = IndustryCodeItem("D45", "燃气生产和供应业")
-    D46 = IndustryCodeItem("D46", "水的生产和供应业")
-    E47 = IndustryCodeItem("E47", "房屋建筑业")
-    E48 = IndustryCodeItem("E48", "土木工程建筑业")
-    E49 = IndustryCodeItem("E49", "建筑安装业")
-    E50 = IndustryCodeItem("E50", "建筑装饰和其他建筑业")
-    F51 = IndustryCodeItem("F51", "批发业")
-    F52 = IndustryCodeItem("F52", "零售业")
-    G53 = IndustryCodeItem("G53", "铁路运输业")
-    G54 = IndustryCodeItem("G54", "道路运输业")
-    G55 = IndustryCodeItem("G55", "水上运输业")
-    G56 = IndustryCodeItem("G56", "航空运输业")
-    G57 = IndustryCodeItem("G57", "管道运输业")
-    G58 = IndustryCodeItem("G58", "装卸搬运和运输代理业")
-    G59 = IndustryCodeItem("G59", "仓储业")
-    G60 = IndustryCodeItem("G60", "邮政业")
-    H61 = IndustryCodeItem("H61", "住宿业")
-    H62 = IndustryCodeItem("H62", "餐饮业")
-    I63 = IndustryCodeItem("I63", "电信、广播电视和卫星传输服务")
-    I64 = IndustryCodeItem("I64", "互联网和相关服务")
-    I65 = IndustryCodeItem("I65", "软件和信息技术服务业")
-    J66 = IndustryCodeItem("J66", "货币金融服务")
-    J67 = IndustryCodeItem("J67", "资本市场服务")
-    J68 = IndustryCodeItem("J68", "保险业")
-    J69 = IndustryCodeItem("J69", "其他金融业")
-    K70 = IndustryCodeItem("K70", "房地产业")
-    L71 = IndustryCodeItem("L71", "租赁业")
-    L72 = IndustryCodeItem("L72", "商务服务业")
-    M73 = IndustryCodeItem("M73", "研究和试验发展")
-    M74 = IndustryCodeItem("M74", "专业技术服务业")
-    M75 = IndustryCodeItem("M75", "科技推广和应用服务业")
-    N76 = IndustryCodeItem("N76", "水利管理业")
-    N77 = IndustryCodeItem("N77", "生态保护和环境治理业")
-    N78 = IndustryCodeItem("N78", "公共设施管理业")
-    O79 = IndustryCodeItem("O79", "居民服务业")
-    O80 = IndustryCodeItem("O80", "机动车、电子产品和日用产品修理业")
-    O81 = IndustryCodeItem("O81", "其他服务业")
-    P82 = IndustryCodeItem("P82", "教育")
-    Q83 = IndustryCodeItem("Q83", "卫生")
-    Q84 = IndustryCodeItem("Q84", "社会工作")
-    R85 = IndustryCodeItem("R85", "新闻和出版业")
-    R86 = IndustryCodeItem("R86", "广播、电视、电影和影视录音制作业")
-    R87 = IndustryCodeItem("R87", "文化艺术业")
-    R88 = IndustryCodeItem("R88", "体育")
-    R89 = IndustryCodeItem("R89", "娱乐业")
-    S90 = IndustryCodeItem("S90", "综合")
-
-
-class SectorCodeItem:
-    def __init__(self, cn, en, name):
-        self.__cn = cn
-        self.__en = en
-        self.__name = name
-
-    @property
-    def cn(self):
-        return self.__cn
-
-    @property
-    def en(self):
-        return self.__en
-
-    @property
-    def name(self):
-        return self.__name
-
-    def __repr__(self):
-        return "{}: {}, {}".format(self.__name, self.__en, self.__cn)
-
-
-@export_as_api
-@export_as_api(name="sector_code")
-class SectorCode:
-    Energy = SectorCodeItem("能源", "energy", "Energy")
-    Materials = SectorCodeItem("原材料", "materials", "Materials")
-    ConsumerDiscretionary = SectorCodeItem(
-        "非必需消费品", "consumer discretionary", "ConsumerDiscretionary"
-    )
-    ConsumerStaples = SectorCodeItem("必需消费品", "consumer staples", "ConsumerStaples")
-    HealthCare = SectorCodeItem("医疗保健", "health care", "HealthCare")
-    Financials = SectorCodeItem("金融", "financials", "Financials")
-    InformationTechnology = SectorCodeItem(
-        "信息技术", "information technology", "InformationTechnology"
-    )
-    TelecommunicationServices = SectorCodeItem(
-        "电信服务", "telecommunication services", "TelecommunicationServices"
-    )
-    Utilities = SectorCodeItem("公共服务", "utilities", "Utilities")
-    Industrials = SectorCodeItem("工业", "industrials", "Industrials")
-
-
-RATECOMP_CN = [
-    '北方资信评估有限公司',
-    '标普信用评级(中国)有限公司',
-    '标准普尔评估有限公司',
-    '大公国际资信评估有限公司',
-    '东方金诚国际信用评估有限公司',
-    '贵州博远信用管理评估有限公司',
-    '惠誉国际信用评级有限公司',
-    '江苏安博尔信用评估有限公司',
-    '江苏东宇国际咨询评估有限公司',
-    '江苏远东国际评估咨询有限公司',
-    '联合信用评级有限公司',
-    '联合资信评估有限公司',
-    '穆迪投资者服务公司',
-    '上海新世纪资信评估投资服务有限公司',
-    '新华远东中国评级',
-    '远东资信评估有限公司',
-    '云南国联资信评估有限公司',
-    '长城资信评估有限公司',
-    '中诚信国际信用评级有限责任公司',
-    '中诚信证券评估有限公司',
-    '中国诚信信用管理股份有限公司',
-    '中国国际金融股份有限公司',
-    '中债资信评估有限责任公司',
-    '中证鹏元资信评估股份有限公司',
-    '中诚信证评数据科技有限公司',
-]
-
-RATETYPE_CN = [
-    '长期',
-    '短期',
-    '长期债务评级',
-    '短期债务评级',
-    '综合财务实力',
-    '个体财务实力',
-    '长期外币评级',
-    '短期外币评级',
-    '主权评级',
-    '国际长期信用评级',
-    '国际短期信用评级',
-    '长期发行人违约评级',
-    '短期发行人违约评级',
-    '独立评级',
-    '支撑评级',
-    '个体评级',
-    '生存力评级',
-    '银行基本实力评级',
-    '银行财务实力评级',
-    '外币高级无担保债务评级',
-    '本币高级无担保债务评级',
-    '外币高级无担保债券评级',
-    '本币高级无担保债券评级',
-    '外币优先无担保债券评级',
-    '本币优先无担保债券评级',
-    '加权平均银行财务实力评级',
-    '加权平均银行外币存款评级',
-    '中国政府长期主权外币债券评级',
-    '外币银行存款评级国别上限',
-    '外币债券评级国别上限',
-    '长期银行存款评级',
-    '短期银行存款评级',
-    '长期外币发行人违约评级',
-    '长期本币发行人违约评级',
-    '长期本币评级',
-    '短期本币评级',
-    '短期外币发行人违约评级',
-    '短期本币发行人违约评级',
-    '长期优先债务评级',
-    '长期次级债务评级',
-    '中关村企业信用评级',
-    '列入评级观察',
-    '列入评级观察(撤销)',
-    '优先股主体评级',
-    '长期投资级',
-    '长期投机级',
-    '长期投资级',
-    '长期投机级'
-]
+# -*- coding: utf-8 -*-
+from rqdatac.decorators import export_as_api
+
+
+class IndustryCodeItem:
+    def __init__(self, code, name):
+        self.__code = code
+        self.__name = name
+
+    @property
+    def code(self):
+        return self.__code
+
+    @property
+    def name(self):
+        return self.__name
+
+    def __repr__(self):
+        return "{0}:{1}".format(self.__code, self.__name)
+
+
+@export_as_api
+@export_as_api(name="industry_code")
+class IndustryCode:
+    """Industry code constant"""
+
+    A01 = IndustryCodeItem("A01", "农业")
+    A02 = IndustryCodeItem("A02", "林业")
+    A03 = IndustryCodeItem("A03", "畜牧业")
+    A04 = IndustryCodeItem("A04", "渔业")
+    A05 = IndustryCodeItem("A05", "农、林、牧、渔服务业")
+    B06 = IndustryCodeItem("B06", "煤炭开采和洗选业")
+    B07 = IndustryCodeItem("B07", "石油和天然气开采业")
+    B08 = IndustryCodeItem("B08", "黑色金属矿采选业")
+    B09 = IndustryCodeItem("B09", "有色金属矿采选业")
+    B10 = IndustryCodeItem("B10", "非金属矿采选业")
+    B11 = IndustryCodeItem("B11", "开采辅助活动")
+    B12 = IndustryCodeItem("B12", "其他采矿业")
+    C13 = IndustryCodeItem("C13", "农副食品加工业")
+    C14 = IndustryCodeItem("C14", "食品制造业")
+    C15 = IndustryCodeItem("C15", "酒、饮料和精制茶制造业")
+    C16 = IndustryCodeItem("C16", "烟草制品业")
+    C17 = IndustryCodeItem("C17", "纺织业")
+    C18 = IndustryCodeItem("C18", "纺织服装、服饰业")
+    C19 = IndustryCodeItem("C19", "皮革、毛皮、羽毛及其制品和制鞋业")
+    C20 = IndustryCodeItem("C20", "木材加工及木、竹、藤、棕、草制品业")
+    C21 = IndustryCodeItem("C21", "家具制造业")
+    C22 = IndustryCodeItem("C22", "造纸及纸制品业")
+    C23 = IndustryCodeItem("C23", "印刷和记录媒介复制业")
+    C24 = IndustryCodeItem("C24", "文教、工美、体育和娱乐用品制造业")
+    C25 = IndustryCodeItem("C25", "石油加工、炼焦及核燃料加工业")
+    C26 = IndustryCodeItem("C26", "化学原料及化学制品制造业")
+    C27 = IndustryCodeItem("C27", "医药制造业")
+    C28 = IndustryCodeItem("C28", "化学纤维制造业")
+    C29 = IndustryCodeItem("C29", "橡胶和塑料制品业")
+    C30 = IndustryCodeItem("C30", "非金属矿物制品业")
+    C31 = IndustryCodeItem("C31", "黑色金属冶炼及压延加工业")
+    C32 = IndustryCodeItem("C32", "有色金属冶炼和压延加工业")
+    C33 = IndustryCodeItem("C33", "金属制品业")
+    C34 = IndustryCodeItem("C34", "通用设备制造业")
+    C35 = IndustryCodeItem("C35", "专用设备制造业")
+    C36 = IndustryCodeItem("C36", "汽车制造业")
+    C37 = IndustryCodeItem("C37", "铁路、船舶、航空航天和其它运输设备制造业")
+    C38 = IndustryCodeItem("C38", "电气机械和器材制造业")
+    C39 = IndustryCodeItem("C39", "计算机、通信和其他电子设备制造业")
+    C40 = IndustryCodeItem("C40", "仪器仪表制造业")
+    C41 = IndustryCodeItem("C41", "其他制造业")
+    C42 = IndustryCodeItem("C42", "废弃资源综合利用业")
+    C43 = IndustryCodeItem("C43", "金属制品、机械和设备修理业")
+    D44 = IndustryCodeItem("D44", "电力、热力生产和供应业")
+    D45 = IndustryCodeItem("D45", "燃气生产和供应业")
+    D46 = IndustryCodeItem("D46", "水的生产和供应业")
+    E47 = IndustryCodeItem("E47", "房屋建筑业")
+    E48 = IndustryCodeItem("E48", "土木工程建筑业")
+    E49 = IndustryCodeItem("E49", "建筑安装业")
+    E50 = IndustryCodeItem("E50", "建筑装饰和其他建筑业")
+    F51 = IndustryCodeItem("F51", "批发业")
+    F52 = IndustryCodeItem("F52", "零售业")
+    G53 = IndustryCodeItem("G53", "铁路运输业")
+    G54 = IndustryCodeItem("G54", "道路运输业")
+    G55 = IndustryCodeItem("G55", "水上运输业")
+    G56 = IndustryCodeItem("G56", "航空运输业")
+    G57 = IndustryCodeItem("G57", "管道运输业")
+    G58 = IndustryCodeItem("G58", "装卸搬运和运输代理业")
+    G59 = IndustryCodeItem("G59", "仓储业")
+    G60 = IndustryCodeItem("G60", "邮政业")
+    H61 = IndustryCodeItem("H61", "住宿业")
+    H62 = IndustryCodeItem("H62", "餐饮业")
+    I63 = IndustryCodeItem("I63", "电信、广播电视和卫星传输服务")
+    I64 = IndustryCodeItem("I64", "互联网和相关服务")
+    I65 = IndustryCodeItem("I65", "软件和信息技术服务业")
+    J66 = IndustryCodeItem("J66", "货币金融服务")
+    J67 = IndustryCodeItem("J67", "资本市场服务")
+    J68 = IndustryCodeItem("J68", "保险业")
+    J69 = IndustryCodeItem("J69", "其他金融业")
+    K70 = IndustryCodeItem("K70", "房地产业")
+    L71 = IndustryCodeItem("L71", "租赁业")
+    L72 = IndustryCodeItem("L72", "商务服务业")
+    M73 = IndustryCodeItem("M73", "研究和试验发展")
+    M74 = IndustryCodeItem("M74", "专业技术服务业")
+    M75 = IndustryCodeItem("M75", "科技推广和应用服务业")
+    N76 = IndustryCodeItem("N76", "水利管理业")
+    N77 = IndustryCodeItem("N77", "生态保护和环境治理业")
+    N78 = IndustryCodeItem("N78", "公共设施管理业")
+    O79 = IndustryCodeItem("O79", "居民服务业")
+    O80 = IndustryCodeItem("O80", "机动车、电子产品和日用产品修理业")
+    O81 = IndustryCodeItem("O81", "其他服务业")
+    P82 = IndustryCodeItem("P82", "教育")
+    Q83 = IndustryCodeItem("Q83", "卫生")
+    Q84 = IndustryCodeItem("Q84", "社会工作")
+    R85 = IndustryCodeItem("R85", "新闻和出版业")
+    R86 = IndustryCodeItem("R86", "广播、电视、电影和影视录音制作业")
+    R87 = IndustryCodeItem("R87", "文化艺术业")
+    R88 = IndustryCodeItem("R88", "体育")
+    R89 = IndustryCodeItem("R89", "娱乐业")
+    S90 = IndustryCodeItem("S90", "综合")
+
+
+class SectorCodeItem:
+    def __init__(self, cn, en, name):
+        self.__cn = cn
+        self.__en = en
+        self.__name = name
+
+    @property
+    def cn(self):
+        return self.__cn
+
+    @property
+    def en(self):
+        return self.__en
+
+    @property
+    def name(self):
+        return self.__name
+
+    def __repr__(self):
+        return "{}: {}, {}".format(self.__name, self.__en, self.__cn)
+
+
+@export_as_api
+@export_as_api(name="sector_code")
+class SectorCode:
+    Energy = SectorCodeItem("能源", "energy", "Energy")
+    Materials = SectorCodeItem("原材料", "materials", "Materials")
+    ConsumerDiscretionary = SectorCodeItem(
+        "非必需消费品", "consumer discretionary", "ConsumerDiscretionary"
+    )
+    ConsumerStaples = SectorCodeItem("必需消费品", "consumer staples", "ConsumerStaples")
+    HealthCare = SectorCodeItem("医疗保健", "health care", "HealthCare")
+    Financials = SectorCodeItem("金融", "financials", "Financials")
+    InformationTechnology = SectorCodeItem(
+        "信息技术", "information technology", "InformationTechnology"
+    )
+    TelecommunicationServices = SectorCodeItem(
+        "电信服务", "telecommunication services", "TelecommunicationServices"
+    )
+    Utilities = SectorCodeItem("公共服务", "utilities", "Utilities")
+    Industrials = SectorCodeItem("工业", "industrials", "Industrials")
+
+
+RATECOMP_CN = [
+    '北方资信评估有限公司',
+    '标普信用评级(中国)有限公司',
+    '标准普尔评估有限公司',
+    '大公国际资信评估有限公司',
+    '东方金诚国际信用评估有限公司',
+    '贵州博远信用管理评估有限公司',
+    '惠誉国际信用评级有限公司',
+    '江苏安博尔信用评估有限公司',
+    '江苏东宇国际咨询评估有限公司',
+    '江苏远东国际评估咨询有限公司',
+    '联合信用评级有限公司',
+    '联合资信评估有限公司',
+    '穆迪投资者服务公司',
+    '上海新世纪资信评估投资服务有限公司',
+    '新华远东中国评级',
+    '远东资信评估有限公司',
+    '云南国联资信评估有限公司',
+    '长城资信评估有限公司',
+    '中诚信国际信用评级有限责任公司',
+    '中诚信证券评估有限公司',
+    '中国诚信信用管理股份有限公司',
+    '中国国际金融股份有限公司',
+    '中债资信评估有限责任公司',
+    '中证鹏元资信评估股份有限公司',
+    '中诚信证评数据科技有限公司',
+]
+
+RATETYPE_CN = [
+    '长期',
+    '短期',
+    '长期债务评级',
+    '短期债务评级',
+    '综合财务实力',
+    '个体财务实力',
+    '长期外币评级',
+    '短期外币评级',
+    '主权评级',
+    '国际长期信用评级',
+    '国际短期信用评级',
+    '长期发行人违约评级',
+    '短期发行人违约评级',
+    '独立评级',
+    '支撑评级',
+    '个体评级',
+    '生存力评级',
+    '银行基本实力评级',
+    '银行财务实力评级',
+    '外币高级无担保债务评级',
+    '本币高级无担保债务评级',
+    '外币高级无担保债券评级',
+    '本币高级无担保债券评级',
+    '外币优先无担保债券评级',
+    '本币优先无担保债券评级',
+    '加权平均银行财务实力评级',
+    '加权平均银行外币存款评级',
+    '中国政府长期主权外币债券评级',
+    '外币银行存款评级国别上限',
+    '外币债券评级国别上限',
+    '长期银行存款评级',
+    '短期银行存款评级',
+    '长期外币发行人违约评级',
+    '长期本币发行人违约评级',
+    '长期本币评级',
+    '短期本币评级',
+    '短期外币发行人违约评级',
+    '短期本币发行人违约评级',
+    '长期优先债务评级',
+    '长期次级债务评级',
+    '中关村企业信用评级',
+    '列入评级观察',
+    '列入评级观察(撤销)',
+    '优先股主体评级',
+    '长期投资级',
+    '长期投机级',
+    '长期投资级',
+    '长期投机级'
+]
```

## rqdatac/services/convertible.py

 * *Ordering differences only*

```diff
@@ -1,713 +1,713 @@
-# -*- coding: utf-8 -*-
-import warnings
-import datetime
-
-import pandas as pd
-import numpy as np
-from rqdatac.services.constant import RATETYPE_CN, RATECOMP_CN
-
-from rqdatac.client import get_client
-from rqdatac.validators import (
-    ensure_int,
-    ensure_date_int,
-    ensure_order_book_id,
-    ensure_order_book_ids,
-    ensure_date_range,
-    ensure_dates_base_on_listed_date,
-    ensure_list_of_string, ensure_date_or_today_int, check_items_in_container)
-from rqdatac.utils import to_datetime, int8_to_datetime
-from rqdatac.decorators import export_as_api, ttl_cache
-from rqdatac.services.calendar import (
-    get_trading_dates,
-)
-from rqdatac.services import shenwan
-from rqdatac.rqdatah_helper import rqdatah_serialize, http_conv_instruments
-
-INS_COLUMNS = [
-    "order_book_id",
-    "symbol",
-    "full_name",
-    "exchange",
-    "bond_type",
-    "trade_type",
-    "value_date",
-    "maturity_date",
-    "par_value",
-    "coupon_rate",
-    "coupon_frequency",
-    "coupon_method",
-    "compensation_rate",
-    "total_issue_size",
-    "de_listed_date",
-    "stock_code",
-    "conversion_start_date",
-    "conversion_end_date",
-    "redemption_price",
-    "issue_price",
-    "call_protection",
-    "listed_date",
-    "stop_trading_date",
-    "early_maturity_date"
-]
-
-
-class Instrument:
-    def __init__(self, attrs):
-        self.__dict__.update(attrs)
-        self.__cache = {}
-
-    def __str__(self):
-        return "{}(\n{}\n)".format(
-            type(self).__name__,
-            ",\n".join(["{}={!r}".format(k, v) for k, v in self.items() if not k.startswith("_")]),
-        )
-
-    __repr__ = __str__
-
-    def __setitem__(self, key, value):
-        self.__dict__[key] = value
-
-    def __getitem__(self, item):
-        return self.__dict__[item]
-
-    def get(self, item, default=None):
-        return self.__dict__.get(item, default)
-
-    def items(self):
-        return self.__dict__.items()
-
-    def keys(self):
-        return self.__dict__.keys()
-
-    def values(self):
-        return self.__dict__.values()
-
-    def __cache_get(self, v):
-        return self.__cache.get(v)
-
-    def __cache_set(self, k, v):
-        self.__cache[k] = v
-
-    def coupon_rate_table(self):
-        """变动利率可转债信息"""
-        if "coupon_rate_table" in self.__cache:
-            return self.__cache_get("coupon_rate_table")
-        info = get_client().execute("convertible.get_coupon_rate_table", self.order_book_id)
-        info = pd.DataFrame(info).set_index(['start_date', 'end_date']) if info else None
-        self.__cache_set("coupon_rate_table", info)
-        return info
-
-    def option(self, option_type=None):
-        if option_type is not None:
-            option_type = ensure_int(option_type)
-            if option_type not in (1, 2, 3, 4, 5, 6, 7):
-                raise ValueError("option_type: expect value in (None, 1, 2, 3, 4, 5, 6, 7)")
-
-        data = get_client().execute("convertible.option", self.order_book_id, option_type)
-        if not data:
-            return
-
-        df = pd.DataFrame(data)
-        if 'payment_year' in df.columns:
-            sort_fields = ['option_type', 'payment_year']
-        else:
-            sort_fields = ['option_type']
-        df = df.sort_values(sort_fields).reset_index()
-        column_order = ['option_type', 'start_date', 'end_date', 'payment_year', 'level', 'window_days',
-                        'reach_days', 'frequency', 'price', 'if_include_interest', 'remark']
-        column = [i for i in column_order if i in df.columns]
-        return df[column]
-
-
-@ttl_cache(12 * 3600)
-def _all_instruments_dict(market="cn"):
-    return {
-        i['order_book_id']: Instrument(i)
-        for i in get_client().execute("convertible.all_instruments", market=market)
-    }
-
-
-@export_as_api(namespace="convertible")
-def all_instruments(date=None, market="cn"):
-    """获取所有可转债详细信息
-
-    :param market:  (Default value = "cn")
-    :returns: DataFrame
-    """
-    profile = lambda v: (
-        v.order_book_id,
-        v.symbol,
-        v.full_name,
-        v.exchange,
-        v.bond_type,
-        v.trade_type,
-        v.value_date,
-        v.maturity_date,
-        v.par_value,
-        v.coupon_rate,
-        v.coupon_frequency,
-        v.coupon_method,
-        v.compensation_rate,
-        v.total_issue_size,
-        v.de_listed_date,
-        v.stock_code,
-        v.conversion_start_date,
-        v.conversion_end_date,
-        v.redemption_price,
-        v.issue_price,
-        v.call_protection,
-        v.listed_date,
-        v.early_maturity_date,
-        getattr(v, 'stop_trading_date', None)
-    )
-
-    def judge(listed_date, de_listed_date):
-        if listed_date and de_listed_date:
-            return listed_date <= date and de_listed_date > date
-        if listed_date:
-            return listed_date <= date
-        else:
-            return False
-
-    if date:
-        date = to_datetime(date)
-        data = [profile(v) for v in _all_instruments_dict(market).values() if judge(v.listed_date, v.de_listed_date)]
-    else:
-        data = [profile(v) for v in _all_instruments_dict(market).values()]
-    df = pd.DataFrame(
-        data,
-        columns=INS_COLUMNS,
-    )
-    df.sort_values('order_book_id', inplace=True)
-    return df.reset_index(drop=True)
-
-
-@export_as_api(namespace="convertible")
-@rqdatah_serialize(converter=http_conv_instruments)
-def instruments(order_book_ids, market="cn"):
-    """获取可转债详细信息
-
-    :param order_book_ids: 可转债代码，str 或 list of str
-    :param market:  (Default value = "cn")
-    :returns: Instrument object or list of Instrument object
-            取决于参数是一个 order_book_id 还是多个 order_book_id
-    """
-    all_dict = _all_instruments_dict(market)
-    order_book_ids = ensure_list_of_string(order_book_ids, "order_book_ids")
-    if len(order_book_ids) == 1:
-        try:
-            return all_dict[order_book_ids[0]]
-        except KeyError:
-            warnings.warn('unknown convertible order_book_id: {}'.format(order_book_ids))
-            return
-    all_list = (all_dict.get(i) for i in order_book_ids)
-    return [i for i in all_list if i]
-
-
-@export_as_api(namespace="convertible")
-def get_cash_flow(order_book_ids, start_date=None, end_date=None, market="cn"):
-    """获取现金流信息
-
-    :param order_book_ids: 可转债ID str or list
-    :param start_date: 开始日期，默认为None
-    :param end_date: 结束日期，默认为None
-    :param market:  (Default value = "cn")
-    :return: pd.DataFrame
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    if start_date:
-        start_date = ensure_date_int(start_date)
-    if end_date:
-        end_date = ensure_date_int(end_date)
-    data = get_client().execute("convertible.get_cash_flow", order_book_ids, start_date, end_date, market=market)
-    if not data:
-        return
-    df = pd.DataFrame(data)
-    df.set_index(["order_book_id", "payment_date"], inplace=True)
-    return df
-
-
-@export_as_api(namespace="convertible")
-def get_call_info(order_book_ids, start_date=None, end_date=None, market="cn"):
-    """获取赎回信息
-
-    :param order_book_ids: 可转债ID，str or list
-    :param start_date: 开始日期，默认为None
-    :param end_date: 结束日期，默认为None
-    :param market:  (Default value = "cn")
-    :return: pd.DataFrame
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    if start_date:
-        start_date = ensure_date_int(start_date)
-    if end_date:
-        end_date = ensure_date_int(end_date)
-    data = get_client().execute("convertible.get_call_info", order_book_ids, start_date, end_date, market=market)
-    if not data:
-        return
-    df = pd.DataFrame(data)
-    df.set_index(["order_book_id", "info_date"], inplace=True)
-    return df
-
-
-@export_as_api(namespace="convertible")
-def get_put_info(order_book_ids, start_date=None, end_date=None, market="cn"):
-    """获取回售信息
-
-    :param order_book_ids: 可转债ID，str or list
-    :param start_date: 开始日期，默认为None
-    :param end_date: 结束日期，默认为None
-    :param market:  (Default value = "cn")
-    :return: pd.DataFrame
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    if start_date:
-        start_date = ensure_date_int(start_date)
-    if end_date:
-        end_date = ensure_date_int(end_date)
-    data = get_client().execute("convertible.get_put_info", order_book_ids, start_date, end_date, market=market)
-    if not data:
-        return
-    df = pd.DataFrame(data)
-    df.set_index(["order_book_id", "info_date"], inplace=True)
-    return df
-
-
-@export_as_api(namespace="convertible")
-def get_conversion_price(order_book_ids, start_date=None, end_date=None, market="cn"):
-    """获取转股价变动信息
-
-    :param order_book_ids: 可转债ID，str or list
-    :param start_date: 开始日期，默认为None
-    :param end_date: 结束日期，默认为None
-    :param market:  (Default value = "cn")
-    :return: pd.DataFrame
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    if start_date:
-        start_date = ensure_date_int(start_date)
-    if end_date:
-        end_date = ensure_date_int(end_date)
-    data = get_client().execute("convertible.get_conversion_price", order_book_ids, start_date, end_date, market=market)
-    if not data:
-        return
-    df = pd.DataFrame(data)
-    df.set_index(["order_book_id", "info_date"], inplace=True)
-    return df
-
-
-@export_as_api(namespace="convertible")
-def get_conversion_info(order_book_ids, start_date=None, end_date=None, market="cn"):
-    """获取转股变动信息
-
-    :param order_book_ids: 可转债ID，str or list
-    :param start_date: 开始日期，默认为None
-    :param end_date: 结束日期，默认为None
-    :param market:  (Default value = "cn")
-    :return: pd.DataFrame
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    if start_date:
-        start_date = ensure_date_int(start_date)
-    if end_date:
-        end_date = ensure_date_int(end_date)
-    data = get_client().execute("convertible.get_conversion_info", order_book_ids, start_date, end_date, market=market)
-    if not data:
-        return
-    df = pd.DataFrame(data)
-    df.set_index(["order_book_id", "info_date"], inplace=True)
-    return df
-
-
-@export_as_api(namespace="convertible")
-def is_suspended(order_book_ids, start_date=None, end_date=None):
-    """获取停牌信息
-    :param order_book_ids: 可转债ID
-    :param start_date: 开始日期, 如'2013-01-04' (Default value = None)
-    :param end_date: 结束日期，如'2014-01-04' (Default value = None)
-    :returns: DataFrame
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    if len(order_book_ids) == 1:
-        instrument = instruments(order_book_ids[0], market="cn")
-        start_date, end_date = ensure_dates_base_on_listed_date(instrument, start_date, end_date, "cn")
-        if start_date is None:
-            return
-    start_date, end_date = ensure_date_range(start_date, end_date)
-
-    trading_dates = pd.to_datetime(get_trading_dates(start_date, end_date, market="cn"))
-    df = pd.DataFrame(data=False, columns=order_book_ids, index=trading_dates)
-    data = get_client().execute("convertible.is_suspended", order_book_ids, start_date, end_date, market="cn")
-    for (order_book_id, date) in data:
-        date = to_datetime(date)
-        df.at[date, order_book_id] = True
-    return df
-
-
-@export_as_api(namespace="convertible")
-def rating(date=None, credit_level=None, institution=None, rating_type=None, target='debt'):
-    """
-    Get rating information for company or bond
-    :param date: str, int, or datatime
-        1): 存续债券的判定是date在[value_date,maturity_date]之间
-        2): 控制credit_date返回当前最新的日期
-    :param credit_level: eg: 'AAA'
-    :param institution: rating company name
-    :param rating_type: rating type name
-    :param target: 'debt' or 'issuer'
-    :return:
-    """
-    check_items_in_container(target, ['debt', 'issuer'], 'target')
-    if institution is not None:
-        check_items_in_container(institution, RATECOMP_CN, 'institution')
-        if institution == "中诚信证券评估有限公司":
-            institution = "中诚信证评数据科技有限公司"
-    if rating_type is not None:
-        check_items_in_container(rating_type, RATETYPE_CN, 'rating_type')
-    date = ensure_date_int(date) if date else None
-
-    res = get_client().execute("convertible.rating", date, credit_level, institution, rating_type, target)
-
-    if date and res and target == 'debt':
-        ins = instruments(res)
-        if not isinstance(ins, list):
-            ins = [ins]
-        res = [i.order_book_id for i in ins if i.value_date <= int8_to_datetime(date) <= i.maturity_date]
-    return res
-
-
-@export_as_api(namespace="convertible")
-def get_latest_rating(order_book_ids, date, institution=None, rating_type=None, target='debt'):
-    """
-    获取在给定日期之前的最新评级记录.
-    返回credit_date和参数date前差距时间最短的一条记录，无需返回所有评级机构最新记录
-
-    :param order_book_ids: str or List[str]债券id列表
-    :param date: str or int or datetime.date) 评级日期; 会返回该日期之前的最新评级记录.
-    :param institution: str or List[str] or None 评级机构; 若为None, 则返回所有评级机构的最新记录
-    :param rating_type: str or None 评级类型; 如果给定的话, 只返回该评级类型下最新的评级信息,
-        如果设为None, 则不管评级类型, 直接返回最新评级记录
-    :param target: str 评级类型, 可选值为 'debt'(代表债券评级) 或者 'issuer'(代表主体评级);
-    :return: a pandas DataFrame with order_book_id as index.
-    """
-    order_book_ids = ensure_list_of_string(order_book_ids, "order_book_ids")
-    check_items_in_container(target, ['debt', 'issuer'], 'target')
-    if institution is not None:
-        institution = ensure_list_of_string(institution, "institution")
-        check_items_in_container(institution, RATECOMP_CN, 'institution')
-        if "中诚信证券评估有限公司" in institution:
-            institution.append("中诚信证评数据科技有限公司")
-
-    data = get_client().execute(
-        "convertible.get_latest_rating",
-        order_book_ids,
-        ensure_date_int(date),
-        institution,
-        rating_type,
-        target
-    )
-    if not data:
-        return
-    df = pd.DataFrame.from_records(data)
-    df.sort_values(["order_book_id", "credit_date"], ascending=False, inplace=True)
-    df.set_index("order_book_id", inplace=True)
-    return df
-
-
-@export_as_api(namespace="convertible")
-def get_instrument_industry(order_book_ids, source='citics', level=1, date=None, market="cn"):
-    """获取可转债对应的行业
-
-    :param order_book_ids: 可转债order_book_id，如['000001.XSHE', '000002.XSHE']
-    :param source: 分类来源。citics 以及 citics_2019: 中信, gildata: 聚源
-    :param date: 如 '2015-01-07' (Default value = None)
-    :param level:  (Default value = 1)
-    :param market:  (Default value = "cn")
-    :returns: DataFrame
-        index: order_book_id
-        columns:
-            if level == 1: ["first_industry_code", "first_industry_name"]
-            if level == 2: ["second_industry_code", "second_industry_name"]
-            if level == 3: ["third_industry_code", "third_industry_name"]
-            if level == 0:
-                [
-                    "first_industry_code", "first_industry_name", "second_industry_code",
-                    "second_industry_name", "third_industry_code", "third_industry_name",
-                ]
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, type="Convertible")
-    all_dict = _all_instruments_dict(market)
-    # array of [(order_book_id, stock_code)]
-    mapper = np.array([(i, all_dict[i].stock_code) for i in order_book_ids if i in all_dict])
-
-    # 调用股票行业接口
-    res = shenwan.get_instrument_industry(set(mapper[:, 1]), source, level, date, market)
-    if res is None:
-        return
-
-    # 转换order_book_id为可转债id
-    res = res.reindex(mapper[:, 1])
-    res.index = pd.Index(mapper[:, 0], name='order_book_id')
-    return res
-
-
-@export_as_api(namespace="convertible")
-def get_industry(industry, source='citics', date=None, market="cn"):
-    """获取行业可转债列表
-
-    :param industry: 行业名称或代码
-    :param source: 分类来源。citics 以及 citics_2019: 中信, gildata: 聚源
-    :param date: 查询日期，默认为当前最新日期
-    :param market:  (Default value = "cn")
-    :return: 所属目标行业的order_book_id list or None
-    """
-    # 调用股票行业接口
-    order_book_ids = shenwan.get_industry(industry, source, date, market)
-    if order_book_ids is None:
-        return
-
-    order_book_ids = set(order_book_ids)
-
-    all_dict = _all_instruments_dict(market)
-    if date:
-        oids = []
-        date = to_datetime(date)
-        for ins in all_dict.values():
-            if ins.stock_code in order_book_ids:
-                if ins.de_listed_date == "0000-00-00" or ins.de_listed_date is None:
-                    ins.de_listed_date = pd.to_datetime("2099-12-31")
-                if ins.listed_date is None:
-                    ins.listed_date = pd.to_datetime("2099-12-31")
-                if ins.listed_date <= date <= ins.de_listed_date:
-                    oids.append(ins.order_book_id)
-    else:
-        oids = [ins.order_book_id for ins in all_dict.values() if ins.stock_code in order_book_ids]
-    return sorted(oids)
-
-
-@export_as_api(namespace="convertible")
-def get_indicators(order_book_ids, start_date=None, end_date=None, fields=None):
-    """获取可转债指标(默认返回最新3个月的数据)
-
-    :param order_book_ids: str or List[str] 合约代码
-    :param start_date: (str or datetime.date): 开始日期
-    :param end_date: (str or datetime.date): 结束时间
-    :param fields: str or List[str] 筛选字段
-
-    :return: Multi-index DataFrame:
-        index: [order_book_id, date]
-        columns:
-            conversion_coefficient	                float	转股系数
-            conversion_value	                    float	转股价值
-            conversion_premium	                    float	转股溢价率
-            pure_bond_value_premium	                float	税后纯债溢价率
-            pure_bond_value_premium_pretax	        float   税前纯债溢价率
-            yield_to_maturity	                    float	税后到期收益率
-            yield_to_maturity_pretax	            float   税前到期收益率
-            yield_to_put	                        float	税后回售收益率
-            yield_to_put_pretax	                    float	税前回售收益率
-            pure_bond_value	                        float	税后纯债价值
-            pure_bond_value_pretax	                float	税前纯债价值
-            double_low_factor	                    float	双低指标
-            call_trigger_price	                    float	赎回触发价
-            put_trigger_price	                    float	回售触发价
-            conversion_price_reset_trigger_price	float	下修触发价
-            turnover_rate	                        float 	换手率
-            remaining_size	                        float 	剩余规模（元）
-            convertible_market_cap_ratio	        float 	转债市值占比
-            pb_ratio	                            float	市净率
-            put_qualified_days	                    float	回售已满足天数
-            call_qualified_days	                    float	赎回已满足天数
-            conversion_price_reset_qualified_days	float	转股价下修已满足天数
-            put_status	                            float	回售条款满足状态
-            call_status	                            float	强赎条款满足状态
-            conversion_price_reset_status	        float	下修条款满足状态
-            iv                                      float   隐含波动率
-            delta                                   float   转债价格对正股股价的敏感度
-            theta                                   float   转债价格对时间的偏导
-            gamma                                   float   转债价格对正股股价的二阶导
-            vega                                    float   转债价格对隐含波动率的偏导
-    """
-    all_fields = [
-        "conversion_coefficient", "conversion_value", "conversion_premium", "pure_bond_value_premium",
-        "pure_bond_value_premium_pretax", "yield_to_maturity", "yield_to_maturity_pretax", "yield_to_put",
-        "yield_to_put_pretax", "pure_bond_value", "pure_bond_value_pretax", "double_low_factor",
-        "call_trigger_price", "put_trigger_price", "conversion_price_reset_trigger_price", "turnover_rate",
-        "remaining_size", "convertible_market_cap_ratio", "pb_ratio", "put_qualified_days",
-        "call_qualified_days", "conversion_price_reset_qualified_days", "put_status", "call_status",
-        "conversion_price_reset_status", "pure_bond_value_1", "pure_bond_value_premium_1",
-        "iv", "delta", "theta", "gamma", "vega",
-    ]
-    order_book_ids = ensure_list_of_string(order_book_ids, "order_book_ids")
-    if fields is None:
-        fields = all_fields
-    else:
-        fields = ensure_list_of_string(fields, "fields")
-        check_items_in_container(fields, all_fields, 'fields')
-
-    # 默认返回最新3个月的数据
-    if start_date is None and end_date is None:
-        start_date, end_date = ensure_date_range(start_date, end_date)
-    start_date = ensure_date_int(start_date) if start_date is not None else start_date
-    end_date = ensure_date_int(end_date) if end_date is not None else end_date
-
-    data = get_client().execute(
-        "convertible.get_indicators", order_book_ids, start_date, end_date, fields
-    )
-    if not data:
-        return
-
-    data = pd.DataFrame(data)
-    data.set_index(["order_book_id", "date"], inplace=True)
-    data.sort_index(inplace=True)
-    return data
-
-
-@export_as_api(namespace="convertible")
-def get_coupon_rate_table(order_book_ids):
-    """ 变动利率可转债信息
-
-    :param order_book_ids: str or List[str] 合约代码
-    :return: DataFrame
-        index: ['order_book_id', 'start_date', 'end_date']
-        columns: ['coupon_rate']
-    """
-    order_book_ids = ensure_list_of_string(order_book_ids, "order_book_ids")
-    info = get_client().execute("convertible.get_coupon_rate_tables", order_book_ids)
-    info = pd.DataFrame(info).set_index(['order_book_id', 'start_date', 'end_date']) if info else None
-
-    return info
-
-
-@export_as_api(namespace="convertible")
-def get_accrued_interest_eod(order_book_ids, start_date=None, end_date=None):
-    """ 获取可转债应计利息
-
-    只输入开始日期，返回开始日往后3个月内数值；
-    只输入结束日期，返回结束日往前3个月应计利息；
-    不输入日期，则返回当前日期往以前3个月数值
-
-    :param order_book_ids: str or List[str] 合约代码
-    :param start_date: 开始时间
-    :param end_date: 结束时间
-    :return: DataFrame
-        index: date
-        columns: order_book_ids      str or List[str]
-    """
-    order_book_ids = ensure_list_of_string(order_book_ids, "order_book_ids")
-
-    if start_date is None or end_date is None:
-        start_date, end_date = ensure_date_range(start_date, end_date)
-    start_date = to_datetime(start_date)
-    end_date = to_datetime(end_date)
-
-    ins = instruments(order_book_ids)
-    if ins is None:
-        return
-
-    ins = ins if isinstance(ins, list) else [ins]
-    # 去掉当天已经完成赎回的转债
-    # 有的 id 比如 123095.XSHE 投资人缴款后突然终止上市，然后就退款了, 导致 maturity_date 为 None
-    order_book_ids = [c.order_book_id for c in ins 
-        if c.bond_type != "separately_traded" 
-        and c.maturity_date is not None
-        and c.maturity_date > start_date
-    ]
-    if not order_book_ids:
-        return None
-
-    # 获得强赎信息
-    called_info = get_call_info(order_book_ids)
-
-    # 获取coupon_rate_table
-    coupon_rate_tables = get_coupon_rate_table(order_book_ids)
-    # sort 一下确保后面取到的 end_date 的最后一条记录是最新的.
-    coupon_rate_tables.sort_index(inplace=True)
-    coupon_rate_tables.reset_index(inplace=True)
-
-    res_list = []
-    for oid, sub_df in coupon_rate_tables.groupby("order_book_id"):
-        record_date = sub_df.iloc[-1].end_date
-        if called_info is not None and oid in called_info.index.get_level_values(0):
-            # 获取登记时间
-            record_date = called_info.loc[oid].record_date[0]
-            sub_df = sub_df[sub_df["start_date"] <= record_date]
-
-        # 生成时间段内对应的coupon_rate
-        date_range = pd.date_range(sub_df.iloc[0].start_date, sub_df.iloc[-1].end_date)
-        df = pd.DataFrame({"date": date_range})
-        df = pd.merge_asof(df, sub_df, left_on="date", right_on="end_date", direction="forward")
-        df.dropna(inplace=True)
-        df = df[df["date"] <= record_date]
-
-        # 计算利息
-        df["value"] = (df.date - df.start_date) / datetime.timedelta(days=365) * df.coupon_rate * 100
-
-        # 闰日用前一天的利息补
-        # FIXME 闰日之后的所有利息需往前挪一天
-        df.loc[(df["date"].dt.month == 2) & (df["date"].dt.day == 29), "value"] = np.nan
-        df = df.ffill()
-
-        df = df[(df.date >= start_date) & (df.date <= end_date)]
-        df = df.pivot(index="date", columns="order_book_id", values="value")
-        df.columns.name = None
-        df = df.sort_index()
-        res_list.append(df)
-
-    res = pd.concat(res_list, axis=1) if res_list else None
-    return res
-
-
-@export_as_api(namespace="convertible")
-def get_call_announcement(order_book_ids, start_date=None, end_date=None, market="cn"):
-    """ 获取合约的赎回提示性公告数据
-
-    :param order_book_ids: 股票合约id
-    :param start_date: 开始时间
-    :param end_date: 结束时间
-    :param market: 默认 'cn'
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-    end_date = ensure_date_or_today_int(end_date)
-    if start_date:
-        start_date = ensure_date_int(start_date)
-        if start_date > end_date:
-            raise ValueError("invalid date range: [{!r}, {!r}]".format(start_date, end_date))
-    data = get_client().execute("convertible.get_call_announcement", order_book_ids, start_date, end_date, market)
-    if data:
-        df = pd.DataFrame(data)
-        df.set_index(['order_book_id', 'info_date'], inplace=True)
-        df.sort_index(inplace=True)
-        return df
-
-
-@export_as_api(namespace="convertible")
-def get_credit_rating(order_book_ids, start_date=None, end_date=None, institutions=None, market="cn"):
-    """ 获取合约的评级信息
-
-    :param order_book_ids: 合约id
-    :param start_date: 开始时间
-    :param end_date: 结束时间
-    :param institutions: 评级机构
-    :param market: 默认 'cn'
-
-    Note: 评级机构清单如下:
-      上海新世纪资信评估投资服务有限公司, 上海资信有限公司, 东方金诚国际信用评估有限公司
-      中债资信评估有限责任公司, 中国诚信信用管理股份有限公司, 中证鹏元资信评估股份有限公司, 中诚信国际信用评级有限责任公司
-      中诚信证评数据科技有限公司, 云南省资信评估事务所, 大公国际资信评估有限公司, 大普信用评级股份有限公司
-      安融信用评级有限公司, 惠誉博华信用评级有限公司, 惠誉国际信用评级有限公司, 标准普尔评级公司, 标普信用评级(中国)有限公司
-      福建省资信评级委员会, 穆迪评级公司, 联合信用评级有限公司, 联合资信评估股份有限公司, 远东资信评估有限公司
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-    if start_date:
-        start_date = ensure_date_int(start_date)
-    if end_date:
-        end_date = ensure_date_int(end_date)
-    if institutions:
-        institutions = ensure_list_of_string(institutions)
-    data = get_client().execute("convertible.get_credit_rating", order_book_ids, start_date, end_date, institutions)
-    if data:
-        df = pd.DataFrame.from_records(data, index=["order_book_id", "credit_date"])
-        df["rice_create_tm"] = pd.to_datetime(df["rice_create_tm"] + 3600*8, unit="s")
-        df.sort_index(inplace=True)
-        return df
+# -*- coding: utf-8 -*-
+import warnings
+import datetime
+
+import pandas as pd
+import numpy as np
+from rqdatac.services.constant import RATETYPE_CN, RATECOMP_CN
+
+from rqdatac.client import get_client
+from rqdatac.validators import (
+    ensure_int,
+    ensure_date_int,
+    ensure_order_book_id,
+    ensure_order_book_ids,
+    ensure_date_range,
+    ensure_dates_base_on_listed_date,
+    ensure_list_of_string, ensure_date_or_today_int, check_items_in_container)
+from rqdatac.utils import to_datetime, int8_to_datetime
+from rqdatac.decorators import export_as_api, ttl_cache
+from rqdatac.services.calendar import (
+    get_trading_dates,
+)
+from rqdatac.services import shenwan
+from rqdatac.rqdatah_helper import rqdatah_serialize, http_conv_instruments
+
+INS_COLUMNS = [
+    "order_book_id",
+    "symbol",
+    "full_name",
+    "exchange",
+    "bond_type",
+    "trade_type",
+    "value_date",
+    "maturity_date",
+    "par_value",
+    "coupon_rate",
+    "coupon_frequency",
+    "coupon_method",
+    "compensation_rate",
+    "total_issue_size",
+    "de_listed_date",
+    "stock_code",
+    "conversion_start_date",
+    "conversion_end_date",
+    "redemption_price",
+    "issue_price",
+    "call_protection",
+    "listed_date",
+    "stop_trading_date",
+    "early_maturity_date"
+]
+
+
+class Instrument:
+    def __init__(self, attrs):
+        self.__dict__.update(attrs)
+        self.__cache = {}
+
+    def __str__(self):
+        return "{}(\n{}\n)".format(
+            type(self).__name__,
+            ",\n".join(["{}={!r}".format(k, v) for k, v in self.items() if not k.startswith("_")]),
+        )
+
+    __repr__ = __str__
+
+    def __setitem__(self, key, value):
+        self.__dict__[key] = value
+
+    def __getitem__(self, item):
+        return self.__dict__[item]
+
+    def get(self, item, default=None):
+        return self.__dict__.get(item, default)
+
+    def items(self):
+        return self.__dict__.items()
+
+    def keys(self):
+        return self.__dict__.keys()
+
+    def values(self):
+        return self.__dict__.values()
+
+    def __cache_get(self, v):
+        return self.__cache.get(v)
+
+    def __cache_set(self, k, v):
+        self.__cache[k] = v
+
+    def coupon_rate_table(self):
+        """变动利率可转债信息"""
+        if "coupon_rate_table" in self.__cache:
+            return self.__cache_get("coupon_rate_table")
+        info = get_client().execute("convertible.get_coupon_rate_table", self.order_book_id)
+        info = pd.DataFrame(info).set_index(['start_date', 'end_date']) if info else None
+        self.__cache_set("coupon_rate_table", info)
+        return info
+
+    def option(self, option_type=None):
+        if option_type is not None:
+            option_type = ensure_int(option_type)
+            if option_type not in (1, 2, 3, 4, 5, 6, 7):
+                raise ValueError("option_type: expect value in (None, 1, 2, 3, 4, 5, 6, 7)")
+
+        data = get_client().execute("convertible.option", self.order_book_id, option_type)
+        if not data:
+            return
+
+        df = pd.DataFrame(data)
+        if 'payment_year' in df.columns:
+            sort_fields = ['option_type', 'payment_year']
+        else:
+            sort_fields = ['option_type']
+        df = df.sort_values(sort_fields).reset_index()
+        column_order = ['option_type', 'start_date', 'end_date', 'payment_year', 'level', 'window_days',
+                        'reach_days', 'frequency', 'price', 'if_include_interest', 'remark']
+        column = [i for i in column_order if i in df.columns]
+        return df[column]
+
+
+@ttl_cache(12 * 3600)
+def _all_instruments_dict(market="cn"):
+    return {
+        i['order_book_id']: Instrument(i)
+        for i in get_client().execute("convertible.all_instruments", market=market)
+    }
+
+
+@export_as_api(namespace="convertible")
+def all_instruments(date=None, market="cn"):
+    """获取所有可转债详细信息
+
+    :param market:  (Default value = "cn")
+    :returns: DataFrame
+    """
+    profile = lambda v: (
+        v.order_book_id,
+        v.symbol,
+        v.full_name,
+        v.exchange,
+        v.bond_type,
+        v.trade_type,
+        v.value_date,
+        v.maturity_date,
+        v.par_value,
+        v.coupon_rate,
+        v.coupon_frequency,
+        v.coupon_method,
+        v.compensation_rate,
+        v.total_issue_size,
+        v.de_listed_date,
+        v.stock_code,
+        v.conversion_start_date,
+        v.conversion_end_date,
+        v.redemption_price,
+        v.issue_price,
+        v.call_protection,
+        v.listed_date,
+        v.early_maturity_date,
+        getattr(v, 'stop_trading_date', None)
+    )
+
+    def judge(listed_date, de_listed_date):
+        if listed_date and de_listed_date:
+            return listed_date <= date and de_listed_date > date
+        if listed_date:
+            return listed_date <= date
+        else:
+            return False
+
+    if date:
+        date = to_datetime(date)
+        data = [profile(v) for v in _all_instruments_dict(market).values() if judge(v.listed_date, v.de_listed_date)]
+    else:
+        data = [profile(v) for v in _all_instruments_dict(market).values()]
+    df = pd.DataFrame(
+        data,
+        columns=INS_COLUMNS,
+    )
+    df.sort_values('order_book_id', inplace=True)
+    return df.reset_index(drop=True)
+
+
+@export_as_api(namespace="convertible")
+@rqdatah_serialize(converter=http_conv_instruments)
+def instruments(order_book_ids, market="cn"):
+    """获取可转债详细信息
+
+    :param order_book_ids: 可转债代码，str 或 list of str
+    :param market:  (Default value = "cn")
+    :returns: Instrument object or list of Instrument object
+            取决于参数是一个 order_book_id 还是多个 order_book_id
+    """
+    all_dict = _all_instruments_dict(market)
+    order_book_ids = ensure_list_of_string(order_book_ids, "order_book_ids")
+    if len(order_book_ids) == 1:
+        try:
+            return all_dict[order_book_ids[0]]
+        except KeyError:
+            warnings.warn('unknown convertible order_book_id: {}'.format(order_book_ids))
+            return
+    all_list = (all_dict.get(i) for i in order_book_ids)
+    return [i for i in all_list if i]
+
+
+@export_as_api(namespace="convertible")
+def get_cash_flow(order_book_ids, start_date=None, end_date=None, market="cn"):
+    """获取现金流信息
+
+    :param order_book_ids: 可转债ID str or list
+    :param start_date: 开始日期，默认为None
+    :param end_date: 结束日期，默认为None
+    :param market:  (Default value = "cn")
+    :return: pd.DataFrame
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    if start_date:
+        start_date = ensure_date_int(start_date)
+    if end_date:
+        end_date = ensure_date_int(end_date)
+    data = get_client().execute("convertible.get_cash_flow", order_book_ids, start_date, end_date, market=market)
+    if not data:
+        return
+    df = pd.DataFrame(data)
+    df.set_index(["order_book_id", "payment_date"], inplace=True)
+    return df
+
+
+@export_as_api(namespace="convertible")
+def get_call_info(order_book_ids, start_date=None, end_date=None, market="cn"):
+    """获取赎回信息
+
+    :param order_book_ids: 可转债ID，str or list
+    :param start_date: 开始日期，默认为None
+    :param end_date: 结束日期，默认为None
+    :param market:  (Default value = "cn")
+    :return: pd.DataFrame
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    if start_date:
+        start_date = ensure_date_int(start_date)
+    if end_date:
+        end_date = ensure_date_int(end_date)
+    data = get_client().execute("convertible.get_call_info", order_book_ids, start_date, end_date, market=market)
+    if not data:
+        return
+    df = pd.DataFrame(data)
+    df.set_index(["order_book_id", "info_date"], inplace=True)
+    return df
+
+
+@export_as_api(namespace="convertible")
+def get_put_info(order_book_ids, start_date=None, end_date=None, market="cn"):
+    """获取回售信息
+
+    :param order_book_ids: 可转债ID，str or list
+    :param start_date: 开始日期，默认为None
+    :param end_date: 结束日期，默认为None
+    :param market:  (Default value = "cn")
+    :return: pd.DataFrame
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    if start_date:
+        start_date = ensure_date_int(start_date)
+    if end_date:
+        end_date = ensure_date_int(end_date)
+    data = get_client().execute("convertible.get_put_info", order_book_ids, start_date, end_date, market=market)
+    if not data:
+        return
+    df = pd.DataFrame(data)
+    df.set_index(["order_book_id", "info_date"], inplace=True)
+    return df
+
+
+@export_as_api(namespace="convertible")
+def get_conversion_price(order_book_ids, start_date=None, end_date=None, market="cn"):
+    """获取转股价变动信息
+
+    :param order_book_ids: 可转债ID，str or list
+    :param start_date: 开始日期，默认为None
+    :param end_date: 结束日期，默认为None
+    :param market:  (Default value = "cn")
+    :return: pd.DataFrame
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    if start_date:
+        start_date = ensure_date_int(start_date)
+    if end_date:
+        end_date = ensure_date_int(end_date)
+    data = get_client().execute("convertible.get_conversion_price", order_book_ids, start_date, end_date, market=market)
+    if not data:
+        return
+    df = pd.DataFrame(data)
+    df.set_index(["order_book_id", "info_date"], inplace=True)
+    return df
+
+
+@export_as_api(namespace="convertible")
+def get_conversion_info(order_book_ids, start_date=None, end_date=None, market="cn"):
+    """获取转股变动信息
+
+    :param order_book_ids: 可转债ID，str or list
+    :param start_date: 开始日期，默认为None
+    :param end_date: 结束日期，默认为None
+    :param market:  (Default value = "cn")
+    :return: pd.DataFrame
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    if start_date:
+        start_date = ensure_date_int(start_date)
+    if end_date:
+        end_date = ensure_date_int(end_date)
+    data = get_client().execute("convertible.get_conversion_info", order_book_ids, start_date, end_date, market=market)
+    if not data:
+        return
+    df = pd.DataFrame(data)
+    df.set_index(["order_book_id", "info_date"], inplace=True)
+    return df
+
+
+@export_as_api(namespace="convertible")
+def is_suspended(order_book_ids, start_date=None, end_date=None):
+    """获取停牌信息
+    :param order_book_ids: 可转债ID
+    :param start_date: 开始日期, 如'2013-01-04' (Default value = None)
+    :param end_date: 结束日期，如'2014-01-04' (Default value = None)
+    :returns: DataFrame
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    if len(order_book_ids) == 1:
+        instrument = instruments(order_book_ids[0], market="cn")
+        start_date, end_date = ensure_dates_base_on_listed_date(instrument, start_date, end_date, "cn")
+        if start_date is None:
+            return
+    start_date, end_date = ensure_date_range(start_date, end_date)
+
+    trading_dates = pd.to_datetime(get_trading_dates(start_date, end_date, market="cn"))
+    df = pd.DataFrame(data=False, columns=order_book_ids, index=trading_dates)
+    data = get_client().execute("convertible.is_suspended", order_book_ids, start_date, end_date, market="cn")
+    for (order_book_id, date) in data:
+        date = to_datetime(date)
+        df.at[date, order_book_id] = True
+    return df
+
+
+@export_as_api(namespace="convertible")
+def rating(date=None, credit_level=None, institution=None, rating_type=None, target='debt'):
+    """
+    Get rating information for company or bond
+    :param date: str, int, or datatime
+        1): 存续债券的判定是date在[value_date,maturity_date]之间
+        2): 控制credit_date返回当前最新的日期
+    :param credit_level: eg: 'AAA'
+    :param institution: rating company name
+    :param rating_type: rating type name
+    :param target: 'debt' or 'issuer'
+    :return:
+    """
+    check_items_in_container(target, ['debt', 'issuer'], 'target')
+    if institution is not None:
+        check_items_in_container(institution, RATECOMP_CN, 'institution')
+        if institution == "中诚信证券评估有限公司":
+            institution = "中诚信证评数据科技有限公司"
+    if rating_type is not None:
+        check_items_in_container(rating_type, RATETYPE_CN, 'rating_type')
+    date = ensure_date_int(date) if date else None
+
+    res = get_client().execute("convertible.rating", date, credit_level, institution, rating_type, target)
+
+    if date and res and target == 'debt':
+        ins = instruments(res)
+        if not isinstance(ins, list):
+            ins = [ins]
+        res = [i.order_book_id for i in ins if i.value_date <= int8_to_datetime(date) <= i.maturity_date]
+    return res
+
+
+@export_as_api(namespace="convertible")
+def get_latest_rating(order_book_ids, date, institution=None, rating_type=None, target='debt'):
+    """
+    获取在给定日期之前的最新评级记录.
+    返回credit_date和参数date前差距时间最短的一条记录，无需返回所有评级机构最新记录
+
+    :param order_book_ids: str or List[str]债券id列表
+    :param date: str or int or datetime.date) 评级日期; 会返回该日期之前的最新评级记录.
+    :param institution: str or List[str] or None 评级机构; 若为None, 则返回所有评级机构的最新记录
+    :param rating_type: str or None 评级类型; 如果给定的话, 只返回该评级类型下最新的评级信息,
+        如果设为None, 则不管评级类型, 直接返回最新评级记录
+    :param target: str 评级类型, 可选值为 'debt'(代表债券评级) 或者 'issuer'(代表主体评级);
+    :return: a pandas DataFrame with order_book_id as index.
+    """
+    order_book_ids = ensure_list_of_string(order_book_ids, "order_book_ids")
+    check_items_in_container(target, ['debt', 'issuer'], 'target')
+    if institution is not None:
+        institution = ensure_list_of_string(institution, "institution")
+        check_items_in_container(institution, RATECOMP_CN, 'institution')
+        if "中诚信证券评估有限公司" in institution:
+            institution.append("中诚信证评数据科技有限公司")
+
+    data = get_client().execute(
+        "convertible.get_latest_rating",
+        order_book_ids,
+        ensure_date_int(date),
+        institution,
+        rating_type,
+        target
+    )
+    if not data:
+        return
+    df = pd.DataFrame.from_records(data)
+    df.sort_values(["order_book_id", "credit_date"], ascending=False, inplace=True)
+    df.set_index("order_book_id", inplace=True)
+    return df
+
+
+@export_as_api(namespace="convertible")
+def get_instrument_industry(order_book_ids, source='citics', level=1, date=None, market="cn"):
+    """获取可转债对应的行业
+
+    :param order_book_ids: 可转债order_book_id，如['000001.XSHE', '000002.XSHE']
+    :param source: 分类来源。citics 以及 citics_2019: 中信, gildata: 聚源
+    :param date: 如 '2015-01-07' (Default value = None)
+    :param level:  (Default value = 1)
+    :param market:  (Default value = "cn")
+    :returns: DataFrame
+        index: order_book_id
+        columns:
+            if level == 1: ["first_industry_code", "first_industry_name"]
+            if level == 2: ["second_industry_code", "second_industry_name"]
+            if level == 3: ["third_industry_code", "third_industry_name"]
+            if level == 0:
+                [
+                    "first_industry_code", "first_industry_name", "second_industry_code",
+                    "second_industry_name", "third_industry_code", "third_industry_name",
+                ]
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, type="Convertible")
+    all_dict = _all_instruments_dict(market)
+    # array of [(order_book_id, stock_code)]
+    mapper = np.array([(i, all_dict[i].stock_code) for i in order_book_ids if i in all_dict])
+
+    # 调用股票行业接口
+    res = shenwan.get_instrument_industry(set(mapper[:, 1]), source, level, date, market)
+    if res is None:
+        return
+
+    # 转换order_book_id为可转债id
+    res = res.reindex(mapper[:, 1])
+    res.index = pd.Index(mapper[:, 0], name='order_book_id')
+    return res
+
+
+@export_as_api(namespace="convertible")
+def get_industry(industry, source='citics', date=None, market="cn"):
+    """获取行业可转债列表
+
+    :param industry: 行业名称或代码
+    :param source: 分类来源。citics 以及 citics_2019: 中信, gildata: 聚源
+    :param date: 查询日期，默认为当前最新日期
+    :param market:  (Default value = "cn")
+    :return: 所属目标行业的order_book_id list or None
+    """
+    # 调用股票行业接口
+    order_book_ids = shenwan.get_industry(industry, source, date, market)
+    if order_book_ids is None:
+        return
+
+    order_book_ids = set(order_book_ids)
+
+    all_dict = _all_instruments_dict(market)
+    if date:
+        oids = []
+        date = to_datetime(date)
+        for ins in all_dict.values():
+            if ins.stock_code in order_book_ids:
+                if ins.de_listed_date == "0000-00-00" or ins.de_listed_date is None:
+                    ins.de_listed_date = pd.to_datetime("2099-12-31")
+                if ins.listed_date is None:
+                    ins.listed_date = pd.to_datetime("2099-12-31")
+                if ins.listed_date <= date <= ins.de_listed_date:
+                    oids.append(ins.order_book_id)
+    else:
+        oids = [ins.order_book_id for ins in all_dict.values() if ins.stock_code in order_book_ids]
+    return sorted(oids)
+
+
+@export_as_api(namespace="convertible")
+def get_indicators(order_book_ids, start_date=None, end_date=None, fields=None):
+    """获取可转债指标(默认返回最新3个月的数据)
+
+    :param order_book_ids: str or List[str] 合约代码
+    :param start_date: (str or datetime.date): 开始日期
+    :param end_date: (str or datetime.date): 结束时间
+    :param fields: str or List[str] 筛选字段
+
+    :return: Multi-index DataFrame:
+        index: [order_book_id, date]
+        columns:
+            conversion_coefficient	                float	转股系数
+            conversion_value	                    float	转股价值
+            conversion_premium	                    float	转股溢价率
+            pure_bond_value_premium	                float	税后纯债溢价率
+            pure_bond_value_premium_pretax	        float   税前纯债溢价率
+            yield_to_maturity	                    float	税后到期收益率
+            yield_to_maturity_pretax	            float   税前到期收益率
+            yield_to_put	                        float	税后回售收益率
+            yield_to_put_pretax	                    float	税前回售收益率
+            pure_bond_value	                        float	税后纯债价值
+            pure_bond_value_pretax	                float	税前纯债价值
+            double_low_factor	                    float	双低指标
+            call_trigger_price	                    float	赎回触发价
+            put_trigger_price	                    float	回售触发价
+            conversion_price_reset_trigger_price	float	下修触发价
+            turnover_rate	                        float 	换手率
+            remaining_size	                        float 	剩余规模（元）
+            convertible_market_cap_ratio	        float 	转债市值占比
+            pb_ratio	                            float	市净率
+            put_qualified_days	                    float	回售已满足天数
+            call_qualified_days	                    float	赎回已满足天数
+            conversion_price_reset_qualified_days	float	转股价下修已满足天数
+            put_status	                            float	回售条款满足状态
+            call_status	                            float	强赎条款满足状态
+            conversion_price_reset_status	        float	下修条款满足状态
+            iv                                      float   隐含波动率
+            delta                                   float   转债价格对正股股价的敏感度
+            theta                                   float   转债价格对时间的偏导
+            gamma                                   float   转债价格对正股股价的二阶导
+            vega                                    float   转债价格对隐含波动率的偏导
+    """
+    all_fields = [
+        "conversion_coefficient", "conversion_value", "conversion_premium", "pure_bond_value_premium",
+        "pure_bond_value_premium_pretax", "yield_to_maturity", "yield_to_maturity_pretax", "yield_to_put",
+        "yield_to_put_pretax", "pure_bond_value", "pure_bond_value_pretax", "double_low_factor",
+        "call_trigger_price", "put_trigger_price", "conversion_price_reset_trigger_price", "turnover_rate",
+        "remaining_size", "convertible_market_cap_ratio", "pb_ratio", "put_qualified_days",
+        "call_qualified_days", "conversion_price_reset_qualified_days", "put_status", "call_status",
+        "conversion_price_reset_status", "pure_bond_value_1", "pure_bond_value_premium_1",
+        "iv", "delta", "theta", "gamma", "vega",
+    ]
+    order_book_ids = ensure_list_of_string(order_book_ids, "order_book_ids")
+    if fields is None:
+        fields = all_fields
+    else:
+        fields = ensure_list_of_string(fields, "fields")
+        check_items_in_container(fields, all_fields, 'fields')
+
+    # 默认返回最新3个月的数据
+    if start_date is None and end_date is None:
+        start_date, end_date = ensure_date_range(start_date, end_date)
+    start_date = ensure_date_int(start_date) if start_date is not None else start_date
+    end_date = ensure_date_int(end_date) if end_date is not None else end_date
+
+    data = get_client().execute(
+        "convertible.get_indicators", order_book_ids, start_date, end_date, fields
+    )
+    if not data:
+        return
+
+    data = pd.DataFrame(data)
+    data.set_index(["order_book_id", "date"], inplace=True)
+    data.sort_index(inplace=True)
+    return data
+
+
+@export_as_api(namespace="convertible")
+def get_coupon_rate_table(order_book_ids):
+    """ 变动利率可转债信息
+
+    :param order_book_ids: str or List[str] 合约代码
+    :return: DataFrame
+        index: ['order_book_id', 'start_date', 'end_date']
+        columns: ['coupon_rate']
+    """
+    order_book_ids = ensure_list_of_string(order_book_ids, "order_book_ids")
+    info = get_client().execute("convertible.get_coupon_rate_tables", order_book_ids)
+    info = pd.DataFrame(info).set_index(['order_book_id', 'start_date', 'end_date']) if info else None
+
+    return info
+
+
+@export_as_api(namespace="convertible")
+def get_accrued_interest_eod(order_book_ids, start_date=None, end_date=None):
+    """ 获取可转债应计利息
+
+    只输入开始日期，返回开始日往后3个月内数值；
+    只输入结束日期，返回结束日往前3个月应计利息；
+    不输入日期，则返回当前日期往以前3个月数值
+
+    :param order_book_ids: str or List[str] 合约代码
+    :param start_date: 开始时间
+    :param end_date: 结束时间
+    :return: DataFrame
+        index: date
+        columns: order_book_ids      str or List[str]
+    """
+    order_book_ids = ensure_list_of_string(order_book_ids, "order_book_ids")
+
+    if start_date is None or end_date is None:
+        start_date, end_date = ensure_date_range(start_date, end_date)
+    start_date = to_datetime(start_date)
+    end_date = to_datetime(end_date)
+
+    ins = instruments(order_book_ids)
+    if ins is None:
+        return
+
+    ins = ins if isinstance(ins, list) else [ins]
+    # 去掉当天已经完成赎回的转债
+    # 有的 id 比如 123095.XSHE 投资人缴款后突然终止上市，然后就退款了, 导致 maturity_date 为 None
+    order_book_ids = [c.order_book_id for c in ins 
+        if c.bond_type != "separately_traded" 
+        and c.maturity_date is not None
+        and c.maturity_date > start_date
+    ]
+    if not order_book_ids:
+        return None
+
+    # 获得强赎信息
+    called_info = get_call_info(order_book_ids)
+
+    # 获取coupon_rate_table
+    coupon_rate_tables = get_coupon_rate_table(order_book_ids)
+    # sort 一下确保后面取到的 end_date 的最后一条记录是最新的.
+    coupon_rate_tables.sort_index(inplace=True)
+    coupon_rate_tables.reset_index(inplace=True)
+
+    res_list = []
+    for oid, sub_df in coupon_rate_tables.groupby("order_book_id"):
+        record_date = sub_df.iloc[-1].end_date
+        if called_info is not None and oid in called_info.index.get_level_values(0):
+            # 获取登记时间
+            record_date = called_info.loc[oid].record_date[0]
+            sub_df = sub_df[sub_df["start_date"] <= record_date]
+
+        # 生成时间段内对应的coupon_rate
+        date_range = pd.date_range(sub_df.iloc[0].start_date, sub_df.iloc[-1].end_date)
+        df = pd.DataFrame({"date": date_range})
+        df = pd.merge_asof(df, sub_df, left_on="date", right_on="end_date", direction="forward")
+        df.dropna(inplace=True)
+        df = df[df["date"] <= record_date]
+
+        # 计算利息
+        df["value"] = (df.date - df.start_date) / datetime.timedelta(days=365) * df.coupon_rate * 100
+
+        # 闰日用前一天的利息补
+        # FIXME 闰日之后的所有利息需往前挪一天
+        df.loc[(df["date"].dt.month == 2) & (df["date"].dt.day == 29), "value"] = np.nan
+        df = df.ffill()
+
+        df = df[(df.date >= start_date) & (df.date <= end_date)]
+        df = df.pivot(index="date", columns="order_book_id", values="value")
+        df.columns.name = None
+        df = df.sort_index()
+        res_list.append(df)
+
+    res = pd.concat(res_list, axis=1) if res_list else None
+    return res
+
+
+@export_as_api(namespace="convertible")
+def get_call_announcement(order_book_ids, start_date=None, end_date=None, market="cn"):
+    """ 获取合约的赎回提示性公告数据
+
+    :param order_book_ids: 股票合约id
+    :param start_date: 开始时间
+    :param end_date: 结束时间
+    :param market: 默认 'cn'
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+    end_date = ensure_date_or_today_int(end_date)
+    if start_date:
+        start_date = ensure_date_int(start_date)
+        if start_date > end_date:
+            raise ValueError("invalid date range: [{!r}, {!r}]".format(start_date, end_date))
+    data = get_client().execute("convertible.get_call_announcement", order_book_ids, start_date, end_date, market)
+    if data:
+        df = pd.DataFrame(data)
+        df.set_index(['order_book_id', 'info_date'], inplace=True)
+        df.sort_index(inplace=True)
+        return df
+
+
+@export_as_api(namespace="convertible")
+def get_credit_rating(order_book_ids, start_date=None, end_date=None, institutions=None, market="cn"):
+    """ 获取合约的评级信息
+
+    :param order_book_ids: 合约id
+    :param start_date: 开始时间
+    :param end_date: 结束时间
+    :param institutions: 评级机构
+    :param market: 默认 'cn'
+
+    Note: 评级机构清单如下:
+      上海新世纪资信评估投资服务有限公司, 上海资信有限公司, 东方金诚国际信用评估有限公司
+      中债资信评估有限责任公司, 中国诚信信用管理股份有限公司, 中证鹏元资信评估股份有限公司, 中诚信国际信用评级有限责任公司
+      中诚信证评数据科技有限公司, 云南省资信评估事务所, 大公国际资信评估有限公司, 大普信用评级股份有限公司
+      安融信用评级有限公司, 惠誉博华信用评级有限公司, 惠誉国际信用评级有限公司, 标准普尔评级公司, 标普信用评级(中国)有限公司
+      福建省资信评级委员会, 穆迪评级公司, 联合信用评级有限公司, 联合资信评估股份有限公司, 远东资信评估有限公司
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+    if start_date:
+        start_date = ensure_date_int(start_date)
+    if end_date:
+        end_date = ensure_date_int(end_date)
+    if institutions:
+        institutions = ensure_list_of_string(institutions)
+    data = get_client().execute("convertible.get_credit_rating", order_book_ids, start_date, end_date, institutions)
+    if data:
+        df = pd.DataFrame.from_records(data, index=["order_book_id", "credit_date"])
+        df["rice_create_tm"] = pd.to_datetime(df["rice_create_tm"] + 3600*8, unit="s")
+        df.sort_index(inplace=True)
+        return df
```

## rqdatac/services/extra.py

 * *Ordering differences only*

```diff
@@ -1,68 +1,68 @@
-import datetime
-import warnings
-
-import pandas as pd
-from rqdatac.services.stock_status import get_shares
-from rqdatac.services.get_price import get_price
-from rqdatac.services.calendar import is_trading_date, get_previous_trading_date
-from rqdatac.services.live import current_snapshot
-from rqdatac.validators import ensure_order_book_ids
-from rqdatac.decorators import export_as_api
-
-
-@export_as_api
-def current_freefloat_turnover(order_book_ids):
-    """
-    股票当日累计自由流通换手率, 即当日累计成交金额/自由流通市值（盘中实时）
-
-    :param order_book_ids: 股票代码或代码列表, 如'000001.XSHE'
-
-    :return: pd.Series or None
-    """
-    today = datetime.date.today()
-    if not is_trading_date(today):
-        warnings.warn('today is not a trading day!')
-        return None
-
-    order_book_ids = ensure_order_book_ids(order_book_ids, type='CS')
-    shares = get_shares(order_book_ids, today, today, fields='free_circulation')
-    if shares is None:
-        return None
-    shares = shares.droplevel(1)['free_circulation']
-
-    snapshots = current_snapshot(order_book_ids)
-    if len(order_book_ids) == 1:
-        snapshots = [snapshots]
-    t_shares = pd.Series({(t.order_book_id, t.datetime): t.total_turnover/t.last for t in snapshots})
-    t_shares.index.names = ['order_book_id', 'datetime']
-    turnover = t_shares / shares
-    return turnover
-
-
-@export_as_api
-def get_live_minute_price_change_rate(order_book_ids):
-    """
-    获取当日分钟累积收益率
-
-    :param order_book_ids: 股票代码或代码列表, 如'000001.XSHE'
-
-    :return: pd.DataFrame or None
-    """
-    today = datetime.date.today()
-    if not is_trading_date(today):
-        warnings.warn('today is not a trading day!')
-        return None
-
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    close = get_price(order_book_ids, today, today, '1m', fields='close', adjust_type='none')
-    if close is None:
-        warnings.warn('today minute data is not ready')
-        return
-
-    close = close['close'].unstack('order_book_id')
-    snapshots = current_snapshot(order_book_ids)
-    if len(order_book_ids) == 1:
-        snapshots = [snapshots]
-    prev_close = pd.Series({t.order_book_id: t.prev_close for t in snapshots})
-    minute_return = close / prev_close - 1
-    return minute_return
+import datetime
+import warnings
+
+import pandas as pd
+from rqdatac.services.stock_status import get_shares
+from rqdatac.services.get_price import get_price
+from rqdatac.services.calendar import is_trading_date, get_previous_trading_date
+from rqdatac.services.live import current_snapshot
+from rqdatac.validators import ensure_order_book_ids
+from rqdatac.decorators import export_as_api
+
+
+@export_as_api
+def current_freefloat_turnover(order_book_ids):
+    """
+    股票当日累计自由流通换手率, 即当日累计成交金额/自由流通市值（盘中实时）
+
+    :param order_book_ids: 股票代码或代码列表, 如'000001.XSHE'
+
+    :return: pd.Series or None
+    """
+    today = datetime.date.today()
+    if not is_trading_date(today):
+        warnings.warn('today is not a trading day!')
+        return None
+
+    order_book_ids = ensure_order_book_ids(order_book_ids, type='CS')
+    shares = get_shares(order_book_ids, today, today, fields='free_circulation')
+    if shares is None:
+        return None
+    shares = shares.droplevel(1)['free_circulation']
+
+    snapshots = current_snapshot(order_book_ids)
+    if len(order_book_ids) == 1:
+        snapshots = [snapshots]
+    t_shares = pd.Series({(t.order_book_id, t.datetime): t.total_turnover/t.last for t in snapshots})
+    t_shares.index.names = ['order_book_id', 'datetime']
+    turnover = t_shares / shares
+    return turnover
+
+
+@export_as_api
+def get_live_minute_price_change_rate(order_book_ids):
+    """
+    获取当日分钟累积收益率
+
+    :param order_book_ids: 股票代码或代码列表, 如'000001.XSHE'
+
+    :return: pd.DataFrame or None
+    """
+    today = datetime.date.today()
+    if not is_trading_date(today):
+        warnings.warn('today is not a trading day!')
+        return None
+
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    close = get_price(order_book_ids, today, today, '1m', fields='close', adjust_type='none')
+    if close is None:
+        warnings.warn('today minute data is not ready')
+        return
+
+    close = close['close'].unstack('order_book_id')
+    snapshots = current_snapshot(order_book_ids)
+    if len(order_book_ids) == 1:
+        snapshots = [snapshots]
+    prev_close = pd.Series({t.order_book_id: t.prev_close for t in snapshots})
+    minute_return = close / prev_close - 1
+    return minute_return
```

## rqdatac/services/factor.py

 * *Ordering differences only*

```diff
@@ -1,912 +1,912 @@
-# -*- coding: utf-8 -*-
-import datetime
-import warnings
-from collections import OrderedDict
-
-import pandas as pd
-import numpy as np
-
-from rqdatac.services.calendar import (
-    get_previous_trading_date,
-    get_next_trading_date,
-    get_trading_dates,
-)
-from rqdatac.validators import (
-    ensure_list_of_string,
-    ensure_date_int,
-    ensure_date_range,
-    ensure_string,
-    ensure_string_in,
-    check_items_in_container,
-    ensure_order_book_ids,
-    ensure_order_book_id,
-)
-from rqdatac.client import get_client
-from rqdatac.decorators import export_as_api
-from rqdatac.rqdatah_helper import rqdatah_serialize, http_conv_list_to_csv
-
-
-VALID_FACTOR_TYPES = [
-    'income_statement',
-    'balance_sheet',
-    'cash_flow_statement',
-    'eod_indicator',
-    'operational_indicator',
-    'cash_flow_indicator',
-    'financial_indicator',
-    'growth_indicator',
-    'alpha101',
-    'moving_average_indicator',
-    'obos_indicator',
-    'energy_indicator',
-    'other',
-]
-
-
-@export_as_api
-@rqdatah_serialize(converter=http_conv_list_to_csv, name='factor')
-def get_all_factor_names(type=None, market="cn"):
-    """获取因子列表
-
-    :param type: str,因子类型 default None (即 eod_indicator)
-        ’income_statement‘：利润表 (以及其 mrq, ttm, lyr)
-        ’balance_sheet‘：资产负债表 (以及其 mrq, ttm, lyr)
-        ’cash_flow_statement‘：现金流量表 (以及其 mrq, ttm, lyr)
-        ‘eod_indicator’：估值有关指标
-        ‘operational_indicator‘：经营衍生指标表
-        ‘cash_flow_indicator’：现金流衍生指标
-        ‘financial_indicator‘：财务衍生指标
-        ‘growth_indicator’：增长衍生指标
-        ’alpha101‘：alpha101 因子
-        'moving_average_indicator'：均线类指标
-        'obos_indicator'：超买超卖指标
-        'energy_indicator'：能量指标
-        'other': 其他因子
-    :return:
-        list
-
-    :param market:  (Default value = "cn")
-
-    """
-    if type is not None and (not isinstance(type, str) or type not in VALID_FACTOR_TYPES):
-        raise ValueError('invalid type: {}'.format(type))
-    return get_client().execute("get_all_factor_names", type=type, market=market)
-
-
-@export_as_api
-def get_factor(order_book_ids, factor, start_date=None, end_date=None, universe=None, expect_df=True, **kwargs):
-    """获取因子
-
-    :param order_book_ids: 股票代码或代码列表
-    :param factor: 如 'total_income'
-    :param date: 如 date='2015-01-05', 默认为前一交易日
-    :param start_date: 开始日期'2015-01-05', 默认为前一交易日, 最小起始日期为'2000-01-04'
-    :param end_date: 结束日期
-    :param universe: 股票池，默认为全A股
-    :param expect_df: 返回 MultiIndex DataFrame (Default value = True)
-    :returns: pd.DataFrame
-    """
-
-    order_book_ids = ensure_order_book_ids(order_book_ids, type="CS")
-    order_book_ids = list(set(order_book_ids))
-
-    factor = ensure_list_of_string(factor)
-    factor = list(OrderedDict.fromkeys(factor))
-
-    if start_date and end_date:
-        start_date, end_date = ensure_date_range(start_date, end_date, datetime.timedelta(days=15))
-        if start_date < 20000104:
-            warnings.warn("start_date is earlier than 2000-01-04, adjusted to 2000-01-04")
-            start_date = 20000104
-    elif start_date:
-        raise ValueError("Expect end_date")
-    elif end_date:
-        raise ValueError("Expect start_date")
-    else:
-        date = kwargs.pop("date", None)
-        date = ensure_date_int(date or get_previous_trading_date(datetime.date.today()))
-        start_date = end_date = date
-
-    if kwargs:
-        raise ValueError('unknown kwargs: {}'.format(kwargs))
-
-    if universe is not None:
-        universe = ensure_string(universe, "universe")
-        if universe != "all":
-            universe = ensure_order_book_id(universe, type="INDX")
-            comp_data = get_client().execute('index_components_v2', universe, start_date, end_date, market='cn')
-            allowed_order_book_ids = set()
-            for comp in comp_data:
-                allowed_order_book_ids.update(comp['component_ids'])
-            not_permit_order_book_ids = set(order_book_ids) - allowed_order_book_ids
-            if not_permit_order_book_ids:
-                warnings.warn(
-                    "%s not in universe pool from %s to %s, value of those order_book_ids may be NaN"
-                    % (not_permit_order_book_ids, start_date, end_date)
-                )
-
-    data = get_client().execute(
-        "get_factor_from_store", order_book_ids, factor, start_date, end_date, universe=universe
-    )
-
-    if not data:
-        return
-
-    factor_value_length = len(data[0][2])
-    if factor_value_length == 0:
-        return
-
-    dates = pd.to_datetime(get_trading_dates(start_date, end_date))
-    days = len(dates)
-    if days > factor_value_length:
-        _get_factor_warning_msg(dates[factor_value_length], dates[-1])
-        dates = dates[0:factor_value_length]
-
-    if expect_df or len(factor) > 1:
-        order_book_id_index_map = {o: i for i, o in enumerate(order_book_ids)}
-        factor_index_map = {f: i for i, f in enumerate(factor)}
-        arr = np.full((len(order_book_ids) * days, len(factor)), np.nan)
-
-        for order_book_id, factor_name, values in data:
-            if not values:
-                continue
-            value_length = min(days, len(values))
-            order_book_id_index = order_book_id_index_map[order_book_id]
-            factor_index = factor_index_map[factor_name]
-            start = order_book_id_index * days
-            arr[start: start + value_length, factor_index] = values[-value_length:]
-
-        multi_index = pd.MultiIndex.from_product([order_book_ids, dates], names=["order_book_id", "date"])
-        df = pd.DataFrame(index=multi_index, columns=factor, data=arr)
-        return df
-
-    order_book_id_index_map = {o: i for i, o in enumerate(order_book_ids)}
-    arr = np.full((days, len(order_book_ids)), np.nan)
-    for order_book_id, _, values in data:
-        arr[:len(values), order_book_id_index_map[order_book_id]] = values
-    df = pd.DataFrame(index=dates, columns=order_book_ids, data=arr)
-
-    if len(df.index) == 1:
-        return df.iloc[0]
-    if len(df.columns) == 1:
-        return df[df.columns[0]]
-    return df
-
-
-def _get_factor_warning_msg(start_date, end_date):
-    if start_date == end_date:
-        end_date = end_date.strftime("%Y%m%d")
-        warnings.warn("{} calculation not completed".format(end_date))
-    else:
-        start_date = start_date.strftime("%Y%m%d")
-        end_date = end_date.strftime("%Y%m%d")
-        warnings.warn(
-            "{} - {} calculation not completed".format(start_date, end_date))
-
-
-_UNIVERSE_MAPPING = {
-    "whole_market": "whole_market",
-    "000300.XSHG": "csi_300",
-    "000905.XSHG": "csi_500",
-    "000906.XSHG": "csi_800",
-}
-
-_METHOD_MAPPING = {"explicit": "explicit_factor_return", "implicit": "implicit_factor_return"}
-
-
-@export_as_api
-def get_factor_return(
-    start_date, end_date, factors=None, universe="whole_market", method="implicit", industry_mapping="sws_2021", model="v1", market="cn"
-):
-    """获取因子收益率数据
-
-    :param start_date: 开始日期（例如：‘2017-03-03’)
-    :param end_date: 结束日期（例如：‘2017-03-20’)
-    :param factors: 因子。默认获取全部因子的因子收益率
-        当 method 参数取值为'implicit' ，可返回全部因子（风格、行业、市场联动）的隐式因子收益率；
-        当 method 参数取值为'explicit' , 只返回风格因子的显式因子收益率。具体因子名称见说明文档 (Default value = None)
-    :param universe: 股票池。默认调用全市场收益率。可选沪深300（‘000300.XSHG’）、中证500（'000905.XSHG'）
-        、以及中证800（'000906.XSHG'） (Default value = "whole_market")
-    :param method: 计算方法。默认为'implicit'（隐式因子收益率），可选'explicit'（显式风格因子收益率) (Default value = "implicit")
-    :param market: 地区代码， 现在仅支持 'cn' (Default value = "cn")
-    :param industry_mapping(str): 使用的行业类别，可选 sws_2021, citics_2019, 默认为 sws_2021
-    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
-    :returns: pd.DataFrame. index 为日期，column 为因子字段名称。
-
-    Usage example::
-        # 获取介于2017-03-03 到 2017-03-20到隐式因子收益率数据
-        get_factor_return('2017-03-03', '2017-03-20')
-
-    """
-    industry_mapping = _convert_industry_mapping(industry_mapping)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-
-    if factors:
-        factors = ensure_list_of_string(factors)
-        if method == "implicit":
-            check_items_in_container(factors, _IMPLICIT_RETURN_FACTORS, "factors")
-        elif method == "explicit":
-            check_items_in_container(factors, _EXPLICIT_RETURN_FACTORS, "factors")
-
-    method = ensure_string(method)
-    if method not in _METHOD_MAPPING:
-        raise ValueError("invalid method: {!r}, valid: explicit, implicit".format(method))
-    method = _METHOD_MAPPING[method]
-
-    if universe not in _UNIVERSE_MAPPING:
-        raise ValueError(
-            "invalid universe: {!r}, valid: {}".format(universe, list(_UNIVERSE_MAPPING.keys()))
-        )
-    universe = _UNIVERSE_MAPPING[universe]
-    check_items_in_container(model, ["v1", "v2", "v2trd"], "model")
-
-    model_to_api = {
-        "v1": "get_factor_return_v3",
-        "v2": "get_factor_return_rqd6_v2",
-        "v2trd": "get_factor_return_rqd6trd",
-    }
-    df = get_client().execute(
-        model_to_api[model], start_date, end_date, factors, universe, method, market=market, industry_mapping=industry_mapping
-    )
-    if not df:
-        return None
-    df = pd.DataFrame(df)
-    # convert to required format.
-    df = df.pivot(index="date", columns="factor")[universe]
-    df.sort_index(inplace=True)
-    return df
-
-
-def _get_all_industries(industry_name):
-    if industry_name == "sw2021":
-        return SHENWAN_INDUSTRY_2021
-    elif industry_name == "citics2019":
-        return CITICS_INDUSTRY_2019
-    else:
-        return SHENWAN_INDUSTRY_2014
-
-
-@export_as_api
-def get_factor_exposure(order_book_ids, start_date=None, end_date=None, factors=None, industry_mapping='sws_2021', model="v1", market="cn"):
-    """获取因子暴露度
-
-    :param order_book_ids: 股票代码或代码列表
-    :param start_date: 如'2013-01-04' (Default value = None)
-    :param end_date: 如'2014-01-04' (Default value = None)
-    :param factors: 如'yield', 'beta', 'volatility' (Default value = None)
-    :param market: 地区代码, 如'cn' (Default value = "cn")
-    :param industry_mapping: 是否按 2014 年后的申万行业分类标 准计算行业暴露度.默认为 True.
-        若取值为 False,则 2014 年前的行业 暴露度按旧行业分类标准计算
-    :param industry_mapping (str): 行业分类标准, 可选值包括 'sws_2021'(申万2021行业分类), 'sws_2014'(申万2014行业分类)
-        默认取 'sws_2021' 行业分类
-    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
-    :returns: MultiIndex DataFrame. index 第一个 level 为 order_book_id，第 二个 level 为 date，columns 为因子字段名称
-    """
-    industry_mapping = _convert_industry_mapping(industry_mapping)
-
-    check_items_in_container(industry_mapping, ["sw2014", "sw2021", "citics2019"], "industry_mapping")
-    check_items_in_container(model, ["v1", "v2", "v2trd"], "model")
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    if not order_book_ids:
-        raise ValueError("no valid order_book_id found")
-
-    start_date, end_date = ensure_date_range(start_date, end_date)
-
-    if factors is not None:
-        factors = ensure_list_of_string(factors)
-        if model == "v1":
-            check_items_in_container(factors, exposure_factors, "factors")
-        elif model == "v2":
-            check_items_in_container(factors, exposure_factors_rqd6, "factors")
-
-    model_to_api = {
-        "v1": "get_factor_exposure_v2",
-        "v2": "get_factor_exposure_rqd6",
-        "v2trd": "get_factor_exposure_rqd6trd",
-    }
-    results = get_client().execute(
-        model_to_api[model], order_book_ids, start_date, end_date, factors, industry_mapping, market
-    )
-
-    if not results:
-        return None
-    index_pairs = []
-    data = []
-
-    fields = [
-        field for field in results[0].keys() if field not in ("order_book_id", "date", "industry")
-    ]
-    industry_factors = _get_all_industries(industry_mapping)
-    for result in results:
-        index_pairs.append((result["date"], result["order_book_id"]))
-        row_data = [result.get(field, np.nan) for field in fields]
-
-        # 填充行业因子数据
-        for industry in industry_factors:
-            if result["industry"] == industry:
-                industry_label = 1
-            else:
-                industry_label = 0
-            row_data.append(industry_label)
-
-        data.append(row_data)
-
-    index = pd.MultiIndex.from_tuples(index_pairs, names=["date", "order_book_id"])
-    fields.extend(industry_factors)
-    result_df = pd.DataFrame(columns=fields, index=index, data=data)
-    result_df.sort_index(inplace=True)
-
-    no_data_book_id = set(order_book_ids) - set(result_df.index.levels[1])
-    if no_data_book_id:
-        warnings.warn("No data for this order_book_id :{}".format(no_data_book_id))
-
-    if factors is not None:
-        return result_df[factors]
-    return result_df
-
-
-exposure_factors = [
-    "residual_volatility",
-    "growth",
-    "liquidity",
-    "beta",
-    "non_linear_size",
-    "leverage",
-    "earnings_yield",
-    "size",
-    "momentum",
-    "book_to_price",
-    "comovement",
-]
-
-exposure_factors_rqd6 = [
-    "liquidity",
-    "leverage",
-    "earnings_variability",
-    "earnings_quality",
-    "profitability",
-    "investment_quality",
-    "book_to_price",
-    "earnings_yield",
-    "longterm_reversal",
-    "growth",
-    "momentum",
-    "mid_cap",
-    "size",
-    "beta",
-    "residual_volatility",
-    "dividend_yield",
-    "comovement"
-]
-
-# 申万2021行业分类
-SHENWAN_INDUSTRY_2021 = [
-    u"银行",
-    u"计算机",
-    u"环保",
-    u"商贸零售",
-    u"电力设备",
-    u"建筑装饰",
-    u"建筑材料",
-    u"农林牧渔",
-    u"电子",
-    u"交通运输",
-    u"汽车",
-    u"纺织服饰",
-    u"医药生物",
-    u"房地产",
-    u"通信",
-    u"公用事业",
-    u"综合",
-    u"机械设备",
-    u"石油石化",
-    u"有色金属",
-    u"传媒",
-    u"家用电器",
-    u"基础化工",
-    u"非银金融",
-    u"社会服务",
-    u"轻工制造",
-    u"国防军工",
-    u"美容护理",
-    u"煤炭",
-    u"食品饮料",
-    u"钢铁"
-]
-
-# 申万2014 行业分类
-SHENWAN_INDUSTRY_2014 = [
-    u"农林牧渔",
-    u"采掘",
-    u"化工",
-    u"钢铁",
-    u"有色金属",
-    u"电子",
-    u"家用电器",
-    u"食品饮料",
-    u"纺织服装",
-    u"轻工制造",
-    u"医药生物",
-    u"公用事业",
-    u"交通运输",
-    u"房地产",
-    u"商业贸易",
-    u"休闲服务",
-    u"综合",
-    u"建筑材料",
-    u"建筑装饰",
-    u"电气设备",
-    u"国防军工",
-    u"计算机",
-    u"传媒",
-    u"通信",
-    u"银行",
-    u"非银金融",
-    u"汽车",
-    u"机械设备",
-]
-
-# 中信2019 行业分类
-CITICS_INDUSTRY_2019 = [
-    u"交通运输",
-    u"传媒",
-    u"农林牧渔",
-    u"医药",
-    u"商贸零售",
-    u"国防军工",
-    u"基础化工",
-    u"家电",
-    u"建材",
-    u"建筑",
-    u"房地产",
-    u"有色金属",
-    u"机械",
-    u"汽车",
-    u"消费者服务",
-    u"煤炭",
-    u"电力及公用事业",
-    u"电力设备及新能源",
-    u"电子",
-    u"石油石化",
-    u"纺织服装",
-    u"综合",
-    u"综合金融",
-    u"计算机",
-    u"轻工制造",
-    u"通信",
-    u"钢铁",
-    u"银行",
-    u"非银行金融",
-    u"食品饮料"
-]
-
-exposure_factors.extend(SHENWAN_INDUSTRY_2021)
-exposure_factors.extend(SHENWAN_INDUSTRY_2014)
-exposure_factors.extend(CITICS_INDUSTRY_2019)
-
-exposure_factors_rqd6.extend(SHENWAN_INDUSTRY_2021)
-exposure_factors_rqd6.extend(CITICS_INDUSTRY_2019)
-
-_STYLE_FACTORS = {
-    "residual_volatility",
-    "growth",
-    "liquidity",
-    "beta",
-    "non_linear_size",
-    "leverage",
-    "earnings_yield",
-    "size",
-    "momentum",
-    "book_to_price"
-}
-
-_STYLE_FACTORS_RQD6 = {
-    "liquidity",
-    "leverage",
-    "earnings_variability",
-    "earnings_quality",
-    "profitability",
-    "investment_quality",
-    "book_to_price",
-    "earnings_yield",
-    "longterm_reversal",
-    "growth",
-    "momentum",
-    "mid_cap",
-    "size",
-    "beta",
-    "residual_volatility",
-    "dividend_yield",
-}
-
-_STYLE_FACTORS_RQD6TRD = _STYLE_FACTORS_RQD6.update({"sentiment"})
-
-_IMPLICIT_RETURN_FACTORS = exposure_factors
-_EXPLICIT_RETURN_FACTORS = _STYLE_FACTORS
-
-
-@export_as_api
-def get_style_factor_exposure(order_book_ids, start_date, end_date, factors=None, model="v1",
-                              industry_mapping="sws_2021", market="cn"):
-    """获取个股风格因子暴露度
-
-    :param order_book_ids: 证券代码（例如：‘600705.XSHG’）
-    :param start_date: 开始日期（例如：‘2017-03-03’）
-    :param end_date: 结束日期（例如：‘2017-03-20’）
-    :param factors: 风格因子。默认调用全部因子的暴露度（'all'）。
-        具体因子名称见说明文档 (Default value = None)
-    :param market:  (Default value = "cn")
-    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
-
-    """
-    industry_mapping = _convert_industry_mapping(industry_mapping)
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    check_items_in_container(model, ["v1", "v2", "v2trd"], "model")
-    if factors is not None:
-        factors = ensure_list_of_string(factors)
-        if model == "v1":
-            check_items_in_container(factors, _STYLE_FACTORS, "factors")
-        elif model == "v2":
-            check_items_in_container(factors, _STYLE_FACTORS_RQD6, "factors")
-        elif model == "v2trd":
-            check_items_in_container(factors, _STYLE_FACTORS_RQD6TRD, "factors")
-
-    model_to_api = {
-        "v1": "get_style_factor_exposure",
-        "v2": "get_style_factor_exposure_rqd6",
-        "v2trd": "get_style_factor_exposure_rqd6trd"
-    }
-    df = get_client().execute(
-        model_to_api[model], order_book_ids, start_date, end_date, factors,
-        industry_mapping=industry_mapping, market=market
-    )
-    if not df:
-        return
-    return pd.DataFrame(df).set_index(["order_book_id", "date"]).sort_index(level=1)
-
-
-_DESCRIPTORS = {
-    "daily_standard_deviation",
-    "cumulative_range",
-    "historical_sigma",
-    "one_month_share_turnover",
-    "three_months_share_turnover",
-    "twelve_months_share_turnover",
-    "earnings_to_price_ratio",
-    "cash_earnings_to_price_ratio",
-    "market_leverage",
-    "debt_to_assets",
-    "book_leverage",
-    "sales_growth",
-    "earnings_growth",
-    "predicted_earning_to_price",
-    "short_term_predicted_earnings_growth",
-    "long_term_predicted_earnings_growth"
-}
-
-_DESCRIPTORS_RQD6 = {
-    "one_month_share_turnover",
-    "three_months_share_turnover",
-    "twelve_months_share_turnover",
-    "annualized_trade_value_ratio",
-    "market_leverage",
-    "debt_to_assets",
-    "book_leverage",
-    "variation_in_sales",
-    "variation_in_earnings",
-    "variation_in_cashflows",
-    "variation_in_fw_eps",
-    "accruals_balancesheet_version",
-    "accruals_cashflow_version",
-    "asset_turnover",
-    "gross_profitability",
-    "gross_margin",
-    "returns_on_asset",
-    "asset_growth",
-    "capital_expenditure_growth",
-    "issuance_growth",
-    "predicted_earning_to_price",
-    "earnings_to_price_ratio",
-    "cash_earnings_to_price_ratio",
-    "enterprice_multiple",
-    "sales_growth",
-    "earnings_growth",
-    "predicted_growth_3_year",
-    "relative_strength",
-    "historical_alpha",
-    "daily_standard_deviation",
-    "cumulative_range",
-    "historical_sigma",
-    "dividend_to_price",
-    "longterm_relative_strength",
-    "longterm_historical_alpha"
-}
-
-_DESCRIPTORS_RQD6TRD = _DESCRIPTORS_RQD6.update({"earn", "epibs", "rribs"})
-
-
-@export_as_api
-def get_descriptor_exposure(order_book_ids, start_date, end_date, descriptors=None, model="v1",
-                            industry_mapping="sws_2021", market="cn"):
-    """获取个股细分因子暴露度
-
-    :param order_book_ids: 证券代码（例如：‘600705.XSHG’）
-    :param start_date: 开始日期（例如：‘2017-03-03’）
-    :param end_date: 结束日期（例如：‘2017-03-20’）
-    :param descriptors: 细分风格因子。默认调用全部因子的暴露度（'all'）。
-        具体细分因子名称见说明文档 (Default value = None)
-    :param market:  (Default value = "cn")
-    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
-    :returns: MultiIndex DataFrame. index 第一个 level 为 order_book_id，第 二个 level 为 date，column 为细分风格因子字段名称。
-    """
-    industry_mapping = _convert_industry_mapping(industry_mapping)
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    check_items_in_container(model, ["v1", "v2", "v2trd"], "model")
-    if descriptors is not None:
-        if descriptors == "all":
-            descriptors = None
-        else:
-            descriptors = ensure_list_of_string(descriptors)
-            if model == "v1":
-                check_items_in_container(descriptors, _DESCRIPTORS, "descriptors")
-            elif model == "v2":
-                check_items_in_container(descriptors, _DESCRIPTORS_RQD6, "descriptors")
-            elif model == "v2trd":
-                check_items_in_container(descriptors, _DESCRIPTORS_RQD6TRD, "descriptors")
-
-    model_to_api = {
-        "v1": "get_descriptor_exposure",
-        "v2": "get_descriptor_exposure_rqd6",
-        "v2trd": "get_descriptor_exposure_rqd6trd",
-    }
-    df = get_client().execute(
-        model_to_api[model], order_book_ids, start_date, end_date, descriptors,
-        industry_mapping=industry_mapping, market=market
-    )
-    if not df:
-        return
-    return pd.DataFrame(df).set_index(["order_book_id", "date"]).sort_index(level=1)
-
-
-@export_as_api
-def get_stock_beta(order_book_ids, start_date, end_date, benchmark="000300.XSHG", model="v1",
-                   industry_mapping="sws_2021", market="cn"):
-    """获取个股相对于基准的贝塔
-
-    :param order_book_ids: 证券代码（例如：‘600705.XSHG’）
-    :param start_date: 开始日期（例如：‘2017-03-03’)
-    :param end_date: 结束日期（例如：‘2017-03-20’）
-    :param benchmark: 基准指数。默认为沪深300（‘000300.XSHG’）
-        可选上证50（'000016.XSHG'）、中证500（'000905.XSHG'）、
-        中证800（'000906.XSHG'）以及中证全指（'000985.XSHG'） (Default value = "000300.XSHG")
-    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
-    :param market:  (Default value = "cn")
-    :returns: pandas.DataFrame，index 为日期，column 为个股的 order_book_id
-    """
-    industry_mapping = _convert_industry_mapping(industry_mapping)
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-
-    all_benchmark = (
-        "000300.XSHG", "000016.XSHG", "000905.XSHG", "000906.XSHG", "000985.XSHG", "000852.XSHG"
-    )
-    benchmark = ensure_string(benchmark, "benchmark")
-    check_items_in_container(benchmark, all_benchmark, "benchmark")
-    benchmark = benchmark.replace(".", "_")
-    model_to_api = {
-        "v1": "get_stock_beta",
-        "v2": "get_stock_beta_rqd6",
-        "v2trd": "get_stock_beta_rqd6trd",
-    }
-    df = get_client().execute(
-        model_to_api[model], order_book_ids, start_date, end_date, benchmark,
-        industry_mapping=industry_mapping, market=market
-    )
-    if not df:
-        return
-    df = pd.DataFrame(df)
-    df = df.pivot(index="date", columns="order_book_id", values=benchmark).sort_index()
-    return df
-
-
-def get_eigenfactor_adjusted_covariance(date, horizon='daily', model="v1", industry_mapping="sws_2021"):
-    """ 获取因子协方差矩阵（特征因子调整）
-
-    :param date: str 日期（例如：‘2017-03-20’）
-    :param horizon: str 预测期限。默认为日度（'daily'），可选月度（‘monthly’）或季度（'quarterly'）。
-    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
-    :param industry_mapping str                     所选用的行业映射, 可选值包括 sws_2021
-
-    :return: pandas.DataFrame，其中 index 和 column 均为因子名称。
-    """
-    industry_mapping = _convert_industry_mapping(industry_mapping)
-    date = get_previous_trading_date(get_next_trading_date(date))
-    date = ensure_date_int(date)
-    ensure_string_in(horizon, HORIZON_CONTAINER, 'horizon')
-    check_items_in_container(model, ["v1", "v2", "v2trd"], "model")
-
-    model_to_api = {
-        "v1": 'get_eigenfactor_adjusted_covariance',
-        "v2": 'get_eigenfactor_adjusted_covariance_rqd6',
-        "v2trd": 'get_eigenfactor_adjusted_covariance_rqd6trd',
-    }
-    df = get_client().execute(model_to_api[model], date, horizon, industry_mapping)
-    if not df:
-        return
-    df = pd.DataFrame(df)
-    df.drop("date", axis=1, inplace=True)
-    return df.reindex(columns=df.index)
-
-
-@export_as_api
-def get_factor_covariance(date, horizon='daily', model="v1", industry_mapping="sws_2021"):
-    """ 获取因子协方差矩阵
-
-    :param date: str 日期（例如：‘2017-03-20’）
-    :param horizon: str 预测期限。默认为日度（'daily'），可选月度（‘monthly’）或季度（'quarterly'）。
-    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
-    :param industry_mapping str                     所选用的行业映射, 可选值包括 sws_2021
-
-    :return: pandas.DataFrame，其中 index 和 column 均为因子名称。
-    """
-    industry_mapping = _convert_industry_mapping(industry_mapping)
-    date = get_previous_trading_date(get_next_trading_date(date))
-    date = ensure_date_int(date)
-    ensure_string_in(horizon, HORIZON_CONTAINER, 'horizon')
-    check_items_in_container(model, ["v1", "v2", "v2trd"], "model")
-
-    model_to_api = {
-        "v1": "get_factor_covariance",
-        "v2": "get_factor_covariance_rqd6",
-        "v2trd": "get_factor_covariance_rqd6trd",
-    }
-    df = get_client().execute(model_to_api[model], date, horizon, industry_mapping)
-    if not df:
-        return
-    df = pd.DataFrame(df)
-    df.drop("date", axis=1, inplace=True)
-    return df.reindex(columns=df.index)
-
-
-@export_as_api
-def get_specific_return(order_book_ids, start_date, end_date, model="v1", industry_mapping="sws_2021"):
-    """ 获取个股特异收益率
-
-    :param order_book_ids	str or [list of str]	证券代码（例如：‘600705.XSHG’）
-    :param start_date	    str                 	开始日期（例如：‘2017-03-03’）
-    :param end_date	        str	                    结束日期（例如：‘2017-03-20’）
-    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
-    :param industry_mapping str                     所选用的行业映射, 可选值包括 sws_2021
-
-    :return: pandas.DataFrame，其中 index 为date, column 为 order_book_ids。
-    """
-    industry_mapping = _convert_industry_mapping(industry_mapping)
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    check_items_in_container(model, ["v1", "v2", "v2trd"], "model")
-
-    model_to_api = {
-        "v1": "get_specific_return",
-        "v2": "get_specific_return_rqd6",
-        "v2trd": "get_specific_return_rqd6trd",
-    }
-    df = get_client().execute(model_to_api[model], order_book_ids, start_date, end_date, industry_mapping)
-    if not df:
-        return
-    df = pd.DataFrame(df)
-    df = df.pivot(index='date', columns='order_book_id', values="specific_return").sort_index()
-    return df
-
-
-@export_as_api
-def get_specific_risk(order_book_ids, start_date, end_date, horizon='daily', model="v1", industry_mapping="sws_2021"):
-    """ 获取个股特异波动率(标准差)
-
-    :param order_book_ids	str or [list of str]	证券代码（例如：‘600705.XSHG’）
-    :param start_date	    str                 	开始日期（例如：‘2017-03-03’）
-    :param end_date	        str	                    结束日期（例如：‘2017-03-20’）
-    :param horizon	        str	    预测期限。默认为日度（'daily'），可选月度（‘monthly’）或季度（'quarterly'）
-    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
-    :param industry_mapping str                     所选用的行业映射, 可选值包括 sws_2021
-
-    :return: pandas.DataFrame，其中 index 为date, column 为 order_book_ids。
-    """
-    industry_mapping = _convert_industry_mapping(industry_mapping)
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    ensure_string_in(horizon, HORIZON_CONTAINER, 'horizon')
-    check_items_in_container(model, ["v1", "v2", "v2trd"], "model")
-
-    model_to_api = {
-        "v1": "get_specific_risk",
-        "v2": "get_specific_risk_rqd6",
-        "v2trd": "get_specific_risk_rqd6trd",
-    }
-    df = get_client().execute(model_to_api[model], order_book_ids, start_date, end_date, horizon, industry_mapping)
-    if not df:
-        return
-    df = pd.DataFrame(df)
-    df = df.pivot(index="date", columns="order_book_id", values="specific_risk").sort_index()
-    return df
-
-
-def get_cross_sectional_bias(start_date, end_date, type='factor', model="v1", industry_mapping="sws_2021"):
-    """ 获取横截面偏差系数
-
-    :param start_date	    str                 	开始日期（例如：‘2017-03-03’）
-    :param end_date	        str	                    结束日期（例如：‘2017-03-20’）
-    :param type	            str	                    默认为 'factor'，可选 'specific'
-    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
-    :param industry_mapping str                     所选用的行业映射, 可选值包括 sws_2021
-
-    :return: pandas.DataFrame，其中 index 为date, column 包含 'daily'、'monthly'  和 'quarterly' 三个字段。
-    """
-    industry_mapping = _convert_industry_mapping(industry_mapping)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    ensure_string_in(type, ['factor', 'specific'], 'horizon')
-    check_items_in_container(model, ["v1", "v2", "v2trd"], "model")
-
-    model_to_api = {
-        "v1": "get_cross_sectional_bias",
-        "v2": "get_cross_sectional_bias_rqd6",
-        "v2trd": "get_cross_sectional_bias_rqd6trd",
-    }
-    df = get_client().execute(model_to_api[model], start_date, end_date, type, industry_mapping)
-    if not df:
-        return
-    df = pd.DataFrame(df)
-    df = df.pivot(index='date', columns='horizon', values="bias").sort_index()
-    return df
-
-
-HORIZON_CONTAINER = ['daily', 'monthly', 'quarterly']
-
-
-@export_as_api
-def get_index_factor_exposure(
-    order_book_ids, start_date=None, end_date=None, factors=None, market="cn"
-):
-    """获取因子暴露度
-
-    :param order_book_ids: 股票代码或代码列表
-    :param start_date: 如'2013-01-04' (Default value = None)
-    :param end_date: 如'2014-01-04' (Default value = None)
-    :param factors: 如'yield', 'beta', 'volatility' (Default value = None)
-    :param market: 地区代码, 如'cn' (Default value = "cn")
-    """
-    try:
-        order_book_ids = ensure_order_book_ids(order_book_ids, type="INDX")
-    except ValueError:
-        return
-
-    start_date, end_date = ensure_date_range(start_date, end_date)
-
-    if factors is not None:
-        factors = ensure_list_of_string(factors)
-        check_items_in_container(factors, exposure_factors, "factors")
-
-    results = get_client().execute(
-        "get_index_factor_exposure", order_book_ids, start_date, end_date, factors, market=market
-    )
-
-    if not results:
-        return None
-    df = pd.DataFrame.from_records(results, index=['date', 'order_book_id'])
-    df.sort_index(inplace=True)
-    return df
-
-
-# 将行业信息定义成与 rqdatad 统一的形式.
-def _convert_industry_mapping(industry_mapping):
-    """ 处理用户输入的 industry_mapping 信息 """
-    # True 与 False是为了跟旧版本兼容
-    input_mapping = {
-        True: "sw2021",
-        False: "sw2014",
-        "sws_2021": "sw2021",
-        "sws_2014": "sw2014",
-        "citics_2019": "citics2019"
-    }
-    return input_mapping.get(industry_mapping, industry_mapping)
+# -*- coding: utf-8 -*-
+import datetime
+import warnings
+from collections import OrderedDict
+
+import pandas as pd
+import numpy as np
+
+from rqdatac.services.calendar import (
+    get_previous_trading_date,
+    get_next_trading_date,
+    get_trading_dates,
+)
+from rqdatac.validators import (
+    ensure_list_of_string,
+    ensure_date_int,
+    ensure_date_range,
+    ensure_string,
+    ensure_string_in,
+    check_items_in_container,
+    ensure_order_book_ids,
+    ensure_order_book_id,
+)
+from rqdatac.client import get_client
+from rqdatac.decorators import export_as_api
+from rqdatac.rqdatah_helper import rqdatah_serialize, http_conv_list_to_csv
+
+
+VALID_FACTOR_TYPES = [
+    'income_statement',
+    'balance_sheet',
+    'cash_flow_statement',
+    'eod_indicator',
+    'operational_indicator',
+    'cash_flow_indicator',
+    'financial_indicator',
+    'growth_indicator',
+    'alpha101',
+    'moving_average_indicator',
+    'obos_indicator',
+    'energy_indicator',
+    'other',
+]
+
+
+@export_as_api
+@rqdatah_serialize(converter=http_conv_list_to_csv, name='factor')
+def get_all_factor_names(type=None, market="cn"):
+    """获取因子列表
+
+    :param type: str,因子类型 default None (即 eod_indicator)
+        ’income_statement‘：利润表 (以及其 mrq, ttm, lyr)
+        ’balance_sheet‘：资产负债表 (以及其 mrq, ttm, lyr)
+        ’cash_flow_statement‘：现金流量表 (以及其 mrq, ttm, lyr)
+        ‘eod_indicator’：估值有关指标
+        ‘operational_indicator‘：经营衍生指标表
+        ‘cash_flow_indicator’：现金流衍生指标
+        ‘financial_indicator‘：财务衍生指标
+        ‘growth_indicator’：增长衍生指标
+        ’alpha101‘：alpha101 因子
+        'moving_average_indicator'：均线类指标
+        'obos_indicator'：超买超卖指标
+        'energy_indicator'：能量指标
+        'other': 其他因子
+    :return:
+        list
+
+    :param market:  (Default value = "cn")
+
+    """
+    if type is not None and (not isinstance(type, str) or type not in VALID_FACTOR_TYPES):
+        raise ValueError('invalid type: {}'.format(type))
+    return get_client().execute("get_all_factor_names", type=type, market=market)
+
+
+@export_as_api
+def get_factor(order_book_ids, factor, start_date=None, end_date=None, universe=None, expect_df=True, **kwargs):
+    """获取因子
+
+    :param order_book_ids: 股票代码或代码列表
+    :param factor: 如 'total_income'
+    :param date: 如 date='2015-01-05', 默认为前一交易日
+    :param start_date: 开始日期'2015-01-05', 默认为前一交易日, 最小起始日期为'2000-01-04'
+    :param end_date: 结束日期
+    :param universe: 股票池，默认为全A股
+    :param expect_df: 返回 MultiIndex DataFrame (Default value = True)
+    :returns: pd.DataFrame
+    """
+
+    order_book_ids = ensure_order_book_ids(order_book_ids, type="CS")
+    order_book_ids = list(set(order_book_ids))
+
+    factor = ensure_list_of_string(factor)
+    factor = list(OrderedDict.fromkeys(factor))
+
+    if start_date and end_date:
+        start_date, end_date = ensure_date_range(start_date, end_date, datetime.timedelta(days=15))
+        if start_date < 20000104:
+            warnings.warn("start_date is earlier than 2000-01-04, adjusted to 2000-01-04")
+            start_date = 20000104
+    elif start_date:
+        raise ValueError("Expect end_date")
+    elif end_date:
+        raise ValueError("Expect start_date")
+    else:
+        date = kwargs.pop("date", None)
+        date = ensure_date_int(date or get_previous_trading_date(datetime.date.today()))
+        start_date = end_date = date
+
+    if kwargs:
+        raise ValueError('unknown kwargs: {}'.format(kwargs))
+
+    if universe is not None:
+        universe = ensure_string(universe, "universe")
+        if universe != "all":
+            universe = ensure_order_book_id(universe, type="INDX")
+            comp_data = get_client().execute('index_components_v2', universe, start_date, end_date, market='cn')
+            allowed_order_book_ids = set()
+            for comp in comp_data:
+                allowed_order_book_ids.update(comp['component_ids'])
+            not_permit_order_book_ids = set(order_book_ids) - allowed_order_book_ids
+            if not_permit_order_book_ids:
+                warnings.warn(
+                    "%s not in universe pool from %s to %s, value of those order_book_ids may be NaN"
+                    % (not_permit_order_book_ids, start_date, end_date)
+                )
+
+    data = get_client().execute(
+        "get_factor_from_store", order_book_ids, factor, start_date, end_date, universe=universe
+    )
+
+    if not data:
+        return
+
+    factor_value_length = len(data[0][2])
+    if factor_value_length == 0:
+        return
+
+    dates = pd.to_datetime(get_trading_dates(start_date, end_date))
+    days = len(dates)
+    if days > factor_value_length:
+        _get_factor_warning_msg(dates[factor_value_length], dates[-1])
+        dates = dates[0:factor_value_length]
+
+    if expect_df or len(factor) > 1:
+        order_book_id_index_map = {o: i for i, o in enumerate(order_book_ids)}
+        factor_index_map = {f: i for i, f in enumerate(factor)}
+        arr = np.full((len(order_book_ids) * days, len(factor)), np.nan)
+
+        for order_book_id, factor_name, values in data:
+            if not values:
+                continue
+            value_length = min(days, len(values))
+            order_book_id_index = order_book_id_index_map[order_book_id]
+            factor_index = factor_index_map[factor_name]
+            start = order_book_id_index * days
+            arr[start: start + value_length, factor_index] = values[-value_length:]
+
+        multi_index = pd.MultiIndex.from_product([order_book_ids, dates], names=["order_book_id", "date"])
+        df = pd.DataFrame(index=multi_index, columns=factor, data=arr)
+        return df
+
+    order_book_id_index_map = {o: i for i, o in enumerate(order_book_ids)}
+    arr = np.full((days, len(order_book_ids)), np.nan)
+    for order_book_id, _, values in data:
+        arr[:len(values), order_book_id_index_map[order_book_id]] = values
+    df = pd.DataFrame(index=dates, columns=order_book_ids, data=arr)
+
+    if len(df.index) == 1:
+        return df.iloc[0]
+    if len(df.columns) == 1:
+        return df[df.columns[0]]
+    return df
+
+
+def _get_factor_warning_msg(start_date, end_date):
+    if start_date == end_date:
+        end_date = end_date.strftime("%Y%m%d")
+        warnings.warn("{} calculation not completed".format(end_date))
+    else:
+        start_date = start_date.strftime("%Y%m%d")
+        end_date = end_date.strftime("%Y%m%d")
+        warnings.warn(
+            "{} - {} calculation not completed".format(start_date, end_date))
+
+
+_UNIVERSE_MAPPING = {
+    "whole_market": "whole_market",
+    "000300.XSHG": "csi_300",
+    "000905.XSHG": "csi_500",
+    "000906.XSHG": "csi_800",
+}
+
+_METHOD_MAPPING = {"explicit": "explicit_factor_return", "implicit": "implicit_factor_return"}
+
+
+@export_as_api
+def get_factor_return(
+    start_date, end_date, factors=None, universe="whole_market", method="implicit", industry_mapping="sws_2021", model="v1", market="cn"
+):
+    """获取因子收益率数据
+
+    :param start_date: 开始日期（例如：‘2017-03-03’)
+    :param end_date: 结束日期（例如：‘2017-03-20’)
+    :param factors: 因子。默认获取全部因子的因子收益率
+        当 method 参数取值为'implicit' ，可返回全部因子（风格、行业、市场联动）的隐式因子收益率；
+        当 method 参数取值为'explicit' , 只返回风格因子的显式因子收益率。具体因子名称见说明文档 (Default value = None)
+    :param universe: 股票池。默认调用全市场收益率。可选沪深300（‘000300.XSHG’）、中证500（'000905.XSHG'）
+        、以及中证800（'000906.XSHG'） (Default value = "whole_market")
+    :param method: 计算方法。默认为'implicit'（隐式因子收益率），可选'explicit'（显式风格因子收益率) (Default value = "implicit")
+    :param market: 地区代码， 现在仅支持 'cn' (Default value = "cn")
+    :param industry_mapping(str): 使用的行业类别，可选 sws_2021, citics_2019, 默认为 sws_2021
+    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
+    :returns: pd.DataFrame. index 为日期，column 为因子字段名称。
+
+    Usage example::
+        # 获取介于2017-03-03 到 2017-03-20到隐式因子收益率数据
+        get_factor_return('2017-03-03', '2017-03-20')
+
+    """
+    industry_mapping = _convert_industry_mapping(industry_mapping)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+
+    if factors:
+        factors = ensure_list_of_string(factors)
+        if method == "implicit":
+            check_items_in_container(factors, _IMPLICIT_RETURN_FACTORS, "factors")
+        elif method == "explicit":
+            check_items_in_container(factors, _EXPLICIT_RETURN_FACTORS, "factors")
+
+    method = ensure_string(method)
+    if method not in _METHOD_MAPPING:
+        raise ValueError("invalid method: {!r}, valid: explicit, implicit".format(method))
+    method = _METHOD_MAPPING[method]
+
+    if universe not in _UNIVERSE_MAPPING:
+        raise ValueError(
+            "invalid universe: {!r}, valid: {}".format(universe, list(_UNIVERSE_MAPPING.keys()))
+        )
+    universe = _UNIVERSE_MAPPING[universe]
+    check_items_in_container(model, ["v1", "v2", "v2trd"], "model")
+
+    model_to_api = {
+        "v1": "get_factor_return_v3",
+        "v2": "get_factor_return_rqd6_v2",
+        "v2trd": "get_factor_return_rqd6trd",
+    }
+    df = get_client().execute(
+        model_to_api[model], start_date, end_date, factors, universe, method, market=market, industry_mapping=industry_mapping
+    )
+    if not df:
+        return None
+    df = pd.DataFrame(df)
+    # convert to required format.
+    df = df.pivot(index="date", columns="factor")[universe]
+    df.sort_index(inplace=True)
+    return df
+
+
+def _get_all_industries(industry_name):
+    if industry_name == "sw2021":
+        return SHENWAN_INDUSTRY_2021
+    elif industry_name == "citics2019":
+        return CITICS_INDUSTRY_2019
+    else:
+        return SHENWAN_INDUSTRY_2014
+
+
+@export_as_api
+def get_factor_exposure(order_book_ids, start_date=None, end_date=None, factors=None, industry_mapping='sws_2021', model="v1", market="cn"):
+    """获取因子暴露度
+
+    :param order_book_ids: 股票代码或代码列表
+    :param start_date: 如'2013-01-04' (Default value = None)
+    :param end_date: 如'2014-01-04' (Default value = None)
+    :param factors: 如'yield', 'beta', 'volatility' (Default value = None)
+    :param market: 地区代码, 如'cn' (Default value = "cn")
+    :param industry_mapping: 是否按 2014 年后的申万行业分类标 准计算行业暴露度.默认为 True.
+        若取值为 False,则 2014 年前的行业 暴露度按旧行业分类标准计算
+    :param industry_mapping (str): 行业分类标准, 可选值包括 'sws_2021'(申万2021行业分类), 'sws_2014'(申万2014行业分类)
+        默认取 'sws_2021' 行业分类
+    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
+    :returns: MultiIndex DataFrame. index 第一个 level 为 order_book_id，第 二个 level 为 date，columns 为因子字段名称
+    """
+    industry_mapping = _convert_industry_mapping(industry_mapping)
+
+    check_items_in_container(industry_mapping, ["sw2014", "sw2021", "citics2019"], "industry_mapping")
+    check_items_in_container(model, ["v1", "v2", "v2trd"], "model")
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    if not order_book_ids:
+        raise ValueError("no valid order_book_id found")
+
+    start_date, end_date = ensure_date_range(start_date, end_date)
+
+    if factors is not None:
+        factors = ensure_list_of_string(factors)
+        if model == "v1":
+            check_items_in_container(factors, exposure_factors, "factors")
+        elif model == "v2":
+            check_items_in_container(factors, exposure_factors_rqd6, "factors")
+
+    model_to_api = {
+        "v1": "get_factor_exposure_v2",
+        "v2": "get_factor_exposure_rqd6",
+        "v2trd": "get_factor_exposure_rqd6trd",
+    }
+    results = get_client().execute(
+        model_to_api[model], order_book_ids, start_date, end_date, factors, industry_mapping, market
+    )
+
+    if not results:
+        return None
+    index_pairs = []
+    data = []
+
+    fields = [
+        field for field in results[0].keys() if field not in ("order_book_id", "date", "industry")
+    ]
+    industry_factors = _get_all_industries(industry_mapping)
+    for result in results:
+        index_pairs.append((result["date"], result["order_book_id"]))
+        row_data = [result.get(field, np.nan) for field in fields]
+
+        # 填充行业因子数据
+        for industry in industry_factors:
+            if result["industry"] == industry:
+                industry_label = 1
+            else:
+                industry_label = 0
+            row_data.append(industry_label)
+
+        data.append(row_data)
+
+    index = pd.MultiIndex.from_tuples(index_pairs, names=["date", "order_book_id"])
+    fields.extend(industry_factors)
+    result_df = pd.DataFrame(columns=fields, index=index, data=data)
+    result_df.sort_index(inplace=True)
+
+    no_data_book_id = set(order_book_ids) - set(result_df.index.levels[1])
+    if no_data_book_id:
+        warnings.warn("No data for this order_book_id :{}".format(no_data_book_id))
+
+    if factors is not None:
+        return result_df[factors]
+    return result_df
+
+
+exposure_factors = [
+    "residual_volatility",
+    "growth",
+    "liquidity",
+    "beta",
+    "non_linear_size",
+    "leverage",
+    "earnings_yield",
+    "size",
+    "momentum",
+    "book_to_price",
+    "comovement",
+]
+
+exposure_factors_rqd6 = [
+    "liquidity",
+    "leverage",
+    "earnings_variability",
+    "earnings_quality",
+    "profitability",
+    "investment_quality",
+    "book_to_price",
+    "earnings_yield",
+    "longterm_reversal",
+    "growth",
+    "momentum",
+    "mid_cap",
+    "size",
+    "beta",
+    "residual_volatility",
+    "dividend_yield",
+    "comovement"
+]
+
+# 申万2021行业分类
+SHENWAN_INDUSTRY_2021 = [
+    u"银行",
+    u"计算机",
+    u"环保",
+    u"商贸零售",
+    u"电力设备",
+    u"建筑装饰",
+    u"建筑材料",
+    u"农林牧渔",
+    u"电子",
+    u"交通运输",
+    u"汽车",
+    u"纺织服饰",
+    u"医药生物",
+    u"房地产",
+    u"通信",
+    u"公用事业",
+    u"综合",
+    u"机械设备",
+    u"石油石化",
+    u"有色金属",
+    u"传媒",
+    u"家用电器",
+    u"基础化工",
+    u"非银金融",
+    u"社会服务",
+    u"轻工制造",
+    u"国防军工",
+    u"美容护理",
+    u"煤炭",
+    u"食品饮料",
+    u"钢铁"
+]
+
+# 申万2014 行业分类
+SHENWAN_INDUSTRY_2014 = [
+    u"农林牧渔",
+    u"采掘",
+    u"化工",
+    u"钢铁",
+    u"有色金属",
+    u"电子",
+    u"家用电器",
+    u"食品饮料",
+    u"纺织服装",
+    u"轻工制造",
+    u"医药生物",
+    u"公用事业",
+    u"交通运输",
+    u"房地产",
+    u"商业贸易",
+    u"休闲服务",
+    u"综合",
+    u"建筑材料",
+    u"建筑装饰",
+    u"电气设备",
+    u"国防军工",
+    u"计算机",
+    u"传媒",
+    u"通信",
+    u"银行",
+    u"非银金融",
+    u"汽车",
+    u"机械设备",
+]
+
+# 中信2019 行业分类
+CITICS_INDUSTRY_2019 = [
+    u"交通运输",
+    u"传媒",
+    u"农林牧渔",
+    u"医药",
+    u"商贸零售",
+    u"国防军工",
+    u"基础化工",
+    u"家电",
+    u"建材",
+    u"建筑",
+    u"房地产",
+    u"有色金属",
+    u"机械",
+    u"汽车",
+    u"消费者服务",
+    u"煤炭",
+    u"电力及公用事业",
+    u"电力设备及新能源",
+    u"电子",
+    u"石油石化",
+    u"纺织服装",
+    u"综合",
+    u"综合金融",
+    u"计算机",
+    u"轻工制造",
+    u"通信",
+    u"钢铁",
+    u"银行",
+    u"非银行金融",
+    u"食品饮料"
+]
+
+exposure_factors.extend(SHENWAN_INDUSTRY_2021)
+exposure_factors.extend(SHENWAN_INDUSTRY_2014)
+exposure_factors.extend(CITICS_INDUSTRY_2019)
+
+exposure_factors_rqd6.extend(SHENWAN_INDUSTRY_2021)
+exposure_factors_rqd6.extend(CITICS_INDUSTRY_2019)
+
+_STYLE_FACTORS = {
+    "residual_volatility",
+    "growth",
+    "liquidity",
+    "beta",
+    "non_linear_size",
+    "leverage",
+    "earnings_yield",
+    "size",
+    "momentum",
+    "book_to_price"
+}
+
+_STYLE_FACTORS_RQD6 = {
+    "liquidity",
+    "leverage",
+    "earnings_variability",
+    "earnings_quality",
+    "profitability",
+    "investment_quality",
+    "book_to_price",
+    "earnings_yield",
+    "longterm_reversal",
+    "growth",
+    "momentum",
+    "mid_cap",
+    "size",
+    "beta",
+    "residual_volatility",
+    "dividend_yield",
+}
+
+_STYLE_FACTORS_RQD6TRD = _STYLE_FACTORS_RQD6.update({"sentiment"})
+
+_IMPLICIT_RETURN_FACTORS = exposure_factors
+_EXPLICIT_RETURN_FACTORS = _STYLE_FACTORS
+
+
+@export_as_api
+def get_style_factor_exposure(order_book_ids, start_date, end_date, factors=None, model="v1",
+                              industry_mapping="sws_2021", market="cn"):
+    """获取个股风格因子暴露度
+
+    :param order_book_ids: 证券代码（例如：‘600705.XSHG’）
+    :param start_date: 开始日期（例如：‘2017-03-03’）
+    :param end_date: 结束日期（例如：‘2017-03-20’）
+    :param factors: 风格因子。默认调用全部因子的暴露度（'all'）。
+        具体因子名称见说明文档 (Default value = None)
+    :param market:  (Default value = "cn")
+    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
+
+    """
+    industry_mapping = _convert_industry_mapping(industry_mapping)
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    check_items_in_container(model, ["v1", "v2", "v2trd"], "model")
+    if factors is not None:
+        factors = ensure_list_of_string(factors)
+        if model == "v1":
+            check_items_in_container(factors, _STYLE_FACTORS, "factors")
+        elif model == "v2":
+            check_items_in_container(factors, _STYLE_FACTORS_RQD6, "factors")
+        elif model == "v2trd":
+            check_items_in_container(factors, _STYLE_FACTORS_RQD6TRD, "factors")
+
+    model_to_api = {
+        "v1": "get_style_factor_exposure",
+        "v2": "get_style_factor_exposure_rqd6",
+        "v2trd": "get_style_factor_exposure_rqd6trd"
+    }
+    df = get_client().execute(
+        model_to_api[model], order_book_ids, start_date, end_date, factors,
+        industry_mapping=industry_mapping, market=market
+    )
+    if not df:
+        return
+    return pd.DataFrame(df).set_index(["order_book_id", "date"]).sort_index(level=1)
+
+
+_DESCRIPTORS = {
+    "daily_standard_deviation",
+    "cumulative_range",
+    "historical_sigma",
+    "one_month_share_turnover",
+    "three_months_share_turnover",
+    "twelve_months_share_turnover",
+    "earnings_to_price_ratio",
+    "cash_earnings_to_price_ratio",
+    "market_leverage",
+    "debt_to_assets",
+    "book_leverage",
+    "sales_growth",
+    "earnings_growth",
+    "predicted_earning_to_price",
+    "short_term_predicted_earnings_growth",
+    "long_term_predicted_earnings_growth"
+}
+
+_DESCRIPTORS_RQD6 = {
+    "one_month_share_turnover",
+    "three_months_share_turnover",
+    "twelve_months_share_turnover",
+    "annualized_trade_value_ratio",
+    "market_leverage",
+    "debt_to_assets",
+    "book_leverage",
+    "variation_in_sales",
+    "variation_in_earnings",
+    "variation_in_cashflows",
+    "variation_in_fw_eps",
+    "accruals_balancesheet_version",
+    "accruals_cashflow_version",
+    "asset_turnover",
+    "gross_profitability",
+    "gross_margin",
+    "returns_on_asset",
+    "asset_growth",
+    "capital_expenditure_growth",
+    "issuance_growth",
+    "predicted_earning_to_price",
+    "earnings_to_price_ratio",
+    "cash_earnings_to_price_ratio",
+    "enterprice_multiple",
+    "sales_growth",
+    "earnings_growth",
+    "predicted_growth_3_year",
+    "relative_strength",
+    "historical_alpha",
+    "daily_standard_deviation",
+    "cumulative_range",
+    "historical_sigma",
+    "dividend_to_price",
+    "longterm_relative_strength",
+    "longterm_historical_alpha"
+}
+
+_DESCRIPTORS_RQD6TRD = _DESCRIPTORS_RQD6.update({"earn", "epibs", "rribs"})
+
+
+@export_as_api
+def get_descriptor_exposure(order_book_ids, start_date, end_date, descriptors=None, model="v1",
+                            industry_mapping="sws_2021", market="cn"):
+    """获取个股细分因子暴露度
+
+    :param order_book_ids: 证券代码（例如：‘600705.XSHG’）
+    :param start_date: 开始日期（例如：‘2017-03-03’）
+    :param end_date: 结束日期（例如：‘2017-03-20’）
+    :param descriptors: 细分风格因子。默认调用全部因子的暴露度（'all'）。
+        具体细分因子名称见说明文档 (Default value = None)
+    :param market:  (Default value = "cn")
+    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
+    :returns: MultiIndex DataFrame. index 第一个 level 为 order_book_id，第 二个 level 为 date，column 为细分风格因子字段名称。
+    """
+    industry_mapping = _convert_industry_mapping(industry_mapping)
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    check_items_in_container(model, ["v1", "v2", "v2trd"], "model")
+    if descriptors is not None:
+        if descriptors == "all":
+            descriptors = None
+        else:
+            descriptors = ensure_list_of_string(descriptors)
+            if model == "v1":
+                check_items_in_container(descriptors, _DESCRIPTORS, "descriptors")
+            elif model == "v2":
+                check_items_in_container(descriptors, _DESCRIPTORS_RQD6, "descriptors")
+            elif model == "v2trd":
+                check_items_in_container(descriptors, _DESCRIPTORS_RQD6TRD, "descriptors")
+
+    model_to_api = {
+        "v1": "get_descriptor_exposure",
+        "v2": "get_descriptor_exposure_rqd6",
+        "v2trd": "get_descriptor_exposure_rqd6trd",
+    }
+    df = get_client().execute(
+        model_to_api[model], order_book_ids, start_date, end_date, descriptors,
+        industry_mapping=industry_mapping, market=market
+    )
+    if not df:
+        return
+    return pd.DataFrame(df).set_index(["order_book_id", "date"]).sort_index(level=1)
+
+
+@export_as_api
+def get_stock_beta(order_book_ids, start_date, end_date, benchmark="000300.XSHG", model="v1",
+                   industry_mapping="sws_2021", market="cn"):
+    """获取个股相对于基准的贝塔
+
+    :param order_book_ids: 证券代码（例如：‘600705.XSHG’）
+    :param start_date: 开始日期（例如：‘2017-03-03’)
+    :param end_date: 结束日期（例如：‘2017-03-20’）
+    :param benchmark: 基准指数。默认为沪深300（‘000300.XSHG’）
+        可选上证50（'000016.XSHG'）、中证500（'000905.XSHG'）、
+        中证800（'000906.XSHG'）以及中证全指（'000985.XSHG'） (Default value = "000300.XSHG")
+    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
+    :param market:  (Default value = "cn")
+    :returns: pandas.DataFrame，index 为日期，column 为个股的 order_book_id
+    """
+    industry_mapping = _convert_industry_mapping(industry_mapping)
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+
+    all_benchmark = (
+        "000300.XSHG", "000016.XSHG", "000905.XSHG", "000906.XSHG", "000985.XSHG", "000852.XSHG"
+    )
+    benchmark = ensure_string(benchmark, "benchmark")
+    check_items_in_container(benchmark, all_benchmark, "benchmark")
+    benchmark = benchmark.replace(".", "_")
+    model_to_api = {
+        "v1": "get_stock_beta",
+        "v2": "get_stock_beta_rqd6",
+        "v2trd": "get_stock_beta_rqd6trd",
+    }
+    df = get_client().execute(
+        model_to_api[model], order_book_ids, start_date, end_date, benchmark,
+        industry_mapping=industry_mapping, market=market
+    )
+    if not df:
+        return
+    df = pd.DataFrame(df)
+    df = df.pivot(index="date", columns="order_book_id", values=benchmark).sort_index()
+    return df
+
+
+def get_eigenfactor_adjusted_covariance(date, horizon='daily', model="v1", industry_mapping="sws_2021"):
+    """ 获取因子协方差矩阵（特征因子调整）
+
+    :param date: str 日期（例如：‘2017-03-20’）
+    :param horizon: str 预测期限。默认为日度（'daily'），可选月度（‘monthly’）或季度（'quarterly'）。
+    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
+    :param industry_mapping str                     所选用的行业映射, 可选值包括 sws_2021
+
+    :return: pandas.DataFrame，其中 index 和 column 均为因子名称。
+    """
+    industry_mapping = _convert_industry_mapping(industry_mapping)
+    date = get_previous_trading_date(get_next_trading_date(date))
+    date = ensure_date_int(date)
+    ensure_string_in(horizon, HORIZON_CONTAINER, 'horizon')
+    check_items_in_container(model, ["v1", "v2", "v2trd"], "model")
+
+    model_to_api = {
+        "v1": 'get_eigenfactor_adjusted_covariance',
+        "v2": 'get_eigenfactor_adjusted_covariance_rqd6',
+        "v2trd": 'get_eigenfactor_adjusted_covariance_rqd6trd',
+    }
+    df = get_client().execute(model_to_api[model], date, horizon, industry_mapping)
+    if not df:
+        return
+    df = pd.DataFrame(df)
+    df.drop("date", axis=1, inplace=True)
+    return df.reindex(columns=df.index)
+
+
+@export_as_api
+def get_factor_covariance(date, horizon='daily', model="v1", industry_mapping="sws_2021"):
+    """ 获取因子协方差矩阵
+
+    :param date: str 日期（例如：‘2017-03-20’）
+    :param horizon: str 预测期限。默认为日度（'daily'），可选月度（‘monthly’）或季度（'quarterly'）。
+    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
+    :param industry_mapping str                     所选用的行业映射, 可选值包括 sws_2021
+
+    :return: pandas.DataFrame，其中 index 和 column 均为因子名称。
+    """
+    industry_mapping = _convert_industry_mapping(industry_mapping)
+    date = get_previous_trading_date(get_next_trading_date(date))
+    date = ensure_date_int(date)
+    ensure_string_in(horizon, HORIZON_CONTAINER, 'horizon')
+    check_items_in_container(model, ["v1", "v2", "v2trd"], "model")
+
+    model_to_api = {
+        "v1": "get_factor_covariance",
+        "v2": "get_factor_covariance_rqd6",
+        "v2trd": "get_factor_covariance_rqd6trd",
+    }
+    df = get_client().execute(model_to_api[model], date, horizon, industry_mapping)
+    if not df:
+        return
+    df = pd.DataFrame(df)
+    df.drop("date", axis=1, inplace=True)
+    return df.reindex(columns=df.index)
+
+
+@export_as_api
+def get_specific_return(order_book_ids, start_date, end_date, model="v1", industry_mapping="sws_2021"):
+    """ 获取个股特异收益率
+
+    :param order_book_ids	str or [list of str]	证券代码（例如：‘600705.XSHG’）
+    :param start_date	    str                 	开始日期（例如：‘2017-03-03’）
+    :param end_date	        str	                    结束日期（例如：‘2017-03-20’）
+    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
+    :param industry_mapping str                     所选用的行业映射, 可选值包括 sws_2021
+
+    :return: pandas.DataFrame，其中 index 为date, column 为 order_book_ids。
+    """
+    industry_mapping = _convert_industry_mapping(industry_mapping)
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    check_items_in_container(model, ["v1", "v2", "v2trd"], "model")
+
+    model_to_api = {
+        "v1": "get_specific_return",
+        "v2": "get_specific_return_rqd6",
+        "v2trd": "get_specific_return_rqd6trd",
+    }
+    df = get_client().execute(model_to_api[model], order_book_ids, start_date, end_date, industry_mapping)
+    if not df:
+        return
+    df = pd.DataFrame(df)
+    df = df.pivot(index='date', columns='order_book_id', values="specific_return").sort_index()
+    return df
+
+
+@export_as_api
+def get_specific_risk(order_book_ids, start_date, end_date, horizon='daily', model="v1", industry_mapping="sws_2021"):
+    """ 获取个股特异波动率(标准差)
+
+    :param order_book_ids	str or [list of str]	证券代码（例如：‘600705.XSHG’）
+    :param start_date	    str                 	开始日期（例如：‘2017-03-03’）
+    :param end_date	        str	                    结束日期（例如：‘2017-03-20’）
+    :param horizon	        str	    预测期限。默认为日度（'daily'），可选月度（‘monthly’）或季度（'quarterly'）
+    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
+    :param industry_mapping str                     所选用的行业映射, 可选值包括 sws_2021
+
+    :return: pandas.DataFrame，其中 index 为date, column 为 order_book_ids。
+    """
+    industry_mapping = _convert_industry_mapping(industry_mapping)
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    ensure_string_in(horizon, HORIZON_CONTAINER, 'horizon')
+    check_items_in_container(model, ["v1", "v2", "v2trd"], "model")
+
+    model_to_api = {
+        "v1": "get_specific_risk",
+        "v2": "get_specific_risk_rqd6",
+        "v2trd": "get_specific_risk_rqd6trd",
+    }
+    df = get_client().execute(model_to_api[model], order_book_ids, start_date, end_date, horizon, industry_mapping)
+    if not df:
+        return
+    df = pd.DataFrame(df)
+    df = df.pivot(index="date", columns="order_book_id", values="specific_risk").sort_index()
+    return df
+
+
+def get_cross_sectional_bias(start_date, end_date, type='factor', model="v1", industry_mapping="sws_2021"):
+    """ 获取横截面偏差系数
+
+    :param start_date	    str                 	开始日期（例如：‘2017-03-03’）
+    :param end_date	        str	                    结束日期（例如：‘2017-03-20’）
+    :param type	            str	                    默认为 'factor'，可选 'specific'
+    :param model: 选用的模型, 可选模型包括 v1, v2; 默认为 v1
+    :param industry_mapping str                     所选用的行业映射, 可选值包括 sws_2021
+
+    :return: pandas.DataFrame，其中 index 为date, column 包含 'daily'、'monthly'  和 'quarterly' 三个字段。
+    """
+    industry_mapping = _convert_industry_mapping(industry_mapping)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    ensure_string_in(type, ['factor', 'specific'], 'horizon')
+    check_items_in_container(model, ["v1", "v2", "v2trd"], "model")
+
+    model_to_api = {
+        "v1": "get_cross_sectional_bias",
+        "v2": "get_cross_sectional_bias_rqd6",
+        "v2trd": "get_cross_sectional_bias_rqd6trd",
+    }
+    df = get_client().execute(model_to_api[model], start_date, end_date, type, industry_mapping)
+    if not df:
+        return
+    df = pd.DataFrame(df)
+    df = df.pivot(index='date', columns='horizon', values="bias").sort_index()
+    return df
+
+
+HORIZON_CONTAINER = ['daily', 'monthly', 'quarterly']
+
+
+@export_as_api
+def get_index_factor_exposure(
+    order_book_ids, start_date=None, end_date=None, factors=None, market="cn"
+):
+    """获取因子暴露度
+
+    :param order_book_ids: 股票代码或代码列表
+    :param start_date: 如'2013-01-04' (Default value = None)
+    :param end_date: 如'2014-01-04' (Default value = None)
+    :param factors: 如'yield', 'beta', 'volatility' (Default value = None)
+    :param market: 地区代码, 如'cn' (Default value = "cn")
+    """
+    try:
+        order_book_ids = ensure_order_book_ids(order_book_ids, type="INDX")
+    except ValueError:
+        return
+
+    start_date, end_date = ensure_date_range(start_date, end_date)
+
+    if factors is not None:
+        factors = ensure_list_of_string(factors)
+        check_items_in_container(factors, exposure_factors, "factors")
+
+    results = get_client().execute(
+        "get_index_factor_exposure", order_book_ids, start_date, end_date, factors, market=market
+    )
+
+    if not results:
+        return None
+    df = pd.DataFrame.from_records(results, index=['date', 'order_book_id'])
+    df.sort_index(inplace=True)
+    return df
+
+
+# 将行业信息定义成与 rqdatad 统一的形式.
+def _convert_industry_mapping(industry_mapping):
+    """ 处理用户输入的 industry_mapping 信息 """
+    # True 与 False是为了跟旧版本兼容
+    input_mapping = {
+        True: "sw2021",
+        False: "sw2014",
+        "sws_2021": "sw2021",
+        "sws_2014": "sw2014",
+        "citics_2019": "citics2019"
+    }
+    return input_mapping.get(industry_mapping, industry_mapping)
```

## rqdatac/services/financial.py

 * *Ordering differences only*

```diff
@@ -1,329 +1,329 @@
-# -*- coding: utf-8 -*-
-import datetime
-
-import pandas as pd
-import math
-
-from rqdatac.client import get_client
-
-from rqdatac.services.orm.pit_financials_ex import FIELDS_LIST_EX
-from rqdatac.validators import (
-    ensure_list_of_string,
-    ensure_string,
-    check_items_in_container,
-    ensure_date_int,
-    ensure_order_book_id,
-    check_quarter,
-    ensure_date_or_today_int,
-    quarter_string_to_date,
-    ensure_order_book_ids,
-)
-from rqdatac.decorators import export_as_api
-
-ENTERPRISE_TYPE_MAP = {
-    13: "business_bank",
-    31: "securities_firms",
-    33: "trust",
-    35: "insurance_company",
-    39: "other_financial_institution",
-    99: "general_enterprise",
-}
-
-INFO_TYPE_MAP = {
-    10: "发行上市书",
-    20: "定期报告",
-    30: "业绩快报",
-    50: "章程制度",
-    70: "临时公告",
-    90: "交易所通报",
-    91: "交易所临时停(复)牌公告",
-    99: "其他",
-    110101: "定期报告:年度报告",
-    110102: "定期报告:半年度报告",
-    110103: "定期报告:第一季报",
-    110104: "定期报告:第三季报",
-    110105: "定期报告:审计报告",
-    110106: "定期报告:第二季报",
-    110107: "定期报告:第四季报",
-    110108: "定期报告:第五季报",
-    110109: "定期报告:第二季报（更正后）",
-    110110: "定期报告:第四季报（更正后）",
-    110111: "定期报告:第五季报（更正后）",
-    110201: "定期报告:年度报告(关联方)",
-    110202: "定期报告:半年度报告(关联方)",
-    110203: "定期报告:第一季报(关联方)",
-    110204: "定期报告:第三季报(关联方)",
-    120101: "临时公告:审计报告(更正后)",
-    120102: "临时公告:年度报告(更正后)",
-    120103: "临时公告:半年度报告(更正后)",
-    120104: "临时公告:第一季报(更正后)",
-    120105: "临时公告:第三季报(更正后)",
-    120106: "临时公告:公开转让说明书(更正后)",
-    120107: "临时公告:业绩快报",
-    120108: "临时公告:业绩快报(更正后)",
-    120201: "临时公告:跟踪评级报告",
-    120202: "临时公告:同业存单发行计划",
-    120203: "临时公告:比较式财务报表",
-    120204: "临时公告:关联方",
-    120205: "临时公告:其他",
-    120206: "临时公告:前期差错更正",
-    120207: "临时公告:第一季度报告",
-    120208: "临时公告:第二季度报告",
-    120209: "临时公告:第三季度报告",
-    120210: "临时公告:第四季度报告",
-    120211: "临时公告：年度报告",
-    130101: "发行上市书:募集说明书",
-    130102: "发行上市书:招股说明书(申报稿)",
-    130103: "发行上市书:招股意向书",
-    130104: "发行上市书:上市公告书",
-    130105: "发行上市书:审阅报告",
-    130106: "发行上市书:招股说明书",
-    130107: "发行上市书:公开转让说明书",
-    130108: "发行上市书:发行公告",
-    130109: "发行上市书:审计报告",
-    130110: "发行上市书:关联方",
-    130111: "发行上市书:其他",
-    140101: "发行披露文件:第一季报",
-    140102: "发行披露文件:半年度报告",
-    140103: "发行披露文件：第三季报",
-    140104: "发行披露文件：审计报告",
-    140105: "发行披露文件：募集说明书",
-    140106: "发行披露文件：跟踪评级报告"
-}
-
-
-@export_as_api
-def get_pit_financials_ex(order_book_ids, fields, start_quarter, end_quarter,
-                          date=None, statements='latest', market='cn'):
-    """
-        获取股票财务数据(Point In Time)
-    :param order_book_ids: 股票合约代码列表
-    :param fields: 指定返回财报字段
-    :param start_quarter: 财报季度 - 起始，如 2020q1
-    :param end_quarter: 财报季度 - 截止
-    :param date: 财报发布日期，默认为当前日期, 如 '2020-01-01' | '20200101'
-    :param statements: 可选 latest/all, 默认为 latest
-            latest: 仅返回在date时点所能观察到的最新数据；
-            all：返回在date时点所能观察到的所有版本，从第一次发布直到观察时点的所有修改。
-    :param market: 股票市场范围
-    :return:
-    """
-    fields = ensure_list_of_string(fields, 'fields')
-    check_items_in_container(fields, FIELDS_LIST_EX, "fields")
-    fields.extend(['order_book_id', 'info_date', 'end_date', 'if_adjusted', 'rice_create_tm'])
-    fields = list(set(fields))
-    fields[fields.index("info_date")], fields[0] = fields[0], fields[fields.index("info_date")]
-
-    check_quarter(start_quarter, 'start_quarter')
-    start_quarter_int = ensure_date_int(quarter_string_to_date(start_quarter))
-
-    check_quarter(end_quarter, 'end_quarter')
-    end_quarter_int = ensure_date_int(quarter_string_to_date(end_quarter))
-
-    if start_quarter > end_quarter:
-        raise ValueError(
-            'invalid quarter range: [{!r}, {!r}]'.format(
-                start_quarter, end_quarter))
-
-    date = ensure_date_or_today_int(date)
-
-    order_book_ids = ensure_list_of_string(order_book_ids, 'order_book_ids')
-
-    if statements not in ['all', 'latest']:
-        raise ValueError("invalid statements , got {!r}".format(statements))
-
-    pit_financial_df = pd.DataFrame(
-        get_client().execute("get_pit_financials_ex", order_book_ids, fields, start_quarter_int, end_quarter_int, date,
-                             statements, market))
-    if pit_financial_df.empty:
-        return
-    # convert rice_create_tm to datetime
-    pit_financial_df['rice_create_tm'] = pd.to_datetime(pit_financial_df['rice_create_tm'] + 3600 * 8, unit='s')
-    pit_financial_df = pit_financial_df.reindex(columns=fields)
-    pit_financial_df.sort_values(['order_book_id', 'end_date', 'info_date'])
-    pit_financial_df["end_date"] = pit_financial_df["end_date"].apply(
-        lambda d: "{}q{}".format(d.year, math.ceil(d.month / 3)))
-    pit_financial_df.rename(columns={"end_date": "quarter"}, inplace=True)
-    pit_financial_df.set_index(['order_book_id', 'quarter'], inplace=True)
-    pit_financial_df['if_adjusted'] = pit_financial_df['if_adjusted'].map(lambda x: 1 if x == 1 else 0).astype(int)
-    pit_financial_df.sort_index(inplace=True)
-    return pit_financial_df
-
-
-@export_as_api
-def current_performance(
-        order_book_id, info_date=None, quarter=None, interval="1q", fields=None, market="cn"
-):
-    """获取A股快报
-
-    :param order_book_id: 股票代码, 如'000001.XSHE'
-    :param info_date: 发布日期, 如'20180501', 默认为最近的交易日 (Default value = None)
-    :param quarter: 发布季度, 如'2018q1' (Default value = None)
-    :param interval: 数据区间， 发布日期, 如'2y', '4q' (Default value = "1q")
-    :param fields: str 或 list 类型. 默认为 None, 返回所有字段 (Default value = None)
-    :param market: 地区代码, 如'cn' (Default value = "cn")
-    :returns: pd.DataFrame
-
-    """
-    order_book_id = ensure_order_book_id(order_book_id, market=market)
-    end_date = None
-    if info_date:
-        info_date = ensure_date_int(info_date)
-    elif quarter:
-        splited = quarter.lower().split("q")
-        if len(quarter) != 6 or len(splited) != 2:
-            raise ValueError(
-                "invalid argument {}: {}, valid parameter: {}".format(
-                    "quarter", quarter, "string format like '2016q1'"
-                )
-            )
-
-        year, quarter = int(splited[0]), int(splited[1])
-        if not 1 <= quarter <= 4:
-            raise ValueError(
-                "invalid argument {}: {}, valid parameter: {}".format(
-                    "quarter", quarter, "quarter should be in [1, 4]"
-                )
-            )
-        month, day = QUARTER_DATE_MAP[quarter]
-        end_date = ensure_date_int(datetime.datetime(year, month, day))
-    else:
-        info_date = ensure_date_int(datetime.date.today())
-    ensure_string(interval, "interval")
-    if interval[-1] not in ("y", "q", "Y", "Q"):
-        raise ValueError(
-            "invalid argument {}: {}, valid parameter: {}".format(
-                "interval", interval, "interval unit should be q(quarter) or y(year)"
-            )
-        )
-
-    try:
-        int(interval[:-1])
-    except ValueError:
-        raise ValueError(
-            "invalid argument {}: {}, valid parameter: {}".format(
-                "interval", interval, "string like 4q, 2y"
-            )
-        )
-    interval = interval.lower()
-
-    if fields is not None:
-        fields = ensure_list_of_string(fields, "fields")
-        check_items_in_container(fields, PERFORMANCE_FIELDS, "fields")
-    else:
-        fields = PERFORMANCE_FIELDS
-
-    data = get_client().execute(
-        "current_performance", order_book_id, info_date, end_date, fields, market=market
-    )
-    if not data:
-        return
-    df = pd.DataFrame(data)
-    df.sort_values(by=["end_date", "info_date", "mark"], ascending=[False, False, True], inplace=True)
-    df.drop_duplicates(subset="end_date", keep="first", inplace=True)
-    num = int(interval[:-1])
-    unit = interval[-1]
-    if unit == "y":
-        latest_month = df.iloc[0]["end_date"].month
-        df["month"] = df.end_date.apply(lambda x: x.month)
-        df = df[df.month == latest_month]
-    df.reset_index(drop=True, inplace=True)
-    return df.loc[: num - 1, ["end_date", "info_date"] + fields]
-
-
-PERFORMANCE_FORECAST_FIELDS = [
-    "forecast_type",
-    "forecast_description",
-    "forecast_growth_rate_floor",
-    "forecast_growth_rate_ceiling",
-    "forecast_earning_floor",
-    "forecast_earning_ceiling",
-    "forecast_np_floor",
-    "forecast_np_ceiling",
-    "forecast_eps_floor",
-    "forecast_eps_ceiling",
-    "net_profit_yoy_const_forecast",
-]
-
-
-@export_as_api
-def performance_forecast(order_book_ids, info_date=None, end_date=None, fields=None, market="cn"):
-    """获取业绩预报
-
-    :param order_book_ids: 股票代码，如['000001.XSHE', '000002.XSHE']
-    :param info_date: 信息发布日期，如'20180501'，默认为最近的交易日 (Default value = None)
-    :param end_date: 业绩预计报告期，如'20180501'，默认为最近的交易日 (Default value = None)
-    :param fields: str或list类型. 默认为None，返回所有字段 (Default value = None)
-    :param market:  (Default value = "cn")
-    :returns: pd.DataFrame
-
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, type='CS')
-    if info_date:
-        info_date = ensure_date_int(info_date)
-    elif end_date:
-        end_date = ensure_date_int(end_date)
-    else:
-        info_date = ensure_date_int(datetime.datetime.today())
-
-    if fields:
-        fields = ensure_list_of_string(fields, "fields")
-        check_items_in_container(fields, PERFORMANCE_FORECAST_FIELDS, "fields")
-    else:
-        fields = PERFORMANCE_FORECAST_FIELDS
-
-    data = get_client().execute(
-        "performance_forecast", order_book_ids, info_date, end_date, fields, market=market
-    )
-    if not data:
-        return
-    if len(order_book_ids) > 1:
-        df = pd.DataFrame(data, columns=["order_book_id", "info_date", "end_date"] + fields)
-        return df.set_index("order_book_id")
-
-    return pd.DataFrame(data, columns=["info_date", "end_date"] + fields)
-
-
-PERFORMANCE_FIELDS = [
-    "operating_revenue",
-    "gross_profit",
-    "operating_profit",
-    "total_profit",
-    "np_parent_owners",
-    "net_profit_cut",
-    "net_operate_cashflow",
-    "total_assets",
-    "se_without_minority",
-    "total_shares",
-    "basic_eps",
-    "eps_weighted",
-    "eps_cut_epscut",
-    "eps_cut_weighted",
-    "roe",
-    "roe_weighted",
-    "roe_cut",
-    "roe_cut_weighted",
-    "net_operate_cashflow_per_share",
-    "equity_per_share",
-    "operating_revenue_yoy",
-    "gross_profit_yoy",
-    "operating_profit_yoy",
-    "total_profit_yoy",
-    "np_parent_minority_pany_yoy",
-    "ne_t_minority_ty_yoy",
-    "net_operate_cash_flow_yoy",
-    "total_assets_to_opening",
-    "se_without_minority_to_opening",
-    "basic_eps_yoy",
-    "eps_weighted_yoy",
-    "eps_cut_yoy",
-    "eps_cut_weighted_yoy",
-    "roe_yoy",
-    "roe_weighted_yoy",
-    "roe_cut_yoy",
-    "roe_cut_weighted_yoy",
-    "net_operate_cash_flow_per_share_yoy",
-    "net_asset_psto_opening",
-]
-
-QUARTER_DATE_MAP = {1: (3, 31), 2: (6, 30), 3: (9, 30), 4: (12, 31)}
+# -*- coding: utf-8 -*-
+import datetime
+
+import pandas as pd
+import math
+
+from rqdatac.client import get_client
+
+from rqdatac.services.orm.pit_financials_ex import FIELDS_LIST_EX
+from rqdatac.validators import (
+    ensure_list_of_string,
+    ensure_string,
+    check_items_in_container,
+    ensure_date_int,
+    ensure_order_book_id,
+    check_quarter,
+    ensure_date_or_today_int,
+    quarter_string_to_date,
+    ensure_order_book_ids,
+)
+from rqdatac.decorators import export_as_api
+
+ENTERPRISE_TYPE_MAP = {
+    13: "business_bank",
+    31: "securities_firms",
+    33: "trust",
+    35: "insurance_company",
+    39: "other_financial_institution",
+    99: "general_enterprise",
+}
+
+INFO_TYPE_MAP = {
+    10: "发行上市书",
+    20: "定期报告",
+    30: "业绩快报",
+    50: "章程制度",
+    70: "临时公告",
+    90: "交易所通报",
+    91: "交易所临时停(复)牌公告",
+    99: "其他",
+    110101: "定期报告:年度报告",
+    110102: "定期报告:半年度报告",
+    110103: "定期报告:第一季报",
+    110104: "定期报告:第三季报",
+    110105: "定期报告:审计报告",
+    110106: "定期报告:第二季报",
+    110107: "定期报告:第四季报",
+    110108: "定期报告:第五季报",
+    110109: "定期报告:第二季报（更正后）",
+    110110: "定期报告:第四季报（更正后）",
+    110111: "定期报告:第五季报（更正后）",
+    110201: "定期报告:年度报告(关联方)",
+    110202: "定期报告:半年度报告(关联方)",
+    110203: "定期报告:第一季报(关联方)",
+    110204: "定期报告:第三季报(关联方)",
+    120101: "临时公告:审计报告(更正后)",
+    120102: "临时公告:年度报告(更正后)",
+    120103: "临时公告:半年度报告(更正后)",
+    120104: "临时公告:第一季报(更正后)",
+    120105: "临时公告:第三季报(更正后)",
+    120106: "临时公告:公开转让说明书(更正后)",
+    120107: "临时公告:业绩快报",
+    120108: "临时公告:业绩快报(更正后)",
+    120201: "临时公告:跟踪评级报告",
+    120202: "临时公告:同业存单发行计划",
+    120203: "临时公告:比较式财务报表",
+    120204: "临时公告:关联方",
+    120205: "临时公告:其他",
+    120206: "临时公告:前期差错更正",
+    120207: "临时公告:第一季度报告",
+    120208: "临时公告:第二季度报告",
+    120209: "临时公告:第三季度报告",
+    120210: "临时公告:第四季度报告",
+    120211: "临时公告：年度报告",
+    130101: "发行上市书:募集说明书",
+    130102: "发行上市书:招股说明书(申报稿)",
+    130103: "发行上市书:招股意向书",
+    130104: "发行上市书:上市公告书",
+    130105: "发行上市书:审阅报告",
+    130106: "发行上市书:招股说明书",
+    130107: "发行上市书:公开转让说明书",
+    130108: "发行上市书:发行公告",
+    130109: "发行上市书:审计报告",
+    130110: "发行上市书:关联方",
+    130111: "发行上市书:其他",
+    140101: "发行披露文件:第一季报",
+    140102: "发行披露文件:半年度报告",
+    140103: "发行披露文件：第三季报",
+    140104: "发行披露文件：审计报告",
+    140105: "发行披露文件：募集说明书",
+    140106: "发行披露文件：跟踪评级报告"
+}
+
+
+@export_as_api
+def get_pit_financials_ex(order_book_ids, fields, start_quarter, end_quarter,
+                          date=None, statements='latest', market='cn'):
+    """
+        获取股票财务数据(Point In Time)
+    :param order_book_ids: 股票合约代码列表
+    :param fields: 指定返回财报字段
+    :param start_quarter: 财报季度 - 起始，如 2020q1
+    :param end_quarter: 财报季度 - 截止
+    :param date: 财报发布日期，默认为当前日期, 如 '2020-01-01' | '20200101'
+    :param statements: 可选 latest/all, 默认为 latest
+            latest: 仅返回在date时点所能观察到的最新数据；
+            all：返回在date时点所能观察到的所有版本，从第一次发布直到观察时点的所有修改。
+    :param market: 股票市场范围
+    :return:
+    """
+    fields = ensure_list_of_string(fields, 'fields')
+    check_items_in_container(fields, FIELDS_LIST_EX, "fields")
+    fields.extend(['order_book_id', 'info_date', 'end_date', 'if_adjusted', 'rice_create_tm'])
+    fields = list(set(fields))
+    fields[fields.index("info_date")], fields[0] = fields[0], fields[fields.index("info_date")]
+
+    check_quarter(start_quarter, 'start_quarter')
+    start_quarter_int = ensure_date_int(quarter_string_to_date(start_quarter))
+
+    check_quarter(end_quarter, 'end_quarter')
+    end_quarter_int = ensure_date_int(quarter_string_to_date(end_quarter))
+
+    if start_quarter > end_quarter:
+        raise ValueError(
+            'invalid quarter range: [{!r}, {!r}]'.format(
+                start_quarter, end_quarter))
+
+    date = ensure_date_or_today_int(date)
+
+    order_book_ids = ensure_list_of_string(order_book_ids, 'order_book_ids')
+
+    if statements not in ['all', 'latest']:
+        raise ValueError("invalid statements , got {!r}".format(statements))
+
+    pit_financial_df = pd.DataFrame(
+        get_client().execute("get_pit_financials_ex", order_book_ids, fields, start_quarter_int, end_quarter_int, date,
+                             statements, market))
+    if pit_financial_df.empty:
+        return
+    # convert rice_create_tm to datetime
+    pit_financial_df['rice_create_tm'] = pd.to_datetime(pit_financial_df['rice_create_tm'] + 3600 * 8, unit='s')
+    pit_financial_df = pit_financial_df.reindex(columns=fields)
+    pit_financial_df.sort_values(['order_book_id', 'end_date', 'info_date'])
+    pit_financial_df["end_date"] = pit_financial_df["end_date"].apply(
+        lambda d: "{}q{}".format(d.year, math.ceil(d.month / 3)))
+    pit_financial_df.rename(columns={"end_date": "quarter"}, inplace=True)
+    pit_financial_df.set_index(['order_book_id', 'quarter'], inplace=True)
+    pit_financial_df['if_adjusted'] = pit_financial_df['if_adjusted'].map(lambda x: 1 if x == 1 else 0).astype(int)
+    pit_financial_df.sort_index(inplace=True)
+    return pit_financial_df
+
+
+@export_as_api
+def current_performance(
+        order_book_id, info_date=None, quarter=None, interval="1q", fields=None, market="cn"
+):
+    """获取A股快报
+
+    :param order_book_id: 股票代码, 如'000001.XSHE'
+    :param info_date: 发布日期, 如'20180501', 默认为最近的交易日 (Default value = None)
+    :param quarter: 发布季度, 如'2018q1' (Default value = None)
+    :param interval: 数据区间， 发布日期, 如'2y', '4q' (Default value = "1q")
+    :param fields: str 或 list 类型. 默认为 None, 返回所有字段 (Default value = None)
+    :param market: 地区代码, 如'cn' (Default value = "cn")
+    :returns: pd.DataFrame
+
+    """
+    order_book_id = ensure_order_book_id(order_book_id, market=market)
+    end_date = None
+    if info_date:
+        info_date = ensure_date_int(info_date)
+    elif quarter:
+        splited = quarter.lower().split("q")
+        if len(quarter) != 6 or len(splited) != 2:
+            raise ValueError(
+                "invalid argument {}: {}, valid parameter: {}".format(
+                    "quarter", quarter, "string format like '2016q1'"
+                )
+            )
+
+        year, quarter = int(splited[0]), int(splited[1])
+        if not 1 <= quarter <= 4:
+            raise ValueError(
+                "invalid argument {}: {}, valid parameter: {}".format(
+                    "quarter", quarter, "quarter should be in [1, 4]"
+                )
+            )
+        month, day = QUARTER_DATE_MAP[quarter]
+        end_date = ensure_date_int(datetime.datetime(year, month, day))
+    else:
+        info_date = ensure_date_int(datetime.date.today())
+    ensure_string(interval, "interval")
+    if interval[-1] not in ("y", "q", "Y", "Q"):
+        raise ValueError(
+            "invalid argument {}: {}, valid parameter: {}".format(
+                "interval", interval, "interval unit should be q(quarter) or y(year)"
+            )
+        )
+
+    try:
+        int(interval[:-1])
+    except ValueError:
+        raise ValueError(
+            "invalid argument {}: {}, valid parameter: {}".format(
+                "interval", interval, "string like 4q, 2y"
+            )
+        )
+    interval = interval.lower()
+
+    if fields is not None:
+        fields = ensure_list_of_string(fields, "fields")
+        check_items_in_container(fields, PERFORMANCE_FIELDS, "fields")
+    else:
+        fields = PERFORMANCE_FIELDS
+
+    data = get_client().execute(
+        "current_performance", order_book_id, info_date, end_date, fields, market=market
+    )
+    if not data:
+        return
+    df = pd.DataFrame(data)
+    df.sort_values(by=["end_date", "info_date", "mark"], ascending=[False, False, True], inplace=True)
+    df.drop_duplicates(subset="end_date", keep="first", inplace=True)
+    num = int(interval[:-1])
+    unit = interval[-1]
+    if unit == "y":
+        latest_month = df.iloc[0]["end_date"].month
+        df["month"] = df.end_date.apply(lambda x: x.month)
+        df = df[df.month == latest_month]
+    df.reset_index(drop=True, inplace=True)
+    return df.loc[: num - 1, ["end_date", "info_date"] + fields]
+
+
+PERFORMANCE_FORECAST_FIELDS = [
+    "forecast_type",
+    "forecast_description",
+    "forecast_growth_rate_floor",
+    "forecast_growth_rate_ceiling",
+    "forecast_earning_floor",
+    "forecast_earning_ceiling",
+    "forecast_np_floor",
+    "forecast_np_ceiling",
+    "forecast_eps_floor",
+    "forecast_eps_ceiling",
+    "net_profit_yoy_const_forecast",
+]
+
+
+@export_as_api
+def performance_forecast(order_book_ids, info_date=None, end_date=None, fields=None, market="cn"):
+    """获取业绩预报
+
+    :param order_book_ids: 股票代码，如['000001.XSHE', '000002.XSHE']
+    :param info_date: 信息发布日期，如'20180501'，默认为最近的交易日 (Default value = None)
+    :param end_date: 业绩预计报告期，如'20180501'，默认为最近的交易日 (Default value = None)
+    :param fields: str或list类型. 默认为None，返回所有字段 (Default value = None)
+    :param market:  (Default value = "cn")
+    :returns: pd.DataFrame
+
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, type='CS')
+    if info_date:
+        info_date = ensure_date_int(info_date)
+    elif end_date:
+        end_date = ensure_date_int(end_date)
+    else:
+        info_date = ensure_date_int(datetime.datetime.today())
+
+    if fields:
+        fields = ensure_list_of_string(fields, "fields")
+        check_items_in_container(fields, PERFORMANCE_FORECAST_FIELDS, "fields")
+    else:
+        fields = PERFORMANCE_FORECAST_FIELDS
+
+    data = get_client().execute(
+        "performance_forecast", order_book_ids, info_date, end_date, fields, market=market
+    )
+    if not data:
+        return
+    if len(order_book_ids) > 1:
+        df = pd.DataFrame(data, columns=["order_book_id", "info_date", "end_date"] + fields)
+        return df.set_index("order_book_id")
+
+    return pd.DataFrame(data, columns=["info_date", "end_date"] + fields)
+
+
+PERFORMANCE_FIELDS = [
+    "operating_revenue",
+    "gross_profit",
+    "operating_profit",
+    "total_profit",
+    "np_parent_owners",
+    "net_profit_cut",
+    "net_operate_cashflow",
+    "total_assets",
+    "se_without_minority",
+    "total_shares",
+    "basic_eps",
+    "eps_weighted",
+    "eps_cut_epscut",
+    "eps_cut_weighted",
+    "roe",
+    "roe_weighted",
+    "roe_cut",
+    "roe_cut_weighted",
+    "net_operate_cashflow_per_share",
+    "equity_per_share",
+    "operating_revenue_yoy",
+    "gross_profit_yoy",
+    "operating_profit_yoy",
+    "total_profit_yoy",
+    "np_parent_minority_pany_yoy",
+    "ne_t_minority_ty_yoy",
+    "net_operate_cash_flow_yoy",
+    "total_assets_to_opening",
+    "se_without_minority_to_opening",
+    "basic_eps_yoy",
+    "eps_weighted_yoy",
+    "eps_cut_yoy",
+    "eps_cut_weighted_yoy",
+    "roe_yoy",
+    "roe_weighted_yoy",
+    "roe_cut_yoy",
+    "roe_cut_weighted_yoy",
+    "net_operate_cash_flow_per_share_yoy",
+    "net_asset_psto_opening",
+]
+
+QUARTER_DATE_MAP = {1: (3, 31), 2: (6, 30), 3: (9, 30), 4: (12, 31)}
```

## rqdatac/services/future.py

 * *Ordering differences only*

```diff
@@ -1,771 +1,771 @@
-# -*- coding: utf-8 -*-
-import six
-import datetime
-import warnings
-import bisect
-
-import pandas as pd
-import numpy as np
-from dateutil.relativedelta import relativedelta
-from rqdatac.validators import (
-    ensure_string,
-    ensure_string_in,
-    ensure_list_of_string,
-    ensure_date_int,
-    ensure_date_or_today_int,
-    ensure_date_range,
-    check_items_in_container,
-    ensure_order_book_ids,
-    ensure_instruments,
-)
-from rqdatac.client import get_client
-from rqdatac.decorators import export_as_api, ttl_cache
-from rqdatac.utils import int8_to_datetime, to_datetime, date_to_int8, to_date
-from rqdatac.services.calendar import current_trading_date, is_trading_date, get_next_trading_date, get_trading_dates
-from rqdatac.services.basic import instruments
-from rqdatac.services import get_price
-
-
-@export_as_api
-def get_dominant_future(underlying_symbol, start_date=None, end_date=None, rule=0, rank=1, market="cn"):
-    import warnings
-
-    msg = "'get_dominant_future' is deprecated, please use 'futures.get_dominant' instead"
-    warnings.warn(msg, category=DeprecationWarning, stacklevel=2)
-    return get_dominant(underlying_symbol, start_date, end_date, rule, rank, market)
-
-
-@export_as_api(namespace='futures')
-def get_dominant(underlying_symbol, start_date=None, end_date=None, rule=0, rank=1, market="cn"):
-    """获取指定期货品种当日对应的主力合约
-
-    :param underlying_symbol: 如'IF' 'IC'
-    :param start_date: 如 '2015-01-07' (Default value = None)
-    :param end_date: 如 '2015-01-08' (Default value = None)
-    :param market:  (Default value = "cn")
-    :param rule:  主力合约规则 (Default value = 0)
-        0：在rule=1的规则上，增加约束(曾做过主力合约的合约，一旦被换下来后，不会再被选上)
-        1：合约首次上市时，以当日收盘同品种持仓量最大者作为从第二个交易日开始的主力合约，当同品种其他合约持仓量在收盘后
-           超过当前主力合约1.1倍时，从第二个交易日开始进行主力合约的切换。日内不会进行主力合约的切换
-    :param rank:  (Default value = 1):
-        1: 主力合约
-        2: 次主力合约
-        3：次次主力合约
-    :returns: pandas.Series
-        返回参数指定的具体主力合约名称
-
-    """
-    if not isinstance(underlying_symbol, six.string_types):
-        raise ValueError("invalid underlying_symbol: {}".format(underlying_symbol))
-
-    check_items_in_container(rule, [0, 1], 'rule')
-    check_items_in_container(rank, [1, 2, 3], 'order')
-
-    underlying_symbol = underlying_symbol.upper()
-
-    if start_date:
-        start_date = ensure_date_int(start_date)
-
-    if end_date:
-        end_date = ensure_date_int(end_date)
-    elif start_date:
-        end_date = start_date
-
-    if rank == 1:
-        result = get_client().execute(
-            "futures.get_dominant", underlying_symbol, start_date, end_date, rule, market=market)
-    else:
-        result = get_client().execute(
-            "futures.get_dominant_v2", underlying_symbol, start_date, end_date, rule, rank, market=market)
-
-    if not result:
-        return
-    df = pd.DataFrame(result)
-    df["date"] = df["date"].apply(int8_to_datetime)
-    return df.set_index("date").sort_index()["dominant"]
-
-
-@ttl_cache(3600)
-def current_real_contract(ob, market):
-    """获取指定期货品种当日对应的真实合约"""
-    date = current_trading_date(market)
-    r = get_dominant(ob, date, date, market=market)
-    if isinstance(r, pd.Series) and r.size == 1:
-        return r[0]
-    return None
-
-
-_FIELDS = [
-    "margin_type",
-    "long_margin_ratio",
-    "short_margin_ratio",
-    "commission_type",
-    "open_commission_ratio",
-    "close_commission_ratio",
-    "close_commission_today_ratio",
-]
-
-
-@export_as_api
-def future_commission_margin(order_book_ids=None, fields=None, hedge_flag="speculation"):
-    import warnings
-
-    msg = "'future_commission_margin' is deprecated, please use 'futures.get_commission_margin' instead"
-    warnings.warn(msg, category=DeprecationWarning, stacklevel=2)
-    return get_commission_margin(order_book_ids, fields, hedge_flag)
-
-
-@export_as_api(namespace='futures')
-def get_commission_margin(order_book_ids=None, fields=None, hedge_flag="speculation"):
-    """获取期货保证金和手续费数据
-
-    :param order_book_ids: 期货合约, 支持 order_book_id 或 order_book_id list,
-        若不指定则默认获取所有合约 (Default value = None)
-    :param fields: str 或 list, 可选字段有： 'margin_type', 'long_margin_ratio', 'short_margin_ratio',
-            'commission_type', 'open_commission_ratio', 'close_commission_ratio',
-            'close_commission_today_ratio', 若不指定则默认获取所有字段 (Default value = None)
-    :param hedge_flag: str, 账户对冲类型, 可选字段为: 'speculation', 'hedge',
-            'arbitrage', 默认为'speculation', 目前仅支持'speculation' (Default value = "speculation")
-    :returns: pandas.DataFrame
-
-    """
-    if order_book_ids:
-        order_book_ids = ensure_list_of_string(order_book_ids)
-
-    if fields is None:
-        fields = _FIELDS
-    else:
-        fields = ensure_list_of_string(fields, "fields")
-        check_items_in_container(fields, _FIELDS, "fields")
-
-    hedge_flag = ensure_string(hedge_flag, "hedge_flag")
-    if hedge_flag not in ["speculation", "hedge", "arbitrage"]:
-        raise ValueError("invalid hedge_flag: {}".format(hedge_flag))
-
-    ret = get_client().execute("futures.get_commission_margin", order_book_ids, fields, hedge_flag)
-    return pd.DataFrame(ret)
-
-
-@export_as_api
-def get_future_member_rank(order_book_id, trading_date=None, info_type='volume'):
-    import warnings
-
-    msg = "'get_future_member_rank' is deprecated, please use 'futures.get_member_rank' instead"
-    warnings.warn(msg, category=DeprecationWarning, stacklevel=2)
-    return get_member_rank(order_book_id, trading_date, info_type)
-
-
-@export_as_api(namespace='futures')
-def get_member_rank(obj, trading_date=None, rank_by='volume', **kwargs):
-    """获取指定日期最近的期货会员排名数据
-    :param obj： 期货合约或品种代码
-    :param trading_date: 日期
-    :param rank_by: 排名依据字段
-    :keyword start_date
-    :keyword end_date
-    :returns pandas.DataFrame or None
-    """
-    if not kwargs:
-        trading_date = ensure_date_or_today_int(trading_date)
-        ret = get_client().execute("futures.get_member_rank", obj, trading_date, rank_by)
-    else:
-        start_date = kwargs.pop("start_date", None)
-        end_date = kwargs.pop("end_date", None)
-        if kwargs:
-            raise ValueError('unknown kwargs: {}'.format(kwargs))
-        elif start_date and end_date:
-            start_date, end_date = ensure_date_int(start_date), ensure_date_int(end_date)
-            ret = get_client().execute("futures.get_member_rank_v2", obj, start_date, end_date, rank_by)
-        else:
-            raise ValueError('please ensure start_date and end_date exist')
-
-    if not ret:
-        return
-
-    df = pd.DataFrame(ret).sort_values(by=['trading_date', 'rank'])
-    df.set_index('trading_date', inplace=True)
-    return df
-
-
-@export_as_api(namespace="futures")
-def get_warehouse_stocks(underlying_symbols, start_date=None, end_date=None, market="cn"):
-    """获取时间区间内期货的注册仓单
-
-    :param underlying_symbols: 期货品种, 支持列表查询
-    :param start_date: 如'2015-01-01', 如果不填写则为去年的当日日期
-    :param end_date: 如'2015-01-01', 如果不填写则为当日日期
-    :param market: 市场, 默认为"cn"
-    :return: pd.DataFrame
-
-    """
-    underlying_symbols = ensure_list_of_string(underlying_symbols, name="underlying_symbols")
-    start_date, end_date = ensure_date_range(start_date, end_date, delta=relativedelta(years=1))
-
-    # 有新老两种 symbol 时对传入的 underlying_symbols 需要对应成新的 symbol, 并对并行期结束后仍使用老的 symbol 予以警告
-    multi_symbol_map = {'RO': 'OI', 'WS': 'WH', 'ER': 'RI', 'TC': 'ZC', 'ME': 'MA'}
-    symbol_date_map = {'RO': 20130515, 'WS': 20130523, 'ER': 20130523, 'TC': 20160408, 'ME': 20150515}
-    for symbol in set(underlying_symbols) & set(multi_symbol_map):
-        date_line = symbol_date_map[symbol]
-        if end_date > date_line:
-            import warnings
-            msg = 'You are using the old symbol: {}, however the new symbol: {} is available after {}.'.format(symbol, multi_symbol_map[symbol], date_line)
-            warnings.warn(msg, category=DeprecationWarning, stacklevel=2)
-
-    # 对传入的 underlying_symbols 依照 multi_symbol_map 生成一个对照 DataFrame
-    symbol_map_df = pd.DataFrame([(symbol, multi_symbol_map.get(symbol, symbol)) for symbol in set(underlying_symbols)],
-                                 columns=['origin', 'new'])
-    # 将 underlying_symbols 中 所有老的 symbol 对应为新的再去 mongo 查询
-    underlying_symbols = list(symbol_map_df.new.unique())
-    ret = get_client().execute("futures.get_warehouse_stocks", underlying_symbols, start_date, end_date, market=market)
-    if not ret:
-        return
-    columns = ["date", "underlying_symbol", "on_warrant", "exchange", 'effective_forecast', 'warrant_units',
-               'contract_multiplier', 'deliverable']
-    df = pd.DataFrame(ret, columns=columns)
-
-    df = df.merge(symbol_map_df, left_on='underlying_symbol', right_on='new')
-    df.drop(['underlying_symbol', 'new'], axis=1, inplace=True)
-    df.rename(columns={'origin': 'underlying_symbol'}, inplace=True)
-    df.set_index(['date', 'underlying_symbol'], inplace=True)
-    return df.sort_index()
-
-
-@export_as_api(namespace="futures")
-def get_contract_multiplier(underlying_symbols, start_date=None, end_date=None, market="cn"):
-    """获取时间区间内期货的合约乘数
-
-    :param underlying_symbols: 期货品种, 支持列表查询
-    :param start_date: 开始日期, 如'2015-01-01', 如果不填写则取underlying_symbols对应实际数据最早范围
-    :param end_date: 结束日期, 如'2015-01-01', 如果不填写则为当日前一天
-    :param market: 市场, 默认为"cn", 当前仅支持中国市场
-    :return: pd.DataFrame
-
-    """
-    underlying_symbols = ensure_list_of_string(underlying_symbols, name="underlying_symbols")
-    ret = get_client().execute("futures.get_contract_multiplier", underlying_symbols)
-    if not ret:
-        return
-
-    # 因 mongo 数据为时间范围，要返回每一天的数据，需复制合约乘数数据至至范围内所有 trading_date
-    if start_date:
-        start_date = to_datetime(start_date)
-    if not end_date:
-        end_date = datetime.datetime.today() - datetime.timedelta(days=1)
-    end_date = to_datetime(end_date)
-
-    def fill(group_df):
-        # 根据当前合约日期范围及给定范围内获取所有 trading_date
-        date_min, date_max = group_df['effective_date'].min(), group_df['cancel_date'].max()
-        if start_date is not None:
-            date_min = max(start_date, date_min)
-        date_max = min(date_max, end_date)
-        trading_dates = pd.to_datetime(get_trading_dates(date_min, date_max)+group_df['effective_date'].to_list()).unique()
-
-        # 使用 trading_dates 作为 index 插入并填充数据
-        everyday_df = group_df.set_index(['effective_date']).reindex(trading_dates).sort_index().ffill().reset_index().rename(columns={'index': 'date'})
-        everyday_df = everyday_df[(everyday_df['date'] >= date_min) & (everyday_df['date'] <= date_max)]
-
-        return everyday_df
-
-    df = pd.DataFrame(ret).groupby(by=['underlying_symbol']).apply(fill)
-
-    df = df[['date', 'underlying_symbol', 'exchange', 'contract_multiplier']]
-    df.set_index(['underlying_symbol', 'date'], inplace=True)
-    df.sort_index(inplace=True)
-    return df
-
-
-@export_as_api(namespace='futures')
-def get_current_basis(order_book_ids, market='cn'):
-    """获取股指期货的实时基差指标
-
-    :param order_book_ids: str or str list	合约代码
-    :param market: str	默认是中国内地市场('cn') 。可选'cn' - 中国内地市场；
-    :return: DataFrame with below fields:
-        字段	类型	说明
-        order_book_id	str	合约代码
-        datetime	datetime	时间戳
-        index	str	指数合约
-        index_px	float	指数最新价格
-        future_px	float	期货最新价格
-        basis	 float	升贴水， 等于期货合约收盘价- 对应指数收盘价
-        basis_rate	float	升贴水率(%)，（期货合约收盘价- 对应指数收盘价）/对应指数收盘价*100
-        basis_annual_rate	float	年化升贴水率（%), basis_rate *(250/合约到期剩余交易日）
-    """
-    ins_list = ensure_instruments(order_book_ids, 'Future')
-    today_str = datetime.date.today().strftime('%Y-%m-%d')
-    underlying_id_map = {}
-    remaining_days_map = {}
-
-    for ins in ins_list:
-        if ins.industry_name != '股指':
-            warnings.warn(
-                'expect 股指期货, got {}({})!'.format(ins.industry_name, ins.order_book_id),
-                stacklevel=0
-            )
-            continue
-        if ins.listed_date == '0000-00-00' or (ins.listed_date > today_str) or (
-                ins.de_listed_date != '0000-00-00' and ins.de_listed_date < today_str):
-            warnings.warn('inactive order_book_id: {}'.format(ins.order_book_id), stacklevel=0)
-            continue
-        underlying_id_map[ins.order_book_id] = ins.underlying_order_book_id
-        remaining_days_map[ins.order_book_id] = len(get_trading_dates(today_str, ins.de_listed_date)) - 1
-    if not underlying_id_map:
-        return None
-    futures = list(underlying_id_map.keys())
-    indexes = list(set(underlying_id_map.values()))
-
-    data = {future: {'order_book_id': future, 'index': index} for future, index in underlying_id_map.items()}
-    from ..services.live import current_snapshot
-    source = {sn.order_book_id: sn for sn in current_snapshot(futures + indexes, market=market)}
-    if not source:
-        return None
-
-    for future, index in underlying_id_map.items():
-        d = data[future]
-        f = source[future]
-        i = source[index]
-        d['datetime'] = f['datetime']
-        d['index_px'] = i['last']
-        d['future_px'] = f['settlement'] if f['settlement'] == f['settlement'] else f['last']
-        d['basis'] = d['future_px'] - d['index_px']
-        d['basis_rate'] = d['basis'] / d['index_px'] * 100
-        n = remaining_days_map[future]
-        if n <= 0:
-            d['basis_annual_rate'] = float('nan')
-        else:
-            d['basis_annual_rate'] = d['basis_rate'] * (250 / n)
-
-    df = pd.DataFrame(list(data.values())).set_index('order_book_id')
-    return df
-
-
-VALID_FIELDS_MAP = {
-    '1d': [
-        "open", "high", "low", "close", "index", "close_index",
-        "basis", "basis_rate", "basis_annual_rate",
-        "settlement", "settle_basis", "settle_basis_rate", "settle_basis_annual_rate"
-    ],
-    '1m': [
-        "open", "high", "low", "close", "index", "close_index",
-        "basis", "basis_rate", "basis_annual_rate"
-    ],
-    'tick': [
-        "index", "future_px", "index_px",
-        "basis", "basis_rate", "basis_annual_rate",
-    ]
-}
-
-FUTURE_PRICE_FIELDS_MAP = {
-    '1d': ['close', 'open', 'high', 'low', 'settlement'],
-    '1m': ['close', 'open', 'high', 'low'],
-    'tick': ['last']
-}
-
-
-@export_as_api(namespace="futures")
-def get_basis(order_book_ids, start_date=None, end_date=None, fields=None, frequency='1d', market="cn"):
-    """ 获取股指期货升贴水信息.
-
-    :param order_book_ids: 期货合约, 支持 order_book_id 或 order_book_id list.
-    :param start_date: 开始时间, 若不传, 为 end_date 前3个月.
-    :param end_date: 结束时间, 若不传, 为 start_date 后3个月, 如果 start_date 也不传, 则默认为最近3个月.
-    :param fields: 需要返回的字段, 若不传则返回所有字段, 支持返回的字段包括
-        open, high, low, close, index, close_index, basis, basis_rate, basis_annual_rate.
-    :param frequency: 数据频率, 默认 '1d', 其他可选 {'1m', 'tick'}
-        frequency=tick时, fields为index, future_px, index_px, basis, basis_rate, basis_annual_rate
-    :param market: 市场, 默认'cn'
-    :return: MultiIndex DataFrame.
-    """
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    ensure_string_in(frequency, ('1d', '1m', 'tick'), 'frequency')
-
-    insts = instruments(order_book_ids)
-    if insts is None:
-        return None
-    if not isinstance(order_book_ids, list):
-        insts = [insts]
-    insts = [
-        x for x in insts
-        if x.type == "Future" and x.listed_date != "0000-00-00" and x.industry_name == "股指"
-    ]
-    if not insts:
-        return None
-
-    underlying_id_map = {x.order_book_id: x.underlying_order_book_id for x in insts}
-    delisted_map = {x.order_book_id: to_date(x.de_listed_date) for x in insts}
-    close_field = 'close' if frequency != 'tick' else 'last'
-
-    if fields is None:
-        fields = VALID_FIELDS_MAP[frequency]
-        need_basis, need_settlement_basis, need_index_price = True, (frequency == '1d'), True
-        future_price_fields = FUTURE_PRICE_FIELDS_MAP[frequency]
-    else:
-        fields = ensure_list_of_string(fields)
-        check_items_in_container(fields, VALID_FIELDS_MAP[frequency], 'fields')
-        need_basis, need_settlement_basis = False, False
-        FUTURE_PRICE_FIELDS = FUTURE_PRICE_FIELDS_MAP[frequency]
-        future_price_fields = set()
-        need_index_price = False
-        for f in fields:
-            if f.startswith('basis') or f == 'future_px':
-                future_price_fields.add(close_field)
-                need_basis, need_index_price = True, f.startswith('basis')
-            elif f == 'index_px' or f == 'close_index':
-                need_index_price = True
-            elif f.startswith('settle'):
-                future_price_fields.add('settlement')
-                need_settlement_basis, need_index_price = True, True
-            elif f in FUTURE_PRICE_FIELDS:
-                future_price_fields.add(f)
-        future_price_fields = list(future_price_fields)
-
-    order_book_ids = [x.order_book_id for x in insts]
-    future_price = get_price.get_price(
-        order_book_ids, start_date, end_date, frequency=frequency, fields=future_price_fields,
-        expect_df=True, market=market
-    )
-    if future_price is None:
-        return None
-
-    future_price["index"] = future_price.index.get_level_values("order_book_id").map(underlying_id_map)
-
-    _all_trading_dates = get_trading_dates(start_date, max(delisted_map.values()))
-    _dates_remain_cache = {
-        (s, e): (bisect.bisect_left(_all_trading_dates, e) - bisect.bisect_left(_all_trading_dates, s))
-        for s in get_trading_dates(start_date, end_date)
-        for e in delisted_map.values()
-    }
-
-    def _calc_annual_rate(row, rate_field):
-        # row.name[1] is current date.
-        order_book_id, current_date = row.name
-        dates_remain = _dates_remain_cache[(current_date.date(), delisted_map[order_book_id])]
-        if dates_remain == 0:
-            # 在到期的时候, basis_annual_rate 的值本身也没有什么意义, 所以直接赋值为 nan.
-            return float("nan")
-        else:
-            return row[rate_field] * 250 / dates_remain
-
-    if need_index_price:
-        underlying_ids = list({x.underlying_order_book_id for x in insts})
-        if frequency == '1d':
-            from rqdatac.services.detail import get_price_df
-            index_close = get_price_df.get_future_indx_daybar(underlying_ids, start_date, end_date, fields=["close"])
-            date_field = 'date'
-        else:
-            index_close = get_price.get_price(underlying_ids, start_date, end_date, frequency=frequency, fields=close_field, expect_df=True)
-            date_field = 'datetime'
-        index_close.columns = ['close_index']
-        future_price = pd.merge_asof(
-            future_price.reset_index().sort_values(date_field),
-            index_close.reset_index().rename(
-                columns={'order_book_id': 'index'}
-            ).sort_values(date_field),
-            on=date_field,
-            by='index',
-            direction='backward'
-        )
-        future_price.set_index(['order_book_id', date_field], inplace=True)
-        future_price.sort_index(inplace=True)
-        future_price.bfill(axis=0, inplace=True)
-
-    if need_basis:
-        future_price["basis"] = future_price[close_field] - future_price["close_index"]
-        future_price["basis_rate"] = future_price["basis"] / future_price["close_index"] * 100
-        future_price["basis_annual_rate"] = future_price.apply(lambda x: _calc_annual_rate(x, "basis_rate"), axis=1)
-
-    if need_settlement_basis:
-        future_price["settle_basis"] = future_price["settlement"] - future_price["close_index"]
-        future_price["settle_basis_rate"] = future_price["settle_basis"] / future_price["close_index"] * 100
-        future_price["settle_basis_annual_rate"] = future_price.apply(
-            lambda x: _calc_annual_rate(x, "settle_basis_rate"), axis=1
-        )
-
-    if frequency == 'tick':
-        future_price.rename(columns={'close_index': 'index_px', close_field: 'future_px'}, inplace=True)
-
-    res = future_price[fields]
-    return res
-
-
-VALID_ADJUST_METHODS = ['prev_close_spread', 'open_spread', 'prev_close_ratio', 'open_ratio']
-
-
-@ttl_cache(1800)
-def _get_future_factors_df(market='cn'):
-    """ 获取所有复权因子表 """
-    data = get_client().execute('futures.__internal__get_future_factors', market=market)
-    df = pd.DataFrame(data)
-    df['ex_date'] = df['ex_date'].apply(int8_to_datetime)
-    df.set_index(['underlying_symbol', 'ex_date'], inplace=True)
-    df.sort_index(inplace=True)
-    return df
-
-
-@export_as_api(namespace='futures')
-def get_ex_factor(underlying_symbols, start_date=None, end_date=None, adjust_method='prev_close_spread', market='cn'):
-    """ 获取期货复权因子
-
-    :param underlying_symbols: 期货合约品种，str or list
-    :param start_date: 开始日期
-    :param end_date: 结束日期
-    :param adjust_method: 复权方法，prev_close_spread, prev_close_ratio, open_spread, open_ratio,
-    默认为‘prev_close_spread'
-    :param market: 默认是中国内地市场('cn') 。可选'cn' - 中国内地市场
-    :return: DataFrame
-    """
-    df = _get_future_factors_df(market)
-    valid_underlying_symbols = df.index.get_level_values('underlying_symbol').unique().tolist()
-    underlying_symbols = ensure_list_of_string(underlying_symbols, 'underlying_symbols')
-    check_items_in_container(adjust_method, VALID_ADJUST_METHODS, 'adjust_method')
-    check_items_in_container(underlying_symbols, valid_underlying_symbols, 'underlying_symbols')
-
-    factor = df.loc[underlying_symbols, adjust_method]
-    factor.name = 'ex_factor'
-    factor = factor.reset_index()
-
-    spread = adjust_method.endswith('spread')
-
-    def _process(x):
-        x['ex_end_date'] = x['ex_date'].shift(-1) - pd.offsets.DateOffset(days=1)
-        if spread:
-            x['ex_cum_factor'] = x['ex_factor'].cumsum()
-        else:
-            x['ex_cum_factor'] = x['ex_factor'].cumprod()
-        return x
-
-    factor = factor.groupby('underlying_symbol', as_index=False).apply(_process)
-    if start_date and end_date:
-        start_date, end_date = to_datetime(start_date), to_datetime(end_date)
-        factor = factor[(start_date <= factor['ex_date']) & (factor['ex_date'] <= end_date)]
-    # _get_future_factors_df 已经排序过了，此处无需再次排序
-    return factor.set_index('ex_date')
-
-
-def __internal_get_ex_factor(underlying_symbols, adjust_type, adjust_method):
-    """ 内部使用，获取复权因子，提供给get_dominant_price进行复权计算用
-    :return: pd.Series
-    """
-    df = _get_future_factors_df()
-    df = df.loc[underlying_symbols]
-
-    factor = df[adjust_method]
-    factor.name = 'ex_factor'
-    factor = factor.reset_index()
-    pre = adjust_type == 'pre'
-    ratio = adjust_method.endswith('ratio')
-
-    def _process(x):
-        if ratio:
-            x['ex_cum_factor'] = x['ex_factor'].cumprod()
-            if pre:
-                x['ex_cum_factor'] = x['ex_cum_factor'] / x['ex_cum_factor'].iloc[-1]
-        else:
-            x['ex_cum_factor'] = x['ex_factor'].cumsum()
-            if pre:
-                x['ex_cum_factor'] = x['ex_cum_factor'] - x['ex_cum_factor'].iloc[-1]
-
-        # tds 是从小到大排列的， 因此reindex后无需再sort
-        return x.set_index('ex_date')
-
-    factor = factor.groupby('underlying_symbol', as_index=True).apply(_process)
-    return factor['ex_cum_factor']
-
-
-DOMINANT_PRICE_ADJUST_FIELDS = [
-    'open', 'high', 'low', 'close', 'last', 'limit_up', 'limit_down', 'settlement', 'prev_settlement', 'prev_close',
-    'a1', 'a2', 'a3', 'a4', 'a5', 'b1', 'b2', 'b3', 'b4', 'b5'
-]
-
-
-@export_as_api(namespace='futures')
-def get_dominant_price(
-        underlying_symbols, start_date=None, end_date=None,
-        frequency='1d', fields=None, adjust_type='pre', adjust_method='prev_close_spread'
-):
-    """ 获取主力合约行情数据
-
-    :param underlying_symbols: 期货合约品种，可传入 underlying_symbol, underlying_symbol list
-    :param start_date: 开始日期, 最小日期为 20210104
-    :param end_date: 结束日期
-    :param frequency: 历史数据的频率。 支持/日/分钟/tick 级别的历史数据，默认为'1d'。
-        1m- 分钟线，1d-日线，分钟可选取不同频率，例如'5m'代表 5 分钟线
-    :param fields: 字段名称列表
-    :param adjust_type: 复权方式，不复权 - none，前复权 - pre，后复权 - post
-    :param adjust_method: 复权方法 ，prev_close_spread/open_spread:基于价差复权因子进行复权，
-        prev_close_ratio/open_ratio:基于比例复权因子进行复权，
-        默认为‘prev_close_spread',adjust_type为None 时，adjust_method 复权方法设置无效
-    :return: MultiIndex DataFrame
-    """
-    # ensure underlying symbols list
-    from ..services.get_price import get_price
-    if not isinstance(underlying_symbols, list):
-        underlying_symbols = [underlying_symbols]
-    if fields and not isinstance(fields, list):
-        fields = [fields]
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    if start_date < 20100104:
-        raise ValueError('expect start_date >= 20100104, get {}'.format(start_date))
-    # ensure adjust_type and adjust_method
-    check_items_in_container(adjust_type, ['none', 'pre', 'post'], 'adjust_type')
-    check_items_in_container(adjust_method, VALID_ADJUST_METHODS, 'adjust_method')
-
-    _date_key = 'date' if frequency == '1d' else 'trading_date'
-    _fields = fields
-    if fields and frequency != '1d' and 'trading_date' not in fields:
-        _fields = ['trading_date'] + fields
-
-    obs = [u + '88' for u in underlying_symbols]
-    df = get_price(
-        order_book_ids=obs, start_date=start_date, end_date=end_date,
-        frequency=frequency, adjust_type='none', fields=_fields, expect_df=True
-    )
-    if df is None:
-        return
-
-    df.reset_index(inplace=True)
-    df['underlying_symbol'] = df['order_book_id'].str[:-2]
-    df.set_index(['underlying_symbol', _date_key], inplace=True)
-    if adjust_type != 'none':
-        # 复权调整
-        factor = __internal_get_ex_factor(underlying_symbols, adjust_type, adjust_method)
-        factor = factor.reindex(factor.index.union(df.index.unique()))
-        factor = factor.groupby(level=0).ffill()
-        values = factor.loc[df.index].values
-        _fields = fields if fields else df.columns.tolist()
-        adjust_fields = [f for f in DOMINANT_PRICE_ADJUST_FIELDS if f in _fields]
-        if adjust_method.endswith('spread'):
-            for field in adjust_fields:
-                df[field] += values
-        elif adjust_method.endswith('ratio'):
-            for field in adjust_fields:
-                df[field] *= values
-        if 'total_turnover' in df.columns:
-            df['total_turnover'] = 0
-
-    if frequency != '1d':
-        df = df.reset_index().set_index(['underlying_symbol', 'datetime'])
-    df.sort_index(inplace=True)
-    del df['order_book_id']
-    return df[fields] if fields else df
-
-
-def get_ob_datetime_multi_index(
-    order_book_ids,
-    start_date,
-    end_date,
-    names=['order_book_id', 'trading_date']
-):
-    start_date = to_datetime(start_date).strftime("%Y-%m-%d")
-    end_date = to_datetime(end_date).strftime("%Y-%m-%d")
-    insts = instruments(order_book_ids)
-    indexs = []
-    dates = get_trading_dates(start_date, end_date)
-    index = pd.to_datetime(dates)
-    for i in insts:
-        oid = i.order_book_id
-        listed_date = i.listed_date
-        de_listed_date = i.de_listed_date if i.de_listed_date != '0000-00-00' else '9999-99-99'
-        start = pd.Timestamp(max(start_date, listed_date))
-        end = pd.Timestamp(min(end_date, de_listed_date))
-        start_pos, end_pos = index.searchsorted(start), index.searchsorted(end)
-        _index = index[start_pos:end_pos+1]
-        indexs.extend([(oid, i) for i in _index])
-
-    return pd.MultiIndex.from_tuples(indexs, names=names)
-
-
-TRADING_PARAMETERS_FIELDS = [
-    'long_margin_ratio',
-    'short_margin_ratio',
-    'commission_type',
-    'open_commission',
-    'close_commission',
-    'discount_rate',
-    'close_commission_today',
-    'non_member_limit_rate',
-    'client_limit_rate',
-    'non_member_limit',
-    'client_limit',
-    'min_order_quantity',
-]
-
-
-@export_as_api(namespace='futures')
-def get_trading_parameters(order_book_ids, start_date=None, end_date=None, fields=None, market='cn'):
-    """ 获取期货交易参数信息
-
-    :param order_book_ids: 期货合约代码或代码列表
-    :param start_date: 开始日期，如 '2019-01-01'，若不指定，默认为当前交易日
-                       未指定时，若查询时间在 T 日 8.40pm 前，返回 T 日数据，否则返回 T+1 日数据
-    :param end_date: 结束日期，如 '2023-01-01'，若不指定，默认为当前交易日
-                     开始日期和结束日期需同时传入或同时不传入
-    :param fields: 所需字段或字段列表，不指定则返回全部字段，可选:
-        [ 'long_margin_ratio', 'short_margin_ratio', 'commission_type', 'open_commission', 
-          'close_commission', 'discount_rate, 'close_commission_today',
-          'non_member_limit_rate', 'client_limit_rate', 'non_member_limit', 'client_limit',
-          'min_order_quantity',
-        ]
-    :param market: 目前只支持中国市场，默认为 'cn'
-
-    :return: DataFrame(MultiIndex(order_book_id, trading_date)) or None
-    
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, type='Future', market=market)
-    # 只存了真实合约信息
-    order_book_ids = list(
-        filter(
-            lambda x: not x.endswith(('88', '99', '888', '889', '88A2', '88A3')),
-            order_book_ids
-        )
-    )
-    if fields is None:
-        fields = TRADING_PARAMETERS_FIELDS
-    else:
-        fields = ensure_list_of_string(fields, 'fields')
-        check_items_in_container(fields, TRADING_PARAMETERS_FIELDS, 'fields')
-    now = datetime.datetime.now()
-    if is_trading_date(now):
-        # dps 任务在 20:40 第一次更新夜盘信息
-        if (now.hour, now.minute) >= (20, 40):
-            day = get_next_trading_date(now)
-        else:
-            day = now.date()
-    else:
-        day = get_next_trading_date(now)
-    day = date_to_int8(day)
-    if start_date is None and end_date is None:
-        start_date = end_date = day
-    elif start_date and end_date:
-        start_date, end_date = ensure_date_range(start_date, end_date)
-        # 数据是不连续向后填补的，因此不能返回还未有记录的日期
-        end_date = min(end_date, day)
-        if end_date < start_date:
-            return None
-    else:
-        raise ValueError('start_date and end_date should be used together or not at the same time')
-
-    insts = instruments(order_book_ids)
-    _oids = []
-    # 筛选位于 start_date 与 end_date 间的 ob
-    for i in insts:
-        listed_date = int(i.listed_date.replace('-', ''))
-        de_listed_date = i.de_listed_date if i.de_listed_date != '0000-00-00' else '9999-99-99'
-        de_listed_date = int(de_listed_date.replace('-', ''))
-        if start_date <= de_listed_date and end_date >= listed_date:
-            _oids.append(i.order_book_id)
-    order_book_ids = _oids
-
-    # 交易参数数据已去重所以不连续，获取全部数据
-    data = get_client().execute('futures.get_trading_parameters', order_book_ids, fields, market)
-    if not data:
-        return
-    
-    indexs = get_ob_datetime_multi_index(order_book_ids, start_date, end_date)
-    df = pd.DataFrame(data)
-    df = df.set_index(['order_book_id', 'trading_date'])
-    df = df.reindex(df.index.union(indexs)).groupby(level=0).ffill().reindex(indexs)
-    if df.empty:
-        return None
-    return df
+# -*- coding: utf-8 -*-
+import six
+import datetime
+import warnings
+import bisect
+
+import pandas as pd
+import numpy as np
+from dateutil.relativedelta import relativedelta
+from rqdatac.validators import (
+    ensure_string,
+    ensure_string_in,
+    ensure_list_of_string,
+    ensure_date_int,
+    ensure_date_or_today_int,
+    ensure_date_range,
+    check_items_in_container,
+    ensure_order_book_ids,
+    ensure_instruments,
+)
+from rqdatac.client import get_client
+from rqdatac.decorators import export_as_api, ttl_cache
+from rqdatac.utils import int8_to_datetime, to_datetime, date_to_int8, to_date
+from rqdatac.services.calendar import current_trading_date, is_trading_date, get_next_trading_date, get_trading_dates
+from rqdatac.services.basic import instruments
+from rqdatac.services import get_price
+
+
+@export_as_api
+def get_dominant_future(underlying_symbol, start_date=None, end_date=None, rule=0, rank=1, market="cn"):
+    import warnings
+
+    msg = "'get_dominant_future' is deprecated, please use 'futures.get_dominant' instead"
+    warnings.warn(msg, category=DeprecationWarning, stacklevel=2)
+    return get_dominant(underlying_symbol, start_date, end_date, rule, rank, market)
+
+
+@export_as_api(namespace='futures')
+def get_dominant(underlying_symbol, start_date=None, end_date=None, rule=0, rank=1, market="cn"):
+    """获取指定期货品种当日对应的主力合约
+
+    :param underlying_symbol: 如'IF' 'IC'
+    :param start_date: 如 '2015-01-07' (Default value = None)
+    :param end_date: 如 '2015-01-08' (Default value = None)
+    :param market:  (Default value = "cn")
+    :param rule:  主力合约规则 (Default value = 0)
+        0：在rule=1的规则上，增加约束(曾做过主力合约的合约，一旦被换下来后，不会再被选上)
+        1：合约首次上市时，以当日收盘同品种持仓量最大者作为从第二个交易日开始的主力合约，当同品种其他合约持仓量在收盘后
+           超过当前主力合约1.1倍时，从第二个交易日开始进行主力合约的切换。日内不会进行主力合约的切换
+    :param rank:  (Default value = 1):
+        1: 主力合约
+        2: 次主力合约
+        3：次次主力合约
+    :returns: pandas.Series
+        返回参数指定的具体主力合约名称
+
+    """
+    if not isinstance(underlying_symbol, six.string_types):
+        raise ValueError("invalid underlying_symbol: {}".format(underlying_symbol))
+
+    check_items_in_container(rule, [0, 1], 'rule')
+    check_items_in_container(rank, [1, 2, 3], 'order')
+
+    underlying_symbol = underlying_symbol.upper()
+
+    if start_date:
+        start_date = ensure_date_int(start_date)
+
+    if end_date:
+        end_date = ensure_date_int(end_date)
+    elif start_date:
+        end_date = start_date
+
+    if rank == 1:
+        result = get_client().execute(
+            "futures.get_dominant", underlying_symbol, start_date, end_date, rule, market=market)
+    else:
+        result = get_client().execute(
+            "futures.get_dominant_v2", underlying_symbol, start_date, end_date, rule, rank, market=market)
+
+    if not result:
+        return
+    df = pd.DataFrame(result)
+    df["date"] = df["date"].apply(int8_to_datetime)
+    return df.set_index("date").sort_index()["dominant"]
+
+
+@ttl_cache(3600)
+def current_real_contract(ob, market):
+    """获取指定期货品种当日对应的真实合约"""
+    date = current_trading_date(market)
+    r = get_dominant(ob, date, date, market=market)
+    if isinstance(r, pd.Series) and r.size == 1:
+        return r[0]
+    return None
+
+
+_FIELDS = [
+    "margin_type",
+    "long_margin_ratio",
+    "short_margin_ratio",
+    "commission_type",
+    "open_commission_ratio",
+    "close_commission_ratio",
+    "close_commission_today_ratio",
+]
+
+
+@export_as_api
+def future_commission_margin(order_book_ids=None, fields=None, hedge_flag="speculation"):
+    import warnings
+
+    msg = "'future_commission_margin' is deprecated, please use 'futures.get_commission_margin' instead"
+    warnings.warn(msg, category=DeprecationWarning, stacklevel=2)
+    return get_commission_margin(order_book_ids, fields, hedge_flag)
+
+
+@export_as_api(namespace='futures')
+def get_commission_margin(order_book_ids=None, fields=None, hedge_flag="speculation"):
+    """获取期货保证金和手续费数据
+
+    :param order_book_ids: 期货合约, 支持 order_book_id 或 order_book_id list,
+        若不指定则默认获取所有合约 (Default value = None)
+    :param fields: str 或 list, 可选字段有： 'margin_type', 'long_margin_ratio', 'short_margin_ratio',
+            'commission_type', 'open_commission_ratio', 'close_commission_ratio',
+            'close_commission_today_ratio', 若不指定则默认获取所有字段 (Default value = None)
+    :param hedge_flag: str, 账户对冲类型, 可选字段为: 'speculation', 'hedge',
+            'arbitrage', 默认为'speculation', 目前仅支持'speculation' (Default value = "speculation")
+    :returns: pandas.DataFrame
+
+    """
+    if order_book_ids:
+        order_book_ids = ensure_list_of_string(order_book_ids)
+
+    if fields is None:
+        fields = _FIELDS
+    else:
+        fields = ensure_list_of_string(fields, "fields")
+        check_items_in_container(fields, _FIELDS, "fields")
+
+    hedge_flag = ensure_string(hedge_flag, "hedge_flag")
+    if hedge_flag not in ["speculation", "hedge", "arbitrage"]:
+        raise ValueError("invalid hedge_flag: {}".format(hedge_flag))
+
+    ret = get_client().execute("futures.get_commission_margin", order_book_ids, fields, hedge_flag)
+    return pd.DataFrame(ret)
+
+
+@export_as_api
+def get_future_member_rank(order_book_id, trading_date=None, info_type='volume'):
+    import warnings
+
+    msg = "'get_future_member_rank' is deprecated, please use 'futures.get_member_rank' instead"
+    warnings.warn(msg, category=DeprecationWarning, stacklevel=2)
+    return get_member_rank(order_book_id, trading_date, info_type)
+
+
+@export_as_api(namespace='futures')
+def get_member_rank(obj, trading_date=None, rank_by='volume', **kwargs):
+    """获取指定日期最近的期货会员排名数据
+    :param obj： 期货合约或品种代码
+    :param trading_date: 日期
+    :param rank_by: 排名依据字段
+    :keyword start_date
+    :keyword end_date
+    :returns pandas.DataFrame or None
+    """
+    if not kwargs:
+        trading_date = ensure_date_or_today_int(trading_date)
+        ret = get_client().execute("futures.get_member_rank", obj, trading_date, rank_by)
+    else:
+        start_date = kwargs.pop("start_date", None)
+        end_date = kwargs.pop("end_date", None)
+        if kwargs:
+            raise ValueError('unknown kwargs: {}'.format(kwargs))
+        elif start_date and end_date:
+            start_date, end_date = ensure_date_int(start_date), ensure_date_int(end_date)
+            ret = get_client().execute("futures.get_member_rank_v2", obj, start_date, end_date, rank_by)
+        else:
+            raise ValueError('please ensure start_date and end_date exist')
+
+    if not ret:
+        return
+
+    df = pd.DataFrame(ret).sort_values(by=['trading_date', 'rank'])
+    df.set_index('trading_date', inplace=True)
+    return df
+
+
+@export_as_api(namespace="futures")
+def get_warehouse_stocks(underlying_symbols, start_date=None, end_date=None, market="cn"):
+    """获取时间区间内期货的注册仓单
+
+    :param underlying_symbols: 期货品种, 支持列表查询
+    :param start_date: 如'2015-01-01', 如果不填写则为去年的当日日期
+    :param end_date: 如'2015-01-01', 如果不填写则为当日日期
+    :param market: 市场, 默认为"cn"
+    :return: pd.DataFrame
+
+    """
+    underlying_symbols = ensure_list_of_string(underlying_symbols, name="underlying_symbols")
+    start_date, end_date = ensure_date_range(start_date, end_date, delta=relativedelta(years=1))
+
+    # 有新老两种 symbol 时对传入的 underlying_symbols 需要对应成新的 symbol, 并对并行期结束后仍使用老的 symbol 予以警告
+    multi_symbol_map = {'RO': 'OI', 'WS': 'WH', 'ER': 'RI', 'TC': 'ZC', 'ME': 'MA'}
+    symbol_date_map = {'RO': 20130515, 'WS': 20130523, 'ER': 20130523, 'TC': 20160408, 'ME': 20150515}
+    for symbol in set(underlying_symbols) & set(multi_symbol_map):
+        date_line = symbol_date_map[symbol]
+        if end_date > date_line:
+            import warnings
+            msg = 'You are using the old symbol: {}, however the new symbol: {} is available after {}.'.format(symbol, multi_symbol_map[symbol], date_line)
+            warnings.warn(msg, category=DeprecationWarning, stacklevel=2)
+
+    # 对传入的 underlying_symbols 依照 multi_symbol_map 生成一个对照 DataFrame
+    symbol_map_df = pd.DataFrame([(symbol, multi_symbol_map.get(symbol, symbol)) for symbol in set(underlying_symbols)],
+                                 columns=['origin', 'new'])
+    # 将 underlying_symbols 中 所有老的 symbol 对应为新的再去 mongo 查询
+    underlying_symbols = list(symbol_map_df.new.unique())
+    ret = get_client().execute("futures.get_warehouse_stocks", underlying_symbols, start_date, end_date, market=market)
+    if not ret:
+        return
+    columns = ["date", "underlying_symbol", "on_warrant", "exchange", 'effective_forecast', 'warrant_units',
+               'contract_multiplier', 'deliverable']
+    df = pd.DataFrame(ret, columns=columns)
+
+    df = df.merge(symbol_map_df, left_on='underlying_symbol', right_on='new')
+    df.drop(['underlying_symbol', 'new'], axis=1, inplace=True)
+    df.rename(columns={'origin': 'underlying_symbol'}, inplace=True)
+    df.set_index(['date', 'underlying_symbol'], inplace=True)
+    return df.sort_index()
+
+
+@export_as_api(namespace="futures")
+def get_contract_multiplier(underlying_symbols, start_date=None, end_date=None, market="cn"):
+    """获取时间区间内期货的合约乘数
+
+    :param underlying_symbols: 期货品种, 支持列表查询
+    :param start_date: 开始日期, 如'2015-01-01', 如果不填写则取underlying_symbols对应实际数据最早范围
+    :param end_date: 结束日期, 如'2015-01-01', 如果不填写则为当日前一天
+    :param market: 市场, 默认为"cn", 当前仅支持中国市场
+    :return: pd.DataFrame
+
+    """
+    underlying_symbols = ensure_list_of_string(underlying_symbols, name="underlying_symbols")
+    ret = get_client().execute("futures.get_contract_multiplier", underlying_symbols)
+    if not ret:
+        return
+
+    # 因 mongo 数据为时间范围，要返回每一天的数据，需复制合约乘数数据至至范围内所有 trading_date
+    if start_date:
+        start_date = to_datetime(start_date)
+    if not end_date:
+        end_date = datetime.datetime.today() - datetime.timedelta(days=1)
+    end_date = to_datetime(end_date)
+
+    def fill(group_df):
+        # 根据当前合约日期范围及给定范围内获取所有 trading_date
+        date_min, date_max = group_df['effective_date'].min(), group_df['cancel_date'].max()
+        if start_date is not None:
+            date_min = max(start_date, date_min)
+        date_max = min(date_max, end_date)
+        trading_dates = pd.to_datetime(get_trading_dates(date_min, date_max)+group_df['effective_date'].to_list()).unique()
+
+        # 使用 trading_dates 作为 index 插入并填充数据
+        everyday_df = group_df.set_index(['effective_date']).reindex(trading_dates).sort_index().ffill().reset_index().rename(columns={'index': 'date'})
+        everyday_df = everyday_df[(everyday_df['date'] >= date_min) & (everyday_df['date'] <= date_max)]
+
+        return everyday_df
+
+    df = pd.DataFrame(ret).groupby(by=['underlying_symbol']).apply(fill)
+
+    df = df[['date', 'underlying_symbol', 'exchange', 'contract_multiplier']]
+    df.set_index(['underlying_symbol', 'date'], inplace=True)
+    df.sort_index(inplace=True)
+    return df
+
+
+@export_as_api(namespace='futures')
+def get_current_basis(order_book_ids, market='cn'):
+    """获取股指期货的实时基差指标
+
+    :param order_book_ids: str or str list	合约代码
+    :param market: str	默认是中国内地市场('cn') 。可选'cn' - 中国内地市场；
+    :return: DataFrame with below fields:
+        字段	类型	说明
+        order_book_id	str	合约代码
+        datetime	datetime	时间戳
+        index	str	指数合约
+        index_px	float	指数最新价格
+        future_px	float	期货最新价格
+        basis	 float	升贴水， 等于期货合约收盘价- 对应指数收盘价
+        basis_rate	float	升贴水率(%)，（期货合约收盘价- 对应指数收盘价）/对应指数收盘价*100
+        basis_annual_rate	float	年化升贴水率（%), basis_rate *(250/合约到期剩余交易日）
+    """
+    ins_list = ensure_instruments(order_book_ids, 'Future')
+    today_str = datetime.date.today().strftime('%Y-%m-%d')
+    underlying_id_map = {}
+    remaining_days_map = {}
+
+    for ins in ins_list:
+        if ins.industry_name != '股指':
+            warnings.warn(
+                'expect 股指期货, got {}({})!'.format(ins.industry_name, ins.order_book_id),
+                stacklevel=0
+            )
+            continue
+        if ins.listed_date == '0000-00-00' or (ins.listed_date > today_str) or (
+                ins.de_listed_date != '0000-00-00' and ins.de_listed_date < today_str):
+            warnings.warn('inactive order_book_id: {}'.format(ins.order_book_id), stacklevel=0)
+            continue
+        underlying_id_map[ins.order_book_id] = ins.underlying_order_book_id
+        remaining_days_map[ins.order_book_id] = len(get_trading_dates(today_str, ins.de_listed_date)) - 1
+    if not underlying_id_map:
+        return None
+    futures = list(underlying_id_map.keys())
+    indexes = list(set(underlying_id_map.values()))
+
+    data = {future: {'order_book_id': future, 'index': index} for future, index in underlying_id_map.items()}
+    from ..services.live import current_snapshot
+    source = {sn.order_book_id: sn for sn in current_snapshot(futures + indexes, market=market)}
+    if not source:
+        return None
+
+    for future, index in underlying_id_map.items():
+        d = data[future]
+        f = source[future]
+        i = source[index]
+        d['datetime'] = f['datetime']
+        d['index_px'] = i['last']
+        d['future_px'] = f['settlement'] if f['settlement'] == f['settlement'] else f['last']
+        d['basis'] = d['future_px'] - d['index_px']
+        d['basis_rate'] = d['basis'] / d['index_px'] * 100
+        n = remaining_days_map[future]
+        if n <= 0:
+            d['basis_annual_rate'] = float('nan')
+        else:
+            d['basis_annual_rate'] = d['basis_rate'] * (250 / n)
+
+    df = pd.DataFrame(list(data.values())).set_index('order_book_id')
+    return df
+
+
+VALID_FIELDS_MAP = {
+    '1d': [
+        "open", "high", "low", "close", "index", "close_index",
+        "basis", "basis_rate", "basis_annual_rate",
+        "settlement", "settle_basis", "settle_basis_rate", "settle_basis_annual_rate"
+    ],
+    '1m': [
+        "open", "high", "low", "close", "index", "close_index",
+        "basis", "basis_rate", "basis_annual_rate"
+    ],
+    'tick': [
+        "index", "future_px", "index_px",
+        "basis", "basis_rate", "basis_annual_rate",
+    ]
+}
+
+FUTURE_PRICE_FIELDS_MAP = {
+    '1d': ['close', 'open', 'high', 'low', 'settlement'],
+    '1m': ['close', 'open', 'high', 'low'],
+    'tick': ['last']
+}
+
+
+@export_as_api(namespace="futures")
+def get_basis(order_book_ids, start_date=None, end_date=None, fields=None, frequency='1d', market="cn"):
+    """ 获取股指期货升贴水信息.
+
+    :param order_book_ids: 期货合约, 支持 order_book_id 或 order_book_id list.
+    :param start_date: 开始时间, 若不传, 为 end_date 前3个月.
+    :param end_date: 结束时间, 若不传, 为 start_date 后3个月, 如果 start_date 也不传, 则默认为最近3个月.
+    :param fields: 需要返回的字段, 若不传则返回所有字段, 支持返回的字段包括
+        open, high, low, close, index, close_index, basis, basis_rate, basis_annual_rate.
+    :param frequency: 数据频率, 默认 '1d', 其他可选 {'1m', 'tick'}
+        frequency=tick时, fields为index, future_px, index_px, basis, basis_rate, basis_annual_rate
+    :param market: 市场, 默认'cn'
+    :return: MultiIndex DataFrame.
+    """
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    ensure_string_in(frequency, ('1d', '1m', 'tick'), 'frequency')
+
+    insts = instruments(order_book_ids)
+    if insts is None:
+        return None
+    if not isinstance(order_book_ids, list):
+        insts = [insts]
+    insts = [
+        x for x in insts
+        if x.type == "Future" and x.listed_date != "0000-00-00" and x.industry_name == "股指"
+    ]
+    if not insts:
+        return None
+
+    underlying_id_map = {x.order_book_id: x.underlying_order_book_id for x in insts}
+    delisted_map = {x.order_book_id: to_date(x.de_listed_date) for x in insts}
+    close_field = 'close' if frequency != 'tick' else 'last'
+
+    if fields is None:
+        fields = VALID_FIELDS_MAP[frequency]
+        need_basis, need_settlement_basis, need_index_price = True, (frequency == '1d'), True
+        future_price_fields = FUTURE_PRICE_FIELDS_MAP[frequency]
+    else:
+        fields = ensure_list_of_string(fields)
+        check_items_in_container(fields, VALID_FIELDS_MAP[frequency], 'fields')
+        need_basis, need_settlement_basis = False, False
+        FUTURE_PRICE_FIELDS = FUTURE_PRICE_FIELDS_MAP[frequency]
+        future_price_fields = set()
+        need_index_price = False
+        for f in fields:
+            if f.startswith('basis') or f == 'future_px':
+                future_price_fields.add(close_field)
+                need_basis, need_index_price = True, f.startswith('basis')
+            elif f == 'index_px' or f == 'close_index':
+                need_index_price = True
+            elif f.startswith('settle'):
+                future_price_fields.add('settlement')
+                need_settlement_basis, need_index_price = True, True
+            elif f in FUTURE_PRICE_FIELDS:
+                future_price_fields.add(f)
+        future_price_fields = list(future_price_fields)
+
+    order_book_ids = [x.order_book_id for x in insts]
+    future_price = get_price.get_price(
+        order_book_ids, start_date, end_date, frequency=frequency, fields=future_price_fields,
+        expect_df=True, market=market
+    )
+    if future_price is None:
+        return None
+
+    future_price["index"] = future_price.index.get_level_values("order_book_id").map(underlying_id_map)
+
+    _all_trading_dates = get_trading_dates(start_date, max(delisted_map.values()))
+    _dates_remain_cache = {
+        (s, e): (bisect.bisect_left(_all_trading_dates, e) - bisect.bisect_left(_all_trading_dates, s))
+        for s in get_trading_dates(start_date, end_date)
+        for e in delisted_map.values()
+    }
+
+    def _calc_annual_rate(row, rate_field):
+        # row.name[1] is current date.
+        order_book_id, current_date = row.name
+        dates_remain = _dates_remain_cache[(current_date.date(), delisted_map[order_book_id])]
+        if dates_remain == 0:
+            # 在到期的时候, basis_annual_rate 的值本身也没有什么意义, 所以直接赋值为 nan.
+            return float("nan")
+        else:
+            return row[rate_field] * 250 / dates_remain
+
+    if need_index_price:
+        underlying_ids = list({x.underlying_order_book_id for x in insts})
+        if frequency == '1d':
+            from rqdatac.services.detail import get_price_df
+            index_close = get_price_df.get_future_indx_daybar(underlying_ids, start_date, end_date, fields=["close"])
+            date_field = 'date'
+        else:
+            index_close = get_price.get_price(underlying_ids, start_date, end_date, frequency=frequency, fields=close_field, expect_df=True)
+            date_field = 'datetime'
+        index_close.columns = ['close_index']
+        future_price = pd.merge_asof(
+            future_price.reset_index().sort_values(date_field),
+            index_close.reset_index().rename(
+                columns={'order_book_id': 'index'}
+            ).sort_values(date_field),
+            on=date_field,
+            by='index',
+            direction='backward'
+        )
+        future_price.set_index(['order_book_id', date_field], inplace=True)
+        future_price.sort_index(inplace=True)
+        future_price.bfill(axis=0, inplace=True)
+
+    if need_basis:
+        future_price["basis"] = future_price[close_field] - future_price["close_index"]
+        future_price["basis_rate"] = future_price["basis"] / future_price["close_index"] * 100
+        future_price["basis_annual_rate"] = future_price.apply(lambda x: _calc_annual_rate(x, "basis_rate"), axis=1)
+
+    if need_settlement_basis:
+        future_price["settle_basis"] = future_price["settlement"] - future_price["close_index"]
+        future_price["settle_basis_rate"] = future_price["settle_basis"] / future_price["close_index"] * 100
+        future_price["settle_basis_annual_rate"] = future_price.apply(
+            lambda x: _calc_annual_rate(x, "settle_basis_rate"), axis=1
+        )
+
+    if frequency == 'tick':
+        future_price.rename(columns={'close_index': 'index_px', close_field: 'future_px'}, inplace=True)
+
+    res = future_price[fields]
+    return res
+
+
+VALID_ADJUST_METHODS = ['prev_close_spread', 'open_spread', 'prev_close_ratio', 'open_ratio']
+
+
+@ttl_cache(1800)
+def _get_future_factors_df(market='cn'):
+    """ 获取所有复权因子表 """
+    data = get_client().execute('futures.__internal__get_future_factors', market=market)
+    df = pd.DataFrame(data)
+    df['ex_date'] = df['ex_date'].apply(int8_to_datetime)
+    df.set_index(['underlying_symbol', 'ex_date'], inplace=True)
+    df.sort_index(inplace=True)
+    return df
+
+
+@export_as_api(namespace='futures')
+def get_ex_factor(underlying_symbols, start_date=None, end_date=None, adjust_method='prev_close_spread', market='cn'):
+    """ 获取期货复权因子
+
+    :param underlying_symbols: 期货合约品种，str or list
+    :param start_date: 开始日期
+    :param end_date: 结束日期
+    :param adjust_method: 复权方法，prev_close_spread, prev_close_ratio, open_spread, open_ratio,
+    默认为‘prev_close_spread'
+    :param market: 默认是中国内地市场('cn') 。可选'cn' - 中国内地市场
+    :return: DataFrame
+    """
+    df = _get_future_factors_df(market)
+    valid_underlying_symbols = df.index.get_level_values('underlying_symbol').unique().tolist()
+    underlying_symbols = ensure_list_of_string(underlying_symbols, 'underlying_symbols')
+    check_items_in_container(adjust_method, VALID_ADJUST_METHODS, 'adjust_method')
+    check_items_in_container(underlying_symbols, valid_underlying_symbols, 'underlying_symbols')
+
+    factor = df.loc[underlying_symbols, adjust_method]
+    factor.name = 'ex_factor'
+    factor = factor.reset_index()
+
+    spread = adjust_method.endswith('spread')
+
+    def _process(x):
+        x['ex_end_date'] = x['ex_date'].shift(-1) - pd.offsets.DateOffset(days=1)
+        if spread:
+            x['ex_cum_factor'] = x['ex_factor'].cumsum()
+        else:
+            x['ex_cum_factor'] = x['ex_factor'].cumprod()
+        return x
+
+    factor = factor.groupby('underlying_symbol', as_index=False).apply(_process)
+    if start_date and end_date:
+        start_date, end_date = to_datetime(start_date), to_datetime(end_date)
+        factor = factor[(start_date <= factor['ex_date']) & (factor['ex_date'] <= end_date)]
+    # _get_future_factors_df 已经排序过了，此处无需再次排序
+    return factor.set_index('ex_date')
+
+
+def __internal_get_ex_factor(underlying_symbols, adjust_type, adjust_method):
+    """ 内部使用，获取复权因子，提供给get_dominant_price进行复权计算用
+    :return: pd.Series
+    """
+    df = _get_future_factors_df()
+    df = df.loc[underlying_symbols]
+
+    factor = df[adjust_method]
+    factor.name = 'ex_factor'
+    factor = factor.reset_index()
+    pre = adjust_type == 'pre'
+    ratio = adjust_method.endswith('ratio')
+
+    def _process(x):
+        if ratio:
+            x['ex_cum_factor'] = x['ex_factor'].cumprod()
+            if pre:
+                x['ex_cum_factor'] = x['ex_cum_factor'] / x['ex_cum_factor'].iloc[-1]
+        else:
+            x['ex_cum_factor'] = x['ex_factor'].cumsum()
+            if pre:
+                x['ex_cum_factor'] = x['ex_cum_factor'] - x['ex_cum_factor'].iloc[-1]
+
+        # tds 是从小到大排列的， 因此reindex后无需再sort
+        return x.set_index('ex_date')
+
+    factor = factor.groupby('underlying_symbol', as_index=True).apply(_process)
+    return factor['ex_cum_factor']
+
+
+DOMINANT_PRICE_ADJUST_FIELDS = [
+    'open', 'high', 'low', 'close', 'last', 'limit_up', 'limit_down', 'settlement', 'prev_settlement', 'prev_close',
+    'a1', 'a2', 'a3', 'a4', 'a5', 'b1', 'b2', 'b3', 'b4', 'b5'
+]
+
+
+@export_as_api(namespace='futures')
+def get_dominant_price(
+        underlying_symbols, start_date=None, end_date=None,
+        frequency='1d', fields=None, adjust_type='pre', adjust_method='prev_close_spread'
+):
+    """ 获取主力合约行情数据
+
+    :param underlying_symbols: 期货合约品种，可传入 underlying_symbol, underlying_symbol list
+    :param start_date: 开始日期, 最小日期为 20210104
+    :param end_date: 结束日期
+    :param frequency: 历史数据的频率。 支持/日/分钟/tick 级别的历史数据，默认为'1d'。
+        1m- 分钟线，1d-日线，分钟可选取不同频率，例如'5m'代表 5 分钟线
+    :param fields: 字段名称列表
+    :param adjust_type: 复权方式，不复权 - none，前复权 - pre，后复权 - post
+    :param adjust_method: 复权方法 ，prev_close_spread/open_spread:基于价差复权因子进行复权，
+        prev_close_ratio/open_ratio:基于比例复权因子进行复权，
+        默认为‘prev_close_spread',adjust_type为None 时，adjust_method 复权方法设置无效
+    :return: MultiIndex DataFrame
+    """
+    # ensure underlying symbols list
+    from ..services.get_price import get_price
+    if not isinstance(underlying_symbols, list):
+        underlying_symbols = [underlying_symbols]
+    if fields and not isinstance(fields, list):
+        fields = [fields]
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    if start_date < 20100104:
+        raise ValueError('expect start_date >= 20100104, get {}'.format(start_date))
+    # ensure adjust_type and adjust_method
+    check_items_in_container(adjust_type, ['none', 'pre', 'post'], 'adjust_type')
+    check_items_in_container(adjust_method, VALID_ADJUST_METHODS, 'adjust_method')
+
+    _date_key = 'date' if frequency == '1d' else 'trading_date'
+    _fields = fields
+    if fields and frequency != '1d' and 'trading_date' not in fields:
+        _fields = ['trading_date'] + fields
+
+    obs = [u + '88' for u in underlying_symbols]
+    df = get_price(
+        order_book_ids=obs, start_date=start_date, end_date=end_date,
+        frequency=frequency, adjust_type='none', fields=_fields, expect_df=True
+    )
+    if df is None:
+        return
+
+    df.reset_index(inplace=True)
+    df['underlying_symbol'] = df['order_book_id'].str[:-2]
+    df.set_index(['underlying_symbol', _date_key], inplace=True)
+    if adjust_type != 'none':
+        # 复权调整
+        factor = __internal_get_ex_factor(underlying_symbols, adjust_type, adjust_method)
+        factor = factor.reindex(factor.index.union(df.index.unique()))
+        factor = factor.groupby(level=0).ffill()
+        values = factor.loc[df.index].values
+        _fields = fields if fields else df.columns.tolist()
+        adjust_fields = [f for f in DOMINANT_PRICE_ADJUST_FIELDS if f in _fields]
+        if adjust_method.endswith('spread'):
+            for field in adjust_fields:
+                df[field] += values
+        elif adjust_method.endswith('ratio'):
+            for field in adjust_fields:
+                df[field] *= values
+        if 'total_turnover' in df.columns:
+            df['total_turnover'] = 0
+
+    if frequency != '1d':
+        df = df.reset_index().set_index(['underlying_symbol', 'datetime'])
+    df.sort_index(inplace=True)
+    del df['order_book_id']
+    return df[fields] if fields else df
+
+
+def get_ob_datetime_multi_index(
+    order_book_ids,
+    start_date,
+    end_date,
+    names=['order_book_id', 'trading_date']
+):
+    start_date = to_datetime(start_date).strftime("%Y-%m-%d")
+    end_date = to_datetime(end_date).strftime("%Y-%m-%d")
+    insts = instruments(order_book_ids)
+    indexs = []
+    dates = get_trading_dates(start_date, end_date)
+    index = pd.to_datetime(dates)
+    for i in insts:
+        oid = i.order_book_id
+        listed_date = i.listed_date
+        de_listed_date = i.de_listed_date if i.de_listed_date != '0000-00-00' else '9999-99-99'
+        start = pd.Timestamp(max(start_date, listed_date))
+        end = pd.Timestamp(min(end_date, de_listed_date))
+        start_pos, end_pos = index.searchsorted(start), index.searchsorted(end)
+        _index = index[start_pos:end_pos+1]
+        indexs.extend([(oid, i) for i in _index])
+
+    return pd.MultiIndex.from_tuples(indexs, names=names)
+
+
+TRADING_PARAMETERS_FIELDS = [
+    'long_margin_ratio',
+    'short_margin_ratio',
+    'commission_type',
+    'open_commission',
+    'close_commission',
+    'discount_rate',
+    'close_commission_today',
+    'non_member_limit_rate',
+    'client_limit_rate',
+    'non_member_limit',
+    'client_limit',
+    'min_order_quantity',
+]
+
+
+@export_as_api(namespace='futures')
+def get_trading_parameters(order_book_ids, start_date=None, end_date=None, fields=None, market='cn'):
+    """ 获取期货交易参数信息
+
+    :param order_book_ids: 期货合约代码或代码列表
+    :param start_date: 开始日期，如 '2019-01-01'，若不指定，默认为当前交易日
+                       未指定时，若查询时间在 T 日 8.40pm 前，返回 T 日数据，否则返回 T+1 日数据
+    :param end_date: 结束日期，如 '2023-01-01'，若不指定，默认为当前交易日
+                     开始日期和结束日期需同时传入或同时不传入
+    :param fields: 所需字段或字段列表，不指定则返回全部字段，可选:
+        [ 'long_margin_ratio', 'short_margin_ratio', 'commission_type', 'open_commission', 
+          'close_commission', 'discount_rate, 'close_commission_today',
+          'non_member_limit_rate', 'client_limit_rate', 'non_member_limit', 'client_limit',
+          'min_order_quantity',
+        ]
+    :param market: 目前只支持中国市场，默认为 'cn'
+
+    :return: DataFrame(MultiIndex(order_book_id, trading_date)) or None
+    
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, type='Future', market=market)
+    # 只存了真实合约信息
+    order_book_ids = list(
+        filter(
+            lambda x: not x.endswith(('88', '99', '888', '889', '88A2', '88A3')),
+            order_book_ids
+        )
+    )
+    if fields is None:
+        fields = TRADING_PARAMETERS_FIELDS
+    else:
+        fields = ensure_list_of_string(fields, 'fields')
+        check_items_in_container(fields, TRADING_PARAMETERS_FIELDS, 'fields')
+    now = datetime.datetime.now()
+    if is_trading_date(now):
+        # dps 任务在 20:40 第一次更新夜盘信息
+        if (now.hour, now.minute) >= (20, 40):
+            day = get_next_trading_date(now)
+        else:
+            day = now.date()
+    else:
+        day = get_next_trading_date(now)
+    day = date_to_int8(day)
+    if start_date is None and end_date is None:
+        start_date = end_date = day
+    elif start_date and end_date:
+        start_date, end_date = ensure_date_range(start_date, end_date)
+        # 数据是不连续向后填补的，因此不能返回还未有记录的日期
+        end_date = min(end_date, day)
+        if end_date < start_date:
+            return None
+    else:
+        raise ValueError('start_date and end_date should be used together or not at the same time')
+
+    insts = instruments(order_book_ids)
+    _oids = []
+    # 筛选位于 start_date 与 end_date 间的 ob
+    for i in insts:
+        listed_date = int(i.listed_date.replace('-', ''))
+        de_listed_date = i.de_listed_date if i.de_listed_date != '0000-00-00' else '9999-99-99'
+        de_listed_date = int(de_listed_date.replace('-', ''))
+        if start_date <= de_listed_date and end_date >= listed_date:
+            _oids.append(i.order_book_id)
+    order_book_ids = _oids
+
+    # 交易参数数据已去重所以不连续，获取全部数据
+    data = get_client().execute('futures.get_trading_parameters', order_book_ids, fields, market)
+    if not data:
+        return
+    
+    indexs = get_ob_datetime_multi_index(order_book_ids, start_date, end_date)
+    df = pd.DataFrame(data)
+    df = df.set_index(['order_book_id', 'trading_date'])
+    df = df.reindex(df.index.union(indexs)).groupby(level=0).ffill().reindex(indexs)
+    if df.empty:
+        return None
+    return df
```

## rqdatac/services/get_capital_flow.py

 * *Ordering differences only*

```diff
@@ -1,386 +1,386 @@
-# -*- coding: utf-8 -*-
-import datetime
-
-import pandas as pd
-import numpy as np
-
-from rqdatac.services.basic import instruments
-from rqdatac.services.calendar import current_trading_date, get_next_trading_date
-from rqdatac.validators import (
-    ensure_string_in,
-    ensure_order_book_ids,
-    ensure_date_range,
-    check_items_in_container,
-    ensure_list_of_string,
-    ensure_instruments,
-)
-from rqdatac.utils import (
-    int8_to_datetime_v,
-    int14_to_datetime_v,
-    int17_to_datetime_v,
-    int17_to_datetime,
-    date_to_int8,
-    get_tick_value,
-    convert_bar_to_multi_df,
-)
-from rqdatac.client import get_client
-from rqdatac.decorators import export_as_api
-from rqdatac.share.errors import PermissionDenied, MarketNotSupportError
-
-
-DAYBAR_FIELDS = MINBAR_FIELDS = ["buy_volume", "buy_value", "sell_volume", "sell_value"]
-TICKBAR_FIELDS = ["datetime", "direction", "volume", "value"]
-
-
-def get_capital_flow_daybar(order_book_ids, start_date, end_date, fields, duration=1, market="cn"):
-    data = get_client().execute(
-        "get_capital_flow_daybar", order_book_ids, start_date, end_date, fields, duration, market=market
-    )
-    data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
-    res = convert_bar_to_multi_df(data, 'date', fields, int8_to_datetime_v, 0.)
-    return res
-
-
-def get_today_capital_flow_minbar(order_book_ids, date, fields, duration, market="cn"):
-    data = get_client().execute("get_today_capital_flow_minbar", order_book_ids, date, fields, duration, market=market)
-    return convert_bar_to_multi_df(data, "datetime", fields, int14_to_datetime_v, 0.)
-
-
-def get_capital_flow_minbar(order_book_ids, start_date, end_date, fields, duration, market):
-    history_permission_denied = realtime_permission_denied = False
-    try:
-        data = get_client().execute(
-            "get_capital_flow_minbar", order_book_ids, start_date, end_date, fields, duration, market=market
-        )
-    except PermissionDenied:
-        history_permission_denied = True
-        data = []
-
-    if data:
-        data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
-        df = convert_bar_to_multi_df(data, 'datetime', fields, int14_to_datetime_v, 0.)
-    else:
-        df = None
-
-    live_date = current_trading_date()
-    if start_date > live_date or end_date < live_date:
-        return df
-
-    live_date_str = '%d-%02d-%02d' % (live_date // 10000, live_date % 10000 // 100, live_date % 100)
-    live_obs = set(
-        ins.order_book_id for ins in instruments(order_book_ids)
-        if ins.de_listed_date == '0000-00-00' or ins.de_listed_date >= live_date_str
-    )
-
-    if df is not None:
-        idx = df.index
-        for ob in idx.levels[0]:
-            if ob not in live_obs:
-                continue
-            loc = idx.get_loc(ob)
-            if date_to_int8(idx[loc.stop - 1][-1]) == live_date:
-                live_obs.remove(ob)
-
-    if not live_obs:
-        return df
-
-    try:
-        live_df = get_today_capital_flow_minbar(list(live_obs), live_date, fields, duration, market)
-    except PermissionDenied:
-        live_df = None
-        realtime_permission_denied = True
-    except MarketNotSupportError:
-        live_df = None
-
-    if history_permission_denied and realtime_permission_denied:
-        raise PermissionDenied("get_capital_flow_minbar")
-
-    if live_df is None:
-        return df
-
-    live_df = live_df[
-        live_df.index.get_level_values(1).date ==
-        datetime.date(live_date // 10000, live_date % 10000 // 100, live_date % 100)
-    ]
-
-    if df is None:
-        return live_df
-    df = pd.concat([df, live_df])
-    df.sort_index(inplace=True)
-    return df
-
-
-def get_today_capital_flow_tick(order_book_id, date, market="cn"):
-    data = get_client().execute("get_today_capital_flow_tick", order_book_id, date, market=market)
-    df = pd.DataFrame(data[0])
-    if df.empty:
-        return None
-    df.datetime = df.datetime.apply(int17_to_datetime)
-    df = df.astype({"direction": "i1", "volume": "u8", "value": "u8"})
-    df.set_index(['order_book_id', 'datetime'], inplace=True)
-    return df
-
-
-def get_capital_flow_tickbar(order_book_ids, start_date, end_date, fields,  market):
-    ins_list = ensure_instruments(order_book_ids)
-    order_book_ids = [ins.order_book_id for ins in ins_list]
-
-    start_date, end_date = ensure_date_range(start_date, end_date, datetime.timedelta(days=3))
-
-    history_permission_denied = realtime_permission_denied = False
-    try:
-        data = get_client().execute(
-            "get_capital_flow_tickbar", order_book_ids, start_date, end_date, fields, market=market
-        )
-    except PermissionDenied:
-        data = []
-        history_permission_denied = True
-
-    if data:
-        data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
-        df_list = []
-        for obid, d in data:
-            df = pd.DataFrame(d)
-            df['order_book_id'] = obid
-            df_list.append(df)
-
-        df = pd.concat(df_list)  # type: pd.DataFrame
-        df["datetime"] = int17_to_datetime_v(df["datetime"].values)
-        df.set_index(['order_book_id', 'datetime'], inplace=True)
-    else:
-        df = None
-
-    live_date = current_trading_date()
-    if start_date > live_date or end_date < live_date:
-        if history_permission_denied:
-            raise PermissionDenied("get_capital_flow_tick")
-        return df
-
-    live_date_str = '%d-%02d-%02d' % (live_date // 10000, live_date % 10000 // 100, live_date % 100)
-    live_dfs = []
-
-    def _to_trading_date(dt):
-        if 7 <= dt.hour < 18:
-            return datetime.datetime(year=dt.year, month=dt.month, day=dt.day)
-        return get_next_trading_date(dt - datetime.timedelta(hours=4))
-
-    for ins in ins_list:
-        if ins.de_listed_date != '0000-00-00' and ins.de_listed_date < live_date_str:
-            continue
-        try:
-            if df is not None and date_to_int8(_to_trading_date(
-                    df.loc[ins.order_book_id].index.max())) == live_date:
-                continue
-        except KeyError:
-            pass
-        try:
-            live_df = get_today_capital_flow_tick(ins.order_book_id, live_date, market=market)
-            if live_df is None:
-                continue
-            live_dfs.append(live_df)
-        except PermissionDenied:
-            realtime_permission_denied = True
-            break
-        except MarketNotSupportError:
-            pass
-
-    if history_permission_denied and realtime_permission_denied:
-        raise PermissionDenied("get_capital_flow_tick")
-
-    if not live_dfs:
-        return df
-
-    live_df = pd.concat(live_dfs)
-    return pd.concat([df, live_df])
-
-
-@export_as_api
-def get_capital_flow(order_book_ids, start_date=None, end_date=None, frequency="1d", market="cn"):
-    """获取资金流入流出数据
-    :param order_book_ids: 股票代码or股票代码列表, 如'000001.XSHE'
-    :param start_date: 开始日期
-    :param end_date: 结束日期
-    :param frequency: 默认为日线。日线使用 '1d', 分钟线 '1m'  快照 'tick' (Default value = "1d"),
-    :param market:  (Default value = "cn")
-    :returns: pandas.DataFrame or None
-    """
-    ensure_string_in(frequency, ("1d", "1m", "tick"), "frequency")
-    if frequency == "tick":
-        df = get_capital_flow_tickbar(order_book_ids, start_date, end_date, TICKBAR_FIELDS, market)
-        if isinstance(order_book_ids, str):
-            return df.droplevel(0)
-        return df
-
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    if frequency == "1d":
-        return get_capital_flow_daybar(order_book_ids, start_date, end_date, DAYBAR_FIELDS, 1, market)
-
-    return get_capital_flow_minbar(order_book_ids, start_date, end_date, MINBAR_FIELDS, 1, market)
-
-
-def _auction_field_type(field_name):
-    return (np.object_ if field_name == "order_book_id"
-            else np.uint64 if field_name == "datetime"
-            else np.float64)
-
-
-AUCTION_FIELDS = [
-    "open",
-    "last",
-    "high",
-    "low",
-    "limit_up",
-    "limit_down",
-    "prev_close",
-    "volume",
-    "total_turnover",
-    "a1",
-    "a2",
-    "a3",
-    "a4",
-    "a5",
-    "b1",
-    "b2",
-    "b3",
-    "b4",
-    "b5",
-    "a1_v",
-    "a2_v",
-    "a3_v",
-    "a4_v",
-    "a5_v",
-    "b1_v",
-    "b2_v",
-    "b3_v",
-    "b4_v",
-    "b5_v",
-]
-
-
-def get_auction_info(order_book_ids, start_date=None, end_date=None, auction_type='close', fields=None, market="cn"):
-    assert auction_type in ('open', 'close'), "auction_type must be 'open' or 'close'"
-
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    if not order_book_ids:
-        return None
-
-    start_date, end_date = ensure_date_range(start_date, end_date, datetime.timedelta(days=0))
-    if fields is None:
-        fields = AUCTION_FIELDS
-    else:
-        fields = ensure_list_of_string(fields, "fields")
-        check_items_in_container(fields, set(AUCTION_FIELDS), "fields")
-
-    history_permission_denied = realtime_permission_denied = False
-    try:
-        data = get_client().execute("get_{}_auction_info_daybar".format(auction_type), order_book_ids,
-                                    start_date, end_date, fields + ["datetime", "date"], market=market)
-    except PermissionDenied:
-        data = []
-        history_permission_denied = True
-
-    live_date = current_trading_date()
-    live_date_str = '%d-%02d-%02d' % (live_date // 10000, live_date % 10000 // 100, live_date % 100)
-
-    live_obs = set(
-        ins.order_book_id for ins in instruments(order_book_ids)
-        if ins.de_listed_date == '0000-00-00' or ins.de_listed_date > live_date_str
-    )
-    if data:
-        data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
-
-        extra_fields = ['open_interest', 'prev_settlement', 'date'] if any(
-            ['prev_settlement' in d for _, d in data]
-        ) else ['date']
-
-        df = convert_bar_to_multi_df(data, 'datetime', fields + extra_fields, int17_to_datetime_v, 0.)
-        if df is not None:
-            del df["date"]
-    else:
-        df = None
-
-    if start_date > live_date or end_date < live_date:
-        return df
-
-    if df is not None:
-        idx = df.index
-        for ob in idx.levels[0]:
-            if ob not in live_obs:
-                continue
-            loc = idx.get_loc(ob)
-            if date_to_int8(idx[loc.stop - 1][-1]) == live_date:
-                live_obs.remove(ob)
-
-    if not live_obs:
-        return df
-
-    try:
-        live_df = get_today_auction(list(live_obs), auction_type, live_date, market=market)
-    except PermissionDenied:
-        live_df = None
-        realtime_permission_denied = True
-    except MarketNotSupportError:
-        live_df = None
-
-    if history_permission_denied and realtime_permission_denied:
-        raise PermissionDenied("get_open_auction_info")
-
-    if live_df is None:
-        return df
-    if 'prev_settlement' in live_df.columns:
-        fields = fields + ['open_interest', 'prev_settlement']
-    if df is None:
-        return live_df[fields]
-    df = pd.concat([df, live_df[fields]])
-    df.sort_index(inplace=True)
-    return df
-
-
-def get_today_auction(order_book_ids, auction_type='close', today=None,  market="cn"):
-    if auction_type == 'close':
-        return
-        # ticks = get_client().execute('get_today_close_auction', order_book_ids, market=market)
-    else:
-        ticks = get_client().execute('get_today_open_auction', order_book_ids, today, market=market)
-    if not ticks:
-        return
-
-    fields = ["order_book_id", "datetime"] + AUCTION_FIELDS
-
-    if any(['prev_settlement' in tick for tick in ticks]):
-        fields += ['open_interest', 'prev_settlement']
-
-    dtype = np.dtype([(f, _auction_field_type(f)) for f in fields])
-    bars = np.array([tuple([get_tick_value(t, f) for f in fields]) for t in ticks], dtype=dtype)
-
-    df = pd.DataFrame(bars)
-    df.datetime = df.datetime.apply(int17_to_datetime)
-    df.set_index(["order_book_id", "datetime"], inplace=True)
-    return df
-
-
-@export_as_api
-def get_open_auction_info(order_book_ids, start_date=None, end_date=None, fields=None, market="cn"):
-    """获取盘前集合竞价数据
-    :param order_book_ids: 股票代码
-    :param start_date: 起始日期，默认为今天
-    :param end_date: 截止日期，默认为今天
-    :param fields: 需要获取的字段, 默认为所有字段
-    :param market:  (Default value = "cn")
-    :returns: pd.DataFrame or None
-    """
-    return get_auction_info(order_book_ids, start_date, end_date, 'open', fields, market)
-
-
-@export_as_api
-def get_close_auction_info(order_book_ids, start_date=None, end_date=None, fields=None, market="cn"):
-    """获取尾盘集合竞价数据
-    :param order_book_ids: 股票代码
-    :param start_date: 起始日期，默认为今天
-    :param end_date: 截止日期，默认为今天
-    :param fields: 需要获取的字段, 默认为所有字段
-    :param market:  (Default value = "cn")
-    :returns: pd.DataFrame or None
-    """
-    return get_auction_info(order_book_ids, start_date, end_date, 'close', fields, market)
+# -*- coding: utf-8 -*-
+import datetime
+
+import pandas as pd
+import numpy as np
+
+from rqdatac.services.basic import instruments
+from rqdatac.services.calendar import current_trading_date, get_next_trading_date
+from rqdatac.validators import (
+    ensure_string_in,
+    ensure_order_book_ids,
+    ensure_date_range,
+    check_items_in_container,
+    ensure_list_of_string,
+    ensure_instruments,
+)
+from rqdatac.utils import (
+    int8_to_datetime_v,
+    int14_to_datetime_v,
+    int17_to_datetime_v,
+    int17_to_datetime,
+    date_to_int8,
+    get_tick_value,
+    convert_bar_to_multi_df,
+)
+from rqdatac.client import get_client
+from rqdatac.decorators import export_as_api
+from rqdatac.share.errors import PermissionDenied, MarketNotSupportError
+
+
+DAYBAR_FIELDS = MINBAR_FIELDS = ["buy_volume", "buy_value", "sell_volume", "sell_value"]
+TICKBAR_FIELDS = ["datetime", "direction", "volume", "value"]
+
+
+def get_capital_flow_daybar(order_book_ids, start_date, end_date, fields, duration=1, market="cn"):
+    data = get_client().execute(
+        "get_capital_flow_daybar", order_book_ids, start_date, end_date, fields, duration, market=market
+    )
+    data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
+    res = convert_bar_to_multi_df(data, 'date', fields, int8_to_datetime_v, 0.)
+    return res
+
+
+def get_today_capital_flow_minbar(order_book_ids, date, fields, duration, market="cn"):
+    data = get_client().execute("get_today_capital_flow_minbar", order_book_ids, date, fields, duration, market=market)
+    return convert_bar_to_multi_df(data, "datetime", fields, int14_to_datetime_v, 0.)
+
+
+def get_capital_flow_minbar(order_book_ids, start_date, end_date, fields, duration, market):
+    history_permission_denied = realtime_permission_denied = False
+    try:
+        data = get_client().execute(
+            "get_capital_flow_minbar", order_book_ids, start_date, end_date, fields, duration, market=market
+        )
+    except PermissionDenied:
+        history_permission_denied = True
+        data = []
+
+    if data:
+        data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
+        df = convert_bar_to_multi_df(data, 'datetime', fields, int14_to_datetime_v, 0.)
+    else:
+        df = None
+
+    live_date = current_trading_date()
+    if start_date > live_date or end_date < live_date:
+        return df
+
+    live_date_str = '%d-%02d-%02d' % (live_date // 10000, live_date % 10000 // 100, live_date % 100)
+    live_obs = set(
+        ins.order_book_id for ins in instruments(order_book_ids)
+        if ins.de_listed_date == '0000-00-00' or ins.de_listed_date >= live_date_str
+    )
+
+    if df is not None:
+        idx = df.index
+        for ob in idx.levels[0]:
+            if ob not in live_obs:
+                continue
+            loc = idx.get_loc(ob)
+            if date_to_int8(idx[loc.stop - 1][-1]) == live_date:
+                live_obs.remove(ob)
+
+    if not live_obs:
+        return df
+
+    try:
+        live_df = get_today_capital_flow_minbar(list(live_obs), live_date, fields, duration, market)
+    except PermissionDenied:
+        live_df = None
+        realtime_permission_denied = True
+    except MarketNotSupportError:
+        live_df = None
+
+    if history_permission_denied and realtime_permission_denied:
+        raise PermissionDenied("get_capital_flow_minbar")
+
+    if live_df is None:
+        return df
+
+    live_df = live_df[
+        live_df.index.get_level_values(1).date ==
+        datetime.date(live_date // 10000, live_date % 10000 // 100, live_date % 100)
+    ]
+
+    if df is None:
+        return live_df
+    df = pd.concat([df, live_df])
+    df.sort_index(inplace=True)
+    return df
+
+
+def get_today_capital_flow_tick(order_book_id, date, market="cn"):
+    data = get_client().execute("get_today_capital_flow_tick", order_book_id, date, market=market)
+    df = pd.DataFrame(data[0])
+    if df.empty:
+        return None
+    df.datetime = df.datetime.apply(int17_to_datetime)
+    df = df.astype({"direction": "i1", "volume": "u8", "value": "u8"})
+    df.set_index(['order_book_id', 'datetime'], inplace=True)
+    return df
+
+
+def get_capital_flow_tickbar(order_book_ids, start_date, end_date, fields,  market):
+    ins_list = ensure_instruments(order_book_ids)
+    order_book_ids = [ins.order_book_id for ins in ins_list]
+
+    start_date, end_date = ensure_date_range(start_date, end_date, datetime.timedelta(days=3))
+
+    history_permission_denied = realtime_permission_denied = False
+    try:
+        data = get_client().execute(
+            "get_capital_flow_tickbar", order_book_ids, start_date, end_date, fields, market=market
+        )
+    except PermissionDenied:
+        data = []
+        history_permission_denied = True
+
+    if data:
+        data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
+        df_list = []
+        for obid, d in data:
+            df = pd.DataFrame(d)
+            df['order_book_id'] = obid
+            df_list.append(df)
+
+        df = pd.concat(df_list)  # type: pd.DataFrame
+        df["datetime"] = int17_to_datetime_v(df["datetime"].values)
+        df.set_index(['order_book_id', 'datetime'], inplace=True)
+    else:
+        df = None
+
+    live_date = current_trading_date()
+    if start_date > live_date or end_date < live_date:
+        if history_permission_denied:
+            raise PermissionDenied("get_capital_flow_tick")
+        return df
+
+    live_date_str = '%d-%02d-%02d' % (live_date // 10000, live_date % 10000 // 100, live_date % 100)
+    live_dfs = []
+
+    def _to_trading_date(dt):
+        if 7 <= dt.hour < 18:
+            return datetime.datetime(year=dt.year, month=dt.month, day=dt.day)
+        return get_next_trading_date(dt - datetime.timedelta(hours=4))
+
+    for ins in ins_list:
+        if ins.de_listed_date != '0000-00-00' and ins.de_listed_date < live_date_str:
+            continue
+        try:
+            if df is not None and date_to_int8(_to_trading_date(
+                    df.loc[ins.order_book_id].index.max())) == live_date:
+                continue
+        except KeyError:
+            pass
+        try:
+            live_df = get_today_capital_flow_tick(ins.order_book_id, live_date, market=market)
+            if live_df is None:
+                continue
+            live_dfs.append(live_df)
+        except PermissionDenied:
+            realtime_permission_denied = True
+            break
+        except MarketNotSupportError:
+            pass
+
+    if history_permission_denied and realtime_permission_denied:
+        raise PermissionDenied("get_capital_flow_tick")
+
+    if not live_dfs:
+        return df
+
+    live_df = pd.concat(live_dfs)
+    return pd.concat([df, live_df])
+
+
+@export_as_api
+def get_capital_flow(order_book_ids, start_date=None, end_date=None, frequency="1d", market="cn"):
+    """获取资金流入流出数据
+    :param order_book_ids: 股票代码or股票代码列表, 如'000001.XSHE'
+    :param start_date: 开始日期
+    :param end_date: 结束日期
+    :param frequency: 默认为日线。日线使用 '1d', 分钟线 '1m'  快照 'tick' (Default value = "1d"),
+    :param market:  (Default value = "cn")
+    :returns: pandas.DataFrame or None
+    """
+    ensure_string_in(frequency, ("1d", "1m", "tick"), "frequency")
+    if frequency == "tick":
+        df = get_capital_flow_tickbar(order_book_ids, start_date, end_date, TICKBAR_FIELDS, market)
+        if isinstance(order_book_ids, str):
+            return df.droplevel(0)
+        return df
+
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    if frequency == "1d":
+        return get_capital_flow_daybar(order_book_ids, start_date, end_date, DAYBAR_FIELDS, 1, market)
+
+    return get_capital_flow_minbar(order_book_ids, start_date, end_date, MINBAR_FIELDS, 1, market)
+
+
+def _auction_field_type(field_name):
+    return (np.object_ if field_name == "order_book_id"
+            else np.uint64 if field_name == "datetime"
+            else np.float64)
+
+
+AUCTION_FIELDS = [
+    "open",
+    "last",
+    "high",
+    "low",
+    "limit_up",
+    "limit_down",
+    "prev_close",
+    "volume",
+    "total_turnover",
+    "a1",
+    "a2",
+    "a3",
+    "a4",
+    "a5",
+    "b1",
+    "b2",
+    "b3",
+    "b4",
+    "b5",
+    "a1_v",
+    "a2_v",
+    "a3_v",
+    "a4_v",
+    "a5_v",
+    "b1_v",
+    "b2_v",
+    "b3_v",
+    "b4_v",
+    "b5_v",
+]
+
+
+def get_auction_info(order_book_ids, start_date=None, end_date=None, auction_type='close', fields=None, market="cn"):
+    assert auction_type in ('open', 'close'), "auction_type must be 'open' or 'close'"
+
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    if not order_book_ids:
+        return None
+
+    start_date, end_date = ensure_date_range(start_date, end_date, datetime.timedelta(days=0))
+    if fields is None:
+        fields = AUCTION_FIELDS
+    else:
+        fields = ensure_list_of_string(fields, "fields")
+        check_items_in_container(fields, set(AUCTION_FIELDS), "fields")
+
+    history_permission_denied = realtime_permission_denied = False
+    try:
+        data = get_client().execute("get_{}_auction_info_daybar".format(auction_type), order_book_ids,
+                                    start_date, end_date, fields + ["datetime", "date"], market=market)
+    except PermissionDenied:
+        data = []
+        history_permission_denied = True
+
+    live_date = current_trading_date()
+    live_date_str = '%d-%02d-%02d' % (live_date // 10000, live_date % 10000 // 100, live_date % 100)
+
+    live_obs = set(
+        ins.order_book_id for ins in instruments(order_book_ids)
+        if ins.de_listed_date == '0000-00-00' or ins.de_listed_date > live_date_str
+    )
+    if data:
+        data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
+
+        extra_fields = ['open_interest', 'prev_settlement', 'date'] if any(
+            ['prev_settlement' in d for _, d in data]
+        ) else ['date']
+
+        df = convert_bar_to_multi_df(data, 'datetime', fields + extra_fields, int17_to_datetime_v, 0.)
+        if df is not None:
+            del df["date"]
+    else:
+        df = None
+
+    if start_date > live_date or end_date < live_date:
+        return df
+
+    if df is not None:
+        idx = df.index
+        for ob in idx.levels[0]:
+            if ob not in live_obs:
+                continue
+            loc = idx.get_loc(ob)
+            if date_to_int8(idx[loc.stop - 1][-1]) == live_date:
+                live_obs.remove(ob)
+
+    if not live_obs:
+        return df
+
+    try:
+        live_df = get_today_auction(list(live_obs), auction_type, live_date, market=market)
+    except PermissionDenied:
+        live_df = None
+        realtime_permission_denied = True
+    except MarketNotSupportError:
+        live_df = None
+
+    if history_permission_denied and realtime_permission_denied:
+        raise PermissionDenied("get_open_auction_info")
+
+    if live_df is None:
+        return df
+    if 'prev_settlement' in live_df.columns:
+        fields = fields + ['open_interest', 'prev_settlement']
+    if df is None:
+        return live_df[fields]
+    df = pd.concat([df, live_df[fields]])
+    df.sort_index(inplace=True)
+    return df
+
+
+def get_today_auction(order_book_ids, auction_type='close', today=None,  market="cn"):
+    if auction_type == 'close':
+        return
+        # ticks = get_client().execute('get_today_close_auction', order_book_ids, market=market)
+    else:
+        ticks = get_client().execute('get_today_open_auction', order_book_ids, today, market=market)
+    if not ticks:
+        return
+
+    fields = ["order_book_id", "datetime"] + AUCTION_FIELDS
+
+    if any(['prev_settlement' in tick for tick in ticks]):
+        fields += ['open_interest', 'prev_settlement']
+
+    dtype = np.dtype([(f, _auction_field_type(f)) for f in fields])
+    bars = np.array([tuple([get_tick_value(t, f) for f in fields]) for t in ticks], dtype=dtype)
+
+    df = pd.DataFrame(bars)
+    df.datetime = df.datetime.apply(int17_to_datetime)
+    df.set_index(["order_book_id", "datetime"], inplace=True)
+    return df
+
+
+@export_as_api
+def get_open_auction_info(order_book_ids, start_date=None, end_date=None, fields=None, market="cn"):
+    """获取盘前集合竞价数据
+    :param order_book_ids: 股票代码
+    :param start_date: 起始日期，默认为今天
+    :param end_date: 截止日期，默认为今天
+    :param fields: 需要获取的字段, 默认为所有字段
+    :param market:  (Default value = "cn")
+    :returns: pd.DataFrame or None
+    """
+    return get_auction_info(order_book_ids, start_date, end_date, 'open', fields, market)
+
+
+@export_as_api
+def get_close_auction_info(order_book_ids, start_date=None, end_date=None, fields=None, market="cn"):
+    """获取尾盘集合竞价数据
+    :param order_book_ids: 股票代码
+    :param start_date: 起始日期，默认为今天
+    :param end_date: 截止日期，默认为今天
+    :param fields: 需要获取的字段, 默认为所有字段
+    :param market:  (Default value = "cn")
+    :returns: pd.DataFrame or None
+    """
+    return get_auction_info(order_book_ids, start_date, end_date, 'close', fields, market)
```

## rqdatac/services/get_price.py

 * *Ordering differences only*

```diff
@@ -1,695 +1,695 @@
-# -*- coding: utf-8 -*-
-import datetime
-import warnings
-import pandas as pd
-import numpy as np
-
-from rqdatac.services.basic import instruments
-from rqdatac.services.calendar import (
-    get_next_trading_date,
-    is_trading_date,
-    get_previous_trading_date,
-    current_trading_date,
-)
-from rqdatac.services.live import get_ticks
-
-from rqdatac.validators import (
-    ensure_string,
-    ensure_list_of_string,
-    check_items_in_container,
-    ensure_instruments,
-    ensure_date_range,
-    is_panel_removed,
-    raise_for_no_panel,
-    ensure_order_book_ids,
-)
-from rqdatac.utils import (
-    to_date_int,
-    to_datetime,
-    to_date,
-    to_time,
-    int8_to_datetime,
-    int17_to_datetime_v,
-    int17_to_datetime,
-    date_to_int8,
-    string_types
-)
-from rqdatac.share.errors import GatewayError
-from rqdatac.client import get_client
-from rqdatac.decorators import export_as_api, ttl_cache, compatible_with_parm, retry
-from rqdatac.share.errors import PermissionDenied, MarketNotSupportError, NoSuchService
-
-
-@export_as_api
-@compatible_with_parm(name="country", value="cn", replace="market")
-def get_price(
-        order_book_ids,
-        start_date=None,
-        end_date=None,
-        frequency="1d",
-        fields=None,
-        adjust_type="pre",
-        skip_suspended=False,
-        expect_df=True,
-        time_slice=None,
-        market="cn",
-        **kwargs
-):
-    """获取证券的历史数据
-
-    :param order_book_ids: 股票列表
-    :param market: 地区代码, 如 'cn' (Default value = "cn")
-    :param start_date: 开始日期, 如 '2013-01-04' (Default value = None)
-    :param end_date: 结束日期, 如 '2014-01-04' (Default value = None)
-    :param frequency: 可选参数, 默认为日线。日线使用 '1d', 分钟线 '1m' (Default value = "1d")
-    :param fields: 可选参数。默认为所有字段。 (Default value = None)
-    :param adjust_type: 可选参数,默认为‘pre', 返回开盘价，收盘价，最高价，最低价依据get_ex_factor 复权因子（包含分红，拆分），volume依据get_split 复权因子（仅涵盖拆分）计算的前复权数据
-            'none'将返回原始数据
-            'post'返回开盘价，收盘价，最高价，最低价依据get_ex_factor 复权因子（包含分红，拆分），volume依据get_split 复权因子（仅涵盖拆分）计算的后复权数据
-            'pre_volume'返回开盘价，收盘价，最高价，最低价,成交量依据get_ex_factor 复权因子（包含分红，拆分）计算的前复权数据
-            'post_volume'返回开盘价，收盘价，最高价，最低价,成交量依据get_ex_factor 复权因子（包含分红，拆分）计算的后复权数据
-            'internal'返回只包含拆分的前复权数据。 (Default value = "pre")
-    :param skip_suspended: 可选参数，默认为False；当设置为True时，返回的数据会过滤掉停牌期间，
-                    此时order_book_ids只能设置为一只股票 (Default value = False)
-    :param expect_df: 返回 MultiIndex DataFrame (Default value = True)
-    :param time_slice: 可选参数。获取分钟线或tick数据时，仅返回指定时间段的数据。
-        类型为(str, str) 或 (datetime.time, datetime.time) 或 (int, int)
-        如：("09:50", "10:11") 或 (datetime.time(9, 50), datetime.time(10, 11)) 或 (930, 1011)
-    :returns: 如果仅传入一只股票, 返回一个 pandas.DataFrame
-        如果传入多只股票, 则返回一个 pandas.Panel
-
-    """
-    sliceable = frequency.endswith(("m", "tick"))
-    # check time_slice
-    if time_slice:
-        if not sliceable:
-            warnings.warn("param [time_slice] only take effect when getting minbar or tick.")
-        if not isinstance(time_slice, (tuple, list)) or len(time_slice) != 2:
-            raise ValueError("time_slice: invalid, expect tuple or list value like ('09:55', '10:11'), got {}".format(time_slice))
-        start, end = to_time(time_slice[0]), to_time(time_slice[1])
-
-    df = _get_price(
-        order_book_ids, start_date, end_date, frequency,
-        fields, adjust_type, skip_suspended, expect_df, market, **kwargs
-    )
-
-    if df is None or not sliceable or not time_slice:
-        # 非tick、minbar或者不指定切片时间，直接返回
-        return df
-
-    # parse slice time_slice
-    index = df.index.get_level_values('datetime')
-    if start > end:
-        # 期货夜盘，可以指定end<start,表示从夜盘到第二天日盘
-        mask = (start <= index.time) | (index.time <= end)
-    else:
-        mask = (start <= index.time) & (index.time <= end)
-
-    return df[mask]
-
-
-@retry(3, suppress_exceptions=(GatewayError, ), delay=3.0)
-def _get_price(
-        order_book_ids,
-        start_date=None,
-        end_date=None,
-        frequency="1d",
-        fields=None,
-        adjust_type="pre",
-        skip_suspended=False,
-        expect_df=True,
-        market="cn",
-        **kwargs
-):
-    # tick数据
-    if frequency == "tick":
-        return get_tick_price(order_book_ids, start_date, end_date, fields, expect_df, market)
-    elif frequency.endswith(("d", "m", "w")):
-        duration = int(frequency[:-1])
-        frequency = frequency[-1]
-        assert 1 <= duration <= 240, "frequency should in range [1, 240]"
-        if market == "hk" and frequency == "m" and duration not in (1, 5, 15, 30, 60):
-            raise ValueError("frequency should be str like 1m, 5m, 15m 30m,or 60m")
-        elif frequency == 'w' and duration not in (1,):
-            raise ValueError("Weekly frequency should be str '1w'")
-    else:
-        raise ValueError("frequency should be str like 1d, 1m, 5m or tick")
-    # 验证adjust_type
-    if "adjusted" in kwargs:
-        adjusted = kwargs.pop("adjusted")
-        adjust_type = "pre" if adjusted else "none"
-
-    if kwargs:
-        raise ValueError('unknown kwargs: {}'.format(kwargs))
-
-    valid_adjust = ["pre", "post", "none", "pre_volume", "post_volume"]
-    ensure_string(adjust_type, "adjust_type")
-    check_items_in_container(adjust_type, valid_adjust, "adjust_type")
-    order_book_ids = ensure_list_of_string(order_book_ids, "order_book_ids")
-    if skip_suspended and len(order_book_ids) > 1:
-        raise ValueError("only accept one order_book_id or symbol if skip_suspended is True")
-
-    assert isinstance(skip_suspended, bool), "'skip_suspended' should be a bool"
-    assert isinstance(expect_df, bool), "'expect_df' should be a bool"
-
-    order_book_ids, stocks, funds, indexes, futures, futures888, spots, options, convertibles, repos = classify_order_book_ids(
-        order_book_ids, market
-    )
-    if not order_book_ids:
-        warnings.warn("no valid instrument")
-        return
-    start_date, end_date = _ensure_date(
-        start_date, end_date, stocks, funds, indexes, futures, spots, options, convertibles, repos
-    )
-    from rqdatac.services.detail.get_price_df import get_price_df, get_week_df
-    if frequency != 'w':
-        df = get_price_df(
-            order_book_ids, start_date, end_date, frequency, duration, fields, adjust_type, skip_suspended,
-            stocks, funds, indexes, futures, futures888, spots, options, convertibles, repos, market
-        )
-        if df is None or expect_df:
-            return df
-        # 单个合约
-        if len(df.index.levels[0]) == 1:
-            df.reset_index(level=0, inplace=True, drop=True)
-            # df.index.name = None
-            if len(df.columns) == 1:
-                df = df[df.columns[0]]
-            return df
-        # 单个字段
-        elif len(df.columns) == 1:
-            field = df.columns[0]
-            df = df.unstack(0)[field]
-            # df.index.name = None
-            df.columns.name = None
-            return df
-        raise_for_no_panel(False)
-        warnings.warn("Panel is removed after pandas version 0.25.0."
-                      " the default value of 'expect_df' will change to True in the future.")
-        # 交换index的顺序，以制作panel
-        return df.swaplevel().to_panel()
-    else:
-        if not expect_df:
-            raise ValueError(
-                "Weekly frequency can only return a DataFrame object, set 'expect_df' to True to resolve this")
-        if skip_suspended:
-            raise ValueError(
-                "Weekly frequency does not support skipping suspended trading days, set 'skip_suspended' to False to resolve this")
-        start_date, end_date = _weekly_start_end_date_handler(start_date, end_date)
-        if start_date > end_date:
-            # 如果*当周没有结束*
-            # 或者start date 和 end date 不能涵盖当周所有的交易日，查询该周的数据时返回为空。
-            return None
-        return get_week_df(order_book_ids, start_date, end_date, fields, adjust_type, market,
-                           *(stocks, funds, indexes, futures, futures888, spots, options, convertibles, repos))
-
-
-def _ensure_date(start_date, end_date, stocks, funds, indexes, futures, spots, options, convertibles, repos):
-    default_start_date, default_end_date = ensure_date_range(start_date, end_date)
-
-    only_futures = futures and (not stocks) and (not funds) and (not indexes) and (not spots) and (
-        not options) and (not convertibles) and (not repos)
-    if only_futures and len(futures) == 1:
-        # 如果只有一只期货, 则给 start_date 和 end_date 合适的默认值
-        # 连续合约的listed_date和de_listed_date都为0, 因此需要特殊处理
-        if futures[0].listed_date != "0000-00-00":
-            default_start_date = to_date_int(futures[0].listed_date)
-        if futures[0].de_listed_date != "0000-00-00":
-            default_end_date = to_date_int(futures[0].de_listed_date)
-
-    start_date = to_date_int(start_date) if start_date else default_start_date
-    end_date = to_date_int(end_date) if end_date else default_end_date
-    if start_date < 20000104:
-        warnings.warn("start_date is earlier than 2000-01-04, adjusted to 2000-01-04")
-        start_date = 20000104
-    return start_date, end_date
-
-
-def _ensure_fields(fields, fields_dict, stocks, funds, futures, futures888, spots, options, convertibles, indexes,
-                   repos):
-    has_dominant_id = False
-    future_only = futures and not any([stocks, funds, spots, options, convertibles, indexes, repos])
-    all_fields = set(fields_dict["common"])
-    if futures:
-        all_fields.update(fields_dict["future"])
-    if stocks:
-        all_fields.update(fields_dict["stock"])
-    if funds:
-        all_fields.update(fields_dict["fund"])
-    if spots:
-        all_fields.update(fields_dict["spot"])
-    if options:
-        all_fields.update(fields_dict["option"])
-    if convertibles:
-        all_fields.update(fields_dict["convertible"])
-    if indexes:
-        all_fields.update(fields_dict["index"])
-    if repos:
-        all_fields.update(fields_dict["repo"])
-    if future_only and futures888 and len(futures) == len(futures888) and not fields:
-        has_dominant_id = True
-
-    if fields:
-        fields = ensure_list_of_string(fields, "fields")
-        fields_set = set(fields)
-        if len(fields_set) < len(fields):
-            warnings.warn("duplicated fields: %s" % [f for f in fields if fields.count(f) > 1])
-            fields = list(fields_set)
-        # 只有期货类型
-        if 'dominant_id' in fields:
-            fields.remove("dominant_id")
-            if not fields:
-                raise ValueError("can't get dominant_id separately, please use futures.get_dominant")
-            if futures888:
-                has_dominant_id = True
-            else:
-                warnings.warn(
-                    "only if one of the order_book_id is future and contains 88/888/99/889 can the dominant_id be selected in fields")
-        check_items_in_container(fields, all_fields, "fields")
-        return fields, has_dominant_id
-    else:
-        return list(all_fields), has_dominant_id
-
-
-def classify_order_book_ids(order_book_ids, market):
-    ins_list = ensure_instruments(order_book_ids, market=market)
-    _order_book_ids = []
-    stocks = []
-    funds = []
-    indexes = []
-    futures = []
-    futures_888 = {}
-    spots = []
-    options = []
-    convertibles = []
-    repos = []
-    for ins in ins_list:
-        if ins.order_book_id not in _order_book_ids:
-            _order_book_ids.append(ins.order_book_id)
-            if ins.type == "CS":
-                stocks.append(ins.order_book_id)
-            elif ins.type == "INDX":
-                indexes.append(ins.order_book_id)
-            elif ins.type in {"ETF", "LOF", "SF", "FUND"}:
-                funds.append(ins.order_book_id)
-            elif ins.type == "Future":
-                if ins.order_book_id.endswith(("88", "889")):
-                    futures_888[ins.order_book_id] = ins.underlying_symbol
-                futures.append(ins)
-            elif ins.type == "Spot":
-                spots.append(ins.order_book_id)
-            elif ins.type == "Option":
-                options.append(ins.order_book_id)
-            elif ins.type == "Convertible":
-                convertibles.append(ins.order_book_id)
-            elif ins.type == "Repo":
-                repos.append(ins.order_book_id)
-    return _order_book_ids, stocks, funds, indexes, futures, futures_888, spots, options, convertibles, repos
-
-
-def _weekly_start_end_date_handler(start_date, end_date):
-    start_date = to_date(start_date)
-    monday = start_date - datetime.timedelta(days=start_date.weekday())
-    first_trading_day_in_week = monday if is_trading_date(monday) else get_next_trading_date(monday)
-    if first_trading_day_in_week < start_date:
-        start_date = monday + datetime.timedelta(weeks=1)
-
-    end_date = to_date(end_date)
-    if end_date > datetime.date.today():
-        end_date = datetime.date.today()
-    friday = end_date - datetime.timedelta(days=end_date.weekday()) + datetime.timedelta(days=4)
-    last_trading_day_in_week = friday if is_trading_date(friday) else get_previous_trading_date(friday)
-    if last_trading_day_in_week > end_date:
-        end_date = friday - datetime.timedelta(weeks=1)
-
-    return to_date_int(start_date), to_date_int(end_date)
-
-
-@ttl_cache(15 * 60)
-def daybar_for_tick_price(order_book_id):
-    ins = instruments(order_book_id)
-    today = to_date_int(datetime.datetime.today())
-
-    if ins.type in ("Future", "Spot", "Option"):
-        fields = ["prev_settlement", "open", "prev_close", "limit_up", "limit_down"]
-    elif ins.type in ("LOF", "ETF", "FUND"):
-        fields = ["open", "prev_close", "limit_up", "limit_down", "iopv"]
-    elif ins.type in ("CS", "Convertible"):
-        fields = ["open", "prev_close", "limit_up", "limit_down"]
-    else:
-        fields = ["open", "prev_close"]
-
-    df = get_price(
-        ins.order_book_id,
-        "2004-12-31",
-        today,
-        frequency="1d",
-        fields=fields,
-        adjust_type="none",
-        skip_suspended=False,
-        expect_df=is_panel_removed,
-        market="cn",
-    )
-
-    if df is not None and isinstance(df.index, pd.MultiIndex):
-        df.reset_index(level=0, inplace=True)
-    return df
-
-
-EQUITIES_TICK_FIELDS = [
-    "trading_date", "open", "last", "high", "low",
-    "prev_close", "volume", "total_turnover", "limit_up", "limit_down",
-    "a1", "a2", "a3", "a4", "a5", "b1", "b2", "b3", "b4", "b5", "a1_v", "a2_v", "a3_v",
-    "a4_v", "a5_v", "b1_v", "b2_v", "b3_v", "b4_v", "b5_v", "change_rate",
-    "num_trades",
-]
-FUND_TICK_FIELDS = EQUITIES_TICK_FIELDS + ["iopv", "prev_iopv"]
-FUTURE_TICK_FIELDS = EQUITIES_TICK_FIELDS + ["open_interest", "prev_settlement"]
-EQUITIES_TICK_COLUMNS = EQUITIES_TICK_FIELDS
-FUTURE_TICK_COLUMNS = [
-    "trading_date", "open", "last", "high", "low", "prev_settlement",
-    "prev_close", "volume", "open_interest", "total_turnover", "limit_up", "limit_down",
-    "a1", "a2", "a3", "a4", "a5", "b1", "b2", "b3", "b4", "b5", "a1_v", "a2_v", "a3_v",
-    "a4_v", "a5_v", "b1_v", "b2_v", "b3_v", "b4_v", "b5_v", "change_rate",
-]
-FUND_TICK_COLUMNS = FUND_TICK_FIELDS
-RELATED_DABAR_FIELDS = {"open", "prev_settlement", "prev_close", "limit_up", "limit_down", "change_rate"}
-
-
-def get_tick_price(order_book_ids, start_date, end_date, fields, expect_df, market):
-    df = get_tick_price_multi_df(order_book_ids, start_date, end_date, fields, market)
-    if df is not None and not expect_df and isinstance(order_book_ids, string_types):
-        df.reset_index(level=0, drop=True, inplace=True)
-    return df
-
-
-def convert_history_tick_to_multi_df(data, dt_name, fields, convert_dt):
-    line_no = 0
-    dt_set = set()
-    obid_level = []
-    obid_slice_map = {}
-    for i, (obid, d) in enumerate(data):
-        dates = d.pop("date")
-        if len(dates) == 0:
-            continue
-        times = d.pop("time")
-        dts = d[dt_name] = [_convert_int_to_datetime(dt, tm) for dt, tm in zip(dates, times)]
-
-        dts_len = len(dts)
-
-        if not obid_level or obid_level[-1] != obid:
-            obid_level.append(obid)
-        obid_slice_map[(i, obid)] = slice(line_no, line_no + dts_len, None)
-
-        dt_set.update(dts)
-        line_no += dts_len
-
-    if line_no == 0:
-        return
-
-    daybars = {}
-    if set(fields) & RELATED_DABAR_FIELDS:
-        ins_list = ensure_instruments(obid_level)
-        for ins in ins_list:
-            daybar = daybar_for_tick_price(ins.order_book_id)
-            if daybar is not None:
-                if ins.type in ["ETF", "LOF", "FUND"]:
-                    daybar['prev_iopv'] = daybar['iopv'].shift(1)
-            daybars[ins.order_book_id] = daybar
-        fields_ = list(set(fields) | {"last", "volume"})
-    else:
-        fields_ = fields
-
-    obid_idx_map = {o: i for i, o in enumerate(obid_level)}
-    obid_label = np.empty(line_no, dtype=object)
-    dt_label = np.empty(line_no, dtype=object)
-    arr = np.full((line_no, len(fields_)), np.nan)
-    r_map_fields = {f: i for i, f in enumerate(fields_)}
-
-    dt_arr_sorted = np.array(sorted(dt_set))
-    dt_level = convert_dt(dt_arr_sorted)
-
-    for i, (obid, d) in enumerate(data):
-        if dt_name not in d:
-            continue
-        dts = d[dt_name]
-        slice_ = obid_slice_map[(i, obid)]
-        for f, value in d.items():
-            if f == dt_name:
-                dt_label[slice_] = dt_arr_sorted.searchsorted(dts, side='left')
-            else:
-                arr[slice_, r_map_fields[f]] = value
-
-        obid_label[slice_] = obid_idx_map[obid]
-
-        trading_date = to_datetime(_to_trading_date(int17_to_datetime(dts[-1])))
-        if "trading_date" in r_map_fields:
-            trading_date_int = date_to_int8(trading_date)
-            arr[slice_, r_map_fields["trading_date"]] = trading_date_int
-
-        daybar = daybars.get(obid)
-        if daybar is not None:
-            try:
-                last = daybar.loc[trading_date]
-            except KeyError:
-                continue
-            day_open = last["open"]
-            if "open" in r_map_fields:
-                arr[slice_, r_map_fields["open"]] = [day_open if v > 0 else 0.0 for v in d["volume"]]
-            if "prev_close" in r_map_fields:
-                _prev_close = arr[slice_, r_map_fields["prev_close"]][0]
-                if _prev_close != _prev_close:
-                    arr[slice_, r_map_fields["prev_close"]] = last["prev_close"]
-            if instruments(obid).type in ("ETF", "LOF", "FUND"):
-                if "prev_iopv" in r_map_fields:
-                    arr[slice_, r_map_fields["prev_iopv"]] = last["prev_iopv"]
-
-            if instruments(obid).type in ("CS", "ETF", "LOF", "FUND", "Future", "Spot", "Option", "Convertible"):
-                if "limit_up" in r_map_fields:
-                    arr[slice_, r_map_fields["limit_up"]] = last["limit_up"]
-                if "limit_down" in r_map_fields:
-                    arr[slice_, r_map_fields["limit_down"]] = last["limit_down"]
-
-            if instruments(obid).type in ("Future", "Option", "Spot"):
-                if "prev_settlement" in r_map_fields:
-                    arr[slice_, r_map_fields["prev_settlement"]] = last["prev_settlement"]
-                if "change_rate" in r_map_fields:
-                    arr[slice_, r_map_fields["change_rate"]] = arr[slice_, r_map_fields["last"]] / last[
-                        "prev_settlement"] - 1
-            elif "change_rate" in r_map_fields:
-                arr[slice_, r_map_fields["change_rate"]] = arr[slice_, r_map_fields["last"]] / last["prev_close"] - 1
-
-    try:
-        func_is_singletz = getattr(pd._libs.lib, 'is_datetime_with_singletz_array')
-        setattr(pd._libs.lib, 'is_datetime_with_singletz_array', lambda *args: True)
-    except AttributeError:
-        func_is_singletz = None
-    multi_idx = pd.MultiIndex(
-        [obid_level, dt_level],
-        [obid_label, dt_label],
-        names=('order_book_id', dt_name)
-    )
-    df = pd.DataFrame(data=arr, index=multi_idx, columns=fields_)
-    if "trading_date" in r_map_fields:
-        df["trading_date"] = df["trading_date"].astype(int).apply(int8_to_datetime)
-    if func_is_singletz is not None:
-        setattr(pd._libs.lib, 'is_datetime_with_singletz_array', func_is_singletz)
-    return df[fields]
-
-
-def get_history_tick(order_book_ids, start_date, end_date, gtw_fields, columns, market):
-    data = get_client().execute("get_tickbar", order_book_ids, start_date, end_date, gtw_fields, market=market)
-    data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
-    history_df = convert_history_tick_to_multi_df(data, "datetime", columns, int17_to_datetime_v)
-
-    if isinstance(history_df, pd.DataFrame) and 'iopv' in history_df.columns:
-        history_df['iopv'] = history_df['iopv'].replace(0.0, np.nan)
-    return history_df
-
-
-def get_tick_price_multi_df(order_book_ids, start_date, end_date, fields, market):
-    start_date, end_date = ensure_date_range(start_date, end_date, datetime.timedelta(days=3))
-
-    live_date = current_trading_date()
-    if start_date > live_date:
-        return
-
-    ins_list = ensure_instruments(order_book_ids)
-    order_book_ids = [ins.order_book_id for ins in ins_list]
-    types = {ins.type for ins in ins_list}
-
-    if "Future" in types or "Option" in types or "Spot" in types:
-        base_fields = FUTURE_TICK_FIELDS
-        base_columns = FUTURE_TICK_COLUMNS
-
-        if ('Option' in types and any((i.type == 'Option' and i.exchange in ('XSHG', 'XSHE')) for i in ins_list)
-        ) or ('CS' in types) or ('LOF' in types) or ('ETF' in types) or ('FUND' in types) or ('Convertible' in types):
-            base_columns = base_columns + ['num_trades']
-    elif 'ETF' in types or 'LOF' in types or 'FUND' in types:
-        base_fields = FUND_TICK_FIELDS
-        base_columns = FUND_TICK_COLUMNS
-    else:
-        base_fields = EQUITIES_TICK_FIELDS
-        base_columns = EQUITIES_TICK_COLUMNS
-
-    if fields:
-        fields = ensure_list_of_string(fields, "fields")
-        check_items_in_container(fields, base_fields, "fields")
-        columns = [f for f in base_columns if f in fields]
-    else:
-        fields = base_fields
-        columns = base_columns
-
-    gtw_fields = set(fields) | {"date", "time"}
-    if set(fields) & RELATED_DABAR_FIELDS:
-        gtw_fields.update({"volume", "last"})
-
-    history_df = get_history_tick(order_book_ids, start_date, end_date, list(gtw_fields), columns, market)
-    if end_date < live_date:
-        return history_df
-
-    live_date_str = '%d-%02d-%02d' % (live_date // 10000, live_date % 10000 // 100, live_date % 100)
-    live_dfs = []
-    for ins in ins_list:
-        if ins.de_listed_date != '0000-00-00' and ins.de_listed_date < live_date_str:
-            continue
-        try:
-            if history_df is not None and date_to_int8(_to_trading_date(
-                    history_df.loc[ins.order_book_id].index.max())) == live_date:
-                continue
-        except KeyError:
-            pass
-
-        try:
-            live_df = get_ticks(ins.order_book_id, start_date=live_date, end_date=live_date, expect_df=True,
-                                market=market)
-            if live_df is None:
-                continue
-            if "trading_date" not in live_df.columns:
-                live_df["trading_date"] = int8_to_datetime(live_date)
-            else:
-                live_df["trading_date"] = live_df["trading_date"].apply(to_datetime)
-            if ins.type in ("Future", "Option", "Spot"):
-                live_df["change_rate"] = live_df["last"] / live_df["prev_settlement"] - 1
-            else:
-                live_df["change_rate"] = live_df["last"] / live_df["prev_close"] - 1
-            live_df = live_df.reindex(columns=columns)
-            live_dfs.append(live_df)
-        except (PermissionDenied, MarketNotSupportError, NoSuchService):
-            pass
-
-    if not live_dfs:
-        return history_df
-
-    if history_df is None:
-        return pd.concat(live_dfs)
-    return pd.concat([history_df] + live_dfs)
-
-
-def _convert_int_to_datetime(date_int, time_int):
-    return date_int * 1000000000 + time_int
-
-
-def _to_trading_date(dt):
-    if 7 <= dt.hour < 18:
-        return datetime.datetime(year=dt.year, month=dt.month, day=dt.day)
-    return get_next_trading_date(dt - datetime.timedelta(hours=4))
-
-
-def _add_minbar_dominant_id(df, dominant):
-    if 'trading_date' in df.columns:
-        dominant.index = dominant.index.map(lambda x: float(x.year * 10000 + x.month * 100 + x.day))
-        date_dominant_map = dominant.to_dict()
-        df['dominant_id'] = df['trading_date'].map(date_dominant_map)
-    else:
-        date_dominant_map = dominant.to_dict()
-
-        def _set_dominant(dt):
-            trading_date = pd.Timestamp(_to_trading_date(dt))
-            return date_dominant_map[trading_date]
-
-        df['dominant_id'] = df.index.map(_set_dominant)
-    return df
-
-
-@ttl_cache(12 * 3600)
-def _get_hk_part_list():
-    """ 获取港股联交所参与者名单 """
-    data = get_client().execute("get_hk_part_list")
-    hk_part_df = pd.DataFrame(data)
-    return hk_part_df
-
-
-@export_as_api()
-def get_stock_connect_holding_details(order_book_ids, start_date=None, end_date=None):
-    """
-    获取北向资金席位持股明细数据
-    :param order_book_ids: 标的合约
-    :param start_date: 起始日期
-    :param end_date: 结束日期
-    :return: pd.DataFrame
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, type="CS", market="cn")
-    start_date, end_date = ensure_date_range(start_date, end_date, datetime.timedelta(days=3))
-
-    # 北向机构持股明细
-    data = get_client().execute("get_stock_connect_holding_details", order_book_ids, start_date, end_date, market="cn")
-    data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
-    df_list = []
-    for obid, d in data:
-        df = pd.DataFrame(d)
-        df["order_book_id"] = obid
-        df_list.append(df)
-    if len(df_list) == 0:
-        return
-    df = pd.concat(df_list, ignore_index=True)
-    df.rename(columns={"datetime": "date"}, inplace=True)
-    df["participant_number"] = df["participant_number"].map(lambda s: s.decode())
-    df["date"] = pd.to_datetime(df["date"].astype("str"), format="%Y%m%d")
-
-    # 获取港股联交所参与者名单来合并获取机构名称
-    hk_part_df = _get_hk_part_list()
-    df = pd.merge(df, hk_part_df, how="left", on="participant_number")
-
-    df.set_index(keys=["order_book_id", "date"], inplace=True)
-    cols = ["participant_number", "ccass_name", "shares_holding", "holding_ratio"]
-    df = df[cols]
-
-    return df
-
-
-@export_as_api
-def get_vwap(order_book_ids, start_date=None, end_date=None, frequency="1d"):
-    """ 获取vwap(成交量加权平均价格)数据
-
-    :param order_book_ids: 标的合约, 支持股票、期货、期权、ETF、可转债
-    :param market: 地区代码, 如 'cn' (Default value = "cn")
-    :param start_date: 开始日期, 如 '2013-01-04' (Default value = None)
-    :param end_date: 结束日期, 如 '2014-01-04' (Default value = None)
-    :param frequency: 可选参数, 默认为日线。日线使用 '1d', 分钟线 '1m' (Default value = "1d")
-    :returns: multi-index series, 其中index为 order_book_id, date 组成的数据, 值为 vwap
-    """
-    if frequency == "tick":
-        raise ValueError("doesn't support get vwap by tick frequency")
-
-    order_book_ids = ensure_order_book_ids(order_book_ids, {"CS", "Future", "Option", "ETF", "Convertible"})
-    price = get_price(
-        order_book_ids,
-        start_date,
-        end_date,
-        fields=["total_turnover", "volume"],
-        frequency=frequency,
-        adjust_type="none"
-    )
-    if price is None:
-        return None
-    vwap = price["total_turnover"] / price["volume"]
-    vwap.fillna(0, inplace=True)
-
-    # 针对一些合约还需要除以 contract_multiplier
-    order_book_ids = list(set(vwap.index.levels[0]))
-    insts = instruments(order_book_ids)
-    multiplier = {i.order_book_id: getattr(i, "contract_multiplier", 1) for i in insts}
-    return vwap.groupby("order_book_id", group_keys=False).apply(
-        lambda one_vwap: one_vwap / multiplier[one_vwap.name]
-    )
+# -*- coding: utf-8 -*-
+import datetime
+import warnings
+import pandas as pd
+import numpy as np
+
+from rqdatac.services.basic import instruments
+from rqdatac.services.calendar import (
+    get_next_trading_date,
+    is_trading_date,
+    get_previous_trading_date,
+    current_trading_date,
+)
+from rqdatac.services.live import get_ticks
+
+from rqdatac.validators import (
+    ensure_string,
+    ensure_list_of_string,
+    check_items_in_container,
+    ensure_instruments,
+    ensure_date_range,
+    is_panel_removed,
+    raise_for_no_panel,
+    ensure_order_book_ids,
+)
+from rqdatac.utils import (
+    to_date_int,
+    to_datetime,
+    to_date,
+    to_time,
+    int8_to_datetime,
+    int17_to_datetime_v,
+    int17_to_datetime,
+    date_to_int8,
+    string_types
+)
+from rqdatac.share.errors import GatewayError
+from rqdatac.client import get_client
+from rqdatac.decorators import export_as_api, ttl_cache, compatible_with_parm, retry
+from rqdatac.share.errors import PermissionDenied, MarketNotSupportError, NoSuchService
+
+
+@export_as_api
+@compatible_with_parm(name="country", value="cn", replace="market")
+def get_price(
+        order_book_ids,
+        start_date=None,
+        end_date=None,
+        frequency="1d",
+        fields=None,
+        adjust_type="pre",
+        skip_suspended=False,
+        expect_df=True,
+        time_slice=None,
+        market="cn",
+        **kwargs
+):
+    """获取证券的历史数据
+
+    :param order_book_ids: 股票列表
+    :param market: 地区代码, 如 'cn' (Default value = "cn")
+    :param start_date: 开始日期, 如 '2013-01-04' (Default value = None)
+    :param end_date: 结束日期, 如 '2014-01-04' (Default value = None)
+    :param frequency: 可选参数, 默认为日线。日线使用 '1d', 分钟线 '1m' (Default value = "1d")
+    :param fields: 可选参数。默认为所有字段。 (Default value = None)
+    :param adjust_type: 可选参数,默认为‘pre', 返回开盘价，收盘价，最高价，最低价依据get_ex_factor 复权因子（包含分红，拆分），volume依据get_split 复权因子（仅涵盖拆分）计算的前复权数据
+            'none'将返回原始数据
+            'post'返回开盘价，收盘价，最高价，最低价依据get_ex_factor 复权因子（包含分红，拆分），volume依据get_split 复权因子（仅涵盖拆分）计算的后复权数据
+            'pre_volume'返回开盘价，收盘价，最高价，最低价,成交量依据get_ex_factor 复权因子（包含分红，拆分）计算的前复权数据
+            'post_volume'返回开盘价，收盘价，最高价，最低价,成交量依据get_ex_factor 复权因子（包含分红，拆分）计算的后复权数据
+            'internal'返回只包含拆分的前复权数据。 (Default value = "pre")
+    :param skip_suspended: 可选参数，默认为False；当设置为True时，返回的数据会过滤掉停牌期间，
+                    此时order_book_ids只能设置为一只股票 (Default value = False)
+    :param expect_df: 返回 MultiIndex DataFrame (Default value = True)
+    :param time_slice: 可选参数。获取分钟线或tick数据时，仅返回指定时间段的数据。
+        类型为(str, str) 或 (datetime.time, datetime.time) 或 (int, int)
+        如：("09:50", "10:11") 或 (datetime.time(9, 50), datetime.time(10, 11)) 或 (930, 1011)
+    :returns: 如果仅传入一只股票, 返回一个 pandas.DataFrame
+        如果传入多只股票, 则返回一个 pandas.Panel
+
+    """
+    sliceable = frequency.endswith(("m", "tick"))
+    # check time_slice
+    if time_slice:
+        if not sliceable:
+            warnings.warn("param [time_slice] only take effect when getting minbar or tick.")
+        if not isinstance(time_slice, (tuple, list)) or len(time_slice) != 2:
+            raise ValueError("time_slice: invalid, expect tuple or list value like ('09:55', '10:11'), got {}".format(time_slice))
+        start, end = to_time(time_slice[0]), to_time(time_slice[1])
+
+    df = _get_price(
+        order_book_ids, start_date, end_date, frequency,
+        fields, adjust_type, skip_suspended, expect_df, market, **kwargs
+    )
+
+    if df is None or not sliceable or not time_slice:
+        # 非tick、minbar或者不指定切片时间，直接返回
+        return df
+
+    # parse slice time_slice
+    index = df.index.get_level_values('datetime')
+    if start > end:
+        # 期货夜盘，可以指定end<start,表示从夜盘到第二天日盘
+        mask = (start <= index.time) | (index.time <= end)
+    else:
+        mask = (start <= index.time) & (index.time <= end)
+
+    return df[mask]
+
+
+@retry(3, suppress_exceptions=(GatewayError, ), delay=3.0)
+def _get_price(
+        order_book_ids,
+        start_date=None,
+        end_date=None,
+        frequency="1d",
+        fields=None,
+        adjust_type="pre",
+        skip_suspended=False,
+        expect_df=True,
+        market="cn",
+        **kwargs
+):
+    # tick数据
+    if frequency == "tick":
+        return get_tick_price(order_book_ids, start_date, end_date, fields, expect_df, market)
+    elif frequency.endswith(("d", "m", "w")):
+        duration = int(frequency[:-1])
+        frequency = frequency[-1]
+        assert 1 <= duration <= 240, "frequency should in range [1, 240]"
+        if market == "hk" and frequency == "m" and duration not in (1, 5, 15, 30, 60):
+            raise ValueError("frequency should be str like 1m, 5m, 15m 30m,or 60m")
+        elif frequency == 'w' and duration not in (1,):
+            raise ValueError("Weekly frequency should be str '1w'")
+    else:
+        raise ValueError("frequency should be str like 1d, 1m, 5m or tick")
+    # 验证adjust_type
+    if "adjusted" in kwargs:
+        adjusted = kwargs.pop("adjusted")
+        adjust_type = "pre" if adjusted else "none"
+
+    if kwargs:
+        raise ValueError('unknown kwargs: {}'.format(kwargs))
+
+    valid_adjust = ["pre", "post", "none", "pre_volume", "post_volume"]
+    ensure_string(adjust_type, "adjust_type")
+    check_items_in_container(adjust_type, valid_adjust, "adjust_type")
+    order_book_ids = ensure_list_of_string(order_book_ids, "order_book_ids")
+    if skip_suspended and len(order_book_ids) > 1:
+        raise ValueError("only accept one order_book_id or symbol if skip_suspended is True")
+
+    assert isinstance(skip_suspended, bool), "'skip_suspended' should be a bool"
+    assert isinstance(expect_df, bool), "'expect_df' should be a bool"
+
+    order_book_ids, stocks, funds, indexes, futures, futures888, spots, options, convertibles, repos = classify_order_book_ids(
+        order_book_ids, market
+    )
+    if not order_book_ids:
+        warnings.warn("no valid instrument")
+        return
+    start_date, end_date = _ensure_date(
+        start_date, end_date, stocks, funds, indexes, futures, spots, options, convertibles, repos
+    )
+    from rqdatac.services.detail.get_price_df import get_price_df, get_week_df
+    if frequency != 'w':
+        df = get_price_df(
+            order_book_ids, start_date, end_date, frequency, duration, fields, adjust_type, skip_suspended,
+            stocks, funds, indexes, futures, futures888, spots, options, convertibles, repos, market
+        )
+        if df is None or expect_df:
+            return df
+        # 单个合约
+        if len(df.index.levels[0]) == 1:
+            df.reset_index(level=0, inplace=True, drop=True)
+            # df.index.name = None
+            if len(df.columns) == 1:
+                df = df[df.columns[0]]
+            return df
+        # 单个字段
+        elif len(df.columns) == 1:
+            field = df.columns[0]
+            df = df.unstack(0)[field]
+            # df.index.name = None
+            df.columns.name = None
+            return df
+        raise_for_no_panel(False)
+        warnings.warn("Panel is removed after pandas version 0.25.0."
+                      " the default value of 'expect_df' will change to True in the future.")
+        # 交换index的顺序，以制作panel
+        return df.swaplevel().to_panel()
+    else:
+        if not expect_df:
+            raise ValueError(
+                "Weekly frequency can only return a DataFrame object, set 'expect_df' to True to resolve this")
+        if skip_suspended:
+            raise ValueError(
+                "Weekly frequency does not support skipping suspended trading days, set 'skip_suspended' to False to resolve this")
+        start_date, end_date = _weekly_start_end_date_handler(start_date, end_date)
+        if start_date > end_date:
+            # 如果*当周没有结束*
+            # 或者start date 和 end date 不能涵盖当周所有的交易日，查询该周的数据时返回为空。
+            return None
+        return get_week_df(order_book_ids, start_date, end_date, fields, adjust_type, market,
+                           *(stocks, funds, indexes, futures, futures888, spots, options, convertibles, repos))
+
+
+def _ensure_date(start_date, end_date, stocks, funds, indexes, futures, spots, options, convertibles, repos):
+    default_start_date, default_end_date = ensure_date_range(start_date, end_date)
+
+    only_futures = futures and (not stocks) and (not funds) and (not indexes) and (not spots) and (
+        not options) and (not convertibles) and (not repos)
+    if only_futures and len(futures) == 1:
+        # 如果只有一只期货, 则给 start_date 和 end_date 合适的默认值
+        # 连续合约的listed_date和de_listed_date都为0, 因此需要特殊处理
+        if futures[0].listed_date != "0000-00-00":
+            default_start_date = to_date_int(futures[0].listed_date)
+        if futures[0].de_listed_date != "0000-00-00":
+            default_end_date = to_date_int(futures[0].de_listed_date)
+
+    start_date = to_date_int(start_date) if start_date else default_start_date
+    end_date = to_date_int(end_date) if end_date else default_end_date
+    if start_date < 20000104:
+        warnings.warn("start_date is earlier than 2000-01-04, adjusted to 2000-01-04")
+        start_date = 20000104
+    return start_date, end_date
+
+
+def _ensure_fields(fields, fields_dict, stocks, funds, futures, futures888, spots, options, convertibles, indexes,
+                   repos):
+    has_dominant_id = False
+    future_only = futures and not any([stocks, funds, spots, options, convertibles, indexes, repos])
+    all_fields = set(fields_dict["common"])
+    if futures:
+        all_fields.update(fields_dict["future"])
+    if stocks:
+        all_fields.update(fields_dict["stock"])
+    if funds:
+        all_fields.update(fields_dict["fund"])
+    if spots:
+        all_fields.update(fields_dict["spot"])
+    if options:
+        all_fields.update(fields_dict["option"])
+    if convertibles:
+        all_fields.update(fields_dict["convertible"])
+    if indexes:
+        all_fields.update(fields_dict["index"])
+    if repos:
+        all_fields.update(fields_dict["repo"])
+    if future_only and futures888 and len(futures) == len(futures888) and not fields:
+        has_dominant_id = True
+
+    if fields:
+        fields = ensure_list_of_string(fields, "fields")
+        fields_set = set(fields)
+        if len(fields_set) < len(fields):
+            warnings.warn("duplicated fields: %s" % [f for f in fields if fields.count(f) > 1])
+            fields = list(fields_set)
+        # 只有期货类型
+        if 'dominant_id' in fields:
+            fields.remove("dominant_id")
+            if not fields:
+                raise ValueError("can't get dominant_id separately, please use futures.get_dominant")
+            if futures888:
+                has_dominant_id = True
+            else:
+                warnings.warn(
+                    "only if one of the order_book_id is future and contains 88/888/99/889 can the dominant_id be selected in fields")
+        check_items_in_container(fields, all_fields, "fields")
+        return fields, has_dominant_id
+    else:
+        return list(all_fields), has_dominant_id
+
+
+def classify_order_book_ids(order_book_ids, market):
+    ins_list = ensure_instruments(order_book_ids, market=market)
+    _order_book_ids = []
+    stocks = []
+    funds = []
+    indexes = []
+    futures = []
+    futures_888 = {}
+    spots = []
+    options = []
+    convertibles = []
+    repos = []
+    for ins in ins_list:
+        if ins.order_book_id not in _order_book_ids:
+            _order_book_ids.append(ins.order_book_id)
+            if ins.type == "CS":
+                stocks.append(ins.order_book_id)
+            elif ins.type == "INDX":
+                indexes.append(ins.order_book_id)
+            elif ins.type in {"ETF", "LOF", "SF", "FUND"}:
+                funds.append(ins.order_book_id)
+            elif ins.type == "Future":
+                if ins.order_book_id.endswith(("88", "889")):
+                    futures_888[ins.order_book_id] = ins.underlying_symbol
+                futures.append(ins)
+            elif ins.type == "Spot":
+                spots.append(ins.order_book_id)
+            elif ins.type == "Option":
+                options.append(ins.order_book_id)
+            elif ins.type == "Convertible":
+                convertibles.append(ins.order_book_id)
+            elif ins.type == "Repo":
+                repos.append(ins.order_book_id)
+    return _order_book_ids, stocks, funds, indexes, futures, futures_888, spots, options, convertibles, repos
+
+
+def _weekly_start_end_date_handler(start_date, end_date):
+    start_date = to_date(start_date)
+    monday = start_date - datetime.timedelta(days=start_date.weekday())
+    first_trading_day_in_week = monday if is_trading_date(monday) else get_next_trading_date(monday)
+    if first_trading_day_in_week < start_date:
+        start_date = monday + datetime.timedelta(weeks=1)
+
+    end_date = to_date(end_date)
+    if end_date > datetime.date.today():
+        end_date = datetime.date.today()
+    friday = end_date - datetime.timedelta(days=end_date.weekday()) + datetime.timedelta(days=4)
+    last_trading_day_in_week = friday if is_trading_date(friday) else get_previous_trading_date(friday)
+    if last_trading_day_in_week > end_date:
+        end_date = friday - datetime.timedelta(weeks=1)
+
+    return to_date_int(start_date), to_date_int(end_date)
+
+
+@ttl_cache(15 * 60)
+def daybar_for_tick_price(order_book_id):
+    ins = instruments(order_book_id)
+    today = to_date_int(datetime.datetime.today())
+
+    if ins.type in ("Future", "Spot", "Option"):
+        fields = ["prev_settlement", "open", "prev_close", "limit_up", "limit_down"]
+    elif ins.type in ("LOF", "ETF", "FUND"):
+        fields = ["open", "prev_close", "limit_up", "limit_down", "iopv"]
+    elif ins.type in ("CS", "Convertible"):
+        fields = ["open", "prev_close", "limit_up", "limit_down"]
+    else:
+        fields = ["open", "prev_close"]
+
+    df = get_price(
+        ins.order_book_id,
+        "2004-12-31",
+        today,
+        frequency="1d",
+        fields=fields,
+        adjust_type="none",
+        skip_suspended=False,
+        expect_df=is_panel_removed,
+        market="cn",
+    )
+
+    if df is not None and isinstance(df.index, pd.MultiIndex):
+        df.reset_index(level=0, inplace=True)
+    return df
+
+
+EQUITIES_TICK_FIELDS = [
+    "trading_date", "open", "last", "high", "low",
+    "prev_close", "volume", "total_turnover", "limit_up", "limit_down",
+    "a1", "a2", "a3", "a4", "a5", "b1", "b2", "b3", "b4", "b5", "a1_v", "a2_v", "a3_v",
+    "a4_v", "a5_v", "b1_v", "b2_v", "b3_v", "b4_v", "b5_v", "change_rate",
+    "num_trades",
+]
+FUND_TICK_FIELDS = EQUITIES_TICK_FIELDS + ["iopv", "prev_iopv"]
+FUTURE_TICK_FIELDS = EQUITIES_TICK_FIELDS + ["open_interest", "prev_settlement"]
+EQUITIES_TICK_COLUMNS = EQUITIES_TICK_FIELDS
+FUTURE_TICK_COLUMNS = [
+    "trading_date", "open", "last", "high", "low", "prev_settlement",
+    "prev_close", "volume", "open_interest", "total_turnover", "limit_up", "limit_down",
+    "a1", "a2", "a3", "a4", "a5", "b1", "b2", "b3", "b4", "b5", "a1_v", "a2_v", "a3_v",
+    "a4_v", "a5_v", "b1_v", "b2_v", "b3_v", "b4_v", "b5_v", "change_rate",
+]
+FUND_TICK_COLUMNS = FUND_TICK_FIELDS
+RELATED_DABAR_FIELDS = {"open", "prev_settlement", "prev_close", "limit_up", "limit_down", "change_rate"}
+
+
+def get_tick_price(order_book_ids, start_date, end_date, fields, expect_df, market):
+    df = get_tick_price_multi_df(order_book_ids, start_date, end_date, fields, market)
+    if df is not None and not expect_df and isinstance(order_book_ids, string_types):
+        df.reset_index(level=0, drop=True, inplace=True)
+    return df
+
+
+def convert_history_tick_to_multi_df(data, dt_name, fields, convert_dt):
+    line_no = 0
+    dt_set = set()
+    obid_level = []
+    obid_slice_map = {}
+    for i, (obid, d) in enumerate(data):
+        dates = d.pop("date")
+        if len(dates) == 0:
+            continue
+        times = d.pop("time")
+        dts = d[dt_name] = [_convert_int_to_datetime(dt, tm) for dt, tm in zip(dates, times)]
+
+        dts_len = len(dts)
+
+        if not obid_level or obid_level[-1] != obid:
+            obid_level.append(obid)
+        obid_slice_map[(i, obid)] = slice(line_no, line_no + dts_len, None)
+
+        dt_set.update(dts)
+        line_no += dts_len
+
+    if line_no == 0:
+        return
+
+    daybars = {}
+    if set(fields) & RELATED_DABAR_FIELDS:
+        ins_list = ensure_instruments(obid_level)
+        for ins in ins_list:
+            daybar = daybar_for_tick_price(ins.order_book_id)
+            if daybar is not None:
+                if ins.type in ["ETF", "LOF", "FUND"]:
+                    daybar['prev_iopv'] = daybar['iopv'].shift(1)
+            daybars[ins.order_book_id] = daybar
+        fields_ = list(set(fields) | {"last", "volume"})
+    else:
+        fields_ = fields
+
+    obid_idx_map = {o: i for i, o in enumerate(obid_level)}
+    obid_label = np.empty(line_no, dtype=object)
+    dt_label = np.empty(line_no, dtype=object)
+    arr = np.full((line_no, len(fields_)), np.nan)
+    r_map_fields = {f: i for i, f in enumerate(fields_)}
+
+    dt_arr_sorted = np.array(sorted(dt_set))
+    dt_level = convert_dt(dt_arr_sorted)
+
+    for i, (obid, d) in enumerate(data):
+        if dt_name not in d:
+            continue
+        dts = d[dt_name]
+        slice_ = obid_slice_map[(i, obid)]
+        for f, value in d.items():
+            if f == dt_name:
+                dt_label[slice_] = dt_arr_sorted.searchsorted(dts, side='left')
+            else:
+                arr[slice_, r_map_fields[f]] = value
+
+        obid_label[slice_] = obid_idx_map[obid]
+
+        trading_date = to_datetime(_to_trading_date(int17_to_datetime(dts[-1])))
+        if "trading_date" in r_map_fields:
+            trading_date_int = date_to_int8(trading_date)
+            arr[slice_, r_map_fields["trading_date"]] = trading_date_int
+
+        daybar = daybars.get(obid)
+        if daybar is not None:
+            try:
+                last = daybar.loc[trading_date]
+            except KeyError:
+                continue
+            day_open = last["open"]
+            if "open" in r_map_fields:
+                arr[slice_, r_map_fields["open"]] = [day_open if v > 0 else 0.0 for v in d["volume"]]
+            if "prev_close" in r_map_fields:
+                _prev_close = arr[slice_, r_map_fields["prev_close"]][0]
+                if _prev_close != _prev_close:
+                    arr[slice_, r_map_fields["prev_close"]] = last["prev_close"]
+            if instruments(obid).type in ("ETF", "LOF", "FUND"):
+                if "prev_iopv" in r_map_fields:
+                    arr[slice_, r_map_fields["prev_iopv"]] = last["prev_iopv"]
+
+            if instruments(obid).type in ("CS", "ETF", "LOF", "FUND", "Future", "Spot", "Option", "Convertible"):
+                if "limit_up" in r_map_fields:
+                    arr[slice_, r_map_fields["limit_up"]] = last["limit_up"]
+                if "limit_down" in r_map_fields:
+                    arr[slice_, r_map_fields["limit_down"]] = last["limit_down"]
+
+            if instruments(obid).type in ("Future", "Option", "Spot"):
+                if "prev_settlement" in r_map_fields:
+                    arr[slice_, r_map_fields["prev_settlement"]] = last["prev_settlement"]
+                if "change_rate" in r_map_fields:
+                    arr[slice_, r_map_fields["change_rate"]] = arr[slice_, r_map_fields["last"]] / last[
+                        "prev_settlement"] - 1
+            elif "change_rate" in r_map_fields:
+                arr[slice_, r_map_fields["change_rate"]] = arr[slice_, r_map_fields["last"]] / last["prev_close"] - 1
+
+    try:
+        func_is_singletz = getattr(pd._libs.lib, 'is_datetime_with_singletz_array')
+        setattr(pd._libs.lib, 'is_datetime_with_singletz_array', lambda *args: True)
+    except AttributeError:
+        func_is_singletz = None
+    multi_idx = pd.MultiIndex(
+        [obid_level, dt_level],
+        [obid_label, dt_label],
+        names=('order_book_id', dt_name)
+    )
+    df = pd.DataFrame(data=arr, index=multi_idx, columns=fields_)
+    if "trading_date" in r_map_fields:
+        df["trading_date"] = df["trading_date"].astype(int).apply(int8_to_datetime)
+    if func_is_singletz is not None:
+        setattr(pd._libs.lib, 'is_datetime_with_singletz_array', func_is_singletz)
+    return df[fields]
+
+
+def get_history_tick(order_book_ids, start_date, end_date, gtw_fields, columns, market):
+    data = get_client().execute("get_tickbar", order_book_ids, start_date, end_date, gtw_fields, market=market)
+    data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
+    history_df = convert_history_tick_to_multi_df(data, "datetime", columns, int17_to_datetime_v)
+
+    if isinstance(history_df, pd.DataFrame) and 'iopv' in history_df.columns:
+        history_df['iopv'] = history_df['iopv'].replace(0.0, np.nan)
+    return history_df
+
+
+def get_tick_price_multi_df(order_book_ids, start_date, end_date, fields, market):
+    start_date, end_date = ensure_date_range(start_date, end_date, datetime.timedelta(days=3))
+
+    live_date = current_trading_date()
+    if start_date > live_date:
+        return
+
+    ins_list = ensure_instruments(order_book_ids)
+    order_book_ids = [ins.order_book_id for ins in ins_list]
+    types = {ins.type for ins in ins_list}
+
+    if "Future" in types or "Option" in types or "Spot" in types:
+        base_fields = FUTURE_TICK_FIELDS
+        base_columns = FUTURE_TICK_COLUMNS
+
+        if ('Option' in types and any((i.type == 'Option' and i.exchange in ('XSHG', 'XSHE')) for i in ins_list)
+        ) or ('CS' in types) or ('LOF' in types) or ('ETF' in types) or ('FUND' in types) or ('Convertible' in types):
+            base_columns = base_columns + ['num_trades']
+    elif 'ETF' in types or 'LOF' in types or 'FUND' in types:
+        base_fields = FUND_TICK_FIELDS
+        base_columns = FUND_TICK_COLUMNS
+    else:
+        base_fields = EQUITIES_TICK_FIELDS
+        base_columns = EQUITIES_TICK_COLUMNS
+
+    if fields:
+        fields = ensure_list_of_string(fields, "fields")
+        check_items_in_container(fields, base_fields, "fields")
+        columns = [f for f in base_columns if f in fields]
+    else:
+        fields = base_fields
+        columns = base_columns
+
+    gtw_fields = set(fields) | {"date", "time"}
+    if set(fields) & RELATED_DABAR_FIELDS:
+        gtw_fields.update({"volume", "last"})
+
+    history_df = get_history_tick(order_book_ids, start_date, end_date, list(gtw_fields), columns, market)
+    if end_date < live_date:
+        return history_df
+
+    live_date_str = '%d-%02d-%02d' % (live_date // 10000, live_date % 10000 // 100, live_date % 100)
+    live_dfs = []
+    for ins in ins_list:
+        if ins.de_listed_date != '0000-00-00' and ins.de_listed_date < live_date_str:
+            continue
+        try:
+            if history_df is not None and date_to_int8(_to_trading_date(
+                    history_df.loc[ins.order_book_id].index.max())) == live_date:
+                continue
+        except KeyError:
+            pass
+
+        try:
+            live_df = get_ticks(ins.order_book_id, start_date=live_date, end_date=live_date, expect_df=True,
+                                market=market)
+            if live_df is None:
+                continue
+            if "trading_date" not in live_df.columns:
+                live_df["trading_date"] = int8_to_datetime(live_date)
+            else:
+                live_df["trading_date"] = live_df["trading_date"].apply(to_datetime)
+            if ins.type in ("Future", "Option", "Spot"):
+                live_df["change_rate"] = live_df["last"] / live_df["prev_settlement"] - 1
+            else:
+                live_df["change_rate"] = live_df["last"] / live_df["prev_close"] - 1
+            live_df = live_df.reindex(columns=columns)
+            live_dfs.append(live_df)
+        except (PermissionDenied, MarketNotSupportError, NoSuchService):
+            pass
+
+    if not live_dfs:
+        return history_df
+
+    if history_df is None:
+        return pd.concat(live_dfs)
+    return pd.concat([history_df] + live_dfs)
+
+
+def _convert_int_to_datetime(date_int, time_int):
+    return date_int * 1000000000 + time_int
+
+
+def _to_trading_date(dt):
+    if 7 <= dt.hour < 18:
+        return datetime.datetime(year=dt.year, month=dt.month, day=dt.day)
+    return get_next_trading_date(dt - datetime.timedelta(hours=4))
+
+
+def _add_minbar_dominant_id(df, dominant):
+    if 'trading_date' in df.columns:
+        dominant.index = dominant.index.map(lambda x: float(x.year * 10000 + x.month * 100 + x.day))
+        date_dominant_map = dominant.to_dict()
+        df['dominant_id'] = df['trading_date'].map(date_dominant_map)
+    else:
+        date_dominant_map = dominant.to_dict()
+
+        def _set_dominant(dt):
+            trading_date = pd.Timestamp(_to_trading_date(dt))
+            return date_dominant_map[trading_date]
+
+        df['dominant_id'] = df.index.map(_set_dominant)
+    return df
+
+
+@ttl_cache(12 * 3600)
+def _get_hk_part_list():
+    """ 获取港股联交所参与者名单 """
+    data = get_client().execute("get_hk_part_list")
+    hk_part_df = pd.DataFrame(data)
+    return hk_part_df
+
+
+@export_as_api()
+def get_stock_connect_holding_details(order_book_ids, start_date=None, end_date=None):
+    """
+    获取北向资金席位持股明细数据
+    :param order_book_ids: 标的合约
+    :param start_date: 起始日期
+    :param end_date: 结束日期
+    :return: pd.DataFrame
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, type="CS", market="cn")
+    start_date, end_date = ensure_date_range(start_date, end_date, datetime.timedelta(days=3))
+
+    # 北向机构持股明细
+    data = get_client().execute("get_stock_connect_holding_details", order_book_ids, start_date, end_date, market="cn")
+    data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
+    df_list = []
+    for obid, d in data:
+        df = pd.DataFrame(d)
+        df["order_book_id"] = obid
+        df_list.append(df)
+    if len(df_list) == 0:
+        return
+    df = pd.concat(df_list, ignore_index=True)
+    df.rename(columns={"datetime": "date"}, inplace=True)
+    df["participant_number"] = df["participant_number"].map(lambda s: s.decode())
+    df["date"] = pd.to_datetime(df["date"].astype("str"), format="%Y%m%d")
+
+    # 获取港股联交所参与者名单来合并获取机构名称
+    hk_part_df = _get_hk_part_list()
+    df = pd.merge(df, hk_part_df, how="left", on="participant_number")
+
+    df.set_index(keys=["order_book_id", "date"], inplace=True)
+    cols = ["participant_number", "ccass_name", "shares_holding", "holding_ratio"]
+    df = df[cols]
+
+    return df
+
+
+@export_as_api
+def get_vwap(order_book_ids, start_date=None, end_date=None, frequency="1d"):
+    """ 获取vwap(成交量加权平均价格)数据
+
+    :param order_book_ids: 标的合约, 支持股票、期货、期权、ETF、可转债
+    :param market: 地区代码, 如 'cn' (Default value = "cn")
+    :param start_date: 开始日期, 如 '2013-01-04' (Default value = None)
+    :param end_date: 结束日期, 如 '2014-01-04' (Default value = None)
+    :param frequency: 可选参数, 默认为日线。日线使用 '1d', 分钟线 '1m' (Default value = "1d")
+    :returns: multi-index series, 其中index为 order_book_id, date 组成的数据, 值为 vwap
+    """
+    if frequency == "tick":
+        raise ValueError("doesn't support get vwap by tick frequency")
+
+    order_book_ids = ensure_order_book_ids(order_book_ids, {"CS", "Future", "Option", "ETF", "Convertible"})
+    price = get_price(
+        order_book_ids,
+        start_date,
+        end_date,
+        fields=["total_turnover", "volume"],
+        frequency=frequency,
+        adjust_type="none"
+    )
+    if price is None:
+        return None
+    vwap = price["total_turnover"] / price["volume"]
+    vwap.fillna(0, inplace=True)
+
+    # 针对一些合约还需要除以 contract_multiplier
+    order_book_ids = list(set(vwap.index.levels[0]))
+    insts = instruments(order_book_ids)
+    multiplier = {i.order_book_id: getattr(i, "contract_multiplier", 1) for i in insts}
+    return vwap.groupby("order_book_id", group_keys=False).apply(
+        lambda one_vwap: one_vwap / multiplier[one_vwap.name]
+    )
```

## rqdatac/services/index.py

 * *Ordering differences only*

```diff
@@ -1,216 +1,216 @@
-# -*- coding: utf-8 -*-
-
-import bisect
-import pandas as pd
-
-from rqdatac.client import get_client
-from rqdatac.decorators import export_as_api, compatible_with_parm
-from rqdatac.validators import (
-    ensure_date_int,
-    ensure_date_range,
-    ensure_list_of_string,
-    ensure_order_book_ids,
-    ensure_order_book_id,
-    check_items_in_container
-)
-from rqdatac.utils import int8_to_datetime
-from rqdatac.services.calendar import get_trading_dates_in_type
-from rqdatac.rqdatah_helper import rqdatah_serialize, http_conv_index_compoents
-
-
-@export_as_api
-@compatible_with_parm(name="country", value="cn", replace="market")
-@rqdatah_serialize(converter=http_conv_index_compoents, name='order_book_id')
-def index_components(order_book_id, date=None, start_date=None, end_date=None, return_create_tm=False, market="cn"):
-    """获取指数成分
-    :param order_book_id: 指数 id
-    :param date: 指定日期；如不指定，返回最近一个交易日的数据
-    :param start_date: 指定开始日期，不能和date同时指定
-    :param end_date: 指定结束日期, 需和start_date同时指定并且应当不小于开始日期
-    :param return_create_tm: 是否返回入库时间, 默认为False
-    :param market:  (Default value = "cn")
-    :returns list or dict
-    """
-    order_book_id = ensure_order_book_id(order_book_id)
-
-    if date and (start_date or end_date):
-        raise ValueError("date cannot be input together with start_date or end_date")
-    elif (start_date and not end_date) or (end_date and not start_date):
-        raise ValueError("start_date and end_date need to be applied together")
-
-    if start_date:
-        start_date, end_date = ensure_date_range(start_date, end_date)
-        trading_dates = get_trading_dates_in_type(start_date, end_date, expect_type="int")
-        if not trading_dates:
-            return
-        data = get_client().execute(
-            "index_components_v2", order_book_id, trading_dates[0], trading_dates[-1],
-            return_create_tm=return_create_tm, market=market
-        )
-        if not data:
-            return
-        if return_create_tm:
-            data = {
-                d["trade_date"]: (d["component_ids"], pd.to_datetime(d["rice_create_tm"] + 3600 * 8, unit="s"))
-                for d in data
-            }
-        else:
-            data = {d["trade_date"]: d["component_ids"] for d in data}
-        dates = sorted(data.keys())
-        date0 = dates[0]
-        res = {}
-        for trading_date in trading_dates:
-            if trading_date < date0:
-                continue
-            position = bisect.bisect_right(dates, trading_date) - 1
-            res[int8_to_datetime(trading_date)] = data[dates[position]]
-        return res
-
-    if date:
-        date = ensure_date_int(date)
-    result = get_client().execute(
-        "index_components", order_book_id, date, return_create_tm=return_create_tm, market=market
-    )
-    if not result:
-        return None
-    if return_create_tm:
-        create_tm = pd.to_datetime(result.pop("rice_create_tm") + 3600 * 8, unit="s")
-        return result["component_ids"], create_tm
-    else:
-        return result
-
-
-@export_as_api
-def index_weights(order_book_id, date=None, start_date=None, end_date=None, market="cn"):
-    """获取指数的权重
-
-    :param order_book_id: 如'000300.XSHG'和'000905.XSHG'
-    :param market: 地区代码, 如 'cn' (Default value = "cn")
-    :param date: 指定日期；如不指定，返回最近一个交易日的
-    :param start_date: 指定开始日期，不能和date同时指定
-    :param end_date: 指定结束日期, 需和start_date同时指定并且应当不小于开始日期
-    :returns: 返回输入日期最近交易日该指数的权重
-
-    """
-    index_name = ensure_order_book_id(order_book_id)
-    if date and (start_date or end_date):
-        raise ValueError("date cannot be input together with start_date or end_date")
-    elif (start_date and not end_date) or (end_date and not start_date):
-        raise ValueError("start_date and end_date need to be applied together")
-
-    if start_date:
-        start_date, end_date = ensure_date_range(start_date, end_date)
-        trading_dates = get_trading_dates_in_type(start_date, end_date, expect_type="int")
-        if not trading_dates:
-            return
-        data = get_client().execute("index_weights_v2", index_name, trading_dates[0], trading_dates[-1], market=market)
-        if not data:
-            return
-
-        data = {ensure_date_int(d["date"]): d["data"] for d in data}
-        dates = sorted(data.keys())
-        for trading_date in trading_dates:
-            if trading_date not in data:
-                position = bisect.bisect_left(dates, trading_date) - 1
-                data[trading_date] = data[dates[position]]
-
-        data = [
-            {"date": int8_to_datetime(date), "order_book_id": c["order_book_id"], "weight": c["weight"]}
-            for date, component_ids in data.items() if date in trading_dates for c in component_ids
-        ]
-        return pd.DataFrame(data).set_index(["date", "order_book_id"]).sort_index()
-
-    if date:
-        date = ensure_date_int(date)
-
-    data = get_client().execute("index_weights", index_name, date, market=market)
-    if not data:
-        return
-    s = pd.Series({d["order_book_id"]: d["weight"] for d in data})
-    s.index.name = "order_book_id"
-    return s
-
-
-@export_as_api
-def index_indicator(order_book_ids, start_date=None, end_date=None, fields=None, market="cn"):
-    """获取指数指标
-
-    :param order_book_ids: 如'000016.XSHG'
-    :param start_date: 如'2016-01-01' (Default value = None)
-    :param end_date: 如'2017-01-01' (Default value = None)
-    :param fields: 如'pb', 默认返回全部 fields (Default value = None)
-    :param market:  (Default value = "cn")
-    :returns: pd.DataFrame 或 None
-
-    """
-    all_fields = ("pe_ttm", "pe_lyr", "pb_ttm", "pb_lyr", "pb_lf")
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    if fields is not None:
-        fields = ensure_list_of_string(fields)
-        for f in fields:
-            if f not in all_fields:
-                raise ValueError("invalid field: {}".format(f))
-    else:
-        fields = all_fields
-
-    df = get_client().execute(
-        "index_indicator", order_book_ids, start_date, end_date, fields, market=market
-    )
-    if not df:
-        return
-    df = pd.DataFrame(df)
-    df.set_index(["order_book_id", "trade_date"], inplace=True)
-    return df
-
-
-# 目前支持日度指数的权重，需配合 dps 任务更改
-EX_WEIGHTS_INDEXES = [
-    "000016.XSHG",
-    "000300.XSHG",
-    "000905.XSHG",
-    "000906.XSHG",
-    "000852.XSHG",
-    "932000.INDX",
-]
-
-
-@export_as_api
-def index_weights_ex(order_book_id, date=None, start_date=None, end_date=None, market="cn"):
-    """ 米筐根据中证公布的月度权重，结合股票涨跌推算的指数成分日度权重，目前包含：
-        上证50、沪深300、 中证500、 中证800、 中证1000、中证2000
-
-    :param order_book_id: 如'000300.XSHG'和'000905.XSHG'
-    :param market: 地区代码, 如 'cn' (Default value = "cn")
-    :param date: 指定日期；如不指定，返回最近一个交易日的
-    :param start_date: 指定开始日期，不能和date同时指定
-    :param end_date: 指定结束日期, 需和start_date同时指定并且应当不小于开始日期
-    :returns: 返回输入日期最近交易日该指数的权重
-
-    """
-    check_items_in_container(order_book_id, EX_WEIGHTS_INDEXES, "order_book_id")
-    if date and (start_date or end_date):
-        raise ValueError("date cannot be input together with start_date or end_date")
-    elif (start_date and not end_date) or (end_date and not start_date):
-        raise ValueError("start_date and end_date need to be applied together")
-    
-    if start_date:
-        start_date, end_date = ensure_date_range(start_date, end_date)
-        data = get_client().execute("index_weights_ex", order_book_id, start_date, end_date, market=market)
-        if not data:
-            return
-        data = [
-            {"date": d["date"], "order_book_id": c["order_book_id"], "weight": c["weight"]}
-            for d in data for c in d["data"]
-        ]
-        return pd.DataFrame(data).set_index(["date", "order_book_id"]).sort_index()
-    
-    if date:
-        date = ensure_date_int(date)
-
-    data = get_client().execute("index_weights_ex", order_book_id, date, date, market=market)
-    if not data:
-        return
-    s = pd.Series({d["order_book_id"]: d["weight"] for d in data[0]["data"]})
-    s.index.name = "order_book_id"
-    return s
+# -*- coding: utf-8 -*-
+
+import bisect
+import pandas as pd
+
+from rqdatac.client import get_client
+from rqdatac.decorators import export_as_api, compatible_with_parm
+from rqdatac.validators import (
+    ensure_date_int,
+    ensure_date_range,
+    ensure_list_of_string,
+    ensure_order_book_ids,
+    ensure_order_book_id,
+    check_items_in_container
+)
+from rqdatac.utils import int8_to_datetime
+from rqdatac.services.calendar import get_trading_dates_in_type
+from rqdatac.rqdatah_helper import rqdatah_serialize, http_conv_index_compoents
+
+
+@export_as_api
+@compatible_with_parm(name="country", value="cn", replace="market")
+@rqdatah_serialize(converter=http_conv_index_compoents, name='order_book_id')
+def index_components(order_book_id, date=None, start_date=None, end_date=None, return_create_tm=False, market="cn"):
+    """获取指数成分
+    :param order_book_id: 指数 id
+    :param date: 指定日期；如不指定，返回最近一个交易日的数据
+    :param start_date: 指定开始日期，不能和date同时指定
+    :param end_date: 指定结束日期, 需和start_date同时指定并且应当不小于开始日期
+    :param return_create_tm: 是否返回入库时间, 默认为False
+    :param market:  (Default value = "cn")
+    :returns list or dict
+    """
+    order_book_id = ensure_order_book_id(order_book_id)
+
+    if date and (start_date or end_date):
+        raise ValueError("date cannot be input together with start_date or end_date")
+    elif (start_date and not end_date) or (end_date and not start_date):
+        raise ValueError("start_date and end_date need to be applied together")
+
+    if start_date:
+        start_date, end_date = ensure_date_range(start_date, end_date)
+        trading_dates = get_trading_dates_in_type(start_date, end_date, expect_type="int")
+        if not trading_dates:
+            return
+        data = get_client().execute(
+            "index_components_v2", order_book_id, trading_dates[0], trading_dates[-1],
+            return_create_tm=return_create_tm, market=market
+        )
+        if not data:
+            return
+        if return_create_tm:
+            data = {
+                d["trade_date"]: (d["component_ids"], pd.to_datetime(d["rice_create_tm"] + 3600 * 8, unit="s"))
+                for d in data
+            }
+        else:
+            data = {d["trade_date"]: d["component_ids"] for d in data}
+        dates = sorted(data.keys())
+        date0 = dates[0]
+        res = {}
+        for trading_date in trading_dates:
+            if trading_date < date0:
+                continue
+            position = bisect.bisect_right(dates, trading_date) - 1
+            res[int8_to_datetime(trading_date)] = data[dates[position]]
+        return res
+
+    if date:
+        date = ensure_date_int(date)
+    result = get_client().execute(
+        "index_components", order_book_id, date, return_create_tm=return_create_tm, market=market
+    )
+    if not result:
+        return None
+    if return_create_tm:
+        create_tm = pd.to_datetime(result.pop("rice_create_tm") + 3600 * 8, unit="s")
+        return result["component_ids"], create_tm
+    else:
+        return result
+
+
+@export_as_api
+def index_weights(order_book_id, date=None, start_date=None, end_date=None, market="cn"):
+    """获取指数的权重
+
+    :param order_book_id: 如'000300.XSHG'和'000905.XSHG'
+    :param market: 地区代码, 如 'cn' (Default value = "cn")
+    :param date: 指定日期；如不指定，返回最近一个交易日的
+    :param start_date: 指定开始日期，不能和date同时指定
+    :param end_date: 指定结束日期, 需和start_date同时指定并且应当不小于开始日期
+    :returns: 返回输入日期最近交易日该指数的权重
+
+    """
+    index_name = ensure_order_book_id(order_book_id)
+    if date and (start_date or end_date):
+        raise ValueError("date cannot be input together with start_date or end_date")
+    elif (start_date and not end_date) or (end_date and not start_date):
+        raise ValueError("start_date and end_date need to be applied together")
+
+    if start_date:
+        start_date, end_date = ensure_date_range(start_date, end_date)
+        trading_dates = get_trading_dates_in_type(start_date, end_date, expect_type="int")
+        if not trading_dates:
+            return
+        data = get_client().execute("index_weights_v2", index_name, trading_dates[0], trading_dates[-1], market=market)
+        if not data:
+            return
+
+        data = {ensure_date_int(d["date"]): d["data"] for d in data}
+        dates = sorted(data.keys())
+        for trading_date in trading_dates:
+            if trading_date not in data:
+                position = bisect.bisect_left(dates, trading_date) - 1
+                data[trading_date] = data[dates[position]]
+
+        data = [
+            {"date": int8_to_datetime(date), "order_book_id": c["order_book_id"], "weight": c["weight"]}
+            for date, component_ids in data.items() if date in trading_dates for c in component_ids
+        ]
+        return pd.DataFrame(data).set_index(["date", "order_book_id"]).sort_index()
+
+    if date:
+        date = ensure_date_int(date)
+
+    data = get_client().execute("index_weights", index_name, date, market=market)
+    if not data:
+        return
+    s = pd.Series({d["order_book_id"]: d["weight"] for d in data})
+    s.index.name = "order_book_id"
+    return s
+
+
+@export_as_api
+def index_indicator(order_book_ids, start_date=None, end_date=None, fields=None, market="cn"):
+    """获取指数指标
+
+    :param order_book_ids: 如'000016.XSHG'
+    :param start_date: 如'2016-01-01' (Default value = None)
+    :param end_date: 如'2017-01-01' (Default value = None)
+    :param fields: 如'pb', 默认返回全部 fields (Default value = None)
+    :param market:  (Default value = "cn")
+    :returns: pd.DataFrame 或 None
+
+    """
+    all_fields = ("pe_ttm", "pe_lyr", "pb_ttm", "pb_lyr", "pb_lf")
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    if fields is not None:
+        fields = ensure_list_of_string(fields)
+        for f in fields:
+            if f not in all_fields:
+                raise ValueError("invalid field: {}".format(f))
+    else:
+        fields = all_fields
+
+    df = get_client().execute(
+        "index_indicator", order_book_ids, start_date, end_date, fields, market=market
+    )
+    if not df:
+        return
+    df = pd.DataFrame(df)
+    df.set_index(["order_book_id", "trade_date"], inplace=True)
+    return df
+
+
+# 目前支持日度指数的权重，需配合 dps 任务更改
+EX_WEIGHTS_INDEXES = [
+    "000016.XSHG",
+    "000300.XSHG",
+    "000905.XSHG",
+    "000906.XSHG",
+    "000852.XSHG",
+    "932000.INDX",
+]
+
+
+@export_as_api
+def index_weights_ex(order_book_id, date=None, start_date=None, end_date=None, market="cn"):
+    """ 米筐根据中证公布的月度权重，结合股票涨跌推算的指数成分日度权重，目前包含：
+        上证50、沪深300、 中证500、 中证800、 中证1000、中证2000
+
+    :param order_book_id: 如'000300.XSHG'和'000905.XSHG'
+    :param market: 地区代码, 如 'cn' (Default value = "cn")
+    :param date: 指定日期；如不指定，返回最近一个交易日的
+    :param start_date: 指定开始日期，不能和date同时指定
+    :param end_date: 指定结束日期, 需和start_date同时指定并且应当不小于开始日期
+    :returns: 返回输入日期最近交易日该指数的权重
+
+    """
+    check_items_in_container(order_book_id, EX_WEIGHTS_INDEXES, "order_book_id")
+    if date and (start_date or end_date):
+        raise ValueError("date cannot be input together with start_date or end_date")
+    elif (start_date and not end_date) or (end_date and not start_date):
+        raise ValueError("start_date and end_date need to be applied together")
+    
+    if start_date:
+        start_date, end_date = ensure_date_range(start_date, end_date)
+        data = get_client().execute("index_weights_ex", order_book_id, start_date, end_date, market=market)
+        if not data:
+            return
+        data = [
+            {"date": d["date"], "order_book_id": c["order_book_id"], "weight": c["weight"]}
+            for d in data for c in d["data"]
+        ]
+        return pd.DataFrame(data).set_index(["date", "order_book_id"]).sort_index()
+    
+    if date:
+        date = ensure_date_int(date)
+
+    data = get_client().execute("index_weights_ex", order_book_id, date, date, market=market)
+    if not data:
+        return
+    s = pd.Series({d["order_book_id"]: d["weight"] for d in data[0]["data"]})
+    s.index.name = "order_book_id"
+    return s
```

## rqdatac/services/ksh_auction_info.py

 * *Ordering differences only*

```diff
@@ -1,168 +1,168 @@
-# -*- coding: utf-8 -*-
-import datetime
-
-import pandas as pd
-import numpy as np
-
-from rqdatac.services.calendar import get_previous_trading_date
-from rqdatac.validators import (
-    ensure_string_in,
-    ensure_order_book_id,
-    ensure_order_book_ids,
-    ensure_date_range,
-    check_items_in_container,
-    ensure_list_of_string
-)
-from rqdatac.utils import (
-    int8_to_datetime_v,
-    int14_to_datetime_v,
-    int17_to_datetime_v,
-    int17_to_datetime,
-    today_int,
-    date_to_int8,
-    convert_bar_to_multi_df,
-)
-from rqdatac.client import get_client
-from rqdatac.decorators import export_as_api
-from rqdatac.share.errors import MarketNotSupportError, PermissionDenied
-
-DAYBAR_FIELDS = [
-    "close", "volume", "total_turnover"
-]
-TICKBAR_FIELDS = [
-    "datetime", "close", "volume", "total_turnover", "bid_vol", "ask_vol"
-]
-
-
-def get_auction_info_daybar(order_book_ids, start_date, end_date, fields, duration=1, market="cn"):
-    data = get_client().execute(
-        "get_auction_info_daybar", order_book_ids, start_date, end_date, fields, duration, market
-    )
-    data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
-    res = convert_bar_to_multi_df(data, 'date', fields, int8_to_datetime_v)
-    return res
-
-
-def get_today_auction_info_minbar(order_book_ids, date, fields, duration, market="cn"):
-    data = get_client().execute("get_today_auction_info_minbar", order_book_ids, date, fields, duration, market)
-    return convert_bar_to_multi_df(data, "datetime", fields, int14_to_datetime_v)
-
-
-def get_auction_info_minbar(order_book_ids, start_date, end_date, fields, duration, market):
-    data = get_client().execute(
-        "get_auction_info_minbar", order_book_ids, start_date, end_date, fields, duration, market
-    )
-    if data:
-        data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
-        df = convert_bar_to_multi_df(data, 'datetime', fields, int14_to_datetime_v)
-    else:
-        df = None
-
-    today = today_int()
-    if df is None:
-        history_latest_date = date_to_int8(get_previous_trading_date(today, market=market))
-    else:
-        history_latest_date = date_to_int8(df.index.get_level_values(1).max())
-
-    if history_latest_date >= end_date or start_date > today or history_latest_date >= today:
-        return df
-    try:
-        live_df = get_today_auction_info_minbar(order_book_ids, today, fields, duration, market)
-    except (MarketNotSupportError, PermissionDenied):
-        live_df = None
-    if live_df is None:
-        return df
-    if df is None:
-        return live_df
-    df = pd.concat([df, live_df])
-    df.sort_index(inplace=True)
-    return df
-
-
-def get_today_auction_info_tick(order_book_id, date, fields, market="cn"):
-    data = get_client().execute("get_today_auction_info_tick", order_book_id, date, market)
-    df = pd.DataFrame(data[0])
-    if df.empty:
-        return None
-    df = df[fields]
-    df.datetime = df.datetime.apply(int17_to_datetime)
-    df.set_index("datetime", inplace=True)
-    return df
-
-
-def get_auction_info_tickbar(order_book_id, start_date, end_date, fields, market):
-    order_book_id = ensure_order_book_id(order_book_id)
-    start_date, end_date = ensure_date_range(start_date, end_date, datetime.timedelta(days=3))
-    data = get_client().execute(
-        "get_auction_info_tickbar", order_book_id, start_date, end_date, fields, market
-    )
-    today = today_int()
-    if data:
-        data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
-        df_list = []
-        for obid, d in data:
-            df = pd.DataFrame(d)
-            df_list.append(df)
-
-        df = pd.concat(df_list)  # type: pd.DataFrame
-        df["datetime"] = int17_to_datetime_v(df["datetime"].values)
-        history_latest_date = date_to_int8(df.iloc[-1]["datetime"])
-        df.set_index("datetime", inplace=True)
-    else:
-        df = None
-        history_latest_date = date_to_int8(get_previous_trading_date(today, market=market))
-
-    if history_latest_date >= end_date or start_date > today or history_latest_date >= today:
-        return df
-    try:
-        live_df = get_today_auction_info_tick(order_book_id, today, fields, market=market)
-    except (MarketNotSupportError, PermissionDenied):
-        live_df = None
-    if live_df is None:
-        return df
-    if df is None:
-        return live_df
-    return pd.concat([df, live_df])
-
-
-@export_as_api
-def get_ksh_auction_info(order_book_ids, start_date=None, end_date=None, frequency="1d", market="cn"):
-    import warnings
-
-    msg = "'get_ksh_auction_info' is deprecated, and will be removed on 2021-01-29, " \
-          "use 'get_auction_info' instead."
-    warnings.warn(msg, stacklevel=2)
-    return get_auction_info(order_book_ids, start_date, end_date, frequency, market)
-
-
-@export_as_api
-def get_auction_info(order_book_ids, start_date=None, end_date=None, frequency="1d", fields=None, market="cn"):
-    """获取股票盘后数据
-    :param order_book_ids: 股票代码or股票代码列表, 如'000001.XSHE'
-    :param start_date: 开始日期
-    :param end_date: 结束日期
-    :param frequency: 默认为日线。日线使用 '1d', 分钟线 '1m'  快照 'tick' (Default value = "1d"),
-    :param fields: 需要获取的字段, 默认为所有字段
-    :param market:  (Default value = "cn")
-    :returns: pandas.DataFrame or None
-    """
-    ensure_string_in(frequency, ("1d", "1m", "tick"), "frequency")
-    if frequency == "tick":
-        if fields is not None:
-            ensure_list_of_string(fields, "fields")
-            check_items_in_container(fields, set(TICKBAR_FIELDS), "fields")
-        else:
-            fields = TICKBAR_FIELDS
-        return get_auction_info_tickbar(order_book_ids, start_date, end_date, fields, market)
-
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    if fields is not None:
-        ensure_list_of_string(fields, "fields")
-        check_items_in_container(fields, set(DAYBAR_FIELDS), "fields")
-    else:
-        fields = DAYBAR_FIELDS
-    if frequency == "1d":
-        return get_auction_info_daybar(order_book_ids, start_date, end_date, fields, 1, market)
-
+# -*- coding: utf-8 -*-
+import datetime
+
+import pandas as pd
+import numpy as np
+
+from rqdatac.services.calendar import get_previous_trading_date
+from rqdatac.validators import (
+    ensure_string_in,
+    ensure_order_book_id,
+    ensure_order_book_ids,
+    ensure_date_range,
+    check_items_in_container,
+    ensure_list_of_string
+)
+from rqdatac.utils import (
+    int8_to_datetime_v,
+    int14_to_datetime_v,
+    int17_to_datetime_v,
+    int17_to_datetime,
+    today_int,
+    date_to_int8,
+    convert_bar_to_multi_df,
+)
+from rqdatac.client import get_client
+from rqdatac.decorators import export_as_api
+from rqdatac.share.errors import MarketNotSupportError, PermissionDenied
+
+DAYBAR_FIELDS = [
+    "close", "volume", "total_turnover"
+]
+TICKBAR_FIELDS = [
+    "datetime", "close", "volume", "total_turnover", "bid_vol", "ask_vol"
+]
+
+
+def get_auction_info_daybar(order_book_ids, start_date, end_date, fields, duration=1, market="cn"):
+    data = get_client().execute(
+        "get_auction_info_daybar", order_book_ids, start_date, end_date, fields, duration, market
+    )
+    data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
+    res = convert_bar_to_multi_df(data, 'date', fields, int8_to_datetime_v)
+    return res
+
+
+def get_today_auction_info_minbar(order_book_ids, date, fields, duration, market="cn"):
+    data = get_client().execute("get_today_auction_info_minbar", order_book_ids, date, fields, duration, market)
+    return convert_bar_to_multi_df(data, "datetime", fields, int14_to_datetime_v)
+
+
+def get_auction_info_minbar(order_book_ids, start_date, end_date, fields, duration, market):
+    data = get_client().execute(
+        "get_auction_info_minbar", order_book_ids, start_date, end_date, fields, duration, market
+    )
+    if data:
+        data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
+        df = convert_bar_to_multi_df(data, 'datetime', fields, int14_to_datetime_v)
+    else:
+        df = None
+
+    today = today_int()
+    if df is None:
+        history_latest_date = date_to_int8(get_previous_trading_date(today, market=market))
+    else:
+        history_latest_date = date_to_int8(df.index.get_level_values(1).max())
+
+    if history_latest_date >= end_date or start_date > today or history_latest_date >= today:
+        return df
+    try:
+        live_df = get_today_auction_info_minbar(order_book_ids, today, fields, duration, market)
+    except (MarketNotSupportError, PermissionDenied):
+        live_df = None
+    if live_df is None:
+        return df
+    if df is None:
+        return live_df
+    df = pd.concat([df, live_df])
+    df.sort_index(inplace=True)
+    return df
+
+
+def get_today_auction_info_tick(order_book_id, date, fields, market="cn"):
+    data = get_client().execute("get_today_auction_info_tick", order_book_id, date, market)
+    df = pd.DataFrame(data[0])
+    if df.empty:
+        return None
+    df = df[fields]
+    df.datetime = df.datetime.apply(int17_to_datetime)
+    df.set_index("datetime", inplace=True)
+    return df
+
+
+def get_auction_info_tickbar(order_book_id, start_date, end_date, fields, market):
+    order_book_id = ensure_order_book_id(order_book_id)
+    start_date, end_date = ensure_date_range(start_date, end_date, datetime.timedelta(days=3))
+    data = get_client().execute(
+        "get_auction_info_tickbar", order_book_id, start_date, end_date, fields, market
+    )
+    today = today_int()
+    if data:
+        data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
+        df_list = []
+        for obid, d in data:
+            df = pd.DataFrame(d)
+            df_list.append(df)
+
+        df = pd.concat(df_list)  # type: pd.DataFrame
+        df["datetime"] = int17_to_datetime_v(df["datetime"].values)
+        history_latest_date = date_to_int8(df.iloc[-1]["datetime"])
+        df.set_index("datetime", inplace=True)
+    else:
+        df = None
+        history_latest_date = date_to_int8(get_previous_trading_date(today, market=market))
+
+    if history_latest_date >= end_date or start_date > today or history_latest_date >= today:
+        return df
+    try:
+        live_df = get_today_auction_info_tick(order_book_id, today, fields, market=market)
+    except (MarketNotSupportError, PermissionDenied):
+        live_df = None
+    if live_df is None:
+        return df
+    if df is None:
+        return live_df
+    return pd.concat([df, live_df])
+
+
+@export_as_api
+def get_ksh_auction_info(order_book_ids, start_date=None, end_date=None, frequency="1d", market="cn"):
+    import warnings
+
+    msg = "'get_ksh_auction_info' is deprecated, and will be removed on 2021-01-29, " \
+          "use 'get_auction_info' instead."
+    warnings.warn(msg, stacklevel=2)
+    return get_auction_info(order_book_ids, start_date, end_date, frequency, market)
+
+
+@export_as_api
+def get_auction_info(order_book_ids, start_date=None, end_date=None, frequency="1d", fields=None, market="cn"):
+    """获取股票盘后数据
+    :param order_book_ids: 股票代码or股票代码列表, 如'000001.XSHE'
+    :param start_date: 开始日期
+    :param end_date: 结束日期
+    :param frequency: 默认为日线。日线使用 '1d', 分钟线 '1m'  快照 'tick' (Default value = "1d"),
+    :param fields: 需要获取的字段, 默认为所有字段
+    :param market:  (Default value = "cn")
+    :returns: pandas.DataFrame or None
+    """
+    ensure_string_in(frequency, ("1d", "1m", "tick"), "frequency")
+    if frequency == "tick":
+        if fields is not None:
+            ensure_list_of_string(fields, "fields")
+            check_items_in_container(fields, set(TICKBAR_FIELDS), "fields")
+        else:
+            fields = TICKBAR_FIELDS
+        return get_auction_info_tickbar(order_book_ids, start_date, end_date, fields, market)
+
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    if fields is not None:
+        ensure_list_of_string(fields, "fields")
+        check_items_in_container(fields, set(DAYBAR_FIELDS), "fields")
+    else:
+        fields = DAYBAR_FIELDS
+    if frequency == "1d":
+        return get_auction_info_daybar(order_book_ids, start_date, end_date, fields, 1, market)
+
     return get_auction_info_minbar(order_book_ids, start_date, end_date, fields, 1, market)
```

## rqdatac/services/live.py

 * *Ordering differences only*

```diff
@@ -1,493 +1,493 @@
-# -*- coding: utf-8 -*-
-import datetime
-from itertools import chain
-
-import pandas as pd
-import numpy as np
-
-from rqdatac.services.basic import instruments
-from rqdatac.services.future import current_real_contract
-from rqdatac.services.calendar import get_trading_dates_in_type, get_previous_trading_date, is_trading_date, get_next_trading_date
-from rqdatac.utils import (to_datetime, int8_to_date, int9_to_time, int14_to_datetime,
-                           get_tick_value, datetime_to_int17, relativedelta, int17_to_datetime)
-from rqdatac.client import get_client
-from rqdatac.decorators import export_as_api
-from rqdatac.validators import (ensure_instruments,
-                                check_items_in_container, ensure_list_of_string)
-from rqdatac.services.stock_status import is_suspended
-from rqdatac.rqdatah_helper import rqdatah_serialize, http_conv_ticks
-
-
-@export_as_api
-@rqdatah_serialize(converter=http_conv_ticks)
-def current_snapshot(order_book_ids, market="cn"):
-    """获取实时行情
-
-    :param order_book_ids: 股票或期货代码或代码列表
-    :param market: 地区代码, 如'cn' (Default value = "cn")
-    :returns: Snapshot Object或Snapshot Object列表
-
-    """
-    _instruments = ensure_instruments(order_book_ids)
-    order_book_ids = []
-    for ins in _instruments:
-        if ins.type == "Future" and ins.order_book_id.endswith("88"):
-            real_contract = current_real_contract(ins.underlying_symbol, market) or ins.order_book_id
-            order_book_ids.append(real_contract)
-        else:
-            order_book_ids.append(ins.order_book_id)
-
-    snapshots = get_client().execute("current_snapshots", order_book_ids, market=market)
-    tick_objects = [TickObject(ins.order_book_id, snapshots[i]) for i, ins in enumerate(_instruments)]
-    if len(order_book_ids) == 1:
-        return tick_objects[0]
-    return tick_objects
-
-
-class TickObject(object):
-    _STOCK_FIELDS = [
-        ("datetime", np.uint64),
-        ("open", np.float64),
-        ("high", np.float64),
-        ("low", np.float64),
-        ("last", np.float64),
-        ('limit_up', np.float64),
-        ('limit_down', np.float64),
-        ("iopv", np.float64),
-        ("pre_iopv", np.float64),
-        ("volume", np.int32),
-        ("total_turnover", np.int64),
-        ("prev_close", np.float64),
-        ('close', np.float64),
-        ('settlement', np.float64),
-        ("ask", list),
-        ("ask_vol", list),
-        ("bid", list),
-        ("bid_vol", list),
-        ("trading_phase_code", str),
-    ]
-
-    _FUTURE_FIELDS = _STOCK_FIELDS + [("open_interest", np.int32), ("prev_settlement", np.float64)]
-
-    _STOCK_FIELD_NAMES = [_n for _n, _ in _STOCK_FIELDS]
-    _FUTURE_FIELD_NAMES = [_n for _n, _ in _FUTURE_FIELDS]
-
-    _NANDict = {_n: np.nan for _n, dtype in _FUTURE_FIELDS if dtype == np.float64}
-
-    def __init__(self, order_book_id, data, dt=None):
-        self._dt = dt
-        if data is None:
-            self._data = self._NANDict
-        else:
-            self._data = data
-        self._order_book_id = order_book_id
-
-    @property
-    def order_book_id(self):
-        return self._order_book_id
-
-    @property
-    def open(self):
-        return self._data.get("open", 0)
-
-    @property
-    def last(self):
-        return self._data.get("last", 0)
-
-    @property
-    def low(self):
-        return self._data.get("low", 0)
-
-    @property
-    def high(self):
-        return self._data.get("high", 0)
-
-    @property
-    def limit_up(self):
-        return self._data.get('limit_up', 0)
-
-    @property
-    def limit_down(self):
-        return self._data.get('limit_down', 0)
-
-    @property
-    def num_trades(self):
-        return self._data.get('num_trades', 0)
-
-    @property
-    def prev_close(self):
-        return self._data.get("prev_close", 0)
-
-    @property
-    def iopv(self):
-        return self._data.get("iopv", np.nan)
-
-    @property
-    def prev_iopv(self):
-        return self._data.get("prev_iopv", np.nan)
-
-    @property
-    def volume(self):
-        return self._data.get("volume", 0)
-
-    @property
-    def total_turnover(self):
-        return self._data.get("total_turnover", 0)
-
-    @property
-    def close(self):
-        return self._data.get('close', np.nan)
-
-    @property
-    def settlement(self):
-        return self._data.get('settlement', np.nan)
-
-    @property
-    def datetime(self):
-        if self._dt is not None:
-            return self._dt
-        if not self._isnan:
-            dt = self._data["datetime"]
-            return to_datetime(dt)
-        return datetime.datetime.min
-
-    @property
-    def prev_settlement(self):
-        try:
-            return self._data["prev_settlement"]
-        except KeyError:
-            return None
-
-    @property
-    def open_interest(self):
-        try:
-            return self._data["open_interest"]
-        except KeyError:
-            return None
-
-    @property
-    def trading_phase_code(self):
-        try:
-            return self._data["trading_phase_code"]
-        except KeyError:
-            return None
-
-    @property
-    def asks(self):
-        return self._data.get("ask", [0, 0, 0, 0, 0])
-
-    @property
-    def ask_vols(self):
-        return self._data.get("ask_vol", [0, 0, 0, 0, 0])
-
-    @property
-    def bids(self):
-        return self._data.get("bid", [0, 0, 0, 0, 0])
-
-    @property
-    def bid_vols(self):
-        return self._data.get("bid_vol", [0, 0, 0, 0, 0])
-
-    @property
-    def _isnan(self):
-        return np.isnan(self._data["last"])
-
-    def __repr__(self):
-        items = []
-        for name in dir(self):
-            if name.startswith("_"):
-                continue
-            items.append((name, getattr(self, name)))
-        return "Tick({0})".format(
-            ", ".join("{0}: {1}".format(k, v) for k, v in items if k is not None)
-        )
-
-    def __getitem__(self, key):
-        return getattr(self, key)
-
-
-EQUITIES_FIELDS = (
-    "datetime",
-    "open",
-    "last",
-    "high",
-    "low",
-    "iopv",
-    "prev_iopv",
-    "limit_up",
-    "limit_down",
-    "prev_close",
-    "volume",
-    "total_turnover",
-    "a1",
-    "a2",
-    "a3",
-    "a4",
-    "a5",
-    "b1",
-    "b2",
-    "b3",
-    "b4",
-    "b5",
-    "a1_v",
-    "a2_v",
-    "a3_v",
-    "a4_v",
-    "a5_v",
-    "b1_v",
-    "b2_v",
-    "b3_v",
-    "b4_v",
-    "b5_v",
-    "num_trades",
-)
-
-FUTURE_FIELDS = (
-    "datetime",
-    "trading_date",
-    "update_time",
-    "open",
-    "last",
-    "high",
-    "low",
-    "limit_up",
-    "limit_down",
-    "prev_settlement",
-    "prev_close",
-    "volume",
-    "total_turnover",
-    "open_interest",
-    "a1",
-    "a2",
-    "a3",
-    "a4",
-    "a5",
-    "b1",
-    "b2",
-    "b3",
-    "b4",
-    "b5",
-    "a1_v",
-    "a2_v",
-    "a3_v",
-    "a4_v",
-    "a5_v",
-    "b1_v",
-    "b2_v",
-    "b3_v",
-    "b4_v",
-    "b5_v",
-)
-
-
-@export_as_api
-def get_ticks(order_book_id, start_date=None, end_date=None, expect_df=True, market="cn"):
-    """获取实时tick
-
-    :param order_book_id: 股票代码, 如'000001.XSHE'
-    :param start_date: 开始日期, 不指定则为今天
-    :param end_date: 结束日期, 不指定则为今天
-    :param expect_df: 返回 MultiIndex DataFrame (Default value = True)
-    :param market:  (Default value = "cn")
-    :returns: pd.DataFrame or None
-
-    """
-    instrument = instruments(order_book_id, market)
-    if not instrument:
-        raise ValueError("invalid order_book_id: {}".format(order_book_id))
-
-    order_book_id = instrument.order_book_id
-    future_like = instrument.type in ("Future", "Option", "Spot")
-
-    now = datetime.datetime.now()
-    if is_trading_date(now):
-        if (now.hour, now.minute) >= (19, 30):
-            day = get_next_trading_date(now)
-        else:
-            day = now.date()
-    else:
-        day = get_next_trading_date(now)
-
-    dates = get_trading_dates_in_type(
-        start_date or day,
-        end_date or day,
-        expect_type="str",
-        fmt="%Y%m%d",
-        market=market,
-    )
-    ticks = get_client().execute("get_ticks_v2", order_book_id, dates, market=market)
-    if future_like:
-        fields = FUTURE_FIELDS
-    else:
-        fields = EQUITIES_FIELDS
-
-    if future_like and instrument.exchange in ("XSHE", "XSHG"):
-        fields = list(FUTURE_FIELDS) + ["num_trades"]
-
-    dtype = np.dtype([(f, _field_type(f)) for f in fields])
-    bars = np.array([tuple([get_tick_value(t, f, np.nan) if f in ("iopv", "prev_iopv") else get_tick_value(t, f)
-                            for f in fields]) for t in chain(*ticks)], dtype=dtype)
-    df = pd.DataFrame(bars)
-
-    if df.empty:
-        return None
-    if "trading_date" in df.columns:
-        df.trading_date = df.trading_date.apply(int8_to_date)
-        df.update_time = df.update_time.apply(int9_to_time)
-    df.datetime = df.datetime.apply(to_datetime)
-    if expect_df:
-        df["order_book_id"] = order_book_id
-        df.set_index(["order_book_id", "datetime"], inplace=True)
-    else:
-        df.set_index("datetime", inplace=True)
-    return df
-
-
-def _field_type(field_name):
-    return np.uint64 if field_name in ("datetime", "trading_date", "update_time") else np.float64
-
-
-@export_as_api
-def current_minute(order_book_ids, skip_suspended=False, fields=None, market="cn"):
-    """获取实时分钟行情
-    :param order_book_ids: 合约代码或代码列表
-    :param skip_suspended: 是否过滤停复牌. (Default value = False)
-    :param fields: 可选参数。默认为所有字段。 (Default value = None)
-    :param market: 地区代码, 如'cn' (Default value = "cn")
-    :returns: None or pd.DataFrame
-    """
-    from rqdatac.services.get_price import classify_order_book_ids, _ensure_fields
-    from rqdatac.services.detail.get_price_df import MINBAR_FIELDS
-
-    (order_book_ids, stocks, funds, indexes, futures, futures888, spots, options,
-        convertibles, repos) = classify_order_book_ids(order_book_ids, market)
-
-    futures_88 = [i for i in instruments(order_book_ids) if i.order_book_id.endswith('88') and i.type == 'Future']
-    real_contracts = {
-        i.order_book_id: current_real_contract(i.underlying_symbol, market)
-        for i in futures_88
-    }
-    real_contracts = {k: v for k, v in real_contracts.items() if v is not None}
-    if skip_suspended and stocks:
-        date = get_previous_trading_date(datetime.date.today() + datetime.timedelta(days=1))
-        df_suspended = is_suspended(stocks, date, date)
-        if not df_suspended.empty:
-            df_suspended_t = df_suspended.T
-            suspended_obids = set(df_suspended_t[df_suspended_t[df_suspended_t.columns[0]]].index)
-            inspection = suspended_obids & set(stocks)
-            if inspection:
-                stocks = set(stocks) - inspection
-                order_book_ids = list(set(order_book_ids) - inspection)
-
-    fields, _ = _ensure_fields(fields, MINBAR_FIELDS, stocks, funds, futures, futures888, spots, options, convertibles, indexes, repos)
-    if real_contracts:
-        order_book_ids = set(order_book_ids)
-        obs = list(order_book_ids.union(set(real_contracts.values())))
-    else:
-        obs = order_book_ids
-    data = get_client().execute("current_minute", obs, fields + ["datetime"], market=market)
-    if not data:
-        return
-
-    if real_contracts:
-        data = {bar['order_book_id']: bar for bar in data}
-
-        def _rename_bar(bar, ob):
-            bar = bar.copy()
-            bar['order_book_id'] = ob
-            return bar
-        data.update((ob, _rename_bar(data[contract], ob)) for ob, contract in real_contracts.items() if contract in data)
-        data = [data[ob] for ob in order_book_ids if ob in data]
-
-    df = pd.DataFrame(data)
-    df["datetime"] = df["datetime"].map(int14_to_datetime, na_action="ignore")
-    df.set_index(["order_book_id", "datetime"], inplace=True)
-    return df
-
-
-@export_as_api
-def get_live_ticks(order_book_ids, start_dt=None, end_dt=None, fields=None, market="cn"):
-    """获取实时tick
-    :param order_book_ids: 股票代码或代码列表, 如'000001.XSHE'
-    :param start_dt: 开始时间，如20200102213000 或 "2020-01-02 21:30:00"， 默认为今天
-    :param end_dt: 结束时间，如20200102153000 或 "2020-01-03 15:30:00"， 默认为今天
-    :param fields: 可选参数。默认为所有字段。 (Default value = None)
-    :param market:  (Default value = "cn")
-
-    :returns: pd.DataFrame or None
-    """
-
-    if start_dt is None and end_dt is None:
-        now = datetime.datetime.now()
-        if is_trading_date(now):
-            if (now.hour, now.minute) >= (19, 30):
-                day = get_next_trading_date(now)
-            else:
-                day = now.date()
-        else:
-            day = get_next_trading_date(now)
-
-        dates = get_trading_dates_in_type(
-            day, day,
-            expect_type="str",
-            fmt="%Y%m%d",
-            market=market,
-        )
-        start_dt, end_dt = 0, 29991231240000000
-    elif start_dt and end_dt:
-        start_datetime = to_datetime(start_dt)
-        end_datetime = to_datetime(end_dt)
-        start_dt = datetime_to_int17(start_datetime)
-        end_dt = datetime_to_int17(end_datetime)
-
-        dates = get_trading_dates_in_type(
-            start_datetime + relativedelta(days=1 if start_datetime.hour > 18 else 0),
-            end_datetime + relativedelta(days=1 if start_datetime.hour > 18 else 0),
-            expect_type="str",
-            fmt="%Y%m%d",
-            market=market,
-        )
-    else:
-        raise ValueError("please specify start_dt/end_dt in the same time")
-    order_book_ids = ensure_list_of_string(order_book_ids)
-    ins = instruments(order_book_ids, market)
-    if not ins:
-        raise ValueError("invalid order_book_id: {}".format(order_book_ids))
-    obids = [i.order_book_id for i in ins]
-    ins_types = {i.type for i in ins}
-    ins_exchanges = {i.exchange for i in ins}
-
-    future_like = ins_types & {"Future", "Option", "Spot"}
-    equities_like = ins_types - {"Future", "Option", "Spot"}
-    etf_option_like = ins_exchanges & {"XSHG", "XSHE"}
-
-    # 去掉 datetime 列，因为后面会统一加上
-    live_equitiles_fields = list(EQUITIES_FIELDS)[1:]
-    live_future_fields = list(FUTURE_FIELDS)[1:]
-    if future_like and equities_like:
-        base_fields = live_equitiles_fields + list(set(live_future_fields) - set(live_equitiles_fields))
-    elif future_like:
-        base_fields = live_future_fields + ["num_trades"] if etf_option_like else live_future_fields
-    else:
-        base_fields = live_equitiles_fields
-
-    if fields is not None:
-        fields = ensure_list_of_string(fields)
-        check_items_in_container(fields, base_fields, "fields")
-    else:
-        fields = base_fields
-    fields = ["order_book_id", "datetime"] + fields
-    ret = get_client().execute("get_live_ticks", obids, start_dt, end_dt, dates, fields, market=market)
-    if not ret:
-        return None
-    header, ticks = ret
-    df = pd.DataFrame(ticks, columns=header)
-    df = df[fields]
-    if "trading_date" in df.columns:
-        df.trading_date = df.trading_date.apply(lambda x: pd.NaT if x == 0 else int8_to_date(x))
-    if "update_time" in df.columns:
-        df.update_time = df.update_time.apply(int9_to_time)
-    df["datetime"] = df["datetime"].apply(int17_to_datetime)
-    df.set_index(["order_book_id", "datetime"], inplace=True)
-    df.sort_index(inplace=True)
-    return df
+# -*- coding: utf-8 -*-
+import datetime
+from itertools import chain
+
+import pandas as pd
+import numpy as np
+
+from rqdatac.services.basic import instruments
+from rqdatac.services.future import current_real_contract
+from rqdatac.services.calendar import get_trading_dates_in_type, get_previous_trading_date, is_trading_date, get_next_trading_date
+from rqdatac.utils import (to_datetime, int8_to_date, int9_to_time, int14_to_datetime,
+                           get_tick_value, datetime_to_int17, relativedelta, int17_to_datetime)
+from rqdatac.client import get_client
+from rqdatac.decorators import export_as_api
+from rqdatac.validators import (ensure_instruments,
+                                check_items_in_container, ensure_list_of_string)
+from rqdatac.services.stock_status import is_suspended
+from rqdatac.rqdatah_helper import rqdatah_serialize, http_conv_ticks
+
+
+@export_as_api
+@rqdatah_serialize(converter=http_conv_ticks)
+def current_snapshot(order_book_ids, market="cn"):
+    """获取实时行情
+
+    :param order_book_ids: 股票或期货代码或代码列表
+    :param market: 地区代码, 如'cn' (Default value = "cn")
+    :returns: Snapshot Object或Snapshot Object列表
+
+    """
+    _instruments = ensure_instruments(order_book_ids)
+    order_book_ids = []
+    for ins in _instruments:
+        if ins.type == "Future" and ins.order_book_id.endswith("88"):
+            real_contract = current_real_contract(ins.underlying_symbol, market) or ins.order_book_id
+            order_book_ids.append(real_contract)
+        else:
+            order_book_ids.append(ins.order_book_id)
+
+    snapshots = get_client().execute("current_snapshots", order_book_ids, market=market)
+    tick_objects = [TickObject(ins.order_book_id, snapshots[i]) for i, ins in enumerate(_instruments)]
+    if len(order_book_ids) == 1:
+        return tick_objects[0]
+    return tick_objects
+
+
+class TickObject(object):
+    _STOCK_FIELDS = [
+        ("datetime", np.uint64),
+        ("open", np.float64),
+        ("high", np.float64),
+        ("low", np.float64),
+        ("last", np.float64),
+        ('limit_up', np.float64),
+        ('limit_down', np.float64),
+        ("iopv", np.float64),
+        ("pre_iopv", np.float64),
+        ("volume", np.int32),
+        ("total_turnover", np.int64),
+        ("prev_close", np.float64),
+        ('close', np.float64),
+        ('settlement', np.float64),
+        ("ask", list),
+        ("ask_vol", list),
+        ("bid", list),
+        ("bid_vol", list),
+        ("trading_phase_code", str),
+    ]
+
+    _FUTURE_FIELDS = _STOCK_FIELDS + [("open_interest", np.int32), ("prev_settlement", np.float64)]
+
+    _STOCK_FIELD_NAMES = [_n for _n, _ in _STOCK_FIELDS]
+    _FUTURE_FIELD_NAMES = [_n for _n, _ in _FUTURE_FIELDS]
+
+    _NANDict = {_n: np.nan for _n, dtype in _FUTURE_FIELDS if dtype == np.float64}
+
+    def __init__(self, order_book_id, data, dt=None):
+        self._dt = dt
+        if data is None:
+            self._data = self._NANDict
+        else:
+            self._data = data
+        self._order_book_id = order_book_id
+
+    @property
+    def order_book_id(self):
+        return self._order_book_id
+
+    @property
+    def open(self):
+        return self._data.get("open", 0)
+
+    @property
+    def last(self):
+        return self._data.get("last", 0)
+
+    @property
+    def low(self):
+        return self._data.get("low", 0)
+
+    @property
+    def high(self):
+        return self._data.get("high", 0)
+
+    @property
+    def limit_up(self):
+        return self._data.get('limit_up', 0)
+
+    @property
+    def limit_down(self):
+        return self._data.get('limit_down', 0)
+
+    @property
+    def num_trades(self):
+        return self._data.get('num_trades', 0)
+
+    @property
+    def prev_close(self):
+        return self._data.get("prev_close", 0)
+
+    @property
+    def iopv(self):
+        return self._data.get("iopv", np.nan)
+
+    @property
+    def prev_iopv(self):
+        return self._data.get("prev_iopv", np.nan)
+
+    @property
+    def volume(self):
+        return self._data.get("volume", 0)
+
+    @property
+    def total_turnover(self):
+        return self._data.get("total_turnover", 0)
+
+    @property
+    def close(self):
+        return self._data.get('close', np.nan)
+
+    @property
+    def settlement(self):
+        return self._data.get('settlement', np.nan)
+
+    @property
+    def datetime(self):
+        if self._dt is not None:
+            return self._dt
+        if not self._isnan:
+            dt = self._data["datetime"]
+            return to_datetime(dt)
+        return datetime.datetime.min
+
+    @property
+    def prev_settlement(self):
+        try:
+            return self._data["prev_settlement"]
+        except KeyError:
+            return None
+
+    @property
+    def open_interest(self):
+        try:
+            return self._data["open_interest"]
+        except KeyError:
+            return None
+
+    @property
+    def trading_phase_code(self):
+        try:
+            return self._data["trading_phase_code"]
+        except KeyError:
+            return None
+
+    @property
+    def asks(self):
+        return self._data.get("ask", [0, 0, 0, 0, 0])
+
+    @property
+    def ask_vols(self):
+        return self._data.get("ask_vol", [0, 0, 0, 0, 0])
+
+    @property
+    def bids(self):
+        return self._data.get("bid", [0, 0, 0, 0, 0])
+
+    @property
+    def bid_vols(self):
+        return self._data.get("bid_vol", [0, 0, 0, 0, 0])
+
+    @property
+    def _isnan(self):
+        return np.isnan(self._data["last"])
+
+    def __repr__(self):
+        items = []
+        for name in dir(self):
+            if name.startswith("_"):
+                continue
+            items.append((name, getattr(self, name)))
+        return "Tick({0})".format(
+            ", ".join("{0}: {1}".format(k, v) for k, v in items if k is not None)
+        )
+
+    def __getitem__(self, key):
+        return getattr(self, key)
+
+
+EQUITIES_FIELDS = (
+    "datetime",
+    "open",
+    "last",
+    "high",
+    "low",
+    "iopv",
+    "prev_iopv",
+    "limit_up",
+    "limit_down",
+    "prev_close",
+    "volume",
+    "total_turnover",
+    "a1",
+    "a2",
+    "a3",
+    "a4",
+    "a5",
+    "b1",
+    "b2",
+    "b3",
+    "b4",
+    "b5",
+    "a1_v",
+    "a2_v",
+    "a3_v",
+    "a4_v",
+    "a5_v",
+    "b1_v",
+    "b2_v",
+    "b3_v",
+    "b4_v",
+    "b5_v",
+    "num_trades",
+)
+
+FUTURE_FIELDS = (
+    "datetime",
+    "trading_date",
+    "update_time",
+    "open",
+    "last",
+    "high",
+    "low",
+    "limit_up",
+    "limit_down",
+    "prev_settlement",
+    "prev_close",
+    "volume",
+    "total_turnover",
+    "open_interest",
+    "a1",
+    "a2",
+    "a3",
+    "a4",
+    "a5",
+    "b1",
+    "b2",
+    "b3",
+    "b4",
+    "b5",
+    "a1_v",
+    "a2_v",
+    "a3_v",
+    "a4_v",
+    "a5_v",
+    "b1_v",
+    "b2_v",
+    "b3_v",
+    "b4_v",
+    "b5_v",
+)
+
+
+@export_as_api
+def get_ticks(order_book_id, start_date=None, end_date=None, expect_df=True, market="cn"):
+    """获取实时tick
+
+    :param order_book_id: 股票代码, 如'000001.XSHE'
+    :param start_date: 开始日期, 不指定则为今天
+    :param end_date: 结束日期, 不指定则为今天
+    :param expect_df: 返回 MultiIndex DataFrame (Default value = True)
+    :param market:  (Default value = "cn")
+    :returns: pd.DataFrame or None
+
+    """
+    instrument = instruments(order_book_id, market)
+    if not instrument:
+        raise ValueError("invalid order_book_id: {}".format(order_book_id))
+
+    order_book_id = instrument.order_book_id
+    future_like = instrument.type in ("Future", "Option", "Spot")
+
+    now = datetime.datetime.now()
+    if is_trading_date(now):
+        if (now.hour, now.minute) >= (19, 30):
+            day = get_next_trading_date(now)
+        else:
+            day = now.date()
+    else:
+        day = get_next_trading_date(now)
+
+    dates = get_trading_dates_in_type(
+        start_date or day,
+        end_date or day,
+        expect_type="str",
+        fmt="%Y%m%d",
+        market=market,
+    )
+    ticks = get_client().execute("get_ticks_v2", order_book_id, dates, market=market)
+    if future_like:
+        fields = FUTURE_FIELDS
+    else:
+        fields = EQUITIES_FIELDS
+
+    if future_like and instrument.exchange in ("XSHE", "XSHG"):
+        fields = list(FUTURE_FIELDS) + ["num_trades"]
+
+    dtype = np.dtype([(f, _field_type(f)) for f in fields])
+    bars = np.array([tuple([get_tick_value(t, f, np.nan) if f in ("iopv", "prev_iopv") else get_tick_value(t, f)
+                            for f in fields]) for t in chain(*ticks)], dtype=dtype)
+    df = pd.DataFrame(bars)
+
+    if df.empty:
+        return None
+    if "trading_date" in df.columns:
+        df.trading_date = df.trading_date.apply(int8_to_date)
+        df.update_time = df.update_time.apply(int9_to_time)
+    df.datetime = df.datetime.apply(to_datetime)
+    if expect_df:
+        df["order_book_id"] = order_book_id
+        df.set_index(["order_book_id", "datetime"], inplace=True)
+    else:
+        df.set_index("datetime", inplace=True)
+    return df
+
+
+def _field_type(field_name):
+    return np.uint64 if field_name in ("datetime", "trading_date", "update_time") else np.float64
+
+
+@export_as_api
+def current_minute(order_book_ids, skip_suspended=False, fields=None, market="cn"):
+    """获取实时分钟行情
+    :param order_book_ids: 合约代码或代码列表
+    :param skip_suspended: 是否过滤停复牌. (Default value = False)
+    :param fields: 可选参数。默认为所有字段。 (Default value = None)
+    :param market: 地区代码, 如'cn' (Default value = "cn")
+    :returns: None or pd.DataFrame
+    """
+    from rqdatac.services.get_price import classify_order_book_ids, _ensure_fields
+    from rqdatac.services.detail.get_price_df import MINBAR_FIELDS
+
+    (order_book_ids, stocks, funds, indexes, futures, futures888, spots, options,
+        convertibles, repos) = classify_order_book_ids(order_book_ids, market)
+
+    futures_88 = [i for i in instruments(order_book_ids) if i.order_book_id.endswith('88') and i.type == 'Future']
+    real_contracts = {
+        i.order_book_id: current_real_contract(i.underlying_symbol, market)
+        for i in futures_88
+    }
+    real_contracts = {k: v for k, v in real_contracts.items() if v is not None}
+    if skip_suspended and stocks:
+        date = get_previous_trading_date(datetime.date.today() + datetime.timedelta(days=1))
+        df_suspended = is_suspended(stocks, date, date)
+        if not df_suspended.empty:
+            df_suspended_t = df_suspended.T
+            suspended_obids = set(df_suspended_t[df_suspended_t[df_suspended_t.columns[0]]].index)
+            inspection = suspended_obids & set(stocks)
+            if inspection:
+                stocks = set(stocks) - inspection
+                order_book_ids = list(set(order_book_ids) - inspection)
+
+    fields, _ = _ensure_fields(fields, MINBAR_FIELDS, stocks, funds, futures, futures888, spots, options, convertibles, indexes, repos)
+    if real_contracts:
+        order_book_ids = set(order_book_ids)
+        obs = list(order_book_ids.union(set(real_contracts.values())))
+    else:
+        obs = order_book_ids
+    data = get_client().execute("current_minute", obs, fields + ["datetime"], market=market)
+    if not data:
+        return
+
+    if real_contracts:
+        data = {bar['order_book_id']: bar for bar in data}
+
+        def _rename_bar(bar, ob):
+            bar = bar.copy()
+            bar['order_book_id'] = ob
+            return bar
+        data.update((ob, _rename_bar(data[contract], ob)) for ob, contract in real_contracts.items() if contract in data)
+        data = [data[ob] for ob in order_book_ids if ob in data]
+
+    df = pd.DataFrame(data)
+    df["datetime"] = df["datetime"].map(int14_to_datetime, na_action="ignore")
+    df.set_index(["order_book_id", "datetime"], inplace=True)
+    return df
+
+
+@export_as_api
+def get_live_ticks(order_book_ids, start_dt=None, end_dt=None, fields=None, market="cn"):
+    """获取实时tick
+    :param order_book_ids: 股票代码或代码列表, 如'000001.XSHE'
+    :param start_dt: 开始时间，如20200102213000 或 "2020-01-02 21:30:00"， 默认为今天
+    :param end_dt: 结束时间，如20200102153000 或 "2020-01-03 15:30:00"， 默认为今天
+    :param fields: 可选参数。默认为所有字段。 (Default value = None)
+    :param market:  (Default value = "cn")
+
+    :returns: pd.DataFrame or None
+    """
+
+    if start_dt is None and end_dt is None:
+        now = datetime.datetime.now()
+        if is_trading_date(now):
+            if (now.hour, now.minute) >= (19, 30):
+                day = get_next_trading_date(now)
+            else:
+                day = now.date()
+        else:
+            day = get_next_trading_date(now)
+
+        dates = get_trading_dates_in_type(
+            day, day,
+            expect_type="str",
+            fmt="%Y%m%d",
+            market=market,
+        )
+        start_dt, end_dt = 0, 29991231240000000
+    elif start_dt and end_dt:
+        start_datetime = to_datetime(start_dt)
+        end_datetime = to_datetime(end_dt)
+        start_dt = datetime_to_int17(start_datetime)
+        end_dt = datetime_to_int17(end_datetime)
+
+        dates = get_trading_dates_in_type(
+            start_datetime + relativedelta(days=1 if start_datetime.hour > 18 else 0),
+            end_datetime + relativedelta(days=1 if start_datetime.hour > 18 else 0),
+            expect_type="str",
+            fmt="%Y%m%d",
+            market=market,
+        )
+    else:
+        raise ValueError("please specify start_dt/end_dt in the same time")
+    order_book_ids = ensure_list_of_string(order_book_ids)
+    ins = instruments(order_book_ids, market)
+    if not ins:
+        raise ValueError("invalid order_book_id: {}".format(order_book_ids))
+    obids = [i.order_book_id for i in ins]
+    ins_types = {i.type for i in ins}
+    ins_exchanges = {i.exchange for i in ins}
+
+    future_like = ins_types & {"Future", "Option", "Spot"}
+    equities_like = ins_types - {"Future", "Option", "Spot"}
+    etf_option_like = ins_exchanges & {"XSHG", "XSHE"}
+
+    # 去掉 datetime 列，因为后面会统一加上
+    live_equitiles_fields = list(EQUITIES_FIELDS)[1:]
+    live_future_fields = list(FUTURE_FIELDS)[1:]
+    if future_like and equities_like:
+        base_fields = live_equitiles_fields + list(set(live_future_fields) - set(live_equitiles_fields))
+    elif future_like:
+        base_fields = live_future_fields + ["num_trades"] if etf_option_like else live_future_fields
+    else:
+        base_fields = live_equitiles_fields
+
+    if fields is not None:
+        fields = ensure_list_of_string(fields)
+        check_items_in_container(fields, base_fields, "fields")
+    else:
+        fields = base_fields
+    fields = ["order_book_id", "datetime"] + fields
+    ret = get_client().execute("get_live_ticks", obids, start_dt, end_dt, dates, fields, market=market)
+    if not ret:
+        return None
+    header, ticks = ret
+    df = pd.DataFrame(ticks, columns=header)
+    df = df[fields]
+    if "trading_date" in df.columns:
+        df.trading_date = df.trading_date.apply(lambda x: pd.NaT if x == 0 else int8_to_date(x))
+    if "update_time" in df.columns:
+        df.update_time = df.update_time.apply(int9_to_time)
+    df["datetime"] = df["datetime"].apply(int17_to_datetime)
+    df.set_index(["order_book_id", "datetime"], inplace=True)
+    df.sort_index(inplace=True)
+    return df
```

## rqdatac/services/live_md_client.py

 * *Ordering differences only*

```diff
@@ -1,457 +1,457 @@
-# -*- coding: utf-8 -*-
-import bisect
-import socket
-import threading
-import time
-import datetime
-import ssl
-import warnings
-import weakref
-from collections import defaultdict
-from functools import partial
-
-from rqdatac.services.basic import instruments, get_previous_trading_date
-from rqdatac.validators import ensure_list_of_string
-from rqdatac.decorators import export_as_api, retry, ttl_cache
-from rqdatac.utils import datetime_to_int14, int8_to_date, connection_error
-from rqdatac.client import get_client
-from rqdatac.share.errors import PermissionDenied
-
-try:
-    from orjson import dumps as json_dumps, loads as json_loads
-except ImportError:
-    try:
-        import rapidjson as json
-    except ImportError:
-        import json
-
-    def json_dumps(*args, **kwargs):
-        return json.dumps(*args, **kwargs).encode('utf-8')
-
-    def json_loads(*args, **kwargs):
-        return json.loads(*args, **kwargs)
-
-
-def str_to_dt_time(s):
-    """ '21:31' -->  datetime.time(21, 31) """
-    return datetime.time(int(s[0:2]), int(s[3:5]))
-
-
-@ttl_cache(1800)
-def to_trading_periods(trading_hours, date):
-    trading_hours = [t.split("-", 1) for t in trading_hours.split(",")]
-    for i, (start, end) in enumerate(trading_hours):
-        trading_hours[i][0] = str_to_dt_time(start)
-        trading_hours[i][1] = str_to_dt_time(end)
-
-    td = int8_to_date(date)
-    prev_td = get_previous_trading_date(date)
-    prev_td_next = prev_td + datetime.timedelta(days=1)
-
-    for i, (start, end) in enumerate(trading_hours):
-        if start.hour > 16:
-            start_dt = prev_td
-            end_dt = start_dt if end.hour > 16 else prev_td_next
-        else:
-            start_dt = end_dt = td
-        trading_hours[i][0] = datetime.datetime.combine(start_dt, start)
-        trading_hours[i][1] = datetime.datetime.combine(end_dt, end)
-
-    return trading_hours
-
-
-def get_trading_minutes(order_book_id, trading_date):
-    result = []
-    delta = datetime.timedelta(minutes=1)
-    for start, end in to_trading_periods(instruments(order_book_id).trading_hours, trading_date):
-        dt = start
-        while dt <= end:
-            result.append(dt)
-            dt += delta
-    return result
-
-
-def futures_resample_dts(trading_minutes, freq):
-    delta = datetime.timedelta(minutes=freq)
-    dt = trading_minutes[0] - datetime.timedelta(minutes=1) + delta
-    dts = set()
-    while dt <= trading_minutes[-1]:
-        dts.add(trading_minutes[bisect.bisect_right(trading_minutes, dt) - 1])
-        dt += delta
-    if trading_minutes[-1] not in dts:
-        dts.add(trading_minutes[-1])
-    return sorted(dts)
-
-
-class MinbarResampler:
-    _resamples = weakref.WeakSet()
-    _cache = {}
-
-    @classmethod
-    def batch_get_bar_from_rqdatac(cls, freq, dt):
-        if (freq, dt) in cls._cache:
-            return cls._cache[freq, dt]
-
-        fields = set()
-        order_book_ids = []
-        for r in cls._resamples:
-            if r.freq == freq and r._bar_dts is not None and dt in r._bar_dts:
-                order_book_ids.append(r.order_book_id)
-                if r.fields is not None:
-                    fields.update(r.fields)
-
-        if not order_book_ids or not fields:
-            return
-
-        try:
-            bars = get_client().execute('get_today_minbar', order_book_ids, list(fields), freq, market='cn')
-        except PermissionDenied:
-            cls._cache[freq, dt] = None
-            return
-
-        if not bars:
-            return
-
-        result = {}
-        for ob, data in bars:
-            try:
-                index = data['datetime'].index(dt)
-            except ValueError:
-                continue
-
-            result[ob] = {k: v[index] for k, v in data.items()}
-
-        cls._cache = {k: v for k, v in cls._cache.items() if k[1] == dt}
-        cls._cache[freq, dt] = result
-
-        return result
-
-    def __init__(self, order_book_id, freq):
-        MinbarResampler._resamples.add(self)
-        self.order_book_id = order_book_id
-        self.freq = freq
-        self.fields = None
-        self._current_bar = None
-        self._max_bar_dt = None
-        self._bar_dts = None
-        self.channel = 'bar_' + order_book_id + '_' + str(freq) + 'm'
-
-    def get_bar_from_rqdatac(self, dt):
-        bars = MinbarResampler.batch_get_bar_from_rqdatac(self.freq, dt)
-        if bars is None or self.order_book_id not in bars:
-            return
-
-        bar = bars[self.order_book_id]
-        bar = {k: bar.get(k) for k in self.fields}
-        bar['datetime'] = dt
-        bar['order_book_id'] = self.order_book_id
-        bar['channel'] = self.channel
-        bar['action'] = 'feed'
-        return bar
-
-    def reset(self):
-        self._current_bar = None
-
-    def enqueue(self, bar):
-        if self.freq == 1:
-            bar = bar.copy()
-            bar['channel'] = self.channel
-            return bar
-
-        if self.fields is None:
-            self.fields = [f for f in bar.keys() if f not in ['order_book_id', 'datetime', 'channel', 'action']]
-
-        dt = bar['datetime']
-        if self._max_bar_dt is None or dt > self._max_bar_dt:
-            trading_minutes = get_trading_minutes(self.order_book_id, bar['trading_date'])
-            ins = instruments(self.order_book_id)
-            if ins.type in ('Future', 'Option', 'Spot') and ins.exchange not in ("CFFEX", "CCFX", 'XSHG', 'XSHE'):
-                bar_dts = futures_resample_dts(trading_minutes, self.freq)
-            elif len(trading_minutes) % self.freq == 0:
-                bar_dts = trading_minutes[self.freq-1::self.freq]
-            else:
-                bar_dts = trading_minutes[self.freq-1::self.freq] + trading_minutes[-1:]
-
-            bar_dts = [datetime_to_int14(dt) for dt in bar_dts]
-            self._bar_dts = set(bar_dts)
-            self._max_bar_dt = bar_dts[-1]
-            trading_minutes = [datetime_to_int14(dt) for dt in trading_minutes]
-
-            if dt == trading_minutes[0] or trading_minutes[trading_minutes.index(dt) - 1] in self._bar_dts:
-                self._current_bar = bar.copy()
-                return
-
-        if dt in self._bar_dts:
-            if self._current_bar is not None:
-                self._update_current_bar(bar)
-                bar, self._current_bar = self._current_bar, {}
-                bar['channel'] = self.channel
-                return bar
-            else:
-                self._current_bar = {}
-                return self.get_bar_from_rqdatac(dt)
-
-        if self._current_bar is not None:
-            self._update_current_bar(bar)
-
-    def _update_current_bar(self, bar):
-        for k, v in bar.items():
-            if k in ('volume', 'total_turnover', 'num_trades'):
-                self._current_bar[k] = self._current_bar.get(k, 0) + v
-            elif k == 'open':
-                if 'open' not in self._current_bar:
-                    self._current_bar['open'] = v
-            elif k == 'low':
-                if 'low' not in self._current_bar or self._current_bar['low'] > v:
-                    self._current_bar['low'] = v
-            elif k == 'high':
-                if 'high' not in self._current_bar or self._current_bar['high'] < v:
-                    self._current_bar['high'] = v
-            else:
-                self._current_bar[k] = v
-
-
-@export_as_api
-class LiveMarketDataClient:
-    def __init__(self, ws_server_uri="wss://rqdata.ricequant.com/live_md", proxy_info=None):
-        """websocket对象初始化
-
-        :param ws_server_uri: websocket服务地址, 如 wss://rqdata.ricequant.com/live_md
-        :param proxy_info: 代理信息, 需要为5个元素的元组: (proxy_type, host, port, user, password),
-            如 ("http", "localhost", 18089, None, None)
-
-        """
-        self._info = None
-        self._client = None
-        self._ws_server_uri = ws_server_uri
-        self._subscribed = set()
-        self.proxy_info = proxy_info
-        self._init_websocket_client()
-        self._resamplers = defaultdict(dict)
-        self._subscribed_by_user = set()
-        self._closed = False
-
-    def _init_websocket_client(self):
-        _token = get_client().execute(
-            "user.get_live_md_auth_token",
-        )
-
-        try:
-            import websocket
-        except ImportError:
-            raise ImportError(
-                "LiveMarketDataClient requires websocket-client package; run 'pip install websocket-client' to fix.")
-
-        login_data = {
-            "action": "auth_by_token",
-            "token": _token
-        }
-        _websocket_client = websocket.WebSocket()
-        if self.proxy_info is not None:
-            if not isinstance(self.proxy_info, tuple) or len(self.proxy_info) != 5:
-                raise ValueError("expected a tuple like (proxy_type, host, port, user, password)")
-            proxy_type, host, port, user, password = self.proxy_info
-            proxy_type = proxy_type.lower()
-            assert proxy_type in ("http", "socks4", "socks5"), \
-                "proxy type {} not supported yet, only support http, socks4, socks5 proxy".format(proxy_type)
-
-            # for non http socket, check python_socks dependency
-            if proxy_type != "http":
-                try:
-                    import python_socks
-                except ImportError:
-                    raise RuntimeError(
-                        "python_socks is required when use SOCKS proxy. "
-                        "You can install it using `pip install python-socks` or `pip install rqdatac[proxy]`"
-                    )
-
-            _websocket_client.connect = partial(
-                _websocket_client.connect,
-                proxy_type=proxy_type,
-                http_proxy_host=host,
-                http_proxy_port=port,
-                http_proxy_auth=(user, password),
-            )
-        self._client = _websocket_client
-        retry(suppress_exceptions=(websocket.WebSocketException,), count=3)(self._websocket_login)(login_data)
-
-    def _websocket_login(self, login_data):
-        try:
-            self._client.connect(self._ws_server_uri)
-        except ssl.SSLCertVerificationError:
-            self._client.sock_opt.sslopt = {"cert_reqs": ssl.CERT_NONE}
-            self._client.connect(self._ws_server_uri)
-        self._client.send(json_dumps(login_data))
-        res = self._client.recv()
-        self._info = json_loads(res)
-
-    @property
-    def info(self):
-        return self._info
-
-    @property
-    def subscriptions(self):
-        """
-        获取当前正在订阅的所有频道
-        """
-        return list(self._subscribed_by_user)
-
-    def close(self):
-        self._closed = True
-        try:
-            self._client.close()
-        except:
-            pass
-
-    def subscribe(self, channels):
-        """订阅实时行情
-
-        :param channels: 订阅的标的列表 分钟和tick分别以 bar_ 和tick_开头 以平安银行为例，
-            subscribe('bar_000001.XSHE')  # 订阅分钟线的实时行情
-            subscribe('bar_AU2112_15m')   # 订阅15分钟线的实时行情
-            subscribe('tick_000001.XSHE')  # 订阅tick的实时行情
-            可以同时订阅多支标的 subscribe(['bar_000001.XSHE'， 'bar_000002.XSHE')
-
-        """
-        if self._closed:
-            raise RuntimeError('this connection is closed.')
-
-        channels = ensure_list_of_string(channels)
-        to_subscribe = set()
-        for ch in channels:
-            ob = ch.split('_')[1]
-            if not instruments(ob):
-                warnings.warn("invalid order_book_id: {}, channel {} ignored".format(ob, ch), stacklevel=0)
-                continue
-
-            self._subscribed_by_user.add(ch)
-
-            if ch.startswith('bar_') and ch.endswith('m'):
-                _, order_book_id, freq = ch.split('_')
-                if int(freq[:-1]) == 1:
-                    warnings.warn('channel {}: for 1-minute bar, please use the format {} directyly'.format(
-                        ch, 'bar_' + order_book_id), stacklevel=0)
-
-                to_subscribe.add('bar_' + order_book_id)
-                if ch not in self._resamplers['bar_' + order_book_id]:
-                    resampler = MinbarResampler(order_book_id, int(freq[:-1]))
-                    self._resamplers['bar_' + order_book_id][resampler.channel] = resampler
-            else:
-                to_subscribe.add(ch)
-
-        data = {
-            "action": "subscribe",
-            "channels": list(to_subscribe),
-        }
-        self._client.send(json_dumps(data))
-
-    def unsubscribe(self, channels):
-        """取消订阅实时行情
-
-        :param channels: 取消订阅的标的列表 分钟和tick分别以 bar_ 和tick_开头 以平安银行为例，
-            unsubscribe('bar_000001.XSHE')  # 订阅分钟线的实时行情
-            unsubscribe('tick_000001.XSHE')  # 订阅tick的实时行情
-
-        """
-        if self._closed:
-            raise RuntimeError('this connection is closed.')
-
-        channels = ensure_list_of_string(channels)
-        for ch in channels:
-            self._subscribed_by_user.discard(ch)
-            if ch.startswith('bar_') and ch.endswith('m'):
-                _, order_book_id, freq = ch.split('_')
-                self._resamplers['bar_' + order_book_id].pop(ch, None)
-
-        channels = [
-            ch for ch in channels
-            if ch not in self._subscribed_by_user and (ch not in self._resamplers or not self._resamplers[ch])
-        ]
-
-        data = {
-            "action": "unsubscribe",
-            "channels": channels,
-        }
-        self._client.send(json_dumps(data))
-
-    def _reconnect(self):
-        from websocket import WebSocketException
-        while True:
-            try:
-                if self._closed:
-                    return
-
-                self._init_websocket_client()
-                self.subscribe(list(self._subscribed_by_user))
-                for resamplers in self._resamplers.values():
-                    for resampler in resamplers.values():
-                        resampler.reset()
-                return
-            except (socket.error, WebSocketException) as e:
-                warnings.warn('web socket reconnect failed: {}, retry ..'.format(str(e)))
-                time.sleep(0.5)
-
-    def _listen(self):
-        from websocket import WebSocketException, ABNF
-        while not self._closed:
-            try:
-                opcode, data = self._client.recv_data()
-
-                if opcode == ABNF.OPCODE_CLOSE:
-                    warnings.warn('web socket closed: {}, will reconnect'.format(data[2:].decode()), stacklevel=0)
-                    self._client.shutdown()
-                    time.sleep(0.1)
-                    self._reconnect()
-                    continue
-
-                data = json_loads(data)
-                if data['action'] == 'feed':
-                    ch = data['channel']
-                    if ch in self._resamplers:
-                        for resampler in self._resamplers[ch].values():
-                            bar = resampler.enqueue(data)
-                            if bar is not None:
-                                yield bar
-                    if ch in self._subscribed_by_user:
-                        yield data
-                elif data['action'] == 'subscribe_reply':
-                    self._subscribed.update(data['subscribed'])
-                elif data['action'] == 'unsubscribe_reply':
-                    self._subscribed -= set(data['unsubscribed'])
-            except (WebSocketException, connection_error) as e:
-                warnings.warn("web socket exception: {}, will reconnect".format(str(e)), stacklevel=0)
-                time.sleep(0.1)
-                self._reconnect()
-
-    def listen(self, handler=None):
-        """获取实时行情。
-        当 handler 参数为 None (默认情况) 时，此函数返回一个generator，用法如下：
-
-            for msg in client.listen():
-                process(msg)
-
-        当 handler 不为 None 时，此函数会启动一个新的线程，在线程中执行：
-
-            for msg in client.listen():
-                handler(msg)
-
-        注意，此时 handler 在另一个线程中执行；请小心处理线程之间的同步问题。此时函数不再阻塞，返回创建的线程对象。
-        当调用 `client.close()` 时，线程会关闭。
-
-        :returns: generator | threading.Thread
-        """
-        if self._closed:
-            raise RuntimeError('this connection is closed.')
-
-        if handler is None:
-            return self._listen()
-
-        def _process_msg():
-            for msg in self._listen():
-                if self._closed:
-                    break
-                handler(msg)
-
-        thread = threading.Thread(target=_process_msg, daemon=True)
-        thread.start()
-        return thread
+# -*- coding: utf-8 -*-
+import bisect
+import socket
+import threading
+import time
+import datetime
+import ssl
+import warnings
+import weakref
+from collections import defaultdict
+from functools import partial
+
+from rqdatac.services.basic import instruments, get_previous_trading_date
+from rqdatac.validators import ensure_list_of_string
+from rqdatac.decorators import export_as_api, retry, ttl_cache
+from rqdatac.utils import datetime_to_int14, int8_to_date, connection_error
+from rqdatac.client import get_client
+from rqdatac.share.errors import PermissionDenied
+
+try:
+    from orjson import dumps as json_dumps, loads as json_loads
+except ImportError:
+    try:
+        import rapidjson as json
+    except ImportError:
+        import json
+
+    def json_dumps(*args, **kwargs):
+        return json.dumps(*args, **kwargs).encode('utf-8')
+
+    def json_loads(*args, **kwargs):
+        return json.loads(*args, **kwargs)
+
+
+def str_to_dt_time(s):
+    """ '21:31' -->  datetime.time(21, 31) """
+    return datetime.time(int(s[0:2]), int(s[3:5]))
+
+
+@ttl_cache(1800)
+def to_trading_periods(trading_hours, date):
+    trading_hours = [t.split("-", 1) for t in trading_hours.split(",")]
+    for i, (start, end) in enumerate(trading_hours):
+        trading_hours[i][0] = str_to_dt_time(start)
+        trading_hours[i][1] = str_to_dt_time(end)
+
+    td = int8_to_date(date)
+    prev_td = get_previous_trading_date(date)
+    prev_td_next = prev_td + datetime.timedelta(days=1)
+
+    for i, (start, end) in enumerate(trading_hours):
+        if start.hour > 16:
+            start_dt = prev_td
+            end_dt = start_dt if end.hour > 16 else prev_td_next
+        else:
+            start_dt = end_dt = td
+        trading_hours[i][0] = datetime.datetime.combine(start_dt, start)
+        trading_hours[i][1] = datetime.datetime.combine(end_dt, end)
+
+    return trading_hours
+
+
+def get_trading_minutes(order_book_id, trading_date):
+    result = []
+    delta = datetime.timedelta(minutes=1)
+    for start, end in to_trading_periods(instruments(order_book_id).trading_hours, trading_date):
+        dt = start
+        while dt <= end:
+            result.append(dt)
+            dt += delta
+    return result
+
+
+def futures_resample_dts(trading_minutes, freq):
+    delta = datetime.timedelta(minutes=freq)
+    dt = trading_minutes[0] - datetime.timedelta(minutes=1) + delta
+    dts = set()
+    while dt <= trading_minutes[-1]:
+        dts.add(trading_minutes[bisect.bisect_right(trading_minutes, dt) - 1])
+        dt += delta
+    if trading_minutes[-1] not in dts:
+        dts.add(trading_minutes[-1])
+    return sorted(dts)
+
+
+class MinbarResampler:
+    _resamples = weakref.WeakSet()
+    _cache = {}
+
+    @classmethod
+    def batch_get_bar_from_rqdatac(cls, freq, dt):
+        if (freq, dt) in cls._cache:
+            return cls._cache[freq, dt]
+
+        fields = set()
+        order_book_ids = []
+        for r in cls._resamples:
+            if r.freq == freq and r._bar_dts is not None and dt in r._bar_dts:
+                order_book_ids.append(r.order_book_id)
+                if r.fields is not None:
+                    fields.update(r.fields)
+
+        if not order_book_ids or not fields:
+            return
+
+        try:
+            bars = get_client().execute('get_today_minbar', order_book_ids, list(fields), freq, market='cn')
+        except PermissionDenied:
+            cls._cache[freq, dt] = None
+            return
+
+        if not bars:
+            return
+
+        result = {}
+        for ob, data in bars:
+            try:
+                index = data['datetime'].index(dt)
+            except ValueError:
+                continue
+
+            result[ob] = {k: v[index] for k, v in data.items()}
+
+        cls._cache = {k: v for k, v in cls._cache.items() if k[1] == dt}
+        cls._cache[freq, dt] = result
+
+        return result
+
+    def __init__(self, order_book_id, freq):
+        MinbarResampler._resamples.add(self)
+        self.order_book_id = order_book_id
+        self.freq = freq
+        self.fields = None
+        self._current_bar = None
+        self._max_bar_dt = None
+        self._bar_dts = None
+        self.channel = 'bar_' + order_book_id + '_' + str(freq) + 'm'
+
+    def get_bar_from_rqdatac(self, dt):
+        bars = MinbarResampler.batch_get_bar_from_rqdatac(self.freq, dt)
+        if bars is None or self.order_book_id not in bars:
+            return
+
+        bar = bars[self.order_book_id]
+        bar = {k: bar.get(k) for k in self.fields}
+        bar['datetime'] = dt
+        bar['order_book_id'] = self.order_book_id
+        bar['channel'] = self.channel
+        bar['action'] = 'feed'
+        return bar
+
+    def reset(self):
+        self._current_bar = None
+
+    def enqueue(self, bar):
+        if self.freq == 1:
+            bar = bar.copy()
+            bar['channel'] = self.channel
+            return bar
+
+        if self.fields is None:
+            self.fields = [f for f in bar.keys() if f not in ['order_book_id', 'datetime', 'channel', 'action']]
+
+        dt = bar['datetime']
+        if self._max_bar_dt is None or dt > self._max_bar_dt:
+            trading_minutes = get_trading_minutes(self.order_book_id, bar['trading_date'])
+            ins = instruments(self.order_book_id)
+            if ins.type in ('Future', 'Option', 'Spot') and ins.exchange not in ("CFFEX", "CCFX", 'XSHG', 'XSHE'):
+                bar_dts = futures_resample_dts(trading_minutes, self.freq)
+            elif len(trading_minutes) % self.freq == 0:
+                bar_dts = trading_minutes[self.freq-1::self.freq]
+            else:
+                bar_dts = trading_minutes[self.freq-1::self.freq] + trading_minutes[-1:]
+
+            bar_dts = [datetime_to_int14(dt) for dt in bar_dts]
+            self._bar_dts = set(bar_dts)
+            self._max_bar_dt = bar_dts[-1]
+            trading_minutes = [datetime_to_int14(dt) for dt in trading_minutes]
+
+            if dt == trading_minutes[0] or trading_minutes[trading_minutes.index(dt) - 1] in self._bar_dts:
+                self._current_bar = bar.copy()
+                return
+
+        if dt in self._bar_dts:
+            if self._current_bar is not None:
+                self._update_current_bar(bar)
+                bar, self._current_bar = self._current_bar, {}
+                bar['channel'] = self.channel
+                return bar
+            else:
+                self._current_bar = {}
+                return self.get_bar_from_rqdatac(dt)
+
+        if self._current_bar is not None:
+            self._update_current_bar(bar)
+
+    def _update_current_bar(self, bar):
+        for k, v in bar.items():
+            if k in ('volume', 'total_turnover', 'num_trades'):
+                self._current_bar[k] = self._current_bar.get(k, 0) + v
+            elif k == 'open':
+                if 'open' not in self._current_bar:
+                    self._current_bar['open'] = v
+            elif k == 'low':
+                if 'low' not in self._current_bar or self._current_bar['low'] > v:
+                    self._current_bar['low'] = v
+            elif k == 'high':
+                if 'high' not in self._current_bar or self._current_bar['high'] < v:
+                    self._current_bar['high'] = v
+            else:
+                self._current_bar[k] = v
+
+
+@export_as_api
+class LiveMarketDataClient:
+    def __init__(self, ws_server_uri="wss://rqdata.ricequant.com/live_md", proxy_info=None):
+        """websocket对象初始化
+
+        :param ws_server_uri: websocket服务地址, 如 wss://rqdata.ricequant.com/live_md
+        :param proxy_info: 代理信息, 需要为5个元素的元组: (proxy_type, host, port, user, password),
+            如 ("http", "localhost", 18089, None, None)
+
+        """
+        self._info = None
+        self._client = None
+        self._ws_server_uri = ws_server_uri
+        self._subscribed = set()
+        self.proxy_info = proxy_info
+        self._init_websocket_client()
+        self._resamplers = defaultdict(dict)
+        self._subscribed_by_user = set()
+        self._closed = False
+
+    def _init_websocket_client(self):
+        _token = get_client().execute(
+            "user.get_live_md_auth_token",
+        )
+
+        try:
+            import websocket
+        except ImportError:
+            raise ImportError(
+                "LiveMarketDataClient requires websocket-client package; run 'pip install websocket-client' to fix.")
+
+        login_data = {
+            "action": "auth_by_token",
+            "token": _token
+        }
+        _websocket_client = websocket.WebSocket()
+        if self.proxy_info is not None:
+            if not isinstance(self.proxy_info, tuple) or len(self.proxy_info) != 5:
+                raise ValueError("expected a tuple like (proxy_type, host, port, user, password)")
+            proxy_type, host, port, user, password = self.proxy_info
+            proxy_type = proxy_type.lower()
+            assert proxy_type in ("http", "socks4", "socks5"), \
+                "proxy type {} not supported yet, only support http, socks4, socks5 proxy".format(proxy_type)
+
+            # for non http socket, check python_socks dependency
+            if proxy_type != "http":
+                try:
+                    import python_socks
+                except ImportError:
+                    raise RuntimeError(
+                        "python_socks is required when use SOCKS proxy. "
+                        "You can install it using `pip install python-socks` or `pip install rqdatac[proxy]`"
+                    )
+
+            _websocket_client.connect = partial(
+                _websocket_client.connect,
+                proxy_type=proxy_type,
+                http_proxy_host=host,
+                http_proxy_port=port,
+                http_proxy_auth=(user, password),
+            )
+        self._client = _websocket_client
+        retry(suppress_exceptions=(websocket.WebSocketException,), count=3)(self._websocket_login)(login_data)
+
+    def _websocket_login(self, login_data):
+        try:
+            self._client.connect(self._ws_server_uri)
+        except ssl.SSLCertVerificationError:
+            self._client.sock_opt.sslopt = {"cert_reqs": ssl.CERT_NONE}
+            self._client.connect(self._ws_server_uri)
+        self._client.send(json_dumps(login_data))
+        res = self._client.recv()
+        self._info = json_loads(res)
+
+    @property
+    def info(self):
+        return self._info
+
+    @property
+    def subscriptions(self):
+        """
+        获取当前正在订阅的所有频道
+        """
+        return list(self._subscribed_by_user)
+
+    def close(self):
+        self._closed = True
+        try:
+            self._client.close()
+        except:
+            pass
+
+    def subscribe(self, channels):
+        """订阅实时行情
+
+        :param channels: 订阅的标的列表 分钟和tick分别以 bar_ 和tick_开头 以平安银行为例，
+            subscribe('bar_000001.XSHE')  # 订阅分钟线的实时行情
+            subscribe('bar_AU2112_15m')   # 订阅15分钟线的实时行情
+            subscribe('tick_000001.XSHE')  # 订阅tick的实时行情
+            可以同时订阅多支标的 subscribe(['bar_000001.XSHE'， 'bar_000002.XSHE')
+
+        """
+        if self._closed:
+            raise RuntimeError('this connection is closed.')
+
+        channels = ensure_list_of_string(channels)
+        to_subscribe = set()
+        for ch in channels:
+            ob = ch.split('_')[1]
+            if not instruments(ob):
+                warnings.warn("invalid order_book_id: {}, channel {} ignored".format(ob, ch), stacklevel=0)
+                continue
+
+            self._subscribed_by_user.add(ch)
+
+            if ch.startswith('bar_') and ch.endswith('m'):
+                _, order_book_id, freq = ch.split('_')
+                if int(freq[:-1]) == 1:
+                    warnings.warn('channel {}: for 1-minute bar, please use the format {} directyly'.format(
+                        ch, 'bar_' + order_book_id), stacklevel=0)
+
+                to_subscribe.add('bar_' + order_book_id)
+                if ch not in self._resamplers['bar_' + order_book_id]:
+                    resampler = MinbarResampler(order_book_id, int(freq[:-1]))
+                    self._resamplers['bar_' + order_book_id][resampler.channel] = resampler
+            else:
+                to_subscribe.add(ch)
+
+        data = {
+            "action": "subscribe",
+            "channels": list(to_subscribe),
+        }
+        self._client.send(json_dumps(data))
+
+    def unsubscribe(self, channels):
+        """取消订阅实时行情
+
+        :param channels: 取消订阅的标的列表 分钟和tick分别以 bar_ 和tick_开头 以平安银行为例，
+            unsubscribe('bar_000001.XSHE')  # 订阅分钟线的实时行情
+            unsubscribe('tick_000001.XSHE')  # 订阅tick的实时行情
+
+        """
+        if self._closed:
+            raise RuntimeError('this connection is closed.')
+
+        channels = ensure_list_of_string(channels)
+        for ch in channels:
+            self._subscribed_by_user.discard(ch)
+            if ch.startswith('bar_') and ch.endswith('m'):
+                _, order_book_id, freq = ch.split('_')
+                self._resamplers['bar_' + order_book_id].pop(ch, None)
+
+        channels = [
+            ch for ch in channels
+            if ch not in self._subscribed_by_user and (ch not in self._resamplers or not self._resamplers[ch])
+        ]
+
+        data = {
+            "action": "unsubscribe",
+            "channels": channels,
+        }
+        self._client.send(json_dumps(data))
+
+    def _reconnect(self):
+        from websocket import WebSocketException
+        while True:
+            try:
+                if self._closed:
+                    return
+
+                self._init_websocket_client()
+                self.subscribe(list(self._subscribed_by_user))
+                for resamplers in self._resamplers.values():
+                    for resampler in resamplers.values():
+                        resampler.reset()
+                return
+            except (socket.error, WebSocketException) as e:
+                warnings.warn('web socket reconnect failed: {}, retry ..'.format(str(e)))
+                time.sleep(0.5)
+
+    def _listen(self):
+        from websocket import WebSocketException, ABNF
+        while not self._closed:
+            try:
+                opcode, data = self._client.recv_data()
+
+                if opcode == ABNF.OPCODE_CLOSE:
+                    warnings.warn('web socket closed: {}, will reconnect'.format(data[2:].decode()), stacklevel=0)
+                    self._client.shutdown()
+                    time.sleep(0.1)
+                    self._reconnect()
+                    continue
+
+                data = json_loads(data)
+                if data['action'] == 'feed':
+                    ch = data['channel']
+                    if ch in self._resamplers:
+                        for resampler in self._resamplers[ch].values():
+                            bar = resampler.enqueue(data)
+                            if bar is not None:
+                                yield bar
+                    if ch in self._subscribed_by_user:
+                        yield data
+                elif data['action'] == 'subscribe_reply':
+                    self._subscribed.update(data['subscribed'])
+                elif data['action'] == 'unsubscribe_reply':
+                    self._subscribed -= set(data['unsubscribed'])
+            except (WebSocketException, connection_error) as e:
+                warnings.warn("web socket exception: {}, will reconnect".format(str(e)), stacklevel=0)
+                time.sleep(0.1)
+                self._reconnect()
+
+    def listen(self, handler=None):
+        """获取实时行情。
+        当 handler 参数为 None (默认情况) 时，此函数返回一个generator，用法如下：
+
+            for msg in client.listen():
+                process(msg)
+
+        当 handler 不为 None 时，此函数会启动一个新的线程，在线程中执行：
+
+            for msg in client.listen():
+                handler(msg)
+
+        注意，此时 handler 在另一个线程中执行；请小心处理线程之间的同步问题。此时函数不再阻塞，返回创建的线程对象。
+        当调用 `client.close()` 时，线程会关闭。
+
+        :returns: generator | threading.Thread
+        """
+        if self._closed:
+            raise RuntimeError('this connection is closed.')
+
+        if handler is None:
+            return self._listen()
+
+        def _process_msg():
+            for msg in self._listen():
+                if self._closed:
+                    break
+                handler(msg)
+
+        thread = threading.Thread(target=_process_msg, daemon=True)
+        thread.start()
+        return thread
```

## rqdatac/services/market_data.py

 * *Ordering differences only*

```diff
@@ -1,564 +1,564 @@
-# -*- coding: utf-8 -*-
-import warnings
-from collections import OrderedDict
-import math
-
-import pandas as pd
-
-from rqdatac.services.calendar import get_previous_trading_date
-from rqdatac.services.get_price import get_price
-from rqdatac.services.basic import instruments
-from rqdatac.validators import (
-    ensure_date_or_today_int,
-    check_quarter,
-    quarter_string_to_date,
-    ensure_list_of_string,
-    ensure_order,
-    check_items_in_container,
-    ensure_date_range,
-    ensure_date_int,
-    ensure_order_book_ids,
-    raise_for_no_panel,
-)
-from rqdatac.client import get_client
-from rqdatac.decorators import export_as_api, compatible_with_parm
-from rqdatac.utils import pf_fill_nan, is_panel_removed
-
-
-@export_as_api
-@compatible_with_parm(name="country", value="cn", replace="market")
-def get_split(order_book_ids, start_date=None, end_date=None, market="cn"):
-    """获取拆分信息
-
-    :param order_book_ids: 股票 order_book_id or order_book_id list
-    :param start_date: 开始日期；默认为上市首日
-    :param end_date: 结束日期；默认为今天
-    :param market:  (Default value = "cn")
-
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-    if start_date is not None:
-        start_date = ensure_date_int(start_date)
-    if end_date is not None:
-        end_date = ensure_date_int(end_date)
-    data = get_client().execute("get_split", order_book_ids, start_date, end_date, market=market)
-    if not data:
-        return
-    df = pd.DataFrame(data)
-    df.sort_values("ex_dividend_date", inplace=True)
-    # cumprod [1, 2, 4] -> [1, 1*2, 1*2*4]
-    df["cum_factor"] = df["split_coefficient_to"] / df["split_coefficient_from"]
-    df["cum_factor"] = df.groupby("order_book_id")["cum_factor"].cumprod()
-    if len(order_book_ids) == 1:
-        df.set_index("ex_dividend_date", inplace=True)
-    else:
-        df.set_index(["order_book_id", "ex_dividend_date"], inplace=True)
-    df.sort_index(inplace=True)
-    return df
-
-
-@export_as_api
-@compatible_with_parm(name="country", value="cn", replace="market")
-def get_dividend(order_book_ids, start_date=None, end_date=None, adjusted=False, expect_df=False, market="cn"):
-    """获取分红信息
-
-    :param order_book_ids: 股票 order_book_id or order_book_id list
-    :param start_date: 开始日期，默认为股票上市日期
-    :param end_date: 结束日期，默认为今天
-    :param adjusted: deprecated
-    :param market:  (Default value = "cn")
-
-    """
-    if adjusted:
-        warnings.warn(
-            "get_dividend adjusted = `True` is not supported yet. "
-            "The default value is `False` now."
-        )
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-    if start_date is not None:
-        start_date = ensure_date_int(start_date)
-    if end_date is not None:
-        end_date = ensure_date_int(end_date)
-    data = get_client().execute("get_dividend", order_book_ids, start_date, end_date, market=market)
-    if not data:
-        return
-    df = pd.DataFrame(data)
-    if len(order_book_ids) == 1 and not expect_df:
-        df.set_index("declaration_announcement_date", inplace=True)
-    else:
-        df.set_index(["order_book_id", "declaration_announcement_date"], inplace=True)
-    return df.sort_index()
-
-
-@export_as_api
-def get_dividend_info(order_book_ids, start_date=None, end_date=None, market="cn"):
-    """对应时间段是否发生分红
-
-    :param order_book_ids: 股票 order_book_id or order_book_id list
-    :param start_date: 开始日期，默认为空
-    :param end_date: 结束日期，默认为空
-    :param market:  (Default value = "cn")
-
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    if start_date is not None:
-        start_date = ensure_date_int(start_date)
-    if end_date is not None:
-        end_date = ensure_date_int(end_date)
-    if start_date and end_date:
-        if start_date > end_date:
-            raise ValueError("invalid date range: [{!r}, {!r}]".format(start_date, end_date))
-
-    data = get_client().execute("get_dividend_info", order_book_ids, start_date, end_date, market=market)
-    if not data:
-        return
-    df = pd.DataFrame(data)
-    if len(order_book_ids) == 1:
-        df.set_index("effective_date", inplace=True)
-    else:
-        df.set_index(["order_book_id", "effective_date"], inplace=True)
-    return df.sort_index()
-
-
-@export_as_api
-def get_dividend_amount(order_book_ids, start_quarter=None, end_quarter=None, date=None, market="cn"):
-    """获取股票历年分红总额
-
-    :param order_book_ids: 股票 order_book_id or order_book_id list
-    :param start_quarter: 开始季度，默认为空
-    :param end_quarter: 结束季度，默认为空
-    :param date: 公告发布日期，默认为当前日期, 如 '2020-01-01' | '20200101'
-    :param market:  (Default value = "cn")
-
-    """
-    def _sum_one_quarter(one_df):
-        return pd.Series({
-            "info_date": one_df.iloc[-1]["info_date"],
-            "amount": one_df["amount"].sum()
-        })
-
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    if start_quarter is not None:
-        check_quarter(start_quarter, 'start_quarter')
-        start_quarter = ensure_date_int(quarter_string_to_date(start_quarter))
-    if end_quarter is not None:
-        check_quarter(end_quarter, 'end_quarter')
-        end_quarter = ensure_date_int(quarter_string_to_date(end_quarter))
-
-    if start_quarter and end_quarter and start_quarter > end_quarter:
-        raise ValueError("invalid quarter range: [{!r}, {!r}]".format(start_quarter, end_quarter))
-    date = ensure_date_or_today_int(date)
-
-    data = get_client().execute("get_dividend_amount", order_book_ids, start_quarter, end_quarter, date, market=market)
-    if not data:
-        return
-    df = pd.DataFrame(data)
-    # 可能在不同的info_date下, 存在相同 end_date的数据, 这时候取info_date最新的那条
-    df.sort_values(["order_book_id", "info_date", "end_date"], inplace=True)
-    df.drop_duplicates(subset=["order_book_id", "end_date"], keep="last", inplace=True)
-    df["quarter"] = df["end_date"].apply(
-        lambda d: "{}q{}".format(d.year, math.ceil(d.month / 3))
-    )
-    df = df.groupby(["order_book_id", "quarter"]).apply(_sum_one_quarter)
-    return df
-
-
-@export_as_api
-@compatible_with_parm(name="country", value="cn", replace="market")
-def get_ex_factor(order_book_ids, start_date=None, end_date=None, market="cn"):
-    """获取复权因子
-
-    :param order_book_ids: 如'000001.XSHE'
-    :param market: 国家代码, 如 'cn' (Default value = "cn")
-    :param start_date: 开始日期，默认为股票上市日期
-    :param end_date: 结束日期，默认为今天
-    :returns: 如果有数据，返回一个DataFrame, 否则返回None
-
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-    if start_date is not None:
-        start_date = ensure_date_int(start_date)
-    if end_date is not None:
-        end_date = ensure_date_int(end_date)
-    data = get_client().execute("get_ex_factor", order_book_ids, start_date, end_date, market=market)
-    if not data:
-        return None
-    df = pd.DataFrame(data)
-    df.sort_values(["order_book_id", "ex_date"], inplace=True)
-    df.set_index("ex_date", inplace=True)
-    return df
-
-
-TURNOVER_FIELDS_MAP = OrderedDict()
-TURNOVER_FIELDS_MAP["today"] = "turnover_rate"
-TURNOVER_FIELDS_MAP["week"] = "week_turnover_rate"
-TURNOVER_FIELDS_MAP["month"] = "month_turnover_rate"
-TURNOVER_FIELDS_MAP["year"] = "year_turnover_rate"
-TURNOVER_FIELDS_MAP["current_year"] = "year_sofar_turnover_rate"
-
-
-def _get_maped_fields(fields):
-    fields = ensure_list_of_string(fields, "fields")
-    check_items_in_container(fields, TURNOVER_FIELDS_MAP, "fields")
-    fields = ensure_order(fields, TURNOVER_FIELDS_MAP.keys())
-    return fields, [TURNOVER_FIELDS_MAP[field] for field in fields]
-
-
-@export_as_api
-def get_turnover_rate(order_book_ids, start_date=None, end_date=None, fields=None, expect_df=True, market="cn"):
-    """获取股票换手率数据
-
-    :param order_book_ids: 股票代码或股票代码列表
-    :param start_date: 开始时间
-    :param end_date: 结束时间；在 start_date 和 end_date 都不指定的情况下，默认为最近3个月
-    :param fields: str或list类型. 默认为None, 返回所有fields.
-                   field 包括： 'today', 'week', 'month', 'year', 'current_year'
-                   (Default value = None)
-    :param expect_df: 返回 MultiIndex DataFrame (Default value = True)
-    :param market: 地区代码, 如: 'cn' (Default value = "cn")
-    :returns: 如果order_book_ids或fields为单个值 返回pandas.DataFrame, 否则返回pandas.Panel
-
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    if fields is not None:
-        fields, mapped_fields = _get_maped_fields(fields)
-    else:
-        fields, mapped_fields = list(TURNOVER_FIELDS_MAP.keys()), list(TURNOVER_FIELDS_MAP.values())
-    df = get_client().execute(
-        "get_turnover_rate", order_book_ids, start_date, end_date, mapped_fields, market=market
-    )
-    if not df:
-        return
-    df = pd.DataFrame(df, columns=["tradedate", "order_book_id"] + mapped_fields)
-    df.rename(columns={v: k for k, v in TURNOVER_FIELDS_MAP.items()}, inplace=True)
-
-    if not expect_df and not is_panel_removed:
-        df.set_index(["tradedate", "order_book_id"], inplace=True)
-        df.sort_index(inplace=True)
-        df = df.to_panel()
-        df = pf_fill_nan(df, order_book_ids)
-        if len(order_book_ids) == 1:
-            df = df.minor_xs(*order_book_ids)
-            if fields and len(fields) == 1:
-                return df[fields[0]]
-            return df
-        if fields and len(fields) == 1:
-            return df[fields[0]]
-        warnings.warn("Panel is removed after pandas version 0.25.0."
-                      " the default value of 'expect_df' will change to True in the future.")
-        return df
-    else:
-        df.sort_values(["order_book_id", "tradedate"], inplace=True)
-        df.set_index(["order_book_id", "tradedate"], inplace=True)
-        if expect_df:
-            return df
-
-        if len(order_book_ids) != 1 and len(fields) != 1:
-            raise_for_no_panel()
-
-        if len(order_book_ids) == 1:
-            df.reset_index(level=0, drop=True, inplace=True)
-            if len(fields) == 1:
-                df = df[fields[0]]
-            return df
-        else:
-            df = df.unstack(0)[fields[0]]
-            df.index.name = None
-            df.columns.name = None
-            return df
-
-
-@export_as_api
-def get_price_change_rate(order_book_ids, start_date=None, end_date=None, expect_df=True, market="cn"):
-    """获取价格变化信息
-
-    :param order_book_ids: 股票列表
-    :param start_date: 开始日期: 如'2013-01-04'
-    :param end_date: 结束日期: 如'2014-01-04'；在 start_date 和 end_date 都不指定的情况下，默认为最近3个月
-    :param expect_df: 是否返回 MultiIndex DataFrame (Default value = True)
-    :param market: 地区代码
-    :returns: 如果输入一只股票, 则返回pandas.Series, 否则返回pandas.DataFrame
-
-    """
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    all_instruments = instruments(order_book_ids)
-    convertibles = []
-    not_convertibles = []
-    for i in all_instruments:
-        if i.type == 'Convertible':
-            convertibles.append(i.order_book_id)
-        else:
-            not_convertibles.append(i.order_book_id)
-    df = None
-    df_convertible = None
-
-    if not_convertibles:
-        # 向前多取一天，防止start_date的收益率缺失
-        start_date_prev = get_previous_trading_date(start_date)
-        df = get_price(
-            order_book_ids=not_convertibles,
-            start_date=start_date_prev, end_date=end_date,
-            adjust_type='post', fields='close', expect_df=True
-        )
-
-        if df is not None:
-            df = df['close']
-            df = df.groupby(level='order_book_id').pct_change().dropna()
-
-    # 因为可转债可能会派息，所以用 close 去算不准，需要用当天不复权的 close 和 prev_close 去算
-    if convertibles:
-        df_convertible = get_price(
-            order_book_ids=convertibles,
-            start_date=start_date, end_date=end_date,
-            adjust_type='none', fields=['close', 'prev_close'], expect_df=True
-        )
-
-        if df_convertible is not None:
-            df_convertible = df_convertible['close'] / df_convertible['prev_close'] - 1
-
-    if df is None and df_convertible is None:
-        return None
-    df = pd.concat([df, df_convertible])
-    if df.empty:
-        return None
-    df = df.unstack('order_book_id')
-
-    if len(order_book_ids) == 1 and not expect_df:
-        series = df[order_book_ids[0]]
-        return series
-
-    return df
-
-
-@export_as_api
-@compatible_with_parm(name="country", value="cn", replace="market")
-def get_yield_curve(start_date=None, end_date=None, tenor=None, market="cn"):
-    """获取国债收益率曲线
-
-    :param market: 地区代码, 如'cn', 'us' (Default value = "cn")
-    :param start_date: 开始日期 (Default value = "2013-01-04")
-    :param end_date: 结束日期 (Default value = "2014-01-04")
-    :param tenor: 类别, 如 OS, 1M, 3M, 1Y (Default value = None)
-
-    """
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    all_tenor = (
-        "0S",
-        "1M",
-        "2M",
-        "3M",
-        "6M",
-        "9M",
-        "1Y",
-        "2Y",
-        "3Y",
-        "4Y",
-        "5Y",
-        "6Y",
-        "7Y",
-        "8Y",
-        "9Y",
-        "10Y",
-        "15Y",
-        "20Y",
-        "30Y",
-        "40Y",
-        "50Y",
-    )
-    if tenor:
-        tenor = ensure_list_of_string(tenor, "tenor")
-        check_items_in_container(tenor, all_tenor, "tenor")
-        tenor = ensure_order(tenor, all_tenor)
-    df = get_client().execute("get_yield_curve", start_date, end_date, tenor, market=market)
-    if not df:
-        return
-    columns = ["trading_date"]
-    columns.extend(tenor or all_tenor)
-    df = pd.DataFrame(df, columns=columns)
-    df.set_index("trading_date", inplace=True)
-    return df.sort_index()
-
-
-@export_as_api
-def get_block_trade(order_book_ids, start_date=None, end_date=None, market='cn'):
-    """获取大宗交易信息
-    :param order_book_ids: 股票代码
-    :param start_date: 起始日期，默认为前三个月
-    :param end_date: 截止日期，默认为今天
-    :param market: (default value = 'cn')
-    :return: pd.DataFrame or None
-    """
-
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-
-    data = get_client().execute('get_block_trade', order_book_ids, start_date, end_date, market=market)
-    if not data:
-        return
-    df = pd.DataFrame(data)[['order_book_id', 'trade_date', 'price', 'volume', 'total_turnover', 'buyer', 'seller']]
-    df.set_index(["order_book_id", "trade_date"], inplace=True)
-    df.sort_index(inplace=True)
-    return df
-
-
-EXCHANGE_DATE_FIELDS = [
-    "currency_pair",
-    "bid_referrence_rate",
-    "ask_referrence_rate",
-    "middle_referrence_rate",
-    "bid_settlement_rate_sh",
-    "ask_settlement_rate_sh",
-    "bid_settlement_rate_sz",
-    "ask_settlement_rate_sz",
-]
-
-
-@export_as_api
-def get_exchange_rate(start_date=None, end_date=None, fields=None):
-    """获取汇率信息
-
-    :param start_date: 开始日期, 如 '2013-01-04' (Default value = None)
-    :param end_date: 结束日期, 如 '2014-01-04' (Default value = None)
-    :param fields: str or list 返回 字段名称:currency_pair、bid_referrence_rate、ask_referrence_rate、middle_referrence_rate
-        bid_settlement_rate_sh、ask_settlement_rate_sh、bid_settlement_rate_sz、ask_settlement_rate_sz
-
-    """
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    if fields:
-        fields = ensure_list_of_string(fields, "fields")
-        check_items_in_container(fields, EXCHANGE_DATE_FIELDS, "fields")
-    else:
-        fields = EXCHANGE_DATE_FIELDS
-
-    data = get_client().execute("get_exchange_rate", start_date, end_date, fields)
-    if not data:
-        return None
-    df = pd.DataFrame(data)
-    df.set_index("date", inplace=True)
-    df = df[fields]
-    return df
-
-
-TEMPORARY_CODE_FIELDS = [
-    "symbol",
-    "temporary_trade_code",
-    "temporary_symbol",
-    "temporary_round_lot",
-    "temporary_effective_date",
-    "parallel_effective_date",
-    "parallel_cancel_date"
-]
-
-
-@export_as_api
-def get_temporary_code(order_book_ids, market="cn"):
-    """临时交易代码查询
-
-    :param order_book_ids: 股票 order_book_id or order_book_id list
-    :param market:  (Default value = "cn")
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-
-    data = get_client().execute("get_temporary_code", order_book_ids, market)
-    if not data:
-        return None
-    df = pd.DataFrame(data)
-    df.set_index("order_book_id", inplace=True)
-    df = df[TEMPORARY_CODE_FIELDS]
-    return df
-
-
-INTERBANK_OFFERED_RATE_FIELDS = ['ON', '1W', '2W', '1M', '3M', '6M', '9M', '1Y']
-
-
-@export_as_api
-def get_interbank_offered_rate(start_date, end_date, fields=None, source='Shibor'):
-    """ 获取银行间同业拆放利率
-
-    :param start_date: 开始日期, 如 '2013-01-04' (Default value = None)
-    :param end_date: 结束日期, 如 '2014-01-04' (Default value = None)
-    :param fields: str or list:
-        ON	隔夜
-        1W	1周
-        2W	2周
-        1M	1个月
-        3M	3个月
-        6M	6个月
-        9M	9个月
-        1Y	1年
-    :param source: str, 默认Shibor 上海银行间同业拆放利率
-
-    :returns DataFrame
-    """
-
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    if fields:
-        fields = ensure_list_of_string(fields, "fields")
-        check_items_in_container(fields, INTERBANK_OFFERED_RATE_FIELDS, "fields")
-    else:
-        fields = INTERBANK_OFFERED_RATE_FIELDS
-
-    data = get_client().execute("get_interbank_offered_rate", start_date, end_date, fields, source)
-    if not data:
-        return None
-    df = pd.DataFrame(data)
-    df.set_index("date", inplace=True)
-    return df
-
-
-@export_as_api
-def get_abnormal_stocks(start_date=None, end_date=None, types=None, market="cn"):
-    """获取龙虎榜每日明细
-
-    :param start_date: 开始日期
-    :param end_date: 结束日期
-    :param types: 异动类型代码
-
-    :returns DataFrame"""
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    if types:
-        types = ensure_list_of_string(types, "types")
-    data = get_client().execute("get_abnormal_stocks", start_date, end_date, types, market)
-    if not data:
-        return None
-    df = pd.DataFrame.from_records(data)
-    df["abnormal_e_date"] = df["date"]
-    df.set_index(["order_book_id", "date"], inplace=True)
-    # 固定返回的列, 确保其包括 change_rate, turnover_rate, amplitude, deviation
-    columns = [
-        "type", "abnormal_s_date", "abnormal_e_date", "volume",
-        "total_turnover", "change_rate", "turnover_rate", "amplitude",
-        "deviation", "reason"
-    ]
-    df = df.reindex(columns=columns)
-    return df
-
-
-@export_as_api
-def get_abnormal_stocks_detail(order_book_ids, start_date=None, end_date=None, sides=None, types=None, market="cn"):
-    """获取龙虎榜机构交易明细
-
-    :param order_book_ids: 证券id
-    :param start_date: 开始时间
-    :param end_date: 结束时间
-    :param sides: 交易方向, 可选值包括buy, sell, cum
-    :param types: 异动类型代码
-
-    :returns DataFrame
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    if types:
-        types = ensure_list_of_string(types, "types")
-    if sides:
-        sides = ensure_list_of_string(sides, "side")
-        check_items_in_container(sides, ["buy", "sell", "cum"], "side")
-    data = get_client().execute("get_abnormal_stocks_detail", order_book_ids, start_date, end_date, sides, types)
-    if not data:
-        return None
-    df = pd.DataFrame.from_records(data)
-    df.sort_values(["order_book_id", "date", "side", "rank"], inplace=True)
-    df.set_index(["order_book_id", "date"], inplace=True)
-    return df
+# -*- coding: utf-8 -*-
+import warnings
+from collections import OrderedDict
+import math
+
+import pandas as pd
+
+from rqdatac.services.calendar import get_previous_trading_date
+from rqdatac.services.get_price import get_price
+from rqdatac.services.basic import instruments
+from rqdatac.validators import (
+    ensure_date_or_today_int,
+    check_quarter,
+    quarter_string_to_date,
+    ensure_list_of_string,
+    ensure_order,
+    check_items_in_container,
+    ensure_date_range,
+    ensure_date_int,
+    ensure_order_book_ids,
+    raise_for_no_panel,
+)
+from rqdatac.client import get_client
+from rqdatac.decorators import export_as_api, compatible_with_parm
+from rqdatac.utils import pf_fill_nan, is_panel_removed
+
+
+@export_as_api
+@compatible_with_parm(name="country", value="cn", replace="market")
+def get_split(order_book_ids, start_date=None, end_date=None, market="cn"):
+    """获取拆分信息
+
+    :param order_book_ids: 股票 order_book_id or order_book_id list
+    :param start_date: 开始日期；默认为上市首日
+    :param end_date: 结束日期；默认为今天
+    :param market:  (Default value = "cn")
+
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+    if start_date is not None:
+        start_date = ensure_date_int(start_date)
+    if end_date is not None:
+        end_date = ensure_date_int(end_date)
+    data = get_client().execute("get_split", order_book_ids, start_date, end_date, market=market)
+    if not data:
+        return
+    df = pd.DataFrame(data)
+    df.sort_values("ex_dividend_date", inplace=True)
+    # cumprod [1, 2, 4] -> [1, 1*2, 1*2*4]
+    df["cum_factor"] = df["split_coefficient_to"] / df["split_coefficient_from"]
+    df["cum_factor"] = df.groupby("order_book_id")["cum_factor"].cumprod()
+    if len(order_book_ids) == 1:
+        df.set_index("ex_dividend_date", inplace=True)
+    else:
+        df.set_index(["order_book_id", "ex_dividend_date"], inplace=True)
+    df.sort_index(inplace=True)
+    return df
+
+
+@export_as_api
+@compatible_with_parm(name="country", value="cn", replace="market")
+def get_dividend(order_book_ids, start_date=None, end_date=None, adjusted=False, expect_df=False, market="cn"):
+    """获取分红信息
+
+    :param order_book_ids: 股票 order_book_id or order_book_id list
+    :param start_date: 开始日期，默认为股票上市日期
+    :param end_date: 结束日期，默认为今天
+    :param adjusted: deprecated
+    :param market:  (Default value = "cn")
+
+    """
+    if adjusted:
+        warnings.warn(
+            "get_dividend adjusted = `True` is not supported yet. "
+            "The default value is `False` now."
+        )
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+    if start_date is not None:
+        start_date = ensure_date_int(start_date)
+    if end_date is not None:
+        end_date = ensure_date_int(end_date)
+    data = get_client().execute("get_dividend", order_book_ids, start_date, end_date, market=market)
+    if not data:
+        return
+    df = pd.DataFrame(data)
+    if len(order_book_ids) == 1 and not expect_df:
+        df.set_index("declaration_announcement_date", inplace=True)
+    else:
+        df.set_index(["order_book_id", "declaration_announcement_date"], inplace=True)
+    return df.sort_index()
+
+
+@export_as_api
+def get_dividend_info(order_book_ids, start_date=None, end_date=None, market="cn"):
+    """对应时间段是否发生分红
+
+    :param order_book_ids: 股票 order_book_id or order_book_id list
+    :param start_date: 开始日期，默认为空
+    :param end_date: 结束日期，默认为空
+    :param market:  (Default value = "cn")
+
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    if start_date is not None:
+        start_date = ensure_date_int(start_date)
+    if end_date is not None:
+        end_date = ensure_date_int(end_date)
+    if start_date and end_date:
+        if start_date > end_date:
+            raise ValueError("invalid date range: [{!r}, {!r}]".format(start_date, end_date))
+
+    data = get_client().execute("get_dividend_info", order_book_ids, start_date, end_date, market=market)
+    if not data:
+        return
+    df = pd.DataFrame(data)
+    if len(order_book_ids) == 1:
+        df.set_index("effective_date", inplace=True)
+    else:
+        df.set_index(["order_book_id", "effective_date"], inplace=True)
+    return df.sort_index()
+
+
+@export_as_api
+def get_dividend_amount(order_book_ids, start_quarter=None, end_quarter=None, date=None, market="cn"):
+    """获取股票历年分红总额
+
+    :param order_book_ids: 股票 order_book_id or order_book_id list
+    :param start_quarter: 开始季度，默认为空
+    :param end_quarter: 结束季度，默认为空
+    :param date: 公告发布日期，默认为当前日期, 如 '2020-01-01' | '20200101'
+    :param market:  (Default value = "cn")
+
+    """
+    def _sum_one_quarter(one_df):
+        return pd.Series({
+            "info_date": one_df.iloc[-1]["info_date"],
+            "amount": one_df["amount"].sum()
+        })
+
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    if start_quarter is not None:
+        check_quarter(start_quarter, 'start_quarter')
+        start_quarter = ensure_date_int(quarter_string_to_date(start_quarter))
+    if end_quarter is not None:
+        check_quarter(end_quarter, 'end_quarter')
+        end_quarter = ensure_date_int(quarter_string_to_date(end_quarter))
+
+    if start_quarter and end_quarter and start_quarter > end_quarter:
+        raise ValueError("invalid quarter range: [{!r}, {!r}]".format(start_quarter, end_quarter))
+    date = ensure_date_or_today_int(date)
+
+    data = get_client().execute("get_dividend_amount", order_book_ids, start_quarter, end_quarter, date, market=market)
+    if not data:
+        return
+    df = pd.DataFrame(data)
+    # 可能在不同的info_date下, 存在相同 end_date的数据, 这时候取info_date最新的那条
+    df.sort_values(["order_book_id", "info_date", "end_date"], inplace=True)
+    df.drop_duplicates(subset=["order_book_id", "end_date"], keep="last", inplace=True)
+    df["quarter"] = df["end_date"].apply(
+        lambda d: "{}q{}".format(d.year, math.ceil(d.month / 3))
+    )
+    df = df.groupby(["order_book_id", "quarter"]).apply(_sum_one_quarter)
+    return df
+
+
+@export_as_api
+@compatible_with_parm(name="country", value="cn", replace="market")
+def get_ex_factor(order_book_ids, start_date=None, end_date=None, market="cn"):
+    """获取复权因子
+
+    :param order_book_ids: 如'000001.XSHE'
+    :param market: 国家代码, 如 'cn' (Default value = "cn")
+    :param start_date: 开始日期，默认为股票上市日期
+    :param end_date: 结束日期，默认为今天
+    :returns: 如果有数据，返回一个DataFrame, 否则返回None
+
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+    if start_date is not None:
+        start_date = ensure_date_int(start_date)
+    if end_date is not None:
+        end_date = ensure_date_int(end_date)
+    data = get_client().execute("get_ex_factor", order_book_ids, start_date, end_date, market=market)
+    if not data:
+        return None
+    df = pd.DataFrame(data)
+    df.sort_values(["order_book_id", "ex_date"], inplace=True)
+    df.set_index("ex_date", inplace=True)
+    return df
+
+
+TURNOVER_FIELDS_MAP = OrderedDict()
+TURNOVER_FIELDS_MAP["today"] = "turnover_rate"
+TURNOVER_FIELDS_MAP["week"] = "week_turnover_rate"
+TURNOVER_FIELDS_MAP["month"] = "month_turnover_rate"
+TURNOVER_FIELDS_MAP["year"] = "year_turnover_rate"
+TURNOVER_FIELDS_MAP["current_year"] = "year_sofar_turnover_rate"
+
+
+def _get_maped_fields(fields):
+    fields = ensure_list_of_string(fields, "fields")
+    check_items_in_container(fields, TURNOVER_FIELDS_MAP, "fields")
+    fields = ensure_order(fields, TURNOVER_FIELDS_MAP.keys())
+    return fields, [TURNOVER_FIELDS_MAP[field] for field in fields]
+
+
+@export_as_api
+def get_turnover_rate(order_book_ids, start_date=None, end_date=None, fields=None, expect_df=True, market="cn"):
+    """获取股票换手率数据
+
+    :param order_book_ids: 股票代码或股票代码列表
+    :param start_date: 开始时间
+    :param end_date: 结束时间；在 start_date 和 end_date 都不指定的情况下，默认为最近3个月
+    :param fields: str或list类型. 默认为None, 返回所有fields.
+                   field 包括： 'today', 'week', 'month', 'year', 'current_year'
+                   (Default value = None)
+    :param expect_df: 返回 MultiIndex DataFrame (Default value = True)
+    :param market: 地区代码, 如: 'cn' (Default value = "cn")
+    :returns: 如果order_book_ids或fields为单个值 返回pandas.DataFrame, 否则返回pandas.Panel
+
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    if fields is not None:
+        fields, mapped_fields = _get_maped_fields(fields)
+    else:
+        fields, mapped_fields = list(TURNOVER_FIELDS_MAP.keys()), list(TURNOVER_FIELDS_MAP.values())
+    df = get_client().execute(
+        "get_turnover_rate", order_book_ids, start_date, end_date, mapped_fields, market=market
+    )
+    if not df:
+        return
+    df = pd.DataFrame(df, columns=["tradedate", "order_book_id"] + mapped_fields)
+    df.rename(columns={v: k for k, v in TURNOVER_FIELDS_MAP.items()}, inplace=True)
+
+    if not expect_df and not is_panel_removed:
+        df.set_index(["tradedate", "order_book_id"], inplace=True)
+        df.sort_index(inplace=True)
+        df = df.to_panel()
+        df = pf_fill_nan(df, order_book_ids)
+        if len(order_book_ids) == 1:
+            df = df.minor_xs(*order_book_ids)
+            if fields and len(fields) == 1:
+                return df[fields[0]]
+            return df
+        if fields and len(fields) == 1:
+            return df[fields[0]]
+        warnings.warn("Panel is removed after pandas version 0.25.0."
+                      " the default value of 'expect_df' will change to True in the future.")
+        return df
+    else:
+        df.sort_values(["order_book_id", "tradedate"], inplace=True)
+        df.set_index(["order_book_id", "tradedate"], inplace=True)
+        if expect_df:
+            return df
+
+        if len(order_book_ids) != 1 and len(fields) != 1:
+            raise_for_no_panel()
+
+        if len(order_book_ids) == 1:
+            df.reset_index(level=0, drop=True, inplace=True)
+            if len(fields) == 1:
+                df = df[fields[0]]
+            return df
+        else:
+            df = df.unstack(0)[fields[0]]
+            df.index.name = None
+            df.columns.name = None
+            return df
+
+
+@export_as_api
+def get_price_change_rate(order_book_ids, start_date=None, end_date=None, expect_df=True, market="cn"):
+    """获取价格变化信息
+
+    :param order_book_ids: 股票列表
+    :param start_date: 开始日期: 如'2013-01-04'
+    :param end_date: 结束日期: 如'2014-01-04'；在 start_date 和 end_date 都不指定的情况下，默认为最近3个月
+    :param expect_df: 是否返回 MultiIndex DataFrame (Default value = True)
+    :param market: 地区代码
+    :returns: 如果输入一只股票, 则返回pandas.Series, 否则返回pandas.DataFrame
+
+    """
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    all_instruments = instruments(order_book_ids)
+    convertibles = []
+    not_convertibles = []
+    for i in all_instruments:
+        if i.type == 'Convertible':
+            convertibles.append(i.order_book_id)
+        else:
+            not_convertibles.append(i.order_book_id)
+    df = None
+    df_convertible = None
+
+    if not_convertibles:
+        # 向前多取一天，防止start_date的收益率缺失
+        start_date_prev = get_previous_trading_date(start_date)
+        df = get_price(
+            order_book_ids=not_convertibles,
+            start_date=start_date_prev, end_date=end_date,
+            adjust_type='post', fields='close', expect_df=True
+        )
+
+        if df is not None:
+            df = df['close']
+            df = df.groupby(level='order_book_id').pct_change().dropna()
+
+    # 因为可转债可能会派息，所以用 close 去算不准，需要用当天不复权的 close 和 prev_close 去算
+    if convertibles:
+        df_convertible = get_price(
+            order_book_ids=convertibles,
+            start_date=start_date, end_date=end_date,
+            adjust_type='none', fields=['close', 'prev_close'], expect_df=True
+        )
+
+        if df_convertible is not None:
+            df_convertible = df_convertible['close'] / df_convertible['prev_close'] - 1
+
+    if df is None and df_convertible is None:
+        return None
+    df = pd.concat([df, df_convertible])
+    if df.empty:
+        return None
+    df = df.unstack('order_book_id')
+
+    if len(order_book_ids) == 1 and not expect_df:
+        series = df[order_book_ids[0]]
+        return series
+
+    return df
+
+
+@export_as_api
+@compatible_with_parm(name="country", value="cn", replace="market")
+def get_yield_curve(start_date=None, end_date=None, tenor=None, market="cn"):
+    """获取国债收益率曲线
+
+    :param market: 地区代码, 如'cn', 'us' (Default value = "cn")
+    :param start_date: 开始日期 (Default value = "2013-01-04")
+    :param end_date: 结束日期 (Default value = "2014-01-04")
+    :param tenor: 类别, 如 OS, 1M, 3M, 1Y (Default value = None)
+
+    """
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    all_tenor = (
+        "0S",
+        "1M",
+        "2M",
+        "3M",
+        "6M",
+        "9M",
+        "1Y",
+        "2Y",
+        "3Y",
+        "4Y",
+        "5Y",
+        "6Y",
+        "7Y",
+        "8Y",
+        "9Y",
+        "10Y",
+        "15Y",
+        "20Y",
+        "30Y",
+        "40Y",
+        "50Y",
+    )
+    if tenor:
+        tenor = ensure_list_of_string(tenor, "tenor")
+        check_items_in_container(tenor, all_tenor, "tenor")
+        tenor = ensure_order(tenor, all_tenor)
+    df = get_client().execute("get_yield_curve", start_date, end_date, tenor, market=market)
+    if not df:
+        return
+    columns = ["trading_date"]
+    columns.extend(tenor or all_tenor)
+    df = pd.DataFrame(df, columns=columns)
+    df.set_index("trading_date", inplace=True)
+    return df.sort_index()
+
+
+@export_as_api
+def get_block_trade(order_book_ids, start_date=None, end_date=None, market='cn'):
+    """获取大宗交易信息
+    :param order_book_ids: 股票代码
+    :param start_date: 起始日期，默认为前三个月
+    :param end_date: 截止日期，默认为今天
+    :param market: (default value = 'cn')
+    :return: pd.DataFrame or None
+    """
+
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+
+    data = get_client().execute('get_block_trade', order_book_ids, start_date, end_date, market=market)
+    if not data:
+        return
+    df = pd.DataFrame(data)[['order_book_id', 'trade_date', 'price', 'volume', 'total_turnover', 'buyer', 'seller']]
+    df.set_index(["order_book_id", "trade_date"], inplace=True)
+    df.sort_index(inplace=True)
+    return df
+
+
+EXCHANGE_DATE_FIELDS = [
+    "currency_pair",
+    "bid_referrence_rate",
+    "ask_referrence_rate",
+    "middle_referrence_rate",
+    "bid_settlement_rate_sh",
+    "ask_settlement_rate_sh",
+    "bid_settlement_rate_sz",
+    "ask_settlement_rate_sz",
+]
+
+
+@export_as_api
+def get_exchange_rate(start_date=None, end_date=None, fields=None):
+    """获取汇率信息
+
+    :param start_date: 开始日期, 如 '2013-01-04' (Default value = None)
+    :param end_date: 结束日期, 如 '2014-01-04' (Default value = None)
+    :param fields: str or list 返回 字段名称:currency_pair、bid_referrence_rate、ask_referrence_rate、middle_referrence_rate
+        bid_settlement_rate_sh、ask_settlement_rate_sh、bid_settlement_rate_sz、ask_settlement_rate_sz
+
+    """
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    if fields:
+        fields = ensure_list_of_string(fields, "fields")
+        check_items_in_container(fields, EXCHANGE_DATE_FIELDS, "fields")
+    else:
+        fields = EXCHANGE_DATE_FIELDS
+
+    data = get_client().execute("get_exchange_rate", start_date, end_date, fields)
+    if not data:
+        return None
+    df = pd.DataFrame(data)
+    df.set_index("date", inplace=True)
+    df = df[fields]
+    return df
+
+
+TEMPORARY_CODE_FIELDS = [
+    "symbol",
+    "temporary_trade_code",
+    "temporary_symbol",
+    "temporary_round_lot",
+    "temporary_effective_date",
+    "parallel_effective_date",
+    "parallel_cancel_date"
+]
+
+
+@export_as_api
+def get_temporary_code(order_book_ids, market="cn"):
+    """临时交易代码查询
+
+    :param order_book_ids: 股票 order_book_id or order_book_id list
+    :param market:  (Default value = "cn")
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+
+    data = get_client().execute("get_temporary_code", order_book_ids, market)
+    if not data:
+        return None
+    df = pd.DataFrame(data)
+    df.set_index("order_book_id", inplace=True)
+    df = df[TEMPORARY_CODE_FIELDS]
+    return df
+
+
+INTERBANK_OFFERED_RATE_FIELDS = ['ON', '1W', '2W', '1M', '3M', '6M', '9M', '1Y']
+
+
+@export_as_api
+def get_interbank_offered_rate(start_date, end_date, fields=None, source='Shibor'):
+    """ 获取银行间同业拆放利率
+
+    :param start_date: 开始日期, 如 '2013-01-04' (Default value = None)
+    :param end_date: 结束日期, 如 '2014-01-04' (Default value = None)
+    :param fields: str or list:
+        ON	隔夜
+        1W	1周
+        2W	2周
+        1M	1个月
+        3M	3个月
+        6M	6个月
+        9M	9个月
+        1Y	1年
+    :param source: str, 默认Shibor 上海银行间同业拆放利率
+
+    :returns DataFrame
+    """
+
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    if fields:
+        fields = ensure_list_of_string(fields, "fields")
+        check_items_in_container(fields, INTERBANK_OFFERED_RATE_FIELDS, "fields")
+    else:
+        fields = INTERBANK_OFFERED_RATE_FIELDS
+
+    data = get_client().execute("get_interbank_offered_rate", start_date, end_date, fields, source)
+    if not data:
+        return None
+    df = pd.DataFrame(data)
+    df.set_index("date", inplace=True)
+    return df
+
+
+@export_as_api
+def get_abnormal_stocks(start_date=None, end_date=None, types=None, market="cn"):
+    """获取龙虎榜每日明细
+
+    :param start_date: 开始日期
+    :param end_date: 结束日期
+    :param types: 异动类型代码
+
+    :returns DataFrame"""
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    if types:
+        types = ensure_list_of_string(types, "types")
+    data = get_client().execute("get_abnormal_stocks", start_date, end_date, types, market)
+    if not data:
+        return None
+    df = pd.DataFrame.from_records(data)
+    df["abnormal_e_date"] = df["date"]
+    df.set_index(["order_book_id", "date"], inplace=True)
+    # 固定返回的列, 确保其包括 change_rate, turnover_rate, amplitude, deviation
+    columns = [
+        "type", "abnormal_s_date", "abnormal_e_date", "volume",
+        "total_turnover", "change_rate", "turnover_rate", "amplitude",
+        "deviation", "reason"
+    ]
+    df = df.reindex(columns=columns)
+    return df
+
+
+@export_as_api
+def get_abnormal_stocks_detail(order_book_ids, start_date=None, end_date=None, sides=None, types=None, market="cn"):
+    """获取龙虎榜机构交易明细
+
+    :param order_book_ids: 证券id
+    :param start_date: 开始时间
+    :param end_date: 结束时间
+    :param sides: 交易方向, 可选值包括buy, sell, cum
+    :param types: 异动类型代码
+
+    :returns DataFrame
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    if types:
+        types = ensure_list_of_string(types, "types")
+    if sides:
+        sides = ensure_list_of_string(sides, "side")
+        check_items_in_container(sides, ["buy", "sell", "cum"], "side")
+    data = get_client().execute("get_abnormal_stocks_detail", order_book_ids, start_date, end_date, sides, types)
+    if not data:
+        return None
+    df = pd.DataFrame.from_records(data)
+    df.sort_values(["order_book_id", "date", "side", "rank"], inplace=True)
+    df.set_index(["order_book_id", "date"], inplace=True)
+    return df
```

## rqdatac/services/options.py

```diff
@@ -1,309 +1,349 @@
-# -*- coding: utf-8 -*-
-import datetime
-
-import numpy as np
-import pandas as pd
-
-from rqdatac.validators import (
-    check_items_in_container,
-    ensure_date_int,
-    ensure_order_book_ids,
-    ensure_string,
-    ensure_string_in,
-    ensure_date_range,
-    ensure_list_of_string
-)
-
-from rqdatac import get_trading_dates
-from rqdatac.client import get_client
-from rqdatac.decorators import export_as_api
-from rqdatac.services.basic import all_instruments, instruments
-from rqdatac.services.get_price import get_price
-from rqdatac.utils import is_panel_removed, convert_bar_to_multi_df, int14_to_datetime_v
-from rqdatac.rqdatah_helper import rqdatah_serialize, http_conv_list_to_csv
-
-VALID_GREEKS_FIELDS = ['iv', 'delta', 'gamma', 'vega', 'theta', 'rho']
-
-
-@export_as_api(namespace='options')
-def get_greeks(order_book_ids, start_date=None, end_date=None, fields=None, model='implied_forward', price_type='close', frequency='1d', market="cn"):
-    """获取指定股票期权的隐含波动率iv， 以及5个希腊字母数值(delta, gamma, bega, theta, rho)
-    :param order_book_ids: 股票 order_book_id or order_book_id list
-    :param start_date: 开始日期, 必要参数
-    :param end_date: 结束日期；默认为今天
-    :param fields: str或list类型. 默认为None, 返回所有fields.
-    :param model: str类型， last: 代表用每日close价格， implied_forward 代表用隐含风险收益率计算
-    :param price_type: 'close' or 'settlement'
-    :param frequency: '1d' or '1m', 如果为'1m'，则price_type必须为'close'
-    :param market: 默认值为"cn"
-    """
-
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-    check_items_in_container(model, ['implied_forward', 'last'], 'model')
-    ensure_string_in(price_type, ('close', 'settlement'), 'price_type')
-    ensure_string_in(frequency, ('1d', '1m'), 'frequency')
-    if frequency == '1m' and price_type != 'close':
-        raise ValueError('1m frequency only support price_type=close!')
-    if start_date is not None:
-        start_date = ensure_date_int(start_date)
-    else:
-        raise ValueError('start_date is expected')
-    if end_date is not None:
-        end_date = ensure_date_int(end_date)
-    else:
-        end_date = ensure_date_int(datetime.datetime.now().date())
-    if end_date < start_date:
-        raise ValueError("invalid date range: [{!r}, {!r}]".format(start_date, end_date))
-
-    if fields is None:
-        fields = VALID_GREEKS_FIELDS
-    else:
-        fields = ensure_list_of_string(fields, 'fields')
-        check_items_in_container(fields, VALID_GREEKS_FIELDS, 'Greeks')
-
-    if frequency == '1m':
-        data = get_client().execute('options.get_greeks_min', order_book_ids, start_date, end_date, fields, model, market=market)
-    else:
-        data = get_client().execute("options.get_greeks", order_book_ids, start_date, end_date, fields, model, price_type, market=market)
-    if not data:
-        return None
-
-    if frequency == '1m':
-        data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
-        df = convert_bar_to_multi_df(data, 'datetime', fields, int14_to_datetime_v)
-        return df
-
-    df = pd.DataFrame(data)
-    date_field = 'trading_date'
-    df.set_index(["order_book_id", date_field], inplace=True)
-    df.sort_index(inplace=True)
-    return df[fields]
-
-
-SPECIAL_UNDERLYING_SYMBOL = ("510050.XSHG", "510300.XSHG", "159919.XSHE")
-
-
-@export_as_api(namespace='options')
-@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
-def get_contracts(
-    underlying,
-    option_type=None,
-    maturity=None,
-    strike=None,
-    trading_date=None
-):
-    """返回符合条件的期权
-
-    :param underlying: 标的合约, 可以填写'M'代表期货品种的字母；也可填写'M1901'这种具体 order_book_id
-    :param option_type: 期权类型, 'C'代表认购期权, 'P'代表认沽期权合约, 默认返回全部
-    :param maturity: 到期月份, 如'1811'代表期权18年11月到期, 默认返回全部到期月份
-    :param strike: 行权价, 向左靠档, 默认返回全部行权价
-    :param trading_date: 查询日期, 默认返回当前全部
-
-    :returns
-        返回order_book_id list；如果无符合条件期权则返回空list[]
-    """
-    underlying = ensure_string(underlying, "underlying").upper()
-    instruments_df = all_instruments(type='Option')
-    underlying_symbols = instruments_df.underlying_symbol.unique()
-    underlying_order_book_ids = instruments_df.underlying_order_book_id.unique()
-    instruments_df = all_instruments(type='Option', date=trading_date)
-    if underlying in underlying_symbols:
-        instruments_df = instruments_df[instruments_df.underlying_symbol == underlying]
-    elif underlying in underlying_order_book_ids:
-        instruments_df = instruments_df[instruments_df.underlying_order_book_id == underlying]
-    else:
-        raise ValueError("Unknown underlying")
-    if instruments_df.empty:
-        return []
-
-    if option_type is not None:
-        option_type = ensure_string(option_type, "option_type").upper()
-        ensure_string_in(option_type, {'P', 'C'}, "option_type")
-        instruments_df = instruments_df[instruments_df.option_type == option_type]
-
-    if maturity is not None:
-        maturity = int(maturity)
-        month = maturity % 100
-        if month not in range(1, 13):
-            raise ValueError("Unknown month")
-        year = maturity // 100 + 2000
-        str_month = str(month)
-        if len(str_month) == 1:
-            str_month = '0' + str_month
-        date_str = str(year) + '-' + str_month
-        instruments_df = instruments_df[instruments_df.maturity_date.str.startswith(date_str)]
-        if instruments_df.empty:
-            return []
-
-    if strike:
-        if underlying in SPECIAL_UNDERLYING_SYMBOL and trading_date:
-            order_book_ids = instruments_df.order_book_id.tolist()
-
-            strikes = get_price(order_book_ids, start_date=trading_date, end_date=trading_date, fields='strike_price',
-                                expect_df=is_panel_removed)
-            if strikes is None:
-                return []
-            if is_panel_removed:
-                strikes.reset_index(level=1, inplace=True, drop=True)
-            else:
-                strikes = strikes.T
-
-            instruments_df.set_index(instruments_df.order_book_id, inplace=True)
-            instruments_df['strike_price'] = strikes[strikes.columns[0]]
-            instruments_df = instruments_df[instruments_df.strike_price.notnull()]
-            if instruments_df.empty:
-                return []
-
-        l = []
-        for date in instruments_df.maturity_date.unique():
-            df = instruments_df[instruments_df.maturity_date == date]
-            df = df[df.strike_price <= strike]
-            if df.empty:
-                continue
-            df = df[df.strike_price.rank(method='min', ascending=False) == 1]
-            l += df.order_book_id.tolist()
-        return l
-
-    return instruments_df.order_book_id.tolist()
-
-
-VALID_CONTRACT_PROPERTY_FIELDS = ['product_name', 'symbol', 'contract_multiplier', 'strike_price']
-
-
-def _get_multi_index(oids, end_date, listed, de_listed):
-    mult = []
-    tds = get_trading_dates('20150101', datetime.date.today())
-    index = pd.to_datetime(tds)
-    for oid in oids:
-        if oid not in listed:
-            continue
-        s = str(listed[oid])
-        e = str(min(end_date, de_listed[oid]))
-        _start, _end = pd.Timestamp(s), pd.Timestamp(e)
-        start_pos, end_pos = index.searchsorted(_start), index.searchsorted(_end)
-        _index = index[start_pos:end_pos+1]
-        mult.extend([(oid, i) for i in _index])
-    return pd.MultiIndex.from_tuples(mult, names=['order_book_id', 'trading_date'])
-
-
-@export_as_api(namespace='options')
-def get_contract_property(
-    order_book_ids,
-    start_date=None,
-    end_date=None,
-    fields=None,
-    market='cn'
-):
-    """获取期权合约属性
-    :param order_book_ids: 股票 order_book_id or order_book_id list
-    :param start_date: 开始日期, 必要参数
-    :param end_date: 结束日期；默认为今天
-    :param fields: str或list类型. 默认为None, 返回所有fields.
-    :param market: 默认值为"cn", 可选：cn
-
-    :returns
-        返回DataFrame, 索引为 MultiIndex([order_book_id, trading_date])
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, type='Option', market=market)
-    listed_dates = {}
-    de_listed_dates = {}
-    _order_book_ids = []
-    for oid in order_book_ids:
-        i = instruments(oid)
-        # 过滤order_book_ids，只取ETF期权
-        # etf 期权的underlying_symbol都是有交易所后缀的
-        if not i.underlying_symbol.endswith(("XSHE", "XSHG")):
-            continue
-        _order_book_ids.append(oid)
-        listed_dates[oid] = int(i.listed_date.replace('-', ''))
-        de_listed_dates[oid] = int(i.de_listed_date.replace('-', ''))
-    order_book_ids = _order_book_ids
-
-    end_date = datetime.date.today() if not end_date else end_date
-    end_date = ensure_date_int(end_date)
-    if start_date:
-        start_date, end_date = ensure_date_range(start_date, end_date)
-        # 如果指定start_date, 将退市的order_book_id过滤掉
-        order_book_ids = [oid for oid in order_book_ids if start_date <= de_listed_dates[oid]]
-
-    if fields is None:
-        fields = VALID_CONTRACT_PROPERTY_FIELDS[:]
-    else:
-        if not isinstance(fields, list):
-            fields = [fields]
-        check_items_in_container(fields, VALID_CONTRACT_PROPERTY_FIELDS, 'Contract Property')
-    # get data from server
-    data = get_client().execute('options.get_contract_property', order_book_ids, fields)
-    if not data:
-        return
-    df = pd.DataFrame(data)
-
-    index = _get_multi_index(order_book_ids, end_date, listed_dates, de_listed_dates)
-    df = df.set_index(['order_book_id', 'trading_date'])
-    df = df.reindex(index).groupby("order_book_id").ffill()
-    if start_date:
-        msk = df.index.get_level_values('trading_date') >= pd.Timestamp(str(start_date))
-        df = df[msk]
-    return df.sort_index()
-
-
-@export_as_api(namespace='options')
-def get_dominant_month(
-    underlying_symbol,
-    start_date=None,
-    end_date=None,
-    rule=0,
-    market='cn'
-):
-    """获取期权主力月份
-    :param underlying_symbol: str, 期权标的代码
-    :param start_date: 开始日期, 默认为期权合约最早上市日期的后一交易日
-    :param end_date: 结束日期；默认为今天
-    :param rule: int, 选取主力月份的规则，默认为 0，主力月份不会切换为已做过主力的月份，可选：0, 1: 只考虑主力月份的选取规则
-    :param market: 默认值为"cn", 可选：cn
-
-    :returns
-        返回 Series, Index 为日期, value 为主力月份
-    """
-    check_items_in_container(rule, [0, 1], 'rule')
-    underlying_symbol = ensure_string(underlying_symbol, "underlying_symbol").upper()
-    if start_date is not None:
-        start_date = ensure_date_int(start_date)
-    else:
-        contracts = get_contracts(underlying_symbol)
-        ins = instruments(contracts)
-        start_date = ensure_date_int(min([i.listed_date for i in ins]))
-    if end_date is not None:
-        end_date = ensure_date_int(end_date)
-    else:
-        end_date = ensure_date_int(datetime.date.today())
-    if end_date < start_date:
-        raise ValueError("invalid date range: [{!r}, {!r}]".format(start_date, end_date))
-
-    result = get_client().execute('options.get_dominant_month', underlying_symbol, start_date, end_date, rule, market=market)
-
-    if not result:
-        return
-    
-    df = pd.DataFrame(result)
-    df = df.set_index('date')
-    return df.sort_index()['dominant']
-
-
-@export_as_api(namespace='options')
-def get_commission(underlying_symbols, market='cn'):
-    """获取期权交易费用信息
-    :param underlying_symbol: str, 期权标的代码
-    :param market: 默认值为"cn", 可选：cn
-
-    :returns
-        返回 DataFrame, Index 为 underlying_symbol
-    """
-    underlying_symbol = ensure_list_of_string(underlying_symbols, "underlying_symbols")
-    result = get_client().execute('options.get_commission', underlying_symbol, market=market)
-
-    if not result:
-        return
-
-    return pd.DataFrame.from_records(result, index=["underlying_symbol"])
+# -*- coding: utf-8 -*-
+import datetime
+
+import numpy as np
+import pandas as pd
+
+from rqdatac.validators import (
+    check_items_in_container,
+    ensure_date_int,
+    ensure_order_book_ids,
+    ensure_string,
+    ensure_string_in,
+    ensure_date_range,
+    ensure_list_of_string
+)
+
+from rqdatac.client import get_client
+from rqdatac.decorators import export_as_api
+from rqdatac.services.calendar import current_trading_date, get_trading_dates
+from rqdatac.services.basic import all_instruments, instruments
+from rqdatac.services.get_price import get_price
+from rqdatac.utils import is_panel_removed, convert_bar_to_multi_df, int14_to_datetime_v
+from rqdatac.rqdatah_helper import rqdatah_serialize, http_conv_list_to_csv
+
+VALID_GREEKS_FIELDS = ['iv', 'delta', 'gamma', 'vega', 'theta', 'rho']
+
+
+def get_greeks_min(order_book_ids, start_date, end_date, fields, model, market):
+    live_date = current_trading_date()
+    if start_date > live_date:
+        return None
+
+    data = get_client().execute('options.get_greeks_min', order_book_ids, start_date, end_date, fields, model, market=market)
+    data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
+    df = convert_bar_to_multi_df(data, 'datetime', fields, int14_to_datetime_v)
+
+    if end_date < live_date:
+        return df
+
+    live_date_str = '%d-%02d-%02d' % (live_date // 10000, live_date % 10000 // 100, live_date % 100)
+    live_obs = set(
+        ins.order_book_id for ins in instruments(order_book_ids)
+        if ins.de_listed_date == '0000-00-00' or ins.de_listed_date >= live_date_str
+    )
+    if df is not None:
+        idx = df.index
+        for ob in idx.levels[0]:
+            if ob not in live_obs:
+                continue
+            loc = idx.get_loc(ob)
+            if date_to_int8(idx[loc.stop - 1][-1]) == live_date:
+                live_obs.remove(ob)
+    if not live_obs:
+        return df
+
+    live_df = None
+    if end_date >= live_date:
+        live_data = get_client().execute('options.get_live_greeks_min', list(live_obs), model, market)
+        live_dfs = [pd.DataFrame(d) for d in live_data if d]
+        if live_dfs:
+            live_df = pd.concat(live_dfs)
+            live_df['datetime'] = int14_to_datetime_v(live_df['datetime'])
+            live_df.set_index(['order_book_id', 'datetime'], inplace=True)
+        if live_df is None:
+            return df
+    if df is None:
+        return live_df
+    df = pd.concat([df, live_df])
+    df.sort_index(inplace=True)
+    return df
+
+
+@export_as_api(namespace='options')
+def get_greeks(order_book_ids, start_date=None, end_date=None, fields=None, model='implied_forward', price_type='close', frequency='1d', market="cn"):
+    """获取指定股票期权的隐含波动率iv， 以及5个希腊字母数值(delta, gamma, bega, theta, rho)
+    :param order_book_ids: 股票 order_book_id or order_book_id list
+    :param start_date: 开始日期, 必要参数
+    :param end_date: 结束日期；默认为今天
+    :param fields: str或list类型. 默认为None, 返回所有fields.
+    :param model: str类型， last: 代表用每日close价格， implied_forward 代表用隐含风险收益率计算
+    :param price_type: 'close' or 'settlement'
+    :param frequency: '1d' or '1m', 如果为'1m'，则price_type必须为'close'
+    :param market: 默认值为"cn"
+    """
+
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+    check_items_in_container(model, ['implied_forward', 'last'], 'model')
+    ensure_string_in(price_type, ('close', 'settlement'), 'price_type')
+    ensure_string_in(frequency, ('1d', '1m'), 'frequency')
+    if frequency == '1m' and price_type != 'close':
+        raise ValueError('1m frequency only support price_type=close!')
+    if start_date is not None:
+        start_date = ensure_date_int(start_date)
+    else:
+        raise ValueError('start_date is expected')
+    if end_date is not None:
+        end_date = ensure_date_int(end_date)
+    else:
+        end_date = ensure_date_int(datetime.datetime.now().date())
+    if end_date < start_date:
+        raise ValueError("invalid date range: [{!r}, {!r}]".format(start_date, end_date))
+
+    if fields is None:
+        fields = VALID_GREEKS_FIELDS
+    else:
+        fields = ensure_list_of_string(fields, 'fields')
+        check_items_in_container(fields, VALID_GREEKS_FIELDS, 'Greeks')
+
+    if frequency == '1m':
+        return get_greeks_min(order_book_ids, start_date, end_date, fields, model, market)
+
+    data = get_client().execute("options.get_greeks", order_book_ids, start_date, end_date, fields, model, price_type, market=market)
+    if not data:
+        return None
+
+    df = pd.DataFrame(data)
+    date_field = 'trading_date'
+    df.set_index(["order_book_id", date_field], inplace=True)
+    df.sort_index(inplace=True)
+    return df[fields]
+
+
+SPECIAL_UNDERLYING_SYMBOL = ("510050.XSHG", "510300.XSHG", "159919.XSHE")
+
+
+@export_as_api(namespace='options')
+@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
+def get_contracts(
+    underlying,
+    option_type=None,
+    maturity=None,
+    strike=None,
+    trading_date=None
+):
+    """返回符合条件的期权
+
+    :param underlying: 标的合约, 可以填写'M'代表期货品种的字母；也可填写'M1901'这种具体 order_book_id
+    :param option_type: 期权类型, 'C'代表认购期权, 'P'代表认沽期权合约, 默认返回全部
+    :param maturity: 到期月份, 如'1811'代表期权18年11月到期, 默认返回全部到期月份
+    :param strike: 行权价, 向左靠档, 默认返回全部行权价
+    :param trading_date: 查询日期, 默认返回当前全部
+
+    :returns
+        返回order_book_id list；如果无符合条件期权则返回空list[]
+    """
+    underlying = ensure_string(underlying, "underlying").upper()
+    instruments_df = all_instruments(type='Option')
+    underlying_symbols = instruments_df.underlying_symbol.unique()
+    underlying_order_book_ids = instruments_df.underlying_order_book_id.unique()
+    instruments_df = all_instruments(type='Option', date=trading_date)
+    if underlying in underlying_symbols:
+        instruments_df = instruments_df[instruments_df.underlying_symbol == underlying]
+    elif underlying in underlying_order_book_ids:
+        instruments_df = instruments_df[instruments_df.underlying_order_book_id == underlying]
+    else:
+        raise ValueError("Unknown underlying")
+    if instruments_df.empty:
+        return []
+
+    if option_type is not None:
+        option_type = ensure_string(option_type, "option_type").upper()
+        ensure_string_in(option_type, {'P', 'C'}, "option_type")
+        instruments_df = instruments_df[instruments_df.option_type == option_type]
+
+    if maturity is not None:
+        maturity = int(maturity)
+        month = maturity % 100
+        if month not in range(1, 13):
+            raise ValueError("Unknown month")
+        year = maturity // 100 + 2000
+        str_month = str(month)
+        if len(str_month) == 1:
+            str_month = '0' + str_month
+        date_str = str(year) + '-' + str_month
+        instruments_df = instruments_df[instruments_df.maturity_date.str.startswith(date_str)]
+        if instruments_df.empty:
+            return []
+
+    if strike:
+        if underlying in SPECIAL_UNDERLYING_SYMBOL and trading_date:
+            order_book_ids = instruments_df.order_book_id.tolist()
+
+            strikes = get_price(order_book_ids, start_date=trading_date, end_date=trading_date, fields='strike_price',
+                                expect_df=is_panel_removed)
+            if strikes is None:
+                return []
+            if is_panel_removed:
+                strikes.reset_index(level=1, inplace=True, drop=True)
+            else:
+                strikes = strikes.T
+
+            instruments_df.set_index(instruments_df.order_book_id, inplace=True)
+            instruments_df['strike_price'] = strikes[strikes.columns[0]]
+            instruments_df = instruments_df[instruments_df.strike_price.notnull()]
+            if instruments_df.empty:
+                return []
+
+        l = []
+        for date in instruments_df.maturity_date.unique():
+            df = instruments_df[instruments_df.maturity_date == date]
+            df = df[df.strike_price <= strike]
+            if df.empty:
+                continue
+            df = df[df.strike_price.rank(method='min', ascending=False) == 1]
+            l += df.order_book_id.tolist()
+        return l
+
+    return instruments_df.order_book_id.tolist()
+
+
+VALID_CONTRACT_PROPERTY_FIELDS = ['product_name', 'symbol', 'contract_multiplier', 'strike_price']
+
+
+def _get_multi_index(oids, end_date, listed, de_listed):
+    mult = []
+    tds = get_trading_dates('20150101', datetime.date.today())
+    index = pd.to_datetime(tds)
+    for oid in oids:
+        if oid not in listed:
+            continue
+        s = str(listed[oid])
+        e = str(min(end_date, de_listed[oid]))
+        _start, _end = pd.Timestamp(s), pd.Timestamp(e)
+        start_pos, end_pos = index.searchsorted(_start), index.searchsorted(_end)
+        _index = index[start_pos:end_pos+1]
+        mult.extend([(oid, i) for i in _index])
+    return pd.MultiIndex.from_tuples(mult, names=['order_book_id', 'trading_date'])
+
+
+@export_as_api(namespace='options')
+def get_contract_property(
+    order_book_ids,
+    start_date=None,
+    end_date=None,
+    fields=None,
+    market='cn'
+):
+    """获取期权合约属性
+    :param order_book_ids: 股票 order_book_id or order_book_id list
+    :param start_date: 开始日期, 必要参数
+    :param end_date: 结束日期；默认为今天
+    :param fields: str或list类型. 默认为None, 返回所有fields.
+    :param market: 默认值为"cn", 可选：cn
+
+    :returns
+        返回DataFrame, 索引为 MultiIndex([order_book_id, trading_date])
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, type='Option', market=market)
+    listed_dates = {}
+    de_listed_dates = {}
+    _order_book_ids = []
+    for oid in order_book_ids:
+        i = instruments(oid)
+        # 过滤order_book_ids，只取ETF期权
+        # etf 期权的underlying_symbol都是有交易所后缀的
+        if not i.underlying_symbol.endswith(("XSHE", "XSHG")):
+            continue
+        _order_book_ids.append(oid)
+        listed_dates[oid] = int(i.listed_date.replace('-', ''))
+        de_listed_dates[oid] = int(i.de_listed_date.replace('-', ''))
+    order_book_ids = _order_book_ids
+
+    end_date = datetime.date.today() if not end_date else end_date
+    end_date = ensure_date_int(end_date)
+    if start_date:
+        start_date, end_date = ensure_date_range(start_date, end_date)
+        # 如果指定start_date, 将退市的order_book_id过滤掉
+        order_book_ids = [oid for oid in order_book_ids if start_date <= de_listed_dates[oid]]
+
+    if fields is None:
+        fields = VALID_CONTRACT_PROPERTY_FIELDS[:]
+    else:
+        if not isinstance(fields, list):
+            fields = [fields]
+        check_items_in_container(fields, VALID_CONTRACT_PROPERTY_FIELDS, 'Contract Property')
+    # get data from server
+    data = get_client().execute('options.get_contract_property', order_book_ids, fields)
+    if not data:
+        return
+    df = pd.DataFrame(data)
+
+    index = _get_multi_index(order_book_ids, end_date, listed_dates, de_listed_dates)
+    df = df.set_index(['order_book_id', 'trading_date'])
+    df = df.reindex(index).groupby("order_book_id").ffill()
+    if start_date:
+        msk = df.index.get_level_values('trading_date') >= pd.Timestamp(str(start_date))
+        df = df[msk]
+    return df.sort_index()
+
+
+@export_as_api(namespace='options')
+def get_dominant_month(
+    underlying_symbol,
+    start_date=None,
+    end_date=None,
+    rule=0,
+    market='cn'
+):
+    """获取期权主力月份
+    :param underlying_symbol: str, 期权标的代码
+    :param start_date: 开始日期, 默认为期权合约最早上市日期的后一交易日
+    :param end_date: 结束日期；默认为今天
+    :param rule: int, 选取主力月份的规则，默认为 0，主力月份不会切换为已做过主力的月份，可选：0, 1: 只考虑主力月份的选取规则
+    :param market: 默认值为"cn", 可选：cn
+
+    :returns
+        返回 Series, Index 为日期, value 为主力月份
+    """
+    check_items_in_container(rule, [0, 1], 'rule')
+    underlying_symbol = ensure_string(underlying_symbol, "underlying_symbol").upper()
+    if start_date is not None:
+        start_date = ensure_date_int(start_date)
+    else:
+        contracts = get_contracts(underlying_symbol)
+        ins = instruments(contracts)
+        start_date = ensure_date_int(min([i.listed_date for i in ins]))
+    if end_date is not None:
+        end_date = ensure_date_int(end_date)
+    else:
+        end_date = ensure_date_int(datetime.date.today())
+    if end_date < start_date:
+        raise ValueError("invalid date range: [{!r}, {!r}]".format(start_date, end_date))
+
+    result = get_client().execute('options.get_dominant_month', underlying_symbol, start_date, end_date, rule, market=market)
+
+    if not result:
+        return
+    
+    df = pd.DataFrame(result)
+    df = df.set_index('date')
+    return df.sort_index()['dominant']
+
+
+@export_as_api(namespace='options')
+def get_commission(underlying_symbols, market='cn'):
+    """获取期权交易费用信息
+    :param underlying_symbol: str, 期权标的代码
+    :param market: 默认值为"cn", 可选：cn
+
+    :returns
+        返回 DataFrame, Index 为 underlying_symbol
+    """
+    underlying_symbol = ensure_list_of_string(underlying_symbols, "underlying_symbols")
+    result = get_client().execute('options.get_commission', underlying_symbol, market=market)
+
+    if not result:
+        return
+
+    return pd.DataFrame.from_records(result, index=["underlying_symbol"])
```

## rqdatac/services/shenwan.py

 * *Ordering differences only*

```diff
@@ -1,285 +1,285 @@
-# -*- coding: utf-8 -*-
-import datetime
-import re
-
-import six
-import pandas as pd
-
-from rqdatac.client import get_client
-from rqdatac.validators import (
-    ensure_date_int,
-    ensure_date_or_today_int,
-    ensure_order_book_ids,
-    ensure_string,
-    ensure_string_in,
-    check_items_in_container
-)
-from rqdatac.decorators import export_as_api
-from rqdatac.utils import to_date_str
-from rqdatac.rqdatah_helper import rqdatah_serialize, http_conv_list_to_csv
-
-
-@export_as_api
-@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
-def shenwan_industry(index_name, date=None, market="cn"):
-    """获取申万行业组成
-
-    :param index_name: 申万行业代码或名字, 如'801010.INDX'或'农林牧渔'
-    :param date: 如 '2015-01-07' (Default value = None)
-    :param market:  (Default value = "cn")
-    :returns: 返回输入日期最近交易日的申万行业组成
-
-    """
-    if not isinstance(index_name, six.string_types):
-        raise ValueError("string expected, got {!r}".format(index_name))
-
-    if not date:
-        date = datetime.date.today()
-    date = ensure_date_int(date)
-    return get_client().execute("shenwan_industry", index_name, date, market=market)
-
-
-LEVEL_MAP = (
-    None,
-    ("index_code", "index_name"),
-    ("second_index_code", "second_index_name"),
-    ("third_index_code", "third_index_name"),
-)
-
-
-@export_as_api
-def shenwan_instrument_industry(order_book_ids, date=None, level=1, expect_df=True, market="cn"):
-    """获取股票对应的申万行业
-
-    :param order_book_ids: 股票列表，如['000001.XSHE', '000002.XSHE']
-    :param date: 如 '2015-01-07' (Default value = None)
-    :param level:  (Default value = 1)
-    :param expect_df: 返回 MultiIndex DataFrame (Default value = True)
-    :param market:  (Default value = "cn")
-    :returns: code, name
-        返回输入日期最近交易日的股票对应申万行业
-
-    """
-
-    if level not in [0, 1, 2, 3]:
-        raise ValueError("level should be in 0,1,2,3")
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-
-    if not date:
-        date = datetime.date.today()
-    date = ensure_date_int(date)
-
-    r = get_client().execute("shenwan_instrument_industry", order_book_ids, date, level, market=market)
-    if not r:
-        return
-
-    if len(order_book_ids) == 1 and not expect_df:
-        r = r[0]
-        if level != 0:
-            return r[LEVEL_MAP[level][0]], r[LEVEL_MAP[level][1]]
-        else:
-            return (
-                r["index_code"],
-                r["index_name"],
-                r["second_index_code"],
-                r["second_index_name"],
-                r["third_index_code"],
-                r["third_index_name"],
-            )
-
-    df = pd.DataFrame(r).set_index("order_book_id")
-    if level != 0 and level != 1:
-        df.rename(columns=dict(zip(LEVEL_MAP[level], LEVEL_MAP[1])), inplace=True)
-    return df
-
-
-@export_as_api
-@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
-def zx_industry(industry_name, date=None):
-    """获取中信行业股票列表
-
-    :param industry_name: 中信行业名称或代码
-    :param date: 查询日期，默认为当前最新日期
-    :return: 所属目标行业的order_book_id list or None
-    """
-    if not isinstance(industry_name, six.string_types):
-        raise ValueError("string expected, got {!r}".format(industry_name))
-    if not date:
-        date = datetime.date.today()
-    date = ensure_date_int(date)
-    return get_client().execute("zx_industry", industry_name, date)
-
-
-ZX_LEVEL_MAP = (
-    None,
-    "first_industry_name",
-    "second_industry_name",
-    "third_industry_name",
-)
-
-
-@export_as_api
-def zx_instrument_industry(order_book_ids, date=None, level=1, expect_df=True):
-    """获取股票对应的中信行业
-
-    :param order_book_ids: 股票列表，如['000001.XSHE', '000002.XSHE']
-    :param date: 如 '2015-01-07' (Default value = None)
-    :param level:  (Default value = 1)
-    :param expect_df: 返回 MultiIndex DataFrame (Default value = True)
-    :returns: code, name
-        返回输入日期最近交易日的股票对应中信行业
-
-    """
-
-    if level not in [0, 1, 2, 3]:
-        raise ValueError("level should be in 0,1,2,3")
-    order_book_ids = ensure_order_book_ids(order_book_ids)
-
-    if not date:
-        date = datetime.date.today()
-    date = ensure_date_int(date)
-
-    r = get_client().execute("zx_instrument_industry", order_book_ids, date, level)
-    if not r:
-        return
-    if len(order_book_ids) == 1 and not expect_df:
-        r = r[0]
-        if level != 0:
-            return [r[ZX_LEVEL_MAP[level]], ]
-        else:
-            return [
-                r["first_industry_name"],
-                r["second_industry_name"],
-                r["third_industry_name"],
-            ]
-
-    df = pd.DataFrame(r).set_index("order_book_id")
-    return df
-
-
-@export_as_api
-@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
-def get_industry(industry, source='citics_2019', date=None, market="cn"):
-    """获取行业股票列表
-
-    :param industry: 行业名称或代码
-    :param source: 分类来源。
-                中国市场: citics 以及 citics_2019: 中信, gildata: 聚源
-                港股: hsi: 恒生
-    :param date: 查询日期，默认为当前最新日期
-    :param market:  (Default value = "cn")
-    :return: 所属目标行业的order_book_id list or None
-    """
-
-    industry = ensure_string(industry, "industry")
-    source = ensure_string_in(source, ["sws", "citics", "gildata", "citics_2019", "hsi"], "source")
-    date = ensure_date_or_today_int(date)
-
-    res = get_client().execute("get_industry", industry, source, date, market=market)
-
-    if not res:
-        return res
-
-    if res[-1] == "have_sector_name":
-        # have_sector_name 代表 industry传入的是风格版块，产业板块或者上下游产业版块
-        from rqdatac.services import basic
-        res_list = basic.instruments(res[:-1])
-        res = []
-        date = to_date_str(date)
-        for order_book in res_list:
-            if order_book.de_listed_date == "0000-00-00" or order_book.de_listed_date is None:
-                order_book.de_listed_date = "2099-12-31"
-            if order_book.listed_date <= date <= order_book.de_listed_date:
-                res.append(order_book.order_book_id)
-    sub_pattern = re.compile('[A-Z]+')
-    res = [sub_pattern.sub('', oid[:-4]) + oid[-4:] for oid in res]
-    return sorted(res)
-
-
-@export_as_api
-def get_instrument_industry(order_book_ids, source='citics_2019', level=1, date=None, market="cn"):
-    """获取股票对应的行业
-
-    :param order_book_ids: 股票列表，如['000001.XSHE', '000002.XSHE']
-    :param source: 分类来源。
-                中国市场: citics 以及 citics_2019: 中信, gildata: 聚源
-                港股: hsi: 恒生
-    :param date: 如 '2015-01-07' (Default value = None)
-    :param level:  (Default value = 1)
-    :param market:  (Default value = "cn")
-    :returns: code, name
-        返回输入日期最近交易日的股票对应行业
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-    source = ensure_string_in(source, ["sws", "citics", "gildata", "citics_2019", "hsi", "sws_2014"], "source")
-    if source == "citics_2019":
-        check_items_in_container(level, [0, 1, 2, 3, "citics_sector"], 'level')
-    else:
-        check_items_in_container(level, [0, 1, 2, 3], 'level')
-    date = ensure_date_or_today_int(date)
-
-    r = get_client().execute("get_instrument_industry", order_book_ids, source, level, date, market=market)
-
-    if not r:
-        return
-    res = [i['order_book_id'] for i in r]
-    if source == "citics_2019" and level == "citics_sector":
-        # is_special industry是否传入的是风格版块，产业板块和上下游产业版块
-        from rqdatac.services import basic
-        res_list = basic.instruments(res)
-        date = to_date_str(date)
-        for index, order_book in enumerate(res_list):
-            if order_book.de_listed_date == "0000-00-00" or order_book.de_listed_date is None:
-                order_book.de_listed_date = "2099-12-31"
-            if not order_book.listed_date <= date <= order_book.de_listed_date:
-                r.pop(index)
-
-    return pd.DataFrame(r).set_index("order_book_id")
-
-
-SHENWAN_COLUMNS = [
-    "index_code",
-    "index_name",
-    "second_index_code",
-    "second_index_name",
-    "third_index_code",
-    "third_index_name"
-]
-OTHER_COLUMNS = [
-    "first_industry_code",
-    "first_industry_name",
-    "second_industry_code",
-    "second_industry_name",
-    "third_industry_code",
-    "third_industry_name"
-]
-
-
-@export_as_api
-def get_industry_mapping(source="citics_2019", date=None, market="cn"):
-    """获取行业分类列表
-
-    :param source: 分类来源。
-                中国市场: citics 以及 citics_2019: 中信, gildata: 聚源
-                港股: hsi: 恒生
-    :param market:  (Default value = "cn")
-    :return: DataFrame
-    """
-    source = ensure_string_in(source, ["sws", "sws_2014", "sws_2021", "citics", "gildata", "citics_2019", "hsi"], "source")
-    if date is None:
-        date = datetime.date.today()
-    date = ensure_date_int(date)
-    res = get_client().execute("get_industry_mapping_v2", source, date, market=market)
-    if not res:
-        return
-    df = pd.DataFrame(res)
-
-    if source.startswith("sws"):
-        df.rename(columns=dict(zip(OTHER_COLUMNS, SHENWAN_COLUMNS)), inplace=True)
-        columns = SHENWAN_COLUMNS
-    else:
-        columns = OTHER_COLUMNS
-
-    df = df.dropna().drop_duplicates()
-    df = df.sort_values(columns[::2]).reset_index(drop=True)
+# -*- coding: utf-8 -*-
+import datetime
+import re
+
+import six
+import pandas as pd
+
+from rqdatac.client import get_client
+from rqdatac.validators import (
+    ensure_date_int,
+    ensure_date_or_today_int,
+    ensure_order_book_ids,
+    ensure_string,
+    ensure_string_in,
+    check_items_in_container
+)
+from rqdatac.decorators import export_as_api
+from rqdatac.utils import to_date_str
+from rqdatac.rqdatah_helper import rqdatah_serialize, http_conv_list_to_csv
+
+
+@export_as_api
+@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
+def shenwan_industry(index_name, date=None, market="cn"):
+    """获取申万行业组成
+
+    :param index_name: 申万行业代码或名字, 如'801010.INDX'或'农林牧渔'
+    :param date: 如 '2015-01-07' (Default value = None)
+    :param market:  (Default value = "cn")
+    :returns: 返回输入日期最近交易日的申万行业组成
+
+    """
+    if not isinstance(index_name, six.string_types):
+        raise ValueError("string expected, got {!r}".format(index_name))
+
+    if not date:
+        date = datetime.date.today()
+    date = ensure_date_int(date)
+    return get_client().execute("shenwan_industry", index_name, date, market=market)
+
+
+LEVEL_MAP = (
+    None,
+    ("index_code", "index_name"),
+    ("second_index_code", "second_index_name"),
+    ("third_index_code", "third_index_name"),
+)
+
+
+@export_as_api
+def shenwan_instrument_industry(order_book_ids, date=None, level=1, expect_df=True, market="cn"):
+    """获取股票对应的申万行业
+
+    :param order_book_ids: 股票列表，如['000001.XSHE', '000002.XSHE']
+    :param date: 如 '2015-01-07' (Default value = None)
+    :param level:  (Default value = 1)
+    :param expect_df: 返回 MultiIndex DataFrame (Default value = True)
+    :param market:  (Default value = "cn")
+    :returns: code, name
+        返回输入日期最近交易日的股票对应申万行业
+
+    """
+
+    if level not in [0, 1, 2, 3]:
+        raise ValueError("level should be in 0,1,2,3")
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+
+    if not date:
+        date = datetime.date.today()
+    date = ensure_date_int(date)
+
+    r = get_client().execute("shenwan_instrument_industry", order_book_ids, date, level, market=market)
+    if not r:
+        return
+
+    if len(order_book_ids) == 1 and not expect_df:
+        r = r[0]
+        if level != 0:
+            return r[LEVEL_MAP[level][0]], r[LEVEL_MAP[level][1]]
+        else:
+            return (
+                r["index_code"],
+                r["index_name"],
+                r["second_index_code"],
+                r["second_index_name"],
+                r["third_index_code"],
+                r["third_index_name"],
+            )
+
+    df = pd.DataFrame(r).set_index("order_book_id")
+    if level != 0 and level != 1:
+        df.rename(columns=dict(zip(LEVEL_MAP[level], LEVEL_MAP[1])), inplace=True)
+    return df
+
+
+@export_as_api
+@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
+def zx_industry(industry_name, date=None):
+    """获取中信行业股票列表
+
+    :param industry_name: 中信行业名称或代码
+    :param date: 查询日期，默认为当前最新日期
+    :return: 所属目标行业的order_book_id list or None
+    """
+    if not isinstance(industry_name, six.string_types):
+        raise ValueError("string expected, got {!r}".format(industry_name))
+    if not date:
+        date = datetime.date.today()
+    date = ensure_date_int(date)
+    return get_client().execute("zx_industry", industry_name, date)
+
+
+ZX_LEVEL_MAP = (
+    None,
+    "first_industry_name",
+    "second_industry_name",
+    "third_industry_name",
+)
+
+
+@export_as_api
+def zx_instrument_industry(order_book_ids, date=None, level=1, expect_df=True):
+    """获取股票对应的中信行业
+
+    :param order_book_ids: 股票列表，如['000001.XSHE', '000002.XSHE']
+    :param date: 如 '2015-01-07' (Default value = None)
+    :param level:  (Default value = 1)
+    :param expect_df: 返回 MultiIndex DataFrame (Default value = True)
+    :returns: code, name
+        返回输入日期最近交易日的股票对应中信行业
+
+    """
+
+    if level not in [0, 1, 2, 3]:
+        raise ValueError("level should be in 0,1,2,3")
+    order_book_ids = ensure_order_book_ids(order_book_ids)
+
+    if not date:
+        date = datetime.date.today()
+    date = ensure_date_int(date)
+
+    r = get_client().execute("zx_instrument_industry", order_book_ids, date, level)
+    if not r:
+        return
+    if len(order_book_ids) == 1 and not expect_df:
+        r = r[0]
+        if level != 0:
+            return [r[ZX_LEVEL_MAP[level]], ]
+        else:
+            return [
+                r["first_industry_name"],
+                r["second_industry_name"],
+                r["third_industry_name"],
+            ]
+
+    df = pd.DataFrame(r).set_index("order_book_id")
+    return df
+
+
+@export_as_api
+@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
+def get_industry(industry, source='citics_2019', date=None, market="cn"):
+    """获取行业股票列表
+
+    :param industry: 行业名称或代码
+    :param source: 分类来源。
+                中国市场: citics 以及 citics_2019: 中信, gildata: 聚源
+                港股: hsi: 恒生
+    :param date: 查询日期，默认为当前最新日期
+    :param market:  (Default value = "cn")
+    :return: 所属目标行业的order_book_id list or None
+    """
+
+    industry = ensure_string(industry, "industry")
+    source = ensure_string_in(source, ["sws", "citics", "gildata", "citics_2019", "hsi"], "source")
+    date = ensure_date_or_today_int(date)
+
+    res = get_client().execute("get_industry", industry, source, date, market=market)
+
+    if not res:
+        return res
+
+    if res[-1] == "have_sector_name":
+        # have_sector_name 代表 industry传入的是风格版块，产业板块或者上下游产业版块
+        from rqdatac.services import basic
+        res_list = basic.instruments(res[:-1])
+        res = []
+        date = to_date_str(date)
+        for order_book in res_list:
+            if order_book.de_listed_date == "0000-00-00" or order_book.de_listed_date is None:
+                order_book.de_listed_date = "2099-12-31"
+            if order_book.listed_date <= date <= order_book.de_listed_date:
+                res.append(order_book.order_book_id)
+    sub_pattern = re.compile('[A-Z]+')
+    res = [sub_pattern.sub('', oid[:-4]) + oid[-4:] for oid in res]
+    return sorted(res)
+
+
+@export_as_api
+def get_instrument_industry(order_book_ids, source='citics_2019', level=1, date=None, market="cn"):
+    """获取股票对应的行业
+
+    :param order_book_ids: 股票列表，如['000001.XSHE', '000002.XSHE']
+    :param source: 分类来源。
+                中国市场: citics 以及 citics_2019: 中信, gildata: 聚源
+                港股: hsi: 恒生
+    :param date: 如 '2015-01-07' (Default value = None)
+    :param level:  (Default value = 1)
+    :param market:  (Default value = "cn")
+    :returns: code, name
+        返回输入日期最近交易日的股票对应行业
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+    source = ensure_string_in(source, ["sws", "citics", "gildata", "citics_2019", "hsi", "sws_2014"], "source")
+    if source == "citics_2019":
+        check_items_in_container(level, [0, 1, 2, 3, "citics_sector"], 'level')
+    else:
+        check_items_in_container(level, [0, 1, 2, 3], 'level')
+    date = ensure_date_or_today_int(date)
+
+    r = get_client().execute("get_instrument_industry", order_book_ids, source, level, date, market=market)
+
+    if not r:
+        return
+    res = [i['order_book_id'] for i in r]
+    if source == "citics_2019" and level == "citics_sector":
+        # is_special industry是否传入的是风格版块，产业板块和上下游产业版块
+        from rqdatac.services import basic
+        res_list = basic.instruments(res)
+        date = to_date_str(date)
+        for index, order_book in enumerate(res_list):
+            if order_book.de_listed_date == "0000-00-00" or order_book.de_listed_date is None:
+                order_book.de_listed_date = "2099-12-31"
+            if not order_book.listed_date <= date <= order_book.de_listed_date:
+                r.pop(index)
+
+    return pd.DataFrame(r).set_index("order_book_id")
+
+
+SHENWAN_COLUMNS = [
+    "index_code",
+    "index_name",
+    "second_index_code",
+    "second_index_name",
+    "third_index_code",
+    "third_index_name"
+]
+OTHER_COLUMNS = [
+    "first_industry_code",
+    "first_industry_name",
+    "second_industry_code",
+    "second_industry_name",
+    "third_industry_code",
+    "third_industry_name"
+]
+
+
+@export_as_api
+def get_industry_mapping(source="citics_2019", date=None, market="cn"):
+    """获取行业分类列表
+
+    :param source: 分类来源。
+                中国市场: citics 以及 citics_2019: 中信, gildata: 聚源
+                港股: hsi: 恒生
+    :param market:  (Default value = "cn")
+    :return: DataFrame
+    """
+    source = ensure_string_in(source, ["sws", "sws_2014", "sws_2021", "citics", "gildata", "citics_2019", "hsi"], "source")
+    if date is None:
+        date = datetime.date.today()
+    date = ensure_date_int(date)
+    res = get_client().execute("get_industry_mapping_v2", source, date, market=market)
+    if not res:
+        return
+    df = pd.DataFrame(res)
+
+    if source.startswith("sws"):
+        df.rename(columns=dict(zip(OTHER_COLUMNS, SHENWAN_COLUMNS)), inplace=True)
+        columns = SHENWAN_COLUMNS
+    else:
+        columns = OTHER_COLUMNS
+
+    df = df.dropna().drop_duplicates()
+    df = df.sort_values(columns[::2]).reset_index(drop=True)
     return df[columns]
```

## rqdatac/services/stock_status.py

 * *Ordering differences only*

```diff
@@ -1,743 +1,743 @@
-# -*- coding: utf-8 -*-
-import datetime
-import warnings
-import math
-
-import pandas as pd
-from dateutil.relativedelta import relativedelta
-
-from rqdatac.utils import to_datetime, is_panel_removed, to_date
-from rqdatac.validators import (
-    ensure_date_range,
-    ensure_date_or_today_int,
-    ensure_list_of_string,
-    check_items_in_container,
-    ensure_order,
-    ensure_order_book_id,
-    ensure_order_book_ids,
-    ensure_dates_base_on_listed_date,
-    ensure_string,
-    ensure_date_int,
-    raise_for_no_panel,
-    check_quarter,
-    quarter_string_to_date,
-)
-from rqdatac.services.basic import instruments
-from rqdatac.services.calendar import (
-    get_trading_dates,
-    get_previous_trading_date,
-    get_trading_dates_in_type,
-)
-from rqdatac.client import get_client
-from rqdatac.decorators import export_as_api, compatible_with_parm
-from rqdatac.rqdatah_helper import rqdatah_serialize, http_conv_list_to_csv
-
-
-@export_as_api
-def current_stock_connect_quota(
-        connect=None, fields=None
-):
-    """
-    获取沪港通、深港通资金流向数据
-
-    :param connect: 字符串，目前可从sh_to_hk, hk_to_sh, sz_to_hk, hk_to_sz多选, 默认为查询所有资金流向数据
-    :param fields:  字符串列表，需要的字段，目前可从buy_turnover, sell_turnover, quota_balance, quota_balance_ratio多选, 默认取所有
-
-    """
-    DEFAULT_CONNECT = ["sh_to_hk", "hk_to_sh", "sz_to_hk", "hk_to_sz"]
-    if connect is None:
-        connect = DEFAULT_CONNECT
-    else:
-        connect = ensure_list_of_string(connect)
-        check_items_in_container(connect, DEFAULT_CONNECT, 'connect')
-
-    DEFAULT_FIELDS = ['buy_turnover', 'sell_turnover', 'quota_balance', 'quota_balance_ratio']
-    if fields is None:
-        fields = DEFAULT_FIELDS
-    else:
-        fields = ensure_list_of_string(fields)
-        check_items_in_container(fields, DEFAULT_FIELDS, 'fields')
-
-    data = get_client().execute("current_stock_connect_quota", connect=connect)
-    res = pd.DataFrame(data)
-    if res.empty:
-        return None
-    res["datetime"] = pd.to_datetime(res["datetime"], format='%Y%m%d%H%M')
-    res.set_index(['datetime', 'connect'], inplace=True)
-    res = res[fields]
-    return res
-
-
-@export_as_api
-def get_stock_connect_quota(connect=None, start_date=None, end_date=None, fields=None):
-    """获取历史沪深港通额度日频数据
-
-    :param connect: 默认返回全部content ["sh_to_hk", "hk_to_sh", "sz_to_hk", "hk_to_sz"]
-    :param start_date: 默认为全部历史数据
-    :param end_date: 默认为最新日期
-    :param fields:  默认为所有字段 ['buy_turnover', 'sell_turnover', 'quota_balance', 'quota_balance_ratio']
-    :return:
-    """
-    DEFAULT_CONNECT = ["sh_to_hk", "hk_to_sh", "sz_to_hk", "hk_to_sz"]
-    if connect is None:
-        connect = DEFAULT_CONNECT
-    else:
-        connect = ensure_list_of_string(connect)
-        check_items_in_container(connect, DEFAULT_CONNECT, 'connect')
-
-    DEFAULT_FIELDS = ['buy_turnover', 'sell_turnover', 'quota_balance', 'quota_balance_ratio']
-    if fields is None:
-        fields = DEFAULT_FIELDS
-    else:
-        fields = ensure_list_of_string(fields)
-        check_items_in_container(fields, DEFAULT_FIELDS, 'fields')
-
-    start_date = ensure_date_int(start_date) if start_date else start_date
-    end_date = ensure_date_int(end_date) if end_date else end_date
-
-    if start_date and end_date and start_date > end_date:
-        raise ValueError("invalid date range: [{!r}, {!r}]".format(start_date, end_date))
-
-    data = get_client().execute(
-        "get_stock_connect_quota", connect=connect, start_date=start_date, end_date=end_date, fields=fields
-    )
-    if not data:
-        return None
-    res = pd.DataFrame(data)
-    res.set_index(['datetime', 'connect'], inplace=True)
-    res.sort_index(ascending=True, inplace=True)
-    return res
-
-
-@export_as_api
-def is_st_stock(order_book_ids, start_date=None, end_date=None, market="cn"):
-    """判断股票在给定的时间段是否是ST股, 返回值为一个DataFrame
-
-    :param order_book_ids: 股票 id
-    :param start_date:  (Default value = None)
-    :param end_date:  (Default value = None)
-    :param market:  (Default value = "cn")
-
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, type="CS", market=market)
-
-    if len(order_book_ids) == 1:
-        instrument = instruments(order_book_ids[0], market=market)
-        start_date, end_date = ensure_dates_base_on_listed_date(instrument, start_date, end_date, market)
-        if start_date is None:
-            return
-
-    start_date, end_date = ensure_date_range(start_date, end_date)
-
-    trading_dates = pd.to_datetime(get_trading_dates(start_date, end_date, market=market))
-    data = get_client().execute(
-        "get_st_days", order_book_ids, start_date=start_date, end_date=end_date
-    )
-    df = pd.DataFrame(data=False, columns=order_book_ids, index=trading_dates)
-    for idx, dates in data.items():
-        for date in dates:
-            date = to_datetime(date)
-            df.at[date, idx] = True
-    return df
-
-
-@export_as_api
-def _is_st_stock(order_book_id, date=None, market="cn"):
-    """判断股票在给定日期是否是ST股
-    :param order_book_id: 股票id
-    :param date:  (Default value = None)
-    :param market:  (Default value = "cn")
-    :returns: True or False
-    """
-    order_book_id = ensure_order_book_id(order_book_id, type="CS", market=market)
-    date = ensure_date_or_today_int(date)
-    df = is_st_stock(order_book_id, start_date=date, end_date=date, market=market)
-    if df is None or df.empty:
-        return False
-    else:
-        return df[order_book_id][0]
-
-
-@export_as_api
-@compatible_with_parm(name="country", value="cn", replace="market")
-def is_suspended(order_book_ids, start_date=None, end_date=None, market="cn"):
-    """获取股票停牌信息
-
-    :param order_book_ids: 股票名称
-    :param start_date: 开始日期, 如'2013-01-04' (Default value = None)
-    :param end_date: 结束日期，如'2014-01-04' (Default value = None)
-    :param market: 地区代码, 如 'cn' (Default value = "cn")
-    :returns: DataFrame
-
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, type="CS", market=market)
-
-    if len(order_book_ids) == 1:
-        instrument = instruments(order_book_ids[0], market=market)
-        start_date, end_date = ensure_dates_base_on_listed_date(instrument, start_date, end_date, market)
-        if start_date is None:
-            return
-    if end_date is None:
-        end_date = datetime.date.today()
-    start_date, end_date = ensure_date_range(start_date, end_date)
-
-    trading_dates = pd.to_datetime(get_trading_dates(start_date, end_date, market=market))
-    df = pd.DataFrame(data=False, columns=order_book_ids, index=trading_dates)
-    data = get_client().execute("get_suspended_days", order_book_ids, start_date, end_date, market=market)
-    for idx, dates in data.items():
-        for date in dates:
-            date = to_datetime(int(date))
-            df.at[date, idx] = True
-    df.sort_index(inplace=True)
-    return df
-
-
-stock_fields = {"shares_holding": "shares_holding", "holding_ratio": "holding_ratio"}
-special_symbols = ["all_connect", "shanghai_connect", "shenzhen_connect"]
-symbols_map = {"shanghai_connect": "SH", "shenzhen_connect": "SZ"}
-
-
-@export_as_api
-def get_stock_connect(order_book_ids, start_date=None, end_date=None, fields=None, expect_df=True):
-    """获取"陆股通"的持股、持股比例
-
-    :param order_book_ids: 股票列表
-    :param start_date: 开始日期: 如'2017-03-17' (Default value = None)
-    :param end_date: 结束日期: 如'2018-03-16' (Default value = None)
-    :param fields: 默认为所有字段，可输入shares_holding, holding_ratio, adjusted_holding_ratio (Default value = None)
-    :param expect_df: 是否返回 MultiIndex DataFrame (Default value = True)
-    :returns: 返回pandas.DataFrame or pandas.Panel
-
-    """
-    if order_book_ids not in ("shanghai_connect", "shenzhen_connect", "all_connect"):
-        order_book_ids = ensure_order_book_ids(order_book_ids, type="CS")
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    if fields is not None:
-        fields = ensure_list_of_string(fields)
-        for f in fields:
-            if f not in ("shares_holding", "holding_ratio", "adjusted_holding_ratio"):
-                raise ValueError("invalid field: {}".format(f))
-    else:
-        fields = ["shares_holding", "holding_ratio", "adjusted_holding_ratio"]
-    data = get_client().execute("get_stock_connect", order_book_ids, start_date, end_date, fields)
-    if not data:
-        return None
-    df = pd.DataFrame(data, columns=["trading_date", "order_book_id"] + fields)
-
-    if not expect_df and not is_panel_removed:
-        df = df.set_index(["trading_date", "order_book_id"])
-        df = df.to_panel()
-        df.major_axis.name = None
-        df.minor_axis.name = None
-        if len(order_book_ids) == 1:
-            df = df.minor_xs(order_book_ids[0])
-        if len(fields) == 1:
-            df = df[fields[0]]
-        if len(order_book_ids) != 1 and len(fields) != 1:
-            warnings.warn("Panel is removed after pandas version 0.25.0."
-                          " the default value of 'expect_df' will change to True in the future.")
-        return df
-    else:
-        df.sort_values(["order_book_id", "trading_date"], inplace=True)
-        df.set_index(["order_book_id", "trading_date"], inplace=True)
-        if expect_df:
-            return df
-
-        if len(order_book_ids) != 1 and len(fields) != 1:
-            raise_for_no_panel()
-
-        if len(order_book_ids) == 1:
-            df.reset_index(level=0, drop=True, inplace=True)
-            if len(fields) == 1:
-                df = df[fields[0]]
-            return df
-        else:
-            df = df.unstack(0)[fields[0]]
-            df.index.name = None
-            df.columns.name = None
-            return df
-
-
-MARGIN_FIELDS = (
-    "margin_balance",
-    "buy_on_margin_value",
-    "short_sell_quantity",
-    "margin_repayment",
-    "short_balance_quantity",
-    "short_repayment_quantity",
-    "short_balance",
-    "total_balance",
-)
-
-MARGIN_SUMMARY_MAP = {"SH": "XSHG", "XSHG": "XSHG", "SZ": "XSHE", "XSHE": "XSHE"}
-
-
-@export_as_api
-def get_securities_margin(
-        order_book_ids, start_date=None, end_date=None, fields=None, expect_df=True, market="cn"
-):
-    """获取股票融资融券数据
-
-    :param order_book_ids: 股票代码或代码列表
-    :param start_date: 开始时间，支持 str, date, datetime, pandasTimestamp
-        默认为 end_date 之前一个月 (Default value = None)
-    :param end_date: 结束时间 默认为当前日期前一天 (Default value = None)
-    :param fields: str 或 list 类型. 默认为 None, 返回所有字段。可选字段包括：
-                   margin_balance, buy_on_margin_value, margin_repayment, short_balance, short_balance_quantity,
-                   short_sell_quantity, short_repayment_quantity, total_balance
-                   (Default value = None)
-    :param expect_df: 返回 MultiIndex DataFrame (Default value = True)
-    :param market: 地区代码, 如: 'cn' (Default value = "cn")
-    :returns: 如果传入多个股票代码，且 fields 为多个或者 None，返回 pandas.Panel
-        如果传入一只股票或者 fields 为单个字段，则返回 pandas.DataFrame
-        如果传入的股票代码和字段数都是1，则返回 pandas.Series
-
-    """
-
-    order_book_ids = ensure_list_of_string(order_book_ids, "order_book_ids")
-    all_list = []
-    for order_book_id in order_book_ids:
-        if order_book_id.upper() in MARGIN_SUMMARY_MAP:
-            all_list.append(MARGIN_SUMMARY_MAP[order_book_id.upper()])
-        else:
-            inst = instruments(order_book_id, market)
-
-            if inst is not None and inst.type in ["CS", "ETF", "LOF"]:
-                all_list.append(inst.order_book_id)
-            else:
-                warnings.warn("{} is not stock, ETF, or LOF.".format(order_book_id))
-    order_book_ids = all_list
-    if not order_book_ids:
-        raise ValueError("no valid securities in {}".format(order_book_ids))
-    if fields is None:
-        fields = list(MARGIN_FIELDS)
-    else:
-        fields = ensure_list_of_string(fields, "fields")
-        check_items_in_container(fields, MARGIN_FIELDS, "fields")
-        fields = ensure_order(fields, MARGIN_FIELDS)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    if end_date > ensure_date_or_today_int(None):
-        end_date = ensure_date_or_today_int(get_previous_trading_date(datetime.date.today()))
-    trading_dates = pd.to_datetime(get_trading_dates(start_date, end_date, market=market))
-
-    data = get_client().execute(
-        "get_securities_margin", order_book_ids, start_date, end_date, market=market
-    )
-    if not data:
-        return
-
-    if not expect_df and not is_panel_removed:
-
-        pl = pd.Panel(items=fields, major_axis=trading_dates, minor_axis=order_book_ids)
-        for r in data:
-            for field in fields:
-                value = r.get(field)
-                pl.at[field, r["date"], r["order_book_id"]] = value
-
-        if len(order_book_ids) == 1:
-            pl = pl.minor_xs(order_book_ids[0])
-        if len(fields) == 1:
-            pl = pl[fields[0]]
-        if len(order_book_ids) != 1 and len(fields) != 1:
-            warnings.warn("Panel is removed after pandas version 0.25.0."
-                          " the default value of 'expect_df' will change to True in the future.")
-        return pl
-    else:
-        df = pd.DataFrame(data)
-        df.sort_values(["order_book_id", "date"], inplace=True)
-        df.set_index(["order_book_id", "date"], inplace=True)
-        df = df.reindex(columns=fields)
-        if expect_df:
-            return df
-
-        if len(order_book_ids) != 1 and len(fields) != 1:
-            raise_for_no_panel()
-
-        if len(order_book_ids) == 1:
-            df.reset_index(level=0, drop=True, inplace=True)
-            if len(fields) == 1:
-                df = df[fields[0]]
-            return df
-        else:
-            df = df.unstack(0)[fields[0]]
-            df.index.name = None
-            df.columns.name = None
-            return df
-
-
-MARGIN_TYPE = ("stock", "cash")
-EXCHANGE_TYPE = {"SZ": "XSHE", "sz": "XSHE", "xshe": "XSHE", "SH": "XSHG", "sh": "XSHG", "xshg": "XSHG"}
-EXCHANGE_CONTENT = ["XSHE", "XSHG"]
-
-
-@export_as_api
-@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
-def get_margin_stocks(date=None, exchange=None, margin_type='stock', market="cn"):
-    """获取融资融券信息
-
-    :param date: 查询日期，默认返回今天上一交易日，支持 str, timestamp, datetime 类型
-    :param exchange: 交易所信息，默认不填写则返回全部。
-                    str类型，默认为 None，返回所有字段。可选字段包括：
-                    'XSHE', 'sz' 代表深交所；'XSHG', 'sh' 代表上交所，不区分大小写
-                    (Default value = None)
-    :param margin_type: 'stock' 代表融券卖出，'cash'，代表融资买入，默认为'stock'
-
-    """
-    if date:
-        date = ensure_date_int(date)
-    else:
-        date = get_previous_trading_date(datetime.date.today())
-        date = date.year * 10000 + date.month * 100 + date.day
-
-    if exchange is None:
-        exchange = EXCHANGE_CONTENT
-    else:
-        exchange = ensure_string(exchange, "exchange")
-        if exchange in EXCHANGE_TYPE:
-            exchange = EXCHANGE_TYPE[exchange]
-        check_items_in_container(exchange, EXCHANGE_CONTENT, "exchange")
-        exchange = [exchange]
-
-    margin_type = ensure_string(margin_type, "margin_type")
-    check_items_in_container(margin_type, MARGIN_TYPE, "margin_type")
-
-    data = get_client().execute(
-        "get_margin_stocks", date, exchange, margin_type, market=market
-    )
-
-    if not data:
-        return []
-    else:
-        return sorted(data)
-
-
-share_fields = {
-    "total": "total_shares",
-    "circulation_a": "a_cir_shares",
-    "non_circulation_a": "a_non_cir_shares",
-    "total_a": "a_total_shares",
-    'preferred_shares': 'preferred_shares',
-    "free_circulation": "free_circulation"
-}
-
-reversed_fields = {v: k for k, v in share_fields.items()}
-
-
-@export_as_api
-@compatible_with_parm(name="country", value="cn", replace="market")
-def get_shares(order_book_ids, start_date=None, end_date=None, fields=None, expect_df=True, market="cn"):
-    """获取流通股本信息
-
-    :param order_book_ids: 股票名称
-    :param start_date: 开始日期, 如'2013-01-04' (Default value = None)
-    :param end_date: 结束日期，如'2014-01-04' (Default value = None)
-    :param fields: 如'total', 'circulation_a' (Default value = None)
-    :param expect_df: 返回 MultiIndex DataFrame (Default value = True)
-    :param market: 地区代码，如'cn' (Default value = "cn")
-    :returns: 返回一个DataFrame
-
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    if fields:
-        fields = ensure_list_of_string(fields, "fields")
-        if 'management_circulation' in fields:
-            fields.remove('management_circulation')
-            if fields:
-                warnings.warn("management_circulation is removed")
-            else:
-                raise ValueError("management_circulation is removed")
-        check_items_in_container(fields, set(share_fields), "fields")
-        fields = [share_fields[i] for i in fields]
-    else:
-        fields = list(share_fields.values())
-
-    all_shares = get_client().execute("get_shares_v2", order_book_ids, fields, start_date=start_date, end_date=end_date, market=market)
-    if not all_shares:
-        return
-    dates = get_trading_dates_in_type(start_date, end_date, expect_type="datetime", market=market)
-    df = pd.DataFrame(all_shares)
-    unique = set(df.order_book_id)
-    missing = [obid for obid in order_book_ids if obid not in unique]
-    if missing:
-        missing_df = pd.DataFrame({"order_book_id": missing, "date": df.date.iloc[-1]})
-        df = pd.concat([df, missing_df])
-    if 'preferred_shares' in df.columns:
-        df['preferred_shares'] = df['preferred_shares'].fillna(0)
-    df.set_index(["date", "order_book_id"], inplace=True)
-    df.sort_index(inplace=True)
-    df = df.unstack(level=1)
-    index = df.index.union(dates)
-    df = df.reindex(index)
-    df = df.fillna(method="ffill")
-    df = df.loc[list(dates)]
-    df = df.dropna(how="all")
-    df = df[fields]
-    if not is_panel_removed and not expect_df:
-        pl = df.stack(1).to_panel()
-        pl.items = [reversed_fields[i] for i in pl.items]
-        if len(order_book_ids) == 1:
-            pl = pl.minor_xs(order_book_ids[0])
-        if len(fields) == 1:
-            pl = pl[reversed_fields[fields[0]]]
-        if len(order_book_ids) != 1 and len(fields) != 1:
-            warnings.warn("Panel is removed after pandas version 0.25.0."
-                          " the default value of 'expect_df' will change to True in the future.")
-        return pl
-    else:
-        df = df.stack(1)
-        df.index.set_names(["date", "order_book_id"], inplace=True)
-        de_listed_map = {i: instruments(i).de_listed_date for i in order_book_ids}
-        max_end_date = df.index.levels[0].max() + pd.Timedelta(days=1)
-        de_listed_map = {k: (pd.to_datetime(v) if v != '0000-00-00' else max_end_date) for k, v in de_listed_map.items()}
-        i0 = df.index.get_level_values(0)
-        i1 = df.index.get_level_values(1).map(de_listed_map)
-        mask = i1 > i0
-        df = df[mask]
-        if df.empty:
-            return None
-        df = df.reorder_levels(["order_book_id", "date"]).sort_index()
-        df = df.rename(columns=reversed_fields)
-        if expect_df:
-            return df
-
-        if len(order_book_ids) != 1 and len(fields) != 1:
-            raise_for_no_panel()
-
-        if len(order_book_ids) == 1:
-            df.reset_index(level=0, drop=True, inplace=True)
-            if len(fields) == 1:
-                df = df[reversed_fields[fields[0]]]
-            return df
-        else:
-            df = df.unstack(0)[reversed_fields[fields[0]]]
-            df.index.name = None
-            df.columns.name = None
-            return df
-
-
-allotment_fields = [
-    "proportion",
-    "allotted_proportion",
-    "allotted_shares",
-    "allotment_price",
-    "book_closure_date",
-    "ex_right_date", ]
-
-
-@export_as_api
-@compatible_with_parm(name="country", value="cn", replace="market")
-def get_allotment(order_book_ids, start_date=None, end_date=None, fields=None, market="cn"):
-    """获取配股信息
-    :param order_book_ids: 股票名称
-    :param start_date: 开始日期, 如'1991-01-01' (Default value = 1991-01-01)
-    :param end_date: 结束日期，如'2014-01-04' (Default value = None)
-    :param market: 地区代码，如'cn' (Default value = "cn")
-    :returns: 返回一个DataFrame
-    'order_book_id': 股票合约代码
-    'declaration_announcement_date': 首次信息发布日期
-    'proportion': 配股比例(每一股对应的配股比例)
-    'allotted_proportion': 实际配股比例(每一股对应的配股比例)
-    'allotted_shares': 实际配股数量
-    'allotment_price': 每股配股价格
-    'book_closure_date': 股权登记日
-    'ex_right_date': 除权除息日
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-
-    if start_date:
-        start_date = ensure_date_int(start_date)
-    if end_date:
-        end_date = ensure_date_int(end_date)
-
-    if fields:
-        fields = ensure_list_of_string(fields, "fields")
-        check_items_in_container(fields, allotment_fields, "fields")
-    else:
-        fields = allotment_fields
-
-    all_allotment = get_client().execute("get_allotment", order_book_ids, fields, start_date, end_date, market=market)
-    if not all_allotment:
-        return
-    df = pd.DataFrame(all_allotment)
-    df.set_index(["order_book_id", "declaration_announcement_date"], inplace=True)
-    df.sort_index(inplace=True)
-    df = df[fields]
-    return df
-
-
-@export_as_api
-def get_symbol_change_info(order_book_ids, market="cn"):
-    """ 获取合约的历史简称信息
-
-    :param order_book_ids: 股票合约id
-    :param market: 默认 'cn'
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-    data = get_client().execute("get_symbol_change_info", order_book_ids, market)
-    if data:
-        df = pd.DataFrame(data)
-        df.set_index(['order_book_id', 'change_date'], inplace=True)
-        df.sort_index(inplace=True)
-        return df
-
-
-@export_as_api
-def get_special_treatment_info(order_book_ids, market="cn"):
-    """ 获取合约的特殊处理状态
-
-    :param order_book_ids: 股票合约id
-    :param market: 默认 'cn'
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-    data = get_client().execute("get_special_treatment_info", order_book_ids, market)
-    if data:
-        df = pd.DataFrame(data)
-        df.set_index(['order_book_id', 'change_date'], inplace=True)
-        df.sort_index(inplace=True)
-        return df
-
-
-@export_as_api
-def get_incentive_plan(order_book_ids, start_date=None, end_date=None, market="cn"):
-    """ 获取合约的股权激励信息
-
-    :param order_book_ids: 股票合约id
-    :param start_date: 开始时间
-    :param end_date: 结束时间
-    :param market: 默认 'cn'
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-    end_date = ensure_date_or_today_int(end_date)
-    if start_date:
-        start_date = ensure_date_int(start_date)
-        if start_date > end_date:
-            raise ValueError("invalid date range: [{!r}, {!r}]".format(start_date, end_date))
-    data = get_client().execute("get_incentive_plan", order_book_ids, start_date, end_date, market)
-    if data:
-        df = pd.DataFrame(data)
-        df.set_index(['order_book_id', 'info_date'], inplace=True)
-        df.sort_index(inplace=True)
-        return df
-
-
-@export_as_api
-def get_investor_ra(order_book_ids, start_date=None, end_date=None, market='cn'):
-    """
-    获取股票投资者关系活动信息
-
-    :param order_book_ids:  股票合约id
-    :param start_date: 开始日期
-    :param end_date: 结束日期
-    :param market: 'cn'
-    :return: pandas.MultiIndex DataFrame
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-    end_date = ensure_date_or_today_int(end_date)
-    if start_date:
-        start_date = ensure_date_int(start_date)
-        if start_date > end_date:
-            raise ValueError("invalid date range: [{!r}, {!r}]".format(start_date, end_date))
-    data = get_client().execute("get_investor_ra", order_book_ids, start_date, end_date, market)
-    if not data:
-        return None
-    df = pd.DataFrame(data)
-    df.rename(columns={'date': 'info_date'}, inplace=True)
-    df.set_index(['order_book_id', 'info_date'], inplace=True)
-    df = df.reindex(columns=['participant', 'institute', 'detail']).astype(str)
-    for col in df.columns:
-        df.loc[df[col] == 'nan', col] = None
-    return df
-
-
-@export_as_api
-def get_announcement(order_book_ids, start_date=None, end_date=None, market="cn"):
-    """
-    获取公司公告数据，包括标题及正文链接
-
-    :param order_book_ids: 股票合约id
-    :param start_date: 开始日期
-    :param end_date: 结束日期
-    :param market: 'cn'
-    :return: pandas.MultiIndex DataFrame
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-    start_date, end_date = ensure_date_range(start_date, end_date)
-    data = get_client().execute("get_announcement", order_book_ids, start_date, end_date, market)
-    if not data:
-        return None
-    df = pd.DataFrame(data)
-    df.set_index(["order_book_id", "info_date"], inplace=True)
-    df.sort_index(inplace=True)
-    return df
-
-
-@export_as_api
-def get_holder_number(order_book_ids, start_date=None, end_date=None, market="cn"):
-    """
-    获取股东人数
-
-    :param order_book_ids: 股票合约id
-    :param start_date: 开始日期
-    :param end_date: 结束日期
-    :param market: 'cn'
-    :return: pandas.MultiIndex DataFrame
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-    start_date, end_date = ensure_date_range(start_date, end_date, delta=relativedelta(years=1))
-    data = get_client().execute("get_holder_number", order_book_ids, start_date, end_date, market)
-    if not data:
-        return None
-    df = pd.DataFrame.from_records(data, index=["order_book_id", "info_date"])
-    df.sort_index(inplace=True)
-    return df
-
-
-_VALID_OPINION_TYPE = {
-    'unqualified', 'unqualified_with_explanation', 'qualified', 'disclaimer',
-    'adverse', 'unaudited', 'qualified_with_explanation', 'uncertainty_audit',
-    'material_uncertainty'
-}
-
-
-@export_as_api
-def get_audit_opinion(order_book_ids, start_quarter, end_quarter, date=None, type=None, opinion_types=None, market="cn"):
-    """
-    获取财务报告审计意见
-    :param: order_book_ids: str | list[str] 合约代码
-    :param: start_quarter:  str 财报回溯查询的起始报告期，例如'2015q2'代表 2015 年半年报
-    :param: end_quarter: str 财报回溯查询的截止报告期，例如'2015q4'代表 2015 年年报，该参数必填。
-    :param: date: 查询日期，默认查询日期为当前最新日期
-    :param: type: 需要返回的审计报告类型, 可选值包括 financial_statements, internal_control
-    :param: opinion_types: str | list[str] 需要返回的审计意见类型, 可选值包括
-        "unqualified", "unqualified_with_explanation", "qualified", "disclaimer",
-        "adverse", "unaudited", "qualified_with_explanation", "uncertainty_audit",
-        "material_uncertainty"
-    :param: market:str 	市场，默认'cn'为中国内地市场
-    """
-    if opinion_types is not None:
-        opinion_types = ensure_list_of_string(opinion_types, "opinion_type")
-        check_items_in_container(opinion_types, _VALID_OPINION_TYPE, "opinion_type")
-    if type is not None:
-        type = ensure_string(type, "type")
-        check_items_in_container(type, {"financial_statements", "internal_control"}, "type")
-    date = ensure_date_or_today_int(date)
-    order_book_ids = ensure_list_of_string(order_book_ids)
-
-    check_quarter(start_quarter, 'start_quarter')
-    start_quarter_int = ensure_date_int(quarter_string_to_date(start_quarter))
-
-    check_quarter(end_quarter, 'end_quarter')
-    end_quarter_int = ensure_date_int(quarter_string_to_date(end_quarter))
-    result_df = pd.DataFrame(
-        get_client().execute("get_audit_opinion", order_book_ids, start_quarter_int, end_quarter_int, date, type, opinion_types, market)
-    )
-    if result_df.empty:
-        return
-    result_df.sort_values(['order_book_id', 'end_date', 'info_date'])
-    result_df["end_date"] = result_df["end_date"].apply(
-        lambda d: "{}q{}".format(d.year, math.ceil(d.month / 3)))
-    result_df.rename(columns={"end_date": "quarter"}, inplace=True)
-    result_df.set_index(['order_book_id', 'quarter'], inplace=True)
-    result_df.sort_index(inplace=True)
-    return result_df
+# -*- coding: utf-8 -*-
+import datetime
+import warnings
+import math
+
+import pandas as pd
+from dateutil.relativedelta import relativedelta
+
+from rqdatac.utils import to_datetime, is_panel_removed, to_date
+from rqdatac.validators import (
+    ensure_date_range,
+    ensure_date_or_today_int,
+    ensure_list_of_string,
+    check_items_in_container,
+    ensure_order,
+    ensure_order_book_id,
+    ensure_order_book_ids,
+    ensure_dates_base_on_listed_date,
+    ensure_string,
+    ensure_date_int,
+    raise_for_no_panel,
+    check_quarter,
+    quarter_string_to_date,
+)
+from rqdatac.services.basic import instruments
+from rqdatac.services.calendar import (
+    get_trading_dates,
+    get_previous_trading_date,
+    get_trading_dates_in_type,
+)
+from rqdatac.client import get_client
+from rqdatac.decorators import export_as_api, compatible_with_parm
+from rqdatac.rqdatah_helper import rqdatah_serialize, http_conv_list_to_csv
+
+
+@export_as_api
+def current_stock_connect_quota(
+        connect=None, fields=None
+):
+    """
+    获取沪港通、深港通资金流向数据
+
+    :param connect: 字符串，目前可从sh_to_hk, hk_to_sh, sz_to_hk, hk_to_sz多选, 默认为查询所有资金流向数据
+    :param fields:  字符串列表，需要的字段，目前可从buy_turnover, sell_turnover, quota_balance, quota_balance_ratio多选, 默认取所有
+
+    """
+    DEFAULT_CONNECT = ["sh_to_hk", "hk_to_sh", "sz_to_hk", "hk_to_sz"]
+    if connect is None:
+        connect = DEFAULT_CONNECT
+    else:
+        connect = ensure_list_of_string(connect)
+        check_items_in_container(connect, DEFAULT_CONNECT, 'connect')
+
+    DEFAULT_FIELDS = ['buy_turnover', 'sell_turnover', 'quota_balance', 'quota_balance_ratio']
+    if fields is None:
+        fields = DEFAULT_FIELDS
+    else:
+        fields = ensure_list_of_string(fields)
+        check_items_in_container(fields, DEFAULT_FIELDS, 'fields')
+
+    data = get_client().execute("current_stock_connect_quota", connect=connect)
+    res = pd.DataFrame(data)
+    if res.empty:
+        return None
+    res["datetime"] = pd.to_datetime(res["datetime"], format='%Y%m%d%H%M')
+    res.set_index(['datetime', 'connect'], inplace=True)
+    res = res[fields]
+    return res
+
+
+@export_as_api
+def get_stock_connect_quota(connect=None, start_date=None, end_date=None, fields=None):
+    """获取历史沪深港通额度日频数据
+
+    :param connect: 默认返回全部content ["sh_to_hk", "hk_to_sh", "sz_to_hk", "hk_to_sz"]
+    :param start_date: 默认为全部历史数据
+    :param end_date: 默认为最新日期
+    :param fields:  默认为所有字段 ['buy_turnover', 'sell_turnover', 'quota_balance', 'quota_balance_ratio']
+    :return:
+    """
+    DEFAULT_CONNECT = ["sh_to_hk", "hk_to_sh", "sz_to_hk", "hk_to_sz"]
+    if connect is None:
+        connect = DEFAULT_CONNECT
+    else:
+        connect = ensure_list_of_string(connect)
+        check_items_in_container(connect, DEFAULT_CONNECT, 'connect')
+
+    DEFAULT_FIELDS = ['buy_turnover', 'sell_turnover', 'quota_balance', 'quota_balance_ratio']
+    if fields is None:
+        fields = DEFAULT_FIELDS
+    else:
+        fields = ensure_list_of_string(fields)
+        check_items_in_container(fields, DEFAULT_FIELDS, 'fields')
+
+    start_date = ensure_date_int(start_date) if start_date else start_date
+    end_date = ensure_date_int(end_date) if end_date else end_date
+
+    if start_date and end_date and start_date > end_date:
+        raise ValueError("invalid date range: [{!r}, {!r}]".format(start_date, end_date))
+
+    data = get_client().execute(
+        "get_stock_connect_quota", connect=connect, start_date=start_date, end_date=end_date, fields=fields
+    )
+    if not data:
+        return None
+    res = pd.DataFrame(data)
+    res.set_index(['datetime', 'connect'], inplace=True)
+    res.sort_index(ascending=True, inplace=True)
+    return res
+
+
+@export_as_api
+def is_st_stock(order_book_ids, start_date=None, end_date=None, market="cn"):
+    """判断股票在给定的时间段是否是ST股, 返回值为一个DataFrame
+
+    :param order_book_ids: 股票 id
+    :param start_date:  (Default value = None)
+    :param end_date:  (Default value = None)
+    :param market:  (Default value = "cn")
+
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, type="CS", market=market)
+
+    if len(order_book_ids) == 1:
+        instrument = instruments(order_book_ids[0], market=market)
+        start_date, end_date = ensure_dates_base_on_listed_date(instrument, start_date, end_date, market)
+        if start_date is None:
+            return
+
+    start_date, end_date = ensure_date_range(start_date, end_date)
+
+    trading_dates = pd.to_datetime(get_trading_dates(start_date, end_date, market=market))
+    data = get_client().execute(
+        "get_st_days", order_book_ids, start_date=start_date, end_date=end_date
+    )
+    df = pd.DataFrame(data=False, columns=order_book_ids, index=trading_dates)
+    for idx, dates in data.items():
+        for date in dates:
+            date = to_datetime(date)
+            df.at[date, idx] = True
+    return df
+
+
+@export_as_api
+def _is_st_stock(order_book_id, date=None, market="cn"):
+    """判断股票在给定日期是否是ST股
+    :param order_book_id: 股票id
+    :param date:  (Default value = None)
+    :param market:  (Default value = "cn")
+    :returns: True or False
+    """
+    order_book_id = ensure_order_book_id(order_book_id, type="CS", market=market)
+    date = ensure_date_or_today_int(date)
+    df = is_st_stock(order_book_id, start_date=date, end_date=date, market=market)
+    if df is None or df.empty:
+        return False
+    else:
+        return df[order_book_id][0]
+
+
+@export_as_api
+@compatible_with_parm(name="country", value="cn", replace="market")
+def is_suspended(order_book_ids, start_date=None, end_date=None, market="cn"):
+    """获取股票停牌信息
+
+    :param order_book_ids: 股票名称
+    :param start_date: 开始日期, 如'2013-01-04' (Default value = None)
+    :param end_date: 结束日期，如'2014-01-04' (Default value = None)
+    :param market: 地区代码, 如 'cn' (Default value = "cn")
+    :returns: DataFrame
+
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, type="CS", market=market)
+
+    if len(order_book_ids) == 1:
+        instrument = instruments(order_book_ids[0], market=market)
+        start_date, end_date = ensure_dates_base_on_listed_date(instrument, start_date, end_date, market)
+        if start_date is None:
+            return
+    if end_date is None:
+        end_date = datetime.date.today()
+    start_date, end_date = ensure_date_range(start_date, end_date)
+
+    trading_dates = pd.to_datetime(get_trading_dates(start_date, end_date, market=market))
+    df = pd.DataFrame(data=False, columns=order_book_ids, index=trading_dates)
+    data = get_client().execute("get_suspended_days", order_book_ids, start_date, end_date, market=market)
+    for idx, dates in data.items():
+        for date in dates:
+            date = to_datetime(int(date))
+            df.at[date, idx] = True
+    df.sort_index(inplace=True)
+    return df
+
+
+stock_fields = {"shares_holding": "shares_holding", "holding_ratio": "holding_ratio"}
+special_symbols = ["all_connect", "shanghai_connect", "shenzhen_connect"]
+symbols_map = {"shanghai_connect": "SH", "shenzhen_connect": "SZ"}
+
+
+@export_as_api
+def get_stock_connect(order_book_ids, start_date=None, end_date=None, fields=None, expect_df=True):
+    """获取"陆股通"的持股、持股比例
+
+    :param order_book_ids: 股票列表
+    :param start_date: 开始日期: 如'2017-03-17' (Default value = None)
+    :param end_date: 结束日期: 如'2018-03-16' (Default value = None)
+    :param fields: 默认为所有字段，可输入shares_holding, holding_ratio, adjusted_holding_ratio (Default value = None)
+    :param expect_df: 是否返回 MultiIndex DataFrame (Default value = True)
+    :returns: 返回pandas.DataFrame or pandas.Panel
+
+    """
+    if order_book_ids not in ("shanghai_connect", "shenzhen_connect", "all_connect"):
+        order_book_ids = ensure_order_book_ids(order_book_ids, type="CS")
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    if fields is not None:
+        fields = ensure_list_of_string(fields)
+        for f in fields:
+            if f not in ("shares_holding", "holding_ratio", "adjusted_holding_ratio"):
+                raise ValueError("invalid field: {}".format(f))
+    else:
+        fields = ["shares_holding", "holding_ratio", "adjusted_holding_ratio"]
+    data = get_client().execute("get_stock_connect", order_book_ids, start_date, end_date, fields)
+    if not data:
+        return None
+    df = pd.DataFrame(data, columns=["trading_date", "order_book_id"] + fields)
+
+    if not expect_df and not is_panel_removed:
+        df = df.set_index(["trading_date", "order_book_id"])
+        df = df.to_panel()
+        df.major_axis.name = None
+        df.minor_axis.name = None
+        if len(order_book_ids) == 1:
+            df = df.minor_xs(order_book_ids[0])
+        if len(fields) == 1:
+            df = df[fields[0]]
+        if len(order_book_ids) != 1 and len(fields) != 1:
+            warnings.warn("Panel is removed after pandas version 0.25.0."
+                          " the default value of 'expect_df' will change to True in the future.")
+        return df
+    else:
+        df.sort_values(["order_book_id", "trading_date"], inplace=True)
+        df.set_index(["order_book_id", "trading_date"], inplace=True)
+        if expect_df:
+            return df
+
+        if len(order_book_ids) != 1 and len(fields) != 1:
+            raise_for_no_panel()
+
+        if len(order_book_ids) == 1:
+            df.reset_index(level=0, drop=True, inplace=True)
+            if len(fields) == 1:
+                df = df[fields[0]]
+            return df
+        else:
+            df = df.unstack(0)[fields[0]]
+            df.index.name = None
+            df.columns.name = None
+            return df
+
+
+MARGIN_FIELDS = (
+    "margin_balance",
+    "buy_on_margin_value",
+    "short_sell_quantity",
+    "margin_repayment",
+    "short_balance_quantity",
+    "short_repayment_quantity",
+    "short_balance",
+    "total_balance",
+)
+
+MARGIN_SUMMARY_MAP = {"SH": "XSHG", "XSHG": "XSHG", "SZ": "XSHE", "XSHE": "XSHE"}
+
+
+@export_as_api
+def get_securities_margin(
+        order_book_ids, start_date=None, end_date=None, fields=None, expect_df=True, market="cn"
+):
+    """获取股票融资融券数据
+
+    :param order_book_ids: 股票代码或代码列表
+    :param start_date: 开始时间，支持 str, date, datetime, pandasTimestamp
+        默认为 end_date 之前一个月 (Default value = None)
+    :param end_date: 结束时间 默认为当前日期前一天 (Default value = None)
+    :param fields: str 或 list 类型. 默认为 None, 返回所有字段。可选字段包括：
+                   margin_balance, buy_on_margin_value, margin_repayment, short_balance, short_balance_quantity,
+                   short_sell_quantity, short_repayment_quantity, total_balance
+                   (Default value = None)
+    :param expect_df: 返回 MultiIndex DataFrame (Default value = True)
+    :param market: 地区代码, 如: 'cn' (Default value = "cn")
+    :returns: 如果传入多个股票代码，且 fields 为多个或者 None，返回 pandas.Panel
+        如果传入一只股票或者 fields 为单个字段，则返回 pandas.DataFrame
+        如果传入的股票代码和字段数都是1，则返回 pandas.Series
+
+    """
+
+    order_book_ids = ensure_list_of_string(order_book_ids, "order_book_ids")
+    all_list = []
+    for order_book_id in order_book_ids:
+        if order_book_id.upper() in MARGIN_SUMMARY_MAP:
+            all_list.append(MARGIN_SUMMARY_MAP[order_book_id.upper()])
+        else:
+            inst = instruments(order_book_id, market)
+
+            if inst is not None and inst.type in ["CS", "ETF", "LOF"]:
+                all_list.append(inst.order_book_id)
+            else:
+                warnings.warn("{} is not stock, ETF, or LOF.".format(order_book_id))
+    order_book_ids = all_list
+    if not order_book_ids:
+        raise ValueError("no valid securities in {}".format(order_book_ids))
+    if fields is None:
+        fields = list(MARGIN_FIELDS)
+    else:
+        fields = ensure_list_of_string(fields, "fields")
+        check_items_in_container(fields, MARGIN_FIELDS, "fields")
+        fields = ensure_order(fields, MARGIN_FIELDS)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    if end_date > ensure_date_or_today_int(None):
+        end_date = ensure_date_or_today_int(get_previous_trading_date(datetime.date.today()))
+    trading_dates = pd.to_datetime(get_trading_dates(start_date, end_date, market=market))
+
+    data = get_client().execute(
+        "get_securities_margin", order_book_ids, start_date, end_date, market=market
+    )
+    if not data:
+        return
+
+    if not expect_df and not is_panel_removed:
+
+        pl = pd.Panel(items=fields, major_axis=trading_dates, minor_axis=order_book_ids)
+        for r in data:
+            for field in fields:
+                value = r.get(field)
+                pl.at[field, r["date"], r["order_book_id"]] = value
+
+        if len(order_book_ids) == 1:
+            pl = pl.minor_xs(order_book_ids[0])
+        if len(fields) == 1:
+            pl = pl[fields[0]]
+        if len(order_book_ids) != 1 and len(fields) != 1:
+            warnings.warn("Panel is removed after pandas version 0.25.0."
+                          " the default value of 'expect_df' will change to True in the future.")
+        return pl
+    else:
+        df = pd.DataFrame(data)
+        df.sort_values(["order_book_id", "date"], inplace=True)
+        df.set_index(["order_book_id", "date"], inplace=True)
+        df = df.reindex(columns=fields)
+        if expect_df:
+            return df
+
+        if len(order_book_ids) != 1 and len(fields) != 1:
+            raise_for_no_panel()
+
+        if len(order_book_ids) == 1:
+            df.reset_index(level=0, drop=True, inplace=True)
+            if len(fields) == 1:
+                df = df[fields[0]]
+            return df
+        else:
+            df = df.unstack(0)[fields[0]]
+            df.index.name = None
+            df.columns.name = None
+            return df
+
+
+MARGIN_TYPE = ("stock", "cash")
+EXCHANGE_TYPE = {"SZ": "XSHE", "sz": "XSHE", "xshe": "XSHE", "SH": "XSHG", "sh": "XSHG", "xshg": "XSHG"}
+EXCHANGE_CONTENT = ["XSHE", "XSHG"]
+
+
+@export_as_api
+@rqdatah_serialize(converter=http_conv_list_to_csv, name='order_book_id')
+def get_margin_stocks(date=None, exchange=None, margin_type='stock', market="cn"):
+    """获取融资融券信息
+
+    :param date: 查询日期，默认返回今天上一交易日，支持 str, timestamp, datetime 类型
+    :param exchange: 交易所信息，默认不填写则返回全部。
+                    str类型，默认为 None，返回所有字段。可选字段包括：
+                    'XSHE', 'sz' 代表深交所；'XSHG', 'sh' 代表上交所，不区分大小写
+                    (Default value = None)
+    :param margin_type: 'stock' 代表融券卖出，'cash'，代表融资买入，默认为'stock'
+
+    """
+    if date:
+        date = ensure_date_int(date)
+    else:
+        date = get_previous_trading_date(datetime.date.today())
+        date = date.year * 10000 + date.month * 100 + date.day
+
+    if exchange is None:
+        exchange = EXCHANGE_CONTENT
+    else:
+        exchange = ensure_string(exchange, "exchange")
+        if exchange in EXCHANGE_TYPE:
+            exchange = EXCHANGE_TYPE[exchange]
+        check_items_in_container(exchange, EXCHANGE_CONTENT, "exchange")
+        exchange = [exchange]
+
+    margin_type = ensure_string(margin_type, "margin_type")
+    check_items_in_container(margin_type, MARGIN_TYPE, "margin_type")
+
+    data = get_client().execute(
+        "get_margin_stocks", date, exchange, margin_type, market=market
+    )
+
+    if not data:
+        return []
+    else:
+        return sorted(data)
+
+
+share_fields = {
+    "total": "total_shares",
+    "circulation_a": "a_cir_shares",
+    "non_circulation_a": "a_non_cir_shares",
+    "total_a": "a_total_shares",
+    'preferred_shares': 'preferred_shares',
+    "free_circulation": "free_circulation"
+}
+
+reversed_fields = {v: k for k, v in share_fields.items()}
+
+
+@export_as_api
+@compatible_with_parm(name="country", value="cn", replace="market")
+def get_shares(order_book_ids, start_date=None, end_date=None, fields=None, expect_df=True, market="cn"):
+    """获取流通股本信息
+
+    :param order_book_ids: 股票名称
+    :param start_date: 开始日期, 如'2013-01-04' (Default value = None)
+    :param end_date: 结束日期，如'2014-01-04' (Default value = None)
+    :param fields: 如'total', 'circulation_a' (Default value = None)
+    :param expect_df: 返回 MultiIndex DataFrame (Default value = True)
+    :param market: 地区代码，如'cn' (Default value = "cn")
+    :returns: 返回一个DataFrame
+
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    if fields:
+        fields = ensure_list_of_string(fields, "fields")
+        if 'management_circulation' in fields:
+            fields.remove('management_circulation')
+            if fields:
+                warnings.warn("management_circulation is removed")
+            else:
+                raise ValueError("management_circulation is removed")
+        check_items_in_container(fields, set(share_fields), "fields")
+        fields = [share_fields[i] for i in fields]
+    else:
+        fields = list(share_fields.values())
+
+    all_shares = get_client().execute("get_shares_v2", order_book_ids, fields, start_date=start_date, end_date=end_date, market=market)
+    if not all_shares:
+        return
+    dates = get_trading_dates_in_type(start_date, end_date, expect_type="datetime", market=market)
+    df = pd.DataFrame(all_shares)
+    unique = set(df.order_book_id)
+    missing = [obid for obid in order_book_ids if obid not in unique]
+    if missing:
+        missing_df = pd.DataFrame({"order_book_id": missing, "date": df.date.iloc[-1]})
+        df = pd.concat([df, missing_df])
+    if 'preferred_shares' in df.columns:
+        df['preferred_shares'] = df['preferred_shares'].fillna(0)
+    df.set_index(["date", "order_book_id"], inplace=True)
+    df.sort_index(inplace=True)
+    df = df.unstack(level=1)
+    index = df.index.union(dates)
+    df = df.reindex(index)
+    df = df.fillna(method="ffill")
+    df = df.loc[list(dates)]
+    df = df.dropna(how="all")
+    df = df[fields]
+    if not is_panel_removed and not expect_df:
+        pl = df.stack(1).to_panel()
+        pl.items = [reversed_fields[i] for i in pl.items]
+        if len(order_book_ids) == 1:
+            pl = pl.minor_xs(order_book_ids[0])
+        if len(fields) == 1:
+            pl = pl[reversed_fields[fields[0]]]
+        if len(order_book_ids) != 1 and len(fields) != 1:
+            warnings.warn("Panel is removed after pandas version 0.25.0."
+                          " the default value of 'expect_df' will change to True in the future.")
+        return pl
+    else:
+        df = df.stack(1)
+        df.index.set_names(["date", "order_book_id"], inplace=True)
+        de_listed_map = {i: instruments(i).de_listed_date for i in order_book_ids}
+        max_end_date = df.index.levels[0].max() + pd.Timedelta(days=1)
+        de_listed_map = {k: (pd.to_datetime(v) if v != '0000-00-00' else max_end_date) for k, v in de_listed_map.items()}
+        i0 = df.index.get_level_values(0)
+        i1 = df.index.get_level_values(1).map(de_listed_map)
+        mask = i1 > i0
+        df = df[mask]
+        if df.empty:
+            return None
+        df = df.reorder_levels(["order_book_id", "date"]).sort_index()
+        df = df.rename(columns=reversed_fields)
+        if expect_df:
+            return df
+
+        if len(order_book_ids) != 1 and len(fields) != 1:
+            raise_for_no_panel()
+
+        if len(order_book_ids) == 1:
+            df.reset_index(level=0, drop=True, inplace=True)
+            if len(fields) == 1:
+                df = df[reversed_fields[fields[0]]]
+            return df
+        else:
+            df = df.unstack(0)[reversed_fields[fields[0]]]
+            df.index.name = None
+            df.columns.name = None
+            return df
+
+
+allotment_fields = [
+    "proportion",
+    "allotted_proportion",
+    "allotted_shares",
+    "allotment_price",
+    "book_closure_date",
+    "ex_right_date", ]
+
+
+@export_as_api
+@compatible_with_parm(name="country", value="cn", replace="market")
+def get_allotment(order_book_ids, start_date=None, end_date=None, fields=None, market="cn"):
+    """获取配股信息
+    :param order_book_ids: 股票名称
+    :param start_date: 开始日期, 如'1991-01-01' (Default value = 1991-01-01)
+    :param end_date: 结束日期，如'2014-01-04' (Default value = None)
+    :param market: 地区代码，如'cn' (Default value = "cn")
+    :returns: 返回一个DataFrame
+    'order_book_id': 股票合约代码
+    'declaration_announcement_date': 首次信息发布日期
+    'proportion': 配股比例(每一股对应的配股比例)
+    'allotted_proportion': 实际配股比例(每一股对应的配股比例)
+    'allotted_shares': 实际配股数量
+    'allotment_price': 每股配股价格
+    'book_closure_date': 股权登记日
+    'ex_right_date': 除权除息日
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+
+    if start_date:
+        start_date = ensure_date_int(start_date)
+    if end_date:
+        end_date = ensure_date_int(end_date)
+
+    if fields:
+        fields = ensure_list_of_string(fields, "fields")
+        check_items_in_container(fields, allotment_fields, "fields")
+    else:
+        fields = allotment_fields
+
+    all_allotment = get_client().execute("get_allotment", order_book_ids, fields, start_date, end_date, market=market)
+    if not all_allotment:
+        return
+    df = pd.DataFrame(all_allotment)
+    df.set_index(["order_book_id", "declaration_announcement_date"], inplace=True)
+    df.sort_index(inplace=True)
+    df = df[fields]
+    return df
+
+
+@export_as_api
+def get_symbol_change_info(order_book_ids, market="cn"):
+    """ 获取合约的历史简称信息
+
+    :param order_book_ids: 股票合约id
+    :param market: 默认 'cn'
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+    data = get_client().execute("get_symbol_change_info", order_book_ids, market)
+    if data:
+        df = pd.DataFrame(data)
+        df.set_index(['order_book_id', 'change_date'], inplace=True)
+        df.sort_index(inplace=True)
+        return df
+
+
+@export_as_api
+def get_special_treatment_info(order_book_ids, market="cn"):
+    """ 获取合约的特殊处理状态
+
+    :param order_book_ids: 股票合约id
+    :param market: 默认 'cn'
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+    data = get_client().execute("get_special_treatment_info", order_book_ids, market)
+    if data:
+        df = pd.DataFrame(data)
+        df.set_index(['order_book_id', 'change_date'], inplace=True)
+        df.sort_index(inplace=True)
+        return df
+
+
+@export_as_api
+def get_incentive_plan(order_book_ids, start_date=None, end_date=None, market="cn"):
+    """ 获取合约的股权激励信息
+
+    :param order_book_ids: 股票合约id
+    :param start_date: 开始时间
+    :param end_date: 结束时间
+    :param market: 默认 'cn'
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+    end_date = ensure_date_or_today_int(end_date)
+    if start_date:
+        start_date = ensure_date_int(start_date)
+        if start_date > end_date:
+            raise ValueError("invalid date range: [{!r}, {!r}]".format(start_date, end_date))
+    data = get_client().execute("get_incentive_plan", order_book_ids, start_date, end_date, market)
+    if data:
+        df = pd.DataFrame(data)
+        df.set_index(['order_book_id', 'info_date'], inplace=True)
+        df.sort_index(inplace=True)
+        return df
+
+
+@export_as_api
+def get_investor_ra(order_book_ids, start_date=None, end_date=None, market='cn'):
+    """
+    获取股票投资者关系活动信息
+
+    :param order_book_ids:  股票合约id
+    :param start_date: 开始日期
+    :param end_date: 结束日期
+    :param market: 'cn'
+    :return: pandas.MultiIndex DataFrame
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+    end_date = ensure_date_or_today_int(end_date)
+    if start_date:
+        start_date = ensure_date_int(start_date)
+        if start_date > end_date:
+            raise ValueError("invalid date range: [{!r}, {!r}]".format(start_date, end_date))
+    data = get_client().execute("get_investor_ra", order_book_ids, start_date, end_date, market)
+    if not data:
+        return None
+    df = pd.DataFrame(data)
+    df.rename(columns={'date': 'info_date'}, inplace=True)
+    df.set_index(['order_book_id', 'info_date'], inplace=True)
+    df = df.reindex(columns=['participant', 'institute', 'detail']).astype(str)
+    for col in df.columns:
+        df.loc[df[col] == 'nan', col] = None
+    return df
+
+
+@export_as_api
+def get_announcement(order_book_ids, start_date=None, end_date=None, market="cn"):
+    """
+    获取公司公告数据，包括标题及正文链接
+
+    :param order_book_ids: 股票合约id
+    :param start_date: 开始日期
+    :param end_date: 结束日期
+    :param market: 'cn'
+    :return: pandas.MultiIndex DataFrame
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+    start_date, end_date = ensure_date_range(start_date, end_date)
+    data = get_client().execute("get_announcement", order_book_ids, start_date, end_date, market)
+    if not data:
+        return None
+    df = pd.DataFrame(data)
+    df.set_index(["order_book_id", "info_date"], inplace=True)
+    df.sort_index(inplace=True)
+    return df
+
+
+@export_as_api
+def get_holder_number(order_book_ids, start_date=None, end_date=None, market="cn"):
+    """
+    获取股东人数
+
+    :param order_book_ids: 股票合约id
+    :param start_date: 开始日期
+    :param end_date: 结束日期
+    :param market: 'cn'
+    :return: pandas.MultiIndex DataFrame
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+    start_date, end_date = ensure_date_range(start_date, end_date, delta=relativedelta(years=1))
+    data = get_client().execute("get_holder_number", order_book_ids, start_date, end_date, market)
+    if not data:
+        return None
+    df = pd.DataFrame.from_records(data, index=["order_book_id", "info_date"])
+    df.sort_index(inplace=True)
+    return df
+
+
+_VALID_OPINION_TYPE = {
+    'unqualified', 'unqualified_with_explanation', 'qualified', 'disclaimer',
+    'adverse', 'unaudited', 'qualified_with_explanation', 'uncertainty_audit',
+    'material_uncertainty'
+}
+
+
+@export_as_api
+def get_audit_opinion(order_book_ids, start_quarter, end_quarter, date=None, type=None, opinion_types=None, market="cn"):
+    """
+    获取财务报告审计意见
+    :param: order_book_ids: str | list[str] 合约代码
+    :param: start_quarter:  str 财报回溯查询的起始报告期，例如'2015q2'代表 2015 年半年报
+    :param: end_quarter: str 财报回溯查询的截止报告期，例如'2015q4'代表 2015 年年报，该参数必填。
+    :param: date: 查询日期，默认查询日期为当前最新日期
+    :param: type: 需要返回的审计报告类型, 可选值包括 financial_statements, internal_control
+    :param: opinion_types: str | list[str] 需要返回的审计意见类型, 可选值包括
+        "unqualified", "unqualified_with_explanation", "qualified", "disclaimer",
+        "adverse", "unaudited", "qualified_with_explanation", "uncertainty_audit",
+        "material_uncertainty"
+    :param: market:str 	市场，默认'cn'为中国内地市场
+    """
+    if opinion_types is not None:
+        opinion_types = ensure_list_of_string(opinion_types, "opinion_type")
+        check_items_in_container(opinion_types, _VALID_OPINION_TYPE, "opinion_type")
+    if type is not None:
+        type = ensure_string(type, "type")
+        check_items_in_container(type, {"financial_statements", "internal_control"}, "type")
+    date = ensure_date_or_today_int(date)
+    order_book_ids = ensure_list_of_string(order_book_ids)
+
+    check_quarter(start_quarter, 'start_quarter')
+    start_quarter_int = ensure_date_int(quarter_string_to_date(start_quarter))
+
+    check_quarter(end_quarter, 'end_quarter')
+    end_quarter_int = ensure_date_int(quarter_string_to_date(end_quarter))
+    result_df = pd.DataFrame(
+        get_client().execute("get_audit_opinion", order_book_ids, start_quarter_int, end_quarter_int, date, type, opinion_types, market)
+    )
+    if result_df.empty:
+        return
+    result_df.sort_values(['order_book_id', 'end_date', 'info_date'])
+    result_df["end_date"] = result_df["end_date"].apply(
+        lambda d: "{}q{}".format(d.year, math.ceil(d.month / 3)))
+    result_df.rename(columns={"end_date": "quarter"}, inplace=True)
+    result_df.set_index(['order_book_id', 'quarter'], inplace=True)
+    result_df.sort_index(inplace=True)
+    return result_df
```

## rqdatac/services/structured_fund.py

 * *Ordering differences only*

```diff
@@ -1,76 +1,76 @@
-# -*- coding: utf-8 -*-
-from decimal import Decimal, DecimalTuple
-
-
-import pandas as pd
-
-from rqdatac.client import get_client
-from rqdatac.decorators import export_as_api
-from rqdatac.validators import ensure_list_of_string
-
-_SIGN = "sign"
-_DIGITS = "digits"
-_EXPONENT = "exponent"
-
-
-def _encode_decimal(num, prefix):
-    decimal_tuple = Decimal(str(num)).normalize().as_tuple()
-    prefix += "."
-    encoded_decimal = {
-        prefix + _SIGN: decimal_tuple.sign,
-        prefix + _DIGITS: decimal_tuple.digits,
-        prefix + _EXPONENT: decimal_tuple.exponent,
-    }
-    return encoded_decimal
-
-
-def _decode_decimal(encoded_decimal):
-    sign = encoded_decimal[_SIGN]
-    digits = tuple(encoded_decimal[_DIGITS])
-    exponent = encoded_decimal[_EXPONENT]
-    return Decimal(DecimalTuple(sign=sign, digits=digits, exponent=exponent))
-
-
-def _remake_decimal(dlist):
-    for one in dlist:
-        for key, value in one.items():
-            if isinstance(value, dict) and value.get(_DIGITS):
-                one[key] = _decode_decimal(value)
-
-
-@export_as_api(namespace="fenji")
-def get_a_by_yield(current_yield, listing=True, market="cn"):
-    if listing is not None:
-        listing = bool(listing)
-
-    data = get_client().execute("fenji.get_a_by_yield", current_yield, listing, market)
-    return data
-
-
-@export_as_api(namespace="fenji")
-def get_a_by_interest_rule(interest_rule, listing=True, market="cn"):
-    if listing is not None:
-        listing = bool(listing)
-    data = get_client().execute("fenji.get_a_by_interest_rule", interest_rule, listing, market)
-    return data
-
-
-@export_as_api(namespace="fenji")
-def get_all(field_list=None, market="cn"):
-    data = get_client().execute("fenji.get_all", field_list, market)
-    _remake_decimal(data)
-    df = pd.DataFrame(data)
-    df.reindex(columns=sorted(df.columns))
-    return df
-
-
-@export_as_api(namespace="fenji")
-def get(order_book_ids, field_list=None, market="cn"):
-    order_book_ids = ensure_list_of_string(order_book_ids, "order_book_ids")
-    data = get_client().execute("fenji.get", order_book_ids, field_list, market)
-    if not data:
-        return
-    _remake_decimal(data)
-    df = pd.DataFrame(data)
-    df.reindex(columns=sorted(df.columns))
-    return df
+# -*- coding: utf-8 -*-
+from decimal import Decimal, DecimalTuple
+
+
+import pandas as pd
+
+from rqdatac.client import get_client
+from rqdatac.decorators import export_as_api
+from rqdatac.validators import ensure_list_of_string
+
+_SIGN = "sign"
+_DIGITS = "digits"
+_EXPONENT = "exponent"
+
+
+def _encode_decimal(num, prefix):
+    decimal_tuple = Decimal(str(num)).normalize().as_tuple()
+    prefix += "."
+    encoded_decimal = {
+        prefix + _SIGN: decimal_tuple.sign,
+        prefix + _DIGITS: decimal_tuple.digits,
+        prefix + _EXPONENT: decimal_tuple.exponent,
+    }
+    return encoded_decimal
+
+
+def _decode_decimal(encoded_decimal):
+    sign = encoded_decimal[_SIGN]
+    digits = tuple(encoded_decimal[_DIGITS])
+    exponent = encoded_decimal[_EXPONENT]
+    return Decimal(DecimalTuple(sign=sign, digits=digits, exponent=exponent))
+
+
+def _remake_decimal(dlist):
+    for one in dlist:
+        for key, value in one.items():
+            if isinstance(value, dict) and value.get(_DIGITS):
+                one[key] = _decode_decimal(value)
+
+
+@export_as_api(namespace="fenji")
+def get_a_by_yield(current_yield, listing=True, market="cn"):
+    if listing is not None:
+        listing = bool(listing)
+
+    data = get_client().execute("fenji.get_a_by_yield", current_yield, listing, market)
+    return data
+
+
+@export_as_api(namespace="fenji")
+def get_a_by_interest_rule(interest_rule, listing=True, market="cn"):
+    if listing is not None:
+        listing = bool(listing)
+    data = get_client().execute("fenji.get_a_by_interest_rule", interest_rule, listing, market)
+    return data
+
+
+@export_as_api(namespace="fenji")
+def get_all(field_list=None, market="cn"):
+    data = get_client().execute("fenji.get_all", field_list, market)
+    _remake_decimal(data)
+    df = pd.DataFrame(data)
+    df.reindex(columns=sorted(df.columns))
+    return df
+
+
+@export_as_api(namespace="fenji")
+def get(order_book_ids, field_list=None, market="cn"):
+    order_book_ids = ensure_list_of_string(order_book_ids, "order_book_ids")
+    data = get_client().execute("fenji.get", order_book_ids, field_list, market)
+    if not data:
+        return
+    _remake_decimal(data)
+    df = pd.DataFrame(data)
+    df.reindex(columns=sorted(df.columns))
+    return df
```

## rqdatac/services/tmall.py

 * *Ordering differences only*

```diff
@@ -1,70 +1,70 @@
-# -*- coding: utf-8 -*-
-import datetime
-import pandas as pd
-from rqdatac.client import get_client
-from rqdatac.validators import ensure_string, check_items_in_container, ensure_order_book_id
-from rqdatac.utils import to_datetime
-from rqdatac.decorators import export_as_api
-
-
-class Tmall:
-    @staticmethod
-    def stocks():
-        """获取电商天猫数据股票列表
-
-        :return:
-            股票列表
-        """
-
-        return get_client().execute("tmall.stocks")
-
-    @staticmethod
-    def data(order_book_id, start_date=None, end_date=None, frequency="1d", fields=None):
-        """获取天猫电商销售额数据
-
-        :param order_book_id: 股票名
-        :param start_date: 开始日期，默认为结束日期前一个月,  必须在2016年6月30日之后 (Default value = None)
-        :param end_date: 结束日期 (Default value = None)
-        :param frequency: 如'1d', '1M' (Default value = "1d")
-        :param fields: 如'sales' (Default value = None)
-        :returns: 返回DataFrame
-
-        """
-        order_book_id = ensure_order_book_id(order_book_id)
-
-        if not end_date:
-            end_date = datetime.date.today()
-
-        if not start_date:
-            start_date = end_date - datetime.timedelta(days=30)
-
-        end_date = to_datetime(end_date)
-        start_date = to_datetime(start_date)
-
-        if start_date < datetime.datetime(2016, 6, 30):
-            raise ValueError("start_date cannot be earlier than 2016-06-30")
-
-        if start_date > end_date:
-            raise ValueError()
-
-        ensure_string(frequency, "frequency")
-        check_items_in_container([frequency], {"1d", "1M"}, "frequency")
-
-        if fields is None:
-            fields = "sales"
-        else:
-            fields = ensure_string(fields, "fields")
-            check_items_in_container(fields, ["sales"], "fields")
-        data = get_client().execute("tmall.data", order_book_id, start_date, end_date, frequency)
-        if not data:
-            return
-        df = pd.DataFrame(data)
-        df = df.set_index("date")
-        df.sort_index(inplace=True)
-        df.columns = ["sales"]
-        return df
-
-
-@export_as_api
-class ecommerce:
-    tmall = Tmall
+# -*- coding: utf-8 -*-
+import datetime
+import pandas as pd
+from rqdatac.client import get_client
+from rqdatac.validators import ensure_string, check_items_in_container, ensure_order_book_id
+from rqdatac.utils import to_datetime
+from rqdatac.decorators import export_as_api
+
+
+class Tmall:
+    @staticmethod
+    def stocks():
+        """获取电商天猫数据股票列表
+
+        :return:
+            股票列表
+        """
+
+        return get_client().execute("tmall.stocks")
+
+    @staticmethod
+    def data(order_book_id, start_date=None, end_date=None, frequency="1d", fields=None):
+        """获取天猫电商销售额数据
+
+        :param order_book_id: 股票名
+        :param start_date: 开始日期，默认为结束日期前一个月,  必须在2016年6月30日之后 (Default value = None)
+        :param end_date: 结束日期 (Default value = None)
+        :param frequency: 如'1d', '1M' (Default value = "1d")
+        :param fields: 如'sales' (Default value = None)
+        :returns: 返回DataFrame
+
+        """
+        order_book_id = ensure_order_book_id(order_book_id)
+
+        if not end_date:
+            end_date = datetime.date.today()
+
+        if not start_date:
+            start_date = end_date - datetime.timedelta(days=30)
+
+        end_date = to_datetime(end_date)
+        start_date = to_datetime(start_date)
+
+        if start_date < datetime.datetime(2016, 6, 30):
+            raise ValueError("start_date cannot be earlier than 2016-06-30")
+
+        if start_date > end_date:
+            raise ValueError()
+
+        ensure_string(frequency, "frequency")
+        check_items_in_container([frequency], {"1d", "1M"}, "frequency")
+
+        if fields is None:
+            fields = "sales"
+        else:
+            fields = ensure_string(fields, "fields")
+            check_items_in_container(fields, ["sales"], "fields")
+        data = get_client().execute("tmall.data", order_book_id, start_date, end_date, frequency)
+        if not data:
+            return
+        df = pd.DataFrame(data)
+        df = df.set_index("date")
+        df.sort_index(inplace=True)
+        df.columns = ["sales"]
+        return df
+
+
+@export_as_api
+class ecommerce:
+    tmall = Tmall
```

## rqdatac/services/xueqiu.py

 * *Ordering differences only*

```diff
@@ -1,102 +1,102 @@
-# -*- coding: utf-8 -*-
-import datetime
-import pandas as pd
-from rqdatac.validators import (
-    ensure_string,
-    ensure_list_of_string,
-    check_items_in_container,
-    ensure_date_range,
-    ensure_date_int,
-    ensure_order_book_ids,
-)
-from rqdatac.client import get_client
-from rqdatac.decorators import export_as_api
-
-FIELDS = (
-    "new_comments",
-    "total_comments",
-    "new_followers",
-    "total_followers",
-    "sell_actions",
-    "buy_actions",
-)
-
-
-@export_as_api(namespace="xueqiu")
-def top_stocks(field, date, frequency="1d", count=5, market="cn"):
-    """获取雪球舆情数据
-
-    :param field: 如 'new_comments', 'total_comments', 'new_followers',
-                 'total_followers', 'sell_actions', 'buy_actions'
-    :param date: 如 '2015-05-21', 必须在2015年4月23日之后
-    :param frequency: 如 '1d', '1w', '1M' (Default value = "1d")
-    :param count: 如 5, 10, 100 (Default value = 5)
-    :param market: 地区代码, 如 'cn' (Default value = "cn")
-    :returns: 如果有数据，返回一个DataFrame,否则返回None
-
-    """
-    field = ensure_string(field, "field")
-    frequency = ensure_string(frequency, "frequency")
-    check_items_in_container([field], FIELDS, "field")
-    check_items_in_container([frequency], {"1d", "1w", "1M"}, "frequency")
-    d = {"1d": "d", "1M": "m", "1w": "w"}
-    frequency = d[frequency]
-    date = ensure_date_int(date)
-    if date < 20150423 or date > ensure_date_int(datetime.datetime.today()):
-        raise ValueError("date out of range, start_date " "cannot be earlier than 2015-04-23")
-    data = get_client().execute("xueqiu.top_stocks", field, date, frequency, count, market)
-
-    if not data:
-        return
-    df = pd.DataFrame(data)
-    df = df[["order_book_id", field]]
-    return df
-
-
-@export_as_api(namespace="xueqiu")
-def history(
-    order_book_ids,
-    start_date="2015-05-21",
-    end_date="2016-05-21",
-    frequency="1d",
-    fields=None,
-    market="cn",
-):
-    """获取雪球历史舆情数据
-
-    :param order_book_ids: 股票代码或代码列表
-    :param start_date: 如 '2015-05-21', 必须在2015年4月23日之后 (Default value = "2015-05-21")
-    :param end_date: 如 '2016-05-21' (Default value = "2016-05-21")
-    :param frequency: 如 '1d' (Default value = "1d")
-    :param fields: 如 'new_comments', 'total_comments', 'new_followers',
-                 'total_followers', 'sell_actions', 'buy_actions' (Default value = None)
-    :param market: 地区代码, 如 'cn' (Default value = "cn")
-    :returns: 返回pd.Panel或pd.DataFrame或pd.Series
-
-    """
-    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
-    if fields:
-        fields = ensure_list_of_string(fields, "fields")
-        check_items_in_container(fields, FIELDS, "fields")
-    else:
-        fields = FIELDS
-    frequency = ensure_string(frequency, "frequency")
-    check_items_in_container([frequency], {"1d"}, "frequency")
-    start_date, end_date = ensure_date_range(start_date, end_date)
-
-    if start_date < 20150423:
-        raise ValueError("date out of range, start_date " "cannot be earlier than 2015-04-23")
-    data = get_client().execute(
-        "xueqiu.history", order_book_ids, start_date, end_date, fields, market
-    )
-    if not data:
-        return
-    df = pd.DataFrame(data)
-    df = df.set_index(["date", "order_book_id"])
-    df.sort_index(inplace=True)
-    pl = df.to_panel()
-    if len(pl.minor_axis) == 1:
-        pl = pl.minor_xs(pl.minor_axis[0])
-    if len(fields) == 1:
-        pl = pl[fields[0]]
-    return pl
+# -*- coding: utf-8 -*-
+import datetime
+import pandas as pd
+from rqdatac.validators import (
+    ensure_string,
+    ensure_list_of_string,
+    check_items_in_container,
+    ensure_date_range,
+    ensure_date_int,
+    ensure_order_book_ids,
+)
+from rqdatac.client import get_client
+from rqdatac.decorators import export_as_api
+
+FIELDS = (
+    "new_comments",
+    "total_comments",
+    "new_followers",
+    "total_followers",
+    "sell_actions",
+    "buy_actions",
+)
+
+
+@export_as_api(namespace="xueqiu")
+def top_stocks(field, date, frequency="1d", count=5, market="cn"):
+    """获取雪球舆情数据
+
+    :param field: 如 'new_comments', 'total_comments', 'new_followers',
+                 'total_followers', 'sell_actions', 'buy_actions'
+    :param date: 如 '2015-05-21', 必须在2015年4月23日之后
+    :param frequency: 如 '1d', '1w', '1M' (Default value = "1d")
+    :param count: 如 5, 10, 100 (Default value = 5)
+    :param market: 地区代码, 如 'cn' (Default value = "cn")
+    :returns: 如果有数据，返回一个DataFrame,否则返回None
+
+    """
+    field = ensure_string(field, "field")
+    frequency = ensure_string(frequency, "frequency")
+    check_items_in_container([field], FIELDS, "field")
+    check_items_in_container([frequency], {"1d", "1w", "1M"}, "frequency")
+    d = {"1d": "d", "1M": "m", "1w": "w"}
+    frequency = d[frequency]
+    date = ensure_date_int(date)
+    if date < 20150423 or date > ensure_date_int(datetime.datetime.today()):
+        raise ValueError("date out of range, start_date " "cannot be earlier than 2015-04-23")
+    data = get_client().execute("xueqiu.top_stocks", field, date, frequency, count, market)
+
+    if not data:
+        return
+    df = pd.DataFrame(data)
+    df = df[["order_book_id", field]]
+    return df
+
+
+@export_as_api(namespace="xueqiu")
+def history(
+    order_book_ids,
+    start_date="2015-05-21",
+    end_date="2016-05-21",
+    frequency="1d",
+    fields=None,
+    market="cn",
+):
+    """获取雪球历史舆情数据
+
+    :param order_book_ids: 股票代码或代码列表
+    :param start_date: 如 '2015-05-21', 必须在2015年4月23日之后 (Default value = "2015-05-21")
+    :param end_date: 如 '2016-05-21' (Default value = "2016-05-21")
+    :param frequency: 如 '1d' (Default value = "1d")
+    :param fields: 如 'new_comments', 'total_comments', 'new_followers',
+                 'total_followers', 'sell_actions', 'buy_actions' (Default value = None)
+    :param market: 地区代码, 如 'cn' (Default value = "cn")
+    :returns: 返回pd.Panel或pd.DataFrame或pd.Series
+
+    """
+    order_book_ids = ensure_order_book_ids(order_book_ids, market=market)
+    if fields:
+        fields = ensure_list_of_string(fields, "fields")
+        check_items_in_container(fields, FIELDS, "fields")
+    else:
+        fields = FIELDS
+    frequency = ensure_string(frequency, "frequency")
+    check_items_in_container([frequency], {"1d"}, "frequency")
+    start_date, end_date = ensure_date_range(start_date, end_date)
+
+    if start_date < 20150423:
+        raise ValueError("date out of range, start_date " "cannot be earlier than 2015-04-23")
+    data = get_client().execute(
+        "xueqiu.history", order_book_ids, start_date, end_date, fields, market
+    )
+    if not data:
+        return
+    df = pd.DataFrame(data)
+    df = df.set_index(["date", "order_book_id"])
+    df.sort_index(inplace=True)
+    pl = df.to_panel()
+    if len(pl.minor_axis) == 1:
+        pl = pl.minor_xs(pl.minor_axis[0])
+    if len(fields) == 1:
+        pl = pl[fields[0]]
+    return pl
```

## rqdatac/services/detail/__init__.py

 * *Ordering differences only*

```diff
@@ -1,3 +1,3 @@
-# -*- coding: utf-8 -*-
-#
-# Copyright 2017 Ricequant, Inc
+# -*- coding: utf-8 -*-
+#
+# Copyright 2017 Ricequant, Inc
```

## rqdatac/services/detail/adjust_price.py

 * *Ordering differences only*

```diff
@@ -1,164 +1,164 @@
-# -*- coding: utf-8 -*-
-#
-# Copyright 2018 Ricequant, Inc
-import time
-import datetime
-from threading import Lock
-
-import numpy as np
-import pandas as pd
-
-from rqdatac.client import get_client
-
-_lock = Lock()
-_expired = time.time()
-_ex_factor_cache = {}
-_split_factor_cache = {}
-
-MIN_DATE = pd.Timestamp(1800, 1, 1)
-
-
-def get_ex_factor_for(order_book_ids, market):
-    with _lock:
-        _prepare_ex_factor_for(order_book_ids, market)
-        return {ob: _ex_factor_cache[ob] for ob in order_book_ids}
-
-
-def _prepare_ex_factor_for(order_book_ids, market):
-    global _ex_factor_cache, _expired, _split_factor_cache
-    if _expired < time.time():
-        _ex_factor_cache.clear()
-        _split_factor_cache.clear()
-        _expired = time.time() + 3600 * 8
-
-    missing = [ob for ob in order_book_ids if ob not in _ex_factor_cache]
-    if not missing:
-        return
-
-    data = get_client().execute('_get_ex_factor', missing, market)
-    if not data:
-        _ex_factor_cache.update((ob, None) for ob in missing)
-        return
-
-    remain = set(r['order_book_id'] for r in data)
-    # for each order_book_id, we add an init ex_factor value
-    data.extend({'order_book_id': o, 'ex_date': MIN_DATE, 'ex_cum_factor': 1.0} for o in remain)
-
-    df = pd.DataFrame(data)
-    df = df[df.ex_date <= datetime.datetime.today()]
-    df.set_index('ex_date', inplace=True)
-    df.sort_index(inplace=True)
-
-    for order_book_id, s in df.groupby('order_book_id')['ex_cum_factor']:
-        _ex_factor_cache[order_book_id] = s
-
-    for order_book_id in missing:
-        if order_book_id not in _ex_factor_cache:
-            _ex_factor_cache[order_book_id] = None
-
-
-def get_split_factor_for(order_book_ids, market):
-    with _lock:
-        _prepare_split_for(order_book_ids, market)
-        return {ob: _split_factor_cache[ob] for ob in order_book_ids}
-
-
-def _prepare_split_for(order_book_ids, market):
-    global _ex_factor_cache, _expired, _split_factor_cache
-    if _expired < time.time():
-        _ex_factor_cache.clear()
-        _split_factor_cache.clear()
-        _expired = time.time() + 3600 * 8
-
-    missing = [ob for ob in order_book_ids if ob not in _split_factor_cache]
-    if not missing:
-        return
-
-    data = get_client().execute('_get_split', missing, market)
-    if not data:
-        _split_factor_cache.update((ob, None) for ob in missing)
-        return
-
-    remain = set(r['order_book_id'] for r in data)
-    # for each order_book_id, we add an init split value
-    data.extend(
-        {
-            'order_book_id': ob,
-            'split_coefficient_to': 1.0,
-            'split_coefficient_from': 1.0,
-            'cum_factor': 1.0,
-            'ex_dividend_date': MIN_DATE,
-        } for ob in remain
-    )
-
-    df = pd.DataFrame(data)
-    df = df[df.ex_dividend_date <= datetime.datetime.today()]
-    df.set_index('ex_dividend_date', inplace=True)
-    df.sort_index(inplace=True)
-    df["cum_factor"] = df["split_coefficient_to"] / df["split_coefficient_from"]
-    df["cum_factor"] = df.groupby("order_book_id")["cum_factor"].cumprod()
-    for order_book_id, s in df.groupby('order_book_id')['cum_factor']:
-        s = s[~s.index.duplicated(keep='last')]
-        # split index 有可能重复
-        _split_factor_cache[order_book_id] = s.copy()
-
-    for order_book_id in missing:
-        if order_book_id not in _split_factor_cache:
-            _split_factor_cache[order_book_id] = None
-
-
-PRICE_FIELDS = {"low", "close", "limit_up", "limit_down", "unit_net_value", "open", "high"}
-
-FIELDS_NEED_TO_ADJUST = PRICE_FIELDS | {'volume'}
-
-
-def adjust_price_multi_df(df, order_book_ids, how, obid_slice_map, market):
-    r_map_fields = {f: i for i, f in enumerate(df.columns) if f in FIELDS_NEED_TO_ADJUST}
-    if not r_map_fields:
-        # 没有需要复权的字段
-        return
-    # 是否前复权
-    pre = how in ('pre', 'pre_volume')
-    volume_adjust_by_ex_factor = how in ('pre_volume', 'post_volume')
-
-    ex_factors = get_ex_factor_for(order_book_ids, market)
-    volume_adjust_factors = {}
-
-    if 'volume' in r_map_fields:
-        if not volume_adjust_by_ex_factor:
-            volume_adjust_factors = get_split_factor_for(order_book_ids, market)
-        else:
-            volume_adjust_factors = ex_factors
-
-    data = df.values
-    timestamps_level = df.index.get_level_values(1)
-    for order_book_id, slice_ in obid_slice_map.items():
-        if order_book_id not in order_book_ids:
-            continue
-        timestamps = timestamps_level[slice_]
-
-        def calculate_factor(factors_map, order_book_id):
-            factors = factors_map.get(order_book_id, None)
-            if factors is not None:
-                factor = np.take(factors.values, factors.index.searchsorted(timestamps, side='right') - 1)
-                if pre:
-                    factor /= factors.iloc[-1]
-                return factor
-
-        factor = calculate_factor(ex_factors, order_book_id)
-        if factor is None:
-            # 如果 ex_factor 为空，则不存在拆分及分红，无需后续处理
-            continue
-
-        if not volume_adjust_by_ex_factor:
-            factor_volume = calculate_factor(volume_adjust_factors, order_book_id)
-        else:
-            factor_volume = factor
-
-        for f, j in r_map_fields.items():
-            if f in PRICE_FIELDS:
-                data[slice_, j] *= factor
-                np.round(data[slice_, j], 4, out=data[slice_, j])
-            elif factor_volume is not None:
-                data[slice_, j] *= 1 / factor_volume
-                np.round(data[slice_, j], 4, out=data[slice_, j])
+# -*- coding: utf-8 -*-
+#
+# Copyright 2018 Ricequant, Inc
+import time
+import datetime
+from threading import Lock
+
+import numpy as np
+import pandas as pd
+
+from rqdatac.client import get_client
+
+_lock = Lock()
+_expired = time.time()
+_ex_factor_cache = {}
+_split_factor_cache = {}
+
+MIN_DATE = pd.Timestamp(1800, 1, 1)
+
+
+def get_ex_factor_for(order_book_ids, market):
+    with _lock:
+        _prepare_ex_factor_for(order_book_ids, market)
+        return {ob: _ex_factor_cache[ob] for ob in order_book_ids}
+
+
+def _prepare_ex_factor_for(order_book_ids, market):
+    global _ex_factor_cache, _expired, _split_factor_cache
+    if _expired < time.time():
+        _ex_factor_cache.clear()
+        _split_factor_cache.clear()
+        _expired = time.time() + 3600 * 8
+
+    missing = [ob for ob in order_book_ids if ob not in _ex_factor_cache]
+    if not missing:
+        return
+
+    data = get_client().execute('_get_ex_factor', missing, market)
+    if not data:
+        _ex_factor_cache.update((ob, None) for ob in missing)
+        return
+
+    remain = set(r['order_book_id'] for r in data)
+    # for each order_book_id, we add an init ex_factor value
+    data.extend({'order_book_id': o, 'ex_date': MIN_DATE, 'ex_cum_factor': 1.0} for o in remain)
+
+    df = pd.DataFrame(data)
+    df = df[df.ex_date <= datetime.datetime.today()]
+    df.set_index('ex_date', inplace=True)
+    df.sort_index(inplace=True)
+
+    for order_book_id, s in df.groupby('order_book_id')['ex_cum_factor']:
+        _ex_factor_cache[order_book_id] = s
+
+    for order_book_id in missing:
+        if order_book_id not in _ex_factor_cache:
+            _ex_factor_cache[order_book_id] = None
+
+
+def get_split_factor_for(order_book_ids, market):
+    with _lock:
+        _prepare_split_for(order_book_ids, market)
+        return {ob: _split_factor_cache[ob] for ob in order_book_ids}
+
+
+def _prepare_split_for(order_book_ids, market):
+    global _ex_factor_cache, _expired, _split_factor_cache
+    if _expired < time.time():
+        _ex_factor_cache.clear()
+        _split_factor_cache.clear()
+        _expired = time.time() + 3600 * 8
+
+    missing = [ob for ob in order_book_ids if ob not in _split_factor_cache]
+    if not missing:
+        return
+
+    data = get_client().execute('_get_split', missing, market)
+    if not data:
+        _split_factor_cache.update((ob, None) for ob in missing)
+        return
+
+    remain = set(r['order_book_id'] for r in data)
+    # for each order_book_id, we add an init split value
+    data.extend(
+        {
+            'order_book_id': ob,
+            'split_coefficient_to': 1.0,
+            'split_coefficient_from': 1.0,
+            'cum_factor': 1.0,
+            'ex_dividend_date': MIN_DATE,
+        } for ob in remain
+    )
+
+    df = pd.DataFrame(data)
+    df = df[df.ex_dividend_date <= datetime.datetime.today()]
+    df.set_index('ex_dividend_date', inplace=True)
+    df.sort_index(inplace=True)
+    df["cum_factor"] = df["split_coefficient_to"] / df["split_coefficient_from"]
+    df["cum_factor"] = df.groupby("order_book_id")["cum_factor"].cumprod()
+    for order_book_id, s in df.groupby('order_book_id')['cum_factor']:
+        s = s[~s.index.duplicated(keep='last')]
+        # split index 有可能重复
+        _split_factor_cache[order_book_id] = s.copy()
+
+    for order_book_id in missing:
+        if order_book_id not in _split_factor_cache:
+            _split_factor_cache[order_book_id] = None
+
+
+PRICE_FIELDS = {"low", "close", "limit_up", "limit_down", "unit_net_value", "open", "high"}
+
+FIELDS_NEED_TO_ADJUST = PRICE_FIELDS | {'volume'}
+
+
+def adjust_price_multi_df(df, order_book_ids, how, obid_slice_map, market):
+    r_map_fields = {f: i for i, f in enumerate(df.columns) if f in FIELDS_NEED_TO_ADJUST}
+    if not r_map_fields:
+        # 没有需要复权的字段
+        return
+    # 是否前复权
+    pre = how in ('pre', 'pre_volume')
+    volume_adjust_by_ex_factor = how in ('pre_volume', 'post_volume')
+
+    ex_factors = get_ex_factor_for(order_book_ids, market)
+    volume_adjust_factors = {}
+
+    if 'volume' in r_map_fields:
+        if not volume_adjust_by_ex_factor:
+            volume_adjust_factors = get_split_factor_for(order_book_ids, market)
+        else:
+            volume_adjust_factors = ex_factors
+
+    data = df.values
+    timestamps_level = df.index.get_level_values(1)
+    for order_book_id, slice_ in obid_slice_map.items():
+        if order_book_id not in order_book_ids:
+            continue
+        timestamps = timestamps_level[slice_]
+
+        def calculate_factor(factors_map, order_book_id):
+            factors = factors_map.get(order_book_id, None)
+            if factors is not None:
+                factor = np.take(factors.values, factors.index.searchsorted(timestamps, side='right') - 1)
+                if pre:
+                    factor /= factors.iloc[-1]
+                return factor
+
+        factor = calculate_factor(ex_factors, order_book_id)
+        if factor is None:
+            # 如果 ex_factor 为空，则不存在拆分及分红，无需后续处理
+            continue
+
+        if not volume_adjust_by_ex_factor:
+            factor_volume = calculate_factor(volume_adjust_factors, order_book_id)
+        else:
+            factor_volume = factor
+
+        for f, j in r_map_fields.items():
+            if f in PRICE_FIELDS:
+                data[slice_, j] *= factor
+                np.round(data[slice_, j], 4, out=data[slice_, j])
+            elif factor_volume is not None:
+                data[slice_, j] *= 1 / factor_volume
+                np.round(data[slice_, j], 4, out=data[slice_, j])
```

## rqdatac/services/detail/get_price_df.py

 * *Ordering differences only*

```diff
@@ -1,370 +1,370 @@
-# -*- coding: utf-8 -*-
-import warnings
-import datetime
-import numpy as np
-import pandas as pd
-
-from rqdatac.services.detail.resample_helper import resample_week_df
-from rqdatac.services.get_price import _ensure_fields
-
-from rqdatac.services.calendar import is_trading_date, current_trading_date, get_next_trading_date
-from rqdatac.utils import (
-    int14_to_datetime_v,
-    int8_to_datetime_v,
-    date_to_int8,
-    convert_bar_to_multi_df,
-)
-from rqdatac.client import get_client
-from rqdatac.services.future import get_dominant, current_real_contract
-from rqdatac.services.basic import instruments
-from rqdatac.services.stock_status import is_suspended
-from rqdatac.share.errors import PermissionDenied, MarketNotSupportError, NoSuchService
-
-DAYBAR_FIELDS = {
-    "future": ["settlement", "prev_settlement", "open_interest", "limit_up", "limit_down",
-               "day_session_open"],
-    "common": ["open", "close", "high", "low", "total_turnover", "volume", "prev_close"],
-    "stock": ["limit_up", "limit_down", "num_trades"],
-    "fund": ["limit_up", "limit_down", "num_trades", "iopv"],
-    "spot": ["settlement", "prev_settlement", "open_interest", "limit_up", "limit_down"],
-    "option": ["open_interest", "strike_price", "contract_multiplier", "prev_settlement", "settlement", "limit_up",
-               "limit_down", "day_session_open"],
-    "convertible": ["limit_up", "limit_down", "num_trades"],
-    "index": [],
-    "repo": ["num_trades"],
-}
-
-WEEKBAR_FIELDS = {
-    "future": ["settlement", "prev_settlement", "open_interest", "day_session_open"],
-    "common": ["open", "close", "high", "low", "total_turnover", "volume"],
-    "stock": ["num_trades"],
-    "fund": ["num_trades", "iopv"],
-    "spot": ["settlement", "prev_settlement", "open_interest"],
-    "option": ["open_interest", "strike_price", "contract_multiplier", "settlement", "day_session_open"],
-    "convertible": ["num_trades"],
-    "index": [],
-    "repo": ["num_trades"],
-}
-
-MINBAR_FIELDS = {
-    "future": ["trading_date", "open_interest"],
-    "common": ["open", "close", "high", "low", "total_turnover", "volume"],
-    "stock": ["num_trades"],
-    "fund": ["num_trades", "iopv"],
-    "spot": ["trading_date", "open_interest"],
-    "option": ["trading_date", "open_interest"],
-    "convertible": ["num_trades"],
-    "index": [],
-    "repo": [],
-}
-
-
-ZERO_FILL_FIELDS = frozenset({"total_turnover", "open_interest", "volume"})
-
-SPOT_DIRECTION_MAP = {0: "null", 1: "多支付空", 2: "空支付多", 3: "交收平衡"}
-
-
-def _get_pride_df_day(
-        order_book_ids,
-        start_date,
-        end_date,
-        duration,
-        fields,
-        adjust_type,
-        skip_suspended,
-        stocks,
-        funds,
-        indexes,
-        futures,
-        futures888,
-        spots,
-        options,
-        convertibles,
-        repos,
-        market
-):
-    fields, has_dominant_id = _ensure_fields(fields, DAYBAR_FIELDS, stocks, funds, futures, futures888, spots, options, convertibles, indexes, repos)
-    pf, obid_slice_map = get_daybar(order_book_ids, start_date, end_date, fields, duration, market)
-    if pf is not None:
-        return _adjust_pf(
-            pf,
-            order_book_ids,
-            stocks,
-            funds,
-            convertibles,
-            futures888,
-            start_date,
-            end_date,
-            has_dominant_id,
-            adjust_type,
-            skip_suspended,
-            obid_slice_map,
-            market,
-        )
-
-
-def get_price_df(
-        order_book_ids,
-        start_date,
-        end_date,
-        frequency,
-        duration,
-        fields,
-        adjust_type,
-        skip_suspended,
-        stocks,
-        funds,
-        indexes,
-        futures,
-        futures888,
-        spots,
-        options,
-        convertibles,
-        repos,
-        market
-):
-    live_date = current_trading_date()
-    if start_date > live_date:
-        return
-
-    if frequency == "d":
-        return _get_pride_df_day(
-            order_book_ids,
-            start_date,
-            end_date,
-            duration,
-            fields,
-            adjust_type,
-            skip_suspended,
-            stocks,
-            funds,
-            indexes,
-            futures,
-            futures888,
-            spots,
-            options,
-            convertibles,
-            repos,
-            market
-        )
-
-    fields, has_dominant_id = _ensure_fields(fields, MINBAR_FIELDS, stocks, funds, futures, futures888, spots, options, convertibles, indexes, repos)
-    try:
-        pf, obid_slice_map = get_minbar(order_book_ids, start_date, end_date, fields, duration, market)
-    except (PermissionDenied, MarketNotSupportError, NoSuchService):
-        warnings.warn("Not permit to get history minbar price")
-        pf = obid_slice_map = None
-
-    if end_date < live_date:
-        return _adjust_pf(
-            pf,
-            order_book_ids,
-            stocks,
-            funds,
-            convertibles,
-            futures888,
-            start_date,
-            end_date,
-            has_dominant_id,
-            adjust_type,
-            skip_suspended,
-            obid_slice_map,
-            market,
-        ) if pf is not None else None
-
-    def _trading_date_of(dt):
-        if 8 < dt.hour < 18:
-            return date_to_int8(dt)
-        return date_to_int8(get_next_trading_date(dt - datetime.timedelta(hours=4)))
-
-    live_date_str = '%d-%02d-%02d' % (live_date // 10000, live_date % 10000 // 100, live_date % 100)
-    live_obs = set(
-        ins.order_book_id for ins in instruments(order_book_ids)
-        if ins.de_listed_date == '0000-00-00' or ins.de_listed_date >= live_date_str
-    )
-
-    if pf is not None:
-        dts = pf.index.get_level_values(1)
-        for ob, slice_ in obid_slice_map.items():
-            if ob not in live_obs:
-                continue
-            if _trading_date_of(dts[slice_][-1]) == live_date:
-                live_obs.remove(ob)
-
-    if live_obs:
-        try:
-            today_pf, today_obid_slice_map = get_today_minbar(live_obs, fields, duration, market)
-            if today_pf is not None:
-                line_no, new_slice_map, available_dfs = 0, {}, []
-                index = today_pf.index.get_level_values(1)
-                for obid, slc in today_obid_slice_map.items():
-                    if _trading_date_of(index[slc.stop - 1]) != live_date:
-                        continue
-                    available_dfs.append(today_pf[slc])
-                    new_slice_map[obid] = slice(line_no, line_no + slc.stop - slc.start)
-                    line_no += slc.stop - slc.start
-                if available_dfs:
-                    today_pf, today_obid_slice_map = pd.concat(available_dfs), new_slice_map
-                else:
-                    today_pf, today_obid_slice_map = None, None
-
-            if pf is None:
-                pf, obid_slice_map = today_pf, today_obid_slice_map
-            elif today_pf is not None:
-                # sort_index 后 obid 为字典序
-                pf = pd.concat([pf, today_pf]).sort_index()
-                line_no, obid_slice_map = 0, {}
-                # np.unique 默认顺序也为字典序，因此不需要再调整
-                obids, counts = np.unique(pf.index.get_level_values(0), return_counts=True)
-                for obid, ct in zip(obids, counts):
-                    obid_slice_map[obid] = slice(line_no, line_no + ct, None)
-                    line_no += ct
-        except (PermissionDenied, MarketNotSupportError, NoSuchService):
-            warnings.warn("Not permit to get realtime minbar price")
-
-    if pf is not None:
-        return _adjust_pf(
-            pf,
-            order_book_ids,
-            stocks,
-            funds,
-            convertibles,
-            futures888,
-            start_date,
-            end_date,
-            has_dominant_id,
-            adjust_type,
-            skip_suspended,
-            obid_slice_map,
-            market,
-        )
-
-
-def get_daybar(order_book_ids, start_date, end_date, fields, duration, market):
-    data = get_client().execute(
-        "get_daybar_v", order_book_ids, start_date, end_date, fields, duration, market
-    )
-    data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
-    return convert_bar_to_multi_df(data, 'date', fields, int8_to_datetime_v, return_slice_map=True)
-
-
-def get_future_indx_daybar(order_book_ids, start_date, end_date, fields, duration=1, market="cn"):
-    data = get_client().execute(
-        "futures.get_future_indx_daybar_v", order_book_ids, start_date, end_date, fields, duration, market
-    )
-    data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
-    multi_df, _ = convert_bar_to_multi_df(data, 'date', fields, int8_to_datetime_v, return_slice_map=True)
-    if multi_df is not None:
-        return multi_df
-
-
-def get_minbar(order_book_ids, start_date, end_date, fields, duration, market):
-    data = get_client().execute(
-        "get_minbar_v", order_book_ids, start_date, end_date, fields, duration, market
-    )
-    data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
-    return convert_bar_to_multi_df(data, "datetime", fields, int14_to_datetime_v, return_slice_map=True)
-
-
-def get_today_minbar(order_book_ids, fields, duration, market="cn"):
-    futures_88 = [i for i in instruments(order_book_ids) if i.order_book_id.endswith('88') and i.type == 'Future']
-    real_contracts = {
-        i.order_book_id: current_real_contract(i.underlying_symbol, market)
-        for i in futures_88
-    }
-    real_contracts = {k: v for k, v in real_contracts.items() if v is not None}
-    order_book_ids = set(order_book_ids)
-    obs = list(order_book_ids.union(set(real_contracts.values())))
-    data = get_client().execute("get_today_minbar", obs, fields, duration, market)
-    data = dict(data)
-    data.update((ob, data.get(c)) for ob, c in real_contracts.items())
-    data = [(k, v) for k, v in data.items() if k in order_book_ids]
-    return convert_bar_to_multi_df(data, "datetime", fields, int14_to_datetime_v, return_slice_map=True)
-
-
-def _adjust_pf(
-        pf,
-        order_book_ids,
-        stocks,
-        funds,
-        convertibles,
-        futures888,
-        start_date,
-        end_date,
-        has_dominant_id,
-        adjust_type,
-        skip_suspended,
-        obid_slice_map,
-        market,
-):
-    adjust = (stocks or funds) and adjust_type in {"pre", "post", "pre_volume", "post_volume"}
-    if adjust:
-        from rqdatac.services.detail.adjust_price import adjust_price_multi_df
-        adjust_price_multi_df(pf, stocks + funds, adjust_type, obid_slice_map, market)
-    if has_dominant_id:
-        # 1.全为非正常合约 2.有期货类型合约并且指定dominant_id字段
-        # 只有满足其中一种才在返回字段中增加dominant_id
-        add_dominant_id(pf, futures888, obid_slice_map)
-    if skip_suspended and len(order_book_ids) == 1 and (stocks or convertibles):
-        pf = filter_suspended(pf, order_book_ids[0], start_date, end_date, len(convertibles) > 0, market)
-
-    if "trading_date" in pf:
-        td = pf.trading_date.values
-        dtidx = pf.index.get_level_values(1).map(date_to_int8)
-        new_td = np.where(~(td != td), td, dtidx.values).astype(int)
-        pf.trading_date = int8_to_datetime_v(new_td)
-
-    return pf
-
-
-def add_dominant_id(result, futures888, obid_slice_map):
-    from rqdatac.services.calendar import get_next_trading_date
-    def _may_shift_date(d):
-        # 夜盘的开始时间是晚上9点, 这时候对应的 dominant_id 应该是下一个交易日的 dominant_id
-        if d.hour >= 21 or not is_trading_date(d):
-            return pd.Timestamp(get_next_trading_date(d))
-        return d
-
-    for order_book_id, underlying in futures888.items():
-        if order_book_id in obid_slice_map:
-            slice_ = obid_slice_map[order_book_id]
-            dts = result.index.get_level_values(1)[slice_].map(_may_shift_date)
-            dominants = get_dominant(
-                underlying, dts[0].date(), dts[-1].date())
-            if dominants is not None:
-                result.loc[result.index[slice_], "dominant_id"] = np.take(
-                    dominants.values, dominants.index.searchsorted(dts, side="right") - 1)
-
-
-def filter_suspended(ret, order_book_id, start_date, end_date, is_convertible, market):
-    if is_convertible:
-        from rqdatac.services.convertible import is_suspended as is_convertible_suspend
-        s = is_convertible_suspend(order_book_id, start_date, end_date)
-    else:
-        s = is_suspended(order_book_id, start_date, end_date, market)
-    ret_date_index = ret.index.get_level_values(1)
-    index = s.index.union(ret_date_index)
-    s = s.reindex(index)
-    s = s.fillna(method="ffill")
-    s = s.loc[ret_date_index]
-    s = s[order_book_id] == False
-    return ret[s.values]
-
-
-def get_week_df(order_book_ids, start_date, end_date, fields, adjust_type, market, stocks, funds, indexes, futures,
-                futures888, spots, options, convertibles, repos):
-    fields, has_dominant_id = _ensure_fields(fields, WEEKBAR_FIELDS, stocks, funds, futures, futures888, spots,
-                                             options, convertibles, indexes, repos)
-    has_volume_field = 'volume' in fields
-    if not has_volume_field:
-        fields.append('volume')
-    df = get_price_df(
-        order_book_ids, start_date, end_date, 'd', 1, fields, adjust_type, False,
-        stocks, funds, indexes, futures, futures888, spots, options, convertibles, repos, market
-    )
-    if df is None:
-        return
-    res = resample_week_df(df, fields)
-    if not has_volume_field:
-        res.drop(columns=['volume'], inplace=True)
-    return res
+# -*- coding: utf-8 -*-
+import warnings
+import datetime
+import numpy as np
+import pandas as pd
+
+from rqdatac.services.detail.resample_helper import resample_week_df
+from rqdatac.services.get_price import _ensure_fields
+
+from rqdatac.services.calendar import is_trading_date, current_trading_date, get_next_trading_date
+from rqdatac.utils import (
+    int14_to_datetime_v,
+    int8_to_datetime_v,
+    date_to_int8,
+    convert_bar_to_multi_df,
+)
+from rqdatac.client import get_client
+from rqdatac.services.future import get_dominant, current_real_contract
+from rqdatac.services.basic import instruments
+from rqdatac.services.stock_status import is_suspended
+from rqdatac.share.errors import PermissionDenied, MarketNotSupportError, NoSuchService
+
+DAYBAR_FIELDS = {
+    "future": ["settlement", "prev_settlement", "open_interest", "limit_up", "limit_down",
+               "day_session_open"],
+    "common": ["open", "close", "high", "low", "total_turnover", "volume", "prev_close"],
+    "stock": ["limit_up", "limit_down", "num_trades"],
+    "fund": ["limit_up", "limit_down", "num_trades", "iopv"],
+    "spot": ["settlement", "prev_settlement", "open_interest", "limit_up", "limit_down"],
+    "option": ["open_interest", "strike_price", "contract_multiplier", "prev_settlement", "settlement", "limit_up",
+               "limit_down", "day_session_open"],
+    "convertible": ["limit_up", "limit_down", "num_trades"],
+    "index": [],
+    "repo": ["num_trades"],
+}
+
+WEEKBAR_FIELDS = {
+    "future": ["settlement", "prev_settlement", "open_interest", "day_session_open"],
+    "common": ["open", "close", "high", "low", "total_turnover", "volume"],
+    "stock": ["num_trades"],
+    "fund": ["num_trades", "iopv"],
+    "spot": ["settlement", "prev_settlement", "open_interest"],
+    "option": ["open_interest", "strike_price", "contract_multiplier", "settlement", "day_session_open"],
+    "convertible": ["num_trades"],
+    "index": [],
+    "repo": ["num_trades"],
+}
+
+MINBAR_FIELDS = {
+    "future": ["trading_date", "open_interest"],
+    "common": ["open", "close", "high", "low", "total_turnover", "volume"],
+    "stock": ["num_trades"],
+    "fund": ["num_trades", "iopv"],
+    "spot": ["trading_date", "open_interest"],
+    "option": ["trading_date", "open_interest"],
+    "convertible": ["num_trades"],
+    "index": [],
+    "repo": [],
+}
+
+
+ZERO_FILL_FIELDS = frozenset({"total_turnover", "open_interest", "volume"})
+
+SPOT_DIRECTION_MAP = {0: "null", 1: "多支付空", 2: "空支付多", 3: "交收平衡"}
+
+
+def _get_pride_df_day(
+        order_book_ids,
+        start_date,
+        end_date,
+        duration,
+        fields,
+        adjust_type,
+        skip_suspended,
+        stocks,
+        funds,
+        indexes,
+        futures,
+        futures888,
+        spots,
+        options,
+        convertibles,
+        repos,
+        market
+):
+    fields, has_dominant_id = _ensure_fields(fields, DAYBAR_FIELDS, stocks, funds, futures, futures888, spots, options, convertibles, indexes, repos)
+    pf, obid_slice_map = get_daybar(order_book_ids, start_date, end_date, fields, duration, market)
+    if pf is not None:
+        return _adjust_pf(
+            pf,
+            order_book_ids,
+            stocks,
+            funds,
+            convertibles,
+            futures888,
+            start_date,
+            end_date,
+            has_dominant_id,
+            adjust_type,
+            skip_suspended,
+            obid_slice_map,
+            market,
+        )
+
+
+def get_price_df(
+        order_book_ids,
+        start_date,
+        end_date,
+        frequency,
+        duration,
+        fields,
+        adjust_type,
+        skip_suspended,
+        stocks,
+        funds,
+        indexes,
+        futures,
+        futures888,
+        spots,
+        options,
+        convertibles,
+        repos,
+        market
+):
+    live_date = current_trading_date()
+    if start_date > live_date:
+        return
+
+    if frequency == "d":
+        return _get_pride_df_day(
+            order_book_ids,
+            start_date,
+            end_date,
+            duration,
+            fields,
+            adjust_type,
+            skip_suspended,
+            stocks,
+            funds,
+            indexes,
+            futures,
+            futures888,
+            spots,
+            options,
+            convertibles,
+            repos,
+            market
+        )
+
+    fields, has_dominant_id = _ensure_fields(fields, MINBAR_FIELDS, stocks, funds, futures, futures888, spots, options, convertibles, indexes, repos)
+    try:
+        pf, obid_slice_map = get_minbar(order_book_ids, start_date, end_date, fields, duration, market)
+    except (PermissionDenied, MarketNotSupportError, NoSuchService):
+        warnings.warn("Not permit to get history minbar price")
+        pf = obid_slice_map = None
+
+    if end_date < live_date:
+        return _adjust_pf(
+            pf,
+            order_book_ids,
+            stocks,
+            funds,
+            convertibles,
+            futures888,
+            start_date,
+            end_date,
+            has_dominant_id,
+            adjust_type,
+            skip_suspended,
+            obid_slice_map,
+            market,
+        ) if pf is not None else None
+
+    def _trading_date_of(dt):
+        if 8 < dt.hour < 18:
+            return date_to_int8(dt)
+        return date_to_int8(get_next_trading_date(dt - datetime.timedelta(hours=4)))
+
+    live_date_str = '%d-%02d-%02d' % (live_date // 10000, live_date % 10000 // 100, live_date % 100)
+    live_obs = set(
+        ins.order_book_id for ins in instruments(order_book_ids)
+        if ins.de_listed_date == '0000-00-00' or ins.de_listed_date >= live_date_str
+    )
+
+    if pf is not None:
+        dts = pf.index.get_level_values(1)
+        for ob, slice_ in obid_slice_map.items():
+            if ob not in live_obs:
+                continue
+            if _trading_date_of(dts[slice_][-1]) == live_date:
+                live_obs.remove(ob)
+
+    if live_obs:
+        try:
+            today_pf, today_obid_slice_map = get_today_minbar(live_obs, fields, duration, market)
+            if today_pf is not None:
+                line_no, new_slice_map, available_dfs = 0, {}, []
+                index = today_pf.index.get_level_values(1)
+                for obid, slc in today_obid_slice_map.items():
+                    if _trading_date_of(index[slc.stop - 1]) != live_date:
+                        continue
+                    available_dfs.append(today_pf[slc])
+                    new_slice_map[obid] = slice(line_no, line_no + slc.stop - slc.start)
+                    line_no += slc.stop - slc.start
+                if available_dfs:
+                    today_pf, today_obid_slice_map = pd.concat(available_dfs), new_slice_map
+                else:
+                    today_pf, today_obid_slice_map = None, None
+
+            if pf is None:
+                pf, obid_slice_map = today_pf, today_obid_slice_map
+            elif today_pf is not None:
+                # sort_index 后 obid 为字典序
+                pf = pd.concat([pf, today_pf]).sort_index()
+                line_no, obid_slice_map = 0, {}
+                # np.unique 默认顺序也为字典序，因此不需要再调整
+                obids, counts = np.unique(pf.index.get_level_values(0), return_counts=True)
+                for obid, ct in zip(obids, counts):
+                    obid_slice_map[obid] = slice(line_no, line_no + ct, None)
+                    line_no += ct
+        except (PermissionDenied, MarketNotSupportError, NoSuchService):
+            warnings.warn("Not permit to get realtime minbar price")
+
+    if pf is not None:
+        return _adjust_pf(
+            pf,
+            order_book_ids,
+            stocks,
+            funds,
+            convertibles,
+            futures888,
+            start_date,
+            end_date,
+            has_dominant_id,
+            adjust_type,
+            skip_suspended,
+            obid_slice_map,
+            market,
+        )
+
+
+def get_daybar(order_book_ids, start_date, end_date, fields, duration, market):
+    data = get_client().execute(
+        "get_daybar_v", order_book_ids, start_date, end_date, fields, duration, market
+    )
+    data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
+    return convert_bar_to_multi_df(data, 'date', fields, int8_to_datetime_v, return_slice_map=True)
+
+
+def get_future_indx_daybar(order_book_ids, start_date, end_date, fields, duration=1, market="cn"):
+    data = get_client().execute(
+        "futures.get_future_indx_daybar_v", order_book_ids, start_date, end_date, fields, duration, market
+    )
+    data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
+    multi_df, _ = convert_bar_to_multi_df(data, 'date', fields, int8_to_datetime_v, return_slice_map=True)
+    if multi_df is not None:
+        return multi_df
+
+
+def get_minbar(order_book_ids, start_date, end_date, fields, duration, market):
+    data = get_client().execute(
+        "get_minbar_v", order_book_ids, start_date, end_date, fields, duration, market
+    )
+    data = [(obid, {k: np.frombuffer(*v) for k, v in d.items()}) for obid, d in data]
+    return convert_bar_to_multi_df(data, "datetime", fields, int14_to_datetime_v, return_slice_map=True)
+
+
+def get_today_minbar(order_book_ids, fields, duration, market="cn"):
+    futures_88 = [i for i in instruments(order_book_ids) if i.order_book_id.endswith('88') and i.type == 'Future']
+    real_contracts = {
+        i.order_book_id: current_real_contract(i.underlying_symbol, market)
+        for i in futures_88
+    }
+    real_contracts = {k: v for k, v in real_contracts.items() if v is not None}
+    order_book_ids = set(order_book_ids)
+    obs = list(order_book_ids.union(set(real_contracts.values())))
+    data = get_client().execute("get_today_minbar", obs, fields, duration, market)
+    data = dict(data)
+    data.update((ob, data.get(c)) for ob, c in real_contracts.items())
+    data = [(k, v) for k, v in data.items() if k in order_book_ids]
+    return convert_bar_to_multi_df(data, "datetime", fields, int14_to_datetime_v, return_slice_map=True)
+
+
+def _adjust_pf(
+        pf,
+        order_book_ids,
+        stocks,
+        funds,
+        convertibles,
+        futures888,
+        start_date,
+        end_date,
+        has_dominant_id,
+        adjust_type,
+        skip_suspended,
+        obid_slice_map,
+        market,
+):
+    adjust = (stocks or funds) and adjust_type in {"pre", "post", "pre_volume", "post_volume"}
+    if adjust:
+        from rqdatac.services.detail.adjust_price import adjust_price_multi_df
+        adjust_price_multi_df(pf, stocks + funds, adjust_type, obid_slice_map, market)
+    if has_dominant_id:
+        # 1.全为非正常合约 2.有期货类型合约并且指定dominant_id字段
+        # 只有满足其中一种才在返回字段中增加dominant_id
+        add_dominant_id(pf, futures888, obid_slice_map)
+    if skip_suspended and len(order_book_ids) == 1 and (stocks or convertibles):
+        pf = filter_suspended(pf, order_book_ids[0], start_date, end_date, len(convertibles) > 0, market)
+
+    if "trading_date" in pf:
+        td = pf.trading_date.values
+        dtidx = pf.index.get_level_values(1).map(date_to_int8)
+        new_td = np.where(~(td != td), td, dtidx.values).astype(int)
+        pf.trading_date = int8_to_datetime_v(new_td)
+
+    return pf
+
+
+def add_dominant_id(result, futures888, obid_slice_map):
+    from rqdatac.services.calendar import get_next_trading_date
+    def _may_shift_date(d):
+        # 夜盘的开始时间是晚上9点, 这时候对应的 dominant_id 应该是下一个交易日的 dominant_id
+        if d.hour >= 21 or not is_trading_date(d):
+            return pd.Timestamp(get_next_trading_date(d))
+        return d
+
+    for order_book_id, underlying in futures888.items():
+        if order_book_id in obid_slice_map:
+            slice_ = obid_slice_map[order_book_id]
+            dts = result.index.get_level_values(1)[slice_].map(_may_shift_date)
+            dominants = get_dominant(
+                underlying, dts[0].date(), dts[-1].date())
+            if dominants is not None:
+                result.loc[result.index[slice_], "dominant_id"] = np.take(
+                    dominants.values, dominants.index.searchsorted(dts, side="right") - 1)
+
+
+def filter_suspended(ret, order_book_id, start_date, end_date, is_convertible, market):
+    if is_convertible:
+        from rqdatac.services.convertible import is_suspended as is_convertible_suspend
+        s = is_convertible_suspend(order_book_id, start_date, end_date)
+    else:
+        s = is_suspended(order_book_id, start_date, end_date, market)
+    ret_date_index = ret.index.get_level_values(1)
+    index = s.index.union(ret_date_index)
+    s = s.reindex(index)
+    s = s.fillna(method="ffill")
+    s = s.loc[ret_date_index]
+    s = s[order_book_id] == False
+    return ret[s.values]
+
+
+def get_week_df(order_book_ids, start_date, end_date, fields, adjust_type, market, stocks, funds, indexes, futures,
+                futures888, spots, options, convertibles, repos):
+    fields, has_dominant_id = _ensure_fields(fields, WEEKBAR_FIELDS, stocks, funds, futures, futures888, spots,
+                                             options, convertibles, indexes, repos)
+    has_volume_field = 'volume' in fields
+    if not has_volume_field:
+        fields.append('volume')
+    df = get_price_df(
+        order_book_ids, start_date, end_date, 'd', 1, fields, adjust_type, False,
+        stocks, funds, indexes, futures, futures888, spots, options, convertibles, repos, market
+    )
+    if df is None:
+        return
+    res = resample_week_df(df, fields)
+    if not has_volume_field:
+        res.drop(columns=['volume'], inplace=True)
+    return res
```

## rqdatac/services/detail/resample_helper.py

 * *Ordering differences only*

```diff
@@ -1,65 +1,65 @@
-# -*- coding: utf-8 -*-
-#
-# Copyright 2017 Ricequant, Inc
-import numpy as np
-import pandas as pd
-from rqdatac.services.calendar import (get_previous_trading_date,
-                                       is_trading_date)
-
-FIELD_METHOD_MAP = {
-    "open": "first",
-    "close": "last",
-    "iopv": "last",
-    "high": np.maximum,
-    "low": np.minimum,
-    "limit_up": np.maximum,
-    "limit_down": np.minimum,
-    "total_turnover": np.add,
-    "volume": np.add,
-    "num_trades": np.add,
-    "acc_net_value": "last",
-    "unit_net_value": "last",
-    "discount_rate": "last",
-    "settlement": "last",
-    "prev_settlement": "last",
-    "open_interest": "last",
-    "basis_spread": "last",
-    "date": "last",
-    "trading_date": "last",
-    "datetime": "last",
-}
-FIELD_METHOD_MAP2 = {
-    "open": "first",
-    "day_session_open": "first",
-    "close": "last",
-    "iopv": "last",
-    "high": "max",
-    "low": "min",
-    "total_turnover": "sum",
-    "volume": "sum",
-    "num_trades": "sum",
-    "acc_net_value": "last",
-    "unit_net_value": "last",
-    "discount_rate": "last",
-    "settlement": "last",
-    "prev_settlement": "last",
-    "open_interest": "last",
-    "basis_spread": "last",
-    "contract_multiplier": "last",
-    "strike_price": "last",
-}
-
-
-def _update_weekly_trading_date_index(idx):
-    if is_trading_date(idx[1]):
-        return idx
-    return idx[0], pd.Timestamp(get_previous_trading_date(idx[1]))
-
-
-def resample_week_df(df, fields):
-    hows = {field: FIELD_METHOD_MAP2[field] for field in fields}
-    res = df.groupby(level="order_book_id").resample("W-Fri", level=1).agg(hows)
-    res.index = res.index.map(_update_weekly_trading_date_index)
-    res = res[~res.index.duplicated(keep='first')]
-    res.sort_index(inplace=True)
-    return res
+# -*- coding: utf-8 -*-
+#
+# Copyright 2017 Ricequant, Inc
+import numpy as np
+import pandas as pd
+from rqdatac.services.calendar import (get_previous_trading_date,
+                                       is_trading_date)
+
+FIELD_METHOD_MAP = {
+    "open": "first",
+    "close": "last",
+    "iopv": "last",
+    "high": np.maximum,
+    "low": np.minimum,
+    "limit_up": np.maximum,
+    "limit_down": np.minimum,
+    "total_turnover": np.add,
+    "volume": np.add,
+    "num_trades": np.add,
+    "acc_net_value": "last",
+    "unit_net_value": "last",
+    "discount_rate": "last",
+    "settlement": "last",
+    "prev_settlement": "last",
+    "open_interest": "last",
+    "basis_spread": "last",
+    "date": "last",
+    "trading_date": "last",
+    "datetime": "last",
+}
+FIELD_METHOD_MAP2 = {
+    "open": "first",
+    "day_session_open": "first",
+    "close": "last",
+    "iopv": "last",
+    "high": "max",
+    "low": "min",
+    "total_turnover": "sum",
+    "volume": "sum",
+    "num_trades": "sum",
+    "acc_net_value": "last",
+    "unit_net_value": "last",
+    "discount_rate": "last",
+    "settlement": "last",
+    "prev_settlement": "last",
+    "open_interest": "last",
+    "basis_spread": "last",
+    "contract_multiplier": "last",
+    "strike_price": "last",
+}
+
+
+def _update_weekly_trading_date_index(idx):
+    if is_trading_date(idx[1]):
+        return idx
+    return idx[0], pd.Timestamp(get_previous_trading_date(idx[1]))
+
+
+def resample_week_df(df, fields):
+    hows = {field: FIELD_METHOD_MAP2[field] for field in fields}
+    res = df.groupby(level="order_book_id").resample("W-Fri", level=1).agg(hows)
+    res.index = res.index.map(_update_weekly_trading_date_index)
+    res = res[~res.index.duplicated(keep='first')]
+    res.sort_index(inplace=True)
+    return res
```

## rqdatac/services/orm/__init__.py

 * *Ordering differences only*

```diff
@@ -1 +1 @@
-# coding=utf-8
+# coding=utf-8
```

## rqdatac/services/orm/pit_financials_ex.py

 * *Ordering differences only*

```diff
@@ -1,406 +1,406 @@
-BALANCE_SHEET_FIELDS = [
-    "adjusted_earnings_per_share",
-    "deferred_expense",
-    "dividend_payable",
-    "short_term_debt",
-    "financial_liabilities",
-    "equity_parent_company",
-    "tax_payable",
-    "payroll_payable",
-    "intangible_assets",
-    "deferred_revenue",
-    "total_assets",
-    "depreciation_reserve",
-    "accts_payable",
-    "deferred_income_tax_liabilities",
-    "other_fees_payable",
-    "financial_asset_hold_to_maturity",
-    "construction_in_progress",
-    "goodwill",
-    "other_payable",
-    "other_payable_interest_dividend",
-    "long_term_receivables",
-    "accrued_expense",
-    "capital_reserve",
-    "accumulated_depreciation",
-    "surplus_reserve",
-    "real_estate_investment",
-    "engineer_material",
-    "minority_interest",
-    "provision",
-    "oil_and_gas_assets",
-    "long_term_liabilities_due_one_year",
-    "bond_payable",
-    "net_fixed_assets",
-    "cash_equivalent",
-    "financial_asset_available_for_sale",
-    "estimated_liabilities",
-    "bad_debt_reserve",
-    "other_non_current_liabilities",
-    "non_current_liability_due_one_year",
-    "non_current_assets",
-    "long_term_deferred_expenses",
-    "net_long_term_equity_investment",
-    "bill_receivable",
-    "non_current_asset_due_one_year",
-    "total_equity_and_liabilities",
-    "long_term_equity_investment",
-    "total_liabilities",
-    "prepaid_tax",
-    "grants_received",
-    "paid_in_capital",
-    "housing_revolving_funds",
-    "notes_payable",
-    "long_term_payable",
-    "other_non_current_assets",
-    "interest_receivable",
-    "impairment_intangible_assets",
-    "advance_from_customers",
-    "deferred_income_tax_assets",
-    "other_current_assets",
-    "fixed_asset_to_be_disposed",
-    "financial_asset_held_for_trading",
-    "short_term_loans",
-    "inventory",
-    "deferred_income",
-    "interest_payable",
-    "non_current_liabilities",
-    "dividend_receivable",
-    "other_current_liabilities",
-    "current_assets",
-    "long_term_loans",
-    "capitalized_biological_assets",
-    "current_liabilities",
-    "contract_work",
-    "total_equity",
-    "prepayment",
-    "net_accts_receivable",
-    "undistributed_profit",
-    "equity_preferred_stock",
-    "other_accts_receivable",
-    "other_equity_investment",
-    "other_illiquidy_financial_assets",
-    "life_reserve_receivable",
-    "reinsurance_payable",
-    "sub_issue_security_proceeds",
-    "fixed_deposits",
-    "insurance_receivable",
-    "policy_dividend_payable",
-    "mortgaged_loan",
-    "comission_payable",
-    "assets_hold_for_sale",
-    "foreign_currency_converted_difference",
-    "refundable_capital_deposits",
-    "other_reserves",
-    "loans_advances_to_customers",
-    "perpetual_equity_debt",
-    "debt_investment",
-    "financial_lease_receivable",
-    "uncertained_impairment_losses",
-    "fund_providing",
-    "unclaimed_reserve_receivable",
-    "unearned_reserve_receivable",
-    "preference_shares",
-    "insurer_deposit_investment",
-    "resale_financial_assets",
-    "borrowings_capital",
-    "other_composite_income",
-    "deposits_from_interbank",
-    "financial_lease_payable",
-    "independent_account_assets",
-    "bill_accts_receivable",
-    "derivative_financial_liabilities",
-    "derivative_financial_assets",
-    "borrowings_from_central_banks",
-    "buy_back_security_proceeds",
-    "other_receivables_interest_dividend",
-    "contract_assets",
-    "reinsurance_receivable",
-    "compensation_payable",
-    "use_right_assets",
-    "perpetual_bond",
-    "loan_account_receivables",
-    "health_reserve_receivable",
-    "insurance_contract_reserve",
-    "settlement_provision",
-    "financial_receivable",
-    "reinsurance_reserve_receivable",
-    "other_liabilities",
-    "unclaimed_indemnity_reserve",
-    "treasury_stock",
-    "subrogation_fee_receivable",
-    "uncertained_premium_reserve",
-    "client_provision",
-    "refundable_deposits",
-    "independent_account_liabilities",
-    "liabilities_hold_for_sale",
-    "life_insurance_reserve",
-    "security_deposits_received",
-    "trade_risk_allowances",
-    "other_assets",
-    "general_reserve",
-    "other_equity_instruments",
-    "deposits_of_interbank",
-    "interbank_deposits",
-    "deposits",
-    "bill_accts_payable",
-    "insurer_mortgage_loan",
-    "specific_reserve",
-    "lend_capital",
-    "seat_costs",
-    "client_deposits",
-    "accrued_staff_costs",
-    "health_insurance_reserve",
-    "other_debt_investment",
-    "precious_metals",
-    "advance_insurance",
-    "contract_liabilities",
-    "lease_liabilities",
-    "proxy_security_proceeds",
-    "consumable_biological_assets",
-    'raw_materials',
-    'materials_in_transit',
-    'development_product',
-    'construction_product',
-    'rental_development_product',
-    'development_cost',
-    'undeveloped_land',
-    'commodity_stocks',
-    'semi_finished_goods',
-    'inprocess_goods',
-    'finished_goods',
-    'low_value_consumption_goods',
-    'installment_sales',
-    'goods_in_consignors',
-    'goods_purchased',
-    'fuel',
-    'wrappage',
-    'materials_in_consignors',
-    'materials_purchased',
-    'materials_cost_variance',
-    'spare_parts',
-    'flight_spare_parts',
-    'expensive_turnover_parts',
-    'common_equipment',
-    'other_inventory',
-    'total_fixed_assets',
-    'total_construction_in_progress',
-    'deposit_in_associate',
-    'debt_assets',
-    'debit_of_associate',
-    'total_shares',
-    'total_a_shares',
-    'circulation_a_shares',
-    'non_circulation_a_shares'
-]
-
-CASHFLOW_STATEMENT_FIELDS = [
-    "exchange_rate_change_effect",
-    "cash_paid_for_other_financing_activities",
-    "cash_received_from_investors",
-    "cash_from_operating_activities",
-    "cash_paid_to_financing_activities",
-    "fcff",
-    "cash_paid_for_employee",
-    "cash_paid_for_goods_and_services",
-    "cash_from_other_operating_activities",
-    "cash_received_from_disposal_of_asset",
-    "cash_received_from_sales_of_goods",
-    "deferred_expense_amortization",
-    "cash_paid_for_other_investment_activities",
-    "fcfe",
-    "cash_flow_from_financing_activities",
-    "cash_received_from_other_financing_activities",
-    "cash_paid_for_dividend_and_interest",
-    "cash_paid_for_debt",
-    "fixed_asset_depreciation",
-    "cash_paid_for_investment_activities",
-    "cash_paid_for_asset",
-    "cash_received_from_financing_activities",
-    "cash_flow_from_investing_activities",
-    "cash_received_from_investment_activities",
-    "net_inc_cash_and_equivalents",
-    "intangible_asset_amortization",
-    "depreciation_and_amortization",
-    "cash_paid_for_other_operation_activities",
-    "cash_received_from_financial_institution_borrows",
-    "cash_received_from_other_investment_activities",
-    "cash_paid_to_acquire_investment",
-    "cash_flow_from_operating_activities",
-    "cash_equivalent_increase",
-    "cash_paid_for_operation_activities",
-    "cash_paid_for_taxes",
-    "refunds_of_taxes",
-    "assets_depreciation_reserves",
-    "net_cash_deal_from_sub",
-    "net_cash_payment_from_sub",
-    "cash_received_from_interests_and_commissions",
-    "cash_paid_for_orignal_insurance",
-    "cash_paid_for_reinsurance",
-    "net_increase_from_repurchasing_business",
-    "net_increase_in_pledge_loans",
-    "cash_received_from_disposal_of_investment",
-    "cash_received_from_issuing_security",
-    "cash_received_from_reinsurance",
-    "cash_received_from_sub_issue_security",
-    "net_increase_from_central_bank",
-    "cash_received_from_minority_invest_subsidiaries",
-    "net_increase_from_trading_financial_assets",
-    "cash_received_from_investment",
-    "net_increase_from_loans_and_advances",
-    "cash_received_from_proxy_security",
-    "net_increase_from_disposing_financial_assets",
-    "end_period_cash_equivalent",
-    "net_increase_from__financing_buy_back",
-    "net_increase_from_insurer_deposit_investment",
-    "cash_paid_for_comissions",
-    "cash_received_from_original_insurance",
-    "cash_received_from_issuing_equity_instruments",
-    "dividends_paid_to_minority_by_subsidiaries",
-    "net_increase_from_lending_capital",
-    "cash_paid_for_policy_dividends",
-    "net_increase_from_financial_institutions",
-    "draw_back_canceled_loans",
-    "other_effecting_cash_equivalent_items",
-    "begin_period_cash_equivalent",
-    "net_increase_from_central_bank_and_banks",
-    "net_increase_from_operating_buy_back",
-    "net_increase_from_investing_buy_back",
-    "net_deposit_increase",
-    "net_increase_from_other_financial_institutions",
-]
-
-INCOME_STATEMENT_FIELDS = [
-    "total_income_minority",
-    "ga_expense",
-    "invest_income_associates",
-    "profit_from_operation",
-    "r_n_d",
-    "total_income",
-    "other_operating_revenue",
-    "total_income_parent_company",
-    "other_operating_cost",
-    "revenue",
-    "net_profit_parent_company",
-    "non_operating_revenue",
-    "selling_expense",
-    "ebitda",
-    "minority_profit",
-    "disposal_loss_on_asset",
-    "non_recurring_pnl",
-    "exchange_gains_or_losses",
-    "financing_expense",
-    "interest_expense",
-    "operating_revenue",
-    "net_profit",
-    "total_expense",
-    "fair_value_change_income",
-    "other_income",
-    "asset_impairment",
-    "adjust_asset_impairment",
-    "non_operating_expense",
-    "net_profit_deduct_non_recurring_pnl",
-    "profit_before_tax",
-    "sales_tax",
-    "basic_earnings_per_share",
-    "ebit",
-    "investment_income",
-    "income_tax",
-    "gross_profit",
-    "cost_of_goods_sold",
-    "interest_income",
-    "unrealised_investment_loss",
-    "fully_diluted_earnings_per_share",
-    "operating_expense",
-    "o_n_a_expense",
-    "credit_asset_impairment",
-    "adjust_credit_asset_impairment",
-    "disposal_income_on_asset",
-    "financing_interest_income",
-    "other_debt_investment_change",
-    "compensation_expense",
-    "other_net_income",
-    "reinsurance_income",
-    "insurance_commission_expense",
-    "corporate_credit_risk_change",
-    "net_open_hedge_income",
-    "other_effecting_net_profits_items",
-    "remearsured_other_income",
-    "other_revenue",
-    "net_commission_income",
-    "earned_premiums",
-    "foreign_currency_statement_converted_difference",
-    "classified_by_ownership",
-    "other_income_classified_income_statement",
-    "other_debt_investment_reserve",
-    "discontinued_operation_net_profit",
-    "premiums_income",
-    "policy_dividend_payout",
-    "other_income_equity_unclassified_income_statement",
-    "sub_issue_security_income",
-    "amortization_reinsurance_cost",
-    "assets_reclassified_other_income",
-    "commission_income",
-    "continuous_operation_net_profit",
-    "unearned_premium_reserve",
-    "classified_by_continuity_operation",
-    "other_effecting_total_profits_items",
-    "net_interest_income",
-    "cash_flow_hedging_effective_portion",
-    "financial_asset_available_for_sale_change",
-    "net_trust_income",
-    "other_income_unclassified_income_statement",
-    "other_income_parent_company",
-    "other_income_equity_classified_income_statement",
-    "net_proxy_security_income",
-    "premium_reserve",
-    "other_equity_instruments_change",
-    "commission_expense",
-    "refunded_premiums",
-    "other_income_minority",
-    "amortization_expense",
-    "amortization_premium_reserve",
-    "reinsurance_cost",
-    "financial_asset_hold_to_maturity_change",
-    "reinsurance",
-    "others",
-    "financing_interest_expense"
-]
-
-TTM_FIELDS = [
-    "operating_expenseTTM",
-    "operating_costTTM",
-    "net_invest_cashflowTTM",
-    "sale_service_render_cashTTM",
-    "ebitTTM",
-    "operating_revenueTTM",
-    "operating_profitTTM",
-    "ni_from_operatingTTM",
-    "net_cashflowTTM",
-    "net_finance_cashflowTTM",
-    "net_operate_cashflowTTM",
-    "operating_payoutTTM",
-    "asset_impairment_lossTTM",
-    "non_operating_net_incomeTTM",
-    "administration_expenseTTM",
-    "gross_profitTTM",
-    "total_operating_costTTM",
-    "financial_expenseTTM",
-    "ni_from_value_changeTTM",
-    "np_parent_company_ownersTTM",
-    "net_profitTTM",
-    "total_profitTTM",
-    "total_operating_revenueTTM"]
-
-MAINDATA_FIELDS = ["adjusted_net_profit", "return_on_equity_weighted_average"]
-
-RND_EXPENDITURE_SHEET_FIELDS = [
-    "expensed_rnd",
-    "capitalized_rnd",
-    "total_rnd",
-    "rnd_to_revenue",
-    "capitalized_rnd_ratio",
-    "rnd_employees",
-    "rnd_employees_ratio"]
-
-FIELDS_LIST_EX = RND_EXPENDITURE_SHEET_FIELDS + MAINDATA_FIELDS + TTM_FIELDS + INCOME_STATEMENT_FIELDS + CASHFLOW_STATEMENT_FIELDS + BALANCE_SHEET_FIELDS
+BALANCE_SHEET_FIELDS = [
+    "adjusted_earnings_per_share",
+    "deferred_expense",
+    "dividend_payable",
+    "short_term_debt",
+    "financial_liabilities",
+    "equity_parent_company",
+    "tax_payable",
+    "payroll_payable",
+    "intangible_assets",
+    "deferred_revenue",
+    "total_assets",
+    "depreciation_reserve",
+    "accts_payable",
+    "deferred_income_tax_liabilities",
+    "other_fees_payable",
+    "financial_asset_hold_to_maturity",
+    "construction_in_progress",
+    "goodwill",
+    "other_payable",
+    "other_payable_interest_dividend",
+    "long_term_receivables",
+    "accrued_expense",
+    "capital_reserve",
+    "accumulated_depreciation",
+    "surplus_reserve",
+    "real_estate_investment",
+    "engineer_material",
+    "minority_interest",
+    "provision",
+    "oil_and_gas_assets",
+    "long_term_liabilities_due_one_year",
+    "bond_payable",
+    "net_fixed_assets",
+    "cash_equivalent",
+    "financial_asset_available_for_sale",
+    "estimated_liabilities",
+    "bad_debt_reserve",
+    "other_non_current_liabilities",
+    "non_current_liability_due_one_year",
+    "non_current_assets",
+    "long_term_deferred_expenses",
+    "net_long_term_equity_investment",
+    "bill_receivable",
+    "non_current_asset_due_one_year",
+    "total_equity_and_liabilities",
+    "long_term_equity_investment",
+    "total_liabilities",
+    "prepaid_tax",
+    "grants_received",
+    "paid_in_capital",
+    "housing_revolving_funds",
+    "notes_payable",
+    "long_term_payable",
+    "other_non_current_assets",
+    "interest_receivable",
+    "impairment_intangible_assets",
+    "advance_from_customers",
+    "deferred_income_tax_assets",
+    "other_current_assets",
+    "fixed_asset_to_be_disposed",
+    "financial_asset_held_for_trading",
+    "short_term_loans",
+    "inventory",
+    "deferred_income",
+    "interest_payable",
+    "non_current_liabilities",
+    "dividend_receivable",
+    "other_current_liabilities",
+    "current_assets",
+    "long_term_loans",
+    "capitalized_biological_assets",
+    "current_liabilities",
+    "contract_work",
+    "total_equity",
+    "prepayment",
+    "net_accts_receivable",
+    "undistributed_profit",
+    "equity_preferred_stock",
+    "other_accts_receivable",
+    "other_equity_investment",
+    "other_illiquidy_financial_assets",
+    "life_reserve_receivable",
+    "reinsurance_payable",
+    "sub_issue_security_proceeds",
+    "fixed_deposits",
+    "insurance_receivable",
+    "policy_dividend_payable",
+    "mortgaged_loan",
+    "comission_payable",
+    "assets_hold_for_sale",
+    "foreign_currency_converted_difference",
+    "refundable_capital_deposits",
+    "other_reserves",
+    "loans_advances_to_customers",
+    "perpetual_equity_debt",
+    "debt_investment",
+    "financial_lease_receivable",
+    "uncertained_impairment_losses",
+    "fund_providing",
+    "unclaimed_reserve_receivable",
+    "unearned_reserve_receivable",
+    "preference_shares",
+    "insurer_deposit_investment",
+    "resale_financial_assets",
+    "borrowings_capital",
+    "other_composite_income",
+    "deposits_from_interbank",
+    "financial_lease_payable",
+    "independent_account_assets",
+    "bill_accts_receivable",
+    "derivative_financial_liabilities",
+    "derivative_financial_assets",
+    "borrowings_from_central_banks",
+    "buy_back_security_proceeds",
+    "other_receivables_interest_dividend",
+    "contract_assets",
+    "reinsurance_receivable",
+    "compensation_payable",
+    "use_right_assets",
+    "perpetual_bond",
+    "loan_account_receivables",
+    "health_reserve_receivable",
+    "insurance_contract_reserve",
+    "settlement_provision",
+    "financial_receivable",
+    "reinsurance_reserve_receivable",
+    "other_liabilities",
+    "unclaimed_indemnity_reserve",
+    "treasury_stock",
+    "subrogation_fee_receivable",
+    "uncertained_premium_reserve",
+    "client_provision",
+    "refundable_deposits",
+    "independent_account_liabilities",
+    "liabilities_hold_for_sale",
+    "life_insurance_reserve",
+    "security_deposits_received",
+    "trade_risk_allowances",
+    "other_assets",
+    "general_reserve",
+    "other_equity_instruments",
+    "deposits_of_interbank",
+    "interbank_deposits",
+    "deposits",
+    "bill_accts_payable",
+    "insurer_mortgage_loan",
+    "specific_reserve",
+    "lend_capital",
+    "seat_costs",
+    "client_deposits",
+    "accrued_staff_costs",
+    "health_insurance_reserve",
+    "other_debt_investment",
+    "precious_metals",
+    "advance_insurance",
+    "contract_liabilities",
+    "lease_liabilities",
+    "proxy_security_proceeds",
+    "consumable_biological_assets",
+    'raw_materials',
+    'materials_in_transit',
+    'development_product',
+    'construction_product',
+    'rental_development_product',
+    'development_cost',
+    'undeveloped_land',
+    'commodity_stocks',
+    'semi_finished_goods',
+    'inprocess_goods',
+    'finished_goods',
+    'low_value_consumption_goods',
+    'installment_sales',
+    'goods_in_consignors',
+    'goods_purchased',
+    'fuel',
+    'wrappage',
+    'materials_in_consignors',
+    'materials_purchased',
+    'materials_cost_variance',
+    'spare_parts',
+    'flight_spare_parts',
+    'expensive_turnover_parts',
+    'common_equipment',
+    'other_inventory',
+    'total_fixed_assets',
+    'total_construction_in_progress',
+    'deposit_in_associate',
+    'debt_assets',
+    'debit_of_associate',
+    'total_shares',
+    'total_a_shares',
+    'circulation_a_shares',
+    'non_circulation_a_shares'
+]
+
+CASHFLOW_STATEMENT_FIELDS = [
+    "exchange_rate_change_effect",
+    "cash_paid_for_other_financing_activities",
+    "cash_received_from_investors",
+    "cash_from_operating_activities",
+    "cash_paid_to_financing_activities",
+    "fcff",
+    "cash_paid_for_employee",
+    "cash_paid_for_goods_and_services",
+    "cash_from_other_operating_activities",
+    "cash_received_from_disposal_of_asset",
+    "cash_received_from_sales_of_goods",
+    "deferred_expense_amortization",
+    "cash_paid_for_other_investment_activities",
+    "fcfe",
+    "cash_flow_from_financing_activities",
+    "cash_received_from_other_financing_activities",
+    "cash_paid_for_dividend_and_interest",
+    "cash_paid_for_debt",
+    "fixed_asset_depreciation",
+    "cash_paid_for_investment_activities",
+    "cash_paid_for_asset",
+    "cash_received_from_financing_activities",
+    "cash_flow_from_investing_activities",
+    "cash_received_from_investment_activities",
+    "net_inc_cash_and_equivalents",
+    "intangible_asset_amortization",
+    "depreciation_and_amortization",
+    "cash_paid_for_other_operation_activities",
+    "cash_received_from_financial_institution_borrows",
+    "cash_received_from_other_investment_activities",
+    "cash_paid_to_acquire_investment",
+    "cash_flow_from_operating_activities",
+    "cash_equivalent_increase",
+    "cash_paid_for_operation_activities",
+    "cash_paid_for_taxes",
+    "refunds_of_taxes",
+    "assets_depreciation_reserves",
+    "net_cash_deal_from_sub",
+    "net_cash_payment_from_sub",
+    "cash_received_from_interests_and_commissions",
+    "cash_paid_for_orignal_insurance",
+    "cash_paid_for_reinsurance",
+    "net_increase_from_repurchasing_business",
+    "net_increase_in_pledge_loans",
+    "cash_received_from_disposal_of_investment",
+    "cash_received_from_issuing_security",
+    "cash_received_from_reinsurance",
+    "cash_received_from_sub_issue_security",
+    "net_increase_from_central_bank",
+    "cash_received_from_minority_invest_subsidiaries",
+    "net_increase_from_trading_financial_assets",
+    "cash_received_from_investment",
+    "net_increase_from_loans_and_advances",
+    "cash_received_from_proxy_security",
+    "net_increase_from_disposing_financial_assets",
+    "end_period_cash_equivalent",
+    "net_increase_from__financing_buy_back",
+    "net_increase_from_insurer_deposit_investment",
+    "cash_paid_for_comissions",
+    "cash_received_from_original_insurance",
+    "cash_received_from_issuing_equity_instruments",
+    "dividends_paid_to_minority_by_subsidiaries",
+    "net_increase_from_lending_capital",
+    "cash_paid_for_policy_dividends",
+    "net_increase_from_financial_institutions",
+    "draw_back_canceled_loans",
+    "other_effecting_cash_equivalent_items",
+    "begin_period_cash_equivalent",
+    "net_increase_from_central_bank_and_banks",
+    "net_increase_from_operating_buy_back",
+    "net_increase_from_investing_buy_back",
+    "net_deposit_increase",
+    "net_increase_from_other_financial_institutions",
+]
+
+INCOME_STATEMENT_FIELDS = [
+    "total_income_minority",
+    "ga_expense",
+    "invest_income_associates",
+    "profit_from_operation",
+    "r_n_d",
+    "total_income",
+    "other_operating_revenue",
+    "total_income_parent_company",
+    "other_operating_cost",
+    "revenue",
+    "net_profit_parent_company",
+    "non_operating_revenue",
+    "selling_expense",
+    "ebitda",
+    "minority_profit",
+    "disposal_loss_on_asset",
+    "non_recurring_pnl",
+    "exchange_gains_or_losses",
+    "financing_expense",
+    "interest_expense",
+    "operating_revenue",
+    "net_profit",
+    "total_expense",
+    "fair_value_change_income",
+    "other_income",
+    "asset_impairment",
+    "adjust_asset_impairment",
+    "non_operating_expense",
+    "net_profit_deduct_non_recurring_pnl",
+    "profit_before_tax",
+    "sales_tax",
+    "basic_earnings_per_share",
+    "ebit",
+    "investment_income",
+    "income_tax",
+    "gross_profit",
+    "cost_of_goods_sold",
+    "interest_income",
+    "unrealised_investment_loss",
+    "fully_diluted_earnings_per_share",
+    "operating_expense",
+    "o_n_a_expense",
+    "credit_asset_impairment",
+    "adjust_credit_asset_impairment",
+    "disposal_income_on_asset",
+    "financing_interest_income",
+    "other_debt_investment_change",
+    "compensation_expense",
+    "other_net_income",
+    "reinsurance_income",
+    "insurance_commission_expense",
+    "corporate_credit_risk_change",
+    "net_open_hedge_income",
+    "other_effecting_net_profits_items",
+    "remearsured_other_income",
+    "other_revenue",
+    "net_commission_income",
+    "earned_premiums",
+    "foreign_currency_statement_converted_difference",
+    "classified_by_ownership",
+    "other_income_classified_income_statement",
+    "other_debt_investment_reserve",
+    "discontinued_operation_net_profit",
+    "premiums_income",
+    "policy_dividend_payout",
+    "other_income_equity_unclassified_income_statement",
+    "sub_issue_security_income",
+    "amortization_reinsurance_cost",
+    "assets_reclassified_other_income",
+    "commission_income",
+    "continuous_operation_net_profit",
+    "unearned_premium_reserve",
+    "classified_by_continuity_operation",
+    "other_effecting_total_profits_items",
+    "net_interest_income",
+    "cash_flow_hedging_effective_portion",
+    "financial_asset_available_for_sale_change",
+    "net_trust_income",
+    "other_income_unclassified_income_statement",
+    "other_income_parent_company",
+    "other_income_equity_classified_income_statement",
+    "net_proxy_security_income",
+    "premium_reserve",
+    "other_equity_instruments_change",
+    "commission_expense",
+    "refunded_premiums",
+    "other_income_minority",
+    "amortization_expense",
+    "amortization_premium_reserve",
+    "reinsurance_cost",
+    "financial_asset_hold_to_maturity_change",
+    "reinsurance",
+    "others",
+    "financing_interest_expense"
+]
+
+TTM_FIELDS = [
+    "operating_expenseTTM",
+    "operating_costTTM",
+    "net_invest_cashflowTTM",
+    "sale_service_render_cashTTM",
+    "ebitTTM",
+    "operating_revenueTTM",
+    "operating_profitTTM",
+    "ni_from_operatingTTM",
+    "net_cashflowTTM",
+    "net_finance_cashflowTTM",
+    "net_operate_cashflowTTM",
+    "operating_payoutTTM",
+    "asset_impairment_lossTTM",
+    "non_operating_net_incomeTTM",
+    "administration_expenseTTM",
+    "gross_profitTTM",
+    "total_operating_costTTM",
+    "financial_expenseTTM",
+    "ni_from_value_changeTTM",
+    "np_parent_company_ownersTTM",
+    "net_profitTTM",
+    "total_profitTTM",
+    "total_operating_revenueTTM"]
+
+MAINDATA_FIELDS = ["adjusted_net_profit", "return_on_equity_weighted_average"]
+
+RND_EXPENDITURE_SHEET_FIELDS = [
+    "expensed_rnd",
+    "capitalized_rnd",
+    "total_rnd",
+    "rnd_to_revenue",
+    "capitalized_rnd_ratio",
+    "rnd_employees",
+    "rnd_employees_ratio"]
+
+FIELDS_LIST_EX = RND_EXPENDITURE_SHEET_FIELDS + MAINDATA_FIELDS + TTM_FIELDS + INCOME_STATEMENT_FIELDS + CASHFLOW_STATEMENT_FIELDS + BALANCE_SHEET_FIELDS
```

## rqdatac/share/codec.py

 * *Ordering differences only*

```diff
@@ -1,176 +1,176 @@
-# -*- coding: utf-8 -*-
-import struct
-import sys
-from datetime import datetime, timedelta, date
-from decimal import Decimal
-from functools import partial
-from zlib import compress as zlib_compress, decompress as zlib_decompress
-
-import msgpack
-
-from .protocol import HEADER_FORMAT, COMPRESSION_METHOD, SERIALIZATION_TYPE
-
-
-def raise_(e):
-    raise e
-
-
-_EPOCH = datetime(1970, 1, 1)
-_EPOCH_DATE = _EPOCH.date()
-
-
-def _object_hook(obj):
-    if "__$dt__" in obj:
-        return _EPOCH + timedelta(seconds=obj["__$dt__"])
-    if "__$dl__" in obj:
-        return Decimal(obj["__$dl__"])
-    if "__$da__" in obj:
-        return _EPOCH_DATE + timedelta(days=obj["__$da__"])
-    return obj
-
-
-def _default(obj):
-    if isinstance(obj, datetime):
-        return {"__$dt__": int((obj - _EPOCH).total_seconds())}
-    if isinstance(obj, date):
-        return {"__$da__": (obj - _EPOCH_DATE).days}
-    if isinstance(obj, Decimal):
-        return {"__$dl__": obj.to_eng_string()}
-    return obj
-
-
-use_bin_type = False if sys.version_info[0] == 2 else True
-try:
-    msgpack.loads(b'\xa4test', raw=True)
-    msgpack_dumps = partial(msgpack.dumps, default=_default, use_bin_type=use_bin_type)
-    msgpack_loads = partial(msgpack.loads, object_hook=_object_hook, raw=False,
-                            max_str_len=2147483647,  # 2**32-1
-                            max_bin_len=2147483647,
-                            max_array_len=2147483647,
-                            max_map_len=2147483647,
-                            max_ext_len=2147483647
-                            )
-except TypeError:
-    msgpack_dumps = partial(msgpack.dumps, default=_default, use_bin_type=use_bin_type)
-    msgpack_loads = partial(msgpack.loads, object_hook=_object_hook, encoding="utf8")
-
-
-try:
-    import snappy
-
-    snappy_decompress = snappy.decompress
-    snappy_compress = snappy.compress
-except (ImportError, AttributeError):
-    snappy = None
-    snappy_compress = snappy_decompress = lambda *_: raise_(
-        RuntimeError(
-            "compression not support {}".format(COMPRESSION_METHOD[COMPRESSION_METHOD.SNAPPY])
-        )
-    )
-
-try:
-    import brotli
-
-    brotli_compress = partial(brotli.compress, quality=1)
-    brotli_decompress = brotli.decompress
-except ImportError:
-    brotli = None
-    brotli_compress = brotli_decompress = lambda *_: raise_(
-        RuntimeError(
-            "compression not support {}".format(COMPRESSION_METHOD[COMPRESSION_METHOD.BROTLI])
-        )
-    )
-
-try:
-    import zstandard as zstd
-    import threading
-    
-    class LocalZstd:
-        def __init__(self):
-            self._local = threading.local()
-
-        def compress(self, data):
-            if getattr(self._local, "compressor", None):
-                return self._local.compressor.compress(data)
-
-            self._local.compressor = zstd.ZstdCompressor(1)
-            return self._local.compressor.compress(data)
-
-        def decompress(self, data):
-            if getattr(self._local, "decompressor", None):
-                return self._local.decompressor.decompress(data)
-            self._local.decompressor = zstd.ZstdDecompressor()
-            return self._local.decompressor.decompress(data)
-
-    local_zstd = LocalZstd()
-    zstd_compress = local_zstd.compress
-    zstd_decompress = local_zstd.decompress
-except ImportError:
-    zstd = None
-    zstd_compress = zstd_decompress = lambda *_: raise_(
-        RuntimeError(
-            "compression not support {}".format(COMPRESSION_METHOD[COMPRESSION_METHOD.ZSTD])
-        )
-    )
-
-
-try:
-    import rapidjson as json
-except ImportError:
-    import json
-_json_dump = partial(json.dumps, default=_default)
-
-
-def json_dumps(*args, **kwargs):
-    return json.dumps(*args, default=_default, **kwargs).encode('utf-8')
-
-
-json_loads = partial(json.loads, object_hook=_object_hook)
-
-
-SERIALIZER = {
-    SERIALIZATION_TYPE.RAW: lambda x: x,
-    SERIALIZATION_TYPE.JSON: json_dumps,
-    SERIALIZATION_TYPE.MSGPACK: msgpack_dumps,
-}
-
-DESERIALIZER = {
-    SERIALIZATION_TYPE.RAW: lambda x: x,
-    SERIALIZATION_TYPE.JSON: json_loads,
-    SERIALIZATION_TYPE.MSGPACK: msgpack_loads,
-}
-
-COMPRESSION = {
-    COMPRESSION_METHOD.NONE: lambda x: x,
-    COMPRESSION_METHOD.SNAPPY: snappy_compress,
-    COMPRESSION_METHOD.ZLIB: zlib_compress,
-    COMPRESSION_METHOD.BROTLI: brotli_compress,
-    COMPRESSION_METHOD.ZSTD: zstd_compress,
-}
-
-DECOMPRESSION = {
-    COMPRESSION_METHOD.NONE: lambda x: x,
-    COMPRESSION_METHOD.SNAPPY: snappy_decompress,
-    COMPRESSION_METHOD.ZLIB: zlib_decompress,
-    COMPRESSION_METHOD.BROTLI: brotli_decompress,
-    COMPRESSION_METHOD.ZSTD: zstd_decompress,
-}
-
-
-_header_struct = struct.Struct(HEADER_FORMAT)
-pack_header = _header_struct.pack
-unpack_header = _header_struct.unpack
-
-
-def pack_one(data, mt, st, cm, force_compress=False):
-    # type: (...,int, int, int) -> bytes
-    data = SERIALIZER[st](data)
-    if force_compress or len(data) > 1024:
-        data = COMPRESSION[cm](data)
-    else:
-        cm = COMPRESSION_METHOD.NONE
-    return pack_header(mt, st, cm, len(data)) + data
-
-
-def unpack_one(data, st, cm):
-    return DESERIALIZER[st](DECOMPRESSION[cm](data))
+# -*- coding: utf-8 -*-
+import struct
+import sys
+from datetime import datetime, timedelta, date
+from decimal import Decimal
+from functools import partial
+from zlib import compress as zlib_compress, decompress as zlib_decompress
+
+import msgpack
+
+from .protocol import HEADER_FORMAT, COMPRESSION_METHOD, SERIALIZATION_TYPE
+
+
+def raise_(e):
+    raise e
+
+
+_EPOCH = datetime(1970, 1, 1)
+_EPOCH_DATE = _EPOCH.date()
+
+
+def _object_hook(obj):
+    if "__$dt__" in obj:
+        return _EPOCH + timedelta(seconds=obj["__$dt__"])
+    if "__$dl__" in obj:
+        return Decimal(obj["__$dl__"])
+    if "__$da__" in obj:
+        return _EPOCH_DATE + timedelta(days=obj["__$da__"])
+    return obj
+
+
+def _default(obj):
+    if isinstance(obj, datetime):
+        return {"__$dt__": int((obj - _EPOCH).total_seconds())}
+    if isinstance(obj, date):
+        return {"__$da__": (obj - _EPOCH_DATE).days}
+    if isinstance(obj, Decimal):
+        return {"__$dl__": obj.to_eng_string()}
+    return obj
+
+
+use_bin_type = False if sys.version_info[0] == 2 else True
+try:
+    msgpack.loads(b'\xa4test', raw=True)
+    msgpack_dumps = partial(msgpack.dumps, default=_default, use_bin_type=use_bin_type)
+    msgpack_loads = partial(msgpack.loads, object_hook=_object_hook, raw=False,
+                            max_str_len=2147483647,  # 2**32-1
+                            max_bin_len=2147483647,
+                            max_array_len=2147483647,
+                            max_map_len=2147483647,
+                            max_ext_len=2147483647
+                            )
+except TypeError:
+    msgpack_dumps = partial(msgpack.dumps, default=_default, use_bin_type=use_bin_type)
+    msgpack_loads = partial(msgpack.loads, object_hook=_object_hook, encoding="utf8")
+
+
+try:
+    import snappy
+
+    snappy_decompress = snappy.decompress
+    snappy_compress = snappy.compress
+except (ImportError, AttributeError):
+    snappy = None
+    snappy_compress = snappy_decompress = lambda *_: raise_(
+        RuntimeError(
+            "compression not support {}".format(COMPRESSION_METHOD[COMPRESSION_METHOD.SNAPPY])
+        )
+    )
+
+try:
+    import brotli
+
+    brotli_compress = partial(brotli.compress, quality=1)
+    brotli_decompress = brotli.decompress
+except ImportError:
+    brotli = None
+    brotli_compress = brotli_decompress = lambda *_: raise_(
+        RuntimeError(
+            "compression not support {}".format(COMPRESSION_METHOD[COMPRESSION_METHOD.BROTLI])
+        )
+    )
+
+try:
+    import zstandard as zstd
+    import threading
+    
+    class LocalZstd:
+        def __init__(self):
+            self._local = threading.local()
+
+        def compress(self, data):
+            if getattr(self._local, "compressor", None):
+                return self._local.compressor.compress(data)
+
+            self._local.compressor = zstd.ZstdCompressor(1)
+            return self._local.compressor.compress(data)
+
+        def decompress(self, data):
+            if getattr(self._local, "decompressor", None):
+                return self._local.decompressor.decompress(data)
+            self._local.decompressor = zstd.ZstdDecompressor()
+            return self._local.decompressor.decompress(data)
+
+    local_zstd = LocalZstd()
+    zstd_compress = local_zstd.compress
+    zstd_decompress = local_zstd.decompress
+except ImportError:
+    zstd = None
+    zstd_compress = zstd_decompress = lambda *_: raise_(
+        RuntimeError(
+            "compression not support {}".format(COMPRESSION_METHOD[COMPRESSION_METHOD.ZSTD])
+        )
+    )
+
+
+try:
+    import rapidjson as json
+except ImportError:
+    import json
+_json_dump = partial(json.dumps, default=_default)
+
+
+def json_dumps(*args, **kwargs):
+    return json.dumps(*args, default=_default, **kwargs).encode('utf-8')
+
+
+json_loads = partial(json.loads, object_hook=_object_hook)
+
+
+SERIALIZER = {
+    SERIALIZATION_TYPE.RAW: lambda x: x,
+    SERIALIZATION_TYPE.JSON: json_dumps,
+    SERIALIZATION_TYPE.MSGPACK: msgpack_dumps,
+}
+
+DESERIALIZER = {
+    SERIALIZATION_TYPE.RAW: lambda x: x,
+    SERIALIZATION_TYPE.JSON: json_loads,
+    SERIALIZATION_TYPE.MSGPACK: msgpack_loads,
+}
+
+COMPRESSION = {
+    COMPRESSION_METHOD.NONE: lambda x: x,
+    COMPRESSION_METHOD.SNAPPY: snappy_compress,
+    COMPRESSION_METHOD.ZLIB: zlib_compress,
+    COMPRESSION_METHOD.BROTLI: brotli_compress,
+    COMPRESSION_METHOD.ZSTD: zstd_compress,
+}
+
+DECOMPRESSION = {
+    COMPRESSION_METHOD.NONE: lambda x: x,
+    COMPRESSION_METHOD.SNAPPY: snappy_decompress,
+    COMPRESSION_METHOD.ZLIB: zlib_decompress,
+    COMPRESSION_METHOD.BROTLI: brotli_decompress,
+    COMPRESSION_METHOD.ZSTD: zstd_decompress,
+}
+
+
+_header_struct = struct.Struct(HEADER_FORMAT)
+pack_header = _header_struct.pack
+unpack_header = _header_struct.unpack
+
+
+def pack_one(data, mt, st, cm, force_compress=False):
+    # type: (...,int, int, int) -> bytes
+    data = SERIALIZER[st](data)
+    if force_compress or len(data) > 1024:
+        data = COMPRESSION[cm](data)
+    else:
+        cm = COMPRESSION_METHOD.NONE
+    return pack_header(mt, st, cm, len(data)) + data
+
+
+def unpack_one(data, st, cm):
+    return DESERIALIZER[st](DECOMPRESSION[cm](data))
```

## rqdatac/share/errors.py

 * *Ordering differences only*

```diff
@@ -1,84 +1,84 @@
-# -*- coding: utf-8 -*-
-
-
-class RQDataError(Exception):
-    rqerrno = 1
-    DEFAULT_MSG = "default rqdata error"
-
-    def __str__(self):
-        s = super(Exception, self).__str__()
-        if s:
-            return s
-        return self.DEFAULT_MSG
-
-    def __repr__(self):
-        return "{}: {}".format(self.__class__.__name__, self.__str__())
-
-
-class AuthenticationFailed(RQDataError):
-    rqerrno = 2
-    DEFAULT_MSG = "authentication failed."
-
-
-class ErrorFromBackend(RQDataError):
-    rqerrno = 3
-    DEFAULT_MSG = "raise error from backend"
-    pass
-
-
-class PermissionDenied(ErrorFromBackend):
-    rqerrno = 4
-    DEFAULT_MSG = "permission denied"
-
-
-class NoSuchService(ErrorFromBackend):
-    rqerrno = 7
-    DEFAULT_MSG = "Can't found the request service"
-
-
-class QuotaExceeded(ErrorFromBackend):
-    rqerrno = 5
-    DEFAULT_MSG = "quota exceeded"
-
-
-class MarketNotSupportError(ErrorFromBackend):
-    rqerrno = 6
-    DEFAULT_MSG = "market not supported yet."
-
-
-class InternalError(RQDataError):
-    rqerrno = -1
-    DEFAULT_MSG = "Server raised an error and can't handle it."
-
-
-class GatewayError(InternalError):
-    rqerrno = -2
-    DEFAULT_MSG = "Can't communicate with gateway."
-
-
-class BadRequest(ErrorFromBackend):
-    rqerrno = 400
-    DEFAULT_MSG = "Bad Request Content"
-
-
-class OverwriteWarning(Warning):
-    pass
-
-
-_ERROR_MAP = {}
-
-
-def __go(lcs):
-    global _ERROR_MAP
-    _ERROR_MAP = {v.rqerrno: v for k, v in lcs.items() if hasattr(v, "rqerrno")}
-
-
-__go(locals())
-del __go
-
-
-def get_error(errorno):
-    return _ERROR_MAP.get(errorno, RQDataError)
-
-
-__all__ = tuple(i.__name__ for i in _ERROR_MAP.values()) + ("get_error",)
+# -*- coding: utf-8 -*-
+
+
+class RQDataError(Exception):
+    rqerrno = 1
+    DEFAULT_MSG = "default rqdata error"
+
+    def __str__(self):
+        s = super(Exception, self).__str__()
+        if s:
+            return s
+        return self.DEFAULT_MSG
+
+    def __repr__(self):
+        return "{}: {}".format(self.__class__.__name__, self.__str__())
+
+
+class AuthenticationFailed(RQDataError):
+    rqerrno = 2
+    DEFAULT_MSG = "authentication failed."
+
+
+class ErrorFromBackend(RQDataError):
+    rqerrno = 3
+    DEFAULT_MSG = "raise error from backend"
+    pass
+
+
+class PermissionDenied(ErrorFromBackend):
+    rqerrno = 4
+    DEFAULT_MSG = "permission denied"
+
+
+class NoSuchService(ErrorFromBackend):
+    rqerrno = 7
+    DEFAULT_MSG = "Can't found the request service"
+
+
+class QuotaExceeded(ErrorFromBackend):
+    rqerrno = 5
+    DEFAULT_MSG = "quota exceeded"
+
+
+class MarketNotSupportError(ErrorFromBackend):
+    rqerrno = 6
+    DEFAULT_MSG = "market not supported yet."
+
+
+class InternalError(RQDataError):
+    rqerrno = -1
+    DEFAULT_MSG = "Server raised an error and can't handle it."
+
+
+class GatewayError(InternalError):
+    rqerrno = -2
+    DEFAULT_MSG = "Can't communicate with gateway."
+
+
+class BadRequest(ErrorFromBackend):
+    rqerrno = 400
+    DEFAULT_MSG = "Bad Request Content"
+
+
+class OverwriteWarning(Warning):
+    pass
+
+
+_ERROR_MAP = {}
+
+
+def __go(lcs):
+    global _ERROR_MAP
+    _ERROR_MAP = {v.rqerrno: v for k, v in lcs.items() if hasattr(v, "rqerrno")}
+
+
+__go(locals())
+del __go
+
+
+def get_error(errorno):
+    return _ERROR_MAP.get(errorno, RQDataError)
+
+
+__all__ = tuple(i.__name__ for i in _ERROR_MAP.values()) + ("get_error",)
```

## rqdatac/share/protocol.py

 * *Ordering differences only*

```diff
@@ -1,76 +1,76 @@
-# -*- coding: utf-8 -*-
-
-"""
-    2 bytes    |1 byte |1 byte |            4 bytes            |
-----------------------------------------------------------------
-|   Msg Type   |   ST  |   CM  |           Body Length         |
-----------------------------------------------------------------
-
-Msg Type: 消息类型
-ST: Serialization Type, 序列化方式
-CM: Compression Method, 压缩方式
-Body Length: 包体长度，不包含头
-
-little-endian
-"""
-
-
-def with_metaclass(mcls):
-    def decorator(cls):
-        body = vars(cls).copy()
-        # clean out class body
-        body.pop("__dict__", None)
-        body.pop("__weakref__", None)
-        return mcls(cls.__name__, cls.__bases__, body)
-
-    return decorator
-
-
-class SimpleEnum(type):
-    def __new__(mcs, name, bases, attrs):
-        mapping = {v: k for k, v in attrs.items() if not k.startswith("_")}
-        attrs["__map"] = mapping
-        attrs["__key"] = frozenset(mapping.keys())
-        return type.__new__(mcs, name, bases, attrs)
-
-    def __getitem__(self, item):
-        _map = self.__dict__["__map"]
-        if item not in self.__dict__["__key"]:
-            return "unknown %s(%s)" % (self.__name__, item)
-        return _map[item]
-
-    def __contains__(self, item):
-        return item in self.__dict__["__key"]
-
-
-@with_metaclass(SimpleEnum)
-class MSG_TYPE:
-    HANDSHAKE = 0
-    REQUEST = 1
-    RESPONSE = 2
-    ERROR = 3
-    STREAM_START = 4
-    STREAM_END = 5
-    FEED = 6
-    TABLE = 7
-    TABLE2 = 8
-
-
-@with_metaclass(SimpleEnum)
-class SERIALIZATION_TYPE:
-    RAW = 0
-    JSON = 1
-    MSGPACK = 2
-
-
-@with_metaclass(SimpleEnum)
-class COMPRESSION_METHOD:
-    NONE = 0
-    SNAPPY = 1
-    ZLIB = 2
-    BROTLI = 3
-    ZSTD = 4
-
-
-HEADER_FORMAT = "<HBBI"
-HEADER_LENGTH = 8
+# -*- coding: utf-8 -*-
+
+"""
+    2 bytes    |1 byte |1 byte |            4 bytes            |
+----------------------------------------------------------------
+|   Msg Type   |   ST  |   CM  |           Body Length         |
+----------------------------------------------------------------
+
+Msg Type: 消息类型
+ST: Serialization Type, 序列化方式
+CM: Compression Method, 压缩方式
+Body Length: 包体长度，不包含头
+
+little-endian
+"""
+
+
+def with_metaclass(mcls):
+    def decorator(cls):
+        body = vars(cls).copy()
+        # clean out class body
+        body.pop("__dict__", None)
+        body.pop("__weakref__", None)
+        return mcls(cls.__name__, cls.__bases__, body)
+
+    return decorator
+
+
+class SimpleEnum(type):
+    def __new__(mcs, name, bases, attrs):
+        mapping = {v: k for k, v in attrs.items() if not k.startswith("_")}
+        attrs["__map"] = mapping
+        attrs["__key"] = frozenset(mapping.keys())
+        return type.__new__(mcs, name, bases, attrs)
+
+    def __getitem__(self, item):
+        _map = self.__dict__["__map"]
+        if item not in self.__dict__["__key"]:
+            return "unknown %s(%s)" % (self.__name__, item)
+        return _map[item]
+
+    def __contains__(self, item):
+        return item in self.__dict__["__key"]
+
+
+@with_metaclass(SimpleEnum)
+class MSG_TYPE:
+    HANDSHAKE = 0
+    REQUEST = 1
+    RESPONSE = 2
+    ERROR = 3
+    STREAM_START = 4
+    STREAM_END = 5
+    FEED = 6
+    TABLE = 7
+    TABLE2 = 8
+
+
+@with_metaclass(SimpleEnum)
+class SERIALIZATION_TYPE:
+    RAW = 0
+    JSON = 1
+    MSGPACK = 2
+
+
+@with_metaclass(SimpleEnum)
+class COMPRESSION_METHOD:
+    NONE = 0
+    SNAPPY = 1
+    ZLIB = 2
+    BROTLI = 3
+    ZSTD = 4
+
+
+HEADER_FORMAT = "<HBBI"
+HEADER_LENGTH = 8
```

## Comparing `rqdatac-3.0.6.dist-info/METADATA` & `rqdatac-3.0.7.1.dist-info/METADATA`

 * *Files 3% similar despite different names*

```diff
@@ -1,17 +1,15 @@
 Metadata-Version: 2.1
 Name: rqdatac
-Version: 3.0.6
+Version: 3.0.7.1
 Summary: Ricequant Data SDK
 Home-page: https://www.ricequant.com/doc/rqdata-institutional#research-version
+Download-URL: https://pypi.org/
 Author: Ricequant
 Author-email: public@ricequant.com
-License: UNKNOWN
-Download-URL: https://pypi.org/
-Platform: UNKNOWN
 Classifier: Programming Language :: Python
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.6
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
@@ -58,9 +56,7 @@
 - [Init](https://www.ricequant.com/doc/rqdata-institutional#research-init)
 - [API Doc](https://www.ricequant.com/doc/rqdata-institutional#research-API)
 - [Change Log](https://www.ricequant.com/doc/rqdata-institutional#research-init)
 
 ## Have A Try
 - Get free access to [RQData](https://www.ricequant.com/welcome/trial/rqdata-cloud ).
 - Learn more [details](https://www.ricequant.com/welcome/rqdata).
-
-
```

## Comparing `rqdatac-3.0.6.dist-info/RECORD` & `rqdatac-3.0.7.1.dist-info/RECORD`

 * *Files 14% similar despite different names*

```diff
@@ -1,52 +1,52 @@
-rqdatac/__init__.py,sha256=a0HbcG9uHohaM-skdDcCD1aTqou4KFAa5d9PLuzmN6I,967
-rqdatac/__init__.pyi,sha256=TySe_FcaM6CGIilA8xLtq3cgN4b1QYYmUtr69TM6_bs,10668
-rqdatac/_internal.py,sha256=abdi2JnDfRvt4JDIArQJuAYAgdKEwHV8ZtRAuw_fOR8,934
-rqdatac/_version.py,sha256=AKE71PtqkpHqW8jXugxZr3Tm83Oh0ZDlE3DZM9ZfnVY,518
-rqdatac/client.py,sha256=pauqhPhvnY3bmWMMJ67e_DCqUdnWYL_s86lxTkGrStg,10387
-rqdatac/connection.cp39-win_amd64.pyd,sha256=5uHbWTFdG03y6Gh0U9wethmgAZBHP5RGApG2tK8oTXg,139776
-rqdatac/connection.cpp,sha256=KwiKuKOh7ZIelC1LncKMgskAN0_ml0GXD-SuA7thLp0,768200
-rqdatac/connection_pool.py,sha256=--mQnkbEFk0BbSsGpiHZKrijyut0niR4OsqGaR2-Y2U,2239
-rqdatac/decorators.py,sha256=cEGPnC2AlXHtt9Vsdxv7324beivEEYjMIFjv51EWZU0,4447
-rqdatac/rqdatah_helper.py,sha256=MmWLVsZ5ZiXcgs_cSeztZ2SL5F6R-bkh-f9LNBZiZMw,3072
-rqdatac/thread_local.py,sha256=ywvXoXa1L4LtFyAFBtEZGvkjvbPQFI-7Gb3mhxZXld8,2140
-rqdatac/utils.py,sha256=y9cOK2STswXy9eC-9309UKde7svzni1Jeoz_BtA-i2I,10929
-rqdatac/validators.py,sha256=lN3S7GXjJ-TLzfhVqj1UgEtcyK9Sm2E4uMoySFVWhzA,9265
+rqdatac/__init__.py,sha256=WJEtBrWnh-eQeMQvmjm2Q9UjBTXr9MYV2obH0BMotTQ,934
+rqdatac/__init__.pyi,sha256=PI4pJaxCHuOHoqORvE8ykHE1ZIe5AMgyE7itRhavkyQ,8402
+rqdatac/_internal.py,sha256=5bfToHhuGdXweJjxz0VOv0KgIo0RZGfz8t8R29B9_TA,895
+rqdatac/_version.py,sha256=aGdbde6QG7rQJIk5l4ls-_vDzh4cLLwwptqOo4BBzD0,499
+rqdatac/client.py,sha256=tXfNVm-Yu0WjPDhv_KY7IvvnEsXNQVZgBnLGddfYYrc,10102
+rqdatac/connection.cpp,sha256=j6th0Fe4wUMCf2_e0PRXWnUMuwPCeRO4SVy7H4kbCmk,768538
+rqdatac/connection.cpython-39-darwin.so,sha256=yk5YcelqKctnTi7DxzGvB1H3YZfnqs8lfYEZH8pLwVk,185696
+rqdatac/connection_pool.py,sha256=WhuG3kLn4pLdm3152P7_0-fXfudbsVHBUUO3TylD3Hc,2173
+rqdatac/decorators.py,sha256=hVryEqJ1xRqiv12JckTvoLhWee3OoseEbju02QZFe1Q,4299
+rqdatac/rqdatah_helper.py,sha256=bxRdBdBFBf48hMMmpQy7EQXI4qkYHKmzb4B9doamxHU,2967
+rqdatac/thread_local.py,sha256=8UTP-B0bhao0bnyDI5HLuKOY2MRnzY-BL4VTbOin_zQ,2082
+rqdatac/utils.py,sha256=kchqRpma_yLEFkZA30WXImy_bew9p0k1DxkApFpVN4M,10573
+rqdatac/validators.py,sha256=Lxk1TuBIGClenS0KKlELcWzNwkp0h1I8W4x6pWfkoZU,9015
 rqdatac/services/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-rqdatac/services/async_live_md_client.py,sha256=r3wOAAYAZ-tiVmOo6gVJHa9TJ-7762zO5suHlRLDg4k,6792
-rqdatac/services/basic.py,sha256=gIZU51IFvJQ7Xm_pG_vfrXhy982nockJ1M-HoSzK82Y,74860
-rqdatac/services/calendar.py,sha256=_AI5pkoJasPJ8qCh3RcMjg7RqzuUw-BVgy9gnjXBEs8,6202
-rqdatac/services/concept.py,sha256=l7dGWo6sMsnlyKQClRkMcaxlxOcIX7PoucvgV5MwBhI,2470
-rqdatac/services/consensus.py,sha256=N157k0uWkOowqcqgcX_KqV7BNYGbXFCRduNp267VaSY,47501
-rqdatac/services/constant.py,sha256=IbnKoILR2wXLoqcVJlFJdtMOnHzYhC2i06qfjPkSeCs,10141
-rqdatac/services/convertible.py,sha256=z_-2QrrqFQCz08OKjMgBATjkTKlevn7MDoLe7jv9oA8,29339
-rqdatac/services/extra.py,sha256=MXt5zBsRGitRIpDrT_IzLrIhAPnb99l-Wv7gXL90WZE,2405
-rqdatac/services/factor.py,sha256=TQCaP1LgQT6ZZvMZdopSfrU9993wBspB5kblwsRnXzY,33958
-rqdatac/services/financial.py,sha256=5gr9K2KjnOE1gkw3gAfVly3TGA20vYYp6BTLdJGIfJc,12561
-rqdatac/services/future.py,sha256=DTfSAdCbaPMnMyz52UrPHJc_O6xOFnNSc58UrpwGNFE,33768
-rqdatac/services/get_capital_flow.py,sha256=zDPF2hgN0u43bv88nn5rszKNY1yjHImmi6Q0x3lBA7c,13532
-rqdatac/services/get_price.py,sha256=wk6zEvMioQmT6RryKTScWj5yAJVK6y5_qFJcCOUftK0,29756
-rqdatac/services/index.py,sha256=n_bXgktyxqE2RmXgjsxOM4lhzDyF1VbqZ7scDH9bvAI,8880
-rqdatac/services/ksh_auction_info.py,sha256=BAHp6f5DfuO3qwyylLWU6UO5ZW4ZARQuGPAXowpVJbI,6473
-rqdatac/services/live.py,sha256=fN2htMMevo8G7oxKU7xSUTLktcafEN2jgPSs4McbXGY,15816
-rqdatac/services/live_md_client.py,sha256=ZFH826cpE8Fq0nrld1_1ue29wNyz2TL6WriAM34puHI,17180
-rqdatac/services/market_data.py,sha256=wclRal_EomNyrNTgtaw1GTkb5EuibnJ6cj_G9kT_oL4,20995
-rqdatac/services/options.py,sha256=0bEwy6Phv6riliwmoRlboLUQO6mzBM2PDTlkDxAqB9k,12650
-rqdatac/services/shenwan.py,sha256=42LrrMfy8F20OgcdSxRcP62p6MHEMjl0Hq-LGKtmHRI,9995
-rqdatac/services/stock_status.py,sha256=1eJJOCeDeMnsTmQRWKGYjjO-EvxU2r7HTePgExp9Oi0,29976
-rqdatac/services/structured_fund.py,sha256=EuHPDy4x0yEhsa8UFmPquRkPYehT7vFMUdfStoCXH78,2310
-rqdatac/services/tmall.py,sha256=xnguR3EtsUgS2pOhuKSIntuYMD5Av0RQ43-o928E6oU,2268
-rqdatac/services/xueqiu.py,sha256=05EjY0arr3czJqcSW7eUaUNHLCg_oR-Op1dz2FnJAlY,3649
-rqdatac/services/detail/__init__.py,sha256=km3ukXA_kKk738F7IUc_8mjfC8xys_k0X7O4U1yu6KU,61
-rqdatac/services/detail/adjust_price.py,sha256=h96rZdV4BkUzXF6hfIz9fT1CBcJF5uCnFcXIbbK2hOg,5733
-rqdatac/services/detail/get_price_df.py,sha256=cQP2kq3wQEVthbszUsz5O65UQUgOLslyI0zo0_5qxXY,14077
-rqdatac/services/detail/resample_helper.py,sha256=EjcyKO3l4exvS8i8DAre6NdlrX27o4m0k8lHFgd8C6c,1833
-rqdatac/services/orm/__init__.py,sha256=ely2PttjgSv7vKdzskuD1rtK_l_UOpmxJSz8isrveD0,16
-rqdatac/services/orm/pit_financials_ex.py,sha256=igBoSVTivx7AT8ogsDlI8rl7kLHg3VE62AoXGRbaUtw,12814
+rqdatac/services/async_live_md_client.py,sha256=6AUZ4tY0pMIthMNuBJcP_eu4ibzDT58kfQ0rJRvCzz0,6605
+rqdatac/services/basic.py,sha256=mM9jHB4nxhF9C6T1j_QsaALaZxq5d4_0RFS3Wv1n220,72801
+rqdatac/services/calendar.py,sha256=wn75DNmR9c_QJr_8roCh7vN_4YkLk3kuLfr425HhRRY,6005
+rqdatac/services/concept.py,sha256=gEx4Hzmomd0Dwqt26JwKu1n8L85R-LJphDD5D-Dw9NQ,2406
+rqdatac/services/consensus.py,sha256=efGfMWcoeZcb5hzVh9lqQdpt9Y_RyOaCCTAkKW4Pc5I,46256
+rqdatac/services/constant.py,sha256=Vsi1RHObKoxsTyp_qRSNm2luf-j2C58nBv0QABAyE0o,9902
+rqdatac/services/convertible.py,sha256=8LWzEbEOGiaqONtNnEDvdMdQwh78G4LDgeBYdbexhW4,28626
+rqdatac/services/extra.py,sha256=lN4JujaGHwnFUI64_oGoHMmKJNMGGW5jabI2Mid6DD0,2337
+rqdatac/services/factor.py,sha256=MZZV8ooKaKAxYbcj33nWJALdgbNj08KosznAD5E6e44,33046
+rqdatac/services/financial.py,sha256=vLLQx8aR9RLttTAKbhnCVEUViJh8UbxgtRPcz1QcoF0,12232
+rqdatac/services/future.py,sha256=pI2puE37fV2ptQnQtQBIDSVPoXnsRpA_HwROMTTFqcQ,32997
+rqdatac/services/get_capital_flow.py,sha256=Yvy-1UCQUmB9tzlPNNiGFpISCuB99MkwHjXu5GjlM60,13146
+rqdatac/services/get_price.py,sha256=pQS0l_HhPD6i5cl2vJvRJ3GU3x02GAf66zTw3LqWmmY,29061
+rqdatac/services/index.py,sha256=X3k75QvrmRgs1MfkpgesfIWzugyelCh2vmdvlUxQfk4,8664
+rqdatac/services/ksh_auction_info.py,sha256=r4OTYLJtddbBBeELbavkrRRYcBPMVbyzDRvNFEjLoY4,6306
+rqdatac/services/live.py,sha256=YnOSCyvg4yNyYtDPUaHzgScQqChqbaAjLcxxxPaRiKA,15323
+rqdatac/services/live_md_client.py,sha256=7gAGqj1wknQRr-2yIwHQlr2W4T0YtHZS-SvCgUkA42o,16723
+rqdatac/services/market_data.py,sha256=EFVuTb_ST9yqDjgJlofVF7AN8TZ-8JVtU7DGrDFkKqk,20431
+rqdatac/services/options.py,sha256=RXSxrBBUlxWsZkJh7jOqHgxnGdFu0y1fN6Gsn7NUtz4,13814
+rqdatac/services/shenwan.py,sha256=U32iGw7coe1vzQML1R8Z5qeWh4XM-8xy0dhAdixQ3gU,9711
+rqdatac/services/stock_status.py,sha256=y_kLHAnZOKh7GDl56I83Uga-cmli4VuDFhRYg19pmzg,29233
+rqdatac/services/structured_fund.py,sha256=N_apy65YHLCjVLIk8Qdfcq8UYtZR3Z7gJtj6bw8ktfs,2234
+rqdatac/services/tmall.py,sha256=aUcF0PhaLu-22LIFyQBN4ssqZhAQ3ntRV8BuJRZjdvo,2198
+rqdatac/services/xueqiu.py,sha256=N_fMI5JpVazZwttNSJDkFvNLGhSGP7uLmVB3etWNk3c,3547
+rqdatac/services/detail/__init__.py,sha256=j0TW7Ke3BzRxHBI0o4WCsAo95vQAnmxWkUw0CJe2Wvk,58
+rqdatac/services/detail/adjust_price.py,sha256=joJX2fdjR2p4TnAfkW9Sg3ULF7Li2jQbrQQMr28JpmE,5569
+rqdatac/services/detail/get_price_df.py,sha256=GyD3a0DSBKf2up30jSqr_2zVQScT_tsTxVHc-LWkP_U,13707
+rqdatac/services/detail/resample_helper.py,sha256=IUPM3XzJmci_EVwsfKD-zifZhdFoaQNGS1bqhm0fZ-Y,1768
+rqdatac/services/orm/__init__.py,sha256=eoZ6GfifbqhMLNzjlqRDVil-yyBkOmVN9ujSgJWNBlY,15
+rqdatac/services/orm/pit_financials_ex.py,sha256=-GoCyBhaLUjNY1oHu0-t5Ayh-u-E692hLYVKE8mWia8,12408
 rqdatac/share/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-rqdatac/share/codec.py,sha256=KYSRcPif3xqXzKVkiXxBwesLuA0THBmuOhBmudKpe3k,5289
-rqdatac/share/errors.py,sha256=BBBnwcxoSRRnxDfGPCBF9UNh0mEe2AI6PISjlBWnSg4,1728
-rqdatac/share/protocol.py,sha256=Gmx2kC04hfqZhsy6EqmxM_y_UWu6k7B9TCRpHzMpP5o,1817
-rqdatac-3.0.6.dist-info/METADATA,sha256=Xvr7HfhhNnln7xmkKmazaAdj6sLvwdSea62X_7Vf0zA,2517
-rqdatac-3.0.6.dist-info/WHEEL,sha256=jr7ubY0Lkz_yXH9FfFe9PTtLhGOsf62dZkNvTYrJINE,100
-rqdatac-3.0.6.dist-info/top_level.txt,sha256=I8Iv5zqeIYph4_6GREZAPsFzfVvodVwdc-ZHdtjJWCY,8
-rqdatac-3.0.6.dist-info/RECORD,,
+rqdatac/share/codec.py,sha256=nOlsaQrrA8LnAS9PPSUqdUtPGdybpYX9fLrrveI5fVc,5113
+rqdatac/share/errors.py,sha256=_Z1uTWszlpME6CYJhjseoyFVcmBfsK_l0z9FnQEuJ9M,1644
+rqdatac/share/protocol.py,sha256=t8U1io5epFfn9rC0PEO-IXhTgQhlfyPzF85PV3Cb_4w,1741
+rqdatac-3.0.7.1.dist-info/METADATA,sha256=Sn_29SB8lssVQtAdAFylIZoiOWCAS-JEP14Tr5ewz7k,2482
+rqdatac-3.0.7.1.dist-info/WHEEL,sha256=pfjXB0CCNW4PSSqQc2t4Up6p3o0jxBnHy_2o38FQkyE,109
+rqdatac-3.0.7.1.dist-info/top_level.txt,sha256=I8Iv5zqeIYph4_6GREZAPsFzfVvodVwdc-ZHdtjJWCY,8
+rqdatac-3.0.7.1.dist-info/RECORD,,
```

